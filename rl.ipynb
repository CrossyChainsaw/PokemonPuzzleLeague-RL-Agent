{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment Configuration\n",
    "- Start Dolphin\n",
    "- Load save state f1\n",
    "- in the worst case scenario set it up manually player1=ash player2=gary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Imports Versioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29.1\n",
      "3.9.2\n",
      "2.4.1+cpu\n",
      "0.19.1+cpu\n",
      "2.4.1+cpu\n",
      "0.9.54\n",
      "1.26.4\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib\n",
    "import torch\n",
    "import torchvision\n",
    "import torchaudio\n",
    "import pyautogui\n",
    "import numpy as np\n",
    "\n",
    "print(gym.__version__)          # 0.29.1\n",
    "print(matplotlib.__version__)   # 3.9.2\n",
    "print(torch.__version__)        # 2.4.1+cpu\n",
    "print(torchvision.__version__)  # 0.19.1+cpu\n",
    "print(torchaudio.__version__)   # 2.4.1+cpu\n",
    "print(pyautogui.__version__)    # 0.9.54\n",
    "print(np.__version__)           # 1.26.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Initialise Environment, Model & Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from DQNCNNAveragePooling import DQNCNN\n",
    "from DQNAgent import DQNAgent\n",
    "from PPLEnv import PPLEnv\n",
    "\n",
    "# States\n",
    "P1_CELL_BBOX_PJ64 = (348, 130, 830, 1004)\n",
    "P1_CELL_BBOX_DOLPHIN = (390, 160, 845, 960)\n",
    "\n",
    "env = PPLEnv(state_bbox=P1_CELL_BBOX_DOLPHIN, color_mode='color')\n",
    "deep_q_learning_model = DQNCNN(action_size=env.action_space.n)\n",
    "agent = DQNAgent(deep_q_learning_model, action_size=env.action_space.n)\n",
    "env.action_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.5098, 2.6084, 2.7086, 2.7665, 2.6565],\n",
      "        [2.4390, 2.6628, 2.5021, 2.6694, 2.5635],\n",
      "        [2.8311, 2.6964, 2.7631, 3.2727, 3.1105],\n",
      "        [2.6325, 2.8417, 2.7454, 2.7510, 2.7260],\n",
      "        [2.5966, 2.7845, 2.7391, 2.7622, 2.6967],\n",
      "        [2.7904, 2.6864, 2.7693, 3.3309, 3.0862],\n",
      "        [2.3836, 2.7116, 2.5952, 2.6772, 2.7295],\n",
      "        [2.5638, 2.7199, 2.5211, 2.7493, 2.7229],\n",
      "        [2.4636, 2.8045, 2.6343, 2.7057, 2.5045],\n",
      "        [2.4763, 2.6904, 2.6358, 2.6438, 2.5076],\n",
      "        [2.3254, 2.5886, 2.5023, 2.5491, 2.4936],\n",
      "        [2.3659, 2.5580, 2.5878, 2.6320, 2.4770],\n",
      "        [2.6380, 2.6784, 2.6663, 2.6672, 2.5167],\n",
      "        [2.9159, 3.1560, 2.7288, 2.8833, 2.7159],\n",
      "        [2.6591, 2.8481, 2.6476, 2.8218, 2.8271],\n",
      "        [2.5556, 2.7493, 2.5878, 2.7519, 2.8016],\n",
      "        [2.6147, 2.7287, 2.6637, 2.8372, 2.7686],\n",
      "        [2.3426, 2.7237, 2.4692, 2.6852, 2.4824],\n",
      "        [2.4683, 2.6792, 2.4952, 2.7116, 2.5588],\n",
      "        [2.4661, 2.5871, 2.6173, 2.6917, 2.5972],\n",
      "        [2.8653, 3.0824, 2.7928, 2.8677, 2.7899],\n",
      "        [2.4929, 2.5955, 2.6799, 2.7319, 2.6295],\n",
      "        [2.4661, 2.5715, 2.6287, 2.7089, 2.6582],\n",
      "        [2.4537, 2.7819, 2.6704, 2.6249, 2.6729],\n",
      "        [2.5658, 2.6981, 2.7554, 2.8166, 2.6477],\n",
      "        [2.4390, 2.6619, 2.5995, 2.5606, 2.5487],\n",
      "        [2.4912, 2.5532, 2.6650, 2.7334, 2.6963],\n",
      "        [2.6494, 2.8784, 2.7851, 2.9300, 2.8393],\n",
      "        [2.6238, 2.7478, 2.7093, 2.7531, 2.4911],\n",
      "        [2.5921, 2.6718, 2.6903, 2.8597, 2.5622],\n",
      "        [2.6223, 2.7386, 2.7092, 2.7516, 2.5036],\n",
      "        [2.3667, 2.6338, 2.6327, 2.6537, 2.5237],\n",
      "        [2.6003, 2.6386, 2.7057, 2.8102, 2.6308],\n",
      "        [2.5762, 2.6353, 2.6794, 2.7663, 2.6094],\n",
      "        [2.3841, 2.5270, 2.5521, 2.6264, 2.4937],\n",
      "        [2.3741, 2.7878, 2.6078, 2.5200, 2.6857],\n",
      "        [2.4005, 2.6476, 2.5116, 2.6355, 2.5463],\n",
      "        [2.5327, 2.5505, 2.6335, 2.7250, 2.5570],\n",
      "        [2.5072, 2.7449, 2.5288, 2.6707, 2.6245],\n",
      "        [2.4891, 2.7012, 2.5020, 2.7444, 2.5858],\n",
      "        [2.4597, 2.5198, 2.5486, 2.6244, 2.6533],\n",
      "        [3.0783, 3.3096, 2.8862, 3.0333, 2.8364],\n",
      "        [2.5145, 2.6344, 2.6312, 2.7620, 2.6236],\n",
      "        [2.3421, 2.5875, 2.5737, 2.6047, 2.4999],\n",
      "        [2.8060, 2.7134, 2.7889, 3.3400, 3.0866],\n",
      "        [2.4229, 2.7031, 2.5468, 2.7709, 2.5373],\n",
      "        [2.3470, 2.5864, 2.5784, 2.6076, 2.4995],\n",
      "        [2.3628, 2.5541, 2.5260, 2.6090, 2.5046],\n",
      "        [2.5883, 2.6446, 2.6867, 2.7860, 2.6169],\n",
      "        [2.4371, 2.6609, 2.6001, 2.5607, 2.5434],\n",
      "        [2.4074, 2.6023, 2.5093, 2.6763, 2.5116],\n",
      "        [2.7539, 2.7314, 2.6862, 2.8036, 2.7430],\n",
      "        [2.9255, 3.1002, 2.6829, 2.9040, 2.6826],\n",
      "        [2.5838, 2.7669, 2.7555, 2.7487, 2.5769],\n",
      "        [2.4317, 2.8484, 2.6365, 2.7800, 2.7641],\n",
      "        [2.4655, 2.5987, 2.6161, 2.7007, 2.5979],\n",
      "        [2.4400, 2.5869, 2.7166, 2.5809, 2.7149],\n",
      "        [2.4777, 2.5403, 2.5900, 2.6710, 2.6753],\n",
      "        [2.6766, 2.7769, 2.7818, 2.7902, 2.5519],\n",
      "        [2.3969, 2.8310, 2.6081, 2.7507, 2.7188],\n",
      "        [2.7314, 2.9486, 2.6293, 2.8017, 2.7153],\n",
      "        [2.4754, 2.5384, 2.5859, 2.6693, 2.6713],\n",
      "        [2.4547, 2.6411, 2.5696, 2.7576, 2.6119],\n",
      "        [2.5381, 2.7157, 2.7150, 2.7708, 2.6723]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.7991, 3.0393, 2.7749, 2.8255, 2.7776],\n",
      "        [2.6703, 2.8916, 2.8474, 2.8867, 2.6168],\n",
      "        [2.3293, 2.4907, 2.5335, 2.5644, 2.4263],\n",
      "        [2.6271, 2.7396, 2.7571, 2.8389, 2.6034],\n",
      "        [2.5231, 2.6083, 2.7290, 2.9080, 2.8696],\n",
      "        [2.5888, 2.8405, 2.6266, 2.9361, 2.7315],\n",
      "        [2.3983, 2.5520, 2.4514, 2.6855, 2.4450],\n",
      "        [2.3690, 2.5527, 2.5637, 2.6172, 2.5097],\n",
      "        [2.5042, 2.7304, 2.4890, 2.6711, 2.6076],\n",
      "        [2.6782, 2.8685, 2.6751, 2.8588, 2.8515],\n",
      "        [2.4800, 2.5559, 2.5295, 2.7771, 2.5028],\n",
      "        [2.4720, 2.6661, 2.5364, 2.7657, 2.5999],\n",
      "        [2.3590, 2.5538, 2.5272, 2.5997, 2.4976],\n",
      "        [2.4883, 2.7519, 2.6149, 2.6739, 2.6680],\n",
      "        [2.4491, 2.5705, 2.6325, 2.7106, 2.6543],\n",
      "        [2.4847, 2.6901, 2.6427, 2.6627, 2.5155],\n",
      "        [2.3221, 2.4963, 2.5371, 2.5690, 2.4193],\n",
      "        [2.4975, 2.7214, 2.4726, 2.6643, 2.5981],\n",
      "        [2.6472, 2.8764, 2.7822, 2.9241, 2.8380],\n",
      "        [2.6113, 3.0099, 2.6967, 3.0003, 2.8690],\n",
      "        [2.3866, 2.6071, 2.6305, 2.6703, 2.4956],\n",
      "        [2.6924, 2.8732, 2.7489, 2.8817, 2.8438],\n",
      "        [2.4865, 2.5402, 2.6553, 2.7123, 2.6851],\n",
      "        [2.4623, 2.6821, 2.5076, 2.6827, 2.5760],\n",
      "        [2.9299, 3.2375, 2.7493, 2.9472, 2.7396],\n",
      "        [2.4214, 2.6426, 2.5032, 2.6454, 2.5364],\n",
      "        [2.6202, 2.8237, 2.6719, 2.7558, 2.6844],\n",
      "        [2.6572, 2.6057, 2.5679, 2.6521, 2.6607],\n",
      "        [2.4427, 2.7264, 2.5522, 2.7952, 2.5438],\n",
      "        [2.4545, 2.6908, 2.5139, 2.7026, 2.5715],\n",
      "        [2.6470, 2.8007, 2.7604, 2.8704, 2.6951],\n",
      "        [2.5776, 2.6349, 2.6796, 2.7661, 2.6103],\n",
      "        [2.4750, 2.5896, 2.5644, 2.7532, 2.5346],\n",
      "        [2.6121, 2.9292, 2.7074, 2.9392, 2.7985],\n",
      "        [2.3857, 2.4807, 2.5212, 2.6324, 2.4717],\n",
      "        [2.5898, 2.6500, 2.6249, 2.9059, 2.7018],\n",
      "        [2.4271, 2.5789, 2.7229, 2.5585, 2.7136],\n",
      "        [2.6153, 2.8356, 2.6136, 2.7818, 2.7573],\n",
      "        [2.8754, 3.0713, 2.6716, 2.8831, 2.6974],\n",
      "        [2.6234, 2.9330, 2.7076, 2.9525, 2.8015],\n",
      "        [2.3849, 2.7112, 2.5954, 2.6771, 2.7303],\n",
      "        [2.5085, 2.7448, 2.5238, 2.6801, 2.6297],\n",
      "        [2.6360, 2.7893, 2.7759, 2.9487, 2.6607],\n",
      "        [2.7426, 2.8115, 2.7536, 2.9986, 2.8326],\n",
      "        [2.4175, 2.6556, 2.5994, 2.7779, 2.5439],\n",
      "        [2.5049, 2.5782, 2.6817, 2.7306, 2.6046],\n",
      "        [2.4958, 2.6908, 2.5500, 2.7245, 2.6232],\n",
      "        [2.4627, 2.5880, 2.6149, 2.6985, 2.6024],\n",
      "        [2.7152, 2.7967, 2.6393, 2.8642, 2.8166],\n",
      "        [2.3683, 2.5676, 2.6016, 2.7097, 2.5886],\n",
      "        [2.5601, 2.7080, 2.5940, 2.8056, 2.6675],\n",
      "        [2.6020, 2.8255, 2.7435, 2.7754, 2.5599],\n",
      "        [2.5759, 2.7899, 2.7052, 2.7821, 2.5602],\n",
      "        [2.3359, 2.6091, 2.5066, 2.6211, 2.5006],\n",
      "        [2.6079, 2.6963, 2.7793, 2.7677, 2.4912],\n",
      "        [2.3866, 2.6071, 2.6305, 2.6703, 2.4956],\n",
      "        [2.5217, 2.6954, 2.6466, 2.7148, 2.6228],\n",
      "        [2.3826, 2.7083, 2.4793, 2.6801, 2.4920],\n",
      "        [2.4595, 2.7640, 2.5883, 2.8295, 2.6010],\n",
      "        [2.4777, 2.6900, 2.6361, 2.6438, 2.5084],\n",
      "        [2.5029, 2.8353, 2.5850, 2.5544, 2.6512],\n",
      "        [2.6065, 2.8401, 2.7130, 2.8598, 2.7026],\n",
      "        [2.3993, 2.6184, 2.5031, 2.6745, 2.5100],\n",
      "        [2.5099, 2.9469, 2.6405, 2.9235, 2.7843]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.4964, 2.9469, 2.6320, 2.9162, 2.7776],\n",
      "        [2.4153, 2.8122, 2.6690, 2.7509, 2.7171],\n",
      "        [2.3437, 2.6740, 2.6106, 2.6150, 2.5354],\n",
      "        [2.6071, 2.6830, 2.6985, 2.7123, 2.5575],\n",
      "        [3.0817, 3.3096, 2.8869, 3.0333, 2.8384],\n",
      "        [2.5071, 2.6057, 2.7090, 2.7576, 2.6553],\n",
      "        [2.8112, 3.0118, 2.6515, 2.8320, 2.7127],\n",
      "        [2.6456, 2.9435, 2.7275, 2.9814, 2.8189],\n",
      "        [2.5027, 2.5317, 2.6119, 2.6099, 2.5251],\n",
      "        [2.4843, 2.5858, 2.6385, 2.6992, 2.6075],\n",
      "        [2.3507, 2.6078, 2.5075, 2.5707, 2.5105],\n",
      "        [2.4166, 2.7044, 2.6247, 2.5677, 2.5122],\n",
      "        [2.3186, 2.5117, 2.5029, 2.5419, 2.4646],\n",
      "        [2.5904, 2.8401, 2.6270, 2.9359, 2.7326],\n",
      "        [2.6460, 2.9471, 2.7272, 2.9774, 2.8212],\n",
      "        [2.7166, 2.5609, 2.6854, 3.0703, 2.9568],\n",
      "        [2.4747, 2.6116, 2.6260, 2.7154, 2.6236],\n",
      "        [3.0746, 3.2979, 2.8961, 3.0597, 2.8248],\n",
      "        [2.6221, 2.7056, 2.7269, 2.8832, 2.5978],\n",
      "        [2.4175, 2.5662, 2.5987, 2.6643, 2.5870],\n",
      "        [2.6400, 2.7688, 2.7089, 2.8545, 2.8225],\n",
      "        [2.9409, 3.1537, 2.7707, 2.9159, 2.7226],\n",
      "        [2.8123, 3.0168, 2.6568, 2.8477, 2.7175],\n",
      "        [2.4631, 2.5448, 2.6506, 2.6064, 2.6362],\n",
      "        [2.5860, 2.8237, 2.6400, 2.7966, 2.7020],\n",
      "        [2.6677, 2.6039, 2.5753, 2.6544, 2.6684],\n",
      "        [2.4212, 2.5578, 2.6033, 2.6549, 2.5680],\n",
      "        [2.5136, 2.7253, 2.5040, 2.7744, 2.6023],\n",
      "        [2.7345, 2.7559, 2.7817, 2.9921, 2.7807],\n",
      "        [2.5088, 2.9183, 2.6568, 2.8845, 2.7716],\n",
      "        [2.6517, 2.8124, 2.7737, 2.8765, 2.7089],\n",
      "        [2.5693, 2.9214, 2.6964, 2.8248, 2.7387],\n",
      "        [2.4176, 2.8891, 2.7282, 2.7323, 2.6084],\n",
      "        [2.3996, 2.8951, 2.7245, 2.7086, 2.6018],\n",
      "        [2.3905, 2.6527, 2.7844, 2.6612, 2.7394],\n",
      "        [2.5135, 2.8232, 2.6562, 2.7964, 2.7984],\n",
      "        [2.4418, 2.6620, 2.5029, 2.6691, 2.5654],\n",
      "        [2.5538, 2.9076, 2.7622, 2.8422, 2.8185],\n",
      "        [2.4713, 2.6307, 2.6104, 2.6772, 2.7328],\n",
      "        [2.5245, 2.8795, 2.7060, 2.8243, 2.8155],\n",
      "        [2.5644, 2.9268, 2.6963, 2.8289, 2.7327],\n",
      "        [2.6168, 2.8353, 2.6140, 2.7817, 2.7583],\n",
      "        [2.5199, 2.6232, 2.7173, 2.7567, 2.6664],\n",
      "        [2.4284, 2.5156, 2.5561, 2.6556, 2.4864],\n",
      "        [2.4677, 2.7654, 2.5738, 2.6441, 2.6372],\n",
      "        [2.4175, 2.8468, 2.6936, 2.7582, 2.7835],\n",
      "        [2.6180, 2.8602, 2.7449, 2.8592, 2.7115],\n",
      "        [2.5116, 2.7802, 2.6180, 2.7102, 2.6797],\n",
      "        [2.4788, 2.5680, 2.6394, 2.6934, 2.5879],\n",
      "        [2.7379, 2.6695, 2.6686, 3.1704, 2.9037],\n",
      "        [2.5059, 2.9371, 2.6746, 2.8961, 2.7991],\n",
      "        [2.5003, 2.5595, 2.6823, 2.7531, 2.7040],\n",
      "        [2.6265, 2.7467, 2.7297, 2.9078, 2.7121],\n",
      "        [2.7704, 2.6933, 2.7729, 3.3128, 3.0950],\n",
      "        [2.1949, 2.4804, 2.5115, 2.5031, 2.4883],\n",
      "        [2.6022, 2.6793, 2.7010, 2.7108, 2.5456],\n",
      "        [2.6620, 2.8475, 2.6482, 2.8218, 2.8290],\n",
      "        [2.6125, 2.7071, 2.7060, 2.7352, 2.5318],\n",
      "        [2.5689, 2.6210, 2.6805, 2.6516, 2.6220],\n",
      "        [2.7712, 2.7635, 2.7921, 3.0346, 2.8586],\n",
      "        [2.2942, 2.5458, 2.4900, 2.5002, 2.4556],\n",
      "        [2.4540, 2.5684, 2.6327, 2.7094, 2.6662],\n",
      "        [2.4493, 2.4969, 2.6156, 2.6907, 2.6255],\n",
      "        [2.4592, 2.6056, 2.6182, 2.7029, 2.6016]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.6217, 2.8171, 2.7376, 2.7386, 2.7166],\n",
      "        [2.4354, 2.4816, 2.5106, 2.6369, 2.4621],\n",
      "        [2.5684, 2.7620, 2.5939, 2.7916, 2.7473],\n",
      "        [2.8085, 2.8023, 2.7656, 2.9050, 2.7603],\n",
      "        [2.6544, 2.8697, 2.7869, 2.9282, 2.8487],\n",
      "        [2.7246, 2.7926, 2.7302, 2.8250, 2.7420],\n",
      "        [2.3894, 2.6384, 2.5111, 2.6160, 2.5390],\n",
      "        [2.6604, 2.5607, 2.6830, 2.9890, 2.8995],\n",
      "        [2.6020, 2.7627, 2.7811, 2.7766, 2.5923],\n",
      "        [2.8059, 2.8319, 2.7540, 2.9182, 2.8049],\n",
      "        [2.3761, 2.5533, 2.5892, 2.6353, 2.4782],\n",
      "        [2.3431, 2.6649, 2.6113, 2.6111, 2.5274],\n",
      "        [2.5879, 2.5383, 2.7817, 2.7845, 2.6688],\n",
      "        [2.4871, 2.6776, 2.5481, 2.7072, 2.6124],\n",
      "        [2.4092, 2.6765, 2.5358, 2.7472, 2.5337],\n",
      "        [2.6764, 2.8531, 2.6568, 2.8223, 2.8324],\n",
      "        [2.8386, 2.6953, 2.7654, 3.2733, 3.1138],\n",
      "        [2.6479, 2.7653, 2.7437, 2.8318, 2.7935],\n",
      "        [2.5632, 2.6124, 2.6719, 2.6571, 2.5856],\n",
      "        [2.5946, 2.8398, 2.6287, 2.9365, 2.7337],\n",
      "        [2.4661, 2.7141, 2.5677, 2.7321, 2.6666],\n",
      "        [2.4776, 2.6446, 2.5625, 2.6422, 2.5787],\n",
      "        [2.3875, 2.7781, 2.7021, 2.6847, 2.7489],\n",
      "        [2.5147, 2.8407, 2.6115, 2.8805, 2.6991],\n",
      "        [2.4600, 2.7246, 2.6449, 2.6025, 2.5388],\n",
      "        [2.6253, 2.8292, 2.7567, 2.7812, 2.5606],\n",
      "        [2.4814, 2.6560, 2.5977, 2.6869, 2.6013],\n",
      "        [2.4679, 2.6366, 2.5502, 2.7165, 2.5605],\n",
      "        [2.4197, 2.8119, 2.6706, 2.7516, 2.7181],\n",
      "        [2.4057, 2.5633, 2.4575, 2.7019, 2.5105],\n",
      "        [2.7882, 2.7291, 2.6851, 2.8349, 2.7364],\n",
      "        [2.3503, 2.6918, 2.6283, 2.6184, 2.5429],\n",
      "        [2.6782, 2.8738, 2.7332, 2.8502, 2.8400],\n",
      "        [2.5513, 2.8614, 2.7495, 2.8272, 2.8633],\n",
      "        [2.7046, 2.7813, 2.7587, 2.9220, 2.6601],\n",
      "        [2.5136, 2.7219, 2.5193, 2.7703, 2.6113],\n",
      "        [2.4673, 2.5985, 2.7007, 2.6126, 2.7181],\n",
      "        [2.6828, 2.7798, 2.7484, 2.9470, 2.7425],\n",
      "        [2.6293, 2.9326, 2.7096, 2.9532, 2.8036],\n",
      "        [2.6519, 2.7644, 2.7338, 2.8885, 2.6558],\n",
      "        [2.5759, 2.7195, 2.5265, 2.7543, 2.7360],\n",
      "        [2.3460, 2.6048, 2.5833, 2.6062, 2.5059],\n",
      "        [2.6531, 2.8799, 2.7825, 2.9228, 2.8353],\n",
      "        [2.5729, 2.7573, 2.7902, 2.8405, 2.7611],\n",
      "        [2.7319, 2.5452, 2.6745, 3.1073, 2.9739],\n",
      "        [2.3609, 2.8185, 2.6646, 2.6674, 2.7569],\n",
      "        [2.3737, 2.6327, 2.6352, 2.6541, 2.5267],\n",
      "        [2.4726, 2.5974, 2.6183, 2.7011, 2.6008],\n",
      "        [2.3486, 2.6787, 2.6149, 2.6242, 2.5447],\n",
      "        [2.5416, 2.5693, 2.6512, 2.7321, 2.6052],\n",
      "        [2.5081, 2.6048, 2.6901, 2.7460, 2.6365],\n",
      "        [2.8529, 3.0485, 2.6667, 2.8640, 2.7153],\n",
      "        [2.4015, 2.5197, 2.5502, 2.6351, 2.4988],\n",
      "        [2.3478, 2.6738, 2.6123, 2.6157, 2.5364],\n",
      "        [2.5551, 2.9351, 2.7341, 2.8606, 2.8894],\n",
      "        [2.9123, 3.1963, 2.7222, 2.9084, 2.7025],\n",
      "        [2.6404, 2.7507, 2.7234, 2.9211, 2.7079],\n",
      "        [2.5376, 2.6736, 2.6372, 2.8222, 2.6351],\n",
      "        [2.6655, 2.8438, 2.7251, 2.8442, 2.7989],\n",
      "        [2.5932, 2.8380, 2.6281, 2.9357, 2.7308],\n",
      "        [2.5634, 2.8256, 2.7353, 2.8371, 2.7756],\n",
      "        [2.7323, 2.8160, 2.6571, 2.8964, 2.8167],\n",
      "        [2.3500, 2.6181, 2.5931, 2.6181, 2.5243],\n",
      "        [2.3880, 2.7245, 2.5018, 2.6931, 2.4987]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.5736, 2.7617, 2.7468, 2.8097, 2.7113],\n",
      "        [2.5520, 2.6922, 2.6594, 2.7275, 2.6367],\n",
      "        [2.4156, 2.8347, 2.6315, 2.7391, 2.7623],\n",
      "        [2.4134, 2.6742, 2.5639, 2.6546, 2.5921],\n",
      "        [2.2484, 2.5183, 2.5345, 2.5365, 2.5166],\n",
      "        [2.6810, 2.7742, 2.7573, 2.9206, 2.7549],\n",
      "        [2.6593, 2.7817, 2.7806, 2.8154, 2.7933],\n",
      "        [2.4854, 2.5354, 2.5805, 2.6613, 2.6721],\n",
      "        [2.4128, 2.5401, 2.5726, 2.6421, 2.4969],\n",
      "        [2.2753, 2.6631, 2.7034, 2.5757, 2.6127],\n",
      "        [2.7739, 2.8076, 2.8346, 3.0461, 2.8343],\n",
      "        [2.4216, 2.6564, 2.5941, 2.7831, 2.5379],\n",
      "        [2.6500, 2.8461, 2.6477, 2.8938, 2.7950],\n",
      "        [2.5060, 2.5854, 2.6427, 2.7304, 2.6604],\n",
      "        [2.5682, 2.7216, 2.5965, 2.7880, 2.6679],\n",
      "        [2.5959, 2.7983, 2.7395, 2.8415, 2.7050],\n",
      "        [2.4746, 2.6779, 2.6220, 2.6947, 2.6226],\n",
      "        [2.5573, 2.6940, 2.7272, 2.7937, 2.6564],\n",
      "        [2.3755, 2.5409, 2.5622, 2.6187, 2.4987],\n",
      "        [2.7984, 2.7904, 2.7619, 2.8942, 2.7481],\n",
      "        [2.5035, 2.8290, 2.5838, 2.7812, 2.6564],\n",
      "        [2.6180, 2.8139, 2.6691, 2.7075, 2.6734],\n",
      "        [2.5003, 2.7686, 2.6002, 2.8099, 2.6082],\n",
      "        [2.4691, 2.6148, 2.7155, 2.8298, 2.8052],\n",
      "        [2.6709, 2.8471, 2.6514, 2.8248, 2.8322],\n",
      "        [2.6109, 2.9021, 2.6678, 2.6386, 2.7176],\n",
      "        [2.5220, 2.6088, 2.7131, 2.7648, 2.6655],\n",
      "        [2.5889, 2.8394, 2.7488, 2.8544, 2.6913],\n",
      "        [2.5757, 2.6338, 2.6516, 2.6412, 2.4653],\n",
      "        [2.3951, 2.4796, 2.5245, 2.6350, 2.4758],\n",
      "        [2.4821, 2.5889, 2.6254, 2.6922, 2.6008],\n",
      "        [2.4999, 2.6998, 2.5059, 2.7467, 2.5910],\n",
      "        [2.3523, 2.5945, 2.5109, 2.5693, 2.5241],\n",
      "        [2.3993, 2.8340, 2.6300, 2.7258, 2.7611],\n",
      "        [2.3873, 2.5925, 2.6190, 2.6449, 2.5158],\n",
      "        [2.6188, 2.9678, 2.7422, 3.0059, 2.8688],\n",
      "        [2.3459, 2.5135, 2.5147, 2.5674, 2.4790],\n",
      "        [2.5788, 2.6394, 2.6812, 2.6808, 2.5542],\n",
      "        [2.5098, 2.7146, 2.5063, 2.7772, 2.6044],\n",
      "        [2.4842, 2.6832, 2.5930, 2.6853, 2.6058],\n",
      "        [2.3984, 2.7955, 2.6225, 2.5375, 2.7094],\n",
      "        [2.3815, 2.6378, 2.5612, 2.7603, 2.5019],\n",
      "        [3.0317, 3.3205, 2.8315, 3.0303, 2.8081],\n",
      "        [2.4530, 2.6294, 2.4209, 2.7507, 2.4521],\n",
      "        [2.8882, 3.1441, 2.6743, 2.8461, 2.7158],\n",
      "        [2.7422, 2.5495, 2.6939, 3.0988, 2.9662],\n",
      "        [2.6576, 2.6854, 2.6693, 2.6737, 2.5309],\n",
      "        [2.4964, 2.5392, 2.6586, 2.7149, 2.6895],\n",
      "        [2.6122, 2.7265, 2.6756, 2.8351, 2.7847],\n",
      "        [2.7782, 2.9736, 2.8277, 3.1535, 2.9319],\n",
      "        [2.6229, 2.8051, 2.7500, 2.9431, 2.6693],\n",
      "        [2.5234, 2.8260, 2.6629, 2.8027, 2.8049],\n",
      "        [2.5145, 2.9367, 2.6779, 2.8990, 2.8023],\n",
      "        [2.6018, 2.8062, 2.6377, 2.8670, 2.7064],\n",
      "        [2.5702, 2.7194, 2.5774, 2.7771, 2.6478],\n",
      "        [2.6986, 2.7809, 2.7508, 2.9542, 2.7639],\n",
      "        [2.3501, 2.6045, 2.5848, 2.6083, 2.5080],\n",
      "        [2.4935, 2.5236, 2.6055, 2.6164, 2.5231],\n",
      "        [2.8998, 3.1688, 2.7052, 2.8863, 2.6929],\n",
      "        [2.4175, 2.7408, 2.6061, 2.7027, 2.7580],\n",
      "        [2.4451, 2.5946, 2.5989, 2.7163, 2.5334],\n",
      "        [2.6155, 2.6825, 2.7015, 2.7151, 2.5607],\n",
      "        [2.4233, 2.5358, 2.5700, 2.6576, 2.4948],\n",
      "        [2.5775, 2.6205, 2.6835, 2.6545, 2.6253]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.7968, 2.7775, 2.7770, 2.8866, 2.7680],\n",
      "        [2.4840, 2.6024, 2.5099, 2.6797, 2.6876],\n",
      "        [2.4676, 2.6175, 2.5728, 2.6313, 2.5946],\n",
      "        [2.3938, 2.5402, 2.5866, 2.6361, 2.4804],\n",
      "        [2.3616, 2.5847, 2.5859, 2.6121, 2.5085],\n",
      "        [2.3830, 2.6982, 2.7666, 2.6917, 2.6687],\n",
      "        [2.6795, 2.6030, 2.5819, 2.6592, 2.6759],\n",
      "        [2.8902, 3.0711, 2.6788, 2.8884, 2.7060],\n",
      "        [2.4363, 2.5794, 2.5928, 2.7120, 2.5188],\n",
      "        [2.6587, 2.6821, 2.6730, 2.6632, 2.5346],\n",
      "        [2.4689, 2.7804, 2.6779, 2.6294, 2.6820],\n",
      "        [2.6825, 2.9048, 2.8433, 2.8740, 2.6264],\n",
      "        [2.6058, 2.9233, 2.6823, 2.8454, 2.7259],\n",
      "        [2.6861, 2.6270, 2.6579, 2.7352, 2.6446],\n",
      "        [2.5169, 2.7206, 2.5097, 2.7727, 2.6122],\n",
      "        [2.4759, 2.6876, 2.7684, 2.6639, 2.6361],\n",
      "        [2.5769, 2.6257, 2.6818, 2.6748, 2.5728],\n",
      "        [2.7118, 2.8740, 2.6981, 2.8799, 2.8834],\n",
      "        [2.6300, 2.8165, 2.7427, 2.7427, 2.7231],\n",
      "        [2.6645, 2.7740, 2.8726, 2.7928, 2.6045],\n",
      "        [2.7870, 2.9821, 2.6499, 2.8208, 2.7237],\n",
      "        [2.6297, 2.8345, 2.6208, 2.7865, 2.7658],\n",
      "        [2.7443, 2.9747, 2.7353, 2.7628, 2.7026],\n",
      "        [2.5094, 2.5169, 2.6035, 2.6064, 2.5175],\n",
      "        [2.4786, 2.5719, 2.6270, 2.6919, 2.5984],\n",
      "        [2.7725, 2.8039, 2.8316, 3.0597, 2.8446],\n",
      "        [2.7655, 2.9744, 2.8137, 3.1312, 2.9313],\n",
      "        [2.5176, 2.7730, 2.6298, 2.7152, 2.6798],\n",
      "        [2.6991, 2.7791, 2.7530, 2.9560, 2.7615],\n",
      "        [2.2454, 2.5184, 2.5296, 2.5363, 2.4937],\n",
      "        [2.4892, 2.8270, 2.5802, 2.8486, 2.6842],\n",
      "        [2.4736, 2.5820, 2.6297, 2.7027, 2.6059],\n",
      "        [2.4858, 2.5884, 2.6291, 2.6940, 2.6048],\n",
      "        [2.4760, 2.5980, 2.7042, 2.6146, 2.7354],\n",
      "        [2.6515, 2.8417, 2.6384, 2.8012, 2.7939],\n",
      "        [2.3057, 2.5450, 2.4965, 2.5048, 2.4626],\n",
      "        [2.3777, 2.6086, 2.6225, 2.6538, 2.5135],\n",
      "        [2.6437, 2.8386, 2.6405, 2.8859, 2.8080],\n",
      "        [2.6105, 2.8353, 2.6487, 2.7907, 2.7126],\n",
      "        [2.4950, 2.6931, 2.5079, 2.7445, 2.5951],\n",
      "        [2.6056, 2.9068, 2.6779, 2.8442, 2.7321],\n",
      "        [2.3807, 2.5875, 2.5857, 2.6239, 2.5399],\n",
      "        [2.6021, 2.8004, 2.7243, 2.9173, 2.6757],\n",
      "        [2.5849, 2.8218, 2.6153, 2.9128, 2.7069],\n",
      "        [3.0202, 3.2847, 2.7957, 2.9851, 2.8305],\n",
      "        [2.7598, 2.6865, 2.7765, 3.3003, 3.0993],\n",
      "        [2.6360, 2.6257, 2.6209, 3.0286, 2.7780],\n",
      "        [2.4522, 2.5626, 2.4637, 2.6483, 2.6615],\n",
      "        [2.3542, 2.5166, 2.5202, 2.5771, 2.4860],\n",
      "        [2.2361, 2.5021, 2.5344, 2.5211, 2.5085],\n",
      "        [2.5117, 2.7157, 2.5133, 2.7639, 2.6052],\n",
      "        [2.3910, 2.5921, 2.6226, 2.6469, 2.5199],\n",
      "        [2.4799, 2.7646, 2.5806, 2.6488, 2.6445],\n",
      "        [2.5026, 2.9323, 2.6802, 2.8965, 2.7950],\n",
      "        [2.6540, 2.8458, 2.6515, 2.8959, 2.7993],\n",
      "        [2.6291, 2.7670, 2.7511, 2.8549, 2.6231],\n",
      "        [2.3456, 2.6446, 2.6082, 2.6194, 2.5251],\n",
      "        [2.4942, 2.5337, 2.6038, 2.6870, 2.6849],\n",
      "        [2.6077, 2.6401, 2.6611, 2.6727, 2.4901],\n",
      "        [2.3303, 2.5108, 2.5094, 2.5466, 2.4716],\n",
      "        [2.7623, 2.9855, 2.8077, 3.1446, 2.9365],\n",
      "        [2.4388, 2.4882, 2.6559, 2.5210, 2.6443],\n",
      "        [2.6219, 2.8565, 2.6769, 2.8684, 2.7296],\n",
      "        [2.4395, 2.4927, 2.5288, 2.6446, 2.4805]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.4176, 2.6166, 2.5137, 2.6806, 2.5220],\n",
      "        [2.4994, 2.5711, 2.6613, 2.7089, 2.6106],\n",
      "        [2.7237, 2.8492, 2.7260, 3.0190, 2.8307],\n",
      "        [2.5222, 2.7524, 2.5679, 2.6698, 2.6521],\n",
      "        [2.5219, 2.7367, 2.5007, 2.6750, 2.6229],\n",
      "        [2.5808, 2.6891, 2.7628, 2.8292, 2.6473],\n",
      "        [2.6479, 2.7662, 2.7269, 2.8247, 2.7881],\n",
      "        [2.4954, 2.5816, 2.6998, 2.7456, 2.6442],\n",
      "        [2.7068, 2.6389, 2.6535, 2.7426, 2.6743],\n",
      "        [2.7227, 2.7106, 2.7636, 2.9566, 2.7510],\n",
      "        [2.7703, 2.7048, 2.7783, 2.9376, 2.7965],\n",
      "        [2.5167, 2.8436, 2.5607, 2.7492, 2.6300],\n",
      "        [2.4851, 2.7641, 2.5842, 2.6505, 2.6484],\n",
      "        [2.4985, 2.5440, 2.6541, 2.6960, 2.6045],\n",
      "        [2.3866, 2.6316, 2.6439, 2.6600, 2.5367],\n",
      "        [2.4523, 2.8463, 2.6478, 2.7864, 2.7769],\n",
      "        [2.7741, 2.8919, 2.7694, 3.0683, 2.8755],\n",
      "        [2.6332, 2.8245, 2.6699, 2.7929, 2.7026],\n",
      "        [2.4828, 2.7725, 2.6672, 2.6420, 2.6856],\n",
      "        [2.6065, 2.8368, 2.6372, 2.9415, 2.7413],\n",
      "        [2.4091, 2.5649, 2.6080, 2.6990, 2.6026],\n",
      "        [2.5990, 2.8349, 2.7253, 2.9326, 2.7039],\n",
      "        [3.0427, 3.3260, 2.8419, 3.0626, 2.8278],\n",
      "        [2.6159, 2.9391, 2.8063, 2.8878, 2.8582],\n",
      "        [2.4735, 2.5415, 2.6171, 2.6431, 2.5561],\n",
      "        [2.4971, 2.6937, 2.5117, 2.7420, 2.5900],\n",
      "        [2.5180, 2.7746, 2.6227, 2.8073, 2.6245],\n",
      "        [2.4189, 2.7894, 2.5829, 2.6366, 2.5172],\n",
      "        [2.7311, 2.8258, 2.7552, 3.0141, 2.7889],\n",
      "        [2.5103, 2.8460, 2.6069, 2.8752, 2.7049],\n",
      "        [2.6305, 2.6477, 2.7336, 2.8449, 2.6658],\n",
      "        [2.4093, 2.5018, 2.5463, 2.6438, 2.4955],\n",
      "        [2.9028, 3.0842, 2.6961, 2.9062, 2.7273],\n",
      "        [2.6102, 2.8295, 2.6675, 2.8335, 2.6963],\n",
      "        [2.3604, 2.5986, 2.5166, 2.5736, 2.5191],\n",
      "        [2.4700, 2.6478, 2.6071, 2.7278, 2.6730],\n",
      "        [2.4317, 2.6082, 2.5227, 2.6841, 2.5271],\n",
      "        [2.7681, 2.7096, 2.7822, 2.9442, 2.7948],\n",
      "        [2.5705, 2.6829, 2.6654, 2.7631, 2.7025],\n",
      "        [2.9940, 3.2297, 2.7900, 2.9612, 2.7909],\n",
      "        [2.5598, 2.6272, 2.7476, 2.7925, 2.6910],\n",
      "        [2.4890, 2.7404, 2.5700, 2.8327, 2.5624],\n",
      "        [2.5066, 2.5393, 2.6516, 2.7102, 2.6951],\n",
      "        [2.3918, 2.6652, 2.5048, 2.6839, 2.5374],\n",
      "        [2.5883, 2.7244, 2.7320, 2.7819, 2.6873],\n",
      "        [2.7731, 2.9365, 2.7459, 3.1320, 2.9063],\n",
      "        [2.4215, 2.5392, 2.5796, 2.6457, 2.5047],\n",
      "        [2.5771, 2.8245, 2.7448, 2.8431, 2.7860],\n",
      "        [2.4900, 2.5787, 2.6537, 2.6632, 2.5966],\n",
      "        [2.3555, 2.6215, 2.6031, 2.6133, 2.5185],\n",
      "        [2.4348, 2.5646, 2.6089, 2.6706, 2.5982],\n",
      "        [2.5094, 2.7035, 2.5065, 2.7526, 2.6013],\n",
      "        [2.4962, 2.5796, 2.5642, 2.7728, 2.5374],\n",
      "        [2.4781, 2.6084, 2.6310, 2.7119, 2.6161],\n",
      "        [2.4983, 2.5539, 2.5399, 2.7833, 2.5146],\n",
      "        [2.4909, 2.5629, 2.6601, 2.6450, 2.6468],\n",
      "        [3.0127, 3.2030, 2.8721, 2.9982, 2.8462],\n",
      "        [2.4905, 2.5802, 2.6368, 2.7004, 2.6092],\n",
      "        [2.5288, 2.7788, 2.6286, 2.7166, 2.6908],\n",
      "        [2.6383, 2.7421, 2.7128, 2.7518, 2.4850],\n",
      "        [2.5902, 2.7770, 2.7767, 2.8276, 2.7087],\n",
      "        [2.7428, 2.6553, 2.6724, 3.1418, 2.8889],\n",
      "        [2.4515, 2.6304, 2.7288, 2.7134, 2.6998],\n",
      "        [2.5864, 2.6960, 2.7665, 2.8229, 2.6609]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.5233, 2.7133, 2.5170, 2.7821, 2.6158],\n",
      "        [2.4572, 2.4765, 2.6101, 2.6770, 2.6208],\n",
      "        [2.3273, 2.5612, 2.5074, 2.5257, 2.4906],\n",
      "        [2.4691, 2.6295, 2.4556, 2.7602, 2.4869],\n",
      "        [2.5897, 2.7178, 2.5359, 2.7577, 2.7395],\n",
      "        [2.7779, 2.9321, 2.8232, 3.0992, 2.8545],\n",
      "        [2.4902, 2.5372, 2.6211, 2.6381, 2.5518],\n",
      "        [2.5138, 2.7012, 2.5163, 2.7479, 2.5980],\n",
      "        [2.5824, 2.6276, 2.7805, 2.8516, 2.6261],\n",
      "        [2.5935, 2.6371, 2.6976, 2.6781, 2.5754],\n",
      "        [2.8035, 2.6681, 2.6939, 3.2425, 2.9819],\n",
      "        [2.5953, 2.7765, 2.7805, 2.8291, 2.7124],\n",
      "        [2.6130, 2.8381, 2.6415, 2.9438, 2.7480],\n",
      "        [2.5249, 2.7592, 2.5910, 2.6674, 2.6644],\n",
      "        [2.4495, 2.8010, 2.6384, 2.6984, 2.5247],\n",
      "        [2.5768, 2.8630, 2.6492, 2.6046, 2.7193],\n",
      "        [2.4265, 2.4959, 2.5483, 2.6419, 2.5099],\n",
      "        [2.4700, 2.7957, 2.7180, 2.6343, 2.6723],\n",
      "        [2.4941, 2.6015, 2.5170, 2.6827, 2.6948],\n",
      "        [2.7371, 2.5509, 2.7065, 3.0788, 2.9615],\n",
      "        [2.4905, 2.6681, 2.5518, 2.7036, 2.6118],\n",
      "        [2.3183, 2.6504, 2.6992, 2.6140, 2.6114],\n",
      "        [2.6016, 2.6432, 2.6813, 2.7623, 2.6212],\n",
      "        [2.4717, 2.8303, 2.7029, 2.7804, 2.7914],\n",
      "        [2.5288, 2.9354, 2.6891, 2.9043, 2.8140],\n",
      "        [2.3660, 2.5156, 2.5621, 2.6012, 2.4695],\n",
      "        [2.7896, 2.8065, 2.8458, 3.0524, 2.8466],\n",
      "        [2.6140, 2.7896, 2.7650, 2.8408, 2.7665],\n",
      "        [2.5473, 2.5644, 2.8512, 2.7688, 2.7210],\n",
      "        [2.6287, 2.6877, 2.7136, 2.7358, 2.5476],\n",
      "        [2.5983, 2.7246, 2.7578, 2.7569, 2.5916],\n",
      "        [2.6647, 2.8447, 2.6589, 2.8993, 2.8070],\n",
      "        [2.6403, 2.8337, 2.6282, 2.7898, 2.7735],\n",
      "        [2.5328, 2.8392, 2.6239, 2.8878, 2.7127],\n",
      "        [2.6080, 2.6364, 2.7019, 2.7876, 2.6345],\n",
      "        [2.5663, 2.4927, 2.7609, 2.7897, 2.7117],\n",
      "        [2.5217, 2.8433, 2.5643, 2.7506, 2.6335],\n",
      "        [2.6849, 2.5559, 2.5804, 2.6911, 2.6147],\n",
      "        [2.3759, 2.6976, 2.6394, 2.6398, 2.5792],\n",
      "        [2.3913, 2.6108, 2.6588, 2.6758, 2.5042],\n",
      "        [2.6638, 2.7550, 2.7568, 2.9317, 2.7228],\n",
      "        [2.6411, 2.7260, 2.6791, 2.8453, 2.7867],\n",
      "        [2.6455, 2.8244, 2.6788, 2.7765, 2.7088],\n",
      "        [2.7786, 2.9361, 2.7496, 3.1339, 2.9102],\n",
      "        [2.6611, 2.9395, 2.7250, 2.9683, 2.8305],\n",
      "        [2.8357, 3.0157, 2.6711, 2.8562, 2.7325],\n",
      "        [2.6406, 2.7749, 2.7438, 2.8274, 2.8314],\n",
      "        [2.3610, 2.6403, 2.6102, 2.6139, 2.5283],\n",
      "        [2.5457, 2.6491, 2.6440, 2.7972, 2.6411],\n",
      "        [2.4629, 2.6903, 2.5636, 2.7355, 2.6720],\n",
      "        [2.4245, 2.7823, 2.6055, 2.6552, 2.5046],\n",
      "        [2.5051, 2.5624, 2.6794, 2.7164, 2.6150],\n",
      "        [2.7579, 2.8665, 2.7483, 3.0381, 2.8609],\n",
      "        [2.4726, 2.7976, 2.7150, 2.6195, 2.6983],\n",
      "        [2.6155, 2.8022, 2.7506, 2.8467, 2.7208],\n",
      "        [2.4409, 2.8873, 2.7430, 2.7404, 2.6238],\n",
      "        [2.7365, 2.8254, 2.7589, 3.0158, 2.7927],\n",
      "        [2.5531, 2.7828, 2.6205, 2.8194, 2.6672],\n",
      "        [2.4539, 2.4760, 2.6099, 2.6723, 2.6264],\n",
      "        [2.4529, 2.6149, 2.7139, 2.7932, 2.7706],\n",
      "        [2.5283, 2.7283, 2.5030, 2.6787, 2.6232],\n",
      "        [2.6342, 2.8975, 2.7012, 2.8486, 2.7469],\n",
      "        [2.6293, 2.6812, 2.7125, 2.7203, 2.5723],\n",
      "        [2.5156, 2.8366, 2.6041, 2.8729, 2.7057]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.5491, 2.6489, 2.6471, 2.7982, 2.6447],\n",
      "        [2.5270, 2.7057, 2.5146, 2.7611, 2.6041],\n",
      "        [2.4888, 2.5167, 2.5665, 2.6335, 2.6727],\n",
      "        [2.6560, 2.7445, 2.7475, 2.9187, 2.7313],\n",
      "        [2.8405, 3.0151, 2.6747, 2.8576, 2.7359],\n",
      "        [2.4037, 2.6421, 2.5387, 2.6992, 2.5463],\n",
      "        [2.4321, 2.6296, 2.5217, 2.6372, 2.5491],\n",
      "        [2.6338, 2.7142, 2.6765, 2.8405, 2.7829],\n",
      "        [2.9190, 3.1674, 2.7198, 2.8933, 2.7082],\n",
      "        [2.5211, 2.7621, 2.6218, 2.7087, 2.6945],\n",
      "        [2.5147, 2.5372, 2.6729, 2.7213, 2.7043],\n",
      "        [2.4276, 2.5031, 2.5542, 2.6516, 2.5082],\n",
      "        [2.5682, 2.8754, 2.7729, 2.8454, 2.9047],\n",
      "        [2.4886, 2.5478, 2.6322, 2.6432, 2.5706],\n",
      "        [2.6384, 2.9662, 2.7569, 3.0125, 2.8841],\n",
      "        [2.5351, 2.5558, 2.7037, 2.7682, 2.7247],\n",
      "        [2.6905, 2.8283, 2.8288, 2.8386, 2.6482],\n",
      "        [2.7453, 2.8312, 2.7837, 3.0206, 2.7799],\n",
      "        [2.4919, 2.5985, 2.6420, 2.7187, 2.6381],\n",
      "        [2.6392, 2.7046, 2.7235, 2.7446, 2.5499],\n",
      "        [2.4861, 2.6076, 2.6353, 2.7134, 2.6208],\n",
      "        [2.5135, 2.5376, 2.6634, 2.7154, 2.7034],\n",
      "        [2.6738, 2.9417, 2.7455, 2.9908, 2.8374],\n",
      "        [2.5422, 2.9389, 2.6437, 2.9286, 2.7850],\n",
      "        [2.6481, 2.8269, 2.7731, 2.7899, 2.5780],\n",
      "        [2.6275, 2.7814, 2.7572, 2.7715, 2.7172],\n",
      "        [2.7523, 2.8195, 2.8032, 2.9874, 2.8332],\n",
      "        [2.6165, 2.8356, 2.6445, 2.9443, 2.7486],\n",
      "        [2.3870, 2.5599, 2.5889, 2.6203, 2.5180],\n",
      "        [2.4519, 2.5653, 2.7451, 2.5458, 2.7415],\n",
      "        [2.5449, 2.8499, 2.6988, 2.8169, 2.8234],\n",
      "        [2.5077, 2.6878, 2.5131, 2.7393, 2.5887],\n",
      "        [2.5069, 2.7940, 2.6582, 2.7259, 2.5295],\n",
      "        [2.6841, 2.9059, 2.6977, 2.6895, 2.6618],\n",
      "        [2.3897, 2.6373, 2.6893, 2.7173, 2.6993],\n",
      "        [2.3424, 2.5771, 2.5175, 2.5393, 2.5028],\n",
      "        [2.5227, 2.5921, 2.6979, 2.7409, 2.6496],\n",
      "        [2.5920, 2.7276, 2.6939, 2.9085, 2.6751],\n",
      "        [2.4481, 2.6489, 2.5298, 2.6489, 2.5836],\n",
      "        [2.6179, 2.8374, 2.6452, 2.9452, 2.7515],\n",
      "        [2.4523, 2.5152, 2.5774, 2.6592, 2.5055],\n",
      "        [2.5897, 2.6084, 2.6924, 2.6613, 2.6301],\n",
      "        [2.3793, 2.6164, 2.6400, 2.6427, 2.5420],\n",
      "        [2.6064, 2.6425, 2.6848, 2.7637, 2.6246],\n",
      "        [2.6989, 2.7900, 2.8311, 2.9829, 2.6921],\n",
      "        [2.3925, 2.6070, 2.6328, 2.6584, 2.5242],\n",
      "        [2.7675, 2.5522, 2.6984, 3.1197, 3.0031],\n",
      "        [2.3953, 2.5859, 2.5961, 2.6284, 2.5505],\n",
      "        [2.4852, 2.6359, 2.4507, 2.7707, 2.4734],\n",
      "        [2.3807, 2.5671, 2.5892, 2.6177, 2.5166],\n",
      "        [2.4546, 2.5129, 2.5729, 2.6646, 2.5041],\n",
      "        [2.4123, 2.5522, 2.6099, 2.6936, 2.6003],\n",
      "        [2.4816, 2.6780, 2.5271, 2.7004, 2.5915],\n",
      "        [2.6128, 2.6357, 2.7055, 2.7890, 2.6379],\n",
      "        [2.4063, 2.8323, 2.7079, 2.7100, 2.7824],\n",
      "        [2.6361, 2.8639, 2.6840, 2.8566, 2.7376],\n",
      "        [2.5863, 2.6101, 2.6878, 2.6657, 2.6029],\n",
      "        [2.4789, 2.5685, 2.4844, 2.6625, 2.6801],\n",
      "        [2.4846, 2.5942, 2.6308, 2.7046, 2.6134],\n",
      "        [2.6074, 2.8111, 2.6391, 2.8149, 2.7219],\n",
      "        [2.3362, 2.5645, 2.5158, 2.5310, 2.4999],\n",
      "        [2.6445, 2.8173, 2.6904, 2.7176, 2.6969],\n",
      "        [2.6371, 2.7531, 2.7259, 2.8006, 2.7760],\n",
      "        [2.6179, 2.8374, 2.6452, 2.9452, 2.7515]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.3731, 2.5152, 2.5333, 2.5829, 2.4995],\n",
      "        [2.4175, 2.5237, 2.5728, 2.6364, 2.5162],\n",
      "        [2.8337, 3.0376, 2.7968, 2.8368, 2.8007],\n",
      "        [2.5092, 2.6839, 2.5275, 2.7153, 2.6128],\n",
      "        [2.3479, 2.5759, 2.4325, 2.6484, 2.4731],\n",
      "        [2.5407, 2.6862, 2.6536, 2.6924, 2.6407],\n",
      "        [2.6465, 2.7281, 2.8021, 2.8038, 2.6108],\n",
      "        [2.5475, 2.8242, 2.6815, 2.8108, 2.8231],\n",
      "        [2.4494, 2.5636, 2.6190, 2.6746, 2.6085],\n",
      "        [2.5885, 2.6852, 2.6733, 2.7497, 2.6479],\n",
      "        [2.4365, 2.6297, 2.5248, 2.6384, 2.5522],\n",
      "        [2.7874, 2.9731, 2.8286, 3.1382, 2.9464],\n",
      "        [2.5250, 2.7042, 2.5280, 2.7558, 2.6172],\n",
      "        [2.6715, 2.6752, 2.6878, 2.6774, 2.5399],\n",
      "        [2.6434, 2.8315, 2.6258, 2.7907, 2.7679],\n",
      "        [2.6178, 2.8334, 2.6150, 2.7786, 2.7442],\n",
      "        [2.6370, 2.6882, 2.7240, 2.7323, 2.5558],\n",
      "        [2.5867, 2.9052, 2.7852, 2.8532, 2.8404],\n",
      "        [2.5604, 2.6361, 2.6743, 2.6434, 2.4833],\n",
      "        [2.5143, 2.5618, 2.6860, 2.7189, 2.6215],\n",
      "        [2.8028, 2.8088, 2.8535, 3.0566, 2.8552],\n",
      "        [2.4794, 2.6622, 2.6400, 2.8015, 2.5920],\n",
      "        [2.5439, 2.7598, 2.5925, 2.8040, 2.6633],\n",
      "        [2.3355, 2.6514, 2.4390, 2.6499, 2.4582],\n",
      "        [2.6625, 2.8588, 2.7747, 2.8504, 2.7118],\n",
      "        [2.2261, 2.4781, 2.5309, 2.5135, 2.5088],\n",
      "        [2.2861, 2.5411, 2.5444, 2.5665, 2.5294],\n",
      "        [2.7238, 2.7793, 2.7689, 2.9631, 2.7833],\n",
      "        [2.6227, 2.8375, 2.6485, 2.9464, 2.7549],\n",
      "        [2.7115, 2.6311, 2.6702, 3.0917, 2.8587],\n",
      "        [2.7184, 2.5613, 2.7078, 3.0451, 2.9481],\n",
      "        [2.3985, 2.5448, 2.5823, 2.6218, 2.5185],\n",
      "        [2.4654, 2.5523, 2.6284, 2.6572, 2.5847],\n",
      "        [2.7042, 2.9216, 2.7787, 2.7487, 2.8045],\n",
      "        [2.4152, 2.7227, 2.5194, 2.7037, 2.5179],\n",
      "        [2.4033, 2.6257, 2.6888, 2.7016, 2.6967],\n",
      "        [2.3947, 2.6884, 2.7674, 2.6771, 2.6745],\n",
      "        [2.4864, 2.5255, 2.6760, 2.5874, 2.6626],\n",
      "        [2.6374, 2.8281, 2.6232, 2.7882, 2.7652],\n",
      "        [2.4654, 2.6531, 2.5206, 2.6678, 2.5644],\n",
      "        [2.4876, 2.6248, 2.6023, 2.6469, 2.6019],\n",
      "        [2.5506, 2.5794, 2.7578, 2.8124, 2.6457],\n",
      "        [2.6521, 2.7412, 2.7230, 2.7559, 2.4951],\n",
      "        [2.4591, 2.5131, 2.5760, 2.6658, 2.5073],\n",
      "        [2.5369, 2.7717, 2.6438, 2.7209, 2.6939],\n",
      "        [2.6445, 2.6630, 2.6846, 2.6529, 2.5131],\n",
      "        [2.8162, 2.9701, 2.8271, 3.1393, 2.9352],\n",
      "        [2.5668, 2.5472, 2.6543, 2.7352, 2.5800],\n",
      "        [2.5107, 2.8078, 2.6724, 2.7418, 2.5349],\n",
      "        [2.4971, 2.7716, 2.6776, 2.6461, 2.6960],\n",
      "        [2.3927, 2.6067, 2.5299, 2.5981, 2.5545],\n",
      "        [2.4978, 2.6162, 2.7257, 2.6966, 2.7119],\n",
      "        [2.5343, 2.5293, 2.6319, 2.6205, 2.5463],\n",
      "        [2.6450, 2.6555, 2.6440, 3.0053, 2.7972],\n",
      "        [2.7843, 2.9842, 2.8226, 3.1518, 2.9518],\n",
      "        [2.6218, 2.7990, 2.7385, 2.9232, 2.6901],\n",
      "        [2.4789, 2.6418, 2.5636, 2.6394, 2.5617],\n",
      "        [3.0087, 3.2291, 2.8008, 2.9657, 2.8016],\n",
      "        [2.4324, 2.6386, 2.5256, 2.6394, 2.5629],\n",
      "        [2.4956, 2.7300, 2.5726, 2.8344, 2.5616],\n",
      "        [2.4799, 2.9058, 2.6289, 2.9040, 2.7551],\n",
      "        [2.8242, 2.7199, 2.8147, 3.3409, 3.1171],\n",
      "        [2.5447, 2.7278, 2.5307, 2.7899, 2.6312],\n",
      "        [2.7988, 2.8850, 2.7464, 2.9332, 2.9276]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.4304, 2.5726, 2.6237, 2.6910, 2.5157],\n",
      "        [2.7321, 2.5675, 2.5701, 2.6593, 2.6877],\n",
      "        [2.5401, 2.8474, 2.7346, 2.7904, 2.6520],\n",
      "        [2.6273, 2.8376, 2.6527, 2.9483, 2.7590],\n",
      "        [2.5545, 2.6438, 2.6904, 2.6473, 2.4809],\n",
      "        [2.5413, 2.7719, 2.6480, 2.7227, 2.6979],\n",
      "        [2.6314, 2.6737, 2.6299, 2.9228, 2.7487],\n",
      "        [2.7115, 2.8720, 2.7570, 2.8626, 2.8654],\n",
      "        [2.4259, 2.5713, 2.5064, 2.6966, 2.4734],\n",
      "        [2.6405, 2.7941, 2.7674, 2.8578, 2.7044],\n",
      "        [2.7215, 2.5762, 2.5847, 2.6619, 2.6805],\n",
      "        [2.3716, 2.6701, 2.6315, 2.6206, 2.5503],\n",
      "        [2.3884, 2.8191, 2.6737, 2.6675, 2.7808],\n",
      "        [2.4968, 2.6075, 2.6454, 2.7177, 2.6303],\n",
      "        [2.6001, 2.8383, 2.7599, 2.8462, 2.8422],\n",
      "        [2.5171, 2.6659, 2.6329, 2.6492, 2.6248],\n",
      "        [2.5969, 2.8102, 2.6280, 2.9149, 2.7172],\n",
      "        [2.6550, 2.7407, 2.7261, 2.7560, 2.4987],\n",
      "        [2.5404, 2.7193, 2.5274, 2.7800, 2.6301],\n",
      "        [2.5487, 2.6052, 2.7340, 2.7785, 2.6842],\n",
      "        [2.4980, 2.5816, 2.5059, 2.6767, 2.6948],\n",
      "        [2.5010, 2.6294, 2.6280, 2.6958, 2.7409],\n",
      "        [2.4614, 2.7002, 2.5713, 2.7833, 2.5638],\n",
      "        [2.3806, 2.6506, 2.6285, 2.6220, 2.5431],\n",
      "        [2.7851, 2.7955, 2.7442, 3.0172, 2.8291],\n",
      "        [2.6447, 2.8379, 2.7385, 2.8723, 2.7291],\n",
      "        [2.8076, 2.9710, 2.8437, 3.1367, 2.9338],\n",
      "        [2.3956, 2.5599, 2.5918, 2.6209, 2.5240],\n",
      "        [2.5225, 2.8008, 2.6720, 2.7335, 2.5383],\n",
      "        [2.5395, 2.6028, 2.7133, 2.7576, 2.6609],\n",
      "        [2.6294, 2.8292, 2.6818, 2.8395, 2.7106],\n",
      "        [2.5181, 2.6756, 2.5708, 2.7186, 2.6365],\n",
      "        [2.6516, 2.7647, 2.7714, 2.8630, 2.6414],\n",
      "        [2.5660, 2.6217, 2.7418, 2.7785, 2.7003],\n",
      "        [2.4621, 2.6516, 2.5296, 2.6655, 2.5848],\n",
      "        [2.2693, 2.5172, 2.5467, 2.5440, 2.5112],\n",
      "        [2.8769, 3.0526, 2.7819, 2.8544, 2.7711],\n",
      "        [2.4215, 2.4779, 2.5452, 2.6439, 2.4969],\n",
      "        [2.5422, 2.7193, 2.5400, 2.7830, 2.6313],\n",
      "        [2.4305, 2.6587, 2.6100, 2.8004, 2.5615],\n",
      "        [2.5136, 2.5599, 2.6669, 2.7121, 2.6061],\n",
      "        [2.4408, 2.6747, 2.5580, 2.7592, 2.5573],\n",
      "        [2.5386, 2.6185, 2.6556, 2.7403, 2.6521],\n",
      "        [2.6011, 2.7600, 2.6175, 2.8036, 2.7718],\n",
      "        [2.7900, 2.8695, 2.7506, 2.9464, 2.9157],\n",
      "        [2.6817, 2.8372, 2.6523, 2.8209, 2.8198],\n",
      "        [2.4068, 2.6973, 2.7846, 2.6995, 2.6863],\n",
      "        [2.5348, 2.9273, 2.6651, 2.9309, 2.8042],\n",
      "        [2.6861, 2.9116, 2.7562, 2.7363, 2.7838],\n",
      "        [2.5040, 2.7635, 2.5986, 2.6563, 2.6628],\n",
      "        [2.4375, 2.5088, 2.5677, 2.6518, 2.5193],\n",
      "        [2.6364, 2.8292, 2.7833, 2.7776, 2.6065],\n",
      "        [2.6154, 2.8333, 2.6141, 2.7785, 2.7420],\n",
      "        [2.3846, 2.6126, 2.6414, 2.6404, 2.5439],\n",
      "        [2.4240, 2.6596, 2.5690, 2.6414, 2.6043],\n",
      "        [2.7851, 2.6854, 2.7954, 3.3084, 3.1175],\n",
      "        [2.7615, 2.8793, 2.7341, 2.9145, 2.8869],\n",
      "        [2.3994, 2.6316, 2.6978, 2.6832, 2.6797],\n",
      "        [2.6153, 2.6428, 2.6922, 2.7668, 2.6319],\n",
      "        [2.3672, 2.5896, 2.5281, 2.5716, 2.5283],\n",
      "        [2.4507, 2.5921, 2.6107, 2.5852, 2.6948],\n",
      "        [2.5467, 2.8389, 2.6348, 2.8923, 2.7233],\n",
      "        [2.4811, 2.6352, 2.6128, 2.7292, 2.6820],\n",
      "        [2.3800, 2.5845, 2.5985, 2.6168, 2.5264]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.4975, 2.6774, 2.5322, 2.7189, 2.5935],\n",
      "        [2.6507, 2.8341, 2.6901, 2.8264, 2.7195],\n",
      "        [2.7033, 2.9688, 2.7515, 2.9784, 2.9152],\n",
      "        [2.4062, 2.5736, 2.6392, 2.7295, 2.6376],\n",
      "        [2.6351, 2.6390, 2.6829, 2.6824, 2.5114],\n",
      "        [2.5627, 2.7900, 2.6966, 2.7626, 2.5600],\n",
      "        [2.7446, 2.8744, 2.7964, 2.8802, 2.8465],\n",
      "        [2.5052, 2.7286, 2.6060, 2.7370, 2.6940],\n",
      "        [2.6745, 2.7474, 2.7549, 2.8333, 2.8213],\n",
      "        [2.6662, 2.7451, 2.7385, 2.7679, 2.5218],\n",
      "        [2.6632, 2.7517, 2.7760, 2.8680, 2.6183],\n",
      "        [2.6064, 2.7602, 2.7736, 2.8217, 2.7373],\n",
      "        [2.5231, 2.5385, 2.6578, 2.7134, 2.7075],\n",
      "        [2.6769, 2.7228, 2.8163, 2.8385, 2.6071],\n",
      "        [2.4048, 2.5513, 2.5541, 2.6237, 2.5345],\n",
      "        [2.5172, 2.5694, 2.7150, 2.7526, 2.6463],\n",
      "        [2.5646, 2.6199, 2.7527, 2.7765, 2.6929],\n",
      "        [2.6716, 2.8446, 2.6662, 2.9124, 2.9185],\n",
      "        [2.3125, 2.5565, 2.5498, 2.5913, 2.5431],\n",
      "        [2.6384, 2.7608, 2.8097, 2.7903, 2.6206],\n",
      "        [2.3895, 2.6059, 2.5348, 2.5854, 2.5385],\n",
      "        [2.6317, 2.8378, 2.6567, 2.9507, 2.7629],\n",
      "        [2.4906, 2.7975, 2.7298, 2.6264, 2.7128],\n",
      "        [2.6121, 2.9266, 2.7303, 2.8645, 2.7730],\n",
      "        [2.7667, 2.8202, 2.8150, 2.9936, 2.8450],\n",
      "        [2.6846, 2.7635, 2.7724, 2.8465, 2.8237],\n",
      "        [2.6917, 2.8782, 2.8124, 2.9377, 2.8646],\n",
      "        [2.7077, 2.8982, 2.8616, 2.8802, 2.6356],\n",
      "        [2.5432, 2.7593, 2.6057, 2.6742, 2.6789],\n",
      "        [2.8161, 2.7620, 2.8216, 3.0524, 2.8891],\n",
      "        [2.4527, 2.5468, 2.6422, 2.6980, 2.6849],\n",
      "        [2.6579, 2.8179, 2.7013, 2.7231, 2.7078],\n",
      "        [2.3854, 2.6164, 2.6193, 2.6322, 2.5517],\n",
      "        [2.7253, 2.5764, 2.5884, 2.6642, 2.6841],\n",
      "        [2.4984, 2.6382, 2.5984, 2.7728, 2.6426],\n",
      "        [2.5402, 2.7646, 2.6323, 2.7268, 2.7026],\n",
      "        [2.5185, 2.5296, 2.6241, 2.6919, 2.7047],\n",
      "        [2.6309, 2.7176, 2.7980, 2.7828, 2.6407],\n",
      "        [2.4063, 2.6349, 2.5599, 2.7074, 2.5533],\n",
      "        [2.3742, 2.6531, 2.7115, 2.6397, 2.6467],\n",
      "        [2.5044, 2.6644, 2.5688, 2.7120, 2.6265],\n",
      "        [2.5184, 2.5810, 2.7179, 2.7538, 2.6619],\n",
      "        [2.5623, 2.8834, 2.7330, 2.8392, 2.8400],\n",
      "        [2.5118, 2.7399, 2.5874, 2.8414, 2.5797],\n",
      "        [2.5344, 2.8314, 2.6242, 2.5670, 2.7143],\n",
      "        [2.4359, 2.7244, 2.6232, 2.7021, 2.7731],\n",
      "        [2.8334, 2.7204, 2.8231, 3.3453, 3.1254],\n",
      "        [2.4220, 2.6893, 2.7935, 2.6850, 2.7089],\n",
      "        [2.6947, 2.6123, 2.5943, 2.6656, 2.6919],\n",
      "        [2.6365, 2.6814, 2.8414, 2.7617, 2.5942],\n",
      "        [2.5837, 2.6959, 2.7369, 2.7836, 2.6857],\n",
      "        [2.6971, 2.9067, 2.7088, 2.6951, 2.6726],\n",
      "        [2.4990, 2.6901, 2.6111, 2.7666, 2.6828],\n",
      "        [2.5509, 2.5751, 2.7327, 2.7994, 2.7496],\n",
      "        [2.5530, 2.7231, 2.5322, 2.7885, 2.6313],\n",
      "        [3.0794, 3.2833, 2.8574, 3.0120, 2.8575],\n",
      "        [2.4564, 2.6884, 2.8314, 2.6991, 2.7906],\n",
      "        [2.5367, 2.5567, 2.7033, 2.7594, 2.7339],\n",
      "        [2.6793, 2.7872, 2.8055, 2.9639, 2.6921],\n",
      "        [2.4495, 2.5994, 2.5376, 2.6907, 2.5418],\n",
      "        [2.3854, 2.7190, 2.4983, 2.6987, 2.5092],\n",
      "        [2.4025, 2.5905, 2.6347, 2.6518, 2.5217],\n",
      "        [2.4319, 2.8325, 2.6555, 2.7379, 2.7865],\n",
      "        [2.3598, 2.4860, 2.5607, 2.5735, 2.4494]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.4502, 2.5054, 2.5725, 2.6626, 2.5252],\n",
      "        [2.8483, 2.8009, 2.7985, 2.9218, 2.7956],\n",
      "        [2.4683, 2.6606, 2.5499, 2.6741, 2.5908],\n",
      "        [2.6026, 2.8503, 2.7776, 2.8450, 2.7070],\n",
      "        [2.5616, 2.9406, 2.6597, 2.9367, 2.8018],\n",
      "        [2.3547, 2.5859, 2.5383, 2.6111, 2.5340],\n",
      "        [2.5095, 2.6646, 2.5732, 2.7141, 2.6318],\n",
      "        [2.5137, 2.5372, 2.6399, 2.6469, 2.5717],\n",
      "        [2.4132, 2.5553, 2.6206, 2.6487, 2.5124],\n",
      "        [2.5788, 2.6531, 2.7518, 2.8124, 2.6533],\n",
      "        [2.6396, 2.8023, 2.7706, 2.8560, 2.7410],\n",
      "        [2.4477, 2.7864, 2.6514, 2.5324, 2.7059],\n",
      "        [2.5373, 2.5097, 2.6225, 2.6007, 2.5366],\n",
      "        [2.3607, 2.5731, 2.5340, 2.5461, 2.5164],\n",
      "        [2.5080, 2.6799, 2.5403, 2.6990, 2.6109],\n",
      "        [2.5295, 2.6748, 2.6891, 2.7094, 2.5423],\n",
      "        [2.5613, 2.6255, 2.6819, 2.6378, 2.4863],\n",
      "        [2.4307, 2.4783, 2.5532, 2.6483, 2.5057],\n",
      "        [2.5249, 2.6877, 2.5359, 2.7367, 2.6226],\n",
      "        [2.5238, 2.5663, 2.6762, 2.7139, 2.6208],\n",
      "        [2.7952, 2.6859, 2.8041, 3.3130, 3.1273],\n",
      "        [2.6487, 2.8179, 2.6559, 2.8982, 2.8854],\n",
      "        [2.3907, 2.5220, 2.5762, 2.6102, 2.4838],\n",
      "        [2.5633, 2.6314, 2.6651, 2.7785, 2.6606],\n",
      "        [2.4287, 2.6283, 2.5396, 2.6264, 2.5588],\n",
      "        [2.4533, 2.9017, 2.7566, 2.7354, 2.6447],\n",
      "        [2.6065, 2.7060, 2.6276, 2.8225, 2.7025],\n",
      "        [2.4183, 2.5427, 2.5995, 2.6521, 2.5379],\n",
      "        [2.5264, 2.6916, 2.5380, 2.7418, 2.6220],\n",
      "        [2.5515, 2.7197, 2.5482, 2.7874, 2.6404],\n",
      "        [2.4947, 2.6561, 2.5599, 2.7294, 2.5891],\n",
      "        [2.3988, 2.5678, 2.6043, 2.6253, 2.5324],\n",
      "        [2.4820, 2.6609, 2.5356, 2.6803, 2.5910],\n",
      "        [2.4177, 2.6264, 2.7012, 2.7082, 2.7100],\n",
      "        [2.4187, 2.6371, 2.5907, 2.7738, 2.5325],\n",
      "        [2.6371, 2.8381, 2.6613, 2.9529, 2.7685],\n",
      "        [2.3894, 2.7138, 2.5001, 2.7132, 2.5151],\n",
      "        [2.5030, 2.6366, 2.4652, 2.7785, 2.4887],\n",
      "        [2.3835, 2.6551, 2.6360, 2.6240, 2.5542],\n",
      "        [2.5507, 2.6963, 2.6711, 2.7046, 2.6533],\n",
      "        [2.5062, 2.5176, 2.5818, 2.6411, 2.6884],\n",
      "        [2.5425, 2.5560, 2.7081, 2.7585, 2.7371],\n",
      "        [2.6356, 2.8363, 2.6607, 2.9521, 2.7656],\n",
      "        [2.4552, 2.6505, 2.6193, 2.7912, 2.5699],\n",
      "        [2.7175, 2.7518, 2.8192, 2.9089, 2.6594],\n",
      "        [2.4828, 2.8088, 2.7562, 2.6283, 2.7252],\n",
      "        [2.6181, 2.9541, 2.7920, 2.8949, 2.9046],\n",
      "        [2.6524, 2.6813, 2.7317, 2.7293, 2.5923],\n",
      "        [2.7083, 2.8532, 2.8363, 2.8331, 2.6183],\n",
      "        [2.5582, 2.7605, 2.6051, 2.8103, 2.6766],\n",
      "        [2.5681, 2.6504, 2.6910, 2.6587, 2.4891],\n",
      "        [2.5223, 2.8263, 2.6063, 2.8609, 2.7110],\n",
      "        [2.4312, 2.5782, 2.6402, 2.6896, 2.5191],\n",
      "        [2.5307, 2.5223, 2.6347, 2.6304, 2.5543],\n",
      "        [2.5395, 2.7630, 2.6375, 2.7163, 2.7108],\n",
      "        [2.7618, 2.8256, 2.7790, 3.0256, 2.8136],\n",
      "        [2.6932, 2.8508, 2.8610, 2.8341, 2.5860],\n",
      "        [2.3825, 2.6227, 2.6246, 2.6254, 2.5379],\n",
      "        [2.7934, 2.9807, 2.7727, 2.7871, 2.7917],\n",
      "        [2.5011, 2.6674, 2.5340, 2.7092, 2.6076],\n",
      "        [2.6507, 2.6888, 2.7364, 2.7387, 2.5691],\n",
      "        [2.6392, 2.8299, 2.6901, 2.8443, 2.7197],\n",
      "        [2.4335, 2.6050, 2.6637, 2.6874, 2.5307],\n",
      "        [2.5453, 2.7198, 2.5055, 2.6806, 2.6334]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.5410, 2.5502, 2.7015, 2.7479, 2.7345],\n",
      "        [2.6220, 2.6381, 2.7209, 2.6890, 2.6007],\n",
      "        [2.3540, 2.6529, 2.4542, 2.6587, 2.4748],\n",
      "        [2.5634, 2.7293, 2.5470, 2.7979, 2.6492],\n",
      "        [2.3665, 2.5774, 2.4478, 2.6571, 2.4898],\n",
      "        [2.5605, 2.8507, 2.5926, 2.7875, 2.6651],\n",
      "        [2.5431, 2.6922, 2.7523, 2.7692, 2.7227],\n",
      "        [2.6424, 2.7226, 2.5653, 2.8497, 2.7769],\n",
      "        [2.5166, 2.5719, 2.6570, 2.7056, 2.6303],\n",
      "        [2.5456, 2.7109, 2.6702, 2.7478, 2.6932],\n",
      "        [2.7156, 2.9687, 2.7606, 2.9841, 2.9218],\n",
      "        [2.4588, 2.8344, 2.6659, 2.7555, 2.7981],\n",
      "        [2.5496, 2.7050, 2.5378, 2.7708, 2.6269],\n",
      "        [2.7790, 2.5451, 2.7103, 3.1255, 3.0123],\n",
      "        [2.4946, 2.7398, 2.6510, 2.8771, 2.6513],\n",
      "        [2.8470, 2.8360, 2.7954, 2.9191, 2.8403],\n",
      "        [2.4760, 2.7016, 2.5835, 2.7900, 2.5775],\n",
      "        [2.6908, 2.7505, 2.7599, 2.9414, 2.7483],\n",
      "        [2.2909, 2.5181, 2.5672, 2.5528, 2.5518],\n",
      "        [2.6445, 2.8350, 2.6583, 2.9447, 2.7603],\n",
      "        [2.5062, 2.6263, 2.6184, 2.6551, 2.6195],\n",
      "        [2.5154, 2.6166, 2.6673, 2.7365, 2.6574],\n",
      "        [2.8443, 2.7934, 2.8113, 2.9089, 2.7947],\n",
      "        [2.5229, 2.6971, 2.6158, 2.7977, 2.6855],\n",
      "        [2.5575, 2.7299, 2.5261, 2.6895, 2.6480],\n",
      "        [2.4276, 2.5645, 2.5698, 2.6414, 2.5474],\n",
      "        [2.7307, 2.8616, 2.7087, 2.8730, 2.8884],\n",
      "        [2.6756, 2.8733, 2.7903, 2.8665, 2.7380],\n",
      "        [2.4038, 2.5687, 2.6083, 2.6272, 2.5372],\n",
      "        [2.4325, 2.6295, 2.5444, 2.6331, 2.5661],\n",
      "        [2.5685, 2.6323, 2.6693, 2.7804, 2.6657],\n",
      "        [2.5534, 2.6199, 2.6681, 2.7467, 2.6665],\n",
      "        [2.3703, 2.5763, 2.5357, 2.5563, 2.5296],\n",
      "        [2.4035, 2.8205, 2.6863, 2.6742, 2.7947],\n",
      "        [2.8273, 2.7108, 2.8172, 3.3327, 3.1371],\n",
      "        [2.7452, 2.5689, 2.5821, 2.6656, 2.7015],\n",
      "        [2.5275, 2.5706, 2.7236, 2.7566, 2.6570],\n",
      "        [2.4190, 2.5814, 2.6551, 2.7359, 2.6461],\n",
      "        [2.4493, 2.5506, 2.4869, 2.7044, 2.4834],\n",
      "        [2.6660, 2.8296, 2.7052, 2.8049, 2.7288],\n",
      "        [2.9724, 3.1080, 2.7087, 2.9264, 2.7196],\n",
      "        [2.5383, 2.6190, 2.5507, 2.7078, 2.7327],\n",
      "        [2.5002, 2.8234, 2.6885, 2.8034, 2.7993],\n",
      "        [2.4163, 2.7770, 2.6368, 2.5304, 2.7239],\n",
      "        [2.5326, 2.5576, 2.6907, 2.7074, 2.6329],\n",
      "        [2.8260, 2.9826, 2.6810, 2.8354, 2.7563],\n",
      "        [2.5408, 2.7513, 2.6527, 2.6926, 2.7088],\n",
      "        [2.5919, 2.7591, 2.6018, 2.7954, 2.7221],\n",
      "        [2.3545, 2.5621, 2.5294, 2.5367, 2.5139],\n",
      "        [2.4869, 2.6618, 2.5396, 2.6822, 2.5959],\n",
      "        [2.7044, 2.6339, 2.6795, 3.0330, 2.8266],\n",
      "        [2.6626, 2.8663, 2.6544, 2.7863, 2.7734],\n",
      "        [2.7407, 2.7795, 2.7846, 2.9717, 2.7954],\n",
      "        [2.4421, 2.5792, 2.5215, 2.7042, 2.4764],\n",
      "        [2.6474, 2.7877, 2.7124, 2.7985, 2.7953],\n",
      "        [2.8317, 2.9536, 2.8519, 3.1308, 2.9125],\n",
      "        [2.3896, 2.5606, 2.4858, 2.6587, 2.4839],\n",
      "        [2.5070, 2.8725, 2.6825, 2.8433, 2.8103],\n",
      "        [2.5362, 2.5326, 2.6619, 2.7202, 2.7169],\n",
      "        [2.5943, 2.4935, 2.7839, 2.8006, 2.7362],\n",
      "        [2.4170, 2.5463, 2.5984, 2.6301, 2.5360],\n",
      "        [2.4970, 2.8012, 2.7391, 2.6457, 2.6998],\n",
      "        [2.5246, 2.6176, 2.7269, 2.6486, 2.7614],\n",
      "        [2.6876, 2.8790, 2.6555, 2.7922, 2.7678]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.7070, 2.6837, 2.7147, 2.6973, 2.5679],\n",
      "        [2.6536, 2.7630, 2.8239, 2.7961, 2.6360],\n",
      "        [2.3944, 2.5615, 2.4904, 2.6605, 2.4882],\n",
      "        [2.8220, 2.6920, 2.8220, 3.3286, 3.1449],\n",
      "        [2.9572, 3.0900, 2.7163, 2.9128, 2.7360],\n",
      "        [2.8325, 2.7119, 2.8224, 3.3345, 3.1422],\n",
      "        [2.6101, 2.8656, 2.6777, 2.6177, 2.7484],\n",
      "        [2.6929, 2.7318, 2.7851, 2.8866, 2.5892],\n",
      "        [2.5232, 2.5899, 2.6586, 2.7186, 2.6397],\n",
      "        [2.6677, 2.8673, 2.6595, 2.7881, 2.7781],\n",
      "        [2.6346, 2.6453, 2.7096, 2.7751, 2.6510],\n",
      "        [2.7496, 2.5699, 2.5868, 2.6673, 2.7061],\n",
      "        [2.5486, 2.8478, 2.6388, 2.8897, 2.7379],\n",
      "        [2.6059, 2.7171, 2.6228, 2.7693, 2.8552],\n",
      "        [2.4086, 2.5697, 2.6131, 2.6290, 2.5417],\n",
      "        [2.6593, 2.8255, 2.7874, 2.7963, 2.6061],\n",
      "        [2.4956, 2.6620, 2.5439, 2.6892, 2.6084],\n",
      "        [2.5132, 2.5969, 2.6556, 2.7157, 2.6395],\n",
      "        [2.5563, 2.6017, 2.7328, 2.7613, 2.6906],\n",
      "        [2.4759, 2.6514, 2.5537, 2.6601, 2.6088],\n",
      "        [2.4998, 2.7409, 2.6561, 2.8789, 2.6561],\n",
      "        [2.4258, 2.6062, 2.6799, 2.6835, 2.5301],\n",
      "        [2.4041, 2.5856, 2.6201, 2.6280, 2.5441],\n",
      "        [2.5696, 2.8033, 2.6878, 2.8063, 2.8275],\n",
      "        [2.4785, 2.4838, 2.6888, 2.5364, 2.6772],\n",
      "        [2.8139, 2.8028, 2.7681, 3.0237, 2.8479],\n",
      "        [2.5409, 2.5336, 2.6668, 2.7220, 2.7215],\n",
      "        [2.5710, 2.9464, 2.6769, 2.9475, 2.8232],\n",
      "        [2.2327, 2.4750, 2.5492, 2.5066, 2.5030],\n",
      "        [2.5524, 2.5579, 2.7170, 2.7622, 2.7471],\n",
      "        [2.4184, 2.6058, 2.6652, 2.6659, 2.5576],\n",
      "        [2.6350, 2.7702, 2.8050, 2.8208, 2.7568],\n",
      "        [2.7298, 2.8913, 2.8937, 2.9075, 2.6636],\n",
      "        [2.4893, 2.4784, 2.6372, 2.6892, 2.6499],\n",
      "        [2.4916, 2.8621, 2.6887, 2.8098, 2.8157],\n",
      "        [2.7726, 2.6500, 2.6217, 2.7350, 2.7260],\n",
      "        [2.7757, 2.8115, 2.8149, 3.0003, 2.7503],\n",
      "        [2.7189, 2.6041, 2.6163, 2.6748, 2.7121],\n",
      "        [2.4809, 2.5679, 2.7700, 2.5573, 2.7691],\n",
      "        [2.6609, 2.9435, 2.8477, 2.9102, 2.8912],\n",
      "        [2.5928, 2.8601, 2.7819, 2.8420, 2.9113],\n",
      "        [2.5661, 2.5773, 2.7463, 2.8052, 2.7654],\n",
      "        [2.5357, 2.5349, 2.6389, 2.7029, 2.7212],\n",
      "        [2.8326, 2.9746, 2.8696, 3.1742, 2.9760],\n",
      "        [2.4679, 2.5490, 2.6557, 2.7037, 2.7001],\n",
      "        [2.6628, 2.8310, 2.6456, 2.7985, 2.7889],\n",
      "        [2.5639, 2.6142, 2.7634, 2.8866, 2.8814],\n",
      "        [2.3938, 2.8028, 2.6819, 2.6647, 2.7902],\n",
      "        [2.6052, 2.5756, 2.8693, 2.7973, 2.7692],\n",
      "        [2.3804, 2.5862, 2.5440, 2.5658, 2.5364],\n",
      "        [2.4798, 2.6234, 2.5677, 2.7442, 2.6111],\n",
      "        [2.6581, 2.8067, 2.6791, 2.8800, 2.7520],\n",
      "        [2.4697, 2.5363, 2.6077, 2.6752, 2.5346],\n",
      "        [2.5027, 2.6394, 2.4875, 2.7739, 2.5185],\n",
      "        [2.4690, 2.6096, 2.5533, 2.6981, 2.5590],\n",
      "        [2.7969, 2.7681, 2.8326, 3.0217, 2.8362],\n",
      "        [2.3323, 2.6619, 2.7425, 2.5902, 2.6600],\n",
      "        [2.5916, 2.7420, 2.6426, 2.8108, 2.7498],\n",
      "        [2.4790, 2.7720, 2.7347, 2.6661, 2.8630],\n",
      "        [2.5511, 2.7019, 2.5382, 2.7644, 2.6270],\n",
      "        [2.5059, 2.5701, 2.6750, 2.7306, 2.6997],\n",
      "        [2.6810, 2.6799, 2.6799, 3.0232, 2.8319],\n",
      "        [2.4509, 2.4503, 2.6693, 2.4851, 2.6603],\n",
      "        [2.4426, 2.6620, 2.5861, 2.6497, 2.6225]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.5328, 2.8276, 2.6158, 2.8660, 2.7257],\n",
      "        [2.8555, 2.7690, 2.7595, 2.8613, 2.7713],\n",
      "        [2.5741, 2.8051, 2.6925, 2.8079, 2.8318],\n",
      "        [2.6728, 2.7199, 2.9115, 2.7425, 2.6495],\n",
      "        [2.6402, 2.6351, 2.7281, 2.7847, 2.6656],\n",
      "        [2.5628, 2.8567, 2.8060, 2.8587, 2.8257],\n",
      "        [2.5006, 2.6679, 2.5447, 2.7058, 2.5994],\n",
      "        [2.5529, 2.8496, 2.6434, 2.8913, 2.7421],\n",
      "        [2.7041, 2.7677, 2.7910, 2.8542, 2.8444],\n",
      "        [2.5880, 2.6242, 2.7704, 2.7997, 2.7232],\n",
      "        [2.6757, 2.8693, 2.7191, 2.8755, 2.7747],\n",
      "        [2.6034, 2.4962, 2.7932, 2.8039, 2.7451],\n",
      "        [2.5678, 2.6906, 2.6794, 2.7042, 2.6673],\n",
      "        [2.5220, 2.5522, 2.6610, 2.6559, 2.6013],\n",
      "        [2.4005, 2.5695, 2.5120, 2.6746, 2.4864],\n",
      "        [2.8167, 2.8068, 2.7727, 3.0313, 2.8513],\n",
      "        [2.4698, 2.6544, 2.6330, 2.7964, 2.5837],\n",
      "        [2.6838, 2.7397, 2.7565, 2.7738, 2.5537],\n",
      "        [2.5188, 2.6944, 2.6294, 2.7741, 2.7021],\n",
      "        [2.5527, 2.5777, 2.5880, 2.7971, 2.5728],\n",
      "        [2.4888, 2.8053, 2.6721, 2.7128, 2.5591],\n",
      "        [2.3990, 2.6362, 2.6418, 2.6392, 2.5699],\n",
      "        [3.1038, 3.2972, 2.8796, 3.0276, 2.8856],\n",
      "        [2.5349, 2.6857, 2.6358, 2.7047, 2.6506],\n",
      "        [2.5164, 2.5877, 2.5262, 2.6857, 2.7172],\n",
      "        [2.6360, 2.7283, 2.7917, 2.7708, 2.6255],\n",
      "        [2.5670, 2.7328, 2.5357, 2.6928, 2.6569],\n",
      "        [2.6394, 2.8498, 2.8006, 2.8806, 2.7360],\n",
      "        [2.5723, 2.6093, 2.7558, 2.7883, 2.7080],\n",
      "        [3.0993, 3.2875, 2.8767, 3.0200, 2.8781],\n",
      "        [2.4592, 2.6198, 2.5488, 2.6961, 2.5581],\n",
      "        [2.9686, 3.1170, 2.8421, 2.9317, 2.8215],\n",
      "        [2.6976, 2.7268, 2.8350, 2.8461, 2.6272],\n",
      "        [2.4034, 2.5885, 2.6198, 2.6267, 2.5486],\n",
      "        [2.5489, 2.5882, 2.6916, 2.7225, 2.6568],\n",
      "        [2.7474, 2.5660, 2.7340, 3.0567, 2.9762],\n",
      "        [2.4363, 2.5627, 2.6329, 2.6583, 2.5294],\n",
      "        [2.5649, 2.7763, 2.6703, 2.7327, 2.7209],\n",
      "        [2.7864, 2.7133, 2.8099, 2.9731, 2.7985],\n",
      "        [2.3744, 2.5766, 2.5469, 2.5514, 2.5295],\n",
      "        [2.6397, 2.7376, 2.6737, 2.7722, 2.6803],\n",
      "        [2.6300, 2.8335, 2.7835, 2.8657, 2.8266],\n",
      "        [2.5626, 2.7139, 2.6888, 2.7648, 2.7162],\n",
      "        [2.3577, 2.6544, 2.7322, 2.6288, 2.6455],\n",
      "        [2.4303, 2.5409, 2.5977, 2.6401, 2.5237],\n",
      "        [2.5406, 2.9174, 2.7141, 2.8769, 2.8421],\n",
      "        [2.4529, 2.5682, 2.6442, 2.7146, 2.6403],\n",
      "        [2.5519, 2.7598, 2.6369, 2.8186, 2.6653],\n",
      "        [2.5232, 2.7661, 2.6365, 2.8512, 2.6510],\n",
      "        [2.5414, 2.6797, 2.5921, 2.7281, 2.6592],\n",
      "        [2.5371, 2.5336, 2.6420, 2.6993, 2.7237],\n",
      "        [2.6843, 2.6287, 2.6612, 3.0463, 2.8195],\n",
      "        [2.6008, 2.9867, 2.7460, 2.9652, 2.8764],\n",
      "        [2.3740, 2.5812, 2.5451, 2.5523, 2.5313],\n",
      "        [2.4551, 2.4520, 2.6736, 2.4867, 2.6646],\n",
      "        [2.5270, 2.5599, 2.6878, 2.7173, 2.6313],\n",
      "        [2.3832, 2.5849, 2.5484, 2.5624, 2.5478],\n",
      "        [2.5629, 2.6070, 2.7349, 2.7674, 2.6845],\n",
      "        [2.3692, 2.5896, 2.5516, 2.6165, 2.5475],\n",
      "        [2.6444, 2.6421, 2.7007, 2.6772, 2.5182],\n",
      "        [2.8487, 2.9746, 2.8550, 3.1523, 2.9642],\n",
      "        [2.5281, 2.5994, 2.6634, 2.7221, 2.6483],\n",
      "        [2.5531, 2.8406, 2.6370, 2.8874, 2.7393],\n",
      "        [2.7638, 2.8194, 2.8041, 2.9981, 2.7868]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.3711, 2.6618, 2.7523, 2.6129, 2.6424],\n",
      "        [2.5390, 2.6874, 2.6398, 2.7062, 2.6565],\n",
      "        [2.5317, 2.5933, 2.6673, 2.7216, 2.6501],\n",
      "        [2.4087, 2.6218, 2.6410, 2.6411, 2.5761],\n",
      "        [2.6634, 2.6530, 2.7477, 2.8263, 2.6856],\n",
      "        [2.4883, 2.6268, 2.5762, 2.7472, 2.6210],\n",
      "        [2.3656, 2.4849, 2.5435, 2.5453, 2.4918],\n",
      "        [2.6555, 2.7428, 2.6676, 2.7867, 2.6874],\n",
      "        [2.5827, 2.5853, 2.7877, 2.8255, 2.6785],\n",
      "        [2.5043, 2.4861, 2.6537, 2.6997, 2.6626],\n",
      "        [2.7525, 2.7878, 2.8038, 2.9835, 2.8065],\n",
      "        [2.5065, 2.6405, 2.5976, 2.6514, 2.5852],\n",
      "        [2.6069, 2.6322, 2.7881, 2.8096, 2.7358],\n",
      "        [2.6497, 2.6418, 2.7389, 2.8033, 2.6752],\n",
      "        [2.6689, 2.6942, 2.7540, 2.7454, 2.5894],\n",
      "        [2.5044, 2.5151, 2.7058, 2.5699, 2.6959],\n",
      "        [2.6562, 2.8436, 2.6797, 2.9597, 2.7892],\n",
      "        [2.7596, 2.6387, 2.7040, 3.1384, 2.9128],\n",
      "        [2.5211, 2.5951, 2.7590, 2.6204, 2.7889],\n",
      "        [2.4074, 2.5901, 2.6238, 2.6281, 2.5544],\n",
      "        [2.4133, 2.5249, 2.5971, 2.6198, 2.5263],\n",
      "        [2.5384, 2.5784, 2.6822, 2.7166, 2.6505],\n",
      "        [2.5179, 2.6736, 2.5512, 2.7078, 2.6256],\n",
      "        [2.4321, 2.6689, 2.5394, 2.6999, 2.5748],\n",
      "        [2.6389, 2.8231, 2.6580, 2.9285, 2.7513],\n",
      "        [2.6698, 2.6931, 2.7504, 2.7514, 2.5877],\n",
      "        [2.5519, 2.5443, 2.6917, 2.7273, 2.7385],\n",
      "        [2.7159, 2.6178, 2.6157, 2.6741, 2.7171],\n",
      "        [2.4495, 2.6586, 2.5863, 2.7459, 2.5782],\n",
      "        [2.7283, 2.9048, 2.8042, 2.7615, 2.8186],\n",
      "        [2.5235, 2.6835, 2.5577, 2.7323, 2.6309],\n",
      "        [2.4984, 2.5583, 2.6582, 2.6701, 2.6182],\n",
      "        [2.4162, 2.6011, 2.5592, 2.5976, 2.5576],\n",
      "        [2.5482, 2.6936, 2.6934, 2.6863, 2.5703],\n",
      "        [2.5622, 2.6128, 2.7208, 2.7587, 2.6801],\n",
      "        [2.7908, 2.6609, 2.7138, 3.1591, 2.9333],\n",
      "        [2.4162, 2.6223, 2.6726, 2.6575, 2.5773],\n",
      "        [2.5123, 2.6687, 2.6704, 2.8145, 2.6249],\n",
      "        [2.8611, 2.6900, 2.8231, 3.3553, 3.1451],\n",
      "        [2.6261, 2.8297, 2.7876, 2.8611, 2.8303],\n",
      "        [3.0730, 3.2901, 2.8422, 3.0055, 2.8800],\n",
      "        [2.6473, 2.5188, 2.8283, 2.8100, 2.7133],\n",
      "        [2.4995, 2.8740, 2.6860, 2.8329, 2.8085],\n",
      "        [2.6003, 2.7454, 2.6515, 2.8138, 2.7601],\n",
      "        [2.6207, 2.9113, 2.8178, 2.8668, 2.8745],\n",
      "        [2.8654, 2.8065, 2.8165, 2.9287, 2.8166],\n",
      "        [2.4868, 2.8059, 2.6673, 2.7013, 2.5627],\n",
      "        [2.4102, 2.6588, 2.6562, 2.6466, 2.5853],\n",
      "        [2.4065, 2.6825, 2.6662, 2.6448, 2.5999],\n",
      "        [2.4365, 2.5479, 2.6168, 2.6586, 2.5572],\n",
      "        [2.3862, 2.6759, 2.4704, 2.6837, 2.4924],\n",
      "        [2.5821, 2.6368, 2.6828, 2.7851, 2.6808],\n",
      "        [2.4395, 2.7914, 2.6595, 2.5436, 2.7408],\n",
      "        [2.3897, 2.5913, 2.5514, 2.5725, 2.5471],\n",
      "        [2.3551, 2.5492, 2.5377, 2.5237, 2.5066],\n",
      "        [2.4672, 2.7937, 2.6423, 2.6673, 2.5542],\n",
      "        [2.6707, 2.6867, 2.7494, 2.7360, 2.6126],\n",
      "        [2.5949, 2.7273, 2.8241, 2.8096, 2.7859],\n",
      "        [2.5435, 2.6718, 2.6587, 2.6605, 2.6530],\n",
      "        [2.4861, 2.7055, 2.5958, 2.7976, 2.5947],\n",
      "        [2.5389, 2.6692, 2.5871, 2.7901, 2.6547],\n",
      "        [2.5607, 2.7254, 2.6883, 2.7657, 2.7154],\n",
      "        [2.6271, 2.7118, 2.6398, 2.8282, 2.7211],\n",
      "        [2.5280, 2.5864, 2.6609, 2.7103, 2.6476]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.7918, 2.8297, 2.8398, 3.0137, 2.8640],\n",
      "        [2.6568, 2.7765, 2.8186, 2.7777, 2.6417],\n",
      "        [2.8122, 2.8057, 2.7804, 2.8647, 2.7960],\n",
      "        [2.7907, 2.8223, 2.8453, 3.0173, 2.8690],\n",
      "        [2.6056, 2.8547, 2.7774, 2.8283, 2.7205],\n",
      "        [2.4630, 2.4936, 2.5801, 2.6594, 2.5371],\n",
      "        [2.4201, 2.6033, 2.5638, 2.5988, 2.5628],\n",
      "        [2.5307, 2.6047, 2.7554, 2.6370, 2.7797],\n",
      "        [2.5308, 2.5851, 2.6645, 2.7095, 2.6510],\n",
      "        [2.8353, 2.8110, 2.8826, 3.0828, 2.8997],\n",
      "        [2.5856, 2.8422, 2.7260, 2.8286, 2.8619],\n",
      "        [2.5085, 2.6718, 2.5534, 2.7085, 2.6105],\n",
      "        [2.5627, 2.6005, 2.7357, 2.7565, 2.6919],\n",
      "        [2.7525, 2.7865, 2.8044, 2.9740, 2.8041],\n",
      "        [2.6171, 2.8578, 2.7968, 2.8563, 2.7216],\n",
      "        [2.5496, 2.6998, 2.5556, 2.7639, 2.6468],\n",
      "        [2.5756, 2.5642, 2.7415, 2.7836, 2.7676],\n",
      "        [2.5402, 2.6671, 2.6148, 2.7682, 2.7617],\n",
      "        [2.6386, 2.5325, 2.8126, 2.8041, 2.7216],\n",
      "        [2.5202, 2.6556, 2.6528, 2.7462, 2.7216],\n",
      "        [2.4341, 2.6427, 2.5863, 2.7178, 2.5830],\n",
      "        [2.5218, 2.6759, 2.5559, 2.7091, 2.6309],\n",
      "        [2.4127, 2.5295, 2.5979, 2.6182, 2.5079],\n",
      "        [2.6789, 2.7257, 2.9223, 2.7497, 2.6651],\n",
      "        [2.5014, 2.6661, 2.5603, 2.6909, 2.6215],\n",
      "        [2.4624, 2.5806, 2.6539, 2.7037, 2.5492],\n",
      "        [2.5263, 2.6052, 2.6697, 2.7213, 2.6571],\n",
      "        [2.3871, 2.5828, 2.5531, 2.5623, 2.5488],\n",
      "        [2.5193, 2.6768, 2.5647, 2.7235, 2.6318],\n",
      "        [2.6729, 2.8398, 2.6535, 2.7989, 2.7961],\n",
      "        [2.6650, 2.7942, 2.7311, 2.8047, 2.8159],\n",
      "        [2.5687, 2.7205, 2.5567, 2.7836, 2.6555],\n",
      "        [2.7077, 2.7955, 2.8335, 2.9743, 2.7245],\n",
      "        [2.5408, 2.8315, 2.6249, 2.8687, 2.7370],\n",
      "        [2.5303, 2.5562, 2.6698, 2.6586, 2.6128],\n",
      "        [2.7949, 2.5608, 2.7341, 3.1230, 3.0269],\n",
      "        [2.4622, 2.8000, 2.6789, 2.5551, 2.7577],\n",
      "        [2.6386, 2.8376, 2.7931, 2.8685, 2.8384],\n",
      "        [2.7256, 2.5634, 2.6199, 2.7075, 2.6588],\n",
      "        [2.5459, 2.5739, 2.6981, 2.7216, 2.6464],\n",
      "        [2.8312, 2.6616, 2.7317, 3.2293, 2.9950],\n",
      "        [2.4577, 2.5189, 2.5987, 2.6555, 2.5470],\n",
      "        [2.5338, 2.6217, 2.8021, 2.8314, 2.7164],\n",
      "        [2.5189, 2.8914, 2.8022, 2.7827, 2.6940],\n",
      "        [2.5423, 2.7611, 2.6769, 2.6777, 2.7211],\n",
      "        [2.4403, 2.6309, 2.5662, 2.6212, 2.5907],\n",
      "        [2.5647, 2.7277, 2.6931, 2.7670, 2.7209],\n",
      "        [2.6569, 2.8425, 2.6520, 2.7934, 2.7844],\n",
      "        [2.3843, 2.5173, 2.5554, 2.5668, 2.5212],\n",
      "        [2.8070, 2.9321, 2.8410, 2.9459, 2.9582],\n",
      "        [2.6014, 2.6608, 2.7744, 2.8205, 2.6787],\n",
      "        [2.5324, 2.6076, 2.6754, 2.7196, 2.6585],\n",
      "        [2.7055, 2.8894, 2.6760, 2.7988, 2.7897],\n",
      "        [2.4172, 2.5272, 2.6017, 2.6211, 2.5315],\n",
      "        [2.4797, 2.7499, 2.6598, 2.7395, 2.7770],\n",
      "        [2.4486, 2.5467, 2.6338, 2.6562, 2.5313],\n",
      "        [2.7064, 2.7351, 2.8608, 2.8393, 2.5992],\n",
      "        [2.4508, 2.5231, 2.6004, 2.6486, 2.5498],\n",
      "        [2.5867, 2.5875, 2.7926, 2.8268, 2.6840],\n",
      "        [2.5476, 2.6425, 2.6745, 2.6958, 2.8130],\n",
      "        [2.7343, 2.9765, 2.7802, 2.9908, 2.9431],\n",
      "        [2.4680, 2.5591, 2.5067, 2.7114, 2.5229],\n",
      "        [2.4266, 2.8248, 2.7207, 2.6920, 2.8149],\n",
      "        [2.5361, 2.7720, 2.6301, 2.6692, 2.6977]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.3662, 2.5580, 2.5445, 2.5395, 2.5325],\n",
      "        [2.4098, 2.6500, 2.6550, 2.6322, 2.5768],\n",
      "        [2.6078, 2.6087, 2.7800, 2.8297, 2.7326],\n",
      "        [2.6391, 2.8443, 2.6757, 2.8233, 2.7593],\n",
      "        [2.7546, 2.7263, 2.7506, 2.7418, 2.6284],\n",
      "        [2.7247, 2.6133, 2.6264, 2.6777, 2.7265],\n",
      "        [2.5414, 2.6798, 2.6462, 2.6998, 2.6651],\n",
      "        [2.5837, 2.7534, 2.5846, 2.7059, 2.6959],\n",
      "        [2.4551, 2.5290, 2.6036, 2.6532, 2.5562],\n",
      "        [2.4964, 2.5255, 2.6187, 2.6756, 2.5508],\n",
      "        [2.3625, 2.5536, 2.5463, 2.5260, 2.5164],\n",
      "        [2.4174, 2.7000, 2.6855, 2.6445, 2.6053],\n",
      "        [2.4131, 2.6157, 2.6425, 2.6297, 2.5673],\n",
      "        [2.4974, 2.5761, 2.7877, 2.5627, 2.7912],\n",
      "        [2.5186, 2.8061, 2.7651, 2.6529, 2.7235],\n",
      "        [3.0807, 3.2946, 2.8520, 3.0082, 2.8911],\n",
      "        [2.4158, 2.6607, 2.6630, 2.6358, 2.5814],\n",
      "        [2.6421, 2.6481, 2.7380, 2.7040, 2.6169],\n",
      "        [2.5012, 2.5866, 2.7838, 2.5844, 2.7833],\n",
      "        [2.5484, 2.5396, 2.6553, 2.7032, 2.7403],\n",
      "        [2.4472, 2.5968, 2.6687, 2.6724, 2.5652],\n",
      "        [2.6949, 2.7142, 2.7874, 2.9098, 2.6645],\n",
      "        [2.8516, 2.9828, 2.8889, 3.1802, 2.9980],\n",
      "        [2.6904, 2.7363, 2.7262, 2.8639, 2.8402],\n",
      "        [2.6113, 2.5895, 2.8150, 2.8367, 2.7102],\n",
      "        [2.5124, 2.5721, 2.5165, 2.6687, 2.7174],\n",
      "        [2.6867, 2.8533, 2.7942, 2.9011, 2.7725],\n",
      "        [2.7254, 2.7906, 2.8398, 2.8399, 2.8570],\n",
      "        [2.4488, 2.6527, 2.5801, 2.7164, 2.5915],\n",
      "        [2.5342, 2.9251, 2.6722, 2.9156, 2.8196],\n",
      "        [2.5416, 2.5831, 2.6901, 2.7240, 2.6640],\n",
      "        [2.4653, 2.5745, 2.6577, 2.7184, 2.6570],\n",
      "        [2.7759, 2.7179, 2.7447, 2.8247, 2.7854],\n",
      "        [2.6320, 2.6209, 2.7303, 2.6824, 2.6514],\n",
      "        [2.4102, 2.5693, 2.5070, 2.6660, 2.5074],\n",
      "        [2.4170, 2.7290, 2.5283, 2.7106, 2.5425],\n",
      "        [2.8407, 2.7813, 2.7823, 2.8614, 2.8274],\n",
      "        [2.4724, 2.5189, 2.6020, 2.6650, 2.5575],\n",
      "        [3.0838, 3.2838, 2.9074, 3.0471, 2.8650],\n",
      "        [2.5821, 2.7565, 2.6034, 2.6937, 2.6974],\n",
      "        [2.8310, 2.8998, 2.7958, 2.9505, 2.9607],\n",
      "        [2.6017, 2.6322, 2.7770, 2.7920, 2.7413],\n",
      "        [2.5711, 2.7162, 2.5564, 2.7772, 2.6503],\n",
      "        [2.6963, 2.7422, 2.7724, 2.8562, 2.8693],\n",
      "        [2.7828, 2.7167, 2.8113, 2.9757, 2.8016],\n",
      "        [2.6611, 2.7339, 2.5925, 2.8647, 2.8178],\n",
      "        [2.6644, 2.8483, 2.6893, 2.9621, 2.8001],\n",
      "        [2.4551, 2.6465, 2.5673, 2.6411, 2.6006],\n",
      "        [2.5995, 2.8878, 2.7708, 2.8513, 2.8817],\n",
      "        [2.5082, 2.8701, 2.7081, 2.8154, 2.8365],\n",
      "        [2.7152, 2.6910, 2.7260, 2.6839, 2.5920],\n",
      "        [2.6850, 2.8539, 2.7895, 2.8884, 2.7726],\n",
      "        [2.5282, 2.6417, 2.6559, 2.7186, 2.7612],\n",
      "        [2.5775, 2.7295, 2.5749, 2.7961, 2.6705],\n",
      "        [2.6444, 2.9044, 2.8486, 2.8671, 2.8703],\n",
      "        [2.6748, 2.8152, 2.6973, 2.8858, 2.7726],\n",
      "        [2.5648, 2.8558, 2.6571, 2.8952, 2.7586],\n",
      "        [2.4483, 2.5732, 2.5916, 2.6485, 2.5717],\n",
      "        [2.8058, 2.9602, 2.6904, 2.8260, 2.7831],\n",
      "        [2.5628, 2.7129, 2.5552, 2.7714, 2.6543],\n",
      "        [2.5559, 2.7839, 2.6682, 2.8786, 2.6791],\n",
      "        [2.8342, 2.9840, 2.8709, 3.1555, 2.9928],\n",
      "        [2.8314, 2.9952, 2.8652, 3.1692, 2.9985],\n",
      "        [2.5218, 2.9160, 2.7760, 2.7317, 2.6928]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.5357, 2.7033, 2.6472, 2.7789, 2.7232],\n",
      "        [2.5679, 2.7036, 2.6929, 2.6961, 2.6803],\n",
      "        [2.5860, 2.6252, 2.7855, 2.8931, 2.9070],\n",
      "        [2.6384, 2.7341, 2.6626, 2.7934, 2.8842],\n",
      "        [2.5273, 2.9215, 2.6737, 2.9220, 2.8042],\n",
      "        [2.8105, 2.9629, 2.6946, 2.8270, 2.7878],\n",
      "        [2.4205, 2.6633, 2.6670, 2.6369, 2.5858],\n",
      "        [2.5063, 2.4883, 2.6578, 2.6906, 2.6807],\n",
      "        [2.5234, 2.6815, 2.6784, 2.8182, 2.6418],\n",
      "        [2.7183, 2.9551, 2.7774, 2.9889, 2.8870],\n",
      "        [3.0316, 3.1744, 2.9109, 2.9787, 2.8932],\n",
      "        [2.6874, 2.8298, 2.7045, 2.8899, 2.7698],\n",
      "        [2.5582, 2.5493, 2.6818, 2.7250, 2.7500],\n",
      "        [2.6127, 2.6115, 2.7841, 2.8307, 2.7374],\n",
      "        [2.5398, 2.6268, 2.7767, 2.8546, 2.8719],\n",
      "        [2.5056, 2.5593, 2.6665, 2.6706, 2.6276],\n",
      "        [2.4207, 2.6178, 2.5719, 2.6024, 2.5791],\n",
      "        [2.4709, 2.8050, 2.6876, 2.5573, 2.7673],\n",
      "        [2.5839, 2.6994, 2.6970, 2.7091, 2.6886],\n",
      "        [2.6353, 2.6918, 2.7123, 2.7752, 2.6868],\n",
      "        [2.5605, 2.7021, 2.5603, 2.7550, 2.6409],\n",
      "        [2.4702, 2.5976, 2.5474, 2.7240, 2.5852],\n",
      "        [2.7058, 2.6202, 2.6812, 3.0830, 2.8540],\n",
      "        [2.6847, 2.8025, 2.7911, 2.7716, 2.7834],\n",
      "        [2.5178, 2.7036, 2.6143, 2.7545, 2.7266],\n",
      "        [2.7243, 2.8505, 2.6932, 2.8359, 2.8652],\n",
      "        [2.5578, 2.8078, 2.7064, 2.7439, 2.5818],\n",
      "        [2.6693, 2.8512, 2.6936, 2.9631, 2.8049],\n",
      "        [2.5771, 2.8049, 2.7190, 2.7578, 2.5886],\n",
      "        [2.9616, 3.0963, 2.7509, 2.9278, 2.7865],\n",
      "        [2.5510, 2.5911, 2.7073, 2.6837, 2.6562],\n",
      "        [2.4485, 2.5780, 2.6662, 2.7363, 2.6600],\n",
      "        [2.5873, 2.8522, 2.6749, 2.9073, 2.7677],\n",
      "        [2.4194, 2.6847, 2.6734, 2.6427, 2.6031],\n",
      "        [2.4758, 2.6120, 2.5756, 2.6878, 2.5783],\n",
      "        [2.5317, 2.6379, 2.6445, 2.6632, 2.6487],\n",
      "        [2.5696, 2.7039, 2.7799, 2.7776, 2.7527],\n",
      "        [2.7121, 2.8710, 2.7975, 2.7547, 2.8027],\n",
      "        [2.5795, 2.8467, 2.6495, 2.5818, 2.7200],\n",
      "        [2.5233, 2.8088, 2.7693, 2.6540, 2.7283],\n",
      "        [2.5991, 2.8046, 2.6938, 2.7307, 2.7498],\n",
      "        [2.7871, 2.7228, 2.8176, 2.9792, 2.8100],\n",
      "        [2.4221, 2.7027, 2.6895, 2.6455, 2.6098],\n",
      "        [2.7971, 2.8965, 2.7746, 2.9266, 2.9320],\n",
      "        [2.6912, 2.9825, 2.8061, 3.0321, 2.9374],\n",
      "        [2.5074, 2.6728, 2.5674, 2.6927, 2.6216],\n",
      "        [2.5530, 2.5423, 2.6593, 2.7042, 2.7450],\n",
      "        [2.5134, 2.6359, 2.7716, 2.8257, 2.8337],\n",
      "        [2.6328, 2.7329, 2.6549, 2.8152, 2.7383],\n",
      "        [2.5516, 2.6222, 2.6906, 2.7419, 2.6938],\n",
      "        [2.4182, 2.7221, 2.6028, 2.4776, 2.6386],\n",
      "        [2.7517, 2.9022, 2.9175, 2.9140, 2.6900],\n",
      "        [2.4915, 2.6996, 2.6391, 2.7789, 2.6255],\n",
      "        [2.7932, 2.8040, 2.7938, 2.8519, 2.8140],\n",
      "        [2.5158, 2.6517, 2.6524, 2.7600, 2.6989],\n",
      "        [2.6772, 2.6711, 2.7345, 2.6682, 2.5490],\n",
      "        [2.5945, 2.8472, 2.7351, 2.8308, 2.8716],\n",
      "        [2.8057, 2.5571, 2.7370, 3.1335, 3.0428],\n",
      "        [2.8309, 2.8819, 2.7906, 2.9616, 2.9605],\n",
      "        [2.6910, 2.6601, 2.7880, 2.8655, 2.7266],\n",
      "        [2.5566, 2.9077, 2.7082, 2.8762, 2.8272],\n",
      "        [2.7093, 2.8568, 2.7041, 2.9254, 2.9606],\n",
      "        [2.7274, 2.6248, 2.6285, 2.6774, 2.7324],\n",
      "        [2.5602, 2.5549, 2.7188, 2.7447, 2.7562]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.5311, 2.8133, 2.7701, 2.6400, 2.7586],\n",
      "        [2.6897, 2.7572, 2.7633, 2.7598, 2.5344],\n",
      "        [2.5309, 2.6711, 2.5943, 2.7407, 2.6278],\n",
      "        [2.3965, 2.5911, 2.4762, 2.6665, 2.5213],\n",
      "        [2.5742, 2.7713, 2.6589, 2.8243, 2.6909],\n",
      "        [2.6565, 2.7831, 2.8355, 2.8688, 2.7923],\n",
      "        [2.5665, 2.7144, 2.5711, 2.7636, 2.6620],\n",
      "        [2.5608, 2.5993, 2.6990, 2.7233, 2.6799],\n",
      "        [2.4399, 2.5751, 2.6337, 2.6364, 2.5708],\n",
      "        [2.9661, 3.0986, 2.7547, 2.9287, 2.7909],\n",
      "        [2.7368, 2.8837, 2.8597, 2.9569, 2.9251],\n",
      "        [2.5061, 2.6667, 2.5714, 2.6808, 2.6316],\n",
      "        [2.5781, 2.7353, 2.7053, 2.7701, 2.7349],\n",
      "        [2.5231, 2.5875, 2.6910, 2.7346, 2.7438],\n",
      "        [2.4455, 2.5560, 2.6239, 2.6403, 2.5685],\n",
      "        [2.7258, 2.8584, 2.7159, 2.9203, 2.8681],\n",
      "        [2.4638, 2.5304, 2.6123, 2.6516, 2.5633],\n",
      "        [2.4823, 2.6597, 2.5780, 2.6628, 2.6197],\n",
      "        [2.5341, 2.7385, 2.7104, 2.6297, 2.6108],\n",
      "        [2.4228, 2.7246, 2.6065, 2.4785, 2.6427],\n",
      "        [2.5575, 2.5448, 2.6630, 2.7051, 2.7493],\n",
      "        [2.7474, 2.9867, 2.7931, 2.9931, 2.9620],\n",
      "        [2.5465, 2.6918, 2.6858, 2.7200, 2.6925],\n",
      "        [2.6399, 2.6943, 2.7161, 2.7761, 2.6911],\n",
      "        [2.5659, 2.6195, 2.7080, 2.6248, 2.4975],\n",
      "        [2.9098, 2.8495, 2.8368, 2.9556, 2.8775],\n",
      "        [2.5454, 2.6452, 2.6717, 2.7115, 2.7898],\n",
      "        [2.4823, 2.5044, 2.5988, 2.6692, 2.5541],\n",
      "        [2.5743, 2.8610, 2.6651, 2.8971, 2.7675],\n",
      "        [2.5319, 2.9215, 2.7845, 2.7338, 2.7022],\n",
      "        [2.8624, 2.7774, 2.8623, 3.0667, 2.9353],\n",
      "        [2.4546, 2.7119, 2.8283, 2.7169, 2.7312],\n",
      "        [2.4471, 2.7915, 2.6680, 2.5397, 2.7578],\n",
      "        [2.4874, 2.5982, 2.6714, 2.7093, 2.5752],\n",
      "        [2.5313, 2.6848, 2.5685, 2.7072, 2.6370],\n",
      "        [2.8558, 2.8220, 2.9021, 3.0748, 2.9083],\n",
      "        [2.6919, 2.8818, 2.7354, 2.8763, 2.7935],\n",
      "        [2.6400, 2.6909, 2.7160, 2.7724, 2.6819],\n",
      "        [2.4979, 2.6695, 2.5759, 2.6790, 2.6258],\n",
      "        [2.4916, 2.7546, 2.6733, 2.7283, 2.8269],\n",
      "        [2.5667, 2.5976, 2.7134, 2.6989, 2.7090],\n",
      "        [2.5112, 2.8169, 2.6942, 2.7187, 2.5849],\n",
      "        [2.6325, 2.6712, 2.8045, 2.8494, 2.7039],\n",
      "        [2.6619, 2.6535, 2.7394, 2.7904, 2.6785],\n",
      "        [2.5808, 2.5727, 2.7494, 2.7806, 2.7794],\n",
      "        [2.6919, 3.0149, 2.7686, 3.0135, 2.9317],\n",
      "        [2.5992, 2.8497, 2.7391, 2.8317, 2.8760],\n",
      "        [2.6333, 2.6980, 2.7235, 2.7849, 2.7686],\n",
      "        [2.5894, 2.7353, 2.5848, 2.7965, 2.6837],\n",
      "        [2.4257, 2.6314, 2.6577, 2.6455, 2.5950],\n",
      "        [2.4483, 2.5701, 2.6543, 2.6597, 2.5504],\n",
      "        [2.7256, 2.7796, 2.8126, 2.8601, 2.8723],\n",
      "        [2.4642, 2.6516, 2.5748, 2.6430, 2.6091],\n",
      "        [2.6214, 2.8592, 2.7179, 2.9230, 2.7806],\n",
      "        [2.6048, 2.8295, 2.7220, 2.8239, 2.8685],\n",
      "        [2.6371, 2.7011, 2.7207, 2.7673, 2.7010],\n",
      "        [2.5855, 2.7875, 2.6400, 2.9041, 2.6398],\n",
      "        [2.5716, 2.6842, 2.8437, 2.7934, 2.8215],\n",
      "        [2.5920, 2.8547, 2.6787, 2.9082, 2.7720],\n",
      "        [2.5533, 2.9223, 2.7255, 2.8866, 2.8483],\n",
      "        [2.5038, 2.5711, 2.6703, 2.6824, 2.6424],\n",
      "        [2.6187, 2.5725, 2.7045, 2.7573, 2.6401],\n",
      "        [2.6697, 2.8393, 2.7077, 2.8256, 2.7757],\n",
      "        [2.5545, 2.5491, 2.6446, 2.6862, 2.7415]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.5265, 2.4977, 2.6732, 2.7046, 2.6877],\n",
      "        [2.5464, 2.6209, 2.6902, 2.7309, 2.6818],\n",
      "        [2.4593, 2.6025, 2.6710, 2.6624, 2.5776],\n",
      "        [2.4952, 2.6628, 2.5829, 2.6597, 2.6202],\n",
      "        [2.5532, 2.6336, 2.7009, 2.7373, 2.7031],\n",
      "        [3.0056, 3.1726, 2.8026, 2.9138, 2.7995],\n",
      "        [2.5357, 2.8880, 2.7039, 2.8450, 2.8220],\n",
      "        [2.4108, 2.5146, 2.6071, 2.6086, 2.5010],\n",
      "        [2.5974, 2.7640, 2.6148, 2.6965, 2.7124],\n",
      "        [2.6607, 2.6508, 2.8481, 2.8681, 2.7369],\n",
      "        [2.5271, 2.8955, 2.8123, 2.7852, 2.7042],\n",
      "        [2.4454, 2.5772, 2.6370, 2.6372, 2.5765],\n",
      "        [2.5654, 2.7047, 2.5733, 2.7482, 2.6670],\n",
      "        [2.6992, 2.9147, 2.7188, 2.6657, 2.7488],\n",
      "        [2.5395, 2.6731, 2.6020, 2.7173, 2.6628],\n",
      "        [2.6813, 2.8069, 2.8263, 2.8620, 2.8328],\n",
      "        [2.5797, 2.5676, 2.7360, 2.7615, 2.7792],\n",
      "        [2.5879, 2.6584, 2.7143, 2.7010, 2.8739],\n",
      "        [2.7483, 2.7152, 2.7455, 2.7181, 2.6213],\n",
      "        [2.5768, 2.7155, 2.5727, 2.7717, 2.6665],\n",
      "        [2.5338, 2.6861, 2.6857, 2.8199, 2.6520],\n",
      "        [2.5326, 2.8178, 2.7741, 2.6560, 2.7413],\n",
      "        [2.8556, 2.7084, 2.8525, 3.3369, 3.1821],\n",
      "        [2.6755, 2.8416, 2.7112, 2.8264, 2.7816],\n",
      "        [2.8521, 2.9096, 2.8344, 3.0930, 2.9482],\n",
      "        [2.6204, 2.6703, 2.7901, 2.8244, 2.6986],\n",
      "        [2.4410, 2.6277, 2.5802, 2.6056, 2.6006],\n",
      "        [2.5548, 2.5404, 2.6342, 2.6696, 2.7395],\n",
      "        [2.6203, 2.6474, 2.8091, 2.8052, 2.7561],\n",
      "        [2.5198, 2.6755, 2.5754, 2.6946, 2.6408],\n",
      "        [2.4551, 2.6807, 2.5590, 2.7053, 2.5988],\n",
      "        [2.7473, 2.6190, 2.6442, 2.6826, 2.7479],\n",
      "        [2.8127, 2.8394, 2.8564, 3.0179, 2.8847],\n",
      "        [2.6540, 2.8565, 2.8100, 2.8634, 2.8984],\n",
      "        [2.5598, 2.5512, 2.6480, 2.6871, 2.7474],\n",
      "        [2.8869, 2.8187, 2.8372, 2.9339, 2.8439],\n",
      "        [2.5447, 2.6027, 2.6462, 2.7658, 2.6007],\n",
      "        [2.3785, 2.5888, 2.5884, 2.6277, 2.5985],\n",
      "        [2.5904, 2.7368, 2.5732, 2.7958, 2.6840],\n",
      "        [2.6852, 2.6923, 2.6709, 2.9379, 2.8040],\n",
      "        [2.5367, 2.6868, 2.5718, 2.7080, 2.6428],\n",
      "        [2.5553, 2.6130, 2.6881, 2.7285, 2.6799],\n",
      "        [2.4707, 2.4950, 2.5900, 2.6595, 2.5492],\n",
      "        [2.5223, 2.6584, 2.6563, 2.7741, 2.6860],\n",
      "        [2.8278, 2.6861, 2.7421, 3.1997, 2.9852],\n",
      "        [2.5681, 2.5878, 2.7207, 2.7307, 2.6793],\n",
      "        [2.5567, 2.6465, 2.6829, 2.7060, 2.8133],\n",
      "        [2.6525, 2.6408, 2.7497, 2.6850, 2.6767],\n",
      "        [2.8655, 2.8269, 2.9064, 3.0768, 2.9159],\n",
      "        [2.7241, 2.8513, 2.8448, 2.8231, 2.6493],\n",
      "        [2.6799, 2.8560, 2.7010, 2.9649, 2.8155],\n",
      "        [2.4996, 2.6246, 2.5814, 2.7061, 2.5933],\n",
      "        [2.8794, 2.9886, 2.8814, 3.1595, 2.9972],\n",
      "        [2.5275, 2.5794, 2.5277, 2.6714, 2.7318],\n",
      "        [2.8555, 2.9022, 2.7986, 2.9522, 2.9874],\n",
      "        [2.5923, 2.7368, 2.5859, 2.7987, 2.6853],\n",
      "        [2.4914, 2.8592, 2.7009, 2.7794, 2.8256],\n",
      "        [2.6661, 2.7508, 2.6986, 2.7788, 2.7112],\n",
      "        [2.7712, 2.8842, 2.7495, 2.8888, 2.9348],\n",
      "        [2.6633, 2.6583, 2.7519, 2.6998, 2.6541],\n",
      "        [2.5776, 2.7201, 2.5662, 2.7741, 2.6690],\n",
      "        [2.6260, 2.8758, 2.8136, 2.8505, 2.9481],\n",
      "        [2.6978, 2.7343, 2.9310, 2.7514, 2.6775],\n",
      "        [2.7532, 2.8634, 2.7220, 2.8515, 2.9110]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.5492, 2.6039, 2.5543, 2.6929, 2.7533],\n",
      "        [2.4321, 2.6227, 2.6539, 2.6351, 2.5873],\n",
      "        [2.6235, 2.5860, 2.7130, 2.7566, 2.6840],\n",
      "        [2.4849, 2.8528, 2.7047, 2.7531, 2.8419],\n",
      "        [2.5722, 2.7946, 2.6976, 2.8806, 2.6925],\n",
      "        [2.6753, 2.5565, 2.8546, 2.8134, 2.7531],\n",
      "        [2.5612, 2.7054, 2.5760, 2.7424, 2.6625],\n",
      "        [2.6356, 2.8096, 2.7557, 2.7812, 2.6286],\n",
      "        [2.6556, 2.8446, 2.8130, 2.8673, 2.8620],\n",
      "        [2.7342, 2.7881, 2.7863, 2.8855, 2.9152],\n",
      "        [2.9199, 2.7443, 2.9253, 3.3907, 3.2552],\n",
      "        [2.8063, 2.8695, 2.7937, 3.0441, 2.9081],\n",
      "        [2.7084, 2.8247, 2.8234, 2.9706, 2.7543],\n",
      "        [2.8219, 2.8338, 2.7307, 2.9266, 2.9019],\n",
      "        [2.5942, 2.8774, 2.8334, 2.8601, 2.8659],\n",
      "        [2.5214, 2.5666, 2.6767, 2.6730, 2.6433],\n",
      "        [2.5632, 2.7104, 2.5818, 2.7475, 2.6685],\n",
      "        [2.7169, 2.8453, 2.7391, 2.7986, 2.7793],\n",
      "        [2.6504, 2.8700, 2.8822, 2.8821, 2.7601],\n",
      "        [2.7706, 2.6359, 2.7229, 3.1237, 2.9236],\n",
      "        [2.4671, 2.5537, 2.6318, 2.6479, 2.5795],\n",
      "        [2.8281, 2.5692, 2.7655, 3.1253, 3.0487],\n",
      "        [2.7034, 2.7371, 2.9345, 2.7521, 2.6833],\n",
      "        [2.7104, 2.8381, 2.7467, 2.7380, 2.7636],\n",
      "        [2.5562, 2.6009, 2.6845, 2.7161, 2.6784],\n",
      "        [2.5147, 2.5018, 2.7199, 2.5451, 2.7192],\n",
      "        [2.4641, 2.5622, 2.6399, 2.6644, 2.5872],\n",
      "        [2.8856, 2.9914, 2.8848, 3.1604, 3.0028],\n",
      "        [2.8771, 2.8099, 2.8350, 2.9216, 2.8348],\n",
      "        [2.5576, 2.6359, 2.7051, 2.7470, 2.7037],\n",
      "        [2.5681, 2.5840, 2.7254, 2.6713, 2.7212],\n",
      "        [2.5166, 2.6413, 2.5994, 2.7531, 2.6510],\n",
      "        [2.5141, 2.7199, 2.6188, 2.8037, 2.6244],\n",
      "        [2.5427, 2.5881, 2.7072, 2.7392, 2.7411],\n",
      "        [2.5499, 2.5371, 2.6226, 2.6536, 2.7383],\n",
      "        [2.5637, 2.5994, 2.6972, 2.7174, 2.6824],\n",
      "        [2.6283, 2.6190, 2.7945, 2.8332, 2.7533],\n",
      "        [2.5566, 2.6801, 2.6650, 2.7002, 2.6626],\n",
      "        [2.4514, 2.8370, 2.7411, 2.6968, 2.8400],\n",
      "        [2.7092, 2.7856, 2.8224, 2.8806, 2.7028],\n",
      "        [2.6081, 2.7613, 2.5822, 2.7091, 2.7061],\n",
      "        [2.6548, 2.7384, 2.6610, 2.7827, 2.8848],\n",
      "        [2.4395, 2.6830, 2.6274, 2.6686, 2.7653],\n",
      "        [2.3331, 2.5368, 2.6035, 2.5636, 2.5958],\n",
      "        [2.6959, 2.8437, 2.8207, 2.8053, 2.6485],\n",
      "        [2.5419, 2.8183, 2.7769, 2.6417, 2.7704],\n",
      "        [2.5682, 2.6071, 2.6376, 2.7823, 2.6190],\n",
      "        [2.8627, 2.7176, 2.8554, 3.3448, 3.1866],\n",
      "        [2.6712, 2.7535, 2.7018, 2.7795, 2.7166],\n",
      "        [2.8563, 2.6744, 2.7511, 3.2339, 3.0207],\n",
      "        [2.6752, 2.5333, 2.8520, 2.8160, 2.7441],\n",
      "        [2.7663, 2.8120, 2.8904, 3.0038, 2.7631],\n",
      "        [2.4077, 2.5291, 2.5732, 2.5714, 2.5451],\n",
      "        [2.8443, 2.9573, 2.8514, 3.1107, 2.9354],\n",
      "        [2.7106, 2.7426, 2.7863, 2.7709, 2.6043],\n",
      "        [2.7042, 2.7144, 2.8558, 2.7972, 2.5794],\n",
      "        [2.5261, 2.4900, 2.5714, 2.6644, 2.5469],\n",
      "        [2.5578, 2.6194, 2.6996, 2.7386, 2.7059],\n",
      "        [2.5239, 2.6815, 2.5833, 2.6791, 2.6466],\n",
      "        [2.5543, 2.8350, 2.6602, 2.5636, 2.7643],\n",
      "        [2.5855, 2.7761, 2.6658, 2.8258, 2.7022],\n",
      "        [2.6689, 2.8066, 2.7848, 2.8099, 2.6457],\n",
      "        [2.8581, 2.9124, 2.8378, 3.0938, 2.9538],\n",
      "        [2.4544, 2.6236, 2.6968, 2.6749, 2.5976]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.5001, 2.5615, 2.6458, 2.6692, 2.5816],\n",
      "        [2.5716, 2.7052, 2.6671, 2.7127, 2.6918],\n",
      "        [2.6726, 2.7476, 2.8250, 2.7786, 2.6675],\n",
      "        [2.5764, 2.6074, 2.7095, 2.7255, 2.6962],\n",
      "        [2.7343, 2.8467, 2.7668, 2.8417, 2.8848],\n",
      "        [2.8274, 2.6982, 2.7368, 2.7992, 2.7892],\n",
      "        [2.5344, 2.9225, 2.7972, 2.7255, 2.7127],\n",
      "        [2.6951, 2.6650, 2.7806, 2.8337, 2.7325],\n",
      "        [2.5623, 2.7961, 2.7365, 2.6662, 2.7659],\n",
      "        [2.9922, 2.7390, 2.9020, 3.3792, 3.2656],\n",
      "        [2.5628, 2.5494, 2.6409, 2.6719, 2.7495],\n",
      "        [2.5810, 2.5548, 2.7027, 2.7314, 2.7679],\n",
      "        [2.6040, 2.7605, 2.5694, 2.6986, 2.7018],\n",
      "        [2.4732, 2.8094, 2.6878, 2.5504, 2.7763],\n",
      "        [2.5222, 2.7237, 2.6238, 2.8016, 2.6264],\n",
      "        [2.8567, 2.9129, 2.8148, 2.9548, 2.9863],\n",
      "        [2.7899, 2.8058, 2.8019, 2.8314, 2.8355],\n",
      "        [2.7148, 2.9543, 2.7890, 2.9710, 2.8917],\n",
      "        [2.5676, 2.7110, 2.5910, 2.7473, 2.6782],\n",
      "        [2.7693, 2.6611, 2.7388, 2.7655, 2.7345],\n",
      "        [2.4610, 2.6434, 2.7373, 2.6903, 2.5838],\n",
      "        [2.5339, 2.6826, 2.6772, 2.5904, 2.6384],\n",
      "        [2.4557, 2.5833, 2.6483, 2.6410, 2.5877],\n",
      "        [2.4847, 2.6569, 2.5874, 2.6449, 2.6264],\n",
      "        [2.5993, 2.6266, 2.7663, 2.7752, 2.7271],\n",
      "        [2.5360, 2.6828, 2.5792, 2.6985, 2.6531],\n",
      "        [2.7126, 2.8842, 2.8307, 2.8695, 2.7815],\n",
      "        [2.7116, 2.6710, 2.8024, 2.8686, 2.7480],\n",
      "        [2.5905, 2.7866, 2.6839, 2.7297, 2.7669],\n",
      "        [2.5767, 2.5523, 2.6932, 2.7242, 2.7655],\n",
      "        [2.6983, 2.8140, 2.8205, 2.8746, 2.7662],\n",
      "        [2.6818, 2.7890, 2.8380, 2.8300, 2.7963],\n",
      "        [2.7331, 2.8817, 2.8121, 2.7579, 2.8238],\n",
      "        [2.5569, 2.6317, 2.6971, 2.7339, 2.6935],\n",
      "        [2.5403, 2.6693, 2.8479, 2.7457, 2.8150],\n",
      "        [2.3864, 2.5662, 2.5636, 2.5301, 2.5400],\n",
      "        [2.8614, 2.6778, 2.7553, 3.2345, 3.0256],\n",
      "        [2.5631, 2.6023, 2.6897, 2.7160, 2.6833],\n",
      "        [2.5782, 2.5797, 2.7305, 2.7183, 2.6835],\n",
      "        [2.5586, 2.6314, 2.6998, 2.7352, 2.6958],\n",
      "        [2.6485, 2.6794, 2.8153, 2.8516, 2.7204],\n",
      "        [2.8648, 2.9601, 2.8188, 3.1588, 2.9898],\n",
      "        [2.8109, 2.6711, 2.6570, 2.7443, 2.7727],\n",
      "        [2.7424, 2.6167, 2.6335, 2.6698, 2.7438],\n",
      "        [2.5529, 2.6592, 2.5083, 2.7919, 2.5408],\n",
      "        [2.4214, 2.6085, 2.5777, 2.5789, 2.5810],\n",
      "        [2.7915, 2.8019, 2.8275, 2.9839, 2.8473],\n",
      "        [2.5849, 2.7822, 2.6707, 2.6832, 2.7452],\n",
      "        [2.4214, 2.4587, 2.5775, 2.6617, 2.5560],\n",
      "        [2.7021, 2.9025, 2.9049, 2.9054, 2.7215],\n",
      "        [2.8963, 2.7091, 2.8520, 3.3619, 3.1820],\n",
      "        [2.8416, 2.9274, 2.8728, 2.9377, 2.9525],\n",
      "        [2.5288, 2.5292, 2.6211, 2.6939, 2.5638],\n",
      "        [2.4404, 2.6281, 2.5856, 2.6054, 2.5989],\n",
      "        [2.6615, 2.7518, 2.7836, 2.7866, 2.7698],\n",
      "        [2.7513, 2.6566, 2.7214, 3.0442, 2.8777],\n",
      "        [2.8899, 2.7887, 2.7910, 2.8692, 2.8149],\n",
      "        [2.4096, 2.6000, 2.5752, 2.5602, 2.5707],\n",
      "        [2.4931, 2.8150, 2.7293, 2.7520, 2.8089],\n",
      "        [2.5323, 2.8372, 2.7703, 2.7896, 2.8306],\n",
      "        [2.5695, 2.9305, 2.7367, 2.8889, 2.8648],\n",
      "        [2.5264, 2.5699, 2.6807, 2.6736, 2.6483],\n",
      "        [2.6302, 2.8023, 2.6871, 2.8340, 2.7520],\n",
      "        [2.8393, 2.5771, 2.7594, 3.1402, 3.0759]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.5786, 2.5968, 2.7681, 2.7683, 2.7133],\n",
      "        [2.7161, 2.9268, 2.7713, 2.8728, 2.8285],\n",
      "        [2.4413, 2.5921, 2.5449, 2.6833, 2.5301],\n",
      "        [2.6996, 2.7883, 2.8662, 2.8060, 2.6884],\n",
      "        [2.6753, 2.9553, 2.7858, 2.8815, 2.8402],\n",
      "        [2.5457, 2.6778, 2.6829, 2.7952, 2.7054],\n",
      "        [2.4501, 2.6305, 2.6731, 2.6494, 2.6148],\n",
      "        [2.8168, 2.8187, 2.8117, 2.8557, 2.8417],\n",
      "        [2.5044, 2.6565, 2.5840, 2.6583, 2.6236],\n",
      "        [2.6483, 2.8512, 2.8587, 2.8590, 2.7530],\n",
      "        [2.6847, 2.5404, 2.8597, 2.8173, 2.7546],\n",
      "        [2.7543, 2.9395, 2.8147, 2.7553, 2.8562],\n",
      "        [2.4493, 2.6899, 2.6353, 2.6699, 2.7753],\n",
      "        [2.5703, 2.7916, 2.6572, 2.6752, 2.7341],\n",
      "        [2.6660, 2.9827, 2.8618, 2.9011, 2.9427],\n",
      "        [2.6332, 2.6929, 2.7152, 2.8454, 2.7249],\n",
      "        [2.7425, 2.8156, 2.8609, 2.9804, 2.7620],\n",
      "        [2.9022, 2.8107, 2.8949, 3.0813, 2.9328],\n",
      "        [2.4394, 2.6900, 2.6900, 2.6417, 2.6196],\n",
      "        [2.7269, 3.0094, 2.8386, 3.0396, 2.9748],\n",
      "        [2.4297, 2.6117, 2.5786, 2.5810, 2.5846],\n",
      "        [2.6987, 2.8236, 2.7321, 2.7177, 2.7508],\n",
      "        [2.4441, 2.6989, 2.6911, 2.6465, 2.6286],\n",
      "        [2.6969, 2.8354, 2.7173, 2.8962, 2.7981],\n",
      "        [2.6048, 2.7232, 2.7203, 2.7187, 2.7144],\n",
      "        [2.5437, 2.5994, 2.7053, 2.7373, 2.7657],\n",
      "        [2.4842, 2.6632, 2.5887, 2.6457, 2.6302],\n",
      "        [2.8859, 2.6720, 2.7579, 3.2707, 3.0494],\n",
      "        [2.4656, 2.7168, 2.8295, 2.6978, 2.7481],\n",
      "        [2.4912, 2.6156, 2.6790, 2.6233, 2.6166],\n",
      "        [2.6027, 2.8195, 2.7376, 2.7616, 2.6152],\n",
      "        [2.3909, 2.5698, 2.5671, 2.5307, 2.5451],\n",
      "        [3.1099, 3.3121, 2.8752, 3.0133, 2.9232],\n",
      "        [2.4901, 2.6320, 2.7123, 2.7015, 2.5905],\n",
      "        [2.6680, 2.7866, 2.6766, 2.8222, 2.8422],\n",
      "        [2.6448, 2.6543, 2.8193, 2.8167, 2.7783],\n",
      "        [2.5911, 2.5764, 2.7457, 2.7596, 2.7916],\n",
      "        [2.4129, 2.6046, 2.4848, 2.6525, 2.5416],\n",
      "        [2.4357, 2.7052, 2.6960, 2.6400, 2.6270],\n",
      "        [2.6451, 2.8617, 2.6880, 2.6053, 2.7132],\n",
      "        [2.6968, 2.7012, 2.6880, 2.9413, 2.8190],\n",
      "        [2.4871, 2.6557, 2.5903, 2.6404, 2.6235],\n",
      "        [2.5677, 2.6265, 2.7074, 2.7399, 2.7165],\n",
      "        [2.5539, 2.6750, 2.6797, 2.7521, 2.7577],\n",
      "        [2.7644, 2.8808, 2.8871, 2.8473, 2.6820],\n",
      "        [2.5387, 2.8366, 2.8068, 2.6427, 2.7884],\n",
      "        [2.5762, 2.7807, 2.7040, 2.6837, 2.7575],\n",
      "        [2.5999, 2.6178, 2.7668, 2.7838, 2.7537],\n",
      "        [2.5673, 2.5978, 2.7012, 2.7171, 2.6864],\n",
      "        [2.6031, 2.7471, 2.5550, 2.6945, 2.6940],\n",
      "        [2.7443, 2.6464, 2.7060, 3.0938, 2.8895],\n",
      "        [2.6634, 2.6424, 2.7530, 2.6925, 2.6692],\n",
      "        [2.4949, 2.8599, 2.7128, 2.7544, 2.8523],\n",
      "        [2.6138, 2.7552, 2.5917, 2.8094, 2.7050],\n",
      "        [2.5950, 2.6018, 2.7300, 2.7473, 2.7595],\n",
      "        [2.5809, 2.6619, 2.7016, 2.7018, 2.8497],\n",
      "        [2.4639, 2.6306, 2.7044, 2.6762, 2.6078],\n",
      "        [3.0340, 3.2637, 2.8349, 2.9803, 2.8391],\n",
      "        [2.4113, 2.6126, 2.5861, 2.6253, 2.5930],\n",
      "        [2.4627, 2.6172, 2.6869, 2.6679, 2.5862],\n",
      "        [3.0209, 3.1328, 2.7537, 2.9387, 2.7755],\n",
      "        [2.5524, 2.5952, 2.7149, 2.7405, 2.7516],\n",
      "        [2.6932, 2.7471, 2.6113, 2.8618, 2.8324],\n",
      "        [2.3963, 2.6114, 2.7695, 2.5885, 2.7130]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.4773, 2.6522, 2.5963, 2.6242, 2.6237],\n",
      "        [2.7825, 2.9435, 2.9572, 2.9290, 2.7523],\n",
      "        [2.6424, 2.6306, 2.8057, 2.8350, 2.7691],\n",
      "        [2.6831, 2.8182, 2.7963, 2.8118, 2.6617],\n",
      "        [2.4210, 2.6066, 2.4927, 2.6700, 2.5460],\n",
      "        [2.5692, 2.5799, 2.6994, 2.6650, 2.6539],\n",
      "        [2.6816, 2.7560, 2.8325, 2.7798, 2.6781],\n",
      "        [2.5286, 2.5132, 2.7307, 2.5470, 2.7351],\n",
      "        [2.6050, 2.6330, 2.7219, 2.7344, 2.7361],\n",
      "        [2.6397, 2.8747, 2.8374, 2.8109, 2.8474],\n",
      "        [2.5474, 2.6091, 2.6607, 2.7581, 2.6251],\n",
      "        [2.4548, 2.5502, 2.6308, 2.6275, 2.5708],\n",
      "        [2.6185, 2.7746, 2.6158, 2.7018, 2.7274],\n",
      "        [2.7062, 2.7637, 2.7727, 2.7585, 2.5542],\n",
      "        [2.7613, 2.7950, 2.8210, 2.9208, 2.7588],\n",
      "        [2.6418, 2.8745, 2.8082, 2.8334, 2.7528],\n",
      "        [2.5622, 2.6631, 2.6818, 2.7240, 2.7975],\n",
      "        [2.7099, 2.8374, 2.7234, 2.8915, 2.8081],\n",
      "        [2.5659, 2.6801, 2.6310, 2.6813, 2.6480],\n",
      "        [2.5587, 2.9384, 2.8039, 2.7374, 2.7305],\n",
      "        [2.7042, 2.6733, 2.7878, 2.8349, 2.7433],\n",
      "        [2.7664, 2.9011, 2.9047, 2.8643, 2.6658],\n",
      "        [2.5724, 2.6254, 2.7036, 2.7322, 2.6990],\n",
      "        [2.8741, 2.9242, 2.8497, 3.0959, 2.9700],\n",
      "        [2.4114, 2.5975, 2.5802, 2.5514, 2.5811],\n",
      "        [2.8732, 2.9101, 2.8154, 2.9731, 2.9949],\n",
      "        [2.4952, 2.6673, 2.7594, 2.7664, 2.8119],\n",
      "        [2.5994, 2.6061, 2.7334, 2.7479, 2.7646],\n",
      "        [2.4643, 2.5909, 2.6511, 2.6398, 2.5969],\n",
      "        [2.7228, 2.8363, 2.8349, 2.9725, 2.7704],\n",
      "        [2.4882, 2.5461, 2.6296, 2.6549, 2.5894],\n",
      "        [2.5964, 2.7340, 2.5806, 2.7765, 2.6897],\n",
      "        [2.4596, 2.6413, 2.5941, 2.6082, 2.6207],\n",
      "        [2.3013, 2.5092, 2.5934, 2.5346, 2.5845],\n",
      "        [2.5903, 2.6266, 2.7483, 2.7464, 2.7133],\n",
      "        [2.5731, 2.5676, 2.7254, 2.7155, 2.6747],\n",
      "        [2.7161, 2.8707, 2.8012, 2.8922, 2.8054],\n",
      "        [2.9722, 2.7521, 2.9339, 3.4249, 3.2697],\n",
      "        [2.6559, 2.8397, 2.7478, 2.7260, 2.8091],\n",
      "        [2.4895, 2.5086, 2.6039, 2.6620, 2.5694],\n",
      "        [2.7547, 2.8824, 2.9166, 2.8485, 2.6533],\n",
      "        [2.4882, 2.5461, 2.6296, 2.6549, 2.5894],\n",
      "        [2.6819, 2.9867, 2.8496, 2.9100, 2.9735],\n",
      "        [2.6070, 2.6727, 2.7289, 2.7037, 2.8956],\n",
      "        [2.5559, 2.8298, 2.7883, 2.6436, 2.7865],\n",
      "        [2.5478, 2.6879, 2.5839, 2.7052, 2.6458],\n",
      "        [2.4936, 2.6648, 2.5944, 2.6461, 2.6366],\n",
      "        [2.5222, 2.6724, 2.5829, 2.6740, 2.6356],\n",
      "        [2.5725, 2.6988, 2.6217, 2.7264, 2.6962],\n",
      "        [2.6734, 2.8641, 2.7752, 2.9389, 2.8042],\n",
      "        [2.5868, 2.7256, 2.5910, 2.7668, 2.6847],\n",
      "        [2.6001, 2.7875, 2.6773, 2.8277, 2.7178],\n",
      "        [2.7106, 2.9715, 2.8890, 2.9141, 2.9519],\n",
      "        [2.7241, 2.9068, 2.8413, 2.8813, 2.8096],\n",
      "        [2.5979, 2.5407, 2.6729, 2.6147, 2.6025],\n",
      "        [2.5790, 2.6900, 2.7697, 2.7737, 2.7904],\n",
      "        [2.7115, 2.7190, 2.7850, 2.7592, 2.6347],\n",
      "        [2.5644, 2.6264, 2.6994, 2.7263, 2.6965],\n",
      "        [2.5720, 2.6473, 2.7164, 2.7489, 2.7195],\n",
      "        [2.9078, 3.0569, 2.8339, 2.8492, 2.8375],\n",
      "        [2.6342, 2.6523, 2.8090, 2.8088, 2.7769],\n",
      "        [2.4406, 2.7013, 2.6910, 2.6399, 2.6234],\n",
      "        [2.7246, 2.8493, 2.7578, 2.7399, 2.7791],\n",
      "        [2.5686, 2.8463, 2.6714, 2.5656, 2.7796]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.6601, 2.6952, 2.7072, 2.8056, 2.8289],\n",
      "        [2.7659, 2.5927, 2.6539, 2.6966, 2.7408],\n",
      "        [2.5586, 2.8337, 2.7185, 2.7275, 2.6092],\n",
      "        [2.6756, 2.9525, 2.7805, 2.8733, 2.8387],\n",
      "        [2.5971, 2.6445, 2.7403, 2.7436, 2.7170],\n",
      "        [2.4766, 2.6698, 2.6187, 2.7250, 2.6268],\n",
      "        [2.4528, 2.6193, 2.6607, 2.6363, 2.6037],\n",
      "        [2.5048, 2.6078, 2.6865, 2.7107, 2.5936],\n",
      "        [2.6511, 2.8462, 2.7499, 2.7404, 2.7942],\n",
      "        [3.0279, 3.1907, 2.8204, 2.9172, 2.8254],\n",
      "        [2.6035, 2.8811, 2.6864, 2.9012, 2.7988],\n",
      "        [2.5912, 2.9306, 2.7340, 2.8812, 2.8634],\n",
      "        [2.5978, 2.7354, 2.5975, 2.7755, 2.6984],\n",
      "        [2.9231, 3.0506, 2.7473, 2.8809, 2.8239],\n",
      "        [2.8288, 2.8248, 2.8655, 2.9797, 2.7661],\n",
      "        [2.4769, 2.6043, 2.7589, 2.6599, 2.7295],\n",
      "        [2.5576, 2.7749, 2.7048, 2.8902, 2.7181],\n",
      "        [2.8851, 3.0163, 2.7334, 2.8488, 2.8225],\n",
      "        [2.4927, 2.6622, 2.5925, 2.6518, 2.6336],\n",
      "        [2.7284, 2.7578, 2.8005, 2.7733, 2.6247],\n",
      "        [2.7458, 2.7106, 2.7554, 2.6981, 2.6240],\n",
      "        [2.5442, 2.5048, 2.5853, 2.6668, 2.5665],\n",
      "        [2.5360, 2.8056, 2.7849, 2.6779, 2.9247],\n",
      "        [2.6220, 2.9529, 2.7496, 2.9174, 2.8793],\n",
      "        [2.7700, 2.9135, 2.9319, 2.9228, 2.7584],\n",
      "        [2.5898, 2.6193, 2.7197, 2.7272, 2.7114],\n",
      "        [2.7006, 2.7534, 2.8611, 2.7997, 2.7179],\n",
      "        [2.4691, 2.6414, 2.5955, 2.6195, 2.6348],\n",
      "        [2.7766, 2.8652, 2.9054, 2.8615, 2.7383],\n",
      "        [2.4739, 2.6409, 2.5905, 2.6200, 2.6128],\n",
      "        [2.5655, 2.5376, 2.7096, 2.7216, 2.7283],\n",
      "        [2.6294, 2.9038, 2.7904, 2.8475, 2.9141],\n",
      "        [2.7271, 2.8403, 2.8381, 2.9731, 2.7752],\n",
      "        [2.5916, 2.8102, 2.7127, 2.8831, 2.7130],\n",
      "        [2.8959, 2.7054, 2.7718, 3.2666, 3.0753],\n",
      "        [2.5417, 2.6964, 2.5975, 2.6814, 2.6662],\n",
      "        [2.6681, 2.7552, 2.6828, 2.8173, 2.7689],\n",
      "        [2.4744, 2.6423, 2.7024, 2.6814, 2.6090],\n",
      "        [2.6720, 2.6507, 2.7596, 2.6937, 2.6791],\n",
      "        [2.5683, 2.6204, 2.6634, 2.7690, 2.6257],\n",
      "        [2.7891, 2.6109, 2.6460, 2.6808, 2.7604],\n",
      "        [2.4578, 2.6182, 2.6655, 2.6393, 2.6033],\n",
      "        [2.5034, 2.6195, 2.5713, 2.7288, 2.6195],\n",
      "        [2.7312, 2.8634, 2.8465, 2.8129, 2.6679],\n",
      "        [2.4900, 2.5736, 2.6660, 2.6631, 2.5754],\n",
      "        [2.5276, 2.6484, 2.6117, 2.7666, 2.6646],\n",
      "        [2.6115, 2.8277, 2.7444, 2.7628, 2.6251],\n",
      "        [2.7196, 2.7632, 2.8572, 2.8106, 2.6579],\n",
      "        [2.7017, 2.6776, 2.7765, 2.8176, 2.7268],\n",
      "        [2.6790, 2.8752, 2.8286, 2.8668, 2.9247],\n",
      "        [2.3518, 2.5517, 2.6174, 2.5661, 2.6152],\n",
      "        [2.6749, 2.9914, 2.8689, 2.9023, 2.9527],\n",
      "        [2.8162, 2.8656, 2.9309, 2.8943, 2.7507],\n",
      "        [2.4835, 2.6008, 2.6913, 2.7411, 2.6962],\n",
      "        [2.5854, 2.7034, 2.8693, 2.7801, 2.8509],\n",
      "        [2.6815, 2.7310, 2.8461, 2.8490, 2.7565],\n",
      "        [2.4023, 2.6064, 2.6056, 2.6309, 2.6233],\n",
      "        [2.8579, 2.8421, 2.8107, 2.8774, 2.8590],\n",
      "        [2.6233, 2.7789, 2.6139, 2.7119, 2.7365],\n",
      "        [2.7799, 3.0061, 2.8155, 2.9987, 2.9903],\n",
      "        [2.5136, 2.5397, 2.6267, 2.6770, 2.5940],\n",
      "        [2.9911, 3.1194, 2.8702, 2.9112, 2.8654],\n",
      "        [2.5753, 2.6496, 2.8351, 2.8383, 2.7627],\n",
      "        [2.5337, 2.5912, 2.6912, 2.6864, 2.6740]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.7620, 2.8036, 2.9517, 2.7971, 2.6907],\n",
      "        [2.7245, 2.8527, 2.7566, 2.7382, 2.7792],\n",
      "        [2.4916, 2.6306, 2.7055, 2.6757, 2.6197],\n",
      "        [2.8456, 3.0149, 2.8225, 2.7927, 2.8058],\n",
      "        [2.9976, 3.1236, 2.7788, 2.9342, 2.8266],\n",
      "        [2.6153, 2.7943, 2.6685, 2.6939, 2.7576],\n",
      "        [2.7393, 2.8019, 2.8212, 2.8844, 2.9010],\n",
      "        [2.5531, 2.6790, 2.6803, 2.7663, 2.7390],\n",
      "        [2.7079, 2.8796, 2.7228, 2.9694, 2.8465],\n",
      "        [2.4883, 2.6769, 2.6495, 2.7898, 2.6058],\n",
      "        [3.2075, 3.3561, 2.9893, 3.0815, 2.9546],\n",
      "        [2.4893, 2.5984, 2.6768, 2.6694, 2.5888],\n",
      "        [2.5863, 2.7265, 2.6003, 2.7514, 2.6961],\n",
      "        [2.6251, 2.8646, 2.6773, 2.8176, 2.7743],\n",
      "        [2.7389, 2.6657, 2.7070, 3.0573, 2.8806],\n",
      "        [2.4791, 2.5846, 2.6516, 2.6442, 2.6040],\n",
      "        [2.5703, 2.8206, 2.7646, 2.6585, 2.7863],\n",
      "        [2.5402, 2.5528, 2.6451, 2.6881, 2.5931],\n",
      "        [2.7171, 2.8732, 2.7468, 2.8644, 2.7969],\n",
      "        [2.7136, 2.7549, 2.7576, 2.8526, 2.8833],\n",
      "        [3.1216, 3.3256, 2.8853, 3.0159, 2.9378],\n",
      "        [2.6072, 2.8769, 2.6830, 2.8986, 2.8000],\n",
      "        [3.0073, 2.7536, 2.9094, 3.3781, 3.2804],\n",
      "        [2.5080, 2.4882, 2.7167, 2.4974, 2.7267],\n",
      "        [2.8430, 2.8630, 2.8781, 3.0228, 2.9154],\n",
      "        [2.6578, 2.8302, 2.7736, 2.7851, 2.6536],\n",
      "        [2.4126, 2.6937, 2.7678, 2.6360, 2.7450],\n",
      "        [2.4150, 2.5996, 2.5810, 2.5509, 2.5797],\n",
      "        [2.5684, 2.7149, 2.8404, 2.6921, 2.7233],\n",
      "        [2.7256, 2.8578, 2.7329, 2.8964, 2.8096],\n",
      "        [2.5061, 2.7040, 2.6343, 2.6678, 2.6903],\n",
      "        [2.7441, 2.9755, 2.8036, 2.9877, 2.9147],\n",
      "        [2.5113, 2.5230, 2.6132, 2.6728, 2.5911],\n",
      "        [2.7492, 2.7155, 2.7584, 2.6994, 2.6283],\n",
      "        [2.9384, 2.9090, 2.8617, 2.9739, 2.9192],\n",
      "        [2.6135, 2.6402, 2.7818, 2.7739, 2.7573],\n",
      "        [2.7880, 2.9456, 2.9349, 2.9031, 2.7323],\n",
      "        [2.4961, 2.6669, 2.5955, 2.6531, 2.6377],\n",
      "        [2.7766, 2.8943, 2.8970, 2.8499, 2.6966],\n",
      "        [2.6694, 2.9043, 2.7287, 2.6310, 2.8135],\n",
      "        [2.6305, 2.7814, 2.5999, 2.7129, 2.7305],\n",
      "        [2.7229, 2.8302, 2.8193, 2.7780, 2.8242],\n",
      "        [2.6009, 2.5857, 2.7471, 2.7407, 2.7802],\n",
      "        [2.5095, 2.5600, 2.6381, 2.6673, 2.6055],\n",
      "        [2.6665, 2.8907, 2.8349, 2.8651, 2.7726],\n",
      "        [2.4512, 2.5982, 2.5365, 2.6732, 2.5487],\n",
      "        [2.5568, 2.6680, 2.5287, 2.7855, 2.5752],\n",
      "        [2.5904, 2.6003, 2.7321, 2.7324, 2.6903],\n",
      "        [2.7055, 2.8408, 2.8115, 2.9465, 2.7810],\n",
      "        [2.5421, 2.5154, 2.6842, 2.6965, 2.7198],\n",
      "        [2.6979, 2.8291, 2.8534, 2.8618, 2.7963],\n",
      "        [2.5969, 2.7291, 2.5879, 2.7609, 2.6804],\n",
      "        [2.5517, 2.6035, 2.7215, 2.7357, 2.7804],\n",
      "        [2.5169, 2.6142, 2.6834, 2.7308, 2.6049],\n",
      "        [2.4713, 2.5904, 2.6157, 2.6327, 2.6035],\n",
      "        [2.7392, 2.8653, 2.7567, 2.8025, 2.8036],\n",
      "        [2.6835, 2.6237, 2.9234, 2.8360, 2.8492],\n",
      "        [2.6076, 2.7437, 2.6012, 2.7825, 2.7043],\n",
      "        [2.4380, 2.6227, 2.4958, 2.6589, 2.5562],\n",
      "        [2.5908, 2.6100, 2.7777, 2.7708, 2.7271],\n",
      "        [2.4671, 2.7374, 2.7163, 2.6659, 2.6722],\n",
      "        [2.5895, 2.6501, 2.7186, 2.7480, 2.7343],\n",
      "        [2.5706, 2.5568, 2.6395, 2.6574, 2.7626],\n",
      "        [2.6716, 2.7583, 2.7416, 2.9272, 2.7502]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.5286, 2.6849, 2.6002, 2.6788, 2.6667],\n",
      "        [2.7409, 2.7805, 2.8043, 2.7862, 2.6204],\n",
      "        [2.6885, 2.5693, 2.8517, 2.8138, 2.7761],\n",
      "        [2.5178, 2.5989, 2.5416, 2.7249, 2.5644],\n",
      "        [2.8574, 2.7628, 2.7483, 2.8228, 2.8318],\n",
      "        [2.6085, 2.7470, 2.5898, 2.7795, 2.7032],\n",
      "        [2.5949, 2.8707, 2.6686, 2.8786, 2.7899],\n",
      "        [2.5138, 2.5855, 2.5414, 2.7228, 2.5984],\n",
      "        [2.6013, 2.6175, 2.6397, 2.8062, 2.6272],\n",
      "        [2.6174, 2.6027, 2.7760, 2.7870, 2.8204],\n",
      "        [2.6594, 2.5175, 2.8325, 2.7847, 2.7368],\n",
      "        [2.5522, 2.7025, 2.6935, 2.5948, 2.6572],\n",
      "        [2.6005, 2.8541, 2.7492, 2.7663, 2.6298],\n",
      "        [2.7732, 2.6019, 2.6596, 2.6990, 2.7500],\n",
      "        [2.5358, 2.6576, 2.6176, 2.7691, 2.6734],\n",
      "        [2.7220, 2.9470, 2.7617, 2.6717, 2.8290],\n",
      "        [2.6810, 2.7105, 2.7205, 2.8713, 2.7684],\n",
      "        [2.7126, 2.8842, 2.7258, 2.9707, 2.8515],\n",
      "        [2.5770, 2.6278, 2.7126, 2.7349, 2.7183],\n",
      "        [2.7472, 2.8373, 2.8584, 2.9754, 2.7815],\n",
      "        [3.1867, 3.3361, 2.9657, 3.0640, 2.9394],\n",
      "        [2.5090, 2.5788, 2.6631, 2.6724, 2.5910],\n",
      "        [2.8613, 2.5988, 2.7757, 3.1443, 3.0996],\n",
      "        [2.5759, 2.6281, 2.5746, 2.6978, 2.7817],\n",
      "        [2.7022, 2.8805, 2.8121, 2.9615, 2.8101],\n",
      "        [2.7883, 2.9449, 2.9326, 2.9005, 2.7238],\n",
      "        [2.6215, 2.7637, 2.5969, 2.8013, 2.7184],\n",
      "        [2.5015, 2.7352, 2.8607, 2.7052, 2.7939],\n",
      "        [3.1296, 3.3201, 2.9441, 3.0563, 2.9174],\n",
      "        [2.4556, 2.6024, 2.5391, 2.6743, 2.5532],\n",
      "        [2.5855, 2.6613, 2.7248, 2.7430, 2.7382],\n",
      "        [2.5041, 2.5196, 2.6133, 2.6629, 2.5820],\n",
      "        [2.7752, 2.9255, 2.8845, 2.9585, 2.9538],\n",
      "        [2.4194, 2.6039, 2.5837, 2.5520, 2.5843],\n",
      "        [2.6145, 2.5604, 2.6912, 2.6282, 2.6242],\n",
      "        [2.8499, 2.7537, 2.8586, 2.9859, 2.8639],\n",
      "        [2.6952, 2.8106, 2.6881, 2.7892, 2.9189],\n",
      "        [2.4730, 2.8643, 2.7484, 2.6903, 2.8689],\n",
      "        [2.8385, 2.6052, 2.7807, 3.1047, 3.0715],\n",
      "        [2.6129, 2.7348, 2.7490, 2.7220, 2.6263],\n",
      "        [2.6763, 2.7629, 2.7445, 2.9284, 2.7551],\n",
      "        [2.4704, 2.6114, 2.6643, 2.6427, 2.6097],\n",
      "        [2.7255, 2.7864, 2.7897, 2.7664, 2.5749],\n",
      "        [2.7754, 2.8142, 2.8065, 2.9068, 2.9460],\n",
      "        [2.5919, 2.6463, 2.5984, 2.7088, 2.7927],\n",
      "        [2.6887, 2.6830, 2.7723, 2.7124, 2.6671],\n",
      "        [2.7351, 2.8780, 2.7034, 2.8153, 2.8637],\n",
      "        [2.6240, 2.6173, 2.7936, 2.8031, 2.8349],\n",
      "        [3.1432, 3.3655, 2.9285, 3.0648, 2.9251],\n",
      "        [3.0447, 3.1432, 2.7790, 2.9405, 2.7994],\n",
      "        [2.6437, 2.8367, 2.7611, 2.7822, 2.6488],\n",
      "        [2.8994, 2.9308, 2.8291, 2.9720, 3.0304],\n",
      "        [2.5835, 2.6447, 2.7148, 2.7291, 2.7134],\n",
      "        [2.5427, 2.6227, 2.6789, 2.7417, 2.6233],\n",
      "        [2.6681, 2.8533, 2.7571, 2.7293, 2.8233],\n",
      "        [2.7115, 2.8811, 2.7204, 2.9616, 2.8407],\n",
      "        [2.4770, 2.6505, 2.6012, 2.6219, 2.6435],\n",
      "        [2.8226, 2.9181, 2.7893, 2.9108, 2.9933],\n",
      "        [2.5423, 2.6954, 2.5978, 2.6871, 2.6710],\n",
      "        [2.5704, 2.5734, 2.7482, 2.6094, 2.7574],\n",
      "        [2.7402, 2.7967, 2.8434, 2.8939, 2.7061],\n",
      "        [2.5650, 2.8359, 2.7968, 2.6402, 2.7934],\n",
      "        [2.7382, 2.9046, 2.8427, 2.8949, 2.8276],\n",
      "        [2.5735, 2.6367, 2.8040, 2.6329, 2.8410]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.9064, 2.8600, 2.9334, 3.0840, 2.9557],\n",
      "        [2.5718, 2.7181, 2.5977, 2.7145, 2.6809],\n",
      "        [2.6028, 2.6018, 2.6238, 2.8115, 2.6190],\n",
      "        [2.6503, 2.6146, 2.9376, 2.7971, 2.8277],\n",
      "        [2.7410, 2.9257, 2.8536, 2.8857, 2.8281],\n",
      "        [2.9455, 2.7232, 2.8450, 3.3115, 3.2178],\n",
      "        [2.8403, 2.9001, 2.8178, 3.0505, 2.9427],\n",
      "        [2.5207, 2.6644, 2.5981, 2.7092, 2.6264],\n",
      "        [2.6470, 2.8406, 2.7676, 2.7840, 2.6518],\n",
      "        [2.6075, 2.7411, 2.7498, 2.7236, 2.6385],\n",
      "        [2.5984, 2.7329, 2.6031, 2.7396, 2.7084],\n",
      "        [2.5753, 2.7166, 2.5971, 2.7194, 2.6885],\n",
      "        [2.5480, 2.7495, 2.6424, 2.8071, 2.6539],\n",
      "        [2.7299, 2.8290, 2.8439, 2.8877, 2.7666],\n",
      "        [2.5549, 2.6270, 2.8465, 2.5751, 2.8640],\n",
      "        [2.7678, 2.6372, 2.6557, 2.6834, 2.7685],\n",
      "        [2.6044, 2.6118, 2.7607, 2.7432, 2.7191],\n",
      "        [2.7334, 2.7549, 2.8032, 2.7710, 2.6519],\n",
      "        [2.4345, 2.6251, 2.5933, 2.5654, 2.5978],\n",
      "        [2.7486, 2.9232, 2.8534, 2.8839, 2.8193],\n",
      "        [2.7172, 2.8891, 2.7287, 2.9718, 2.8561],\n",
      "        [2.7311, 2.7125, 2.7609, 2.6773, 2.6101],\n",
      "        [2.6086, 2.5716, 2.6973, 2.6485, 2.6386],\n",
      "        [2.5798, 2.6405, 2.8053, 2.6325, 2.8570],\n",
      "        [2.6216, 2.8802, 2.6792, 2.8152, 2.7711],\n",
      "        [2.4731, 2.6435, 2.6039, 2.6093, 2.6190],\n",
      "        [2.5362, 2.7317, 2.6492, 2.7418, 2.6251],\n",
      "        [2.9056, 2.8405, 2.8581, 2.9277, 2.8715],\n",
      "        [2.5651, 2.7179, 2.5995, 2.7229, 2.6734],\n",
      "        [2.9131, 3.0222, 2.9354, 3.1769, 3.0452],\n",
      "        [2.5402, 2.6623, 2.6202, 2.7702, 2.6777],\n",
      "        [2.6162, 2.6245, 2.7452, 2.7520, 2.7828],\n",
      "        [2.8102, 2.8704, 2.8765, 2.8947, 2.9637],\n",
      "        [2.5471, 2.6274, 2.6816, 2.7428, 2.6277],\n",
      "        [2.6352, 2.6741, 2.7464, 2.6560, 2.5687],\n",
      "        [2.4149, 2.5957, 2.5797, 2.5488, 2.5831],\n",
      "        [2.9415, 2.7643, 2.8936, 3.3770, 3.2131],\n",
      "        [2.6635, 2.8608, 2.7587, 2.7442, 2.8082],\n",
      "        [2.6059, 2.9644, 2.7682, 2.8909, 2.9136],\n",
      "        [2.8789, 2.9881, 2.8756, 3.1171, 2.9700],\n",
      "        [2.7485, 2.7210, 2.7667, 2.6967, 2.6262],\n",
      "        [2.8658, 2.6037, 2.7784, 3.1454, 3.1040],\n",
      "        [2.6987, 2.7748, 2.8447, 2.7844, 2.6963],\n",
      "        [2.6268, 2.6689, 2.7277, 2.7633, 2.7471],\n",
      "        [2.6346, 2.7772, 2.6071, 2.8140, 2.7280],\n",
      "        [2.7712, 2.7483, 2.8118, 2.9051, 2.7974],\n",
      "        [2.4628, 2.6632, 2.6857, 2.6490, 2.6325],\n",
      "        [2.8021, 2.6662, 2.7464, 3.1298, 2.9571],\n",
      "        [2.6033, 2.7432, 2.6029, 2.7709, 2.7026],\n",
      "        [2.5197, 2.7737, 2.6960, 2.7233, 2.8605],\n",
      "        [2.6274, 2.8226, 2.7221, 2.7465, 2.7927],\n",
      "        [2.5780, 2.7259, 2.5997, 2.7390, 2.6812],\n",
      "        [2.4568, 2.5598, 2.6040, 2.6000, 2.5884],\n",
      "        [2.7804, 2.8967, 2.8939, 2.8479, 2.7032],\n",
      "        [2.5218, 2.8798, 2.7206, 2.7827, 2.8596],\n",
      "        [2.6739, 2.7334, 2.7528, 2.7926, 2.8166],\n",
      "        [2.5174, 2.6218, 2.6949, 2.7143, 2.6067],\n",
      "        [2.6844, 2.6773, 2.8650, 2.8798, 2.7312],\n",
      "        [2.7002, 2.9141, 2.8487, 2.8975, 2.9509],\n",
      "        [2.5976, 2.7371, 2.7325, 2.6795, 2.6277],\n",
      "        [2.6210, 2.6339, 2.7366, 2.7626, 2.7769],\n",
      "        [2.5662, 2.8830, 2.7849, 2.8019, 2.8894],\n",
      "        [2.5812, 2.9219, 2.7466, 2.8606, 2.8903],\n",
      "        [2.5777, 2.5758, 2.7510, 2.6122, 2.7623]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.4544, 2.5580, 2.6426, 2.6244, 2.5469],\n",
      "        [2.8280, 2.8345, 2.8516, 2.9911, 2.8875],\n",
      "        [2.5968, 2.6315, 2.7209, 2.7253, 2.7188],\n",
      "        [2.4719, 2.7713, 2.5659, 2.7212, 2.5962],\n",
      "        [2.8573, 2.5987, 2.7729, 3.1426, 3.0950],\n",
      "        [2.5589, 2.8559, 2.7277, 2.7277, 2.6346],\n",
      "        [2.6820, 2.7416, 2.7490, 2.7807, 2.7490],\n",
      "        [2.7370, 2.7824, 2.8689, 2.8159, 2.6755],\n",
      "        [2.5566, 2.6316, 2.8233, 2.5951, 2.8445],\n",
      "        [2.9550, 2.9071, 2.9293, 3.0184, 2.9878],\n",
      "        [2.4288, 2.7032, 2.5123, 2.6766, 2.5507],\n",
      "        [2.5300, 2.6913, 2.6035, 2.6709, 2.6552],\n",
      "        [2.6039, 2.6237, 2.7858, 2.7740, 2.7404],\n",
      "        [2.5964, 2.5908, 2.7056, 2.6662, 2.6603],\n",
      "        [2.7377, 2.8104, 2.8105, 2.8290, 2.8897],\n",
      "        [2.5614, 2.5541, 2.6454, 2.7016, 2.6058],\n",
      "        [2.8144, 2.8748, 2.8792, 2.8957, 2.9679],\n",
      "        [2.6699, 2.8882, 2.7058, 2.6113, 2.7400],\n",
      "        [2.6641, 2.6217, 2.7481, 2.7673, 2.7278],\n",
      "        [2.5891, 2.7168, 2.6386, 2.7331, 2.7183],\n",
      "        [2.4968, 2.6643, 2.7440, 2.7051, 2.6102],\n",
      "        [2.7339, 2.9350, 2.9281, 2.9125, 2.7551],\n",
      "        [2.6537, 2.8056, 2.6648, 2.8110, 2.7801],\n",
      "        [2.5936, 2.6478, 2.7180, 2.7374, 2.7214],\n",
      "        [2.7219, 2.7282, 2.7060, 2.9471, 2.8461],\n",
      "        [2.9077, 2.8616, 2.9353, 3.0839, 2.9583],\n",
      "        [2.4733, 2.6577, 2.6032, 2.6069, 2.6278],\n",
      "        [2.6105, 2.6491, 2.7624, 2.7516, 2.7359],\n",
      "        [2.8367, 2.8355, 2.8616, 2.9600, 2.7869],\n",
      "        [2.7054, 2.7873, 2.7275, 2.7867, 2.7540],\n",
      "        [2.5110, 2.5811, 2.6498, 2.6637, 2.6167],\n",
      "        [2.5216, 2.6259, 2.6975, 2.7153, 2.6107],\n",
      "        [2.6641, 2.8976, 2.8233, 2.8389, 2.7754],\n",
      "        [2.5546, 2.5288, 2.6919, 2.6996, 2.7328],\n",
      "        [3.1697, 3.3499, 2.9362, 3.0432, 2.9645],\n",
      "        [2.4876, 2.6432, 2.7043, 2.6736, 2.6127],\n",
      "        [2.4438, 2.6268, 2.5953, 2.5737, 2.6084],\n",
      "        [2.7290, 2.8897, 2.7424, 2.8236, 2.8277],\n",
      "        [2.5477, 2.7072, 2.7002, 2.8137, 2.6662],\n",
      "        [2.4672, 2.6584, 2.6814, 2.6402, 2.6235],\n",
      "        [2.6935, 2.8133, 2.6950, 2.8281, 2.8693],\n",
      "        [2.8064, 2.6705, 2.7491, 3.1308, 2.9612],\n",
      "        [2.6091, 2.7415, 2.7418, 2.6995, 2.6393],\n",
      "        [2.5786, 2.7048, 2.6479, 2.6715, 2.6680],\n",
      "        [2.7371, 2.9985, 2.9111, 2.9273, 2.9734],\n",
      "        [2.4188, 2.5996, 2.5821, 2.5497, 2.5869],\n",
      "        [2.5583, 2.7077, 2.6423, 2.7103, 2.7081],\n",
      "        [2.7557, 2.8466, 2.8639, 2.9775, 2.7905],\n",
      "        [2.4485, 2.5329, 2.6213, 2.5887, 2.5370],\n",
      "        [2.4007, 2.6093, 2.6197, 2.6135, 2.6339],\n",
      "        [2.7263, 2.7881, 2.6374, 2.8756, 2.8784],\n",
      "        [2.6099, 2.5852, 2.7238, 2.7378, 2.8009],\n",
      "        [2.6438, 2.7445, 2.7443, 2.7234, 2.7532],\n",
      "        [2.6162, 2.7511, 2.6015, 2.7792, 2.7091],\n",
      "        [2.6899, 2.6855, 2.7485, 2.6741, 2.5828],\n",
      "        [2.6564, 2.6141, 2.9387, 2.7952, 2.8272],\n",
      "        [2.7262, 2.7859, 2.7868, 2.7638, 2.5766],\n",
      "        [2.4690, 2.7250, 2.7085, 2.6523, 2.6551],\n",
      "        [2.6720, 2.7500, 2.8089, 2.8058, 2.7807],\n",
      "        [2.6087, 2.6337, 2.7385, 2.7348, 2.7229],\n",
      "        [2.7439, 2.8593, 2.8498, 2.9778, 2.7935],\n",
      "        [2.9505, 2.9232, 2.8699, 2.9772, 2.9341],\n",
      "        [2.5924, 2.6684, 2.8128, 2.8641, 2.9247],\n",
      "        [2.6073, 2.7472, 2.6054, 2.7718, 2.7066]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.7303, 2.7927, 2.6399, 2.8765, 2.8830],\n",
      "        [2.7112, 2.6975, 2.7740, 2.8000, 2.7333],\n",
      "        [2.6603, 2.6300, 2.7520, 2.7660, 2.7488],\n",
      "        [2.4542, 2.6419, 2.6006, 2.5860, 2.6164],\n",
      "        [2.7157, 2.9052, 2.8589, 2.8967, 2.8169],\n",
      "        [2.5271, 2.5837, 2.6662, 2.6802, 2.6030],\n",
      "        [2.5558, 2.6787, 2.6270, 2.7610, 2.6922],\n",
      "        [2.7633, 2.9195, 2.8601, 2.8786, 2.8208],\n",
      "        [2.6202, 2.7555, 2.6040, 2.7801, 2.7138],\n",
      "        [2.4695, 2.7125, 2.7869, 2.6633, 2.7459],\n",
      "        [2.5139, 2.6313, 2.7090, 2.7377, 2.7232],\n",
      "        [2.7405, 2.7954, 2.6335, 2.8872, 2.9012],\n",
      "        [2.7131, 2.8639, 2.8384, 2.8730, 2.8585],\n",
      "        [2.6737, 2.8928, 2.7082, 2.6122, 2.7447],\n",
      "        [2.6014, 2.7477, 2.6098, 2.7552, 2.7103],\n",
      "        [2.7226, 2.6983, 2.7563, 2.7068, 2.6096],\n",
      "        [2.6961, 2.8948, 2.8400, 2.8751, 2.9223],\n",
      "        [2.4691, 2.6898, 2.6962, 2.6545, 2.6468],\n",
      "        [2.6026, 2.7273, 2.6408, 2.8143, 2.7353],\n",
      "        [2.6276, 2.6660, 2.7717, 2.7725, 2.7547],\n",
      "        [2.4978, 2.8344, 2.7031, 2.5497, 2.8110],\n",
      "        [2.4939, 2.6629, 2.6036, 2.6253, 2.6340],\n",
      "        [2.5495, 2.7061, 2.6125, 2.6766, 2.6895],\n",
      "        [2.6110, 2.6581, 2.7560, 2.7444, 2.7399],\n",
      "        [2.4671, 2.6780, 2.6924, 2.6444, 2.6312],\n",
      "        [2.5718, 2.5943, 2.7016, 2.6744, 2.6738],\n",
      "        [2.8044, 2.9554, 2.9472, 2.8971, 2.7506],\n",
      "        [2.6928, 2.6741, 2.7732, 2.6992, 2.7016],\n",
      "        [2.3867, 2.5812, 2.6298, 2.5895, 2.6335],\n",
      "        [2.6109, 2.5969, 2.7308, 2.7360, 2.8071],\n",
      "        [2.7482, 2.8919, 2.7116, 2.8185, 2.8772],\n",
      "        [2.5831, 2.5870, 2.7557, 2.6125, 2.7708],\n",
      "        [2.6107, 2.5948, 2.7195, 2.7354, 2.8086],\n",
      "        [2.8835, 2.8104, 2.7941, 2.8484, 2.8903],\n",
      "        [2.6209, 2.7601, 2.5975, 2.7825, 2.7163],\n",
      "        [2.6130, 2.7461, 2.7442, 2.7004, 2.6442],\n",
      "        [2.6792, 2.9373, 2.8647, 2.8754, 3.0176],\n",
      "        [2.4355, 2.7088, 2.7873, 2.6378, 2.7184],\n",
      "        [2.5944, 2.6884, 2.7066, 2.7213, 2.8448],\n",
      "        [2.6306, 2.7700, 2.6034, 2.7957, 2.7226],\n",
      "        [2.6554, 2.8495, 2.7728, 2.7860, 2.6608],\n",
      "        [2.5996, 2.8227, 2.6778, 2.6822, 2.7668],\n",
      "        [2.7025, 2.5539, 2.8720, 2.8059, 2.7632],\n",
      "        [2.6959, 2.7867, 2.8078, 2.7940, 2.8076],\n",
      "        [2.5187, 2.7667, 2.7018, 2.7149, 2.8550],\n",
      "        [2.6691, 2.9053, 2.7532, 2.9311, 2.8345],\n",
      "        [2.9043, 2.7579, 2.8850, 3.3527, 3.2295],\n",
      "        [2.4934, 2.6823, 2.7275, 2.6851, 2.6441],\n",
      "        [2.6426, 2.6648, 2.8109, 2.8035, 2.7889],\n",
      "        [2.6259, 2.6159, 2.7762, 2.7816, 2.8342],\n",
      "        [2.4733, 2.6616, 2.6086, 2.6125, 2.6346],\n",
      "        [2.7266, 2.8657, 2.7380, 2.9029, 2.8299],\n",
      "        [2.7453, 2.7774, 2.9646, 2.7607, 2.7284],\n",
      "        [2.5773, 2.8497, 2.8046, 2.6433, 2.8073],\n",
      "        [2.5938, 2.6355, 2.7109, 2.7218, 2.7187],\n",
      "        [2.7521, 2.8871, 2.8604, 2.8188, 2.6912],\n",
      "        [2.7083, 2.8244, 2.6962, 2.7923, 2.9323],\n",
      "        [3.1030, 3.2385, 2.8921, 2.9694, 2.8663],\n",
      "        [2.8009, 2.6960, 2.7625, 2.7727, 2.7734],\n",
      "        [2.5653, 2.5585, 2.6477, 2.7025, 2.6105],\n",
      "        [2.7240, 2.6942, 2.8053, 2.8391, 2.7658],\n",
      "        [2.5256, 2.6303, 2.6998, 2.7162, 2.6153],\n",
      "        [2.6375, 2.8109, 2.6615, 2.7013, 2.7697],\n",
      "        [2.5629, 2.7151, 2.6062, 2.7031, 2.6874]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.5028, 2.6959, 2.7788, 2.7100, 2.7874],\n",
      "        [2.4954, 2.6524, 2.7089, 2.6754, 2.6223],\n",
      "        [2.6094, 2.7590, 2.6835, 2.8175, 2.7775],\n",
      "        [2.5331, 2.6115, 2.5531, 2.7242, 2.5915],\n",
      "        [2.7161, 2.8256, 2.7013, 2.7929, 2.9335],\n",
      "        [2.5295, 2.6351, 2.7020, 2.7171, 2.6204],\n",
      "        [2.8016, 2.9635, 2.8596, 2.7768, 2.8996],\n",
      "        [2.8109, 2.7714, 2.7829, 2.7391, 2.6764],\n",
      "        [2.6398, 2.7817, 2.6197, 2.8080, 2.7381],\n",
      "        [2.5983, 2.6443, 2.5862, 2.7023, 2.7997],\n",
      "        [2.7000, 2.7858, 2.7056, 2.8051, 2.9490],\n",
      "        [2.8682, 3.0139, 2.7360, 2.8385, 2.8512],\n",
      "        [2.5952, 2.7010, 2.6742, 2.7967, 2.7447],\n",
      "        [2.6124, 2.7493, 2.6067, 2.7575, 2.7192],\n",
      "        [2.6771, 2.5548, 2.8508, 2.8201, 2.8292],\n",
      "        [2.4617, 2.7108, 2.7859, 2.6625, 2.7444],\n",
      "        [2.9086, 2.7630, 2.8875, 3.3536, 3.2348],\n",
      "        [2.8825, 2.9388, 2.8182, 2.9465, 3.0202],\n",
      "        [2.7595, 2.8161, 2.8535, 2.8921, 2.7252],\n",
      "        [2.6060, 2.6662, 2.7293, 2.7354, 2.7404],\n",
      "        [2.9582, 2.7372, 2.8526, 3.3142, 3.2319],\n",
      "        [2.6366, 2.9085, 2.6558, 2.7823, 2.7511],\n",
      "        [2.7298, 2.7377, 2.7107, 2.9490, 2.8561],\n",
      "        [2.8210, 2.9311, 2.7844, 2.8988, 2.9889],\n",
      "        [2.6344, 2.7578, 2.5883, 2.7926, 2.6323],\n",
      "        [2.4893, 2.8829, 2.7589, 2.6943, 2.8876],\n",
      "        [2.5493, 2.9672, 2.8336, 2.7581, 2.7470],\n",
      "        [2.5994, 2.9331, 2.8163, 2.7758, 2.7158],\n",
      "        [2.6194, 2.7597, 2.6136, 2.7813, 2.7258],\n",
      "        [2.7279, 2.6992, 2.8077, 2.8400, 2.7712],\n",
      "        [2.6010, 2.6420, 2.7157, 2.7242, 2.7259],\n",
      "        [2.9561, 2.8615, 2.9361, 3.1122, 3.0100],\n",
      "        [2.7417, 3.0059, 2.9096, 2.9219, 2.9853],\n",
      "        [2.7470, 2.8800, 2.7461, 2.9015, 2.8329],\n",
      "        [2.4987, 2.6512, 2.6820, 2.6516, 2.6546],\n",
      "        [2.6368, 2.7592, 2.7425, 2.7264, 2.7524],\n",
      "        [2.7320, 2.9875, 2.7831, 2.8806, 2.8529],\n",
      "        [2.7382, 2.8458, 2.8460, 2.8014, 2.8345],\n",
      "        [2.6335, 2.7091, 2.7453, 2.7108, 2.9289],\n",
      "        [2.6207, 2.5851, 2.7045, 2.6513, 2.6524],\n",
      "        [2.9368, 2.7508, 2.8797, 3.3700, 3.2250],\n",
      "        [2.5685, 2.5317, 2.6007, 2.6731, 2.5935],\n",
      "        [2.4461, 2.6379, 2.6001, 2.5681, 2.6110],\n",
      "        [3.1726, 3.3504, 2.9382, 3.0375, 2.9674],\n",
      "        [2.6699, 2.8424, 2.7145, 2.8424, 2.7950],\n",
      "        [2.5347, 2.6180, 2.6957, 2.7150, 2.7177],\n",
      "        [2.9102, 2.8678, 2.9334, 3.0971, 2.9744],\n",
      "        [2.7313, 2.8934, 2.7625, 2.8665, 2.8179],\n",
      "        [2.5154, 2.6891, 2.6087, 2.6473, 2.6532],\n",
      "        [2.4797, 2.7525, 2.7293, 2.6569, 2.6715],\n",
      "        [2.8031, 2.8950, 2.9224, 2.8689, 2.7665],\n",
      "        [2.6591, 2.6845, 2.8283, 2.7998, 2.7991],\n",
      "        [2.5194, 2.6902, 2.6122, 2.6477, 2.6592],\n",
      "        [2.5735, 2.7254, 2.6015, 2.7214, 2.6815],\n",
      "        [2.7395, 2.8809, 2.7314, 2.9207, 2.9857],\n",
      "        [2.7048, 2.5874, 2.8617, 2.8177, 2.7947],\n",
      "        [2.5612, 2.8643, 2.7236, 2.7168, 2.6420],\n",
      "        [2.7731, 2.7937, 2.8484, 2.9046, 2.6809],\n",
      "        [2.4461, 2.6379, 2.6001, 2.5681, 2.6110],\n",
      "        [2.7069, 2.7921, 2.8154, 2.8119, 2.8862],\n",
      "        [2.5845, 2.8620, 2.8077, 2.6510, 2.8201],\n",
      "        [2.6378, 2.7816, 2.6070, 2.8051, 2.7368],\n",
      "        [2.8528, 2.8574, 2.7450, 2.9043, 2.9506],\n",
      "        [2.5394, 2.7370, 2.6360, 2.7856, 2.6606]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.7053, 2.8271, 2.7022, 2.8308, 2.8839],\n",
      "        [2.7158, 2.8863, 2.7165, 2.9442, 2.8370],\n",
      "        [2.7244, 2.7054, 2.7951, 2.8189, 2.7603],\n",
      "        [2.8761, 2.6172, 2.7983, 3.1346, 3.1002],\n",
      "        [2.6585, 2.6995, 2.7387, 2.8006, 2.7653],\n",
      "        [2.5584, 2.6510, 2.7025, 2.7332, 2.6477],\n",
      "        [2.7286, 2.8155, 2.6803, 2.8665, 2.8521],\n",
      "        [2.6075, 2.7363, 2.6928, 2.7127, 2.7370],\n",
      "        [2.6751, 2.8511, 2.7173, 2.8509, 2.7918],\n",
      "        [2.8325, 2.8562, 2.8670, 2.9928, 2.8956],\n",
      "        [2.5753, 2.8671, 2.7336, 2.7270, 2.6398],\n",
      "        [2.6007, 2.7514, 2.6091, 2.7366, 2.7135],\n",
      "        [2.5842, 2.5619, 2.7187, 2.7286, 2.7616],\n",
      "        [2.5266, 2.5651, 2.6394, 2.6769, 2.6173],\n",
      "        [2.5204, 2.6932, 2.6101, 2.6588, 2.6646],\n",
      "        [2.8072, 2.8997, 2.9248, 2.8699, 2.7713],\n",
      "        [2.7887, 2.9061, 2.7379, 2.8484, 2.9343],\n",
      "        [2.5140, 2.7308, 2.5970, 2.7181, 2.6570],\n",
      "        [2.8849, 2.9739, 2.9028, 2.9473, 3.0019],\n",
      "        [2.8248, 2.6335, 2.6488, 2.6850, 2.8014],\n",
      "        [2.5402, 2.5612, 2.6382, 2.6719, 2.6291],\n",
      "        [2.8265, 2.8891, 2.8865, 2.8985, 2.9831],\n",
      "        [2.6337, 2.8994, 2.7036, 2.5924, 2.8215],\n",
      "        [2.7810, 2.7967, 2.9145, 2.8542, 2.6797],\n",
      "        [2.7134, 2.8255, 2.8999, 2.8809, 2.9005],\n",
      "        [2.7762, 2.9029, 2.8813, 2.8341, 2.7100],\n",
      "        [2.7594, 2.8851, 2.7803, 2.7712, 2.8173],\n",
      "        [2.8103, 3.0387, 2.8351, 3.0061, 3.0238],\n",
      "        [2.7175, 2.8751, 2.8441, 2.8795, 2.8682],\n",
      "        [2.5765, 2.5473, 2.7073, 2.7145, 2.7441],\n",
      "        [2.7260, 2.8959, 2.6966, 2.8017, 2.8586],\n",
      "        [2.5949, 2.9531, 2.8569, 2.7979, 2.7743],\n",
      "        [2.4351, 2.6230, 2.5968, 2.5505, 2.5982],\n",
      "        [2.9602, 2.8661, 2.9384, 3.1131, 3.0149],\n",
      "        [2.5574, 2.8785, 2.7811, 2.7911, 2.8540],\n",
      "        [2.8158, 2.9913, 2.8675, 2.7784, 2.9251],\n",
      "        [2.5798, 2.6035, 2.7061, 2.6760, 2.6837],\n",
      "        [2.9632, 2.9036, 2.8760, 2.9669, 2.9474],\n",
      "        [2.5714, 2.8698, 2.7349, 2.7305, 2.6493],\n",
      "        [2.4858, 2.6496, 2.6830, 2.6464, 2.6345],\n",
      "        [2.7102, 2.5629, 2.8765, 2.8076, 2.7732],\n",
      "        [2.5132, 2.6331, 2.7098, 2.7484, 2.7287],\n",
      "        [2.7986, 2.9398, 2.9021, 2.9692, 2.9914],\n",
      "        [2.6771, 2.9146, 2.7578, 2.9329, 2.8447],\n",
      "        [2.7322, 2.9057, 2.7381, 2.9747, 2.8727],\n",
      "        [2.5301, 2.8626, 2.7282, 2.5749, 2.8432],\n",
      "        [2.8664, 2.8798, 2.8835, 3.0199, 2.8479],\n",
      "        [2.5453, 2.6496, 2.7098, 2.7205, 2.6377],\n",
      "        [2.6834, 2.8580, 2.7892, 2.7914, 2.6827],\n",
      "        [2.5763, 2.6601, 2.7010, 2.7527, 2.6655],\n",
      "        [2.4740, 2.6886, 2.6964, 2.6477, 2.6375],\n",
      "        [2.7149, 2.8897, 2.7192, 2.9475, 2.8412],\n",
      "        [2.9455, 2.8926, 2.8725, 2.9564, 2.9189],\n",
      "        [2.6233, 2.8174, 2.7014, 2.7443, 2.8111],\n",
      "        [2.6740, 2.8468, 2.7168, 2.8432, 2.7998],\n",
      "        [2.8177, 2.7836, 2.7969, 2.7547, 2.7035],\n",
      "        [2.5384, 2.8055, 2.6079, 2.7298, 2.6257],\n",
      "        [2.6206, 2.9634, 2.7530, 2.8887, 2.8959],\n",
      "        [2.7358, 2.8539, 2.7831, 2.8192, 2.8937],\n",
      "        [2.5214, 2.7580, 2.8730, 2.7099, 2.8169],\n",
      "        [2.5691, 2.6140, 2.7091, 2.6825, 2.6956],\n",
      "        [2.5330, 2.5837, 2.6525, 2.6724, 2.6316],\n",
      "        [2.6650, 2.7173, 2.7371, 2.8283, 2.7659],\n",
      "        [2.5713, 2.6456, 2.8560, 2.5788, 2.8836]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.7184, 2.9693, 2.9013, 2.8820, 2.9493],\n",
      "        [2.7494, 2.8706, 2.8483, 2.9665, 2.8121],\n",
      "        [2.9321, 3.0476, 2.9413, 3.1951, 3.0783],\n",
      "        [2.5576, 2.6930, 2.6353, 2.7667, 2.7044],\n",
      "        [2.7664, 2.9068, 2.7277, 2.8226, 2.9041],\n",
      "        [2.5875, 2.5659, 2.7208, 2.7293, 2.7659],\n",
      "        [2.8796, 2.8943, 2.9002, 3.0208, 2.9621],\n",
      "        [3.0242, 3.1562, 2.7963, 2.9409, 2.8593],\n",
      "        [2.5340, 2.7237, 2.8946, 2.7020, 2.8795],\n",
      "        [2.6669, 2.7076, 2.7628, 2.6725, 2.6019],\n",
      "        [2.6403, 2.7764, 2.6054, 2.7906, 2.7265],\n",
      "        [2.7199, 2.8594, 2.8204, 2.8209, 2.7047],\n",
      "        [2.6264, 2.7694, 2.6122, 2.7751, 2.7293],\n",
      "        [2.6130, 2.8364, 2.7498, 2.6858, 2.8135],\n",
      "        [2.4822, 2.6758, 2.6900, 2.6434, 2.6418],\n",
      "        [2.6641, 2.8642, 2.7395, 2.7441, 2.8246],\n",
      "        [2.8047, 2.9519, 2.9056, 2.9726, 2.9896],\n",
      "        [2.5345, 2.6668, 2.7297, 2.7125, 2.6344],\n",
      "        [2.7796, 2.9070, 2.8835, 2.8348, 2.7146],\n",
      "        [2.6781, 2.6367, 2.7515, 2.7736, 2.7211],\n",
      "        [3.0573, 3.2289, 2.8411, 2.9254, 2.8628],\n",
      "        [2.5934, 2.7254, 2.6391, 2.7280, 2.7234],\n",
      "        [2.4937, 2.6375, 2.6780, 2.6480, 2.6364],\n",
      "        [2.6161, 2.6725, 2.6128, 2.7143, 2.8196],\n",
      "        [2.9350, 3.0275, 2.9286, 3.1535, 3.0197],\n",
      "        [2.7794, 2.8957, 2.7980, 2.8517, 2.9370],\n",
      "        [2.7820, 2.7522, 2.7745, 2.6978, 2.6702],\n",
      "        [2.6060, 2.6889, 2.8235, 2.8704, 2.9431],\n",
      "        [2.4798, 2.6769, 2.6126, 2.6614, 2.6384],\n",
      "        [2.8519, 2.7187, 2.6867, 2.7537, 2.8278],\n",
      "        [2.6208, 2.6725, 2.6089, 2.7221, 2.8308],\n",
      "        [2.6142, 2.7568, 2.6174, 2.7579, 2.7280],\n",
      "        [2.6185, 2.6316, 2.7489, 2.7389, 2.7221],\n",
      "        [2.6193, 2.7349, 2.6453, 2.8066, 2.7403],\n",
      "        [2.4422, 2.6294, 2.5971, 2.5572, 2.6100],\n",
      "        [2.7466, 2.8762, 2.7475, 2.9000, 2.8493],\n",
      "        [2.6926, 2.7560, 2.7643, 2.7970, 2.8416],\n",
      "        [2.7203, 2.8051, 2.7365, 2.7902, 2.7730],\n",
      "        [2.5027, 2.6607, 2.7130, 2.6769, 2.6310],\n",
      "        [2.6681, 2.8872, 2.7644, 2.8363, 2.9364],\n",
      "        [2.7097, 2.9987, 2.8083, 2.8703, 2.8757],\n",
      "        [2.5168, 2.6371, 2.7119, 2.7492, 2.7331],\n",
      "        [2.6496, 2.7905, 2.6263, 2.8081, 2.7515],\n",
      "        [2.8606, 2.6240, 2.8022, 3.1101, 3.0889],\n",
      "        [2.8871, 2.9533, 2.8290, 2.9544, 3.0271],\n",
      "        [2.5238, 2.6971, 2.6121, 2.6595, 2.6688],\n",
      "        [2.7373, 2.9116, 2.7410, 2.9762, 2.8802],\n",
      "        [2.4892, 2.6535, 2.6850, 2.6471, 2.6387],\n",
      "        [2.5871, 2.8729, 2.8124, 2.6677, 2.8064],\n",
      "        [2.5259, 2.5938, 2.6586, 2.6651, 2.6335],\n",
      "        [2.5163, 2.6038, 2.6653, 2.6581, 2.6350],\n",
      "        [2.6076, 2.6780, 2.7308, 2.7475, 2.7576],\n",
      "        [2.3842, 2.5867, 2.6371, 2.5741, 2.6503],\n",
      "        [2.5907, 2.7393, 2.6091, 2.7187, 2.7034],\n",
      "        [2.6648, 2.9231, 2.7965, 2.8512, 2.9478],\n",
      "        [2.6186, 2.6575, 2.6714, 2.7925, 2.6749],\n",
      "        [2.5609, 2.8265, 2.7244, 2.7479, 2.8899],\n",
      "        [2.9004, 2.8818, 2.8652, 3.0430, 2.9778],\n",
      "        [2.6105, 2.6526, 2.7210, 2.7351, 2.7372],\n",
      "        [2.6186, 2.6575, 2.6714, 2.7925, 2.6749],\n",
      "        [2.8591, 2.7878, 2.8681, 2.9925, 2.8849],\n",
      "        [2.5659, 2.5855, 2.6663, 2.6892, 2.6261],\n",
      "        [2.7596, 2.8021, 2.8948, 2.8340, 2.7326],\n",
      "        [2.6154, 2.6588, 2.7303, 2.7284, 2.7394]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.9661, 2.7922, 2.9083, 3.3820, 3.2406],\n",
      "        [2.8250, 2.9915, 2.9845, 2.9397, 2.7990],\n",
      "        [2.7829, 2.9114, 2.8855, 2.8356, 2.7188],\n",
      "        [2.6037, 2.6600, 2.6851, 2.7775, 2.6656],\n",
      "        [2.8973, 2.8406, 2.9040, 3.0383, 2.9417],\n",
      "        [2.7001, 2.7640, 2.7600, 2.7848, 2.7727],\n",
      "        [2.7963, 2.9291, 2.9433, 2.8589, 2.6987],\n",
      "        [3.0833, 3.2991, 2.8494, 2.9569, 2.9148],\n",
      "        [2.8663, 2.8671, 2.8890, 2.9888, 2.8083],\n",
      "        [2.6255, 2.7500, 2.6557, 2.7459, 2.7552],\n",
      "        [2.6887, 2.9245, 2.8359, 2.8448, 2.8085],\n",
      "        [2.7112, 2.7988, 2.7123, 2.8074, 2.9621],\n",
      "        [2.6680, 2.9287, 2.7974, 2.8494, 2.9519],\n",
      "        [2.6157, 2.7648, 2.6184, 2.7582, 2.7283],\n",
      "        [2.8432, 2.7838, 2.7946, 2.8389, 2.8718],\n",
      "        [2.6547, 2.8040, 2.6011, 2.7113, 2.7539],\n",
      "        [2.7002, 2.7792, 2.7526, 2.9183, 2.7826],\n",
      "        [2.5488, 2.6491, 2.7021, 2.7381, 2.6404],\n",
      "        [2.6783, 2.7421, 2.7441, 2.8553, 2.7760],\n",
      "        [2.8654, 2.7488, 2.7673, 2.8062, 2.8556],\n",
      "        [2.6600, 2.7194, 2.7768, 2.6753, 2.5994],\n",
      "        [2.7282, 2.6119, 2.8913, 2.8246, 2.8142],\n",
      "        [2.7112, 2.7650, 2.8650, 2.8641, 2.7841],\n",
      "        [2.6821, 2.8595, 2.7216, 2.8524, 2.8001],\n",
      "        [2.7424, 2.8624, 2.7873, 2.8206, 2.9020],\n",
      "        [2.8226, 2.9998, 2.8717, 2.7799, 2.9336],\n",
      "        [2.8719, 2.7510, 2.7692, 2.8093, 2.8491],\n",
      "        [2.6311, 2.6149, 2.7510, 2.7441, 2.8311],\n",
      "        [3.1515, 3.3645, 2.9055, 3.0236, 2.9759],\n",
      "        [2.6209, 2.7445, 2.8921, 2.7890, 2.8916],\n",
      "        [2.8137, 2.9231, 2.7635, 2.8637, 2.9782],\n",
      "        [2.4911, 2.7649, 2.7289, 2.6709, 2.6976],\n",
      "        [2.6092, 2.6191, 2.7598, 2.6466, 2.7849],\n",
      "        [2.6339, 2.8506, 2.7220, 2.8935, 2.7613],\n",
      "        [2.5207, 2.7389, 2.6008, 2.7194, 2.6648],\n",
      "        [2.5744, 2.7338, 2.6134, 2.7057, 2.6957],\n",
      "        [2.9054, 2.9668, 2.8484, 2.9654, 3.0427],\n",
      "        [2.5870, 2.6527, 2.6855, 2.7672, 2.6694],\n",
      "        [2.4896, 2.6668, 2.6106, 2.6085, 2.6423],\n",
      "        [2.6108, 2.8048, 2.6898, 2.7632, 2.8117],\n",
      "        [2.5791, 2.7327, 2.6188, 2.6956, 2.7130],\n",
      "        [2.8672, 3.0263, 2.8085, 2.7833, 2.8152],\n",
      "        [2.4686, 2.6561, 2.5134, 2.6657, 2.5894],\n",
      "        [2.6615, 2.7666, 2.7552, 2.7275, 2.7771],\n",
      "        [2.8936, 3.0591, 2.8538, 2.8123, 2.9058],\n",
      "        [2.7971, 2.6321, 2.6752, 2.7047, 2.7832],\n",
      "        [2.6472, 2.8364, 2.7066, 2.8307, 2.7648],\n",
      "        [2.5961, 2.8662, 2.8006, 2.6583, 2.8289],\n",
      "        [2.5771, 2.7321, 2.6146, 2.7060, 2.7052],\n",
      "        [2.6117, 2.6905, 2.8239, 2.8681, 2.9473],\n",
      "        [2.6000, 2.5917, 2.6580, 2.6647, 2.7999],\n",
      "        [2.7657, 2.8729, 2.8657, 2.9773, 2.8155],\n",
      "        [2.5325, 2.6934, 2.8271, 2.7003, 2.8158],\n",
      "        [2.4563, 2.6501, 2.6060, 2.5702, 2.6232],\n",
      "        [2.6338, 2.6324, 2.6422, 2.8186, 2.6500],\n",
      "        [2.9061, 2.7850, 2.8845, 2.9806, 2.9299],\n",
      "        [2.7827, 2.9002, 2.8000, 2.8524, 2.9409],\n",
      "        [2.6117, 2.7533, 2.6931, 2.7139, 2.7369],\n",
      "        [2.6912, 3.0618, 2.8151, 2.9847, 2.9773],\n",
      "        [2.5267, 2.5892, 2.6541, 2.6639, 2.6336],\n",
      "        [2.5344, 2.6506, 2.5905, 2.7255, 2.5755],\n",
      "        [2.4902, 2.7651, 2.7354, 2.6591, 2.6840],\n",
      "        [2.8616, 2.7818, 2.8621, 2.9904, 2.8814],\n",
      "        [2.3805, 2.5914, 2.6305, 2.5726, 2.6270]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.9122, 2.7840, 2.8824, 2.9757, 2.9349],\n",
      "        [2.4406, 2.6243, 2.5941, 2.5549, 2.6117],\n",
      "        [2.5373, 2.5573, 2.6326, 2.6727, 2.6184],\n",
      "        [2.8439, 2.8688, 2.8732, 2.9959, 2.9077],\n",
      "        [2.6356, 2.6017, 2.7125, 2.6548, 2.6687],\n",
      "        [2.7495, 2.7297, 2.8101, 2.8447, 2.7830],\n",
      "        [2.6007, 2.7334, 2.6429, 2.7299, 2.7307],\n",
      "        [2.7275, 2.8678, 2.8244, 2.8231, 2.7126],\n",
      "        [2.9816, 2.9757, 2.9161, 3.0295, 3.0073],\n",
      "        [2.6618, 2.7045, 2.7618, 2.6628, 2.5989],\n",
      "        [2.5614, 2.7291, 2.7000, 2.8161, 2.6833],\n",
      "        [2.4942, 2.7962, 2.5779, 2.7264, 2.6205],\n",
      "        [2.6492, 2.7909, 2.6139, 2.8000, 2.7442],\n",
      "        [2.6771, 2.9481, 2.8138, 2.8648, 2.9640],\n",
      "        [2.6546, 2.7665, 2.7452, 2.7243, 2.7699],\n",
      "        [2.6558, 2.6563, 2.7932, 2.7717, 2.7558],\n",
      "        [2.6444, 2.6378, 2.7866, 2.7860, 2.8561],\n",
      "        [2.7642, 2.9570, 2.7895, 2.8814, 2.8711],\n",
      "        [2.7995, 2.7723, 2.7874, 2.7243, 2.6846],\n",
      "        [2.9557, 2.9053, 2.8784, 2.9592, 2.9326],\n",
      "        [2.4836, 2.7489, 2.7174, 2.6504, 2.6702],\n",
      "        [2.8306, 3.0269, 2.8292, 2.7413, 2.8706],\n",
      "        [2.6565, 2.9349, 2.8779, 2.8795, 2.9291],\n",
      "        [2.8404, 2.8596, 2.8639, 2.9921, 2.8950],\n",
      "        [2.7206, 2.9220, 2.8538, 2.8774, 2.9700],\n",
      "        [2.7709, 2.9091, 2.8712, 2.8236, 2.7144],\n",
      "        [2.6031, 2.7544, 2.8614, 2.7009, 2.7629],\n",
      "        [2.5880, 2.7415, 2.6095, 2.7248, 2.6977],\n",
      "        [2.7476, 2.8842, 2.8536, 2.8820, 2.8594],\n",
      "        [2.6246, 2.7328, 2.7073, 2.7280, 2.7472],\n",
      "        [2.7194, 2.6038, 2.8698, 2.8213, 2.8114],\n",
      "        [2.6315, 2.6226, 2.7668, 2.7593, 2.8367],\n",
      "        [2.4596, 2.6541, 2.5131, 2.6630, 2.5907],\n",
      "        [2.4503, 2.7334, 2.7892, 2.6450, 2.7845],\n",
      "        [2.7532, 2.9169, 2.7238, 2.8175, 2.8937],\n",
      "        [2.6240, 2.8333, 2.7351, 2.6952, 2.8127],\n",
      "        [2.6901, 2.8702, 2.7917, 2.7936, 2.6904],\n",
      "        [2.5629, 2.6122, 2.6765, 2.6962, 2.6375],\n",
      "        [2.6621, 2.9029, 2.6990, 2.8262, 2.8136],\n",
      "        [2.7105, 2.9895, 2.8847, 2.8864, 2.9720],\n",
      "        [2.4773, 2.7276, 2.7942, 2.6662, 2.7609],\n",
      "        [2.6900, 2.5516, 2.8505, 2.7922, 2.7717],\n",
      "        [2.6381, 2.6298, 2.7760, 2.7706, 2.8457],\n",
      "        [2.9377, 2.8458, 2.8248, 2.8809, 2.8799],\n",
      "        [2.5199, 2.6095, 2.6638, 2.6556, 2.6403],\n",
      "        [2.7461, 2.8751, 2.7625, 2.7288, 2.8039],\n",
      "        [2.6758, 2.8957, 2.7684, 2.8385, 2.9439],\n",
      "        [2.5717, 2.7057, 2.6357, 2.7286, 2.7105],\n",
      "        [2.8317, 2.7132, 2.7644, 3.1228, 2.9871],\n",
      "        [2.6244, 3.0187, 2.7438, 2.9516, 2.9103],\n",
      "        [2.6539, 2.9301, 2.8338, 2.8229, 2.7727],\n",
      "        [2.7668, 2.8014, 2.9840, 2.7679, 2.7602],\n",
      "        [2.8156, 3.0449, 2.8280, 3.0016, 3.0232],\n",
      "        [2.5768, 2.8810, 2.7321, 2.7206, 2.6586],\n",
      "        [2.6450, 2.6368, 2.7868, 2.7830, 2.8537],\n",
      "        [2.5007, 2.6044, 2.6270, 2.6291, 2.6330],\n",
      "        [2.9401, 3.0565, 2.9455, 3.1976, 3.0862],\n",
      "        [2.8332, 2.9417, 2.7876, 2.8969, 3.0006],\n",
      "        [2.3453, 2.5555, 2.6196, 2.5451, 2.6307],\n",
      "        [2.5420, 2.7966, 2.7108, 2.7241, 2.8807],\n",
      "        [2.7919, 2.8511, 2.8253, 2.8985, 2.9861],\n",
      "        [2.4862, 2.7037, 2.7022, 2.6501, 2.6538],\n",
      "        [2.4939, 2.7985, 2.5756, 2.7288, 2.6224],\n",
      "        [2.6495, 2.7220, 2.7565, 2.7148, 2.9474]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.5616, 2.8666, 2.7109, 2.6921, 2.6443],\n",
      "        [2.7992, 2.9283, 2.7668, 2.9374, 2.9491],\n",
      "        [2.6970, 3.0125, 2.8849, 2.8973, 3.0269],\n",
      "        [2.6362, 2.7811, 2.6169, 2.7909, 2.7414],\n",
      "        [2.5421, 2.6578, 2.5949, 2.7287, 2.5828],\n",
      "        [2.7735, 2.8058, 2.8819, 2.8318, 2.7508],\n",
      "        [2.6338, 2.7383, 2.6646, 2.7842, 2.8652],\n",
      "        [2.7697, 2.9468, 2.8696, 2.8842, 2.8470],\n",
      "        [2.6635, 2.8630, 2.7358, 2.7549, 2.8363],\n",
      "        [2.9224, 3.0239, 2.9169, 2.9809, 3.0861],\n",
      "        [2.7761, 2.9394, 2.8560, 2.9039, 2.8661],\n",
      "        [2.7490, 2.9237, 2.7481, 2.9805, 2.8924],\n",
      "        [2.6726, 2.7773, 2.7626, 2.7593, 2.7792],\n",
      "        [2.6555, 2.8020, 2.5891, 2.7076, 2.7515],\n",
      "        [2.4949, 2.7595, 2.7298, 2.6654, 2.6963],\n",
      "        [2.5409, 2.5607, 2.6354, 2.6747, 2.6226],\n",
      "        [2.6195, 2.6621, 2.7267, 2.7298, 2.7468],\n",
      "        [2.7047, 2.6580, 2.9452, 2.8213, 2.8817],\n",
      "        [2.8441, 2.8634, 2.8669, 2.9944, 2.8992],\n",
      "        [2.4062, 2.6137, 2.6347, 2.5960, 2.6420],\n",
      "        [2.8110, 2.9317, 2.9128, 2.8569, 2.7407],\n",
      "        [2.5950, 2.7506, 2.6175, 2.7310, 2.7074],\n",
      "        [2.4989, 2.6861, 2.6182, 2.6141, 2.6570],\n",
      "        [2.6044, 2.6517, 2.7484, 2.7536, 2.8101],\n",
      "        [2.7817, 2.9180, 2.7570, 2.9265, 2.9432],\n",
      "        [2.5420, 2.5981, 2.6555, 2.6757, 2.6410],\n",
      "        [2.6797, 2.8760, 2.7829, 2.7923, 2.6894],\n",
      "        [2.6506, 2.7963, 2.6214, 2.8018, 2.7500],\n",
      "        [2.6389, 2.7202, 2.7433, 2.7101, 2.9292],\n",
      "        [2.5371, 2.8043, 2.6094, 2.7383, 2.6411],\n",
      "        [2.6279, 2.6512, 2.7488, 2.7425, 2.7415],\n",
      "        [2.7085, 2.7868, 2.7574, 2.9219, 2.7906],\n",
      "        [2.7113, 2.9983, 2.8891, 2.8848, 2.9702],\n",
      "        [2.6423, 2.7799, 2.6173, 2.7865, 2.7395],\n",
      "        [2.6248, 2.6627, 2.7380, 2.7317, 2.7507],\n",
      "        [2.6212, 2.7001, 2.7461, 2.7528, 2.7784],\n",
      "        [2.7628, 2.8737, 2.8436, 2.7890, 2.8692],\n",
      "        [2.8911, 2.6332, 2.8073, 3.1392, 3.1160],\n",
      "        [3.0319, 3.1708, 2.8981, 2.9239, 2.9153],\n",
      "        [2.6846, 2.6502, 2.7536, 2.7709, 2.7522],\n",
      "        [2.7515, 2.7715, 2.8758, 2.7856, 2.6439],\n",
      "        [2.6380, 2.6218, 2.7698, 2.7556, 2.8413],\n",
      "        [2.9147, 2.7386, 2.7964, 3.2557, 3.0827],\n",
      "        [2.5264, 2.7805, 2.8768, 2.7331, 2.8102],\n",
      "        [2.6336, 2.6397, 2.7667, 2.7317, 2.7459],\n",
      "        [2.6906, 2.6519, 2.7637, 2.7746, 2.7584],\n",
      "        [2.7195, 2.8065, 2.7173, 2.8109, 2.9700],\n",
      "        [2.6892, 2.6488, 2.7581, 2.7776, 2.7327],\n",
      "        [2.4969, 2.6983, 2.7043, 2.6615, 2.6725],\n",
      "        [2.8970, 2.6376, 2.7970, 3.1534, 3.1381],\n",
      "        [2.7200, 2.8433, 2.7114, 2.8358, 2.8999],\n",
      "        [2.6491, 2.8393, 2.7087, 2.8406, 2.7708],\n",
      "        [2.5449, 2.7356, 2.9014, 2.7061, 2.8912],\n",
      "        [2.8689, 2.7930, 2.8691, 2.9970, 2.8931],\n",
      "        [2.5365, 2.7422, 2.6584, 2.6733, 2.7322],\n",
      "        [2.6601, 2.8358, 2.6751, 2.7080, 2.7963],\n",
      "        [2.4543, 2.7311, 2.5267, 2.6836, 2.5784],\n",
      "        [2.6156, 2.8980, 2.7018, 2.5788, 2.8325],\n",
      "        [2.5156, 2.6870, 2.6163, 2.6316, 2.6588],\n",
      "        [2.7691, 2.9832, 2.8061, 2.8863, 2.8873],\n",
      "        [2.6202, 2.6831, 2.7412, 2.7533, 2.7756],\n",
      "        [2.6317, 2.7145, 2.7364, 2.7155, 2.9101],\n",
      "        [2.5246, 2.6867, 2.7526, 2.7071, 2.6371],\n",
      "        [2.8205, 2.9843, 2.8709, 2.7827, 2.9210]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.8035, 2.6447, 2.6825, 2.7211, 2.7756],\n",
      "        [2.6706, 2.8302, 2.6442, 2.7267, 2.7891],\n",
      "        [2.5944, 2.7446, 2.6185, 2.7145, 2.7186],\n",
      "        [2.7393, 2.7473, 2.8114, 2.7453, 2.7114],\n",
      "        [2.5721, 2.7274, 2.6644, 2.7051, 2.7157],\n",
      "        [2.5766, 2.6703, 2.7136, 2.7407, 2.6673],\n",
      "        [2.5875, 2.6337, 2.7205, 2.6900, 2.7154],\n",
      "        [2.7813, 2.8407, 2.8675, 2.9007, 2.7511],\n",
      "        [2.5469, 2.6203, 2.6860, 2.6845, 2.6330],\n",
      "        [2.5546, 2.6346, 2.5660, 2.7322, 2.6147],\n",
      "        [2.7943, 2.9232, 2.8931, 2.8419, 2.7313],\n",
      "        [2.5813, 2.6430, 2.7209, 2.7010, 2.7261],\n",
      "        [2.5320, 2.7499, 2.6078, 2.7256, 2.6757],\n",
      "        [2.5379, 2.6003, 2.6612, 2.6700, 2.6451],\n",
      "        [2.5430, 2.6640, 2.7238, 2.7195, 2.6390],\n",
      "        [2.7386, 2.8578, 2.8848, 2.8479, 2.8707],\n",
      "        [2.7657, 2.9050, 2.8620, 2.8222, 2.7132],\n",
      "        [2.4967, 2.7418, 2.8032, 2.6728, 2.7756],\n",
      "        [2.8354, 2.9408, 2.7784, 2.8698, 2.9927],\n",
      "        [2.6684, 2.8140, 2.6282, 2.8249, 2.7666],\n",
      "        [2.5972, 2.6922, 2.6434, 2.7713, 2.6991],\n",
      "        [2.8253, 2.9349, 2.7713, 2.8700, 2.9901],\n",
      "        [2.7388, 2.8502, 2.7157, 2.8014, 2.9583],\n",
      "        [2.8263, 2.9208, 2.9372, 2.8779, 2.7917],\n",
      "        [2.6120, 2.6139, 2.7715, 2.6233, 2.8013],\n",
      "        [2.8459, 2.8717, 2.8415, 2.8482, 2.9096],\n",
      "        [2.7629, 2.7693, 2.8168, 2.7593, 2.7182],\n",
      "        [2.7164, 2.8061, 2.7685, 2.9409, 2.7994],\n",
      "        [2.5984, 2.7543, 2.6201, 2.7336, 2.7112],\n",
      "        [2.5779, 2.7400, 2.7188, 2.8237, 2.7006],\n",
      "        [2.7478, 2.7259, 2.7730, 2.7143, 2.6390],\n",
      "        [2.5966, 2.7195, 2.6634, 2.6739, 2.6854],\n",
      "        [2.6437, 2.6307, 2.7732, 2.7600, 2.8498],\n",
      "        [2.5686, 2.7364, 2.7055, 2.8207, 2.6913],\n",
      "        [2.5191, 2.7111, 2.7431, 2.6944, 2.6731],\n",
      "        [2.7363, 2.7917, 2.6201, 2.8692, 2.9005],\n",
      "        [2.6108, 2.7104, 2.6980, 2.6824, 2.7345],\n",
      "        [2.7862, 2.9711, 2.8985, 2.8951, 2.8637],\n",
      "        [2.4883, 2.7292, 2.7168, 2.6616, 2.6706],\n",
      "        [2.9429, 2.8828, 2.8929, 2.9372, 2.9247],\n",
      "        [2.5868, 2.5625, 2.7098, 2.7139, 2.7607],\n",
      "        [2.6691, 2.6962, 2.8277, 2.8084, 2.8228],\n",
      "        [2.5864, 2.7461, 2.6178, 2.7163, 2.7087],\n",
      "        [2.6391, 2.6216, 2.7569, 2.7478, 2.8377],\n",
      "        [2.6316, 2.6504, 2.7664, 2.6851, 2.7957],\n",
      "        [2.4902, 2.7645, 2.7314, 2.6559, 2.6867],\n",
      "        [2.5312, 2.6727, 2.7256, 2.6930, 2.6553],\n",
      "        [2.6506, 2.6626, 2.7661, 2.7631, 2.8218],\n",
      "        [2.5593, 2.7412, 2.6939, 2.8297, 2.6763],\n",
      "        [2.7449, 2.9027, 2.8343, 2.9610, 2.8444],\n",
      "        [2.5594, 2.6240, 2.6845, 2.6856, 2.6475],\n",
      "        [2.7875, 2.8313, 2.8257, 2.8173, 2.9399],\n",
      "        [2.6820, 2.7378, 2.7481, 2.8356, 2.7863],\n",
      "        [2.7997, 2.8127, 2.9101, 2.8717, 2.7400],\n",
      "        [2.6728, 2.8474, 2.6933, 2.8402, 2.7996],\n",
      "        [2.5035, 2.6689, 2.6941, 2.6539, 2.6538],\n",
      "        [2.6018, 2.5816, 2.7298, 2.7357, 2.7811],\n",
      "        [2.6973, 2.7792, 2.7748, 2.7719, 2.7933],\n",
      "        [2.6540, 2.6027, 2.7117, 2.6473, 2.6664],\n",
      "        [2.6558, 2.8527, 2.7236, 2.7595, 2.8336],\n",
      "        [2.7225, 2.7133, 2.7931, 2.7168, 2.7260],\n",
      "        [2.7148, 2.8051, 2.6928, 2.8212, 2.8006],\n",
      "        [2.6829, 2.9034, 2.7742, 2.8434, 2.9520],\n",
      "        [2.6360, 2.6261, 2.7465, 2.7451, 2.8378]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.6811, 3.0368, 2.7597, 2.9780, 2.9423],\n",
      "        [2.5222, 2.6941, 2.6211, 2.6374, 2.6658],\n",
      "        [2.8650, 2.9658, 2.8167, 2.9268, 3.0408],\n",
      "        [2.8755, 2.8003, 2.8742, 3.0034, 2.9004],\n",
      "        [2.8178, 2.9394, 2.9180, 2.8629, 2.7486],\n",
      "        [2.6316, 2.6939, 2.7455, 2.7469, 2.7690],\n",
      "        [2.8065, 2.6481, 2.6848, 2.7241, 2.7794],\n",
      "        [2.4162, 2.6126, 2.6476, 2.6020, 2.6654],\n",
      "        [2.5916, 2.5738, 2.6268, 2.6894, 2.6242],\n",
      "        [2.8201, 2.9711, 2.9149, 2.9774, 3.0070],\n",
      "        [2.8003, 2.9315, 2.8691, 2.8023, 2.8933],\n",
      "        [2.4976, 2.6956, 2.6241, 2.6714, 2.6567],\n",
      "        [2.6124, 2.6199, 2.7737, 2.6249, 2.8044],\n",
      "        [2.6402, 2.6472, 2.7716, 2.7373, 2.7531],\n",
      "        [2.7007, 2.8814, 2.7999, 2.8016, 2.7024],\n",
      "        [2.4998, 2.6946, 2.7014, 2.6534, 2.6602],\n",
      "        [2.4660, 2.7416, 2.8061, 2.6506, 2.7516],\n",
      "        [2.6616, 2.9244, 2.7064, 2.6053, 2.8105],\n",
      "        [2.6213, 2.6716, 2.7427, 2.7469, 2.7597],\n",
      "        [2.6426, 2.9871, 2.7675, 2.8995, 2.9195],\n",
      "        [2.8888, 2.9723, 2.8339, 2.9535, 3.0255],\n",
      "        [2.7730, 2.7660, 2.7348, 3.0107, 2.9214],\n",
      "        [2.6482, 2.7813, 2.7488, 2.7193, 2.7737],\n",
      "        [2.7918, 2.8359, 2.8297, 2.8223, 2.9466],\n",
      "        [2.5474, 2.5679, 2.6403, 2.6803, 2.6298],\n",
      "        [2.8482, 2.9137, 2.9012, 2.9098, 3.0074],\n",
      "        [2.3384, 2.5606, 2.6249, 2.5358, 2.6143],\n",
      "        [2.6371, 2.6613, 2.8065, 2.7870, 2.7783],\n",
      "        [2.7423, 2.6035, 2.8984, 2.8364, 2.8205],\n",
      "        [2.5804, 2.7174, 2.7871, 2.7194, 2.7902],\n",
      "        [2.5582, 2.6493, 2.7184, 2.7220, 2.7425],\n",
      "        [2.7052, 2.7872, 2.8300, 2.8193, 2.8193],\n",
      "        [2.9096, 2.8461, 2.9048, 3.0476, 2.9441],\n",
      "        [2.7461, 2.9386, 2.8782, 2.9100, 2.8509],\n",
      "        [2.5292, 2.6403, 2.7046, 2.6844, 2.6333],\n",
      "        [2.6350, 2.6539, 2.7688, 2.6883, 2.7992],\n",
      "        [2.5899, 2.5660, 2.7121, 2.7169, 2.7641],\n",
      "        [2.6732, 2.8333, 2.6517, 2.7204, 2.7883],\n",
      "        [2.6362, 2.7010, 2.8103, 2.6820, 2.8921],\n",
      "        [2.6479, 2.9600, 2.8577, 2.8635, 2.9648],\n",
      "        [2.7264, 3.0082, 2.8137, 2.8915, 2.8952],\n",
      "        [2.7548, 2.7657, 2.7270, 2.9604, 2.8842],\n",
      "        [2.5167, 2.7376, 2.8035, 2.6960, 2.7984],\n",
      "        [3.0318, 3.2365, 2.7933, 2.8948, 2.8749],\n",
      "        [2.7544, 2.9295, 2.7527, 2.9857, 2.8971],\n",
      "        [3.0556, 3.1801, 2.7955, 2.9428, 2.8531],\n",
      "        [2.6573, 2.8035, 2.6264, 2.8075, 2.7573],\n",
      "        [2.5218, 2.7050, 2.6253, 2.6444, 2.6757],\n",
      "        [2.7393, 2.8992, 2.8586, 2.8907, 2.8924],\n",
      "        [2.6367, 2.6566, 2.7574, 2.7418, 2.7477],\n",
      "        [2.7264, 2.9287, 2.8593, 2.8881, 2.9567],\n",
      "        [2.4881, 2.7387, 2.8023, 2.6744, 2.7724],\n",
      "        [2.7370, 2.8703, 2.8931, 2.8723, 2.8602],\n",
      "        [2.6005, 2.6012, 2.7738, 2.5960, 2.8042],\n",
      "        [2.6373, 2.7761, 2.6227, 2.7687, 2.7470],\n",
      "        [2.5538, 2.6819, 2.6001, 2.7409, 2.6758],\n",
      "        [2.5830, 2.9376, 2.8220, 2.8100, 2.9459],\n",
      "        [2.9512, 3.0682, 2.9541, 3.2068, 3.0983],\n",
      "        [2.5755, 2.7118, 2.6468, 2.7768, 2.7228],\n",
      "        [2.9347, 3.0431, 2.9378, 3.0020, 3.0936],\n",
      "        [2.5263, 2.7239, 2.6499, 2.7429, 2.6800],\n",
      "        [2.6646, 2.7776, 2.7530, 2.7322, 2.7820],\n",
      "        [2.4737, 2.5967, 2.6170, 2.5913, 2.6164],\n",
      "        [2.7786, 2.9684, 2.8779, 2.9006, 2.8717]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.7618, 2.8802, 2.8978, 2.9123, 2.9401],\n",
      "        [2.5590, 2.6185, 2.6862, 2.6954, 2.6388],\n",
      "        [2.5734, 2.9283, 2.7572, 2.7904, 2.9233],\n",
      "        [2.5074, 2.8099, 2.5874, 2.7373, 2.6341],\n",
      "        [2.9477, 2.9179, 2.8548, 2.9458, 2.9541],\n",
      "        [2.8774, 2.8032, 2.8809, 3.0002, 2.9050],\n",
      "        [2.3984, 2.6090, 2.6422, 2.5848, 2.6446],\n",
      "        [3.0772, 3.2021, 2.7947, 2.9610, 2.8443],\n",
      "        [2.8318, 2.9418, 2.7763, 2.8762, 2.9969],\n",
      "        [2.6643, 2.9494, 2.8828, 2.8816, 2.9452],\n",
      "        [2.7494, 2.8855, 2.8863, 2.8824, 2.8512],\n",
      "        [2.5606, 2.6906, 2.6328, 2.7129, 2.6694],\n",
      "        [2.8901, 2.9234, 2.8742, 3.0641, 2.9482],\n",
      "        [2.7341, 2.5890, 2.8926, 2.8210, 2.8000],\n",
      "        [2.6340, 2.8590, 2.7641, 2.6988, 2.8366],\n",
      "        [2.5023, 2.6837, 2.6256, 2.6189, 2.6774],\n",
      "        [2.6375, 2.8476, 2.7454, 2.7061, 2.8279],\n",
      "        [2.5812, 2.7310, 2.6228, 2.6966, 2.6961],\n",
      "        [2.6535, 2.8965, 2.7738, 2.7749, 2.6798],\n",
      "        [2.6467, 2.7856, 2.7749, 2.7410, 2.6853],\n",
      "        [2.6649, 2.8479, 2.7004, 2.7138, 2.8135],\n",
      "        [3.0917, 3.3349, 2.8772, 3.0034, 2.9093],\n",
      "        [2.6140, 2.7471, 2.6529, 2.7406, 2.7451],\n",
      "        [2.7728, 2.8844, 2.8511, 2.7980, 2.8799],\n",
      "        [3.0998, 3.3188, 2.8619, 2.9697, 2.9337],\n",
      "        [2.6428, 2.9158, 2.8038, 2.8605, 2.9520],\n",
      "        [2.7176, 2.7812, 2.7759, 2.7924, 2.7937],\n",
      "        [2.5066, 2.7088, 2.7115, 2.6703, 2.6827],\n",
      "        [2.5505, 2.5710, 2.6425, 2.6831, 2.6330],\n",
      "        [2.9949, 2.9908, 2.9265, 3.0407, 3.0248],\n",
      "        [2.6555, 2.7061, 2.7832, 2.7816, 2.7892],\n",
      "        [2.6277, 2.7116, 2.8378, 2.8831, 2.9650],\n",
      "        [2.6380, 3.0027, 2.7836, 2.9120, 2.9399],\n",
      "        [2.7346, 2.9371, 2.8648, 2.8887, 2.9852],\n",
      "        [2.7283, 2.8225, 2.8287, 2.8096, 2.8446],\n",
      "        [2.7719, 3.0393, 2.9298, 2.9373, 3.0179],\n",
      "        [2.6589, 2.6095, 2.7188, 2.6459, 2.6730],\n",
      "        [2.5555, 2.8108, 2.7212, 2.7351, 2.8957],\n",
      "        [2.7715, 2.8911, 2.8694, 2.8996, 2.8478],\n",
      "        [2.6997, 2.6522, 2.7585, 2.7813, 2.7295],\n",
      "        [2.5614, 2.6413, 2.5759, 2.7396, 2.5786],\n",
      "        [2.6206, 2.6199, 2.7550, 2.7299, 2.7279],\n",
      "        [2.6793, 2.8541, 2.6983, 2.8463, 2.8063],\n",
      "        [2.8028, 2.9736, 2.7444, 2.8267, 2.8934],\n",
      "        [2.5464, 2.8694, 2.8252, 2.7345, 2.9083],\n",
      "        [2.6223, 2.6890, 2.7372, 2.7477, 2.7610],\n",
      "        [2.7757, 2.9249, 2.7310, 2.8315, 2.9118],\n",
      "        [2.4997, 2.7324, 2.7163, 2.6590, 2.6727],\n",
      "        [2.5015, 2.7402, 2.7211, 2.6717, 2.6859],\n",
      "        [2.9027, 2.8012, 2.8843, 2.9656, 2.9286],\n",
      "        [2.6169, 2.7265, 2.5504, 2.8138, 2.6102],\n",
      "        [2.6261, 2.6711, 2.7315, 2.7369, 2.7554],\n",
      "        [2.4693, 2.7448, 2.8084, 2.6536, 2.7548],\n",
      "        [2.8361, 3.0654, 2.8526, 3.0198, 3.0515],\n",
      "        [2.6094, 2.8859, 2.8256, 2.6591, 2.8459],\n",
      "        [2.6072, 2.7292, 2.7120, 2.7697, 2.8224],\n",
      "        [2.7592, 2.8999, 2.7593, 2.9176, 2.8666],\n",
      "        [2.7541, 2.9167, 2.7640, 2.8504, 2.8650],\n",
      "        [2.9826, 2.9460, 2.9195, 3.0042, 2.9942],\n",
      "        [2.7922, 2.8336, 2.8683, 2.9079, 2.7338],\n",
      "        [2.5516, 2.5924, 2.6553, 2.6887, 2.6443],\n",
      "        [2.6748, 2.8206, 2.6329, 2.8309, 2.7733],\n",
      "        [2.8166, 2.9649, 2.9494, 2.8858, 2.7332],\n",
      "        [2.7762, 2.7693, 2.7371, 3.0136, 2.9246]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.5730, 2.6941, 2.6312, 2.7321, 2.6747],\n",
      "        [3.2586, 3.4205, 3.0255, 3.1074, 3.0167],\n",
      "        [2.5910, 2.6534, 2.7278, 2.7113, 2.7357],\n",
      "        [2.5655, 2.8348, 2.6251, 2.7476, 2.6532],\n",
      "        [2.7206, 2.8185, 2.7164, 2.8455, 2.8360],\n",
      "        [2.6043, 2.7588, 2.6216, 2.7396, 2.7149],\n",
      "        [2.5523, 2.7153, 2.8414, 2.7165, 2.8369],\n",
      "        [2.6139, 2.7734, 2.7075, 2.8186, 2.8192],\n",
      "        [2.5490, 2.7565, 2.6677, 2.6862, 2.7462],\n",
      "        [2.6555, 2.7967, 2.6265, 2.7955, 2.7485],\n",
      "        [2.5925, 2.5723, 2.7161, 2.7188, 2.7757],\n",
      "        [2.5714, 2.7177, 2.6303, 2.7446, 2.6773],\n",
      "        [2.9680, 3.1409, 2.9064, 2.8863, 2.9519],\n",
      "        [2.5232, 2.7446, 2.8081, 2.7032, 2.8045],\n",
      "        [2.5571, 2.7501, 2.9111, 2.7190, 2.9046],\n",
      "        [2.8644, 2.8777, 2.8762, 3.0123, 2.9253],\n",
      "        [2.5824, 2.7521, 2.7174, 2.8363, 2.7001],\n",
      "        [2.7444, 2.8863, 2.8373, 2.8385, 2.7314],\n",
      "        [2.5078, 2.6802, 2.6960, 2.6612, 2.6634],\n",
      "        [2.6643, 2.6979, 2.7977, 2.7858, 2.7868],\n",
      "        [2.6623, 2.8536, 2.7187, 2.8534, 2.7843],\n",
      "        [2.9477, 2.8869, 2.9229, 3.1308, 3.0554],\n",
      "        [2.7879, 2.8508, 2.8745, 2.9169, 2.7614],\n",
      "        [2.4532, 2.6434, 2.6075, 2.5571, 2.6152],\n",
      "        [2.6141, 2.7394, 2.6648, 2.7783, 2.7275],\n",
      "        [2.9419, 2.7993, 2.9095, 3.3717, 3.2693],\n",
      "        [2.5599, 2.6886, 2.6044, 2.7479, 2.6817],\n",
      "        [2.8866, 2.8242, 2.9005, 3.0287, 2.9263],\n",
      "        [2.5294, 2.7121, 2.6290, 2.6467, 2.6793],\n",
      "        [2.5367, 2.7077, 2.7689, 2.7258, 2.6534],\n",
      "        [2.6254, 2.6928, 2.7394, 2.7520, 2.7640],\n",
      "        [2.6190, 2.8025, 2.6887, 2.7814, 2.8265],\n",
      "        [2.6395, 2.6851, 2.7465, 2.7451, 2.7647],\n",
      "        [2.7159, 2.9255, 2.9046, 2.8866, 2.8247],\n",
      "        [2.6710, 2.8154, 2.6404, 2.8263, 2.7723],\n",
      "        [2.7924, 2.6612, 2.8038, 2.9957, 3.0429],\n",
      "        [2.6122, 2.7287, 2.7158, 2.7588, 2.8444],\n",
      "        [2.6170, 2.9693, 2.7602, 2.8735, 2.9096],\n",
      "        [2.6653, 2.8088, 2.6275, 2.8296, 2.7668],\n",
      "        [2.9157, 2.9686, 2.8664, 3.0913, 3.0198],\n",
      "        [2.6778, 2.8242, 2.6351, 2.8350, 2.7762],\n",
      "        [2.5999, 2.9002, 2.7542, 2.7484, 2.6790],\n",
      "        [2.7644, 2.9029, 2.8665, 2.8976, 2.8778],\n",
      "        [2.4817, 2.6689, 2.6191, 2.5937, 2.6500],\n",
      "        [2.5050, 2.6986, 2.7032, 2.6624, 2.6665],\n",
      "        [2.8630, 2.8059, 2.8084, 2.8555, 2.8959],\n",
      "        [2.5651, 2.6041, 2.6653, 2.6953, 2.6578],\n",
      "        [2.5024, 2.7510, 2.7257, 2.6643, 2.6823],\n",
      "        [2.8223, 2.8815, 2.9080, 2.8722, 2.9623],\n",
      "        [2.6163, 2.7561, 2.7352, 2.8472, 2.7590],\n",
      "        [2.6452, 2.6750, 2.6759, 2.8226, 2.6904],\n",
      "        [2.7746, 2.8950, 2.8716, 2.9040, 2.8509],\n",
      "        [2.7236, 2.7750, 2.7733, 2.8016, 2.7773],\n",
      "        [2.6412, 2.7796, 2.6307, 2.7606, 2.7560],\n",
      "        [2.6370, 2.8628, 2.7663, 2.7031, 2.8397],\n",
      "        [2.6121, 2.9787, 2.8701, 2.8147, 2.7939],\n",
      "        [2.8643, 2.7332, 2.7806, 3.1710, 3.0248],\n",
      "        [2.8549, 2.8825, 2.8483, 2.8589, 2.9205],\n",
      "        [2.6722, 3.0282, 2.7707, 2.9774, 2.9490],\n",
      "        [2.6412, 2.7796, 2.6307, 2.7606, 2.7560],\n",
      "        [2.6690, 2.8910, 2.7822, 2.7885, 2.6884],\n",
      "        [2.8978, 2.9157, 2.9193, 3.0520, 2.9800],\n",
      "        [3.0671, 2.8183, 2.9524, 3.4058, 3.3446],\n",
      "        [2.7662, 2.7484, 2.8226, 2.8596, 2.8010]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.7669, 2.9427, 2.7601, 2.9985, 2.9093],\n",
      "        [2.8212, 2.9413, 2.7594, 2.8711, 2.9672],\n",
      "        [2.6500, 2.6860, 2.7578, 2.7563, 2.7759],\n",
      "        [2.7627, 2.8228, 2.9016, 2.8305, 2.7830],\n",
      "        [2.5904, 2.6847, 2.7223, 2.7556, 2.6794],\n",
      "        [2.5855, 2.7415, 2.6730, 2.7197, 2.7277],\n",
      "        [2.7320, 3.0131, 2.9005, 2.9067, 2.9929],\n",
      "        [2.5630, 2.5968, 2.6581, 2.7017, 2.6543],\n",
      "        [2.5060, 2.7207, 2.7164, 2.6684, 2.6718],\n",
      "        [2.5672, 2.8263, 2.7267, 2.7497, 2.9121],\n",
      "        [2.6554, 2.7115, 2.7780, 2.7734, 2.7834],\n",
      "        [2.7802, 2.9866, 2.9578, 2.9388, 2.8028],\n",
      "        [2.6677, 2.8034, 2.6272, 2.8122, 2.7558],\n",
      "        [2.6344, 2.9026, 2.7640, 2.7628, 2.6773],\n",
      "        [2.9031, 2.9272, 2.9158, 3.0532, 2.9776],\n",
      "        [2.7959, 2.7283, 2.7430, 3.0851, 2.9404],\n",
      "        [2.8796, 2.9808, 2.9005, 2.9295, 2.9931],\n",
      "        [2.9181, 2.9788, 2.8418, 2.9704, 3.0580],\n",
      "        [2.6240, 2.7339, 2.5543, 2.8223, 2.6155],\n",
      "        [2.7213, 2.9335, 2.7910, 2.9613, 2.8732],\n",
      "        [2.5632, 2.6381, 2.6999, 2.7016, 2.6475],\n",
      "        [2.9016, 2.9386, 2.9002, 3.0767, 2.9384],\n",
      "        [2.8161, 2.7830, 2.7988, 2.7379, 2.6969],\n",
      "        [2.5321, 2.6497, 2.6486, 2.6697, 2.6688],\n",
      "        [2.6340, 2.7212, 2.8315, 2.7484, 2.8688],\n",
      "        [2.5932, 2.7505, 2.6295, 2.7136, 2.7248],\n",
      "        [2.7746, 2.9080, 2.7870, 2.7575, 2.8364],\n",
      "        [2.8137, 2.8278, 2.9194, 2.8869, 2.7528],\n",
      "        [2.7524, 2.8731, 2.8942, 2.8628, 2.8831],\n",
      "        [2.5341, 2.7077, 2.7398, 2.7112, 2.6715],\n",
      "        [2.8028, 2.8736, 2.8470, 2.8827, 2.9618],\n",
      "        [2.6141, 3.0043, 2.8506, 2.7584, 2.7946],\n",
      "        [3.0039, 2.9641, 2.9604, 3.0477, 3.0478],\n",
      "        [2.4515, 2.6480, 2.6111, 2.5606, 2.6191],\n",
      "        [2.6988, 2.7249, 2.8507, 2.8384, 2.8466],\n",
      "        [2.5916, 2.7544, 2.7278, 2.8382, 2.7129],\n",
      "        [2.9214, 2.7665, 2.7994, 3.2309, 3.0776],\n",
      "        [2.7000, 2.6743, 2.7766, 2.7895, 2.7910],\n",
      "        [2.6377, 2.6959, 2.7456, 2.7625, 2.7693],\n",
      "        [2.5155, 2.7038, 2.6291, 2.6313, 2.6724],\n",
      "        [2.5155, 2.6704, 2.6926, 2.6638, 2.6623],\n",
      "        [2.9394, 2.9891, 2.8566, 2.9860, 3.0789],\n",
      "        [3.0838, 3.2100, 2.7988, 2.9699, 2.8500],\n",
      "        [2.8228, 2.8583, 2.8737, 2.9888, 2.8807],\n",
      "        [2.5641, 2.6171, 2.6723, 2.6944, 2.6636],\n",
      "        [2.7752, 2.7875, 2.9399, 2.8079, 2.7354],\n",
      "        [2.7633, 2.9020, 2.8689, 2.9024, 2.8765],\n",
      "        [2.5588, 2.6161, 2.6667, 2.6928, 2.6570],\n",
      "        [2.8873, 2.8183, 2.8864, 3.0159, 2.9128],\n",
      "        [2.7042, 2.8260, 2.9037, 2.8487, 2.9028],\n",
      "        [2.7905, 2.7572, 2.8626, 2.9025, 2.8405],\n",
      "        [2.7262, 2.8056, 2.7691, 2.9397, 2.8073],\n",
      "        [2.5649, 2.6401, 2.5723, 2.7490, 2.6507],\n",
      "        [2.8652, 2.8914, 2.8884, 3.0167, 2.9285],\n",
      "        [2.7583, 2.8694, 2.8906, 2.8104, 2.7506],\n",
      "        [2.7221, 2.6767, 2.9571, 2.8390, 2.8984],\n",
      "        [2.5455, 2.7641, 2.6161, 2.7405, 2.6874],\n",
      "        [2.9227, 2.8672, 2.9206, 3.0614, 2.9661],\n",
      "        [2.7499, 2.9108, 2.8654, 2.9027, 2.9016],\n",
      "        [2.9932, 2.9018, 2.9596, 3.1379, 3.0482],\n",
      "        [2.7966, 2.8336, 2.8455, 2.8081, 2.6999],\n",
      "        [2.6548, 2.8519, 2.7220, 2.7669, 2.8444],\n",
      "        [2.5348, 2.6946, 2.7318, 2.7040, 2.6642],\n",
      "        [3.2547, 3.4200, 3.0242, 3.1010, 3.0213]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.7636, 2.8439, 2.7476, 2.8299, 2.8046],\n",
      "        [2.6130, 2.7444, 2.7189, 2.7995, 2.8026],\n",
      "        [2.7401, 2.9592, 2.8799, 2.8971, 2.8480],\n",
      "        [2.5189, 2.7952, 2.7541, 2.6852, 2.7092],\n",
      "        [2.5607, 2.6827, 2.7354, 2.7392, 2.6532],\n",
      "        [2.6389, 2.6871, 2.7401, 2.7526, 2.7657],\n",
      "        [2.6432, 2.8692, 2.7241, 2.8955, 2.7755],\n",
      "        [2.5099, 2.7251, 2.7192, 2.6732, 2.6739],\n",
      "        [2.5576, 2.6277, 2.6792, 2.6913, 2.6632],\n",
      "        [2.7018, 2.8582, 2.6963, 2.8410, 2.8291],\n",
      "        [2.6560, 2.6865, 2.7683, 2.7639, 2.7717],\n",
      "        [2.8378, 2.9629, 2.9366, 2.8848, 2.7638],\n",
      "        [2.4692, 2.6599, 2.6185, 2.5770, 2.6303],\n",
      "        [2.7893, 2.9833, 2.8074, 2.9060, 2.8941],\n",
      "        [2.7401, 2.7326, 2.8048, 2.7365, 2.7407],\n",
      "        [2.6668, 2.7001, 2.8090, 2.7977, 2.8060],\n",
      "        [2.5637, 2.7101, 2.7596, 2.7374, 2.6653],\n",
      "        [2.8615, 2.6589, 2.8101, 3.0982, 3.0892],\n",
      "        [2.6947, 3.0035, 2.8593, 2.8908, 2.9811],\n",
      "        [2.8349, 2.9072, 2.8965, 2.9420, 2.8725],\n",
      "        [2.4539, 2.6600, 2.6450, 2.6590, 2.6759],\n",
      "        [2.8418, 3.0077, 2.8857, 2.8060, 2.9399],\n",
      "        [2.9041, 2.6604, 2.8092, 3.1625, 3.1374],\n",
      "        [3.0449, 3.2522, 2.8028, 2.9116, 2.8862],\n",
      "        [2.8296, 2.7410, 2.7744, 3.0799, 2.9590],\n",
      "        [2.5699, 2.6545, 2.5725, 2.7531, 2.5969],\n",
      "        [2.6413, 2.9779, 2.8438, 2.8048, 2.7557],\n",
      "        [2.5810, 2.7024, 2.6359, 2.7413, 2.6794],\n",
      "        [2.7710, 2.9473, 2.7632, 3.0035, 2.9115],\n",
      "        [2.7453, 2.6907, 2.9631, 2.8699, 2.9138],\n",
      "        [2.7175, 2.8067, 2.8056, 2.7989, 2.9125],\n",
      "        [2.7132, 2.9540, 2.7817, 2.9604, 2.8798],\n",
      "        [2.7190, 3.0373, 2.9009, 2.9207, 3.0459],\n",
      "        [2.6878, 2.8552, 2.6682, 2.7408, 2.8035],\n",
      "        [2.4950, 2.6861, 2.6275, 2.6107, 2.6573],\n",
      "        [2.6873, 2.9538, 2.7494, 2.9485, 2.8753],\n",
      "        [2.9730, 3.1353, 2.8799, 2.8858, 2.9109],\n",
      "        [2.6516, 2.6857, 2.7737, 2.7230, 2.7595],\n",
      "        [2.5194, 2.6748, 2.6955, 2.6686, 2.6644],\n",
      "        [2.6044, 2.7649, 2.6379, 2.7152, 2.7310],\n",
      "        [2.6792, 2.8239, 2.6453, 2.8355, 2.7772],\n",
      "        [2.6653, 2.6149, 2.7161, 2.6484, 2.6722],\n",
      "        [2.7956, 2.8426, 2.8395, 2.8187, 2.6804],\n",
      "        [3.1102, 3.3313, 2.8692, 2.9839, 2.9419],\n",
      "        [2.5332, 2.7374, 2.8009, 2.7351, 2.8224],\n",
      "        [2.7700, 2.9440, 2.7319, 2.8361, 2.9004],\n",
      "        [2.5499, 2.7525, 2.8056, 2.7365, 2.8310],\n",
      "        [2.9057, 2.9432, 2.9034, 3.0821, 2.9407],\n",
      "        [2.5050, 2.6931, 2.6327, 2.6168, 2.6644],\n",
      "        [2.5596, 2.7573, 2.6637, 2.7886, 2.6909],\n",
      "        [2.6306, 2.8874, 2.8035, 2.6928, 2.8516],\n",
      "        [2.5194, 2.7582, 2.7338, 2.6895, 2.6995],\n",
      "        [2.9485, 2.8869, 2.9019, 2.9505, 2.9482],\n",
      "        [2.8118, 2.9658, 2.8649, 2.7952, 2.9074],\n",
      "        [2.5519, 2.7335, 2.7994, 2.7583, 2.8467],\n",
      "        [3.2507, 3.4129, 3.0361, 3.1325, 3.0096],\n",
      "        [2.7196, 2.8027, 2.8394, 2.8360, 2.8305],\n",
      "        [3.0229, 2.8015, 2.9043, 3.3408, 3.2891],\n",
      "        [2.6395, 2.8797, 2.7890, 2.7036, 2.8507],\n",
      "        [2.7769, 3.0100, 2.7983, 2.7048, 2.8879],\n",
      "        [2.6154, 2.6656, 2.5867, 2.7078, 2.8206],\n",
      "        [2.5459, 2.7093, 2.7668, 2.7297, 2.6551],\n",
      "        [2.7406, 2.7181, 2.8056, 2.7184, 2.7882],\n",
      "        [2.7361, 2.7342, 2.8983, 2.9110, 2.7853]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.6398, 2.7938, 2.6347, 2.7676, 2.7494],\n",
      "        [2.7155, 2.6801, 2.7807, 2.8007, 2.7786],\n",
      "        [3.0765, 2.8287, 2.9538, 3.4154, 3.3463],\n",
      "        [2.8038, 2.7377, 2.7488, 3.0943, 2.9447],\n",
      "        [3.1827, 3.4023, 2.9287, 3.0560, 3.0058],\n",
      "        [2.6499, 2.9147, 2.7726, 2.7774, 2.6830],\n",
      "        [2.5706, 2.8288, 2.7313, 2.7536, 2.9056],\n",
      "        [2.7739, 2.9490, 2.7606, 2.9990, 2.9027],\n",
      "        [2.7918, 2.9447, 2.7956, 2.8832, 2.8642],\n",
      "        [2.5228, 2.8000, 2.7568, 2.6896, 2.7112],\n",
      "        [2.6501, 2.7145, 2.7578, 2.7680, 2.7822],\n",
      "        [2.7561, 2.9723, 2.8852, 2.9241, 3.0088],\n",
      "        [2.9462, 2.9135, 2.8613, 3.0781, 2.9792],\n",
      "        [2.5358, 2.6691, 2.7012, 2.6813, 2.6696],\n",
      "        [2.9165, 2.6612, 2.8248, 3.1646, 3.1361],\n",
      "        [2.6501, 2.7954, 2.6411, 2.7882, 2.7597],\n",
      "        [2.7122, 2.7779, 2.7662, 2.8861, 2.8048],\n",
      "        [2.9523, 2.8918, 2.9046, 2.9553, 2.9506],\n",
      "        [2.8589, 2.7291, 2.7832, 3.1643, 3.0120],\n",
      "        [2.7700, 2.7561, 2.8210, 2.8566, 2.7970],\n",
      "        [2.8516, 3.0161, 2.9741, 2.9388, 2.7849],\n",
      "        [2.5215, 2.7256, 2.7211, 2.6883, 2.6923],\n",
      "        [2.7449, 3.0285, 2.8264, 2.9128, 2.9085],\n",
      "        [2.7813, 2.9044, 2.8768, 2.9169, 2.8532],\n",
      "        [2.7751, 2.9522, 2.7661, 3.0081, 2.9136],\n",
      "        [2.7751, 2.9522, 2.7661, 3.0081, 2.9136],\n",
      "        [2.4974, 2.7760, 2.5458, 2.7298, 2.6009],\n",
      "        [2.7090, 2.6723, 2.9730, 2.8301, 2.8796],\n",
      "        [2.9669, 2.7840, 2.8186, 3.3044, 3.1437],\n",
      "        [2.6122, 2.6100, 2.6773, 2.7355, 2.6563],\n",
      "        [2.7986, 2.7669, 2.8684, 2.9117, 2.8448],\n",
      "        [2.6404, 2.7996, 2.8961, 2.7308, 2.8025],\n",
      "        [2.7936, 2.8524, 2.8340, 2.8167, 2.6500],\n",
      "        [2.5209, 2.7761, 2.7421, 2.6922, 2.7110],\n",
      "        [2.6390, 2.7916, 2.6428, 2.7732, 2.7471],\n",
      "        [2.8162, 2.9324, 2.8843, 2.8360, 2.9031],\n",
      "        [2.7735, 2.9504, 2.7654, 3.0072, 2.9106],\n",
      "        [2.8399, 2.6722, 2.8156, 3.0579, 3.0725],\n",
      "        [2.6806, 2.8293, 2.6066, 2.7339, 2.7717],\n",
      "        [2.6841, 2.9724, 2.8961, 2.9037, 2.9579],\n",
      "        [2.5392, 2.8109, 2.7551, 2.6992, 2.7408],\n",
      "        [2.7713, 2.9116, 2.8749, 2.9123, 2.8809],\n",
      "        [2.6277, 2.7772, 2.6408, 2.7683, 2.7435],\n",
      "        [2.6482, 2.6889, 2.7537, 2.7591, 2.7701],\n",
      "        [2.8196, 2.9022, 2.9138, 3.0220, 2.8457],\n",
      "        [2.8048, 2.6746, 2.8116, 3.0092, 3.0497],\n",
      "        [2.5526, 2.6925, 2.7530, 2.7886, 2.7827],\n",
      "        [2.7971, 2.9767, 2.8082, 2.9251, 2.9016],\n",
      "        [2.5237, 2.7999, 2.7504, 2.7015, 2.7248],\n",
      "        [2.6612, 2.6822, 2.6767, 2.8421, 2.6863],\n",
      "        [2.5197, 2.6933, 2.7034, 2.6749, 2.6701],\n",
      "        [2.7567, 2.8833, 2.9044, 2.9132, 2.8932],\n",
      "        [2.6152, 2.9224, 2.8586, 2.6848, 2.8712],\n",
      "        [2.7497, 2.8416, 2.8436, 2.8457, 2.9313],\n",
      "        [2.7466, 3.0729, 2.9170, 2.9435, 3.0236],\n",
      "        [2.8055, 2.7917, 2.7729, 3.0736, 2.9630],\n",
      "        [2.8849, 2.9138, 2.9173, 2.9921, 2.9307],\n",
      "        [2.7889, 2.9456, 2.7357, 2.8460, 2.9133],\n",
      "        [2.6897, 2.8324, 2.6365, 2.8431, 2.7755],\n",
      "        [2.6030, 2.8098, 2.6770, 2.8420, 2.7067],\n",
      "        [2.7604, 2.6236, 2.9106, 2.8573, 2.8337],\n",
      "        [2.6473, 2.8754, 2.7089, 2.7161, 2.8148],\n",
      "        [2.9532, 2.8071, 2.9182, 3.3782, 3.2773],\n",
      "        [2.4872, 2.6836, 2.5313, 2.6910, 2.6131]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.6611, 2.6933, 2.6860, 2.8404, 2.6992],\n",
      "        [2.5678, 2.7466, 2.6427, 2.6886, 2.7089],\n",
      "        [2.7441, 2.7330, 2.8063, 2.7365, 2.7505],\n",
      "        [2.5485, 2.7008, 2.7117, 2.6939, 2.7043],\n",
      "        [2.8526, 2.9521, 2.9562, 2.9068, 2.8107],\n",
      "        [2.7872, 2.8355, 2.7947, 2.9087, 2.9533],\n",
      "        [2.6620, 2.8080, 2.6407, 2.8092, 2.7589],\n",
      "        [2.6410, 3.0269, 2.8589, 2.7828, 2.8078],\n",
      "        [2.5323, 2.6395, 2.6485, 2.6614, 2.6582],\n",
      "        [2.6021, 2.6990, 2.7305, 2.7689, 2.6855],\n",
      "        [2.5780, 2.5965, 2.6554, 2.7135, 2.6565],\n",
      "        [2.5190, 2.7777, 2.7421, 2.6858, 2.6972],\n",
      "        [2.9675, 2.9130, 2.9100, 2.9676, 2.9462],\n",
      "        [2.6471, 2.7914, 2.7533, 2.7667, 2.7938],\n",
      "        [2.9381, 2.8691, 2.8363, 2.8946, 2.9432],\n",
      "        [2.8123, 3.0989, 2.8964, 3.0848, 3.0579],\n",
      "        [2.4627, 2.6617, 2.6189, 2.5734, 2.6249],\n",
      "        [2.6957, 2.8652, 2.6737, 2.7494, 2.8074],\n",
      "        [2.8029, 2.8931, 2.8692, 2.8967, 2.9955],\n",
      "        [2.6551, 2.9396, 2.7057, 2.9184, 2.8515],\n",
      "        [2.7130, 2.6776, 2.9757, 2.8342, 2.8815],\n",
      "        [2.7542, 2.9609, 2.8785, 2.9119, 2.9973],\n",
      "        [2.7232, 2.9076, 2.8154, 2.8272, 2.7180],\n",
      "        [2.6497, 2.7222, 2.7605, 2.7825, 2.7937],\n",
      "        [2.7443, 2.7832, 2.7619, 2.9119, 2.8306],\n",
      "        [2.6320, 2.8389, 2.7768, 2.6775, 2.7147],\n",
      "        [2.7488, 3.0337, 2.8291, 2.9169, 2.9104],\n",
      "        [2.8105, 2.9511, 2.7782, 2.9582, 2.9657],\n",
      "        [2.5930, 2.7232, 2.7297, 2.6850, 2.7132],\n",
      "        [2.5036, 2.6973, 2.6318, 2.6224, 2.6620],\n",
      "        [2.4627, 2.6617, 2.6189, 2.5734, 2.6249],\n",
      "        [2.7493, 2.8661, 2.7311, 2.8270, 2.9825],\n",
      "        [2.8112, 2.9109, 2.9008, 3.0174, 2.8472],\n",
      "        [2.7792, 2.9575, 2.7688, 3.0122, 2.9156],\n",
      "        [2.9024, 2.9699, 2.8583, 3.0930, 3.0017],\n",
      "        [2.5269, 2.7177, 2.6370, 2.6443, 2.6782],\n",
      "        [2.7792, 2.9452, 2.7939, 2.9030, 2.8607],\n",
      "        [2.5997, 2.7623, 2.6447, 2.7133, 2.7364],\n",
      "        [2.5187, 2.6761, 2.5939, 2.7256, 2.6041],\n",
      "        [2.7097, 2.8682, 2.7020, 2.8495, 2.8330],\n",
      "        [2.4175, 2.6306, 2.6542, 2.6065, 2.6558],\n",
      "        [2.5628, 2.6287, 2.6780, 2.6978, 2.6633],\n",
      "        [2.6627, 2.7710, 2.6849, 2.8148, 2.8873],\n",
      "        [2.6608, 2.6584, 2.7489, 2.7633, 2.8640],\n",
      "        [2.5251, 2.7056, 2.6340, 2.6419, 2.6708],\n",
      "        [2.5232, 2.7744, 2.7397, 2.6878, 2.6994],\n",
      "        [3.0658, 3.2004, 2.9146, 2.9628, 2.9157],\n",
      "        [2.7622, 2.7572, 2.8072, 2.8375, 2.7829],\n",
      "        [2.6105, 2.7729, 2.6372, 2.7392, 2.7250],\n",
      "        [2.6606, 2.7163, 2.7884, 2.7821, 2.7899],\n",
      "        [2.5839, 2.7516, 2.6379, 2.7083, 2.7063],\n",
      "        [2.5980, 2.7172, 2.7249, 2.6948, 2.7138],\n",
      "        [2.7809, 2.8339, 2.8010, 2.8962, 2.9559],\n",
      "        [3.0520, 3.2620, 2.8082, 2.9204, 2.8902],\n",
      "        [2.8359, 2.9887, 2.9631, 2.9082, 2.7451],\n",
      "        [2.4246, 2.6302, 2.6629, 2.6088, 2.6828],\n",
      "        [2.6762, 2.9625, 2.7341, 2.9441, 2.8692],\n",
      "        [2.7933, 2.8764, 2.8464, 2.8699, 2.9485],\n",
      "        [2.6870, 2.8336, 2.6506, 2.8438, 2.7810],\n",
      "        [2.6800, 2.7166, 2.8079, 2.8038, 2.7959],\n",
      "        [2.6618, 2.7005, 2.7662, 2.7695, 2.7820],\n",
      "        [2.7106, 2.7396, 2.8591, 2.8515, 2.8527],\n",
      "        [2.6073, 2.6720, 2.7381, 2.7292, 2.7444],\n",
      "        [2.6174, 2.8344, 2.7624, 2.6596, 2.7017]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.5691, 2.7459, 2.6442, 2.6876, 2.7033],\n",
      "        [2.8319, 2.9663, 2.7907, 2.9738, 2.9746],\n",
      "        [2.5690, 2.6467, 2.6868, 2.7060, 2.6718],\n",
      "        [2.8142, 2.9558, 2.7808, 2.9628, 2.9685],\n",
      "        [3.2206, 3.3883, 2.9941, 3.0753, 2.9797],\n",
      "        [2.7972, 2.8527, 2.9094, 2.8592, 2.7314],\n",
      "        [2.6504, 2.7067, 2.7529, 2.7765, 2.7827],\n",
      "        [2.9196, 2.8390, 2.7903, 2.8689, 2.9036],\n",
      "        [2.6033, 2.7668, 2.6471, 2.7176, 2.7391],\n",
      "        [2.6033, 2.7668, 2.6471, 2.7176, 2.7391],\n",
      "        [2.7288, 2.7018, 2.9879, 2.8599, 2.9134],\n",
      "        [2.7122, 2.9390, 2.7952, 2.8769, 2.9732],\n",
      "        [2.5555, 2.7604, 2.8113, 2.7884, 2.8595],\n",
      "        [2.8821, 2.8292, 2.8208, 2.8792, 2.9089],\n",
      "        [2.6771, 2.8230, 2.6445, 2.8229, 2.7728],\n",
      "        [2.7302, 2.9855, 2.8850, 2.9038, 3.0495],\n",
      "        [2.8026, 2.8443, 2.8495, 2.8217, 2.7006],\n",
      "        [2.8508, 3.0059, 2.9379, 3.0143, 3.0278],\n",
      "        [2.8098, 2.9419, 2.8099, 2.8360, 2.8640],\n",
      "        [2.6339, 2.7625, 2.6774, 2.8006, 2.7389],\n",
      "        [2.8377, 2.9770, 2.9727, 2.8981, 2.7317],\n",
      "        [2.6752, 2.7378, 2.6532, 2.7677, 2.8700],\n",
      "        [2.6321, 2.7826, 2.6320, 2.7686, 2.7271],\n",
      "        [2.6406, 2.7526, 2.7346, 2.7730, 2.8782],\n",
      "        [2.6625, 2.6500, 2.7517, 2.7735, 2.8560],\n",
      "        [2.6727, 2.7044, 2.7827, 2.7504, 2.8153],\n",
      "        [2.7805, 2.7739, 2.8086, 2.7069, 2.6637],\n",
      "        [2.8599, 2.8293, 2.8158, 2.7805, 2.7253],\n",
      "        [2.9799, 2.9265, 2.9041, 2.9877, 2.9557],\n",
      "        [2.6140, 2.9228, 2.7590, 2.7579, 2.6879],\n",
      "        [2.8013, 2.9383, 2.8117, 2.8088, 2.8568],\n",
      "        [2.9045, 2.7942, 2.7939, 2.8463, 2.8922],\n",
      "        [2.6629, 2.6918, 2.8237, 2.8158, 2.7958],\n",
      "        [2.5492, 2.7266, 2.7503, 2.7288, 2.6802],\n",
      "        [2.5521, 2.6715, 2.7005, 2.6974, 2.6847],\n",
      "        [2.9839, 3.1500, 2.8880, 2.8995, 2.9178],\n",
      "        [2.5232, 2.7249, 2.6408, 2.7004, 2.6736],\n",
      "        [2.4764, 2.7027, 2.8242, 2.6355, 2.7926],\n",
      "        [2.8088, 2.9782, 2.8792, 2.9402, 2.8920],\n",
      "        [2.6288, 2.7592, 2.6775, 2.7067, 2.7146],\n",
      "        [2.9585, 3.1126, 2.9494, 3.2291, 3.1180],\n",
      "        [2.6701, 2.8160, 2.6466, 2.8213, 2.7711],\n",
      "        [2.6911, 2.7410, 2.7681, 2.8074, 2.8078],\n",
      "        [2.6609, 2.7906, 2.9199, 2.8283, 2.9246],\n",
      "        [2.6804, 2.6797, 2.8115, 2.8224, 2.8856],\n",
      "        [2.6270, 2.7869, 2.6393, 2.7655, 2.7319],\n",
      "        [2.7659, 2.7619, 2.8097, 2.8420, 2.7857],\n",
      "        [2.5474, 2.7232, 2.7590, 2.7248, 2.6886],\n",
      "        [2.6455, 2.7972, 2.6434, 2.7598, 2.7520],\n",
      "        [2.9675, 2.9106, 2.9361, 3.1557, 3.0672],\n",
      "        [2.7128, 2.9144, 2.8063, 2.8283, 2.7153],\n",
      "        [2.7368, 3.0043, 2.9034, 2.9195, 3.0699],\n",
      "        [2.6383, 2.8061, 2.6497, 2.7798, 2.7476],\n",
      "        [2.7466, 2.8406, 2.7886, 2.9744, 2.8213],\n",
      "        [2.6971, 2.7462, 2.7876, 2.6990, 2.6279],\n",
      "        [2.6989, 2.9423, 2.7248, 2.8630, 2.8424],\n",
      "        [2.5281, 2.8299, 2.5983, 2.7753, 2.6483],\n",
      "        [2.6144, 2.5975, 2.6423, 2.7139, 2.6355],\n",
      "        [2.6672, 2.7249, 2.7784, 2.6752, 2.5997],\n",
      "        [2.6548, 2.8853, 2.7141, 2.7249, 2.8195],\n",
      "        [2.8065, 2.9191, 2.8936, 3.0176, 2.8503],\n",
      "        [2.5242, 2.7214, 2.7156, 2.6845, 2.6777],\n",
      "        [3.2697, 3.4400, 3.0359, 3.1207, 3.0310],\n",
      "        [2.4752, 2.6635, 2.6177, 2.5912, 2.6391]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.7043, 2.7394, 2.8625, 2.9488, 3.0171],\n",
      "        [2.6155, 2.6142, 2.6579, 2.7220, 2.6504],\n",
      "        [2.5923, 2.6277, 2.6767, 2.7278, 2.6688],\n",
      "        [2.6524, 2.8144, 2.9036, 2.7434, 2.8095],\n",
      "        [2.5352, 2.6938, 2.7053, 2.6854, 2.6735],\n",
      "        [2.8072, 2.8490, 2.8518, 2.8259, 2.7032],\n",
      "        [2.7209, 2.6976, 2.7836, 2.8225, 2.7935],\n",
      "        [2.9181, 2.9564, 2.8926, 3.0972, 2.9656],\n",
      "        [2.8194, 2.8656, 2.8858, 2.9399, 2.7515],\n",
      "        [2.6540, 2.7055, 2.6222, 2.7460, 2.8464],\n",
      "        [2.7724, 2.6379, 2.9180, 2.8699, 2.8409],\n",
      "        [2.6906, 2.8222, 2.7777, 2.7727, 2.8029],\n",
      "        [2.7323, 2.9712, 2.7923, 2.9793, 2.8896],\n",
      "        [2.8889, 2.9060, 2.8920, 3.0407, 2.9396],\n",
      "        [2.6310, 2.6362, 2.7928, 2.6293, 2.8245],\n",
      "        [2.6671, 2.7109, 2.7020, 2.8359, 2.7140],\n",
      "        [2.5654, 2.7073, 2.7605, 2.8014, 2.7900],\n",
      "        [2.6032, 2.8684, 2.7478, 2.7991, 2.8974],\n",
      "        [2.7693, 2.9456, 2.7513, 2.9893, 2.8821],\n",
      "        [2.8038, 2.9572, 2.7493, 2.8629, 2.9291],\n",
      "        [2.4873, 2.5994, 2.6274, 2.6033, 2.6106],\n",
      "        [2.9706, 2.8619, 2.8878, 3.3853, 3.2575],\n",
      "        [2.6337, 2.8481, 2.6896, 2.8789, 2.7198],\n",
      "        [2.7693, 2.8959, 2.7550, 2.8980, 2.9321],\n",
      "        [2.6852, 2.8114, 2.6890, 2.8058, 2.8040],\n",
      "        [2.7687, 2.9881, 2.8933, 2.9374, 3.0162],\n",
      "        [2.8035, 2.9594, 2.7980, 2.9420, 2.8924],\n",
      "        [2.6744, 2.8222, 2.6433, 2.8176, 2.7683],\n",
      "        [2.7989, 2.8627, 2.6728, 2.9336, 2.9544],\n",
      "        [2.5314, 2.7415, 2.8650, 2.6819, 2.8580],\n",
      "        [2.7114, 2.9647, 2.8152, 2.8889, 2.9835],\n",
      "        [2.8116, 3.0553, 2.8544, 3.0249, 2.9849],\n",
      "        [2.5278, 2.7295, 2.6430, 2.7044, 2.6761],\n",
      "        [2.5108, 2.6016, 2.6596, 2.6343, 2.5927],\n",
      "        [2.5985, 2.8264, 2.7614, 2.6516, 2.6927],\n",
      "        [2.7016, 2.7510, 2.7899, 2.7030, 2.6304],\n",
      "        [2.9496, 2.8179, 2.9173, 3.3785, 3.2770],\n",
      "        [2.5893, 2.8618, 2.6393, 2.7735, 2.6665],\n",
      "        [2.4922, 2.6873, 2.6349, 2.5977, 2.6502],\n",
      "        [2.6558, 2.6962, 2.7587, 2.7687, 2.7715],\n",
      "        [2.6413, 2.7801, 2.6659, 2.7961, 2.7333],\n",
      "        [2.8341, 2.8570, 2.9496, 2.9001, 2.7244],\n",
      "        [2.7284, 2.9099, 2.7526, 2.8956, 2.8358],\n",
      "        [2.3861, 2.5997, 2.6459, 2.5858, 2.6609],\n",
      "        [2.6079, 2.7364, 2.6619, 2.8177, 2.7382],\n",
      "        [2.8002, 2.9364, 2.8046, 2.7884, 2.8504],\n",
      "        [3.0132, 2.9639, 2.9093, 3.0143, 2.9978],\n",
      "        [2.7763, 2.7655, 2.8287, 2.8630, 2.8048],\n",
      "        [2.7372, 3.0026, 2.8985, 2.9122, 3.0672],\n",
      "        [3.0223, 3.0241, 2.9439, 3.0751, 3.0447],\n",
      "        [2.9765, 2.9388, 2.9780, 3.1376, 3.0202],\n",
      "        [2.5248, 2.7457, 2.7287, 2.6915, 2.6797],\n",
      "        [2.8328, 3.0616, 2.8636, 3.0545, 2.9921],\n",
      "        [2.5478, 2.6835, 2.7084, 2.6938, 2.6767],\n",
      "        [2.7575, 2.9578, 2.7585, 2.8648, 2.8658],\n",
      "        [2.6960, 3.0739, 2.7790, 3.0022, 2.9625],\n",
      "        [2.9419, 2.7909, 2.8132, 3.2522, 3.0888],\n",
      "        [2.6603, 2.8134, 2.6473, 2.8001, 2.7634],\n",
      "        [2.7685, 3.0278, 2.9360, 2.9272, 2.9897],\n",
      "        [2.5484, 2.7729, 2.8235, 2.7299, 2.8185],\n",
      "        [2.5587, 2.7858, 2.6244, 2.7595, 2.6944],\n",
      "        [2.6275, 2.7819, 2.6399, 2.7503, 2.7419],\n",
      "        [2.6103, 2.9386, 2.8160, 2.8367, 2.8984],\n",
      "        [2.8490, 2.8924, 2.8785, 2.9756, 2.8411]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.7698, 2.8471, 2.6717, 2.8424, 2.9185],\n",
      "        [2.6548, 2.7137, 2.7609, 2.7878, 2.7883],\n",
      "        [2.8741, 2.9840, 2.8038, 2.9113, 3.0193],\n",
      "        [2.7306, 2.8569, 2.7121, 2.8496, 2.8982],\n",
      "        [2.6705, 2.8257, 2.7212, 2.8664, 2.8273],\n",
      "        [2.5379, 2.7443, 2.7304, 2.7043, 2.7017],\n",
      "        [2.7711, 2.9656, 2.8852, 2.9339, 2.9658],\n",
      "        [2.6411, 2.7914, 2.6363, 2.7761, 2.7319],\n",
      "        [2.7728, 2.7760, 2.8100, 2.8422, 2.7939],\n",
      "        [2.8484, 2.7454, 2.7709, 3.1882, 2.9946],\n",
      "        [2.7887, 2.7994, 2.8325, 2.9486, 2.7536],\n",
      "        [2.9148, 2.8562, 2.9178, 3.0618, 2.9427],\n",
      "        [2.5857, 2.6150, 2.6695, 2.7285, 2.6543],\n",
      "        [2.7423, 2.7919, 2.7595, 2.8628, 2.9128],\n",
      "        [2.5650, 2.7694, 2.8158, 2.7961, 2.8644],\n",
      "        [2.6075, 2.7746, 2.6414, 2.7304, 2.7259],\n",
      "        [2.5393, 2.7309, 2.6436, 2.6560, 2.6857],\n",
      "        [2.9709, 2.8268, 2.9284, 3.3941, 3.2867],\n",
      "        [2.6099, 2.6021, 2.7813, 2.5777, 2.8180],\n",
      "        [2.8126, 2.8610, 2.8082, 2.9282, 2.9693],\n",
      "        [2.5411, 2.7108, 2.7174, 2.6939, 2.6792],\n",
      "        [2.6785, 3.0272, 2.7903, 2.9371, 2.9422],\n",
      "        [2.8033, 2.8668, 2.6750, 2.9373, 2.9568],\n",
      "        [2.5570, 2.7534, 2.7666, 2.7348, 2.6987],\n",
      "        [2.6041, 2.9135, 2.7393, 2.7346, 2.6740],\n",
      "        [2.6856, 2.9057, 2.7555, 2.9404, 2.7994],\n",
      "        [2.5307, 2.7530, 2.7309, 2.6949, 2.6870],\n",
      "        [2.9470, 2.9998, 2.8705, 3.0233, 3.0749],\n",
      "        [2.6099, 2.6021, 2.7813, 2.5777, 2.8180],\n",
      "        [2.6460, 2.9293, 2.7748, 2.7833, 2.6880],\n",
      "        [2.6581, 2.7072, 2.7509, 2.7709, 2.7747],\n",
      "        [2.8364, 2.7398, 2.7033, 2.7378, 2.8526],\n",
      "        [2.6774, 2.6688, 2.7867, 2.7923, 2.8707],\n",
      "        [2.6934, 2.7217, 2.8271, 2.8393, 2.8420],\n",
      "        [2.6261, 2.6121, 2.6478, 2.7262, 2.6464],\n",
      "        [2.6270, 2.6239, 2.6629, 2.7255, 2.6591],\n",
      "        [2.5898, 2.9225, 2.7679, 2.6190, 2.8816],\n",
      "        [2.8265, 2.8764, 2.8514, 2.8621, 2.9715],\n",
      "        [2.9155, 2.9841, 2.8657, 3.1063, 3.0094],\n",
      "        [2.9842, 2.8035, 2.8288, 3.3202, 3.1531],\n",
      "        [2.6807, 2.6516, 2.7414, 2.6989, 2.7022],\n",
      "        [2.9003, 2.8383, 2.8821, 3.0078, 2.9224],\n",
      "        [2.9394, 2.6843, 2.8242, 3.1942, 3.1674],\n",
      "        [2.8159, 2.9517, 2.8111, 2.8623, 2.8680],\n",
      "        [2.6978, 2.8469, 2.6446, 2.8528, 2.7874],\n",
      "        [2.5563, 2.8196, 2.8903, 2.7537, 2.8344],\n",
      "        [2.7913, 2.9339, 2.7793, 2.9517, 2.8861],\n",
      "        [2.5377, 2.8057, 2.7529, 2.7115, 2.7227],\n",
      "        [2.6503, 2.7245, 2.8512, 2.6869, 2.9132],\n",
      "        [2.6981, 2.8909, 2.7397, 2.8774, 2.8026],\n",
      "        [2.5502, 2.9521, 2.7983, 2.7451, 2.9391],\n",
      "        [2.9452, 3.0021, 2.8849, 3.1243, 3.0367],\n",
      "        [2.9084, 2.8387, 2.9003, 3.0375, 2.9243],\n",
      "        [2.7693, 2.7638, 2.9205, 2.9274, 2.8423],\n",
      "        [2.6298, 2.8480, 2.7692, 2.6722, 2.7094],\n",
      "        [2.5919, 2.8554, 2.7424, 2.7763, 2.9259],\n",
      "        [2.6429, 2.7424, 2.7216, 2.7217, 2.7531],\n",
      "        [2.5522, 2.6877, 2.7105, 2.6974, 2.6790],\n",
      "        [2.7649, 2.9536, 2.8848, 2.9324, 2.9458],\n",
      "        [2.6815, 2.6764, 2.7971, 2.7931, 2.8541],\n",
      "        [2.5379, 2.7443, 2.7304, 2.7043, 2.7017],\n",
      "        [2.6323, 2.7461, 2.8432, 2.8724, 2.9383],\n",
      "        [2.6778, 2.7009, 2.6860, 2.8582, 2.6957],\n",
      "        [2.5317, 2.7913, 2.7488, 2.6979, 2.7049]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.7685, 2.8994, 2.8961, 2.8987, 2.8950],\n",
      "        [2.8818, 2.9133, 2.9356, 2.8814, 2.7406],\n",
      "        [2.7435, 2.8920, 2.7133, 2.8677, 2.8683],\n",
      "        [2.5926, 2.6487, 2.6892, 2.7231, 2.6792],\n",
      "        [2.6961, 2.6489, 2.7371, 2.6898, 2.6939],\n",
      "        [2.7606, 2.8541, 2.7953, 2.9858, 2.8285],\n",
      "        [2.9381, 2.8411, 2.9063, 3.0061, 2.9501],\n",
      "        [2.6550, 2.6577, 2.7709, 2.7619, 2.7467],\n",
      "        [2.6038, 2.7529, 2.6490, 2.7771, 2.6956],\n",
      "        [2.7914, 2.9362, 2.8659, 3.0055, 2.8606],\n",
      "        [2.8549, 3.0792, 2.8806, 3.0749, 3.0104],\n",
      "        [2.5652, 2.7661, 2.6730, 2.7828, 2.7038],\n",
      "        [2.5213, 2.6264, 2.6773, 2.6687, 2.6025],\n",
      "        [2.7026, 2.6633, 2.7528, 2.6986, 2.7098],\n",
      "        [2.6685, 2.7181, 2.7618, 2.7806, 2.7851],\n",
      "        [2.9498, 2.9014, 2.9372, 3.0980, 2.9793],\n",
      "        [2.5941, 2.6812, 2.5860, 2.7760, 2.6099],\n",
      "        [2.5761, 2.7740, 2.6626, 2.7803, 2.7077],\n",
      "        [3.0918, 3.2226, 2.8194, 2.9846, 2.8783],\n",
      "        [2.9932, 2.9400, 2.9106, 3.0001, 2.9634],\n",
      "        [2.6279, 2.6085, 2.7348, 2.7551, 2.7880],\n",
      "        [2.3899, 2.6003, 2.6416, 2.5903, 2.6535],\n",
      "        [2.6815, 2.8107, 2.6829, 2.7926, 2.7972],\n",
      "        [2.7189, 2.8784, 2.6679, 2.7704, 2.8124],\n",
      "        [2.7463, 2.8636, 2.9319, 2.8852, 2.9084],\n",
      "        [2.8554, 2.8313, 2.8177, 2.7803, 2.7318],\n",
      "        [2.7391, 2.9473, 2.8066, 2.8018, 2.8791],\n",
      "        [2.7277, 3.0059, 2.8482, 2.9148, 3.0008],\n",
      "        [2.6501, 2.7953, 2.6401, 2.7846, 2.7320],\n",
      "        [2.5453, 2.7960, 2.6985, 2.7301, 2.8638],\n",
      "        [2.7126, 2.9547, 2.7315, 2.8740, 2.8494],\n",
      "        [2.6659, 2.7412, 2.7672, 2.7987, 2.8021],\n",
      "        [2.5875, 2.9142, 2.8528, 2.7779, 2.9344],\n",
      "        [2.5937, 2.6270, 2.6723, 2.7298, 2.6659],\n",
      "        [2.5113, 2.7032, 2.5465, 2.7266, 2.6239],\n",
      "        [2.6247, 2.6443, 2.6962, 2.7447, 2.6680],\n",
      "        [2.9155, 3.0163, 2.8485, 2.9755, 3.0610],\n",
      "        [2.7959, 2.8657, 2.8305, 2.8185, 2.6415],\n",
      "        [2.7412, 2.9795, 2.7967, 2.9864, 2.8941],\n",
      "        [2.5692, 2.8332, 2.9064, 2.7781, 2.8454],\n",
      "        [2.5822, 2.7585, 2.6504, 2.6984, 2.7102],\n",
      "        [2.7965, 2.9622, 2.8030, 2.9186, 2.8706],\n",
      "        [2.8326, 3.0674, 2.8597, 3.0455, 2.9929],\n",
      "        [2.6630, 2.7429, 2.7670, 2.7964, 2.7930],\n",
      "        [2.7495, 2.9643, 2.9258, 2.9203, 2.8435],\n",
      "        [2.5238, 2.7140, 2.6377, 2.6388, 2.6701],\n",
      "        [2.5742, 2.7953, 2.6324, 2.7689, 2.7026],\n",
      "        [2.6986, 2.8439, 2.6453, 2.8474, 2.7805],\n",
      "        [2.5888, 2.7439, 2.6181, 2.7802, 2.7096],\n",
      "        [2.6777, 2.7162, 2.8334, 2.8281, 2.8185],\n",
      "        [2.7677, 3.0615, 2.8453, 2.9216, 2.9204],\n",
      "        [2.7780, 2.7697, 2.8249, 2.8565, 2.8008],\n",
      "        [2.6835, 2.7437, 2.7949, 2.8029, 2.7998],\n",
      "        [2.4789, 2.6870, 2.6589, 2.6826, 2.6892],\n",
      "        [2.6740, 2.7858, 2.7384, 2.7760, 2.7833],\n",
      "        [2.6801, 2.7380, 2.7851, 2.6859, 2.6067],\n",
      "        [2.9045, 3.0094, 2.8418, 2.9688, 3.0661],\n",
      "        [2.6402, 2.7996, 2.6457, 2.7762, 2.7390],\n",
      "        [2.8537, 3.0478, 2.8786, 2.8171, 2.9487],\n",
      "        [2.9602, 2.9311, 2.8669, 3.1022, 2.9908],\n",
      "        [2.6382, 2.7646, 2.6887, 2.7166, 2.7132],\n",
      "        [2.5741, 2.7681, 2.7028, 2.8455, 2.6799],\n",
      "        [2.8812, 3.0550, 3.0219, 2.9914, 2.8404],\n",
      "        [2.9511, 3.0037, 2.8726, 3.0268, 3.0771]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.7973, 2.8827, 2.7030, 2.9203, 2.9266],\n",
      "        [2.5605, 2.6952, 2.7144, 2.7045, 2.6831],\n",
      "        [2.8174, 2.8104, 2.7541, 3.0448, 2.9351],\n",
      "        [2.6750, 2.8213, 2.6544, 2.8110, 2.7734],\n",
      "        [2.8240, 2.8740, 2.8558, 2.8473, 2.6965],\n",
      "        [2.6891, 2.6351, 2.7206, 2.6744, 2.6772],\n",
      "        [2.8013, 2.9796, 2.7803, 3.0321, 2.9281],\n",
      "        [2.5277, 2.5686, 2.6433, 2.7243, 2.6505],\n",
      "        [2.6606, 2.7312, 2.8539, 2.6927, 2.9290],\n",
      "        [2.7004, 2.8493, 2.6519, 2.8509, 2.7841],\n",
      "        [2.5493, 2.7183, 2.7214, 2.7009, 2.6833],\n",
      "        [2.6934, 2.7285, 2.8268, 2.8227, 2.8118],\n",
      "        [2.6170, 2.7747, 2.6420, 2.7350, 2.7199],\n",
      "        [2.5215, 2.8009, 2.5581, 2.7519, 2.6134],\n",
      "        [2.7058, 2.9797, 2.6983, 2.8374, 2.8058],\n",
      "        [2.6550, 2.7065, 2.7794, 2.8035, 2.8442],\n",
      "        [2.6920, 2.8329, 2.6477, 2.8356, 2.7735],\n",
      "        [2.7031, 2.8341, 2.7838, 2.7839, 2.8095],\n",
      "        [2.5392, 2.7753, 2.7390, 2.6999, 2.6958],\n",
      "        [2.6054, 2.9671, 2.7599, 2.8455, 2.9065],\n",
      "        [2.7976, 2.8134, 2.7532, 3.0046, 2.9109],\n",
      "        [2.6714, 2.7381, 2.7727, 2.8040, 2.8101],\n",
      "        [2.8009, 2.9232, 2.7543, 2.8746, 2.9833],\n",
      "        [2.8189, 3.0045, 2.7706, 2.8559, 2.9272],\n",
      "        [2.6779, 2.6622, 2.7456, 2.7103, 2.7110],\n",
      "        [2.9767, 3.1300, 2.9587, 3.2460, 3.1273],\n",
      "        [2.8179, 3.0899, 2.9628, 2.9883, 3.0408],\n",
      "        [2.6977, 2.7137, 2.7944, 2.8101, 2.8521],\n",
      "        [2.6805, 2.7086, 2.8322, 2.8304, 2.8047],\n",
      "        [2.4877, 2.6745, 2.6271, 2.5917, 2.6314],\n",
      "        [2.6768, 2.7251, 2.7677, 2.7820, 2.7851],\n",
      "        [2.8065, 2.9710, 2.7897, 2.8810, 2.8919],\n",
      "        [2.9253, 3.0235, 2.8603, 2.9962, 3.0523],\n",
      "        [2.9736, 3.0800, 2.9500, 3.0345, 3.1220],\n",
      "        [2.5906, 2.6453, 2.6870, 2.7237, 2.6721],\n",
      "        [2.8474, 2.8694, 2.9562, 2.9113, 2.7309],\n",
      "        [2.6974, 2.9838, 2.7452, 2.9634, 2.8809],\n",
      "        [2.6796, 2.7034, 2.7826, 2.7846, 2.7740],\n",
      "        [2.5154, 2.6417, 2.6411, 2.6343, 2.6420],\n",
      "        [2.6870, 3.0350, 2.7946, 2.9443, 2.9464],\n",
      "        [2.6904, 2.7213, 2.7910, 2.7653, 2.8245],\n",
      "        [2.3990, 2.6112, 2.6519, 2.5963, 2.6671],\n",
      "        [2.7089, 2.7579, 2.7765, 2.8224, 2.8169],\n",
      "        [2.9347, 3.0892, 2.7790, 2.8953, 2.9061],\n",
      "        [2.6344, 2.6196, 2.6517, 2.7333, 2.6505],\n",
      "        [2.6713, 2.7676, 2.7589, 2.7739, 2.9256],\n",
      "        [2.7635, 2.8450, 2.7363, 2.8992, 2.8544],\n",
      "        [2.6713, 3.0104, 2.8617, 2.8334, 2.7718],\n",
      "        [2.8844, 2.7562, 2.7973, 3.1872, 3.0255],\n",
      "        [2.7417, 2.7159, 2.9019, 2.9050, 2.8334],\n",
      "        [2.5551, 2.7534, 2.7662, 2.7283, 2.7071],\n",
      "        [2.9797, 2.8986, 2.8634, 2.9514, 2.9641],\n",
      "        [2.6413, 2.9546, 2.8417, 2.8560, 2.9296],\n",
      "        [2.6051, 2.6394, 2.6828, 2.7385, 2.6751],\n",
      "        [2.7898, 2.6786, 2.9266, 2.8805, 2.8592],\n",
      "        [2.7423, 2.8117, 2.7833, 2.9167, 2.8255],\n",
      "        [2.4389, 2.6514, 2.6649, 2.6255, 2.6672],\n",
      "        [2.6810, 2.6743, 2.7629, 2.7926, 2.8704],\n",
      "        [2.7628, 3.0571, 2.9233, 2.9368, 3.0053],\n",
      "        [2.7061, 2.8544, 2.6487, 2.8598, 2.7916],\n",
      "        [2.8560, 2.8942, 2.8938, 3.0237, 2.8987],\n",
      "        [3.1033, 2.8567, 2.9685, 3.4387, 3.3601],\n",
      "        [2.6587, 2.7323, 2.8552, 2.6942, 2.9175],\n",
      "        [2.5929, 2.7411, 2.7757, 2.7651, 2.6811]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.4819, 2.6943, 2.6668, 2.6740, 2.6980],\n",
      "        [2.7597, 2.7161, 2.9791, 2.8758, 2.9185],\n",
      "        [2.7858, 2.9152, 2.9212, 2.9403, 2.9089],\n",
      "        [2.8785, 2.7138, 2.7029, 2.7473, 2.8499],\n",
      "        [2.7282, 3.0407, 2.8793, 2.9228, 2.9990],\n",
      "        [2.5192, 2.6449, 2.6429, 2.6376, 2.6437],\n",
      "        [2.7217, 2.8835, 2.6750, 2.7779, 2.8213],\n",
      "        [2.4865, 2.6852, 2.6309, 2.5952, 2.6381],\n",
      "        [2.8113, 2.9242, 2.8904, 2.8624, 2.8926],\n",
      "        [2.7123, 2.7470, 2.8562, 2.8546, 2.8486],\n",
      "        [2.8640, 2.9258, 2.9324, 2.9147, 2.9852],\n",
      "        [2.6347, 2.7110, 2.8753, 2.6358, 2.9212],\n",
      "        [2.7121, 2.8578, 2.6634, 2.8662, 2.7949],\n",
      "        [2.9070, 3.0156, 2.9042, 2.9846, 3.0410],\n",
      "        [2.9487, 2.9507, 2.8695, 2.9471, 2.9531],\n",
      "        [2.7689, 3.0842, 2.8947, 2.9622, 3.0841],\n",
      "        [2.6799, 2.8254, 2.6542, 2.7949, 2.7713],\n",
      "        [2.6030, 2.9558, 2.8296, 2.8238, 2.9394],\n",
      "        [2.6528, 2.6359, 2.7559, 2.7790, 2.8011],\n",
      "        [2.5493, 2.7293, 2.6461, 2.6639, 2.6842],\n",
      "        [2.8117, 2.9595, 2.7781, 2.9819, 3.0431],\n",
      "        [2.5703, 2.7464, 2.7604, 2.7470, 2.6911],\n",
      "        [2.5992, 2.9183, 2.7295, 2.7230, 2.6760],\n",
      "        [3.0304, 2.9418, 2.9818, 3.1786, 3.0684],\n",
      "        [2.5951, 2.6545, 2.6874, 2.7286, 2.6764],\n",
      "        [2.6392, 2.6347, 2.6687, 2.7360, 2.6650],\n",
      "        [2.7755, 2.8146, 2.7991, 2.8500, 2.7982],\n",
      "        [2.6839, 2.7260, 2.7099, 2.8501, 2.7222],\n",
      "        [2.7744, 2.8616, 2.7390, 2.8515, 2.9898],\n",
      "        [2.4955, 2.6826, 2.6274, 2.6088, 2.6497],\n",
      "        [2.5271, 2.6162, 2.6673, 2.6481, 2.6008],\n",
      "        [2.7051, 2.8441, 2.6445, 2.8471, 2.7740],\n",
      "        [2.6110, 2.8129, 2.6784, 2.8439, 2.7149],\n",
      "        [2.8461, 2.6860, 2.7053, 2.7743, 2.8010],\n",
      "        [2.6853, 2.6799, 2.7761, 2.7963, 2.8705],\n",
      "        [2.9576, 2.9084, 2.9412, 3.1058, 2.9831],\n",
      "        [2.6284, 2.8384, 2.6909, 2.8709, 2.7246],\n",
      "        [2.6807, 2.7284, 2.7697, 2.7854, 2.7869],\n",
      "        [2.8592, 2.9983, 2.9840, 2.9165, 2.7428],\n",
      "        [2.5723, 2.6931, 2.7323, 2.7287, 2.6629],\n",
      "        [2.9206, 2.9620, 2.9118, 3.0788, 2.9324],\n",
      "        [2.8054, 2.9830, 2.7823, 3.0357, 2.9300],\n",
      "        [2.6678, 2.7284, 2.7588, 2.7855, 2.7835],\n",
      "        [2.8282, 2.9623, 2.8171, 2.8730, 2.8740],\n",
      "        [2.6455, 2.9412, 2.7775, 2.7854, 2.6920],\n",
      "        [2.8254, 2.8752, 2.9372, 2.8922, 2.7808],\n",
      "        [2.6025, 2.6848, 2.5920, 2.7805, 2.6245],\n",
      "        [2.5577, 2.7055, 2.7163, 2.7052, 2.6829],\n",
      "        [2.7191, 2.7577, 2.8495, 2.8592, 2.8494],\n",
      "        [2.5886, 2.7995, 2.6905, 2.7278, 2.7690],\n",
      "        [2.7648, 2.8560, 2.8713, 2.8826, 2.8349],\n",
      "        [2.7693, 2.7578, 2.8192, 2.7594, 2.7641],\n",
      "        [2.6556, 3.0245, 2.7516, 2.9659, 2.9038],\n",
      "        [3.0288, 3.0139, 2.9186, 3.0435, 3.0112],\n",
      "        [2.9781, 2.8695, 2.8302, 2.9349, 2.9375],\n",
      "        [2.6094, 2.6768, 2.7137, 2.7363, 2.6791],\n",
      "        [2.6901, 2.7117, 2.6918, 2.8686, 2.7016],\n",
      "        [2.8056, 2.9377, 2.9089, 2.9332, 2.9439],\n",
      "        [2.7005, 2.8419, 2.6576, 2.8455, 2.7839],\n",
      "        [2.8387, 2.8877, 2.8574, 2.8735, 2.9778],\n",
      "        [2.7883, 3.0115, 2.9037, 2.9631, 3.0238],\n",
      "        [2.7050, 3.0767, 2.8297, 2.9921, 2.9809],\n",
      "        [2.8151, 2.8772, 2.6812, 2.9479, 2.9627],\n",
      "        [3.0742, 3.2283, 2.9491, 2.9721, 2.9892]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.9498, 2.6941, 2.8424, 3.1932, 3.1537],\n",
      "        [2.6820, 2.6727, 2.7437, 2.7789, 2.8702],\n",
      "        [2.8076, 2.9842, 2.7834, 3.0381, 2.9298],\n",
      "        [2.6397, 2.8011, 2.6487, 2.7691, 2.7429],\n",
      "        [2.6839, 2.8090, 2.7564, 2.7393, 2.7930],\n",
      "        [2.9439, 2.9632, 2.9462, 3.0997, 3.0058],\n",
      "        [2.6875, 2.9695, 2.7248, 2.9442, 2.8667],\n",
      "        [2.8596, 2.8480, 2.8852, 2.9878, 2.8759],\n",
      "        [2.5898, 2.7712, 2.8197, 2.7926, 2.8666],\n",
      "        [2.7197, 2.8792, 2.6426, 2.7688, 2.8036],\n",
      "        [2.7828, 2.7287, 2.9839, 2.9050, 2.9345],\n",
      "        [2.7561, 2.9947, 2.8781, 2.9077, 2.8557],\n",
      "        [2.7395, 3.0165, 2.8543, 2.9253, 3.0074],\n",
      "        [2.6005, 2.7474, 2.7793, 2.7717, 2.6856],\n",
      "        [2.8092, 2.9861, 2.7841, 3.0389, 2.9328],\n",
      "        [2.8877, 3.0175, 2.8866, 2.9543, 3.0360],\n",
      "        [2.9318, 2.9985, 2.8740, 3.1209, 3.0182],\n",
      "        [2.7511, 2.9904, 2.8771, 2.9060, 2.8459],\n",
      "        [2.8092, 2.9861, 2.7841, 3.0389, 2.9328],\n",
      "        [2.7147, 2.9183, 2.7758, 2.8140, 2.8692],\n",
      "        [2.6035, 2.8624, 2.7490, 2.7845, 2.9237],\n",
      "        [3.0174, 3.1557, 2.8043, 2.9354, 2.9061],\n",
      "        [2.7208, 2.8710, 2.6411, 2.7709, 2.8001],\n",
      "        [2.4642, 2.6726, 2.6681, 2.6520, 2.6791],\n",
      "        [2.7239, 2.7885, 2.8169, 2.7339, 2.6457],\n",
      "        [2.6117, 2.9296, 2.7699, 2.6179, 2.8614],\n",
      "        [2.5567, 2.7245, 2.7249, 2.7074, 2.6877],\n",
      "        [2.5857, 2.7778, 2.7085, 2.8554, 2.6861],\n",
      "        [2.7490, 2.8832, 2.7549, 2.8914, 2.8976],\n",
      "        [2.7971, 2.9540, 2.7737, 2.9070, 2.8944],\n",
      "        [2.6759, 2.6996, 2.7885, 2.7929, 2.7730],\n",
      "        [2.7886, 2.7902, 2.8177, 2.8560, 2.8027],\n",
      "        [2.8291, 2.8783, 2.9391, 2.8954, 2.7834],\n",
      "        [2.8857, 3.1167, 2.8819, 3.0684, 3.0851],\n",
      "        [2.9968, 2.9108, 2.8613, 2.9434, 2.9280],\n",
      "        [2.7613, 2.9859, 2.8400, 2.8196, 2.8979],\n",
      "        [2.7143, 2.9381, 2.8084, 2.8330, 2.7140],\n",
      "        [2.7597, 2.9550, 2.8137, 2.7989, 2.9056],\n",
      "        [3.0095, 2.9442, 2.9654, 3.0331, 3.0107],\n",
      "        [2.9047, 2.9113, 2.9034, 3.0327, 2.9447],\n",
      "        [2.6243, 3.0432, 2.8865, 2.8121, 2.8010],\n",
      "        [2.6492, 2.7817, 2.7392, 2.8343, 2.8227],\n",
      "        [2.6744, 2.7643, 2.8541, 2.7892, 2.8923],\n",
      "        [2.6354, 2.9940, 2.8529, 2.8638, 2.9779],\n",
      "        [2.6738, 2.8383, 2.6574, 2.8161, 2.7727],\n",
      "        [2.8327, 2.9603, 2.8883, 2.8413, 2.9120],\n",
      "        [2.9031, 2.7079, 2.8389, 3.1326, 3.1187],\n",
      "        [2.8923, 3.0435, 3.0114, 2.9911, 2.8166],\n",
      "        [2.6801, 2.9081, 2.7265, 2.7469, 2.8333],\n",
      "        [2.6045, 2.6807, 2.5941, 2.7867, 2.6720],\n",
      "        [2.6492, 2.9443, 2.7794, 2.7885, 2.6946],\n",
      "        [2.8263, 2.8414, 2.9347, 2.8702, 2.6886],\n",
      "        [2.6744, 2.7234, 2.6322, 2.7628, 2.8570],\n",
      "        [2.5463, 2.7023, 2.6071, 2.7502, 2.6193],\n",
      "        [2.6876, 2.7290, 2.7116, 2.8532, 2.7249],\n",
      "        [2.5540, 2.8577, 2.6124, 2.7837, 2.6602],\n",
      "        [2.8199, 2.9428, 2.8978, 2.9499, 2.8766],\n",
      "        [2.7360, 2.9919, 2.7828, 2.9875, 2.8977],\n",
      "        [2.6931, 2.8356, 2.8015, 2.7903, 2.7141],\n",
      "        [2.6849, 2.6759, 2.7452, 2.7841, 2.8719],\n",
      "        [2.9340, 2.9383, 2.9308, 3.0529, 2.8561],\n",
      "        [2.8254, 2.8998, 2.7032, 2.9591, 2.9557],\n",
      "        [2.5528, 2.7757, 2.7431, 2.7086, 2.6987],\n",
      "        [2.7767, 2.7705, 2.8248, 2.7711, 2.7609]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.8806, 3.0516, 2.7780, 2.8891, 2.9257],\n",
      "        [2.8199, 2.8106, 2.8165, 2.7453, 2.6887],\n",
      "        [2.8311, 2.8003, 2.8780, 2.9415, 2.8553],\n",
      "        [2.7665, 3.0329, 2.9197, 2.9450, 3.0872],\n",
      "        [2.8292, 3.0032, 2.8272, 2.9691, 2.9195],\n",
      "        [2.5503, 2.6572, 2.6588, 2.6738, 2.6650],\n",
      "        [2.6617, 2.8128, 2.6519, 2.7809, 2.7563],\n",
      "        [2.6215, 2.9918, 2.7861, 2.8560, 2.9421],\n",
      "        [2.6765, 2.7520, 2.7730, 2.8068, 2.7993],\n",
      "        [2.7219, 2.8649, 2.6701, 2.8707, 2.8054],\n",
      "        [2.7806, 2.8368, 2.9076, 2.9284, 2.8347],\n",
      "        [2.8353, 2.9686, 2.8215, 2.8789, 2.8800],\n",
      "        [2.9696, 2.9004, 2.8532, 2.9258, 2.9646],\n",
      "        [2.7867, 2.8439, 2.9115, 2.9222, 2.8483],\n",
      "        [2.7643, 2.8344, 2.8075, 2.8640, 2.8995],\n",
      "        [2.6167, 2.9769, 2.7664, 2.8549, 2.9144],\n",
      "        [2.6706, 2.9288, 2.8266, 2.7316, 2.8760],\n",
      "        [2.8313, 2.9651, 2.8008, 2.9656, 2.9062],\n",
      "        [2.6512, 2.7684, 2.5609, 2.8490, 2.6318],\n",
      "        [2.8196, 2.9745, 2.9018, 2.8826, 2.7646],\n",
      "        [2.7537, 2.8217, 2.7897, 2.9263, 2.8336],\n",
      "        [2.9176, 2.9299, 2.9074, 3.0629, 2.9614],\n",
      "        [2.7030, 2.8424, 2.6540, 2.8449, 2.7814],\n",
      "        [2.7845, 2.6411, 2.9222, 2.8715, 2.8314],\n",
      "        [3.0248, 3.1101, 2.9407, 3.2781, 3.1292],\n",
      "        [2.6929, 2.7298, 2.8417, 2.8410, 2.8283],\n",
      "        [2.5972, 2.8660, 2.6442, 2.7967, 2.6804],\n",
      "        [2.6963, 2.8332, 2.6482, 2.8296, 2.7655],\n",
      "        [2.7933, 2.9374, 2.8661, 2.8869, 2.7612],\n",
      "        [2.8010, 2.9421, 2.9185, 2.9336, 2.8829],\n",
      "        [2.8133, 2.8371, 2.9143, 2.8462, 2.6857],\n",
      "        [2.8326, 2.9156, 2.9029, 2.9576, 2.8173],\n",
      "        [2.8621, 2.7017, 2.7147, 2.7689, 2.8360],\n",
      "        [2.6579, 2.7949, 2.9237, 2.8199, 2.9200],\n",
      "        [2.6706, 2.9288, 2.8266, 2.7316, 2.8760],\n",
      "        [2.8884, 3.0556, 2.9960, 2.9723, 2.8072],\n",
      "        [2.8523, 2.8788, 2.8973, 2.9725, 2.7468],\n",
      "        [2.5946, 2.6593, 2.6948, 2.7262, 2.6826],\n",
      "        [2.5261, 2.6511, 2.6472, 2.6434, 2.6495],\n",
      "        [2.6796, 2.9209, 2.8120, 2.7422, 2.8751],\n",
      "        [2.6086, 2.6402, 2.6804, 2.7427, 2.6756],\n",
      "        [2.7110, 2.6623, 2.7452, 2.7026, 2.7036],\n",
      "        [2.6758, 2.7845, 2.7218, 2.8622, 2.8066],\n",
      "        [2.6036, 2.7569, 2.6262, 2.7929, 2.7191],\n",
      "        [2.8175, 2.9812, 2.9161, 2.8723, 2.7843],\n",
      "        [2.8478, 2.9217, 2.8730, 2.9285, 2.9900],\n",
      "        [2.6483, 2.7776, 2.8725, 2.8108, 2.8814],\n",
      "        [2.9990, 2.9452, 2.9272, 2.9994, 2.9681],\n",
      "        [2.6794, 2.8222, 2.7704, 2.7953, 2.8139],\n",
      "        [2.8354, 2.8928, 2.8620, 2.8585, 2.6919],\n",
      "        [2.5560, 2.8553, 2.6121, 2.7987, 2.6641],\n",
      "        [2.8066, 2.9498, 2.8744, 3.0191, 2.8708],\n",
      "        [2.5737, 2.7101, 2.7186, 2.7170, 2.7031],\n",
      "        [2.6391, 2.6212, 2.7425, 2.7628, 2.8032],\n",
      "        [2.5341, 2.6224, 2.6715, 2.6539, 2.6067],\n",
      "        [2.6403, 2.6351, 2.7979, 2.6189, 2.8350],\n",
      "        [2.6839, 2.7652, 2.7843, 2.8135, 2.8211],\n",
      "        [2.6633, 2.8125, 2.6603, 2.8003, 2.7650],\n",
      "        [2.6852, 2.9126, 2.7943, 2.7514, 2.8690],\n",
      "        [2.6949, 2.6791, 2.7758, 2.8049, 2.8752],\n",
      "        [2.8836, 2.9956, 2.8077, 2.9284, 3.0288],\n",
      "        [2.6141, 2.7723, 2.6523, 2.7291, 2.7203],\n",
      "        [2.6128, 2.6328, 2.6811, 2.7434, 2.6734],\n",
      "        [3.1471, 3.3043, 2.9282, 3.0249, 2.9240]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.6882, 2.9148, 2.7317, 2.7540, 2.8410],\n",
      "        [3.0296, 3.1136, 2.9434, 3.2825, 3.1334],\n",
      "        [2.6666, 2.7625, 2.7342, 2.7420, 2.7692],\n",
      "        [2.7216, 2.8671, 2.6574, 2.8731, 2.8037],\n",
      "        [2.5707, 2.7662, 2.7750, 2.7418, 2.7189],\n",
      "        [2.8210, 3.0546, 2.8244, 2.7476, 2.9159],\n",
      "        [2.6538, 2.9540, 2.7861, 2.7991, 2.7118],\n",
      "        [2.6624, 2.7240, 2.7789, 2.8141, 2.8707],\n",
      "        [2.8243, 2.9514, 2.7954, 2.9669, 2.9075],\n",
      "        [2.6572, 2.7884, 2.7444, 2.8412, 2.8303],\n",
      "        [3.0018, 2.9352, 2.9466, 3.1344, 3.0452],\n",
      "        [2.6963, 2.8349, 2.6489, 2.8348, 2.7676],\n",
      "        [2.9007, 2.9083, 2.9483, 3.0044, 2.8302],\n",
      "        [2.7819, 2.8288, 2.7499, 2.9334, 2.8627],\n",
      "        [2.7657, 2.8129, 2.7721, 2.8843, 2.9298],\n",
      "        [2.7827, 3.0092, 2.9697, 2.9628, 2.8765],\n",
      "        [2.5986, 2.7735, 2.6568, 2.7257, 2.7249],\n",
      "        [2.8312, 2.9858, 2.7596, 2.8838, 2.9394],\n",
      "        [2.7810, 2.8712, 2.8063, 3.0035, 2.8429],\n",
      "        [2.7491, 2.7763, 2.8722, 2.8726, 2.8778],\n",
      "        [2.6765, 2.7953, 2.6990, 2.7560, 2.7453],\n",
      "        [2.6592, 3.0003, 2.8000, 2.8908, 2.9670],\n",
      "        [2.8604, 2.7508, 2.7172, 2.7605, 2.8681],\n",
      "        [2.9244, 3.0261, 2.8531, 2.9865, 3.0803],\n",
      "        [2.8372, 2.9189, 2.9054, 2.9618, 2.8215],\n",
      "        [2.8240, 2.9135, 2.8969, 2.8910, 2.9032],\n",
      "        [2.7055, 2.8420, 2.6626, 2.8280, 2.7983],\n",
      "        [2.5542, 2.8030, 2.7551, 2.7145, 2.7144],\n",
      "        [2.8131, 2.8265, 2.7622, 3.0180, 2.9229],\n",
      "        [2.7959, 2.8324, 2.8100, 2.8690, 2.8241],\n",
      "        [3.1696, 3.3194, 3.0071, 3.0652, 3.0302],\n",
      "        [3.2230, 3.4421, 2.9455, 3.0762, 3.0256],\n",
      "        [2.7013, 2.8465, 2.6560, 2.8531, 2.7872],\n",
      "        [3.1236, 2.8742, 2.9851, 3.4565, 3.3777],\n",
      "        [3.0964, 3.2358, 2.8435, 3.0109, 2.9180],\n",
      "        [3.1200, 2.8704, 2.9780, 3.4521, 3.3722],\n",
      "        [2.8082, 2.7897, 2.8106, 2.7746, 2.6816],\n",
      "        [2.6973, 2.8134, 2.6914, 2.8745, 2.7971],\n",
      "        [2.5986, 2.7823, 2.6594, 2.7208, 2.7309],\n",
      "        [2.7526, 2.8026, 2.8749, 2.9038, 2.8190],\n",
      "        [2.7122, 2.8422, 2.8731, 2.8590, 2.8818],\n",
      "        [2.6879, 2.7320, 2.7676, 2.8026, 2.7951],\n",
      "        [2.7162, 2.9068, 2.7503, 2.9041, 2.8167],\n",
      "        [2.7367, 2.8453, 2.8020, 2.8245, 2.8268],\n",
      "        [2.5495, 2.7916, 2.7529, 2.7222, 2.7119],\n",
      "        [2.6931, 2.7185, 2.7878, 2.8044, 2.7868],\n",
      "        [2.5802, 2.9710, 2.8258, 2.7782, 2.9555],\n",
      "        [2.6341, 3.0784, 2.8973, 2.8206, 2.8136],\n",
      "        [2.6710, 2.8350, 2.6667, 2.8076, 2.7686],\n",
      "        [2.5639, 2.8391, 2.7725, 2.7383, 2.7504],\n",
      "        [2.5639, 2.8391, 2.7725, 2.7383, 2.7504],\n",
      "        [2.8175, 2.9480, 2.9163, 2.9434, 2.9542],\n",
      "        [2.8856, 2.8685, 2.8974, 2.9974, 2.8999],\n",
      "        [3.0402, 3.0240, 2.9255, 3.0546, 3.0230],\n",
      "        [2.8223, 2.9552, 2.8146, 2.8039, 2.8662],\n",
      "        [2.8562, 2.9868, 2.7797, 2.9071, 2.9777],\n",
      "        [3.0038, 2.8505, 2.9377, 3.4204, 3.2992],\n",
      "        [2.5658, 2.7518, 2.7445, 2.7258, 2.7163],\n",
      "        [2.8179, 3.0760, 2.8358, 2.9515, 2.9214],\n",
      "        [2.8546, 2.9881, 2.7981, 2.9930, 3.0046],\n",
      "        [2.8304, 2.9922, 2.8735, 2.9704, 2.9067],\n",
      "        [2.6905, 2.7301, 2.7774, 2.7942, 2.7963],\n",
      "        [2.6864, 2.8324, 2.6561, 2.8188, 2.7756],\n",
      "        [2.6945, 2.7109, 2.7943, 2.8042, 2.7788]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.6583, 2.7344, 2.9076, 2.6535, 2.9524],\n",
      "        [2.9876, 2.8565, 2.9404, 3.0899, 2.9903],\n",
      "        [2.5723, 2.6754, 2.6707, 2.6975, 2.6858],\n",
      "        [2.8326, 2.8597, 2.8644, 2.8489, 2.7401],\n",
      "        [2.8446, 3.0233, 2.8413, 2.9520, 2.9361],\n",
      "        [2.7946, 2.8851, 2.8695, 2.8896, 2.9639],\n",
      "        [2.5494, 2.6538, 2.6988, 2.6983, 2.6257],\n",
      "        [2.7382, 2.8960, 2.6855, 2.7924, 2.8363],\n",
      "        [2.6887, 2.9270, 2.8180, 2.7509, 2.8842],\n",
      "        [2.5606, 2.7411, 2.6597, 2.6767, 2.7164],\n",
      "        [2.7129, 2.7701, 2.6741, 2.7999, 2.8953],\n",
      "        [2.6317, 2.8722, 2.6639, 2.8363, 2.7011],\n",
      "        [2.7160, 2.9851, 2.7565, 2.6666, 2.8884],\n",
      "        [2.8369, 2.9314, 2.9589, 2.9030, 2.8001],\n",
      "        [2.7348, 2.8663, 2.6661, 2.8796, 2.8004],\n",
      "        [2.6401, 2.7984, 2.6673, 2.7497, 2.7646],\n",
      "        [2.5935, 2.8527, 2.9209, 2.7998, 2.8638],\n",
      "        [2.6558, 2.8093, 2.6581, 2.7731, 2.7567],\n",
      "        [2.5893, 2.7375, 2.7344, 2.7309, 2.7325],\n",
      "        [2.8615, 2.9916, 2.9349, 2.9104, 2.7812],\n",
      "        [2.6737, 2.8116, 2.7693, 2.9026, 2.7963],\n",
      "        [2.8125, 2.7925, 2.8140, 2.7790, 2.6863],\n",
      "        [2.8503, 2.9902, 2.7805, 2.8964, 2.9677],\n",
      "        [2.5348, 2.6569, 2.6529, 2.6517, 2.6580],\n",
      "        [2.8038, 2.9216, 2.7557, 2.8676, 3.0093],\n",
      "        [2.6653, 2.8430, 2.7103, 2.8395, 2.8615],\n",
      "        [2.7061, 2.7240, 2.7019, 2.8829, 2.7164],\n",
      "        [2.7427, 2.9808, 2.8236, 2.9119, 3.0026],\n",
      "        [2.6031, 2.7851, 2.6627, 2.7251, 2.7355],\n",
      "        [2.5422, 2.7314, 2.6547, 2.6550, 2.6887],\n",
      "        [2.6697, 2.9907, 2.8493, 2.8818, 2.9774],\n",
      "        [2.4983, 2.7066, 2.6771, 2.6883, 2.7123],\n",
      "        [2.6665, 2.8753, 2.7078, 2.9072, 2.7424],\n",
      "        [2.5275, 2.8078, 2.8360, 2.7163, 2.8390],\n",
      "        [2.7100, 2.7001, 2.8131, 2.8177, 2.8747],\n",
      "        [2.6544, 2.7340, 2.8814, 2.6723, 2.9286],\n",
      "        [2.7412, 2.8482, 2.8054, 2.8290, 2.8317],\n",
      "        [2.7474, 3.0098, 2.8496, 2.9254, 3.0106],\n",
      "        [2.8469, 3.0114, 2.9007, 2.9740, 2.9184],\n",
      "        [2.8092, 2.9193, 2.7577, 2.8725, 3.0041],\n",
      "        [2.6627, 2.7654, 2.7493, 2.7485, 2.7690],\n",
      "        [2.7770, 2.8431, 2.8077, 2.8577, 2.8332],\n",
      "        [2.4769, 2.6819, 2.6767, 2.6632, 2.6908],\n",
      "        [2.6950, 2.7330, 2.7807, 2.7986, 2.8009],\n",
      "        [2.6893, 2.8294, 2.7400, 2.7851, 2.7955],\n",
      "        [3.2200, 3.4013, 3.0006, 3.1114, 2.9901],\n",
      "        [2.8374, 3.0181, 2.8295, 2.9612, 2.9256],\n",
      "        [2.8634, 3.0335, 2.7815, 2.8864, 2.9334],\n",
      "        [2.9033, 3.0076, 2.8210, 2.9368, 3.0404],\n",
      "        [2.7448, 2.9940, 2.8346, 2.9182, 3.0067],\n",
      "        [2.6466, 2.7179, 2.7577, 2.7762, 2.7924],\n",
      "        [2.7008, 2.7533, 2.8111, 2.8199, 2.8189],\n",
      "        [2.8001, 2.7962, 2.8393, 2.7837, 2.7806],\n",
      "        [2.6308, 2.9980, 2.7921, 2.8647, 2.9510],\n",
      "        [2.9186, 2.8617, 2.8409, 2.9144, 2.9370],\n",
      "        [2.7657, 2.8528, 2.8345, 2.8447, 2.9443],\n",
      "        [2.7524, 3.0266, 2.8632, 2.9369, 3.0197],\n",
      "        [2.7893, 2.9662, 2.7665, 3.0159, 2.9014],\n",
      "        [2.6950, 2.6901, 2.7471, 2.7844, 2.8840],\n",
      "        [2.8374, 2.8265, 2.7665, 3.0627, 2.9517],\n",
      "        [2.8176, 2.8294, 2.7656, 3.0225, 2.9276],\n",
      "        [2.6756, 2.7660, 2.7217, 2.7371, 2.7880],\n",
      "        [2.7146, 2.9043, 2.7764, 2.7882, 2.8774],\n",
      "        [2.9747, 3.0228, 2.8873, 3.0488, 3.0958]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.7161, 3.0742, 2.8363, 2.9737, 3.0063],\n",
      "        [2.5078, 2.6907, 2.6389, 2.6098, 2.6489],\n",
      "        [2.8872, 2.9148, 2.8814, 2.9146, 3.0131],\n",
      "        [2.5729, 2.7235, 2.7263, 2.7177, 2.7014],\n",
      "        [3.1052, 2.8849, 3.0170, 3.5101, 3.3812],\n",
      "        [2.6138, 2.9936, 2.8610, 2.8217, 2.9755],\n",
      "        [2.8588, 2.9022, 2.8692, 2.8915, 2.9970],\n",
      "        [2.6267, 2.6613, 2.7011, 2.7537, 2.6996],\n",
      "        [3.1102, 3.2392, 2.9417, 3.0056, 2.9500],\n",
      "        [2.6906, 3.0313, 2.8141, 2.9433, 2.9826],\n",
      "        [2.7065, 2.6950, 2.7894, 2.8150, 2.8909],\n",
      "        [2.5269, 2.7994, 2.5692, 2.7527, 2.6297],\n",
      "        [2.6936, 2.7117, 2.7998, 2.8079, 2.7899],\n",
      "        [2.8034, 2.7896, 2.9402, 2.9568, 2.8688],\n",
      "        [2.6067, 2.6917, 2.7368, 2.7465, 2.6772],\n",
      "        [2.6869, 2.7371, 2.6424, 2.7771, 2.8739],\n",
      "        [2.6226, 2.6486, 2.6891, 2.7550, 2.6893],\n",
      "        [2.6199, 2.8091, 2.9484, 2.7784, 2.9465],\n",
      "        [2.5400, 2.6593, 2.6559, 2.6556, 2.6631],\n",
      "        [2.6492, 2.7802, 2.6832, 2.8015, 2.7697],\n",
      "        [2.6167, 2.8186, 2.7027, 2.7519, 2.7926],\n",
      "        [2.9808, 2.9222, 2.9573, 3.1211, 3.0060],\n",
      "        [2.7183, 2.7726, 2.6773, 2.8039, 2.9004],\n",
      "        [2.6158, 2.7296, 2.7694, 2.8173, 2.8058],\n",
      "        [2.8462, 3.0229, 2.9179, 2.9590, 2.9050],\n",
      "        [2.7043, 2.7198, 2.8092, 2.7546, 2.8482],\n",
      "        [2.6670, 2.7477, 2.7551, 2.8297, 2.7372],\n",
      "        [2.7316, 2.8733, 2.6359, 2.7786, 2.8068],\n",
      "        [2.7014, 2.7599, 2.7870, 2.8136, 2.8177],\n",
      "        [2.7611, 2.7177, 3.0029, 2.8762, 2.9160],\n",
      "        [2.8423, 2.9688, 2.8052, 2.9785, 2.9104],\n",
      "        [2.7219, 2.8566, 2.6708, 2.8637, 2.8041],\n",
      "        [2.6172, 2.7270, 2.6413, 2.8009, 2.6378],\n",
      "        [2.9062, 3.1267, 2.8946, 3.0852, 3.0988],\n",
      "        [2.5119, 2.6919, 2.6417, 2.6129, 2.6523],\n",
      "        [2.7237, 2.7646, 2.8303, 2.8517, 2.8385],\n",
      "        [2.5922, 2.7479, 2.7656, 2.7581, 2.7036],\n",
      "        [2.6435, 2.6280, 2.8000, 2.6065, 2.8439],\n",
      "        [2.8677, 2.8396, 2.8266, 2.7872, 2.7417],\n",
      "        [2.5161, 2.6969, 2.6402, 2.6266, 2.6689],\n",
      "        [2.5950, 2.7751, 2.8202, 2.7769, 2.7019],\n",
      "        [2.4645, 2.6693, 2.6800, 2.6470, 2.6883],\n",
      "        [2.5595, 2.6619, 2.6650, 2.6783, 2.6749],\n",
      "        [2.9680, 2.7063, 2.8543, 3.2083, 3.1706],\n",
      "        [2.5816, 2.8526, 2.7852, 2.7492, 2.7702],\n",
      "        [2.5364, 2.7267, 2.6541, 2.6435, 2.6842],\n",
      "        [2.6981, 3.0297, 2.8782, 2.8558, 2.7940],\n",
      "        [3.0139, 2.9231, 2.8727, 2.9600, 2.9474],\n",
      "        [2.7258, 2.8673, 2.6670, 2.8725, 2.8061],\n",
      "        [2.5850, 2.7128, 2.7252, 2.7236, 2.7034],\n",
      "        [2.8500, 3.0191, 2.9125, 2.9792, 2.9256],\n",
      "        [2.6591, 2.8098, 2.6641, 2.7799, 2.7679],\n",
      "        [2.8946, 3.0012, 2.8914, 2.9645, 3.0127],\n",
      "        [2.5732, 2.8073, 2.7649, 2.7389, 2.7368],\n",
      "        [2.7033, 2.8533, 2.7987, 2.7703, 2.7220],\n",
      "        [2.7984, 2.8812, 2.7663, 2.8836, 3.0260],\n",
      "        [2.8310, 3.0600, 2.8312, 2.7562, 2.9260],\n",
      "        [2.7175, 2.7408, 2.8052, 2.8144, 2.8171],\n",
      "        [2.7077, 2.8433, 2.8023, 2.7809, 2.7286],\n",
      "        [2.5967, 2.7722, 2.6696, 2.7068, 2.7287],\n",
      "        [2.6238, 2.7264, 2.7579, 2.7945, 2.6962],\n",
      "        [2.5713, 2.7699, 2.7494, 2.7331, 2.7275],\n",
      "        [2.5990, 2.8553, 2.9241, 2.8038, 2.8689],\n",
      "        [2.6954, 2.7895, 2.7089, 2.8324, 2.7662]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.6943, 2.6791, 2.7252, 2.7631, 2.8782],\n",
      "        [2.9006, 2.8766, 2.9079, 3.0108, 2.9153],\n",
      "        [2.7287, 2.7670, 2.8331, 2.8562, 2.8443],\n",
      "        [2.7001, 2.7607, 2.8679, 2.7088, 2.9618],\n",
      "        [2.8480, 2.9906, 2.8232, 2.9790, 2.9269],\n",
      "        [2.6886, 2.9849, 2.8237, 2.9091, 2.9770],\n",
      "        [2.6862, 3.0308, 2.8012, 2.9377, 2.9578],\n",
      "        [2.6132, 2.7810, 2.6658, 2.7383, 2.7402],\n",
      "        [2.6620, 2.7353, 2.9023, 2.6576, 2.9583],\n",
      "        [2.7140, 2.6900, 2.7875, 2.8220, 2.8950],\n",
      "        [3.2369, 3.4494, 2.9624, 3.1091, 3.0490],\n",
      "        [2.6233, 2.9157, 2.6835, 2.5870, 2.8341],\n",
      "        [2.7155, 2.8499, 2.8159, 2.8104, 2.7377],\n",
      "        [2.6295, 2.7697, 2.6634, 2.7921, 2.7205],\n",
      "        [2.6746, 2.7622, 2.6892, 2.8444, 2.7558],\n",
      "        [2.7161, 2.8540, 2.6651, 2.8657, 2.8027],\n",
      "        [2.8265, 2.9609, 2.8868, 3.0366, 2.8911],\n",
      "        [2.6485, 2.6304, 2.8027, 2.6108, 2.8494],\n",
      "        [2.5950, 2.7705, 2.6669, 2.7085, 2.7263],\n",
      "        [2.8040, 3.1243, 2.9517, 2.9952, 3.0663],\n",
      "        [2.9377, 2.9416, 2.9207, 3.0807, 2.9812],\n",
      "        [2.8369, 2.8997, 2.8588, 2.8541, 2.6790],\n",
      "        [2.9620, 3.1352, 2.8976, 2.8833, 2.9137],\n",
      "        [2.9239, 2.9831, 2.9479, 2.9838, 3.0632],\n",
      "        [2.8822, 2.8573, 2.8814, 2.9937, 2.8928],\n",
      "        [2.6633, 2.9609, 2.7869, 2.7988, 2.7245],\n",
      "        [2.7917, 2.8636, 2.8073, 3.0001, 2.8539],\n",
      "        [2.8740, 3.0384, 2.7877, 2.8949, 2.9441],\n",
      "        [2.6772, 2.6523, 2.7746, 2.8066, 2.8373],\n",
      "        [2.9920, 2.9701, 2.9237, 3.1311, 3.0516],\n",
      "        [2.6823, 2.7997, 2.7041, 2.8416, 2.7753],\n",
      "        [2.7904, 2.8366, 2.8127, 2.8662, 2.8265],\n",
      "        [2.8027, 2.7723, 2.8354, 2.7819, 2.8200],\n",
      "        [2.7006, 2.7591, 2.7855, 2.8157, 2.8151],\n",
      "        [2.7930, 2.8773, 2.7524, 2.8703, 3.0285],\n",
      "        [2.9449, 3.0389, 2.9405, 2.9919, 3.0400],\n",
      "        [2.9688, 2.9860, 2.9569, 3.1171, 3.0242],\n",
      "        [2.6350, 2.9908, 2.7904, 2.8696, 2.9569],\n",
      "        [2.5805, 2.7479, 2.6680, 2.6918, 2.7116],\n",
      "        [2.7212, 2.7423, 2.8090, 2.7918, 2.8522],\n",
      "        [3.1248, 3.2462, 2.8401, 3.0154, 2.9079],\n",
      "        [2.7370, 2.9992, 2.7168, 2.8633, 2.8334],\n",
      "        [2.7039, 3.0717, 2.7822, 3.0108, 2.9720],\n",
      "        [2.7764, 3.0040, 2.8174, 3.0169, 2.9240],\n",
      "        [2.9958, 2.9317, 2.8861, 2.9614, 2.9922],\n",
      "        [2.7893, 2.8799, 2.7591, 2.9068, 2.8796],\n",
      "        [2.5723, 2.7609, 2.7442, 2.7232, 2.7134],\n",
      "        [2.7345, 2.7635, 2.8514, 2.8654, 2.8540],\n",
      "        [2.8588, 2.8834, 3.0389, 2.8460, 2.8249],\n",
      "        [2.7903, 2.9265, 2.7365, 2.9078, 2.9231],\n",
      "        [2.7644, 2.7306, 2.8078, 2.8591, 2.8271],\n",
      "        [2.8582, 3.1284, 2.9143, 3.1277, 3.0875],\n",
      "        [2.7519, 2.8049, 2.8568, 2.8568, 2.9390],\n",
      "        [2.5866, 2.6915, 2.7167, 2.7264, 2.6990],\n",
      "        [2.7371, 2.6876, 2.7727, 2.7283, 2.7386],\n",
      "        [2.7424, 2.9512, 2.8045, 2.8279, 2.8999],\n",
      "        [2.6730, 2.7702, 2.7551, 2.7568, 2.7798],\n",
      "        [2.6464, 2.8045, 2.6729, 2.7515, 2.7667],\n",
      "        [2.6848, 2.8325, 2.6713, 2.8090, 2.7848],\n",
      "        [3.0229, 2.8767, 2.9529, 3.4337, 3.3155],\n",
      "        [2.6540, 2.9156, 2.7819, 2.8311, 2.9640],\n",
      "        [2.6215, 2.8209, 2.7055, 2.7563, 2.7984],\n",
      "        [3.2738, 3.4601, 3.0055, 3.1339, 3.0628],\n",
      "        [2.7093, 2.7187, 2.8034, 2.8169, 2.7939]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.6361, 2.8026, 2.6757, 2.7579, 2.7625],\n",
      "        [2.6971, 3.0691, 2.7832, 3.0206, 2.9569],\n",
      "        [2.7124, 2.8419, 2.7561, 2.8072, 2.8217],\n",
      "        [2.6379, 2.6539, 2.6981, 2.7565, 2.7105],\n",
      "        [2.7273, 2.7427, 2.8161, 2.8230, 2.8223],\n",
      "        [2.7836, 2.7441, 3.0194, 2.9069, 2.9562],\n",
      "        [2.6203, 2.8632, 2.6383, 2.8051, 2.6982],\n",
      "        [2.6521, 2.9059, 2.7770, 2.8419, 2.9365],\n",
      "        [2.6596, 2.8596, 2.7108, 2.8983, 2.7547],\n",
      "        [2.6118, 2.7469, 2.7745, 2.7712, 2.7173],\n",
      "        [2.9210, 2.9433, 2.9604, 2.9162, 2.7753],\n",
      "        [2.8853, 2.8551, 2.8424, 2.8089, 2.7589],\n",
      "        [2.5836, 2.7104, 2.7256, 2.7283, 2.7050],\n",
      "        [2.5616, 2.7415, 2.6605, 2.6727, 2.7037],\n",
      "        [2.6421, 2.8341, 2.6983, 2.8712, 2.7448],\n",
      "        [2.6899, 2.8378, 2.9179, 2.7843, 2.8328],\n",
      "        [2.8097, 2.8946, 2.8792, 2.9035, 2.9810],\n",
      "        [2.6896, 2.9540, 2.8591, 2.7463, 2.9068],\n",
      "        [2.6885, 2.6769, 2.7140, 2.7510, 2.8767],\n",
      "        [2.8306, 2.9933, 2.7624, 2.8896, 2.9431],\n",
      "        [2.6745, 2.7829, 2.5759, 2.8700, 2.6556],\n",
      "        [2.8418, 2.9670, 2.8279, 2.8215, 2.8866],\n",
      "        [2.7011, 2.8565, 2.6753, 2.8403, 2.8008],\n",
      "        [2.7094, 2.7327, 2.7977, 2.8327, 2.8817],\n",
      "        [2.8597, 2.9835, 2.8375, 2.9007, 2.9047],\n",
      "        [2.8813, 2.9548, 2.9511, 3.0796, 2.8944],\n",
      "        [2.7378, 2.8830, 2.8068, 2.8686, 2.8835],\n",
      "        [2.7104, 2.8275, 2.7745, 2.7642, 2.8219],\n",
      "        [2.7309, 2.9270, 2.7751, 2.8273, 2.9009],\n",
      "        [2.8162, 2.9462, 2.9438, 2.9481, 2.9201],\n",
      "        [2.7150, 2.7476, 2.7297, 2.8775, 2.7530],\n",
      "        [3.1411, 3.2572, 2.8331, 3.0185, 2.9057],\n",
      "        [2.8213, 3.0032, 2.8892, 3.0574, 2.9265],\n",
      "        [2.6681, 2.9369, 2.8693, 2.7750, 3.0415],\n",
      "        [2.7176, 2.7189, 2.8179, 2.8099, 2.8107],\n",
      "        [2.6835, 2.6575, 2.7751, 2.8058, 2.8309],\n",
      "        [2.7553, 3.0834, 2.8336, 3.0122, 2.9957],\n",
      "        [3.0175, 2.8628, 2.9489, 3.4367, 3.3151],\n",
      "        [2.9021, 3.0499, 2.9675, 3.0565, 3.0686],\n",
      "        [2.8020, 2.9557, 2.8621, 2.8853, 2.7743],\n",
      "        [2.6374, 2.7194, 2.6186, 2.8241, 2.7218],\n",
      "        [2.9189, 3.0170, 2.8314, 2.9504, 3.0564],\n",
      "        [2.5739, 2.7999, 2.7605, 2.7307, 2.7280],\n",
      "        [2.6278, 2.6566, 2.7005, 2.7635, 2.7053],\n",
      "        [2.8819, 2.8439, 2.8397, 2.8028, 2.7493],\n",
      "        [2.5835, 2.8510, 2.7854, 2.7559, 2.7710],\n",
      "        [2.9207, 3.0637, 3.0307, 3.0163, 2.8456],\n",
      "        [2.5664, 2.8233, 2.7711, 2.7326, 2.7365],\n",
      "        [2.7164, 2.7742, 2.7962, 2.8410, 2.8465],\n",
      "        [2.9592, 2.7160, 2.8628, 3.1926, 3.1656],\n",
      "        [2.7602, 2.7960, 2.8001, 2.8877, 2.8494],\n",
      "        [2.6106, 2.7962, 2.8439, 2.7976, 2.8739],\n",
      "        [3.0460, 2.8930, 2.9725, 3.4560, 3.3211],\n",
      "        [3.1637, 3.4031, 2.9246, 3.0797, 2.9669],\n",
      "        [2.7379, 2.9954, 2.7549, 2.6814, 2.8695],\n",
      "        [2.8380, 3.0053, 2.8030, 3.0643, 2.9624],\n",
      "        [2.5386, 2.7230, 2.6585, 2.6425, 2.6948],\n",
      "        [2.7068, 2.8297, 2.7533, 2.7983, 2.8199],\n",
      "        [2.7543, 3.0157, 2.8878, 2.9077, 2.8514],\n",
      "        [2.6414, 2.9653, 2.8188, 2.8498, 2.9588],\n",
      "        [2.8481, 2.9824, 2.9139, 2.9037, 2.7791],\n",
      "        [2.8497, 2.8964, 2.9411, 2.9050, 2.7732],\n",
      "        [2.8603, 2.9615, 2.9255, 3.0658, 2.8937],\n",
      "        [3.0024, 2.8201, 2.8519, 3.3349, 3.1482]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.0118, 2.8256, 2.8534, 3.3318, 3.1601],\n",
      "        [2.5494, 2.7369, 2.6637, 2.6565, 2.7000],\n",
      "        [2.6707, 2.7373, 2.8983, 2.6686, 2.9585],\n",
      "        [2.8308, 2.8057, 2.8270, 2.7962, 2.7079],\n",
      "        [2.6847, 2.7024, 2.7707, 2.7658, 2.7711],\n",
      "        [2.6916, 2.8140, 2.7177, 2.7627, 2.7697],\n",
      "        [2.8590, 3.0339, 2.7970, 2.8915, 2.9651],\n",
      "        [2.7217, 3.1035, 2.8062, 3.0395, 2.9885],\n",
      "        [2.9011, 3.0181, 2.9712, 2.9469, 2.8179],\n",
      "        [2.7726, 3.0270, 2.7473, 2.9086, 2.8729],\n",
      "        [2.7141, 2.8314, 2.7780, 2.7685, 2.8277],\n",
      "        [2.6722, 2.6691, 2.7118, 2.7922, 2.6973],\n",
      "        [2.8601, 2.8990, 2.8376, 2.9736, 3.0149],\n",
      "        [2.8913, 2.7652, 2.7406, 2.7855, 2.9026],\n",
      "        [2.7302, 3.0852, 2.8473, 2.9876, 3.0230],\n",
      "        [2.8077, 2.8946, 2.8781, 2.8877, 2.9070],\n",
      "        [2.8152, 2.8631, 2.9311, 2.9488, 2.8792],\n",
      "        [2.7135, 2.9305, 2.7681, 2.9587, 2.8290],\n",
      "        [2.8786, 2.7108, 2.7278, 2.8070, 2.8392],\n",
      "        [2.5369, 2.6385, 2.6572, 2.6478, 2.6535],\n",
      "        [2.7043, 2.8941, 2.7204, 2.9528, 2.7594],\n",
      "        [2.8766, 2.7566, 2.7226, 2.7710, 2.8877],\n",
      "        [2.8465, 2.9620, 2.9178, 2.9783, 2.9064],\n",
      "        [2.6240, 2.8671, 2.6417, 2.8093, 2.7036],\n",
      "        [2.9058, 3.0583, 2.9691, 3.0589, 3.0695],\n",
      "        [2.7153, 2.9713, 2.8133, 2.8364, 2.7355],\n",
      "        [2.8964, 2.7828, 2.8012, 3.2304, 3.0365],\n",
      "        [2.9643, 3.0228, 2.8986, 3.1519, 3.0526],\n",
      "        [2.7873, 2.9246, 2.7420, 2.9071, 2.9083],\n",
      "        [2.6247, 2.7842, 2.6734, 2.7417, 2.7448],\n",
      "        [2.7498, 2.8838, 2.6889, 2.8964, 2.8359],\n",
      "        [2.5530, 2.6695, 2.6654, 2.6687, 2.6789],\n",
      "        [2.6081, 2.7980, 2.7001, 2.8215, 2.7431],\n",
      "        [3.0042, 2.9401, 2.8935, 2.9711, 3.0040],\n",
      "        [2.8535, 2.9006, 2.9447, 2.9093, 2.7789],\n",
      "        [2.7133, 2.8935, 2.7566, 2.8601, 2.8997],\n",
      "        [2.5592, 2.8283, 2.5825, 2.7859, 2.6491],\n",
      "        [3.0503, 2.8586, 2.9515, 3.4600, 3.3183],\n",
      "        [2.6331, 2.7462, 2.6519, 2.8239, 2.7348],\n",
      "        [2.6033, 2.7786, 2.6738, 2.7174, 2.7368],\n",
      "        [2.6779, 2.7480, 2.9205, 2.6716, 2.9745],\n",
      "        [2.9874, 2.7213, 2.8541, 3.2356, 3.2087],\n",
      "        [2.8543, 3.0568, 3.0064, 3.0083, 2.8605],\n",
      "        [2.9311, 2.7198, 2.8527, 3.1599, 3.1421],\n",
      "        [2.9127, 3.0151, 2.8280, 2.9550, 3.0594],\n",
      "        [2.9736, 3.1179, 2.8053, 2.9311, 2.9441],\n",
      "        [2.6307, 2.8767, 2.7739, 2.8097, 2.9540],\n",
      "        [2.6099, 2.7842, 2.6782, 2.7235, 2.7510],\n",
      "        [2.6721, 2.9694, 2.7945, 2.8079, 2.7353],\n",
      "        [3.0021, 3.0584, 2.9124, 3.0578, 3.1241],\n",
      "        [2.7298, 2.7507, 2.8161, 2.8010, 2.8631],\n",
      "        [2.4781, 2.6798, 2.6900, 2.6603, 2.7042],\n",
      "        [2.6019, 2.7670, 2.6701, 2.7149, 2.7290],\n",
      "        [2.7406, 2.7683, 2.8608, 2.8701, 2.8755],\n",
      "        [2.7160, 2.7396, 2.8016, 2.8204, 2.8207],\n",
      "        [2.7703, 2.9611, 2.8416, 2.8795, 2.7639],\n",
      "        [2.6632, 3.0755, 2.9069, 2.8513, 2.8421],\n",
      "        [2.9254, 2.8016, 2.8253, 3.2084, 3.0625],\n",
      "        [2.7582, 3.0198, 2.8916, 2.9122, 2.8571],\n",
      "        [2.8089, 2.9260, 2.7703, 2.9221, 2.9719],\n",
      "        [2.5221, 2.7189, 2.6860, 2.7212, 2.7282],\n",
      "        [2.8403, 3.0076, 2.8060, 3.0679, 2.9652],\n",
      "        [2.9370, 2.8749, 2.8539, 2.9329, 2.9605],\n",
      "        [2.9308, 3.0364, 2.8556, 2.9929, 3.0837]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.8597, 2.9340, 2.8866, 2.9333, 3.0084],\n",
      "        [2.8855, 2.9028, 2.9207, 3.0036, 2.7835],\n",
      "        [2.7246, 2.8030, 2.7970, 2.8086, 2.9912],\n",
      "        [2.6896, 2.7068, 2.7740, 2.7697, 2.7762],\n",
      "        [2.8191, 2.8099, 2.8586, 2.8045, 2.7953],\n",
      "        [2.8503, 2.9752, 2.8348, 2.8298, 2.8973],\n",
      "        [3.0551, 2.9019, 2.9798, 3.4644, 3.3324],\n",
      "        [2.8570, 2.8608, 2.9917, 2.8832, 2.7977],\n",
      "        [2.8593, 3.0616, 3.0098, 3.0123, 2.8658],\n",
      "        [2.8107, 3.0880, 2.9526, 2.9813, 3.0560],\n",
      "        [2.7962, 2.8619, 2.8149, 2.9855, 2.8697],\n",
      "        [2.5811, 2.8262, 2.7738, 2.7400, 2.7457],\n",
      "        [3.0305, 2.9566, 2.9699, 3.1630, 3.0771],\n",
      "        [2.8184, 2.9032, 2.8860, 2.9122, 2.9925],\n",
      "        [2.7208, 2.7441, 2.8048, 2.8243, 2.8259],\n",
      "        [2.7362, 2.9249, 2.7665, 2.8484, 2.8997],\n",
      "        [2.7185, 2.9350, 2.7716, 2.9626, 2.8342],\n",
      "        [2.9750, 2.9845, 2.8340, 3.0331, 3.0480],\n",
      "        [2.8273, 2.8374, 2.8024, 3.0106, 2.9315],\n",
      "        [2.8241, 2.8726, 2.6787, 2.9556, 2.9726],\n",
      "        [2.6486, 3.0037, 2.8021, 2.8829, 2.9730],\n",
      "        [2.8697, 2.9874, 2.9141, 2.8750, 2.9516],\n",
      "        [2.7413, 2.8538, 2.7190, 2.8573, 2.8544],\n",
      "        [2.9985, 3.0402, 2.9047, 3.0710, 3.1224],\n",
      "        [3.0091, 2.9445, 2.8968, 2.9752, 3.0096],\n",
      "        [2.5540, 2.7411, 2.6668, 2.6603, 2.7050],\n",
      "        [2.9855, 2.8788, 2.9399, 3.0518, 2.9951],\n",
      "        [2.5537, 2.7401, 2.5711, 2.7510, 2.6665],\n",
      "        [2.8099, 2.8493, 2.7698, 2.9593, 2.8943],\n",
      "        [2.5293, 2.7062, 2.6542, 2.6296, 2.6729],\n",
      "        [2.7463, 3.0037, 2.7619, 2.6897, 2.8802],\n",
      "        [2.7261, 2.7394, 2.8210, 2.8259, 2.8203],\n",
      "        [2.8153, 2.8451, 2.8260, 2.8863, 2.8405],\n",
      "        [2.8676, 2.9164, 2.8845, 2.8890, 2.7284],\n",
      "        [2.6330, 2.7413, 2.6507, 2.8149, 2.6557],\n",
      "        [2.6328, 3.0090, 2.8761, 2.8399, 2.9974],\n",
      "        [2.7246, 2.7423, 2.8608, 2.8694, 2.8477],\n",
      "        [3.0182, 3.1532, 2.8222, 2.9522, 2.9484],\n",
      "        [2.5774, 2.8116, 2.7723, 2.7479, 2.7429],\n",
      "        [2.7004, 2.8437, 2.6759, 2.8346, 2.7921],\n",
      "        [2.8640, 3.0469, 2.8543, 2.9737, 2.9544],\n",
      "        [2.8324, 2.8824, 2.9300, 2.9061, 2.8010],\n",
      "        [2.5896, 2.8837, 2.6370, 2.8158, 2.6972],\n",
      "        [2.6684, 2.8176, 2.6761, 2.7839, 2.7853],\n",
      "        [3.0070, 3.0627, 2.9159, 3.0619, 3.1293],\n",
      "        [2.8838, 3.0085, 2.8196, 3.0197, 3.0363],\n",
      "        [2.8832, 3.0179, 2.8232, 3.0365, 3.1259],\n",
      "        [2.7644, 2.9781, 2.8266, 2.9218, 3.0133],\n",
      "        [2.5221, 2.7239, 2.6935, 2.7095, 2.7385],\n",
      "        [2.5931, 2.8330, 2.7305, 2.7736, 2.9086],\n",
      "        [3.0276, 2.8760, 2.9629, 3.4479, 3.3335],\n",
      "        [2.6030, 2.7276, 2.7382, 2.7408, 2.7246],\n",
      "        [2.8517, 2.9698, 2.8091, 2.9925, 2.9311],\n",
      "        [2.7881, 2.7442, 3.0237, 2.9132, 2.9575],\n",
      "        [2.6924, 2.8018, 2.7665, 2.8369, 2.9095],\n",
      "        [2.9013, 2.7873, 2.8045, 3.2343, 3.0418],\n",
      "        [2.7171, 2.9084, 2.7312, 2.9595, 2.7755],\n",
      "        [2.9164, 2.7432, 2.7288, 2.7844, 2.8940],\n",
      "        [2.8708, 3.0995, 2.8915, 3.0753, 3.0362],\n",
      "        [2.8609, 2.8572, 2.8886, 3.0128, 2.8307],\n",
      "        [2.6982, 2.8462, 2.9249, 2.7926, 2.8436],\n",
      "        [2.6191, 2.8689, 2.9379, 2.8227, 2.8866],\n",
      "        [2.7855, 2.7737, 2.8964, 2.9370, 2.9009],\n",
      "        [2.5813, 2.7280, 2.6311, 2.7818, 2.6561]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.6145, 2.7674, 2.7846, 2.7788, 2.7301],\n",
      "        [2.9706, 2.9025, 2.9606, 3.1155, 2.9951],\n",
      "        [2.7168, 2.7465, 2.7991, 2.8216, 2.8260],\n",
      "        [2.7017, 2.9762, 2.8859, 2.7538, 2.9286],\n",
      "        [2.6642, 2.9176, 2.7925, 2.8410, 2.9902],\n",
      "        [3.0136, 2.9493, 2.9029, 2.9789, 3.0154],\n",
      "        [3.1296, 2.9062, 3.0380, 3.5317, 3.4095],\n",
      "        [2.7709, 3.0042, 2.8471, 2.9374, 3.0347],\n",
      "        [2.6523, 2.6769, 2.7168, 2.7806, 2.7231],\n",
      "        [2.6234, 2.6898, 2.7224, 2.7583, 2.7200],\n",
      "        [2.5579, 2.7446, 2.5769, 2.7544, 2.6716],\n",
      "        [2.6443, 2.7115, 2.6244, 2.8219, 2.7146],\n",
      "        [2.8392, 3.0262, 2.9434, 3.0016, 2.9273],\n",
      "        [2.5582, 2.7456, 2.6726, 2.6637, 2.7101],\n",
      "        [2.6316, 2.8339, 2.7231, 2.7674, 2.8167],\n",
      "        [2.9306, 3.1469, 2.9156, 3.1065, 3.1269],\n",
      "        [2.9812, 3.0580, 2.8979, 3.0437, 3.1022],\n",
      "        [2.7774, 3.1163, 2.8157, 3.0585, 3.0077],\n",
      "        [3.0244, 3.1194, 2.9880, 3.0802, 3.1727],\n",
      "        [2.7626, 2.9529, 2.8018, 2.9388, 2.8525],\n",
      "        [2.7671, 2.8266, 2.8391, 2.7764, 2.6895],\n",
      "        [2.6793, 2.6511, 2.6845, 2.7709, 2.6923],\n",
      "        [2.7982, 2.9689, 2.8666, 2.8917, 2.7850],\n",
      "        [2.8864, 2.9318, 2.9095, 2.9637, 3.0481],\n",
      "        [2.6012, 2.7397, 2.7484, 2.7441, 2.7291],\n",
      "        [2.8932, 2.9242, 2.9192, 3.0545, 2.9527],\n",
      "        [3.0430, 3.1572, 3.0148, 3.2753, 3.1545],\n",
      "        [2.5741, 2.7541, 2.6728, 2.6841, 2.7192],\n",
      "        [2.7167, 2.7571, 2.7913, 2.8232, 2.8298],\n",
      "        [2.8659, 3.0076, 2.8449, 2.9494, 2.9267],\n",
      "        [2.7256, 2.7438, 2.8132, 2.8333, 2.8231],\n",
      "        [2.9828, 2.8352, 2.8488, 3.2703, 3.1143],\n",
      "        [2.7197, 2.7101, 2.7654, 2.8078, 2.9123],\n",
      "        [3.0734, 3.0154, 2.9504, 3.0727, 3.0597],\n",
      "        [2.7006, 2.8229, 2.7267, 2.7700, 2.7800],\n",
      "        [2.7654, 2.8117, 2.8075, 2.8927, 2.8637],\n",
      "        [2.7226, 2.7461, 2.8105, 2.8444, 2.8980],\n",
      "        [2.6106, 2.7186, 2.7375, 2.7446, 2.7271],\n",
      "        [2.6385, 2.7944, 2.6539, 2.8213, 2.7595],\n",
      "        [2.7911, 2.9899, 2.8444, 2.8503, 2.9322],\n",
      "        [2.9205, 2.9601, 3.0609, 2.9322, 2.8476],\n",
      "        [2.9015, 3.0819, 2.8636, 2.8198, 2.8794],\n",
      "        [2.7797, 2.9706, 2.8513, 2.8870, 2.7746],\n",
      "        [2.7186, 2.7768, 2.8023, 2.8323, 2.8365],\n",
      "        [2.6102, 2.7380, 2.7466, 2.7501, 2.7434],\n",
      "        [2.6290, 2.7112, 2.7558, 2.7671, 2.7036],\n",
      "        [2.7149, 2.7533, 2.7896, 2.8206, 2.8273],\n",
      "        [2.6275, 2.7520, 2.7957, 2.8540, 2.8482],\n",
      "        [2.9161, 3.0351, 2.9898, 2.9593, 2.8323],\n",
      "        [2.6388, 2.8382, 2.7222, 2.7729, 2.8197],\n",
      "        [3.1844, 3.3320, 2.9581, 3.0598, 2.9659],\n",
      "        [2.7542, 2.8919, 2.6829, 2.9020, 2.8405],\n",
      "        [2.7904, 2.9151, 2.7873, 2.9277, 2.9415],\n",
      "        [2.5935, 2.8904, 2.6406, 2.8216, 2.7040],\n",
      "        [2.8500, 3.0171, 2.8156, 3.0755, 2.9762],\n",
      "        [2.8284, 2.8188, 2.8622, 2.8091, 2.8130],\n",
      "        [2.7463, 2.7846, 2.8496, 2.8728, 2.8659],\n",
      "        [2.8328, 2.9881, 2.9227, 2.9817, 2.9697],\n",
      "        [2.8266, 3.0980, 2.8837, 2.9649, 2.9785],\n",
      "        [2.8651, 2.9552, 2.9820, 2.9279, 2.8328],\n",
      "        [2.6611, 2.9655, 2.7787, 2.7802, 2.7358],\n",
      "        [2.7689, 2.8707, 2.8282, 2.8544, 2.8645],\n",
      "        [2.6676, 2.8202, 2.6892, 2.7742, 2.7961],\n",
      "        [2.7969, 2.7575, 3.0327, 2.9189, 2.9728]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.7516, 2.6955, 2.7813, 2.7314, 2.7484],\n",
      "        [2.6341, 2.7161, 2.7612, 2.7702, 2.7083],\n",
      "        [2.7947, 3.0135, 2.7937, 2.7156, 2.8575],\n",
      "        [2.6728, 3.0822, 2.9256, 2.8521, 2.8508],\n",
      "        [2.7536, 2.8917, 2.6915, 2.8962, 2.8377],\n",
      "        [2.9067, 2.9331, 2.9173, 3.0699, 2.9520],\n",
      "        [2.7787, 2.8145, 2.8184, 2.9028, 2.8707],\n",
      "        [2.7625, 3.0411, 2.9520, 2.9742, 3.0253],\n",
      "        [2.6584, 3.0136, 2.8145, 2.8897, 2.9832],\n",
      "        [2.6196, 2.7723, 2.7900, 2.7819, 2.7348],\n",
      "        [2.7215, 2.7253, 2.8382, 2.7504, 2.8798],\n",
      "        [2.7200, 2.7584, 2.7951, 2.8237, 2.8321],\n",
      "        [2.8255, 2.7032, 2.9436, 2.9193, 2.9037],\n",
      "        [2.8198, 2.9025, 2.8385, 3.0368, 2.8858],\n",
      "        [2.6272, 2.7633, 2.7838, 2.7733, 2.7360],\n",
      "        [2.7284, 2.9451, 2.7837, 2.9693, 2.8444],\n",
      "        [2.9233, 3.0262, 2.9181, 2.9897, 3.0450],\n",
      "        [2.5952, 2.7795, 2.6893, 2.7126, 2.7442],\n",
      "        [2.7260, 2.8674, 2.6929, 2.8559, 2.8234],\n",
      "        [2.8060, 3.0620, 2.9487, 2.9716, 3.1285],\n",
      "        [2.8106, 3.0458, 2.8269, 2.7408, 2.9467],\n",
      "        [2.5730, 2.8415, 2.5969, 2.7961, 2.6635],\n",
      "        [3.0161, 2.8906, 2.9657, 3.0881, 3.0250],\n",
      "        [2.5741, 2.8402, 2.8926, 2.7330, 2.8305],\n",
      "        [2.7424, 2.7023, 2.7853, 2.7513, 2.7590],\n",
      "        [2.7100, 2.9225, 2.8081, 2.9984, 2.8544],\n",
      "        [3.0992, 3.2288, 2.8561, 3.0077, 2.9577],\n",
      "        [2.6857, 2.7585, 2.9240, 2.6778, 2.9851],\n",
      "        [2.7254, 2.7761, 2.8062, 2.8421, 2.8411],\n",
      "        [2.6062, 2.7447, 2.7539, 2.7473, 2.7338],\n",
      "        [2.8193, 2.7982, 2.8579, 2.8025, 2.8162],\n",
      "        [2.6529, 2.7296, 2.6294, 2.8271, 2.6846],\n",
      "        [2.5662, 2.7618, 2.6882, 2.7331, 2.7332],\n",
      "        [2.7349, 3.0918, 2.8512, 3.0012, 3.0181],\n",
      "        [2.9703, 2.8900, 2.9448, 3.1006, 2.9798],\n",
      "        [3.0612, 3.1613, 3.0090, 3.2835, 3.1650],\n",
      "        [3.0347, 2.9899, 3.0233, 3.2108, 3.0857],\n",
      "        [2.7630, 2.8018, 2.8165, 2.8688, 2.8713],\n",
      "        [3.2544, 3.4285, 3.0309, 3.1416, 3.0290],\n",
      "        [2.7503, 2.8724, 2.9061, 2.8919, 2.9232],\n",
      "        [2.8974, 3.0649, 2.8122, 2.9154, 2.9714],\n",
      "        [2.6972, 2.7387, 2.6432, 2.7787, 2.8868],\n",
      "        [2.8544, 2.9136, 2.7277, 2.9799, 2.9957],\n",
      "        [2.6868, 2.9553, 2.8895, 2.7905, 3.0626],\n",
      "        [2.6158, 2.7807, 2.6844, 2.7252, 2.7438],\n",
      "        [2.7907, 2.8326, 2.9068, 2.9365, 2.8608],\n",
      "        [2.8691, 3.0725, 3.0222, 3.0191, 2.8764],\n",
      "        [2.7517, 2.7577, 2.8346, 2.8561, 2.9058],\n",
      "        [2.9392, 2.9627, 2.9793, 2.9311, 2.7965],\n",
      "        [2.4997, 2.6933, 2.7136, 2.6732, 2.7462],\n",
      "        [2.6281, 2.8787, 2.9499, 2.8294, 2.8969],\n",
      "        [2.7224, 2.7127, 2.7616, 2.8004, 2.9127],\n",
      "        [2.7186, 2.8112, 2.7922, 2.8269, 2.9624],\n",
      "        [2.7969, 2.8560, 2.8239, 2.9635, 2.8804],\n",
      "        [2.8044, 3.1468, 2.8856, 3.0780, 3.0579],\n",
      "        [2.6174, 2.8288, 2.8715, 2.7875, 2.8785],\n",
      "        [2.7925, 2.7396, 2.8208, 2.8663, 2.8056],\n",
      "        [2.8315, 3.0300, 2.9337, 2.9803, 3.0641],\n",
      "        [2.6916, 2.8204, 2.7731, 2.8856, 2.8480],\n",
      "        [2.5980, 2.7654, 2.7592, 2.7418, 2.7364],\n",
      "        [2.9011, 2.8029, 2.8130, 3.2021, 3.0347],\n",
      "        [2.8738, 3.0567, 2.8664, 2.9803, 2.9648],\n",
      "        [2.5938, 2.7801, 2.7632, 2.7445, 2.7393],\n",
      "        [2.7603, 2.7670, 2.8835, 2.8896, 2.9215]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.7687, 2.9031, 2.7086, 2.9097, 2.8557],\n",
      "        [2.8924, 2.9820, 2.9603, 3.0890, 2.9202],\n",
      "        [2.7690, 2.9386, 2.7532, 2.8084, 2.8897],\n",
      "        [2.6740, 3.0234, 2.8304, 2.8838, 3.0061],\n",
      "        [3.0743, 3.1517, 2.9877, 3.3228, 3.1815],\n",
      "        [3.0696, 3.2023, 2.8535, 2.9946, 2.9651],\n",
      "        [2.8853, 3.0057, 2.8647, 2.9001, 2.9311],\n",
      "        [2.5815, 2.7710, 2.6917, 2.6946, 2.7355],\n",
      "        [2.8752, 2.8596, 2.8003, 3.0938, 2.9934],\n",
      "        [2.9658, 2.9700, 2.9511, 3.1049, 3.0121],\n",
      "        [2.7533, 3.0177, 2.7911, 2.6979, 2.9297],\n",
      "        [2.8650, 2.9186, 2.8660, 2.9832, 3.0464],\n",
      "        [2.7495, 2.8804, 2.6923, 2.8837, 2.8314],\n",
      "        [2.7965, 2.9552, 2.7851, 2.9421, 2.8990],\n",
      "        [2.8549, 2.8552, 2.8833, 3.0064, 2.8175],\n",
      "        [2.6748, 2.9294, 2.8024, 2.8600, 2.9618],\n",
      "        [2.8685, 3.0212, 2.7901, 2.9144, 2.9754],\n",
      "        [2.8856, 3.0448, 2.9353, 3.0058, 2.9611],\n",
      "        [2.6325, 2.7956, 2.8349, 2.8119, 2.7322],\n",
      "        [2.9233, 2.9891, 2.9637, 3.0231, 2.9468],\n",
      "        [2.9285, 3.0905, 2.8186, 2.9290, 2.9757],\n",
      "        [2.7482, 2.8804, 2.8211, 2.8647, 2.8865],\n",
      "        [2.6626, 2.7213, 2.7565, 2.7814, 2.7345],\n",
      "        [3.3287, 3.4851, 3.0708, 3.1819, 3.0799],\n",
      "        [2.7650, 3.0267, 2.7447, 2.8852, 2.8640],\n",
      "        [3.0195, 2.9981, 2.9548, 3.1560, 3.0824],\n",
      "        [2.8635, 3.0903, 2.8630, 2.7839, 2.9627],\n",
      "        [2.7523, 2.7385, 2.8551, 2.8741, 2.9464],\n",
      "        [2.8361, 3.0356, 2.9393, 2.9833, 3.0686],\n",
      "        [2.6197, 2.7733, 2.7938, 2.7793, 2.7329],\n",
      "        [2.5961, 2.8229, 2.7836, 2.7484, 2.7529],\n",
      "        [2.9480, 2.9729, 2.9145, 2.9511, 3.0062],\n",
      "        [2.7039, 2.9074, 2.7408, 2.9380, 2.7832],\n",
      "        [2.7310, 2.9231, 2.7479, 2.9690, 2.7899],\n",
      "        [2.7794, 2.8333, 2.8838, 2.8803, 2.9711],\n",
      "        [2.8811, 2.9228, 2.9017, 2.8972, 2.7560],\n",
      "        [2.7783, 2.9936, 2.8442, 2.9316, 3.0279],\n",
      "        [2.8604, 2.9861, 2.9549, 2.9796, 3.0009],\n",
      "        [2.7529, 2.9371, 2.8106, 2.8196, 2.9194],\n",
      "        [2.6434, 2.8078, 2.6926, 2.7559, 2.7673],\n",
      "        [2.7118, 2.8596, 2.6979, 2.8311, 2.8150],\n",
      "        [2.7827, 3.0283, 2.8696, 2.9499, 3.0483],\n",
      "        [2.9153, 2.8833, 2.8645, 2.8340, 2.7944],\n",
      "        [2.6034, 2.8612, 2.8018, 2.7674, 2.7843],\n",
      "        [2.7579, 3.0628, 2.9408, 2.9643, 3.0540],\n",
      "        [3.0700, 2.9180, 2.9978, 3.4741, 3.3485],\n",
      "        [2.8306, 3.0299, 2.9358, 2.9858, 3.0432],\n",
      "        [2.6234, 2.7909, 2.8032, 2.7922, 2.7467],\n",
      "        [2.6821, 2.8323, 2.6924, 2.7933, 2.7996],\n",
      "        [3.1400, 2.9173, 3.0496, 3.5379, 3.4198],\n",
      "        [3.0742, 2.9086, 3.0097, 3.4879, 3.3753],\n",
      "        [2.5955, 2.6944, 2.6963, 2.7122, 2.7135],\n",
      "        [2.7269, 2.9600, 2.8521, 2.7826, 2.9265],\n",
      "        [2.6472, 2.6558, 2.7123, 2.7774, 2.7096],\n",
      "        [2.6232, 2.8179, 2.8643, 2.8122, 2.8957],\n",
      "        [2.8304, 3.0188, 2.9374, 2.9861, 3.0264],\n",
      "        [2.6515, 2.9815, 2.8162, 2.6804, 2.9517],\n",
      "        [2.8638, 2.9274, 2.8862, 2.8768, 2.7100],\n",
      "        [2.8600, 3.0278, 2.8267, 3.0818, 2.9859],\n",
      "        [2.6790, 3.1164, 2.9364, 2.8566, 2.8605],\n",
      "        [2.7352, 2.7542, 2.8237, 2.8392, 2.8324],\n",
      "        [2.6088, 2.7069, 2.7026, 2.7277, 2.7259],\n",
      "        [2.9049, 2.9788, 2.9761, 3.0982, 2.9211],\n",
      "        [2.6032, 2.7018, 2.7292, 2.7338, 2.6878]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.6335, 2.7192, 2.7478, 2.7596, 2.7408],\n",
      "        [2.9452, 3.1633, 2.9343, 3.1169, 3.1430],\n",
      "        [2.6418, 2.8303, 2.7163, 2.8363, 2.7721],\n",
      "        [2.9775, 2.9002, 2.9624, 3.1022, 2.9915],\n",
      "        [2.7273, 2.8091, 2.7308, 2.8854, 2.8033],\n",
      "        [2.8798, 3.0233, 2.8628, 2.9595, 2.9421],\n",
      "        [2.9213, 3.1058, 2.9350, 2.8760, 3.0161],\n",
      "        [2.7638, 3.0240, 2.7861, 2.7034, 2.9006],\n",
      "        [2.6524, 2.7607, 2.6766, 2.8310, 2.6780],\n",
      "        [3.0744, 2.8849, 2.9799, 3.4779, 3.3462],\n",
      "        [2.8435, 3.0307, 2.9455, 2.9969, 3.0356],\n",
      "        [2.7484, 2.8013, 2.8489, 2.8605, 2.8671],\n",
      "        [2.7689, 2.7779, 2.8956, 2.8967, 2.9321],\n",
      "        [3.0160, 2.9603, 2.9983, 3.1602, 3.0457],\n",
      "        [2.7685, 2.9619, 2.7693, 3.0227, 2.8134],\n",
      "        [2.6700, 2.7850, 2.7024, 2.8201, 2.7574],\n",
      "        [2.6057, 2.8608, 2.8051, 2.7625, 2.7809],\n",
      "        [2.9963, 2.9011, 2.9688, 3.1058, 3.0000],\n",
      "        [2.9520, 2.9785, 2.9215, 2.9554, 3.0124],\n",
      "        [2.7236, 2.7962, 2.8186, 2.8535, 2.8615],\n",
      "        [2.6801, 2.7906, 2.7863, 2.7658, 2.7890],\n",
      "        [2.8910, 2.8194, 2.8159, 3.1702, 3.0227],\n",
      "        [2.8385, 2.8883, 2.9587, 2.9667, 2.9054],\n",
      "        [2.8286, 2.9136, 2.8508, 3.0440, 2.8964],\n",
      "        [2.8053, 2.6809, 2.9441, 2.9280, 2.9480],\n",
      "        [2.7440, 2.8632, 2.7416, 2.8508, 2.8605],\n",
      "        [2.9112, 3.1267, 2.9257, 3.1185, 3.0650],\n",
      "        [2.6967, 2.8452, 2.7044, 2.8001, 2.8172],\n",
      "        [3.1322, 3.3339, 2.8730, 2.9947, 2.9665],\n",
      "        [3.0553, 2.8418, 2.8805, 3.3846, 3.2054],\n",
      "        [2.8504, 3.0028, 2.9402, 2.9875, 2.9859],\n",
      "        [2.9365, 3.0404, 2.8564, 2.9732, 3.0856],\n",
      "        [2.8893, 2.9204, 3.0769, 2.8784, 2.8656],\n",
      "        [2.6303, 2.7411, 2.7602, 2.7646, 2.7566],\n",
      "        [2.7269, 2.9185, 2.7469, 2.9702, 2.7847],\n",
      "        [3.1082, 3.2394, 2.8685, 3.0150, 2.9683],\n",
      "        [2.7377, 2.8128, 2.8867, 2.7806, 2.9840],\n",
      "        [3.0453, 3.1473, 3.0227, 3.1064, 3.1887],\n",
      "        [2.8580, 3.0115, 2.8416, 2.9440, 2.9523],\n",
      "        [2.6140, 2.7418, 2.7604, 2.7532, 2.7396],\n",
      "        [2.8292, 3.1103, 2.9778, 2.9955, 3.0773],\n",
      "        [2.7303, 2.7780, 2.8138, 2.8443, 2.8556],\n",
      "        [2.5824, 2.7680, 2.6930, 2.6891, 2.7343],\n",
      "        [2.7969, 2.7589, 3.0425, 2.9108, 2.9638],\n",
      "        [2.6122, 2.7056, 2.7401, 2.7410, 2.7176],\n",
      "        [2.8712, 3.0203, 2.9495, 2.9277, 2.8229],\n",
      "        [2.9239, 2.9778, 2.9863, 2.9665, 3.0491],\n",
      "        [2.8467, 3.0045, 2.9413, 2.9923, 2.9853],\n",
      "        [3.0575, 3.1738, 3.0352, 3.2869, 3.1705],\n",
      "        [2.9805, 2.9076, 2.9638, 3.1089, 2.9938],\n",
      "        [2.6656, 2.6924, 2.7340, 2.7906, 2.7380],\n",
      "        [2.9594, 3.0203, 2.9344, 3.1233, 2.9964],\n",
      "        [2.7469, 2.7723, 2.8361, 2.8433, 2.8508],\n",
      "        [2.7572, 2.7620, 2.7362, 2.9204, 2.7732],\n",
      "        [2.7703, 2.9535, 2.7985, 2.9377, 2.8708],\n",
      "        [2.7371, 2.9562, 2.7961, 2.9764, 2.8549],\n",
      "        [2.7409, 2.8648, 2.7370, 2.8546, 2.8552],\n",
      "        [2.5588, 2.6623, 2.6827, 2.6648, 2.6779],\n",
      "        [2.7641, 2.9008, 2.6999, 2.9182, 2.8515],\n",
      "        [2.8623, 2.8689, 2.8000, 3.0563, 2.9762],\n",
      "        [3.0378, 2.9747, 2.9708, 3.0385, 3.0370],\n",
      "        [2.7455, 2.8743, 2.8360, 2.8056, 2.7718],\n",
      "        [2.6261, 2.7570, 2.8685, 2.7725, 2.8708],\n",
      "        [2.5991, 2.8087, 2.7862, 2.7530, 2.7521]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.7912, 2.8595, 2.8304, 2.8817, 2.9387],\n",
      "        [3.1186, 2.9000, 2.9808, 3.4235, 3.3775],\n",
      "        [2.6724, 2.8670, 2.7353, 2.8964, 2.7808],\n",
      "        [2.7839, 2.9452, 2.7460, 2.8260, 2.8891],\n",
      "        [2.7483, 2.8863, 2.7097, 2.8837, 2.8399],\n",
      "        [3.0568, 3.0120, 3.0525, 3.2129, 3.0978],\n",
      "        [2.9352, 3.0808, 3.0105, 3.0869, 3.1158],\n",
      "        [2.9096, 2.7499, 2.7664, 2.8272, 2.8797],\n",
      "        [2.7089, 2.9983, 2.8371, 2.8385, 2.7595],\n",
      "        [2.7874, 2.8437, 2.8982, 2.8884, 2.9829],\n",
      "        [2.7384, 2.8827, 2.7117, 2.8665, 2.8390],\n",
      "        [2.8866, 3.0724, 2.8862, 2.9911, 2.9810],\n",
      "        [2.6812, 2.8449, 2.7945, 2.9230, 2.7892],\n",
      "        [2.6927, 2.6694, 2.7934, 2.8085, 2.8634],\n",
      "        [2.9278, 2.9563, 2.9266, 2.9517, 3.0642],\n",
      "        [3.2035, 3.4196, 2.9486, 3.0728, 3.0295],\n",
      "        [2.8495, 2.8390, 2.8781, 2.9145, 2.8657],\n",
      "        [2.7963, 2.9909, 2.8806, 2.9018, 2.7940],\n",
      "        [2.9444, 2.9126, 2.8952, 2.8691, 2.8297],\n",
      "        [2.7475, 2.7453, 2.7292, 2.9249, 2.7553],\n",
      "        [2.7506, 2.8718, 2.7430, 2.8522, 2.8683],\n",
      "        [2.9407, 3.0453, 2.8640, 2.9771, 3.0912],\n",
      "        [2.8054, 2.9225, 2.7782, 2.9137, 2.9710],\n",
      "        [2.6641, 2.8066, 2.7034, 2.8218, 2.7614],\n",
      "        [2.7456, 2.8091, 2.8949, 2.7865, 2.9922],\n",
      "        [2.8632, 2.8728, 2.8136, 3.0615, 2.9810],\n",
      "        [2.7079, 2.7494, 2.8136, 2.7972, 2.8206],\n",
      "        [2.7833, 2.8326, 2.8324, 2.9067, 2.8846],\n",
      "        [2.8443, 3.0464, 2.9544, 2.9917, 3.0804],\n",
      "        [2.8219, 3.0290, 2.8727, 3.0525, 2.9623],\n",
      "        [2.6363, 2.8255, 2.8359, 2.8051, 2.7783],\n",
      "        [2.8503, 3.0636, 2.9642, 3.0086, 3.0942],\n",
      "        [2.9905, 2.7502, 2.9011, 3.2182, 3.2039],\n",
      "        [2.6012, 2.8719, 2.8172, 2.7596, 2.7845],\n",
      "        [2.8840, 3.0330, 2.8133, 2.9282, 2.9980],\n",
      "        [2.7118, 2.9174, 2.7546, 2.9457, 2.7943],\n",
      "        [3.2741, 3.4873, 3.0067, 3.1418, 3.0929],\n",
      "        [2.7375, 2.8233, 2.7608, 2.9095, 2.8350],\n",
      "        [2.5596, 2.7455, 2.6903, 2.6584, 2.7117],\n",
      "        [2.9155, 2.8889, 2.8797, 2.8347, 2.7968],\n",
      "        [2.7497, 2.8662, 2.7548, 2.9220, 2.8615],\n",
      "        [2.9094, 2.9401, 2.9738, 2.9963, 2.8678],\n",
      "        [2.6139, 2.8843, 2.8226, 2.7815, 2.8071],\n",
      "        [2.6184, 2.7598, 2.7727, 2.7578, 2.7491],\n",
      "        [2.8154, 2.8924, 2.9165, 2.9220, 2.9165],\n",
      "        [2.9086, 2.7953, 2.7667, 2.8048, 2.9281],\n",
      "        [2.9072, 3.0343, 2.8526, 3.0379, 3.0629],\n",
      "        [2.7588, 2.7039, 2.7904, 2.7312, 2.7555],\n",
      "        [2.8227, 2.8853, 2.8595, 2.8925, 2.8890],\n",
      "        [2.6476, 2.7791, 2.8280, 2.8703, 2.8668],\n",
      "        [2.9981, 3.0095, 2.8662, 3.0513, 3.0742],\n",
      "        [2.8640, 2.9409, 2.7651, 2.9777, 2.9959],\n",
      "        [2.7142, 2.8273, 2.7979, 2.8545, 2.9356],\n",
      "        [2.9339, 3.0870, 3.0081, 3.0835, 3.1072],\n",
      "        [3.1041, 3.0641, 3.0423, 3.1475, 3.1473],\n",
      "        [2.7498, 2.7594, 2.8671, 2.8555, 2.8558],\n",
      "        [2.8217, 2.8894, 2.9329, 2.9447, 2.9137],\n",
      "        [2.5873, 2.7739, 2.6990, 2.6959, 2.7403],\n",
      "        [2.8333, 2.9906, 2.9012, 2.9116, 2.8121],\n",
      "        [3.1508, 3.3643, 2.9133, 3.0403, 2.9494],\n",
      "        [2.8844, 2.8561, 2.8328, 3.1456, 3.0347],\n",
      "        [2.5942, 2.6953, 2.7442, 2.7359, 2.6770],\n",
      "        [2.6810, 2.8413, 2.7130, 2.7813, 2.8077],\n",
      "        [2.8365, 2.9557, 2.8058, 2.9438, 3.0031]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.7482, 2.8228, 2.8423, 2.8761, 2.8899],\n",
      "        [2.9554, 2.9842, 3.0061, 2.9453, 2.8175],\n",
      "        [2.7843, 2.9206, 2.7153, 2.9253, 2.8639],\n",
      "        [2.7380, 2.7453, 2.8640, 2.7646, 2.9006],\n",
      "        [2.5526, 2.7521, 2.7262, 2.7456, 2.7632],\n",
      "        [2.7380, 2.8748, 2.8292, 2.8457, 2.8807],\n",
      "        [2.6215, 2.8041, 2.7161, 2.7280, 2.7760],\n",
      "        [2.7263, 3.0738, 2.8517, 2.9719, 3.0054],\n",
      "        [2.8794, 3.0005, 2.8543, 3.0124, 2.9705],\n",
      "        [2.7851, 2.8185, 2.9135, 2.9162, 2.9231],\n",
      "        [2.5928, 2.7848, 2.7115, 2.7054, 2.7510],\n",
      "        [2.8487, 2.9355, 2.8413, 2.9051, 2.8940],\n",
      "        [2.6399, 2.7479, 2.7941, 2.7875, 2.7322],\n",
      "        [2.7022, 2.7024, 2.7518, 2.8165, 2.7324],\n",
      "        [2.7793, 2.7788, 2.8919, 2.8819, 2.8680],\n",
      "        [2.6595, 2.8628, 2.7536, 2.7900, 2.8451],\n",
      "        [2.6143, 2.9138, 2.6710, 2.8384, 2.7283],\n",
      "        [2.8700, 3.0620, 2.8475, 2.9350, 3.0023],\n",
      "        [2.8493, 2.9335, 2.9645, 2.9031, 2.8407],\n",
      "        [2.8186, 2.9148, 2.9318, 2.9281, 2.9405],\n",
      "        [2.6886, 2.8442, 2.7198, 2.7910, 2.8210],\n",
      "        [2.9129, 3.0226, 2.9667, 2.9224, 2.9932],\n",
      "        [2.8441, 2.9167, 2.7417, 2.9063, 2.9862],\n",
      "        [2.7110, 2.8513, 2.7075, 2.8246, 2.8037],\n",
      "        [3.2781, 3.4918, 3.0138, 3.1455, 3.0981],\n",
      "        [2.8509, 2.8398, 2.8668, 2.8076, 2.7315],\n",
      "        [2.6838, 2.8431, 2.7095, 2.7960, 2.8029],\n",
      "        [2.8323, 2.9083, 2.8029, 2.9596, 2.9294],\n",
      "        [3.1526, 2.9329, 3.0721, 3.5500, 3.4381],\n",
      "        [2.8971, 3.0201, 2.8857, 2.9114, 2.9475],\n",
      "        [2.8943, 3.0212, 2.8826, 2.9298, 2.9466],\n",
      "        [2.7454, 2.8221, 2.9009, 2.7879, 2.9945],\n",
      "        [2.9155, 3.0423, 2.9638, 2.9104, 2.9967],\n",
      "        [2.6288, 2.7571, 2.7794, 2.7638, 2.7559],\n",
      "        [2.8364, 2.9229, 2.8651, 3.0512, 2.9069],\n",
      "        [3.0608, 3.0423, 2.9724, 3.0641, 3.0869],\n",
      "        [2.6757, 2.8540, 2.7896, 2.9352, 2.7789],\n",
      "        [2.8714, 3.0277, 2.8727, 2.9822, 2.9472],\n",
      "        [2.9480, 2.9169, 2.9019, 2.8725, 2.8347],\n",
      "        [2.7295, 2.8439, 2.7544, 2.8016, 2.8068],\n",
      "        [2.8045, 2.7661, 3.0648, 2.9207, 2.9821],\n",
      "        [2.7542, 2.8852, 2.7067, 2.8792, 2.8314],\n",
      "        [2.9508, 3.1099, 3.0655, 3.0173, 2.8890],\n",
      "        [3.0651, 2.8771, 2.9027, 3.3876, 3.2336],\n",
      "        [3.0325, 2.9104, 2.9938, 3.1038, 3.0457],\n",
      "        [2.8531, 2.8674, 2.8405, 3.0316, 2.9632],\n",
      "        [2.7993, 3.0492, 2.8474, 3.0417, 2.9685],\n",
      "        [2.8829, 3.0218, 2.9599, 2.9336, 2.8222],\n",
      "        [2.7159, 2.6943, 2.8211, 2.8396, 2.8839],\n",
      "        [2.7838, 2.7864, 2.9070, 2.9378, 2.8969],\n",
      "        [2.8749, 3.1052, 2.8846, 2.7955, 2.9793],\n",
      "        [2.7518, 2.7568, 2.8611, 2.8383, 2.8525],\n",
      "        [2.6616, 2.6841, 2.7380, 2.7943, 2.7309],\n",
      "        [2.7807, 2.9532, 2.7744, 2.8198, 2.9061],\n",
      "        [2.6936, 2.8968, 2.7544, 2.9269, 2.7956],\n",
      "        [2.8858, 2.8934, 3.0393, 2.9083, 2.8370],\n",
      "        [2.5809, 2.8540, 2.9026, 2.7642, 2.8594],\n",
      "        [3.0574, 3.0136, 3.0591, 3.2157, 3.1012],\n",
      "        [3.0414, 3.0048, 2.9496, 3.1698, 3.0677],\n",
      "        [2.6627, 2.8036, 2.8413, 2.8251, 2.7551],\n",
      "        [2.6000, 2.7835, 2.7116, 2.7020, 2.7513],\n",
      "        [2.8144, 2.7744, 3.0624, 2.9344, 2.9892],\n",
      "        [2.7362, 2.7783, 2.8211, 2.8379, 2.8529],\n",
      "        [2.6578, 2.6952, 2.7426, 2.7900, 2.7393]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.7994, 3.0826, 2.9283, 2.9767, 3.0783],\n",
      "        [2.7396, 2.7836, 2.7008, 2.8177, 2.9302],\n",
      "        [2.7802, 2.7911, 2.9159, 2.9070, 2.9480],\n",
      "        [3.0258, 3.0923, 2.9742, 3.2224, 3.1366],\n",
      "        [2.6881, 2.8492, 2.7255, 2.7875, 2.8177],\n",
      "        [2.5615, 2.7429, 2.6943, 2.6662, 2.7238],\n",
      "        [2.6626, 2.7797, 2.8226, 2.8294, 2.7478],\n",
      "        [2.7659, 2.7958, 2.8986, 2.8861, 2.8924],\n",
      "        [3.0679, 2.9257, 3.0107, 3.4717, 3.3717],\n",
      "        [2.5846, 2.8580, 2.9089, 2.7673, 2.8649],\n",
      "        [2.6620, 2.7109, 2.7579, 2.7858, 2.7502],\n",
      "        [2.7427, 3.0080, 2.8595, 2.8591, 2.7756],\n",
      "        [2.7525, 2.8872, 2.7189, 2.8740, 2.8527],\n",
      "        [2.5695, 2.6745, 2.7018, 2.6745, 2.6926],\n",
      "        [2.9517, 3.1181, 3.0657, 3.0273, 2.8814],\n",
      "        [2.8377, 3.1292, 3.0005, 3.0022, 3.0875],\n",
      "        [2.8076, 2.8317, 2.9358, 2.9226, 2.9468],\n",
      "        [2.8864, 3.0258, 2.9663, 2.9368, 2.8277],\n",
      "        [2.7569, 2.7393, 2.8566, 2.8585, 2.9490],\n",
      "        [2.6199, 2.8921, 2.8413, 2.7756, 2.8034],\n",
      "        [2.7713, 2.7644, 2.8917, 2.8999, 2.9751],\n",
      "        [2.9153, 2.9366, 2.9661, 3.0284, 2.8207],\n",
      "        [2.7134, 2.7872, 2.9678, 2.7003, 3.0172],\n",
      "        [2.7325, 2.7321, 2.8699, 2.7341, 2.9117],\n",
      "        [2.9915, 2.9927, 2.9894, 3.0882, 2.9353],\n",
      "        [2.9427, 3.0898, 3.0245, 3.0937, 3.1267],\n",
      "        [2.7458, 2.7329, 2.8124, 2.8359, 2.9464],\n",
      "        [3.0574, 2.9070, 3.0025, 3.4698, 3.3660],\n",
      "        [2.7576, 2.8890, 2.7128, 2.8822, 2.8369],\n",
      "        [2.9010, 3.0638, 2.9632, 3.0204, 2.9835],\n",
      "        [3.0615, 2.9452, 2.9717, 3.4606, 3.3474],\n",
      "        [2.8484, 3.0318, 2.9663, 3.0060, 3.0317],\n",
      "        [2.8439, 2.9640, 2.8191, 2.9505, 3.0136],\n",
      "        [2.7812, 2.9205, 2.7329, 2.9250, 2.8730],\n",
      "        [2.8446, 2.8793, 2.8702, 2.9105, 2.8776],\n",
      "        [2.7249, 2.7180, 2.7645, 2.7831, 2.9236],\n",
      "        [2.8306, 2.7803, 3.0513, 2.9366, 2.9983],\n",
      "        [3.0383, 2.9781, 2.9413, 3.0003, 3.0480],\n",
      "        [2.8005, 3.0645, 2.9117, 2.9693, 3.0746],\n",
      "        [2.9699, 2.9872, 2.9787, 3.1156, 3.0144],\n",
      "        [2.8705, 2.9358, 2.9047, 2.8861, 2.7242],\n",
      "        [2.7118, 2.8584, 2.7163, 2.8226, 2.8268],\n",
      "        [2.9978, 2.7585, 2.9143, 3.2247, 3.2147],\n",
      "        [2.9450, 3.0978, 3.0259, 3.0964, 3.1206],\n",
      "        [2.7650, 2.9013, 2.7185, 2.8940, 2.8486],\n",
      "        [2.7581, 2.7853, 2.8562, 2.8535, 2.8665],\n",
      "        [2.7109, 2.8441, 2.8057, 2.9027, 2.8741],\n",
      "        [2.6890, 2.8413, 2.7618, 2.8136, 2.8240],\n",
      "        [3.0001, 2.8803, 2.8771, 2.9314, 2.9805],\n",
      "        [2.7161, 2.9164, 2.7652, 2.9544, 2.8032],\n",
      "        [2.6668, 2.6975, 2.7479, 2.7960, 2.7498],\n",
      "        [2.6240, 2.8155, 2.8318, 2.7858, 2.7802],\n",
      "        [2.7646, 2.8985, 2.7187, 2.8977, 2.8529],\n",
      "        [2.6202, 2.8551, 2.8209, 2.7798, 2.7935],\n",
      "        [2.6596, 2.8306, 2.8749, 2.8276, 2.7742],\n",
      "        [2.8329, 2.8871, 2.8678, 2.9073, 2.8891],\n",
      "        [2.6574, 2.8326, 2.8901, 2.8498, 2.9418],\n",
      "        [2.9630, 2.9918, 2.9422, 2.9661, 3.0287],\n",
      "        [2.5615, 2.7429, 2.6943, 2.6662, 2.7238],\n",
      "        [3.0001, 2.7667, 2.9073, 3.2247, 3.2245],\n",
      "        [2.6211, 2.8923, 2.8352, 2.7878, 2.8173],\n",
      "        [2.7008, 2.7694, 2.8188, 2.8220, 2.8557],\n",
      "        [2.9079, 2.9160, 3.0076, 2.9472, 2.8120],\n",
      "        [2.8261, 3.0872, 2.9834, 2.9898, 3.1554]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.6769, 3.0242, 2.9111, 2.8889, 3.0244],\n",
      "        [2.7508, 2.9738, 2.8677, 2.8090, 2.9472],\n",
      "        [2.7800, 2.9319, 2.6990, 2.8194, 2.8719],\n",
      "        [2.6583, 2.6798, 2.7384, 2.7876, 2.7366],\n",
      "        [2.6730, 2.9871, 2.8078, 2.7847, 2.7578],\n",
      "        [2.9097, 2.9490, 2.9733, 3.0196, 2.8451],\n",
      "        [2.8017, 2.8715, 2.8493, 2.8912, 2.9543],\n",
      "        [2.8038, 3.0682, 2.9177, 2.9721, 3.0796],\n",
      "        [2.7476, 2.8169, 2.8488, 2.8693, 2.8895],\n",
      "        [2.7583, 2.8794, 2.7668, 2.8635, 2.8810],\n",
      "        [2.7481, 2.8349, 2.7793, 2.9187, 2.8502],\n",
      "        [2.8871, 2.8510, 2.9328, 2.9700, 2.9114],\n",
      "        [2.7110, 2.8623, 2.7220, 2.8199, 2.8234],\n",
      "        [2.7363, 2.8365, 2.8288, 2.8450, 2.9911],\n",
      "        [2.9131, 3.2230, 2.9382, 3.1662, 3.1537],\n",
      "        [2.6675, 2.9180, 2.8293, 2.8409, 3.0013],\n",
      "        [2.7880, 3.0019, 2.8662, 2.8683, 2.9582],\n",
      "        [2.9007, 2.8809, 2.8936, 2.8217, 2.7836],\n",
      "        [2.6467, 2.8371, 2.8541, 2.8142, 2.7933],\n",
      "        [2.8481, 2.8352, 2.9047, 2.8179, 2.8720],\n",
      "        [2.8494, 2.8233, 2.8964, 2.8227, 2.8786],\n",
      "        [2.7141, 3.1046, 2.9688, 2.8971, 2.8887],\n",
      "        [2.7479, 2.7958, 2.8416, 2.8514, 2.8726],\n",
      "        [2.7055, 2.9593, 2.8142, 2.8303, 2.8197],\n",
      "        [2.8180, 2.7855, 2.9802, 2.9710, 2.9184],\n",
      "        [2.9641, 3.1367, 3.1074, 3.0634, 2.9307],\n",
      "        [2.6708, 2.7952, 2.7010, 2.8480, 2.7836],\n",
      "        [2.6453, 2.7545, 2.7836, 2.7755, 2.7771],\n",
      "        [2.7470, 2.8387, 2.8389, 2.8415, 3.0123],\n",
      "        [2.6700, 2.7010, 2.7535, 2.7987, 2.7546],\n",
      "        [2.6698, 2.9902, 2.9385, 2.8507, 3.0236],\n",
      "        [2.8097, 2.8338, 2.9481, 2.9365, 2.9504],\n",
      "        [3.0460, 3.0878, 2.9597, 3.1066, 3.1679],\n",
      "        [3.1831, 3.3012, 2.8908, 3.0549, 2.9580],\n",
      "        [3.0413, 3.1002, 2.9679, 3.0901, 3.1713],\n",
      "        [3.0584, 3.0181, 3.0654, 3.2336, 3.1175],\n",
      "        [2.8423, 2.8225, 2.8959, 2.8178, 2.8616],\n",
      "        [2.8440, 3.1569, 2.9765, 3.0274, 3.1701],\n",
      "        [2.5908, 2.7746, 2.7138, 2.6935, 2.7512],\n",
      "        [3.0870, 3.2191, 2.8812, 2.9964, 2.9865],\n",
      "        [3.0292, 2.9650, 3.0178, 3.1687, 3.0560],\n",
      "        [2.8075, 2.8609, 2.8549, 2.9506, 2.9030],\n",
      "        [2.6588, 2.8660, 2.7663, 2.7904, 2.8522],\n",
      "        [3.0119, 3.1594, 2.8596, 2.9625, 2.9908],\n",
      "        [2.8367, 2.9154, 2.8206, 2.9666, 2.9410],\n",
      "        [2.8674, 2.9757, 2.8264, 2.9213, 3.0729],\n",
      "        [2.7828, 2.9251, 2.6994, 2.8221, 2.8690],\n",
      "        [2.9414, 3.1025, 2.8416, 2.9283, 2.9915],\n",
      "        [2.7639, 2.8467, 2.8550, 2.8311, 3.0527],\n",
      "        [3.0517, 3.1902, 2.8731, 2.9797, 2.9900],\n",
      "        [2.7498, 2.8243, 2.9398, 2.9873, 3.0733],\n",
      "        [2.7890, 2.9897, 2.8472, 2.8742, 2.9584],\n",
      "        [2.7449, 2.7529, 2.8758, 2.7705, 2.9109],\n",
      "        [2.9663, 2.9955, 2.9480, 2.9689, 3.0338],\n",
      "        [2.7305, 3.0913, 2.8304, 3.0272, 2.9880],\n",
      "        [2.7567, 2.8407, 2.8479, 2.8359, 3.0331],\n",
      "        [2.6724, 2.9268, 2.8274, 2.8453, 3.0049],\n",
      "        [2.6330, 2.7528, 2.7431, 2.7566, 2.7607],\n",
      "        [2.8552, 2.9430, 2.9062, 3.0635, 2.9370],\n",
      "        [2.7526, 2.9050, 2.8615, 2.8147, 2.7849],\n",
      "        [2.7335, 2.8400, 2.8229, 2.8554, 2.9732],\n",
      "        [2.6066, 2.7906, 2.7229, 2.7075, 2.7612],\n",
      "        [2.9028, 2.9363, 3.0963, 2.8897, 2.8783],\n",
      "        [2.9168, 3.1414, 2.9442, 3.1153, 3.0826]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.9062, 3.0282, 2.9703, 2.9051, 2.9981],\n",
      "        [2.6989, 2.8961, 2.8033, 2.9143, 2.8281],\n",
      "        [3.3794, 3.5384, 3.1398, 3.2238, 3.1349],\n",
      "        [2.7519, 2.8975, 2.8633, 2.8089, 2.7884],\n",
      "        [2.8506, 2.9710, 2.8303, 2.9560, 3.0230],\n",
      "        [2.8650, 3.0055, 2.9445, 2.9502, 2.8486],\n",
      "        [2.6269, 2.7581, 2.7855, 2.7649, 2.7599],\n",
      "        [2.9577, 2.9277, 2.9190, 2.8810, 2.8497],\n",
      "        [2.8073, 3.0706, 2.9244, 2.9773, 3.0840],\n",
      "        [2.6618, 2.9028, 2.9992, 2.8341, 2.9556],\n",
      "        [2.7141, 2.8655, 2.7271, 2.8223, 2.8278],\n",
      "        [2.8867, 2.9009, 2.9300, 2.8929, 2.8147],\n",
      "        [2.6969, 2.7591, 2.8438, 2.8452, 2.9334],\n",
      "        [2.9456, 3.0152, 3.0043, 3.0446, 2.9783],\n",
      "        [2.8168, 3.1010, 2.9515, 2.9924, 3.0973],\n",
      "        [2.7088, 2.9627, 2.8195, 2.8329, 2.8242],\n",
      "        [2.8358, 3.0768, 2.8712, 2.7637, 2.9825],\n",
      "        [2.8393, 2.8906, 2.8786, 2.9089, 2.8892],\n",
      "        [2.7353, 2.7768, 2.6966, 2.8109, 2.9304],\n",
      "        [2.6705, 2.8184, 2.7013, 2.8505, 2.7974],\n",
      "        [2.9436, 2.8370, 2.8789, 2.8954, 2.9247],\n",
      "        [2.7620, 2.7945, 2.9187, 2.9000, 2.9097],\n",
      "        [2.7194, 3.0169, 2.8632, 2.8543, 2.7892],\n",
      "        [2.7059, 3.1234, 2.9685, 2.8856, 2.8942],\n",
      "        [3.0622, 3.1582, 2.9877, 3.3078, 3.1833],\n",
      "        [2.9221, 2.7596, 2.7872, 2.8324, 2.8977],\n",
      "        [2.8220, 2.8153, 2.9518, 2.9666, 2.9479],\n",
      "        [2.5789, 2.8510, 2.6337, 2.7973, 2.6926],\n",
      "        [2.7241, 2.7225, 2.8803, 2.7087, 2.9203],\n",
      "        [2.7780, 3.0579, 2.8304, 3.0319, 2.9705],\n",
      "        [2.8094, 3.0335, 2.8916, 2.9623, 3.0714],\n",
      "        [2.8373, 2.7872, 3.0624, 2.9420, 3.0079],\n",
      "        [2.8805, 2.8708, 2.9010, 2.8073, 2.7634],\n",
      "        [2.6864, 2.7830, 2.8189, 2.8594, 2.7701],\n",
      "        [2.7441, 2.8105, 2.8461, 2.8602, 2.8759],\n",
      "        [2.7618, 2.7799, 2.8747, 2.8547, 2.8661],\n",
      "        [2.7141, 2.8644, 2.7345, 2.8151, 2.8418],\n",
      "        [3.1267, 2.9496, 3.0943, 3.5270, 3.4558],\n",
      "        [2.8916, 2.9183, 2.9366, 2.9006, 2.8137],\n",
      "        [2.8783, 2.8525, 2.9339, 2.9645, 2.9178],\n",
      "        [3.0515, 3.0157, 2.9681, 3.1792, 3.0825],\n",
      "        [2.7373, 2.8792, 2.8567, 2.9553, 2.8657],\n",
      "        [2.7983, 3.0307, 2.8188, 2.9447, 2.9409],\n",
      "        [2.7843, 2.8986, 2.8623, 2.8472, 2.9001],\n",
      "        [2.6167, 2.8087, 2.8094, 2.7662, 2.7707],\n",
      "        [2.9113, 2.8948, 2.8724, 3.1663, 3.0680],\n",
      "        [2.9015, 3.0805, 2.9889, 3.0073, 2.9749],\n",
      "        [2.8642, 3.0367, 2.8459, 3.0738, 2.9859],\n",
      "        [2.7522, 2.8134, 2.8575, 2.8735, 2.9001],\n",
      "        [2.8885, 2.9952, 2.9743, 2.9295, 2.9816],\n",
      "        [2.8827, 3.0539, 2.8658, 3.1020, 3.0185],\n",
      "        [2.9507, 2.7821, 2.7823, 2.8138, 2.9402],\n",
      "        [2.6024, 2.7951, 2.7277, 2.7134, 2.7652],\n",
      "        [2.9833, 2.9937, 2.9896, 3.1258, 3.0360],\n",
      "        [2.7945, 2.9361, 2.7383, 2.9390, 2.8864],\n",
      "        [2.6793, 3.0482, 2.8683, 2.8906, 3.0371],\n",
      "        [3.1504, 3.3537, 2.9047, 3.0109, 2.9916],\n",
      "        [2.7565, 2.7995, 2.8508, 2.8502, 2.8740],\n",
      "        [2.8935, 3.0126, 2.9819, 3.0146, 2.9634],\n",
      "        [2.9507, 3.0575, 2.9633, 3.0137, 3.0814],\n",
      "        [3.0482, 2.8708, 2.9159, 3.3729, 3.2078],\n",
      "        [2.8421, 2.9192, 2.8201, 2.9680, 2.9443],\n",
      "        [2.9031, 3.0262, 2.9038, 2.8955, 2.9564],\n",
      "        [2.7709, 2.7630, 2.8919, 2.8900, 2.9741]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.6785, 2.6611, 2.8536, 2.6271, 2.8963],\n",
      "        [2.6143, 2.6549, 2.7336, 2.8089, 2.7457],\n",
      "        [2.9043, 3.0628, 2.9752, 3.0439, 2.9941],\n",
      "        [2.8682, 3.0363, 2.8481, 3.0728, 2.9858],\n",
      "        [2.8133, 3.1557, 2.8714, 3.0863, 3.0537],\n",
      "        [2.8848, 3.0414, 2.8949, 2.9929, 2.9664],\n",
      "        [2.6232, 2.8293, 2.9603, 2.7624, 2.9559],\n",
      "        [2.7020, 2.8990, 2.8081, 2.9166, 2.8322],\n",
      "        [2.6790, 2.8080, 2.8535, 2.8372, 2.7722],\n",
      "        [2.6791, 2.6922, 2.7520, 2.8017, 2.7585],\n",
      "        [2.7537, 2.8513, 2.7892, 2.8036, 2.8533],\n",
      "        [2.9551, 3.1086, 3.0429, 3.1045, 3.1348],\n",
      "        [2.8552, 3.1320, 2.9317, 3.0079, 3.0178],\n",
      "        [3.0701, 2.9818, 2.9459, 3.0110, 3.0232],\n",
      "        [2.7834, 3.0467, 2.8224, 2.7212, 2.9296],\n",
      "        [2.9314, 2.9926, 2.9505, 3.0314, 3.1286],\n",
      "        [3.0655, 3.1613, 2.9931, 3.3104, 3.1876],\n",
      "        [2.6533, 2.8714, 2.7165, 2.8401, 2.7906],\n",
      "        [2.9452, 3.0013, 3.0242, 2.9854, 3.0794],\n",
      "        [2.6411, 2.7700, 2.7964, 2.7717, 2.7731],\n",
      "        [2.5617, 2.7546, 2.7125, 2.6598, 2.7249],\n",
      "        [3.0014, 3.0030, 3.0062, 3.0964, 2.9491],\n",
      "        [2.6295, 2.9017, 2.8567, 2.7831, 2.8167],\n",
      "        [2.6719, 2.9939, 2.9437, 2.8518, 3.0282],\n",
      "        [2.8879, 3.0560, 2.8432, 2.9379, 3.0126],\n",
      "        [2.8578, 3.1851, 3.0267, 3.0416, 3.1348],\n",
      "        [2.9515, 3.1068, 3.0391, 3.0985, 3.1322],\n",
      "        [2.9305, 2.7664, 2.7946, 2.8313, 2.9234],\n",
      "        [3.0964, 2.9482, 3.0435, 3.4974, 3.3869],\n",
      "        [2.7568, 2.7516, 2.8396, 2.7939, 2.8173],\n",
      "        [2.9407, 2.8319, 2.8655, 3.2662, 3.0935],\n",
      "        [2.8936, 2.8574, 2.9430, 2.9750, 2.9201],\n",
      "        [2.9108, 3.2166, 2.9481, 3.1538, 3.1474],\n",
      "        [2.7840, 2.9814, 2.8424, 2.8803, 2.9597],\n",
      "        [2.7950, 3.0701, 2.9645, 2.9507, 2.9060],\n",
      "        [2.8579, 2.9420, 2.8426, 2.9335, 3.0988],\n",
      "        [2.8471, 3.0874, 3.0011, 3.0002, 3.1508],\n",
      "        [2.9658, 3.0133, 3.0601, 3.1478, 2.9723],\n",
      "        [2.7027, 2.9065, 3.0437, 2.8517, 3.0432],\n",
      "        [2.8596, 2.9112, 2.9953, 2.9850, 2.9352],\n",
      "        [2.6649, 2.8721, 2.7763, 2.7952, 2.8606],\n",
      "        [2.8631, 2.9311, 2.7678, 2.9218, 3.0160],\n",
      "        [2.8894, 3.0547, 2.8641, 3.0951, 3.0124],\n",
      "        [2.7358, 2.8409, 2.6567, 2.9224, 2.7221],\n",
      "        [2.7383, 2.9192, 2.8000, 2.8897, 2.9401],\n",
      "        [2.6743, 2.6975, 2.7594, 2.8046, 2.7491],\n",
      "        [2.9250, 3.0529, 2.8828, 3.0529, 3.0875],\n",
      "        [2.6295, 2.9017, 2.8567, 2.7831, 2.8167],\n",
      "        [2.7619, 2.7804, 2.8692, 2.8543, 2.8662],\n",
      "        [2.8487, 2.8289, 2.9062, 2.8228, 2.8703],\n",
      "        [2.9186, 2.8027, 2.7839, 2.8067, 2.9434],\n",
      "        [2.6463, 2.9131, 2.8556, 2.7933, 2.8468],\n",
      "        [2.7473, 2.8135, 2.8510, 2.8625, 2.8800],\n",
      "        [3.0164, 2.9318, 2.8857, 2.9588, 3.0120],\n",
      "        [2.8546, 2.7361, 2.9914, 2.9441, 2.9434],\n",
      "        [2.8036, 3.0699, 2.9587, 2.9496, 2.9130],\n",
      "        [2.9013, 2.8746, 2.8620, 3.1599, 3.0592],\n",
      "        [2.8739, 2.9897, 3.0022, 2.9134, 2.8639],\n",
      "        [3.1551, 3.3028, 3.0409, 3.0439, 3.0842],\n",
      "        [2.4644, 2.6804, 2.7358, 2.6482, 2.7291],\n",
      "        [2.8139, 2.8672, 2.8650, 2.9555, 2.9116],\n",
      "        [2.7626, 2.8275, 2.9240, 2.8010, 3.0165],\n",
      "        [2.7542, 2.8806, 2.8180, 2.8374, 2.8804],\n",
      "        [3.0582, 2.9981, 3.0079, 3.0572, 3.0677]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.7509, 2.8351, 2.7706, 2.9051, 2.8374],\n",
      "        [2.7989, 2.9537, 2.7328, 2.8348, 2.8975],\n",
      "        [2.6421, 2.7627, 2.7570, 2.7634, 2.7743],\n",
      "        [2.6303, 2.8820, 2.8463, 2.7877, 2.8217],\n",
      "        [2.8263, 3.0729, 3.0000, 2.9499, 3.0353],\n",
      "        [2.7869, 2.9856, 2.8469, 2.8825, 2.9653],\n",
      "        [2.6825, 3.0117, 2.8677, 2.6998, 2.9850],\n",
      "        [2.6807, 2.7522, 2.6802, 2.8510, 2.7626],\n",
      "        [2.8866, 3.0805, 2.8749, 2.9482, 3.0272],\n",
      "        [2.7638, 2.7431, 2.8376, 2.7831, 2.8092],\n",
      "        [2.7374, 2.8643, 2.7824, 2.7992, 2.8292],\n",
      "        [2.8568, 3.0325, 2.8486, 3.0720, 2.9863],\n",
      "        [2.7836, 2.7330, 2.8331, 2.7585, 2.7936],\n",
      "        [2.6333, 2.7974, 2.8118, 2.7727, 2.7797],\n",
      "        [2.8151, 2.8437, 2.9626, 2.9274, 2.9544],\n",
      "        [2.7856, 2.9176, 2.7370, 2.9157, 2.8723],\n",
      "        [2.7880, 2.9759, 2.8370, 2.9640, 2.9036],\n",
      "        [2.6790, 2.7111, 2.7676, 2.8055, 2.7683],\n",
      "        [2.6993, 2.8046, 2.8256, 2.7381, 2.9476],\n",
      "        [2.7456, 3.0008, 2.9150, 2.7967, 2.9690],\n",
      "        [2.8762, 2.8590, 2.8939, 2.8330, 2.7683],\n",
      "        [2.9008, 2.9110, 3.0602, 2.9188, 2.8548],\n",
      "        [2.6908, 2.7778, 2.8381, 2.8402, 2.8682],\n",
      "        [2.8417, 3.0839, 2.8808, 2.7682, 2.9922],\n",
      "        [2.6672, 2.6899, 2.7524, 2.7943, 2.7501],\n",
      "        [3.2620, 3.4542, 3.0306, 3.1325, 3.0780],\n",
      "        [3.0504, 2.9922, 2.9619, 3.0104, 3.0677],\n",
      "        [2.7371, 2.8678, 2.7652, 2.8522, 2.8657],\n",
      "        [2.9732, 2.9794, 3.0386, 3.0676, 2.9193],\n",
      "        [2.7030, 2.7662, 2.8532, 2.8496, 2.9430],\n",
      "        [3.0668, 3.1214, 3.0193, 3.2457, 3.1633],\n",
      "        [2.6670, 2.7187, 2.7706, 2.7941, 2.7628],\n",
      "        [2.8878, 3.0455, 2.8994, 2.9950, 2.9720],\n",
      "        [3.0056, 2.8920, 2.8956, 2.9384, 3.0067],\n",
      "        [2.8349, 2.8515, 2.9767, 2.9520, 2.9715],\n",
      "        [2.6869, 2.7732, 2.6873, 2.8650, 2.7862],\n",
      "        [2.9376, 2.9176, 2.9606, 3.0435, 2.9633],\n",
      "        [2.6083, 2.8018, 2.7365, 2.7177, 2.7744],\n",
      "        [2.7915, 2.9339, 2.7398, 2.9315, 2.8906],\n",
      "        [2.6415, 2.9144, 2.8615, 2.8000, 2.8461],\n",
      "        [2.6828, 2.7727, 2.8339, 2.8526, 2.8702],\n",
      "        [2.7419, 2.8386, 2.8155, 2.8006, 2.8623],\n",
      "        [2.7367, 2.7317, 2.7845, 2.7927, 2.9423],\n",
      "        [2.7427, 3.0920, 2.8789, 2.9849, 3.0306],\n",
      "        [2.9002, 3.0091, 2.9698, 2.9154, 3.0043],\n",
      "        [2.6752, 2.7934, 2.8423, 2.8390, 2.7665],\n",
      "        [2.6333, 2.7974, 2.8118, 2.7727, 2.7797],\n",
      "        [2.7861, 2.8674, 2.8836, 2.8457, 3.0900],\n",
      "        [2.9635, 2.9348, 2.9283, 2.8854, 2.8595],\n",
      "        [2.7332, 2.7930, 2.8634, 2.8740, 2.9581],\n",
      "        [2.7359, 2.8289, 2.8154, 2.8001, 2.8550],\n",
      "        [2.8994, 3.0598, 2.8581, 2.9465, 3.0344],\n",
      "        [2.7214, 2.8486, 2.9609, 2.8747, 2.9719],\n",
      "        [2.8188, 3.0955, 2.9480, 2.9936, 3.1033],\n",
      "        [2.7841, 3.0650, 2.8398, 3.0363, 2.9803],\n",
      "        [2.6631, 2.8769, 2.7248, 2.8448, 2.7999],\n",
      "        [2.7521, 2.7975, 2.7209, 2.8273, 2.9489],\n",
      "        [3.0127, 3.0769, 2.9727, 3.1934, 3.1150],\n",
      "        [2.9190, 2.9595, 2.9883, 3.0269, 2.8594],\n",
      "        [2.8079, 3.1411, 2.9079, 3.0551, 3.0641],\n",
      "        [2.8355, 2.8010, 3.0924, 2.9497, 3.0243],\n",
      "        [2.7468, 2.7993, 2.7197, 2.8269, 2.9491],\n",
      "        [2.7686, 2.8293, 2.8816, 2.7655, 2.7074],\n",
      "        [2.8786, 2.9360, 2.7728, 2.9992, 3.0210]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.7923, 2.9459, 2.7177, 2.8284, 2.8906],\n",
      "        [2.7481, 2.8944, 2.7460, 2.8744, 2.8640],\n",
      "        [2.7637, 2.7538, 2.8383, 2.8529, 2.9719],\n",
      "        [2.9727, 3.1971, 2.9816, 3.1383, 3.1893],\n",
      "        [2.6700, 2.6935, 2.7564, 2.7962, 2.7547],\n",
      "        [2.9592, 3.1170, 3.0978, 3.0650, 2.9507],\n",
      "        [2.8001, 3.0163, 2.8852, 2.8774, 2.9772],\n",
      "        [2.9718, 3.0253, 3.0683, 3.1536, 2.9870],\n",
      "        [2.7407, 2.8628, 2.7825, 2.8903, 2.8507],\n",
      "        [3.1272, 3.2785, 3.0088, 3.0189, 3.0435],\n",
      "        [2.8467, 2.9442, 2.8382, 2.9555, 2.9564],\n",
      "        [2.6729, 2.7416, 2.7899, 2.7925, 2.7800],\n",
      "        [2.7869, 3.0593, 2.8372, 3.0341, 2.9816],\n",
      "        [2.6281, 2.8510, 2.8338, 2.7850, 2.8068],\n",
      "        [2.7967, 2.9378, 2.7568, 2.9365, 2.8969],\n",
      "        [2.8163, 3.0830, 2.9372, 2.9813, 3.0987],\n",
      "        [2.8537, 3.1483, 3.0264, 3.0143, 3.1121],\n",
      "        [2.7959, 2.8091, 2.9404, 2.9188, 2.9721],\n",
      "        [2.6849, 2.7622, 2.6830, 2.8496, 2.7215],\n",
      "        [2.7380, 2.8122, 2.9603, 2.7536, 3.0205],\n",
      "        [2.7930, 2.9095, 2.8758, 2.8536, 2.9145],\n",
      "        [2.7819, 3.0929, 2.9737, 2.9419, 2.9037],\n",
      "        [2.7780, 2.9122, 2.7487, 2.8882, 2.8894],\n",
      "        [2.8634, 2.9756, 2.8438, 2.9226, 3.0992],\n",
      "        [2.8045, 2.9139, 2.8879, 2.8585, 2.9258],\n",
      "        [2.8215, 2.8747, 2.8742, 2.9599, 2.9219],\n",
      "        [2.9386, 2.9573, 3.0581, 2.9891, 2.8363],\n",
      "        [2.7667, 2.7468, 2.8417, 2.7850, 2.8139],\n",
      "        [2.9143, 3.0874, 2.9970, 3.0336, 3.0100],\n",
      "        [2.7157, 2.7086, 2.7585, 2.8065, 2.7580],\n",
      "        [2.7846, 3.0281, 2.8986, 2.8926, 2.8086],\n",
      "        [2.7425, 2.8699, 2.8433, 2.8921, 2.9560],\n",
      "        [2.9869, 3.0521, 2.9822, 3.1472, 3.0370],\n",
      "        [2.9565, 2.7849, 2.9281, 3.1554, 3.1911],\n",
      "        [2.7945, 3.0482, 2.8285, 2.9464, 2.9434],\n",
      "        [2.7446, 2.8935, 2.7420, 2.8692, 2.8514],\n",
      "        [2.7191, 2.6964, 2.7450, 2.8023, 2.7454],\n",
      "        [2.8077, 2.9651, 2.7718, 2.8496, 2.9233],\n",
      "        [2.7511, 2.8804, 2.7779, 2.8628, 2.8841],\n",
      "        [2.8030, 2.8084, 2.9376, 2.9526, 2.9265],\n",
      "        [2.7014, 2.8266, 2.8342, 2.7772, 2.8273],\n",
      "        [2.8286, 2.9484, 2.8162, 2.9323, 3.0051],\n",
      "        [2.7700, 2.7981, 2.7918, 2.9336, 2.8131],\n",
      "        [2.8022, 2.8690, 2.9086, 2.8001, 2.7439],\n",
      "        [2.7987, 2.8438, 2.8732, 2.8979, 2.9215],\n",
      "        [2.7712, 2.8842, 2.7797, 2.9363, 2.8882],\n",
      "        [2.7518, 2.7635, 2.8483, 2.8049, 2.8359],\n",
      "        [3.0217, 3.0354, 2.9044, 3.0705, 3.1083],\n",
      "        [2.8938, 3.0669, 2.8804, 3.1095, 3.0367],\n",
      "        [2.7980, 2.9330, 2.8861, 2.9129, 2.9621],\n",
      "        [2.8568, 3.1721, 2.9964, 3.0367, 3.1897],\n",
      "        [2.6881, 2.8601, 2.9203, 2.9050, 3.0019],\n",
      "        [2.7379, 2.8853, 2.7398, 2.8447, 2.8505],\n",
      "        [2.6994, 2.9383, 2.7465, 2.8924, 2.7849],\n",
      "        [2.6535, 2.7569, 2.7960, 2.7826, 2.7795],\n",
      "        [2.9847, 3.0492, 3.0319, 3.0355, 3.1421],\n",
      "        [2.9304, 2.7700, 2.8003, 2.8388, 2.9121],\n",
      "        [2.9195, 2.9651, 2.9598, 3.0096, 3.1155],\n",
      "        [2.7407, 2.8908, 2.8608, 2.9599, 2.8630],\n",
      "        [2.9316, 2.7698, 2.7988, 2.8519, 2.8966],\n",
      "        [2.8312, 2.8264, 2.9654, 2.9731, 2.9627],\n",
      "        [3.0810, 2.9264, 3.0314, 3.4839, 3.3965],\n",
      "        [3.0202, 3.1995, 2.9794, 2.9336, 2.9909],\n",
      "        [2.7534, 2.8136, 2.8568, 2.8613, 2.8862]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.6263, 2.9286, 2.7834, 2.6203, 2.8575],\n",
      "        [2.6757, 2.7456, 2.7937, 2.7958, 2.7850],\n",
      "        [2.7550, 2.9062, 2.7462, 2.8670, 2.8708],\n",
      "        [2.8306, 2.7934, 2.8879, 2.9038, 2.8751],\n",
      "        [2.7717, 2.9134, 2.8877, 2.8376, 2.8154],\n",
      "        [2.9386, 2.7779, 2.8067, 2.8386, 2.9391],\n",
      "        [2.6565, 2.8304, 2.8569, 2.8210, 2.7961],\n",
      "        [2.9191, 3.0457, 2.9202, 2.9297, 2.9820],\n",
      "        [2.8236, 3.0231, 2.9195, 2.9234, 2.8356],\n",
      "        [2.6518, 3.0500, 2.9092, 2.8337, 3.0546],\n",
      "        [3.0137, 2.9526, 3.0318, 3.1546, 3.0546],\n",
      "        [2.7659, 2.9922, 2.8906, 2.8215, 2.9714],\n",
      "        [2.8106, 3.0458, 2.8363, 2.9542, 2.9608],\n",
      "        [2.8038, 3.0082, 2.8702, 2.8867, 2.9826],\n",
      "        [2.7639, 2.8000, 2.8750, 2.8681, 2.8941],\n",
      "        [2.7483, 2.8584, 2.8458, 2.8678, 2.9973],\n",
      "        [2.6710, 2.7407, 2.7883, 2.7925, 2.7798],\n",
      "        [2.8042, 3.0826, 2.9777, 2.9586, 2.9216],\n",
      "        [2.7875, 3.0323, 2.9026, 2.8961, 2.8138],\n",
      "        [2.8721, 2.9432, 2.7806, 2.9295, 3.0316],\n",
      "        [3.0543, 2.9360, 3.0304, 3.1236, 3.0798],\n",
      "        [2.9604, 3.1239, 3.0504, 3.1043, 3.1434],\n",
      "        [3.0442, 2.9832, 3.0420, 3.1822, 3.0800],\n",
      "        [2.9814, 2.8649, 2.8852, 2.9126, 2.9795],\n",
      "        [2.7612, 3.1438, 2.9792, 2.8835, 2.9315],\n",
      "        [2.8641, 3.0566, 2.8676, 2.9524, 2.9812],\n",
      "        [2.9130, 3.0952, 2.8750, 2.9354, 3.0364],\n",
      "        [3.1761, 2.9606, 3.1094, 3.5695, 3.4759],\n",
      "        [3.1496, 2.9275, 3.0283, 3.4482, 3.4196],\n",
      "        [2.7981, 2.9432, 2.7220, 2.8345, 2.8928],\n",
      "        [2.8434, 2.9578, 3.0398, 2.9697, 3.0211],\n",
      "        [3.0419, 2.9015, 2.9255, 3.3423, 3.2044],\n",
      "        [2.6528, 2.8242, 2.7420, 2.7561, 2.7968],\n",
      "        [2.9325, 3.2107, 3.0160, 3.1842, 3.1845],\n",
      "        [2.5701, 2.7659, 2.7241, 2.6668, 2.7395],\n",
      "        [2.7582, 2.8374, 2.8688, 2.8782, 2.9021],\n",
      "        [2.6782, 2.8523, 2.9028, 2.8425, 2.8031],\n",
      "        [2.7192, 2.8018, 2.8285, 2.8786, 2.8033],\n",
      "        [2.6779, 2.8439, 2.9655, 2.8317, 2.9648],\n",
      "        [3.0165, 2.7807, 2.9431, 3.2401, 3.2448],\n",
      "        [2.6810, 2.8012, 2.8501, 2.8442, 2.7763],\n",
      "        [2.6791, 2.8745, 2.7784, 2.8929, 2.8124],\n",
      "        [2.9777, 3.0819, 2.9142, 2.9997, 3.1340],\n",
      "        [2.7685, 2.9047, 2.8331, 2.8536, 2.8977],\n",
      "        [2.6395, 2.8130, 2.7468, 2.7419, 2.7897],\n",
      "        [2.8192, 3.0873, 2.9412, 2.9848, 3.1039],\n",
      "        [2.8858, 2.9742, 2.8260, 3.0017, 3.0114],\n",
      "        [2.7449, 2.8987, 2.7515, 2.8596, 2.8649],\n",
      "        [2.8250, 2.8525, 2.9708, 2.9490, 2.9750],\n",
      "        [2.9764, 3.1533, 3.0131, 2.9180, 3.0889],\n",
      "        [2.7683, 2.9052, 2.7500, 2.8737, 2.8843],\n",
      "        [2.8344, 2.7149, 2.9920, 2.9531, 2.9925],\n",
      "        [2.7229, 2.8752, 2.7851, 2.8432, 2.8787],\n",
      "        [2.9248, 2.9743, 2.9564, 2.9508, 3.0887],\n",
      "        [2.7599, 2.7710, 2.8938, 2.7788, 2.9362],\n",
      "        [2.9366, 3.1116, 2.8746, 2.9487, 3.0271],\n",
      "        [2.7736, 2.9155, 2.7498, 2.9047, 2.8790],\n",
      "        [3.0230, 3.2036, 2.9834, 2.9371, 2.9962],\n",
      "        [2.8567, 3.1528, 3.0305, 3.0179, 3.1174],\n",
      "        [2.8308, 2.7856, 2.8805, 2.8986, 2.8610],\n",
      "        [2.8606, 2.9542, 2.9545, 2.9313, 2.9780],\n",
      "        [2.6615, 2.8453, 2.9046, 2.8330, 2.7884],\n",
      "        [2.9787, 2.8629, 2.9024, 3.2517, 3.1358],\n",
      "        [2.6036, 2.7264, 2.7369, 2.7099, 2.7458]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.5910, 2.7968, 2.7648, 2.7730, 2.8132],\n",
      "        [2.6653, 2.9298, 3.0156, 2.8638, 2.9610],\n",
      "        [2.7709, 2.8352, 2.8770, 2.8735, 2.9097],\n",
      "        [2.7275, 2.7099, 2.7536, 2.8133, 2.7612],\n",
      "        [2.9724, 3.1432, 3.1013, 3.0432, 2.9251],\n",
      "        [2.8302, 2.7789, 2.8790, 2.8960, 2.8579],\n",
      "        [2.9141, 3.0794, 2.9870, 3.0419, 3.0147],\n",
      "        [2.6579, 2.7661, 2.8022, 2.7856, 2.7905],\n",
      "        [2.8158, 3.0863, 2.9758, 2.9608, 2.9334],\n",
      "        [2.7834, 2.7746, 2.9047, 2.8883, 2.9947],\n",
      "        [2.6384, 2.8768, 2.8491, 2.7839, 2.8117],\n",
      "        [2.9171, 2.8864, 2.9774, 3.0149, 2.9639],\n",
      "        [2.8523, 2.9521, 2.8457, 2.9620, 2.9664],\n",
      "        [2.8778, 2.8974, 2.8790, 3.0531, 3.0032],\n",
      "        [2.8915, 2.9071, 2.8588, 3.0864, 3.0258],\n",
      "        [2.9607, 3.0343, 3.0266, 3.0583, 3.0027],\n",
      "        [2.8687, 3.0665, 2.9466, 3.0868, 3.0103],\n",
      "        [2.6782, 2.6993, 2.7644, 2.8003, 2.7636],\n",
      "        [3.0450, 3.2164, 3.0007, 2.9538, 3.0657],\n",
      "        [2.9424, 3.0242, 3.0381, 3.1325, 2.9789],\n",
      "        [2.7734, 2.7961, 2.8851, 2.8648, 2.8864],\n",
      "        [2.9623, 2.7929, 2.9358, 3.1621, 3.2013],\n",
      "        [2.8439, 2.8936, 2.8676, 2.9547, 3.0347],\n",
      "        [2.7125, 2.8475, 2.7749, 2.9011, 2.8601],\n",
      "        [2.7768, 2.7618, 2.8734, 2.8771, 2.9815],\n",
      "        [2.5409, 2.7416, 2.7762, 2.7080, 2.8042],\n",
      "        [2.6199, 2.8108, 2.7437, 2.7303, 2.7919],\n",
      "        [2.7637, 2.8061, 2.8630, 2.8584, 2.8927],\n",
      "        [2.8171, 3.0605, 2.9199, 2.9769, 3.0997],\n",
      "        [2.9334, 3.0089, 2.9748, 3.0058, 3.1031],\n",
      "        [3.0119, 3.1131, 3.0329, 3.0508, 3.1293],\n",
      "        [2.7358, 2.8213, 2.8429, 2.8886, 2.8280],\n",
      "        [2.7859, 2.8150, 2.8946, 2.8472, 2.9387],\n",
      "        [2.8698, 2.8698, 2.9353, 2.8476, 2.8665],\n",
      "        [2.9408, 2.9796, 2.9938, 3.0963, 3.0180],\n",
      "        [2.6754, 2.7301, 2.7819, 2.8022, 2.7769],\n",
      "        [2.6321, 2.8658, 2.8407, 2.7800, 2.8068],\n",
      "        [2.7612, 2.7651, 2.8852, 2.8544, 2.8709],\n",
      "        [2.7515, 3.1039, 2.8910, 2.9935, 3.0454],\n",
      "        [2.8596, 3.1568, 3.0343, 3.0212, 3.1223],\n",
      "        [2.9161, 3.0790, 2.9917, 3.0546, 3.0149],\n",
      "        [2.7616, 3.1233, 3.0115, 2.9389, 2.9409],\n",
      "        [3.2162, 3.3275, 2.9383, 3.0864, 2.9874],\n",
      "        [2.9165, 3.1000, 3.0107, 3.0207, 3.0001],\n",
      "        [2.8975, 3.0331, 3.0168, 3.0132, 3.0574],\n",
      "        [2.7864, 2.8105, 2.8976, 2.8729, 2.9033],\n",
      "        [2.9500, 3.1726, 2.9752, 3.1389, 3.1262],\n",
      "        [2.6554, 2.7912, 2.8146, 2.7878, 2.8065],\n",
      "        [2.9294, 3.1195, 3.0364, 3.0286, 3.0128],\n",
      "        [2.7342, 2.8575, 2.7907, 2.7994, 2.8270],\n",
      "        [2.7205, 2.7026, 2.8367, 2.8327, 2.9068],\n",
      "        [2.8440, 2.9888, 2.8236, 2.9541, 2.9838],\n",
      "        [3.0517, 2.8985, 2.9281, 3.3446, 3.2120],\n",
      "        [3.1675, 3.2996, 2.9277, 3.0648, 3.0016],\n",
      "        [3.0687, 3.1177, 2.9865, 3.1054, 3.2121],\n",
      "        [2.7459, 2.9051, 3.0021, 2.8349, 2.9139],\n",
      "        [2.7712, 2.8034, 2.8798, 2.8661, 2.8958],\n",
      "        [2.8272, 2.8827, 2.8817, 2.9665, 2.9319],\n",
      "        [2.7777, 2.7650, 2.8884, 2.8768, 2.9828],\n",
      "        [2.6837, 3.0099, 2.9605, 2.8626, 3.0490],\n",
      "        [2.6854, 2.7604, 2.8149, 2.8116, 2.7735],\n",
      "        [2.9323, 2.9116, 2.9157, 2.8340, 2.8333],\n",
      "        [2.7213, 2.7163, 2.7658, 2.8128, 2.7676],\n",
      "        [3.0818, 3.0166, 3.0537, 3.2099, 3.1482]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.8719, 2.9873, 2.8562, 2.9322, 3.1135],\n",
      "        [2.7809, 2.8886, 2.8061, 2.9175, 3.0157],\n",
      "        [2.9143, 2.9200, 2.9712, 3.0591, 2.9064],\n",
      "        [2.9232, 3.0112, 2.9945, 3.0040, 3.1268],\n",
      "        [3.0834, 2.9422, 3.0482, 3.4949, 3.4143],\n",
      "        [2.8629, 2.8483, 2.9271, 2.8366, 2.8953],\n",
      "        [2.6442, 2.8121, 2.8274, 2.7835, 2.7982],\n",
      "        [2.8611, 3.0274, 2.9496, 2.9383, 2.8593],\n",
      "        [2.8047, 2.9490, 2.7686, 2.9456, 2.9110],\n",
      "        [2.6396, 2.9370, 2.7107, 2.8712, 2.7688],\n",
      "        [2.6843, 2.8001, 2.7265, 2.8577, 2.7264],\n",
      "        [2.9548, 2.8516, 2.8866, 3.2799, 3.1190],\n",
      "        [2.9103, 2.9739, 2.9554, 2.9241, 2.7824],\n",
      "        [3.1210, 3.0747, 3.0265, 3.1160, 3.1331],\n",
      "        [2.9070, 3.0334, 2.8974, 3.0357, 3.0143],\n",
      "        [2.7622, 2.8694, 2.8242, 2.9371, 2.9159],\n",
      "        [2.6367, 2.8483, 2.9808, 2.7755, 2.9802],\n",
      "        [2.7394, 2.7867, 2.8630, 2.8249, 2.8691],\n",
      "        [2.8794, 3.0138, 3.0327, 3.0225, 3.0264],\n",
      "        [2.9476, 3.1698, 2.9848, 3.1496, 3.1208],\n",
      "        [2.8341, 2.7966, 3.0988, 2.9396, 3.0140],\n",
      "        [2.8707, 2.9572, 2.8501, 2.9333, 3.1067],\n",
      "        [2.7857, 2.7550, 2.8533, 2.7898, 2.8232],\n",
      "        [3.0149, 2.9490, 3.0242, 3.1425, 3.0467],\n",
      "        [2.8871, 2.8763, 2.9447, 2.9591, 2.9315],\n",
      "        [2.7671, 3.0380, 2.8969, 2.8806, 2.8137],\n",
      "        [2.8360, 2.8007, 2.8927, 2.9153, 2.8810],\n",
      "        [2.9190, 2.9706, 2.9657, 2.9330, 2.8161],\n",
      "        [2.7653, 2.8444, 2.8798, 2.8855, 2.9135],\n",
      "        [3.0006, 2.8724, 2.9147, 3.2916, 3.1658],\n",
      "        [3.0404, 2.7849, 2.9494, 3.2708, 3.2696],\n",
      "        [2.8135, 3.0962, 3.0309, 3.0235, 3.0928],\n",
      "        [2.9318, 3.1230, 3.0410, 3.0315, 3.0172],\n",
      "        [2.8236, 3.1132, 2.9663, 2.9983, 3.1169],\n",
      "        [2.8659, 2.9614, 2.9627, 2.9372, 2.9870],\n",
      "        [2.6732, 2.7535, 2.8013, 2.8056, 2.7939],\n",
      "        [2.6737, 3.0196, 2.8688, 2.7001, 2.9912],\n",
      "        [2.7488, 2.9022, 2.8729, 2.9691, 2.8770],\n",
      "        [2.6694, 2.9317, 3.0201, 2.8680, 2.9616],\n",
      "        [2.8872, 2.9720, 2.8735, 2.9423, 2.9388],\n",
      "        [2.7206, 2.9290, 2.7958, 2.9503, 2.8383],\n",
      "        [2.8358, 2.8007, 2.8959, 2.9097, 2.8841],\n",
      "        [2.7865, 2.7870, 2.7825, 2.9539, 2.8068],\n",
      "        [2.9151, 3.0653, 2.9199, 2.9905, 2.9963],\n",
      "        [3.0939, 3.2180, 3.0986, 3.3221, 3.2266],\n",
      "        [2.8186, 2.9945, 2.8352, 2.9725, 2.9470],\n",
      "        [2.6395, 2.8895, 2.8567, 2.7898, 2.8266],\n",
      "        [2.7495, 2.8952, 2.7509, 2.8586, 2.8721],\n",
      "        [2.7888, 2.8140, 2.9020, 2.8757, 2.9075],\n",
      "        [3.0829, 3.0339, 3.0319, 3.0790, 3.0873],\n",
      "        [3.0902, 3.0008, 3.0649, 3.2325, 3.1706],\n",
      "        [2.7118, 3.0197, 2.8554, 2.8256, 2.7951],\n",
      "        [2.7611, 2.8190, 2.8750, 2.8798, 2.9106],\n",
      "        [2.6124, 2.8867, 2.9442, 2.7818, 2.8966],\n",
      "        [2.6594, 2.8428, 2.7536, 2.7643, 2.8135],\n",
      "        [2.8483, 3.0467, 2.9222, 2.8788, 3.0221],\n",
      "        [2.7689, 2.9190, 2.7598, 2.8931, 2.8869],\n",
      "        [2.7696, 2.8360, 2.8833, 2.8893, 2.9289],\n",
      "        [2.5981, 2.7876, 2.7405, 2.6946, 2.7721],\n",
      "        [3.0833, 3.0258, 3.0664, 3.2650, 3.1958],\n",
      "        [2.9182, 3.0677, 2.8703, 2.9606, 3.0557],\n",
      "        [2.8518, 3.0711, 3.0415, 3.0095, 2.9652],\n",
      "        [3.1451, 2.9735, 3.1220, 3.5439, 3.4875],\n",
      "        [2.6647, 2.8164, 2.8293, 2.7962, 2.8316]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.0198, 3.0262, 3.0327, 3.1133, 2.9780],\n",
      "        [3.0357, 3.0728, 3.0238, 3.2029, 3.0972],\n",
      "        [2.7149, 2.8703, 2.7507, 2.8191, 2.8387],\n",
      "        [2.6445, 2.8333, 2.7553, 2.7467, 2.8073],\n",
      "        [2.6482, 2.9241, 2.8746, 2.8108, 2.8587],\n",
      "        [2.8083, 2.9522, 2.7726, 2.9481, 2.9149],\n",
      "        [2.8449, 3.0862, 2.9152, 3.0768, 3.0196],\n",
      "        [2.6493, 2.8365, 2.8463, 2.7978, 2.8237],\n",
      "        [2.7441, 3.0653, 2.9428, 2.9364, 3.0791],\n",
      "        [2.6935, 2.8117, 2.8687, 2.8830, 2.9063],\n",
      "        [2.7797, 2.8427, 2.8972, 2.7731, 2.7275],\n",
      "        [2.8762, 3.2094, 3.0529, 3.0584, 3.1643],\n",
      "        [2.7723, 2.9744, 2.8516, 2.8969, 2.9742],\n",
      "        [2.6839, 2.8203, 2.8823, 2.9008, 2.9196],\n",
      "        [2.9800, 2.7977, 2.7966, 2.8291, 2.9799],\n",
      "        [2.8146, 3.1859, 2.9037, 3.0994, 3.0944],\n",
      "        [2.6378, 2.8874, 2.8564, 2.7864, 2.8217],\n",
      "        [2.9235, 3.0585, 2.9211, 2.9682, 3.0010],\n",
      "        [2.6500, 2.7495, 2.7982, 2.7734, 2.7737],\n",
      "        [2.8377, 2.8883, 2.9797, 2.9775, 2.9290],\n",
      "        [2.9823, 3.1493, 3.1147, 3.0453, 2.9380],\n",
      "        [2.7785, 2.7613, 2.8577, 2.7970, 2.8319],\n",
      "        [2.7560, 3.1246, 3.0137, 2.9430, 2.9386],\n",
      "        [2.6957, 2.7791, 2.6956, 2.8630, 2.7277],\n",
      "        [2.8068, 3.0126, 2.8876, 2.8956, 2.9883],\n",
      "        [2.9067, 3.0397, 2.9190, 2.8772, 2.9751],\n",
      "        [2.6396, 2.8978, 2.8647, 2.7992, 2.8394],\n",
      "        [2.9191, 3.0520, 2.9338, 2.9108, 2.9872],\n",
      "        [3.0537, 2.9936, 3.0559, 3.1910, 3.0929],\n",
      "        [2.7570, 2.8689, 2.8582, 2.8762, 3.0101],\n",
      "        [2.7770, 2.8420, 2.8856, 2.8790, 2.9179],\n",
      "        [2.9072, 2.9265, 2.9599, 2.9115, 2.8475],\n",
      "        [2.8061, 3.0074, 2.8666, 2.9889, 2.9162],\n",
      "        [2.6199, 2.7218, 2.7853, 2.7450, 2.7169],\n",
      "        [2.8403, 2.9063, 2.8938, 2.9977, 2.9422],\n",
      "        [2.6880, 2.8848, 2.7902, 2.9010, 2.8251],\n",
      "        [2.6083, 2.8036, 2.7465, 2.7055, 2.7795],\n",
      "        [3.0982, 3.2214, 3.1035, 3.3249, 3.2307],\n",
      "        [2.7144, 3.0290, 2.8405, 2.8107, 2.8143],\n",
      "        [2.9215, 2.9368, 3.0433, 2.9484, 2.8244],\n",
      "        [2.8840, 2.8803, 2.9321, 2.9450, 2.9188],\n",
      "        [2.7600, 2.7646, 2.9098, 2.7578, 2.9537],\n",
      "        [2.9308, 2.9619, 3.0060, 3.0423, 2.8603],\n",
      "        [2.9322, 2.9209, 2.9026, 3.1850, 3.1016],\n",
      "        [2.6848, 2.8042, 2.8651, 2.8922, 2.9016],\n",
      "        [2.6354, 2.9030, 2.8601, 2.7878, 2.8268],\n",
      "        [3.0572, 3.1497, 3.0669, 3.0988, 3.1808],\n",
      "        [2.9715, 3.0380, 3.0722, 3.1515, 2.9975],\n",
      "        [2.8360, 2.8027, 3.1126, 2.9479, 3.0304],\n",
      "        [2.6897, 2.8032, 2.7336, 2.8629, 2.7327],\n",
      "        [2.8022, 2.8821, 2.9074, 2.8600, 3.1138],\n",
      "        [2.7982, 2.7511, 2.8531, 2.7724, 2.8163],\n",
      "        [2.6729, 2.9349, 3.0243, 2.8706, 2.9656],\n",
      "        [2.8215, 2.8851, 2.9523, 2.9192, 3.0364],\n",
      "        [2.7011, 2.8584, 2.7547, 2.8039, 2.8311],\n",
      "        [2.7724, 2.8562, 2.9769, 3.0115, 3.1108],\n",
      "        [2.4821, 2.7022, 2.7596, 2.6636, 2.7564],\n",
      "        [2.9937, 2.7911, 2.9419, 3.2118, 3.2287],\n",
      "        [2.6802, 2.8745, 2.7755, 2.8693, 2.8286],\n",
      "        [2.7697, 2.8128, 2.8715, 2.8638, 2.9008],\n",
      "        [2.7985, 2.7971, 2.9320, 2.9237, 3.0176],\n",
      "        [2.7917, 3.0452, 2.9540, 2.9806, 3.1013],\n",
      "        [2.7343, 2.9537, 2.8851, 2.7662, 2.8351],\n",
      "        [2.6924, 3.0329, 2.8853, 2.7185, 3.0155]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.9684, 3.1871, 3.0063, 3.1680, 3.1428],\n",
      "        [2.6113, 2.8048, 2.6536, 2.7981, 2.7435],\n",
      "        [2.7719, 2.9702, 2.8445, 2.9069, 2.9798],\n",
      "        [3.0582, 3.1297, 3.0234, 3.2507, 3.1835],\n",
      "        [2.9081, 3.0287, 2.8755, 2.9655, 3.1097],\n",
      "        [2.6833, 2.7744, 2.8351, 2.8122, 2.7778],\n",
      "        [2.7825, 2.8065, 2.8972, 2.8726, 2.8981],\n",
      "        [2.7218, 2.8576, 2.7870, 2.9085, 2.8717],\n",
      "        [2.9984, 3.1116, 2.9517, 3.0493, 3.1724],\n",
      "        [2.9166, 3.0250, 3.0170, 3.0415, 2.9662],\n",
      "        [2.8392, 2.7893, 2.8911, 2.9038, 2.8696],\n",
      "        [2.7873, 2.8037, 2.9234, 2.8879, 2.9115],\n",
      "        [2.7786, 2.9372, 2.8998, 2.8376, 2.8249],\n",
      "        [2.6998, 2.8339, 2.8813, 2.8549, 2.8039],\n",
      "        [2.7792, 2.8628, 2.9517, 2.8177, 3.0466],\n",
      "        [2.9461, 3.0648, 2.9582, 2.9999, 3.1090],\n",
      "        [2.7101, 2.8783, 2.7685, 2.8099, 2.8471],\n",
      "        [2.7524, 2.9031, 2.7589, 2.8583, 2.8717],\n",
      "        [3.0378, 3.0435, 2.9878, 3.0315, 3.0701],\n",
      "        [2.7866, 3.1532, 2.9309, 3.0454, 3.0921],\n",
      "        [2.8591, 2.9625, 2.8549, 2.9725, 2.9831],\n",
      "        [2.7405, 2.8572, 2.6902, 2.9283, 2.7674],\n",
      "        [3.1390, 3.1439, 3.0716, 3.1839, 3.1905],\n",
      "        [2.7875, 2.9241, 2.7558, 2.9073, 2.8818],\n",
      "        [2.7998, 3.0468, 2.9190, 2.9072, 2.8304],\n",
      "        [2.7700, 2.8468, 2.8852, 2.8874, 2.9171],\n",
      "        [2.9162, 3.0488, 2.9278, 2.8885, 2.9814],\n",
      "        [2.7833, 2.9275, 2.9036, 2.8483, 2.8317],\n",
      "        [2.9267, 3.1407, 2.9588, 3.0269, 3.0504],\n",
      "        [3.0202, 2.9573, 3.0306, 3.1170, 3.0426],\n",
      "        [2.9364, 2.9888, 2.9727, 2.9619, 3.1057],\n",
      "        [2.8691, 3.1679, 3.0473, 3.0294, 3.1344],\n",
      "        [2.7181, 2.7700, 2.8231, 2.8358, 2.7977],\n",
      "        [2.9074, 3.0838, 2.9001, 3.1232, 3.0561],\n",
      "        [2.8462, 2.7288, 3.0076, 2.9638, 3.0087],\n",
      "        [2.7629, 2.8691, 2.8680, 2.8683, 3.0316],\n",
      "        [2.8571, 3.2093, 2.9664, 3.1229, 3.1328],\n",
      "        [2.9103, 2.9302, 2.9638, 2.9139, 2.8510],\n",
      "        [2.6385, 2.9152, 2.8726, 2.7911, 2.8393],\n",
      "        [2.9257, 3.1107, 3.0234, 3.0287, 3.0123],\n",
      "        [2.9100, 3.0433, 2.9228, 2.8796, 2.9786],\n",
      "        [3.0412, 3.1885, 2.9000, 2.9887, 3.0309],\n",
      "        [2.7160, 2.8445, 2.8532, 2.7908, 2.8487],\n",
      "        [2.7718, 2.8114, 2.8804, 2.8677, 2.9021],\n",
      "        [2.8114, 2.9558, 2.7763, 2.9504, 2.9184],\n",
      "        [2.7924, 2.7850, 2.9170, 2.8961, 3.0065],\n",
      "        [2.8434, 3.0105, 2.8587, 2.9833, 2.9666],\n",
      "        [2.6500, 2.7069, 2.7750, 2.7893, 2.7950],\n",
      "        [2.9469, 3.1007, 3.0016, 2.9159, 3.0508],\n",
      "        [2.6543, 2.8509, 2.8747, 2.8111, 2.8250],\n",
      "        [2.7179, 3.0322, 2.8626, 2.8271, 2.8120],\n",
      "        [2.9128, 3.0709, 3.0164, 2.9650, 2.8856],\n",
      "        [2.9770, 3.1371, 3.0735, 3.1242, 3.1683],\n",
      "        [2.6037, 2.7965, 2.7510, 2.6934, 2.7761],\n",
      "        [2.8869, 2.9079, 2.8913, 3.0609, 3.0152],\n",
      "        [2.9454, 3.2254, 3.0330, 3.1951, 3.2019],\n",
      "        [3.0289, 2.7950, 2.9595, 3.2512, 3.2618],\n",
      "        [2.6582, 2.8550, 2.8805, 2.8166, 2.8303],\n",
      "        [2.8099, 3.0100, 2.8323, 3.0581, 2.8743],\n",
      "        [3.0548, 3.1243, 2.9913, 3.1041, 3.2009],\n",
      "        [2.9800, 3.0902, 2.9237, 3.0110, 3.1479],\n",
      "        [2.8684, 2.9090, 2.8906, 3.0212, 2.9700],\n",
      "        [2.9426, 2.9993, 2.9944, 3.0127, 3.1284],\n",
      "        [2.8847, 3.0146, 2.8731, 2.9957, 3.0630]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.8210, 3.1931, 2.9113, 3.1039, 3.1014],\n",
      "        [3.1178, 3.2219, 3.1187, 3.3346, 3.2351],\n",
      "        [2.6071, 2.8003, 2.7514, 2.6998, 2.7861],\n",
      "        [2.9345, 3.0630, 2.9400, 2.9425, 3.0017],\n",
      "        [2.8229, 3.0229, 2.8907, 2.9884, 2.9332],\n",
      "        [2.8239, 3.1068, 3.0430, 3.0309, 3.1040],\n",
      "        [2.6144, 2.8055, 2.7549, 2.7087, 2.7839],\n",
      "        [2.8899, 2.9113, 2.8949, 3.0631, 3.0185],\n",
      "        [2.6651, 2.7995, 2.8318, 2.7940, 2.8087],\n",
      "        [2.6468, 2.8399, 2.7654, 2.7558, 2.8162],\n",
      "        [2.7218, 2.8914, 2.7690, 2.8325, 2.8628],\n",
      "        [2.7021, 2.6903, 2.8845, 2.6475, 2.9310],\n",
      "        [2.7860, 2.8279, 2.8262, 2.9367, 2.8475],\n",
      "        [2.7707, 2.8749, 2.8738, 2.8726, 3.0375],\n",
      "        [2.9923, 3.0301, 3.0617, 2.9775, 2.8721],\n",
      "        [2.7577, 2.9198, 2.8506, 2.9466, 2.9668],\n",
      "        [2.7979, 2.9399, 2.7651, 2.9214, 2.8969],\n",
      "        [2.7753, 3.0184, 2.9282, 2.8256, 2.9975],\n",
      "        [2.8161, 2.9548, 2.9092, 2.9291, 2.9874],\n",
      "        [2.7710, 2.9696, 2.8130, 3.0075, 2.8483],\n",
      "        [3.0802, 3.0483, 3.0092, 3.2034, 3.1221],\n",
      "        [2.7855, 2.8499, 2.9042, 2.7776, 2.7341],\n",
      "        [2.6922, 2.7426, 2.8005, 2.8127, 2.7948],\n",
      "        [2.6612, 2.8583, 2.8839, 2.8187, 2.8335],\n",
      "        [2.7880, 2.9143, 2.8077, 2.8881, 2.9243],\n",
      "        [2.9501, 3.1040, 3.0053, 2.9181, 3.0541],\n",
      "        [2.7016, 2.7346, 2.7915, 2.8226, 2.7928],\n",
      "        [2.8646, 2.9624, 2.8411, 2.9603, 2.9601],\n",
      "        [2.9123, 3.0892, 2.9045, 3.1263, 3.0626],\n",
      "        [2.7891, 2.8439, 2.7676, 2.8650, 3.0016],\n",
      "        [2.8809, 2.9779, 2.9795, 2.9661, 3.0806],\n",
      "        [2.9660, 3.0028, 3.0241, 3.1208, 3.0279],\n",
      "        [3.0917, 3.1919, 3.0303, 3.3328, 3.2242],\n",
      "        [2.7803, 2.8338, 2.8835, 2.8735, 2.9118],\n",
      "        [2.7748, 2.8148, 2.8839, 2.8698, 2.9053],\n",
      "        [3.1128, 3.2899, 3.0565, 3.0225, 3.1064],\n",
      "        [2.9283, 2.9787, 2.9347, 3.0322, 3.1091],\n",
      "        [2.8977, 3.0839, 2.9914, 3.1171, 3.0186],\n",
      "        [2.6974, 2.7738, 2.8301, 2.8212, 2.7881],\n",
      "        [2.9697, 3.0316, 3.0581, 3.0069, 3.1155],\n",
      "        [2.8062, 2.9536, 2.7698, 2.9404, 2.9122],\n",
      "        [2.9019, 2.9736, 3.0461, 2.9554, 2.9314],\n",
      "        [2.8540, 3.0910, 2.9229, 3.0830, 3.0269],\n",
      "        [2.7740, 3.1214, 2.9246, 3.0145, 3.0924],\n",
      "        [2.7772, 3.0485, 2.9086, 2.8879, 2.8244],\n",
      "        [2.8526, 3.0389, 2.9512, 2.9405, 2.8614],\n",
      "        [2.7754, 2.7889, 2.9174, 2.7960, 2.9547],\n",
      "        [3.0581, 3.1277, 2.9951, 3.1064, 3.2042],\n",
      "        [2.9723, 3.1385, 2.8848, 2.9544, 3.0352],\n",
      "        [2.7835, 3.1224, 2.9901, 2.9284, 2.9025],\n",
      "        [2.7971, 2.9381, 2.8948, 2.9066, 2.9575],\n",
      "        [3.0424, 2.9053, 2.9372, 3.3200, 3.1977],\n",
      "        [3.1537, 3.2913, 2.9385, 3.0549, 3.0330],\n",
      "        [2.5669, 2.7621, 2.7906, 2.7352, 2.8156],\n",
      "        [2.7345, 2.8596, 2.7886, 2.9073, 2.8766],\n",
      "        [2.7240, 2.8416, 2.8516, 2.8026, 2.8523],\n",
      "        [2.7124, 2.9425, 2.8859, 2.7533, 2.8266],\n",
      "        [2.9002, 3.0262, 3.0390, 2.9403, 2.9027],\n",
      "        [2.6583, 2.8063, 2.8315, 2.7913, 2.8065],\n",
      "        [2.9292, 3.1232, 3.0323, 3.0426, 3.0345],\n",
      "        [2.6698, 2.8445, 2.8846, 2.8297, 2.8243],\n",
      "        [2.6460, 2.8416, 2.8406, 2.7885, 2.8120],\n",
      "        [2.6814, 2.8530, 2.9082, 2.8535, 2.8020],\n",
      "        [2.9350, 2.9100, 2.9177, 3.2183, 3.1266]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.0435, 3.0603, 2.9324, 3.0894, 3.1360],\n",
      "        [2.7494, 3.1462, 3.0169, 2.9260, 2.9362],\n",
      "        [2.7399, 2.9999, 2.8606, 2.8583, 2.8663],\n",
      "        [2.8322, 3.1045, 2.9965, 2.9734, 2.9516],\n",
      "        [2.9405, 2.9918, 2.9875, 3.0289, 3.1447],\n",
      "        [2.9819, 3.0941, 3.0057, 3.0397, 3.1242],\n",
      "        [2.7439, 2.8275, 3.0082, 2.7269, 3.0648],\n",
      "        [2.6937, 2.8671, 2.7672, 2.7984, 2.8384],\n",
      "        [2.8250, 2.8291, 2.9737, 2.9710, 3.0450],\n",
      "        [3.0796, 2.9766, 2.9521, 3.0282, 3.0748],\n",
      "        [2.8048, 2.9211, 3.0535, 2.9564, 3.0693],\n",
      "        [2.7230, 2.8327, 2.8563, 2.7578, 2.9793],\n",
      "        [2.8069, 2.8571, 2.9383, 2.9236, 2.9492],\n",
      "        [2.7738, 2.8448, 2.8862, 2.8838, 2.9162],\n",
      "        [2.7433, 2.9006, 2.7657, 2.8461, 2.8691],\n",
      "        [2.8814, 3.0072, 2.8720, 2.9814, 3.0652],\n",
      "        [2.9391, 3.0184, 3.0033, 3.0485, 3.1266],\n",
      "        [2.7939, 2.9027, 2.8209, 2.9267, 3.0291],\n",
      "        [2.6499, 2.8482, 2.8464, 2.7886, 2.8145],\n",
      "        [2.7749, 2.8636, 2.8008, 2.9248, 2.8696],\n",
      "        [2.6290, 2.7323, 2.7953, 2.7512, 2.7263],\n",
      "        [2.8940, 2.7580, 3.0472, 2.9739, 2.9791],\n",
      "        [2.7817, 2.8740, 2.8241, 2.9456, 2.8967],\n",
      "        [3.0454, 2.9567, 3.0453, 3.1487, 3.0666],\n",
      "        [2.9227, 3.0702, 3.0193, 2.9678, 2.8804],\n",
      "        [2.9154, 3.0931, 2.9080, 3.1284, 3.0656],\n",
      "        [2.8113, 2.9555, 2.7684, 2.9426, 2.9135],\n",
      "        [2.7160, 2.8852, 2.7751, 2.8139, 2.8531],\n",
      "        [2.7759, 2.9613, 2.8403, 2.9193, 2.9854],\n",
      "        [3.1216, 3.2314, 3.1036, 3.3366, 3.2461],\n",
      "        [2.9230, 3.0849, 2.8721, 2.9608, 3.0509],\n",
      "        [2.7988, 2.9429, 2.7759, 2.9277, 2.9109],\n",
      "        [2.9318, 3.0820, 2.8858, 2.9701, 3.0696],\n",
      "        [2.6977, 2.9093, 2.8101, 2.8225, 2.9011],\n",
      "        [2.6787, 2.7715, 2.8163, 2.7995, 2.8027],\n",
      "        [2.8094, 2.8972, 2.9155, 2.8664, 3.1229],\n",
      "        [2.7686, 2.9193, 2.7719, 2.8921, 2.8913],\n",
      "        [2.8593, 2.9621, 2.9901, 2.9618, 2.9983],\n",
      "        [2.6446, 2.9137, 2.8703, 2.7941, 2.8363],\n",
      "        [2.8598, 2.9437, 2.9813, 2.9590, 2.9790],\n",
      "        [2.9088, 3.0810, 2.8692, 2.9541, 3.0444],\n",
      "        [2.9137, 3.0912, 2.9072, 3.1275, 3.0625],\n",
      "        [2.9042, 2.8993, 2.8994, 3.0944, 3.0248],\n",
      "        [3.1033, 3.0645, 3.1243, 3.2531, 3.1610],\n",
      "        [2.6407, 2.7497, 2.7677, 2.7468, 2.7798],\n",
      "        [2.6294, 2.8229, 2.7593, 2.7304, 2.7997],\n",
      "        [2.6736, 2.8698, 2.8914, 2.8343, 2.8327],\n",
      "        [2.7048, 2.7896, 2.7056, 2.8692, 2.7371],\n",
      "        [2.7802, 2.8497, 2.8920, 2.8832, 2.9191],\n",
      "        [2.8200, 2.8696, 2.8998, 2.9164, 2.9494],\n",
      "        [3.0972, 3.2058, 3.1001, 3.1505, 3.2592],\n",
      "        [2.7489, 2.8745, 2.8090, 2.8107, 2.8445],\n",
      "        [2.9944, 3.1218, 3.0129, 3.0452, 3.1642],\n",
      "        [2.7782, 3.0222, 2.9316, 2.8277, 3.0005],\n",
      "        [3.1245, 2.9440, 3.0556, 3.5204, 3.4187],\n",
      "        [2.8440, 2.8212, 2.9125, 2.9262, 2.9317],\n",
      "        [2.8277, 2.8847, 2.8965, 2.9435, 2.9469],\n",
      "        [2.7583, 2.9101, 2.7655, 2.8623, 2.8777],\n",
      "        [2.9334, 3.0012, 2.8299, 3.0478, 3.0839],\n",
      "        [2.9143, 3.1577, 2.9498, 3.0309, 3.0494],\n",
      "        [2.7718, 3.0857, 2.9752, 2.9676, 3.1030],\n",
      "        [2.6387, 2.8285, 2.7657, 2.7333, 2.8061],\n",
      "        [2.6490, 2.8454, 2.8438, 2.7904, 2.8148],\n",
      "        [2.8897, 2.8729, 2.9546, 2.8424, 2.9489]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.6563, 2.8472, 2.7682, 2.7546, 2.8193],\n",
      "        [2.7620, 3.0452, 2.9788, 2.8004, 3.0077],\n",
      "        [2.6571, 2.8634, 2.8579, 2.8049, 2.8372],\n",
      "        [3.0988, 2.9547, 3.0678, 3.4994, 3.4327],\n",
      "        [2.7744, 2.9085, 2.8067, 2.8823, 2.9140],\n",
      "        [2.8346, 2.8907, 2.9258, 2.8186, 2.7801],\n",
      "        [2.7786, 2.8541, 2.9718, 2.8060, 3.0518],\n",
      "        [2.7812, 3.0257, 2.9347, 2.8295, 3.0031],\n",
      "        [2.7212, 2.8072, 2.8660, 2.8671, 2.9069],\n",
      "        [2.7619, 2.7636, 2.8180, 2.8143, 2.9767],\n",
      "        [2.9362, 2.9833, 3.0459, 2.9785, 2.9205],\n",
      "        [2.8168, 2.9744, 2.7476, 2.8485, 2.9206],\n",
      "        [2.6500, 2.8865, 2.8621, 2.7932, 2.8270],\n",
      "        [2.8034, 2.8031, 2.9348, 2.9168, 3.0194],\n",
      "        [2.8012, 2.7957, 2.9268, 2.9022, 3.0154],\n",
      "        [2.9142, 3.0522, 2.9125, 3.0511, 3.0251],\n",
      "        [2.9422, 3.1809, 2.9936, 3.1310, 3.1296],\n",
      "        [2.7643, 2.9089, 2.7644, 2.8805, 2.8658],\n",
      "        [2.7890, 3.0738, 2.8447, 3.0318, 2.9966],\n",
      "        [2.9343, 2.9923, 3.0663, 2.9855, 2.9145],\n",
      "        [3.0013, 3.1837, 3.1587, 3.0947, 2.9822],\n",
      "        [2.7940, 2.9335, 2.9100, 2.8475, 2.8410],\n",
      "        [2.9722, 2.8888, 2.9206, 3.2030, 3.1113],\n",
      "        [2.9363, 3.1049, 2.9932, 2.9107, 3.0452],\n",
      "        [2.7958, 2.9129, 2.8092, 2.9561, 2.9187],\n",
      "        [2.9520, 3.2680, 2.9897, 3.1958, 3.2056],\n",
      "        [2.8428, 3.1004, 2.9092, 3.0771, 3.0291],\n",
      "        [2.7033, 2.7333, 2.7965, 2.8280, 2.7883],\n",
      "        [2.7952, 2.8470, 2.9337, 2.9052, 2.9375],\n",
      "        [2.8759, 2.9590, 2.9176, 3.0701, 2.9624],\n",
      "        [2.7770, 2.8397, 2.8841, 2.8774, 2.9155],\n",
      "        [2.8016, 2.7724, 2.8711, 2.8008, 2.8393],\n",
      "        [2.6476, 2.8028, 2.7228, 2.8345, 2.7417],\n",
      "        [3.0492, 3.0876, 3.0393, 3.2118, 3.1098],\n",
      "        [2.7633, 2.8995, 2.7978, 2.8735, 2.9002],\n",
      "        [2.7130, 3.0363, 2.8952, 2.7064, 2.9899],\n",
      "        [3.0561, 2.9584, 3.0465, 3.1116, 3.0851],\n",
      "        [2.7908, 2.8117, 2.9097, 2.8851, 2.9000],\n",
      "        [2.5116, 2.7212, 2.7750, 2.6889, 2.7956],\n",
      "        [3.0075, 2.9591, 2.9549, 2.9936, 3.0596],\n",
      "        [2.7500, 2.8906, 2.8602, 2.9345, 2.9276],\n",
      "        [2.8231, 2.8119, 2.9574, 2.9465, 3.0322],\n",
      "        [2.7966, 2.7904, 2.9165, 2.8946, 3.0097],\n",
      "        [2.7918, 2.7937, 2.9088, 2.8733, 2.9108],\n",
      "        [2.7932, 2.9371, 2.7741, 2.9103, 2.9063],\n",
      "        [2.6642, 2.8134, 2.8376, 2.7950, 2.8120],\n",
      "        [2.9185, 3.0967, 2.9111, 3.1303, 3.0683],\n",
      "        [2.6778, 2.8413, 2.8736, 2.8298, 2.8133],\n",
      "        [2.9964, 3.0551, 3.1005, 3.1747, 3.0187],\n",
      "        [2.8531, 2.9770, 2.8470, 2.9528, 3.0352],\n",
      "        [2.7811, 2.9256, 2.8515, 2.8608, 2.9126],\n",
      "        [3.0817, 2.9535, 3.0664, 3.1733, 3.1067],\n",
      "        [2.7943, 2.8072, 2.9202, 2.8732, 2.9118],\n",
      "        [2.8529, 3.0212, 2.8691, 2.9895, 2.9754],\n",
      "        [2.9360, 3.1514, 2.9690, 3.0329, 3.0593],\n",
      "        [2.8192, 3.0770, 2.8587, 2.9660, 2.9741],\n",
      "        [2.8066, 2.8459, 2.9509, 2.9212, 2.9572],\n",
      "        [2.8713, 3.2452, 2.9886, 3.1390, 3.1602],\n",
      "        [2.7324, 2.8746, 2.9408, 2.8573, 2.9475],\n",
      "        [2.9197, 3.0940, 2.8837, 2.9634, 3.0545],\n",
      "        [2.8885, 3.0054, 2.8746, 2.9436, 3.1300],\n",
      "        [3.0213, 3.0482, 3.0032, 3.0227, 3.0864],\n",
      "        [2.8078, 2.9246, 3.0567, 2.9583, 3.0720],\n",
      "        [2.8528, 2.7183, 3.0081, 2.9372, 2.9424]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.1635, 3.3015, 2.9481, 3.0606, 3.0410],\n",
      "        [2.6982, 2.7677, 2.8138, 2.8151, 2.8094],\n",
      "        [2.9890, 2.9728, 3.0276, 3.0855, 3.0235],\n",
      "        [2.8323, 2.9071, 2.9322, 2.8297, 2.7761],\n",
      "        [2.9384, 3.1038, 3.0175, 3.0705, 3.0385],\n",
      "        [3.0335, 3.1029, 3.1308, 3.0603, 2.9765],\n",
      "        [2.4985, 2.7191, 2.7756, 2.6734, 2.7707],\n",
      "        [3.0008, 3.1781, 3.1312, 3.0674, 2.9538],\n",
      "        [2.7660, 2.8452, 2.9930, 2.7763, 3.0540],\n",
      "        [2.8096, 2.8710, 2.7918, 2.8780, 3.0134],\n",
      "        [2.6636, 2.8325, 2.8472, 2.7957, 2.8165],\n",
      "        [2.7347, 2.7264, 2.9108, 2.6814, 2.9578],\n",
      "        [2.7973, 2.8021, 2.7970, 2.9637, 2.8205],\n",
      "        [2.7118, 2.7007, 2.8933, 2.6531, 2.9389],\n",
      "        [2.7932, 2.8277, 2.9046, 2.8816, 2.9185],\n",
      "        [2.6904, 2.8099, 2.7992, 2.8092, 2.8228],\n",
      "        [2.7779, 2.8348, 2.7560, 2.8506, 2.9857],\n",
      "        [2.8084, 2.8395, 2.9194, 2.8628, 2.9618],\n",
      "        [2.9615, 2.8049, 2.8350, 2.8565, 2.9666],\n",
      "        [2.6925, 2.7739, 2.8213, 2.8179, 2.8120],\n",
      "        [2.9096, 2.9097, 2.9458, 2.8176, 2.8092],\n",
      "        [2.6991, 2.8320, 2.8924, 2.9090, 2.9369],\n",
      "        [2.8766, 2.8884, 2.9234, 2.8260, 2.7824],\n",
      "        [2.7469, 3.0066, 2.8666, 2.8621, 2.8713],\n",
      "        [2.5104, 2.7169, 2.7693, 2.6882, 2.7862],\n",
      "        [2.8829, 2.8728, 2.9486, 2.8549, 2.9004],\n",
      "        [2.8557, 2.9817, 3.0599, 2.9822, 3.0599],\n",
      "        [2.8476, 3.0530, 2.9312, 2.9065, 3.0141],\n",
      "        [2.8965, 3.0863, 2.9055, 2.9717, 3.0195],\n",
      "        [2.8486, 3.1967, 2.9142, 3.1121, 3.0982],\n",
      "        [2.7948, 2.7787, 2.8743, 2.8071, 2.8466],\n",
      "        [3.0718, 3.0110, 3.0750, 3.2015, 3.1078],\n",
      "        [2.8973, 2.9029, 2.9447, 2.9478, 2.9371],\n",
      "        [2.8859, 3.2067, 3.0310, 3.0600, 3.2239],\n",
      "        [2.8313, 3.2036, 2.9210, 3.1094, 3.1097],\n",
      "        [3.0300, 3.1312, 2.9807, 3.0737, 3.2069],\n",
      "        [2.7642, 2.8292, 2.9003, 2.8980, 2.9956],\n",
      "        [3.0525, 3.2053, 2.9124, 2.9943, 3.0425],\n",
      "        [2.7913, 2.8710, 2.9920, 3.0187, 3.1259],\n",
      "        [2.7867, 2.8902, 2.8287, 2.8285, 2.8958],\n",
      "        [2.7853, 2.7995, 2.9264, 2.8016, 2.9627],\n",
      "        [3.0118, 2.9105, 2.9244, 2.9520, 3.0211],\n",
      "        [2.9208, 3.0981, 2.9133, 3.1311, 3.0678],\n",
      "        [2.7787, 2.8510, 2.9837, 2.7928, 3.0694],\n",
      "        [2.7842, 3.1320, 2.9342, 3.0202, 3.1006],\n",
      "        [2.8571, 2.9801, 2.8500, 2.9546, 3.0376],\n",
      "        [2.8305, 2.9656, 2.7813, 2.9570, 2.9199],\n",
      "        [2.7235, 3.0844, 2.8936, 2.9430, 3.0442],\n",
      "        [2.7634, 2.9119, 2.7654, 2.8769, 2.8701],\n",
      "        [2.7110, 2.7868, 2.7152, 2.8737, 2.7990],\n",
      "        [2.8982, 3.0284, 2.8865, 3.0037, 3.0743],\n",
      "        [3.0713, 3.0073, 2.9774, 3.0166, 3.1000],\n",
      "        [2.7959, 2.8383, 2.8353, 2.9421, 2.8554],\n",
      "        [2.7567, 3.1530, 3.0231, 2.9298, 2.9413],\n",
      "        [2.8934, 3.0838, 3.0264, 3.0409, 3.0894],\n",
      "        [2.9305, 2.9939, 3.0516, 2.9719, 2.8780],\n",
      "        [2.7535, 2.8009, 2.8784, 2.8344, 2.8814],\n",
      "        [2.7994, 2.8254, 2.9216, 2.8898, 2.9214],\n",
      "        [3.2382, 3.3507, 2.9645, 3.1022, 3.0104],\n",
      "        [2.8396, 3.1779, 2.9463, 3.0797, 3.1026],\n",
      "        [2.8280, 3.0070, 2.8385, 2.8569, 2.9683],\n",
      "        [3.3263, 3.5460, 3.0812, 3.1849, 3.1626],\n",
      "        [2.7229, 2.9075, 2.8530, 2.9716, 2.8398],\n",
      "        [2.7758, 2.8439, 2.8867, 2.8814, 2.9168]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.8715, 2.9724, 2.9988, 2.9679, 3.0057],\n",
      "        [3.1346, 3.2366, 3.1328, 3.3433, 3.2457],\n",
      "        [2.8170, 3.1299, 3.0114, 2.9676, 2.9393],\n",
      "        [2.8880, 2.8857, 3.0489, 3.0399, 2.9416],\n",
      "        [2.7668, 2.7512, 2.8852, 2.8783, 2.9477],\n",
      "        [2.9452, 3.1583, 2.9747, 3.0371, 3.0641],\n",
      "        [3.0109, 3.0203, 3.0811, 3.0954, 2.9594],\n",
      "        [2.7128, 2.9674, 2.8845, 2.8742, 3.0558],\n",
      "        [2.7002, 2.8928, 2.9564, 2.8668, 2.9809],\n",
      "        [2.7371, 2.9062, 2.8672, 2.9652, 2.8571],\n",
      "        [2.8028, 2.8302, 2.9640, 2.9295, 2.9435],\n",
      "        [2.7221, 3.0952, 2.9188, 2.9219, 3.0878],\n",
      "        [2.8123, 3.1579, 2.9323, 3.0452, 3.0877],\n",
      "        [2.7591, 2.9103, 2.7738, 2.8573, 2.8845],\n",
      "        [2.7865, 2.8576, 2.8954, 2.8911, 2.9251],\n",
      "        [2.7495, 2.8735, 2.8002, 2.9150, 2.8867],\n",
      "        [2.7900, 2.7914, 2.8625, 2.8639, 3.0016],\n",
      "        [2.7090, 2.9055, 2.8088, 2.9131, 2.8419],\n",
      "        [2.9511, 3.0291, 3.0121, 3.0549, 3.1341],\n",
      "        [2.9053, 3.1004, 3.0303, 3.0453, 3.1119],\n",
      "        [2.7160, 3.0407, 2.9947, 2.8849, 3.0791],\n",
      "        [3.0512, 3.1448, 2.9998, 3.0998, 3.1928],\n",
      "        [2.9499, 3.1187, 3.0245, 3.0574, 3.0441],\n",
      "        [2.9575, 3.0557, 3.0517, 3.1416, 3.0037],\n",
      "        [2.7688, 2.8890, 2.8715, 2.8971, 3.0044],\n",
      "        [3.0094, 2.8962, 2.9169, 2.9336, 3.0099],\n",
      "        [2.7901, 2.8029, 2.9246, 2.7999, 2.9661],\n",
      "        [2.8066, 2.9273, 2.8271, 2.9641, 2.9308],\n",
      "        [2.9616, 3.2751, 2.9956, 3.2000, 3.2105],\n",
      "        [3.0580, 2.8039, 2.9541, 3.2958, 3.2995],\n",
      "        [3.1440, 3.1163, 3.0795, 3.1565, 3.1727],\n",
      "        [2.7999, 2.7823, 2.8769, 2.8095, 2.8488],\n",
      "        [2.7671, 2.8931, 2.8698, 2.9117, 2.9850],\n",
      "        [2.9812, 2.8957, 2.9262, 3.2072, 3.1160],\n",
      "        [2.9897, 3.1437, 3.1078, 3.0309, 2.8955],\n",
      "        [3.0093, 3.0463, 3.0028, 3.0032, 3.0897],\n",
      "        [2.6078, 2.7936, 2.7499, 2.6999, 2.7799],\n",
      "        [2.7416, 2.9108, 2.7882, 2.8459, 2.8757],\n",
      "        [3.0797, 2.9272, 2.9572, 3.3631, 3.2382],\n",
      "        [2.7387, 2.8554, 2.8630, 2.8102, 2.8623],\n",
      "        [2.6646, 2.9260, 2.8824, 2.8074, 2.8542],\n",
      "        [3.1945, 3.3265, 2.9566, 3.0831, 3.0268],\n",
      "        [2.6975, 2.7774, 2.8238, 2.8203, 2.8141],\n",
      "        [2.7681, 2.9076, 2.8819, 2.9580, 2.9363],\n",
      "        [3.1911, 3.3984, 2.9546, 3.0424, 3.0411],\n",
      "        [3.0786, 3.0268, 3.0867, 3.2101, 3.1206],\n",
      "        [2.9279, 3.1037, 2.9168, 3.1345, 3.0732],\n",
      "        [2.7021, 2.9152, 2.8195, 2.8231, 2.9053],\n",
      "        [2.8527, 3.0542, 2.9556, 2.9456, 2.8641],\n",
      "        [2.9325, 3.0219, 3.0239, 2.9793, 3.0322],\n",
      "        [2.8127, 3.0725, 2.9403, 2.9279, 2.8446],\n",
      "        [2.7019, 2.8773, 2.7751, 2.8087, 2.8482],\n",
      "        [2.6589, 2.8416, 2.7740, 2.7550, 2.8341],\n",
      "        [2.7606, 2.8845, 2.8171, 2.8164, 2.8516],\n",
      "        [2.8900, 2.9817, 2.9322, 3.0909, 2.9723],\n",
      "        [3.1587, 3.1291, 3.1189, 3.1928, 3.2223],\n",
      "        [2.6730, 2.8201, 2.8429, 2.7990, 2.8165],\n",
      "        [3.2063, 3.4245, 2.9884, 3.0846, 3.0188],\n",
      "        [2.9979, 3.0479, 3.1657, 2.9927, 2.9405],\n",
      "        [2.7954, 2.8478, 2.8973, 2.8923, 2.9232],\n",
      "        [2.8385, 3.0372, 2.9031, 2.9966, 2.9435],\n",
      "        [2.7174, 2.8215, 2.8821, 2.8941, 2.9291],\n",
      "        [3.1263, 3.2451, 3.1354, 3.3685, 3.2708],\n",
      "        [2.7885, 2.8616, 2.9758, 2.8085, 3.0673]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.9464, 3.1118, 3.0181, 3.0633, 3.0426],\n",
      "        [2.7014, 2.8710, 2.9221, 2.8643, 2.8142],\n",
      "        [2.6175, 2.8078, 2.7603, 2.7010, 2.7795],\n",
      "        [2.7066, 2.7320, 2.7928, 2.8226, 2.7902],\n",
      "        [2.8347, 2.8698, 2.9885, 2.9545, 2.9894],\n",
      "        [3.1197, 3.0719, 3.0505, 3.1135, 3.1182],\n",
      "        [2.9317, 2.9526, 2.9857, 2.9212, 2.8681],\n",
      "        [2.8101, 3.1751, 2.9496, 3.0590, 3.1079],\n",
      "        [2.8111, 2.8432, 2.9266, 2.8548, 2.9171],\n",
      "        [2.7165, 2.8671, 2.7506, 2.8827, 2.8473],\n",
      "        [2.7328, 2.8214, 2.8805, 2.8697, 2.9100],\n",
      "        [2.9424, 2.9403, 2.8979, 3.1580, 3.0911],\n",
      "        [2.7892, 3.1002, 2.9867, 2.9770, 3.1126],\n",
      "        [2.8819, 2.9532, 2.9314, 2.9434, 2.9592],\n",
      "        [2.8121, 2.8018, 2.9202, 2.9003, 3.0156],\n",
      "        [2.8077, 2.7935, 2.9035, 2.8981, 3.0086],\n",
      "        [2.7628, 2.8453, 3.0037, 2.7593, 3.0554],\n",
      "        [2.8529, 2.8968, 2.9130, 2.9595, 2.9583],\n",
      "        [3.1342, 3.2476, 3.1449, 3.3581, 3.2644],\n",
      "        [2.7071, 2.7714, 2.8198, 2.8169, 2.8119],\n",
      "        [3.0929, 2.9656, 3.0644, 3.1414, 3.1126],\n",
      "        [2.7949, 3.0365, 2.9428, 2.8369, 3.0098],\n",
      "        [2.7924, 2.8652, 2.9797, 2.8135, 3.0586],\n",
      "        [2.8379, 3.0146, 2.8438, 2.8625, 2.9725],\n",
      "        [2.7438, 2.8099, 2.8951, 2.8790, 2.9845],\n",
      "        [3.1642, 3.3177, 3.0484, 3.0473, 3.0812],\n",
      "        [2.9462, 3.1269, 2.9554, 3.0450, 3.0519],\n",
      "        [2.9714, 3.0845, 3.0372, 2.9658, 3.0607],\n",
      "        [2.8246, 2.8214, 2.9537, 2.9365, 3.0342],\n",
      "        [2.8346, 3.1023, 2.8344, 2.9370, 2.9474],\n",
      "        [2.8030, 2.9116, 2.8714, 2.8802, 2.9254],\n",
      "        [2.9311, 3.1059, 2.9186, 3.1367, 3.0721],\n",
      "        [2.6939, 2.8444, 2.8542, 2.8138, 2.8541],\n",
      "        [2.9777, 2.9938, 3.0822, 3.0276, 2.9129],\n",
      "        [2.9690, 2.9944, 3.0308, 3.0686, 2.8823],\n",
      "        [2.9829, 3.1078, 2.9270, 2.9989, 3.1221],\n",
      "        [2.9220, 2.9922, 3.0607, 2.9669, 2.9437],\n",
      "        [3.2328, 3.3791, 3.0876, 3.1158, 3.1104],\n",
      "        [2.7174, 3.0581, 2.9076, 2.7342, 3.0344],\n",
      "        [2.8325, 3.0164, 2.8618, 2.8600, 2.9794],\n",
      "        [2.7335, 3.0920, 2.8989, 2.9485, 3.0484],\n",
      "        [2.9952, 2.8251, 2.9669, 3.1834, 3.2293],\n",
      "        [3.0036, 2.8220, 2.8179, 2.8447, 2.9988],\n",
      "        [3.1428, 2.9988, 3.0935, 3.5309, 3.4384],\n",
      "        [2.9587, 3.1447, 3.0449, 3.0512, 3.0367],\n",
      "        [3.0344, 3.0591, 3.0113, 3.0304, 3.0932],\n",
      "        [3.1177, 3.0061, 3.0383, 3.5021, 3.4130],\n",
      "        [2.7881, 2.9387, 2.7871, 2.8957, 2.8998],\n",
      "        [2.7711, 2.9108, 3.0562, 2.9140, 3.0540],\n",
      "        [2.9348, 2.9458, 2.9818, 2.9122, 2.8918],\n",
      "        [2.9723, 3.1435, 2.9080, 2.9727, 3.0577],\n",
      "        [2.7917, 2.9171, 2.8670, 2.8644, 2.9038],\n",
      "        [2.7323, 2.9311, 2.8081, 2.9406, 2.8508],\n",
      "        [2.9057, 2.9979, 3.0341, 2.9465, 2.9077],\n",
      "        [2.9504, 3.2256, 3.1079, 3.0964, 3.1882],\n",
      "        [2.7971, 2.8640, 2.9032, 2.8923, 2.9283],\n",
      "        [2.7277, 2.9191, 2.8690, 2.9817, 2.8596],\n",
      "        [3.0302, 3.0491, 3.0513, 3.1683, 3.0840],\n",
      "        [3.0453, 2.9657, 3.0449, 3.1577, 3.0613],\n",
      "        [2.9174, 3.0398, 3.0495, 2.9464, 2.9121],\n",
      "        [2.8099, 2.8251, 2.9410, 2.9011, 2.9269],\n",
      "        [2.8795, 3.1359, 3.0384, 3.0266, 3.2026],\n",
      "        [3.1863, 2.9649, 3.0646, 3.4735, 3.4537],\n",
      "        [3.0845, 3.1754, 3.0906, 3.1155, 3.2005]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.8099, 2.9394, 2.9376, 2.8941, 2.8409],\n",
      "        [3.1409, 3.2754, 2.9428, 3.0375, 3.0453],\n",
      "        [3.0149, 3.0700, 3.1128, 3.1863, 3.0286],\n",
      "        [2.8043, 2.9210, 2.9720, 2.9423, 3.0172],\n",
      "        [2.8695, 2.8328, 2.9247, 2.9316, 2.9099],\n",
      "        [2.7356, 2.8808, 2.7843, 2.8836, 2.8382],\n",
      "        [2.7978, 2.8837, 3.0301, 3.0065, 2.9923],\n",
      "        [3.3724, 3.5349, 3.1517, 3.2059, 3.1405],\n",
      "        [2.7158, 2.8829, 3.0032, 2.8591, 2.9993],\n",
      "        [2.9732, 3.2001, 3.0067, 3.1551, 3.1433],\n",
      "        [3.1674, 3.1371, 3.1251, 3.2005, 3.2274],\n",
      "        [2.9481, 3.0513, 3.0883, 2.9928, 2.9298],\n",
      "        [2.8524, 2.9051, 2.9369, 2.8294, 2.7893],\n",
      "        [2.8478, 3.1970, 2.9377, 3.1206, 3.1180],\n",
      "        [2.6757, 3.0695, 2.9368, 2.8497, 3.0794],\n",
      "        [2.9127, 3.0555, 3.0638, 3.0246, 3.0325],\n",
      "        [2.6690, 2.8799, 3.0100, 2.7968, 3.0055],\n",
      "        [2.7093, 2.9069, 2.9610, 2.9104, 3.0128],\n",
      "        [2.8652, 3.1451, 2.9951, 3.0276, 3.1488],\n",
      "        [2.7655, 2.8460, 3.0226, 2.7401, 3.0772],\n",
      "        [3.0671, 2.9742, 3.0612, 3.1615, 3.0786],\n",
      "        [2.7777, 2.8966, 2.8774, 2.9039, 3.0092],\n",
      "        [2.6578, 2.6927, 2.7778, 2.8272, 2.7895],\n",
      "        [2.9764, 3.0114, 3.0568, 3.0477, 2.9424],\n",
      "        [2.9206, 3.2407, 3.0646, 3.0879, 3.2138],\n",
      "        [2.6955, 3.0411, 2.8889, 2.7131, 3.0135],\n",
      "        [2.7682, 2.8893, 2.7160, 2.9451, 2.7896],\n",
      "        [2.9005, 2.8937, 2.9610, 2.8727, 2.9018],\n",
      "        [2.9060, 2.9055, 2.9696, 2.8727, 2.8968],\n",
      "        [3.0671, 3.1486, 3.0067, 3.1100, 3.1985],\n",
      "        [2.9361, 2.9214, 2.9837, 3.0046, 2.9688],\n",
      "        [2.8769, 3.0525, 2.9033, 3.0144, 2.9869],\n",
      "        [2.7017, 2.8351, 2.8523, 2.8138, 2.8476],\n",
      "        [2.8447, 3.0003, 2.7785, 2.8678, 2.9418],\n",
      "        [3.1319, 3.2513, 3.1329, 3.3454, 3.2534],\n",
      "        [3.0845, 3.0185, 2.9860, 3.0265, 3.1071],\n",
      "        [2.9529, 3.0071, 3.0780, 2.9965, 2.9241],\n",
      "        [2.7468, 3.0521, 2.8852, 2.8477, 2.8206],\n",
      "        [2.9238, 2.9821, 2.8194, 3.0324, 3.0652],\n",
      "        [2.7488, 2.7375, 2.9191, 2.6904, 2.9648],\n",
      "        [2.7601, 2.8307, 2.8849, 2.8650, 2.9194],\n",
      "        [2.7955, 2.9572, 2.7886, 2.9132, 2.9103],\n",
      "        [2.7271, 2.8589, 2.9020, 2.8713, 2.8219],\n",
      "        [3.2149, 3.4317, 2.9945, 3.0914, 3.0236],\n",
      "        [2.8168, 3.0168, 2.8819, 2.9074, 3.0069],\n",
      "        [2.7258, 2.7118, 2.9015, 2.6621, 2.9458],\n",
      "        [2.7286, 2.8346, 2.8777, 2.8768, 2.8160],\n",
      "        [2.8073, 2.9435, 2.8694, 2.8805, 2.9322],\n",
      "        [2.6951, 2.8052, 2.8390, 2.8082, 2.8206],\n",
      "        [2.7843, 2.9471, 2.7924, 2.8977, 2.8984],\n",
      "        [3.3066, 3.5007, 3.0787, 3.1673, 3.1241],\n",
      "        [2.8684, 3.0969, 2.8921, 2.7754, 2.9460],\n",
      "        [2.7802, 2.8567, 3.0014, 2.7857, 3.0612],\n",
      "        [2.9390, 3.1075, 2.9155, 3.1312, 3.0645],\n",
      "        [2.8951, 2.9441, 2.8792, 3.0261, 2.9953],\n",
      "        [2.7229, 2.7571, 2.8116, 2.8375, 2.8113],\n",
      "        [3.0159, 3.1899, 3.1401, 3.0768, 2.9611],\n",
      "        [2.9368, 2.9552, 2.9854, 2.9310, 2.8694],\n",
      "        [2.8123, 2.9512, 2.7805, 2.9347, 2.9153],\n",
      "        [2.6486, 2.8388, 2.7738, 2.7391, 2.8103],\n",
      "        [3.0750, 2.8173, 2.9793, 3.2927, 3.2962],\n",
      "        [2.8894, 2.9454, 2.9335, 2.9468, 2.9440],\n",
      "        [3.0544, 2.9413, 2.9436, 2.9752, 3.0463],\n",
      "        [3.0250, 2.9216, 2.9331, 2.9617, 3.0283]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.8051, 2.8448, 2.8994, 2.8878, 2.9250],\n",
      "        [2.6676, 2.7078, 2.7850, 2.8475, 2.7968],\n",
      "        [2.7131, 2.9260, 2.7710, 2.8808, 2.8464],\n",
      "        [2.8361, 2.9564, 2.7641, 2.9548, 2.8262],\n",
      "        [2.8049, 2.8802, 2.9124, 2.9125, 2.9416],\n",
      "        [3.1066, 2.9684, 3.0739, 3.5029, 3.4381],\n",
      "        [2.8045, 2.8558, 2.9028, 2.9024, 2.9374],\n",
      "        [2.6871, 2.8308, 2.8515, 2.8102, 2.8236],\n",
      "        [2.9305, 2.9207, 2.9170, 3.1121, 3.0398],\n",
      "        [2.7946, 2.9401, 2.7890, 2.9091, 2.9057],\n",
      "        [2.7280, 2.7603, 2.8145, 2.8423, 2.8138],\n",
      "        [3.0724, 2.9308, 2.9589, 3.3396, 3.2162],\n",
      "        [2.9538, 3.0548, 3.0915, 2.9978, 2.9325],\n",
      "        [3.3513, 3.5530, 3.1514, 3.2408, 3.1499],\n",
      "        [2.6729, 2.9040, 2.8760, 2.8084, 2.8387],\n",
      "        [2.9049, 2.9930, 2.9413, 3.1027, 2.9798],\n",
      "        [2.7062, 2.7982, 2.8299, 2.8181, 2.8009],\n",
      "        [2.6823, 2.9186, 2.8873, 2.8261, 2.8586],\n",
      "        [2.8135, 3.0230, 2.9123, 2.8614, 2.9994],\n",
      "        [2.7260, 2.7506, 2.8104, 2.8433, 2.7999],\n",
      "        [2.8752, 3.1617, 3.0116, 3.0361, 3.1554],\n",
      "        [2.7312, 3.0626, 2.9172, 2.7380, 3.0320],\n",
      "        [2.8895, 3.1432, 3.0450, 3.0354, 3.2081],\n",
      "        [2.7627, 3.2044, 3.0378, 2.9219, 2.9511],\n",
      "        [2.8218, 2.9653, 2.7914, 2.9410, 2.9209],\n",
      "        [2.8147, 2.8080, 2.9149, 2.9043, 3.0158],\n",
      "        [2.7854, 2.8782, 2.8620, 2.8367, 2.9014],\n",
      "        [2.7194, 2.8468, 2.9043, 2.9232, 2.9465],\n",
      "        [2.7267, 2.9229, 3.0772, 2.8676, 3.0716],\n",
      "        [2.7824, 2.9185, 2.8908, 2.9696, 2.9436],\n",
      "        [2.7041, 2.8829, 2.7890, 2.7959, 2.8554],\n",
      "        [2.9776, 3.1109, 3.0688, 3.0071, 2.9150],\n",
      "        [2.9130, 3.0236, 2.8895, 2.9596, 3.1422],\n",
      "        [3.0202, 3.0695, 3.1169, 3.1900, 3.0275],\n",
      "        [2.7070, 2.8384, 2.8552, 2.8186, 2.8501],\n",
      "        [2.9606, 3.0015, 3.0607, 2.9945, 2.9327],\n",
      "        [2.8601, 3.1261, 3.0152, 2.9915, 2.9665],\n",
      "        [2.8348, 2.8700, 2.9590, 2.9351, 2.9554],\n",
      "        [2.7164, 2.9605, 3.0581, 2.8766, 3.0129],\n",
      "        [2.9572, 2.9698, 3.0771, 2.9771, 2.8306],\n",
      "        [2.7051, 2.8148, 2.8661, 2.8366, 2.8020],\n",
      "        [2.6993, 2.9673, 2.9069, 2.8322, 2.8991],\n",
      "        [3.0802, 3.0936, 3.0992, 3.2129, 3.1515],\n",
      "        [2.7944, 2.9103, 2.8262, 2.8504, 2.8774],\n",
      "        [2.9564, 3.0243, 2.8461, 3.0654, 3.0975],\n",
      "        [2.9546, 2.9300, 2.9157, 3.2005, 3.1135],\n",
      "        [3.4204, 3.5797, 3.2072, 3.2841, 3.1824],\n",
      "        [2.9259, 3.1476, 3.0528, 3.0761, 3.1722],\n",
      "        [2.9147, 2.9028, 3.0674, 3.0469, 2.9944],\n",
      "        [2.6801, 2.9319, 2.8931, 2.8245, 2.8683],\n",
      "        [3.0026, 3.0403, 3.0369, 3.1035, 2.9954],\n",
      "        [2.8127, 2.8369, 2.9180, 2.9009, 2.9199],\n",
      "        [2.9953, 3.1521, 3.1216, 3.0410, 2.9060],\n",
      "        [2.7918, 2.9009, 2.8866, 2.9007, 3.0342],\n",
      "        [2.9415, 3.1118, 2.9206, 3.1373, 3.0698],\n",
      "        [2.9528, 3.1131, 3.0098, 3.0696, 3.0443],\n",
      "        [3.0657, 3.1556, 3.0092, 3.1116, 3.2004],\n",
      "        [2.7044, 2.8980, 2.8130, 2.8949, 2.8487],\n",
      "        [2.9430, 3.1151, 2.9262, 3.1465, 3.0808],\n",
      "        [2.8266, 2.9616, 2.7859, 2.9441, 2.9186],\n",
      "        [2.7002, 2.8085, 2.8420, 2.8130, 2.8231],\n",
      "        [2.9358, 3.0750, 3.0377, 3.0519, 3.0437],\n",
      "        [2.8649, 3.1318, 2.9827, 3.0180, 3.1417],\n",
      "        [2.7485, 2.9092, 2.7814, 2.8447, 2.8729]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.0998, 3.0387, 3.1006, 3.2221, 3.1332],\n",
      "        [2.7376, 2.8116, 2.7347, 2.8894, 2.7426],\n",
      "        [2.9724, 2.8113, 2.8425, 2.8865, 2.9493],\n",
      "        [2.6848, 2.7850, 2.8231, 2.7973, 2.7752],\n",
      "        [2.9518, 3.0716, 2.9330, 3.0662, 3.0451],\n",
      "        [3.1773, 2.9544, 3.0489, 3.4863, 3.4431],\n",
      "        [2.7874, 2.7657, 2.8934, 2.8884, 2.9460],\n",
      "        [2.8219, 2.9672, 2.8697, 2.9885, 2.9796],\n",
      "        [2.6844, 2.9181, 2.8871, 2.8167, 2.8459],\n",
      "        [2.8392, 3.1036, 2.8785, 2.7656, 2.9839],\n",
      "        [2.8175, 3.0944, 2.8620, 3.0518, 3.0109],\n",
      "        [3.0125, 2.9805, 2.9678, 2.9135, 2.8869],\n",
      "        [2.9484, 3.1182, 2.9292, 3.1511, 3.0833],\n",
      "        [2.8464, 2.9866, 2.7903, 2.9730, 2.9398],\n",
      "        [2.8578, 3.0181, 2.8380, 2.8791, 2.9705],\n",
      "        [2.9623, 3.0077, 2.9586, 3.0579, 3.1296],\n",
      "        [3.0009, 2.9098, 2.9382, 3.2231, 3.1263],\n",
      "        [2.8520, 2.8942, 2.9200, 2.9385, 2.9665],\n",
      "        [2.7887, 2.9936, 2.9304, 2.8131, 2.8748],\n",
      "        [3.0282, 3.0591, 3.0858, 3.0020, 2.8922],\n",
      "        [2.8365, 2.9658, 2.7826, 2.9486, 2.9165],\n",
      "        [2.8472, 3.0264, 2.8710, 2.8733, 2.9871],\n",
      "        [2.6792, 2.8862, 3.0157, 2.8060, 3.0104],\n",
      "        [2.8167, 2.8004, 2.9031, 2.9044, 3.0142],\n",
      "        [2.8749, 2.8466, 2.9388, 2.9368, 2.9578],\n",
      "        [2.9775, 2.8686, 2.8492, 2.8637, 3.0070],\n",
      "        [3.0478, 3.0548, 3.0556, 3.1747, 3.0957],\n",
      "        [3.0035, 3.1273, 3.0948, 3.0304, 2.9320],\n",
      "        [2.8069, 2.8064, 2.9234, 2.8877, 2.9056],\n",
      "        [2.8131, 2.8455, 2.9176, 2.9049, 2.9335],\n",
      "        [3.0774, 2.9805, 3.0673, 3.1709, 3.0835],\n",
      "        [2.8793, 2.8357, 3.1345, 2.9715, 3.0451],\n",
      "        [2.6229, 2.8088, 2.7622, 2.7021, 2.7758],\n",
      "        [2.8080, 2.8273, 2.9254, 2.9000, 2.9155],\n",
      "        [2.8137, 2.8684, 2.9109, 2.9121, 2.9357],\n",
      "        [2.8829, 2.7598, 3.0344, 2.9897, 3.0316],\n",
      "        [2.6982, 2.8265, 2.8501, 2.8148, 2.8267],\n",
      "        [2.8258, 2.9619, 2.9179, 2.8813, 2.9502],\n",
      "        [3.1087, 3.0008, 2.9723, 3.0520, 3.0920],\n",
      "        [2.8068, 2.8766, 2.9108, 2.9208, 2.9416],\n",
      "        [3.0639, 2.9477, 2.9495, 2.9853, 3.0513],\n",
      "        [2.8998, 2.8486, 3.1240, 2.9899, 3.0681],\n",
      "        [2.9484, 3.1182, 2.9292, 3.1511, 3.0833],\n",
      "        [2.7769, 3.0479, 2.9982, 2.8624, 3.1601],\n",
      "        [2.8272, 3.0232, 2.8877, 2.9170, 3.0117],\n",
      "        [2.8199, 2.8380, 2.9282, 2.9025, 2.9200],\n",
      "        [2.9110, 2.9001, 2.9669, 2.8822, 2.9069],\n",
      "        [2.9664, 3.2363, 3.1176, 3.1099, 3.1963],\n",
      "        [2.7362, 2.7182, 2.9071, 2.6713, 2.9507],\n",
      "        [2.7489, 2.8831, 2.7874, 2.8844, 2.8466],\n",
      "        [2.9251, 2.9094, 2.9729, 2.9738, 2.9592],\n",
      "        [2.9484, 3.1182, 2.9292, 3.1511, 3.0833],\n",
      "        [2.8650, 2.8987, 3.0070, 2.9657, 3.0078],\n",
      "        [2.7206, 2.9090, 2.8056, 2.8969, 2.8550],\n",
      "        [2.8194, 2.9531, 2.7886, 2.9247, 2.9205],\n",
      "        [2.8759, 2.9006, 3.0075, 2.9757, 3.0169],\n",
      "        [2.9682, 2.9786, 3.0242, 3.1000, 2.9448],\n",
      "        [2.9076, 2.8906, 2.9631, 2.8736, 2.9126],\n",
      "        [2.8013, 2.9442, 2.7917, 2.8866, 2.9072],\n",
      "        [2.8170, 2.9499, 2.7922, 2.9096, 2.9232],\n",
      "        [2.7148, 2.8004, 2.8421, 2.8248, 2.8249],\n",
      "        [3.1240, 3.0396, 3.0017, 3.0573, 3.0801],\n",
      "        [2.7706, 2.9253, 2.7844, 2.8746, 2.8841],\n",
      "        [2.9647, 3.1422, 2.9171, 2.9800, 3.0717]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.8049, 3.0575, 2.9695, 2.8450, 3.0218],\n",
      "        [2.6904, 2.8398, 2.8536, 2.8134, 2.8275],\n",
      "        [2.7935, 2.9365, 2.7880, 2.8883, 2.8973],\n",
      "        [2.8137, 2.9483, 2.9076, 2.9044, 2.9577],\n",
      "        [2.8514, 3.0509, 2.9216, 2.9298, 3.0180],\n",
      "        [2.9561, 2.9818, 3.0003, 2.9532, 2.8764],\n",
      "        [2.8077, 2.8772, 2.9113, 2.9172, 2.9424],\n",
      "        [2.8692, 3.0143, 2.8044, 2.8939, 2.9599],\n",
      "        [2.9316, 3.0706, 3.0100, 3.0038, 2.9123],\n",
      "        [2.7753, 2.9285, 2.7958, 2.8589, 2.8950],\n",
      "        [3.1419, 2.9282, 2.9794, 3.4533, 3.2983],\n",
      "        [2.9176, 3.0339, 2.8958, 3.0083, 3.0852],\n",
      "        [2.7637, 2.7468, 2.9273, 2.7045, 2.9728],\n",
      "        [2.6694, 2.8539, 2.7835, 2.7669, 2.8284],\n",
      "        [2.8313, 2.9711, 2.7969, 2.9501, 2.9262],\n",
      "        [2.8281, 2.8457, 2.9383, 2.9126, 2.9366],\n",
      "        [3.0656, 2.9892, 3.0661, 3.1791, 3.0800],\n",
      "        [2.8214, 2.9527, 2.7948, 2.9143, 2.9262],\n",
      "        [2.9753, 2.8610, 2.8407, 2.8564, 3.0016],\n",
      "        [2.9814, 3.1139, 2.9216, 3.0020, 3.1049],\n",
      "        [2.7808, 2.8555, 3.0311, 2.7547, 3.0854],\n",
      "        [2.9161, 3.1993, 3.0772, 3.0654, 3.1675],\n",
      "        [2.7447, 3.0546, 2.8772, 2.8392, 2.8238],\n",
      "        [2.8421, 2.9580, 2.8387, 2.9345, 2.9613],\n",
      "        [2.9881, 3.0985, 2.9894, 3.0317, 3.1353],\n",
      "        [2.7051, 2.8710, 2.7855, 2.7958, 2.8380],\n",
      "        [2.8221, 2.9526, 2.8779, 2.8945, 2.9401],\n",
      "        [2.8316, 3.0260, 2.8904, 2.9219, 3.0148],\n",
      "        [3.0637, 2.9821, 3.0600, 3.1785, 3.0762],\n",
      "        [2.8202, 2.8118, 2.8978, 2.8432, 2.8756],\n",
      "        [2.9273, 3.1292, 3.0465, 3.0578, 3.1645],\n",
      "        [3.0185, 3.1721, 3.1013, 3.1507, 3.1932],\n",
      "        [2.7127, 2.8571, 2.8658, 2.8312, 2.8645],\n",
      "        [3.1374, 3.0852, 3.0626, 3.1333, 3.1294],\n",
      "        [2.7471, 2.7738, 2.8256, 2.8560, 2.8226],\n",
      "        [2.6855, 2.8752, 2.7922, 2.8322, 2.8300],\n",
      "        [2.8380, 3.0345, 2.8897, 2.8713, 2.9982],\n",
      "        [2.9690, 3.0165, 3.0867, 3.0108, 2.9322],\n",
      "        [3.0168, 2.9833, 2.9705, 2.9184, 2.8900],\n",
      "        [2.9918, 3.0209, 3.0657, 3.0623, 2.9506],\n",
      "        [2.7004, 2.8174, 2.8082, 2.8083, 2.8252],\n",
      "        [2.8285, 2.8745, 2.7936, 2.8933, 3.0242],\n",
      "        [2.8027, 2.8053, 2.9426, 2.7896, 2.9831],\n",
      "        [2.9300, 3.0569, 3.0714, 3.0593, 3.0605],\n",
      "        [2.8560, 3.0693, 2.9356, 2.9236, 3.0251],\n",
      "        [2.6890, 2.9826, 2.7493, 2.8925, 2.8006],\n",
      "        [2.7145, 2.8205, 2.8714, 2.8456, 2.8072],\n",
      "        [3.0503, 2.9145, 2.9536, 3.3276, 3.2010],\n",
      "        [2.8266, 2.8500, 2.8401, 2.9777, 2.8601],\n",
      "        [2.9756, 2.9508, 2.9586, 2.8820, 2.8628],\n",
      "        [2.9207, 3.1113, 3.0439, 3.0601, 3.1217],\n",
      "        [3.0029, 3.0280, 3.0318, 3.1481, 3.0506],\n",
      "        [2.8230, 2.8744, 2.9446, 2.9229, 2.9543],\n",
      "        [2.9814, 3.1139, 2.9216, 3.0020, 3.1049],\n",
      "        [2.8463, 2.8886, 3.0136, 3.0884, 3.1730],\n",
      "        [2.6642, 2.7586, 2.8170, 2.7767, 2.7455],\n",
      "        [2.9626, 3.1174, 2.9148, 2.9955, 3.0884],\n",
      "        [2.8421, 2.9557, 2.8345, 2.9364, 2.9616],\n",
      "        [2.8724, 2.9098, 2.9249, 2.9774, 2.9691],\n",
      "        [2.7802, 2.8890, 2.6934, 2.9542, 2.7696],\n",
      "        [2.8182, 2.8712, 2.9136, 2.9170, 2.9388],\n",
      "        [2.6640, 2.8490, 2.7810, 2.7558, 2.8188],\n",
      "        [3.1016, 3.1422, 3.0274, 3.1547, 3.2305],\n",
      "        [2.6851, 2.8749, 2.8685, 2.8145, 2.8339]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.1260, 2.9405, 2.9838, 3.4224, 3.2838],\n",
      "        [2.6892, 2.8774, 2.8719, 2.8188, 2.8376],\n",
      "        [2.9574, 3.1239, 2.9357, 3.1605, 3.0903],\n",
      "        [2.7872, 2.9330, 2.7875, 2.8963, 2.8875],\n",
      "        [3.2496, 3.4708, 3.0258, 3.1354, 3.0479],\n",
      "        [2.8123, 2.9562, 2.7944, 2.9118, 2.9165],\n",
      "        [2.6259, 2.8056, 2.7647, 2.7064, 2.7748],\n",
      "        [3.0225, 2.9955, 3.0493, 3.1137, 3.0421],\n",
      "        [2.8413, 2.8578, 2.9426, 2.9157, 2.9449],\n",
      "        [3.1196, 3.1558, 3.0349, 3.1671, 3.2385],\n",
      "        [2.9985, 2.9016, 2.9252, 3.2815, 3.1398],\n",
      "        [2.8461, 2.9690, 3.0188, 2.9715, 3.0253],\n",
      "        [2.8693, 2.9265, 2.9893, 2.9588, 3.0707],\n",
      "        [2.9191, 3.0017, 2.9504, 3.1166, 2.9891],\n",
      "        [3.0207, 2.9859, 2.9740, 2.9230, 2.8938],\n",
      "        [2.6876, 2.8916, 3.0218, 2.8151, 3.0171],\n",
      "        [2.7966, 3.0817, 3.0036, 2.8536, 3.0137],\n",
      "        [2.9429, 2.9325, 2.9662, 2.8454, 2.8278],\n",
      "        [2.7569, 3.1074, 2.9145, 2.9709, 3.0629],\n",
      "        [2.8182, 2.8643, 2.9117, 2.9160, 2.9465],\n",
      "        [2.7180, 2.9063, 2.8217, 2.9081, 2.8575],\n",
      "        [2.8940, 3.0168, 2.9065, 3.0107, 3.0479],\n",
      "        [2.9863, 3.1127, 2.9490, 3.1070, 3.1353],\n",
      "        [2.8973, 2.9416, 2.9130, 2.9996, 3.0770],\n",
      "        [2.8300, 2.9629, 2.7973, 2.9390, 2.9271],\n",
      "        [3.0667, 3.2245, 2.9978, 2.9653, 3.0125],\n",
      "        [2.8658, 2.9299, 2.9524, 2.8571, 2.7946],\n",
      "        [2.8353, 2.9167, 2.9283, 2.8916, 3.1236],\n",
      "        [2.8263, 2.9552, 2.8814, 2.8988, 2.9438],\n",
      "        [2.9454, 3.0609, 3.0696, 2.9743, 2.9299],\n",
      "        [2.8570, 2.9934, 2.7713, 2.8803, 2.9385],\n",
      "        [2.8236, 2.8673, 2.9152, 2.9178, 2.9397],\n",
      "        [2.9698, 3.1425, 2.9711, 3.0674, 3.0666],\n",
      "        [2.7073, 2.8324, 2.8606, 2.8264, 2.8346],\n",
      "        [2.7794, 2.9310, 2.7993, 2.8632, 2.8986],\n",
      "        [2.8287, 3.0849, 2.9415, 2.9269, 2.8530],\n",
      "        [2.9402, 2.9209, 2.9861, 3.0001, 2.9697],\n",
      "        [2.7427, 2.8104, 2.8644, 2.8559, 2.8165],\n",
      "        [2.9539, 2.9698, 3.0628, 2.9636, 2.8323],\n",
      "        [3.0565, 3.0602, 3.0622, 3.1845, 3.1025],\n",
      "        [2.8276, 3.0276, 2.8599, 3.0609, 2.8903],\n",
      "        [3.1084, 3.0441, 3.1071, 3.2321, 3.1400],\n",
      "        [3.0222, 3.1238, 3.0336, 3.0721, 3.1484],\n",
      "        [2.8349, 2.8169, 2.9489, 2.9297, 3.0319],\n",
      "        [3.0881, 3.1146, 3.0649, 3.2427, 3.1316],\n",
      "        [3.1706, 3.1364, 3.0979, 3.1849, 3.1902],\n",
      "        [2.8179, 2.9509, 2.9112, 2.9087, 2.9615],\n",
      "        [2.8897, 3.1705, 3.0209, 3.0501, 3.1647],\n",
      "        [2.9772, 3.1482, 2.9832, 3.0587, 3.0774],\n",
      "        [2.8244, 2.8144, 2.9013, 2.8476, 2.8793],\n",
      "        [2.8302, 2.8088, 2.9186, 2.9205, 3.0231],\n",
      "        [2.6655, 2.7527, 2.8159, 2.7705, 2.7500],\n",
      "        [3.1881, 3.3139, 2.9569, 3.0718, 3.0514],\n",
      "        [2.9423, 3.0796, 3.0671, 3.0507, 3.0322],\n",
      "        [2.7871, 2.8239, 2.8991, 2.8620, 2.9002],\n",
      "        [2.8934, 2.8385, 2.9193, 2.9542, 2.9017],\n",
      "        [2.9085, 2.8541, 3.1303, 2.9993, 3.0750],\n",
      "        [3.0690, 3.1614, 3.0819, 3.0964, 3.1724],\n",
      "        [3.2332, 3.3581, 3.0816, 3.1128, 3.0853],\n",
      "        [2.8172, 2.9462, 2.7857, 2.9234, 2.8981],\n",
      "        [2.8405, 2.9717, 2.9245, 2.9396, 2.9843],\n",
      "        [3.0092, 2.9025, 2.9457, 2.9527, 2.9919],\n",
      "        [2.9105, 3.2726, 3.0134, 3.1695, 3.1823],\n",
      "        [2.9982, 3.0724, 3.0867, 3.1778, 3.0220]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.7316, 2.8981, 2.7960, 2.8270, 2.8612],\n",
      "        [2.8512, 2.7936, 2.8931, 2.8152, 2.8540],\n",
      "        [2.8492, 2.9783, 2.8064, 2.9696, 2.9410],\n",
      "        [2.7006, 2.9393, 2.8566, 2.8643, 3.0240],\n",
      "        [2.6501, 2.9155, 2.6983, 2.8540, 2.7590],\n",
      "        [2.8302, 3.1022, 2.8715, 3.0664, 3.0220],\n",
      "        [3.1684, 3.2593, 3.1566, 3.3770, 3.2675],\n",
      "        [3.1054, 3.1632, 3.0300, 3.1466, 3.2356],\n",
      "        [2.7967, 3.0867, 2.9350, 2.9168, 2.8597],\n",
      "        [2.8272, 2.8886, 2.9273, 2.9340, 2.9660],\n",
      "        [2.9632, 3.1222, 2.9317, 3.1560, 3.0814],\n",
      "        [2.7531, 2.8344, 2.8952, 2.9100, 2.9309],\n",
      "        [2.8897, 3.1405, 2.8773, 3.0015, 2.9961],\n",
      "        [2.7746, 2.9012, 2.8169, 2.9067, 2.9046],\n",
      "        [2.8235, 2.9431, 2.9049, 2.8633, 2.9473],\n",
      "        [2.8948, 2.8506, 2.9462, 2.9531, 2.9523],\n",
      "        [3.1905, 2.9626, 3.0589, 3.5010, 3.4548],\n",
      "        [2.7431, 2.7611, 2.8222, 2.8622, 2.8128],\n",
      "        [3.1059, 2.9565, 2.9805, 3.3945, 3.2576],\n",
      "        [2.8856, 3.2299, 2.9551, 3.1504, 3.1417],\n",
      "        [2.8901, 3.1790, 3.0204, 3.0550, 3.1643],\n",
      "        [2.7344, 2.7925, 2.8369, 2.8476, 2.8317],\n",
      "        [2.8275, 2.9609, 2.8021, 2.9184, 2.9272],\n",
      "        [2.8064, 3.0819, 3.0069, 2.8439, 3.0409],\n",
      "        [2.9249, 3.2046, 3.0845, 3.0757, 3.1758],\n",
      "        [3.0568, 3.1985, 2.9295, 3.0135, 3.0662],\n",
      "        [2.8719, 3.0593, 2.9251, 3.0277, 2.9645],\n",
      "        [2.8912, 2.9310, 3.0203, 3.0210, 2.9668],\n",
      "        [3.0676, 3.1566, 3.0057, 3.1080, 3.2303],\n",
      "        [2.8316, 2.8402, 2.9359, 2.9193, 2.9254],\n",
      "        [2.7334, 2.9149, 2.9779, 2.8976, 3.0019],\n",
      "        [3.2433, 3.0179, 3.1667, 3.6236, 3.5318],\n",
      "        [2.7892, 2.7571, 2.8932, 2.8930, 2.9500],\n",
      "        [3.0378, 3.0846, 3.1289, 3.2123, 3.0454],\n",
      "        [3.4267, 3.5812, 3.1872, 3.2706, 3.1873],\n",
      "        [2.7140, 2.8653, 2.8980, 2.8581, 2.8319],\n",
      "        [3.0731, 3.1638, 3.0854, 3.1024, 3.1768],\n",
      "        [2.8635, 2.8587, 2.9782, 2.9517, 2.9538],\n",
      "        [2.8271, 2.9605, 2.8046, 2.9381, 2.9316],\n",
      "        [2.7987, 2.7912, 2.9488, 2.7704, 2.9907],\n",
      "        [2.7866, 2.9310, 2.8023, 2.8746, 2.9107],\n",
      "        [2.9416, 3.1934, 3.1059, 3.0736, 3.1611],\n",
      "        [3.1628, 3.2662, 3.1657, 3.3886, 3.2841],\n",
      "        [2.7948, 2.8891, 2.8861, 2.8575, 2.9099],\n",
      "        [2.6842, 2.7154, 2.7876, 2.8654, 2.7988],\n",
      "        [2.7529, 2.7681, 2.8260, 2.8529, 2.8331],\n",
      "        [3.1179, 3.0916, 3.0727, 3.2428, 3.1841],\n",
      "        [2.6893, 2.8757, 2.8767, 2.8256, 2.8391],\n",
      "        [2.9203, 2.8950, 2.9724, 2.8834, 2.9378],\n",
      "        [3.0126, 3.0421, 3.0228, 3.0296, 3.1581],\n",
      "        [2.9235, 3.0074, 3.0079, 2.9837, 3.0288],\n",
      "        [2.6842, 2.9802, 2.8348, 2.6708, 2.9061],\n",
      "        [2.8470, 2.8746, 2.9773, 2.9565, 2.9828],\n",
      "        [3.1777, 3.2501, 3.1121, 3.4136, 3.2882],\n",
      "        [2.9989, 2.9721, 2.9732, 2.9092, 2.8875],\n",
      "        [3.0245, 3.1663, 3.1299, 3.0622, 2.9169],\n",
      "        [2.9743, 3.0166, 3.0104, 2.9799, 2.8579],\n",
      "        [2.9957, 3.2981, 3.0183, 3.2317, 3.2324],\n",
      "        [2.7474, 2.8823, 2.9265, 2.8936, 2.8395],\n",
      "        [2.9007, 2.8550, 3.1515, 3.0059, 3.0762],\n",
      "        [2.8096, 2.8014, 2.8588, 2.8679, 3.0083],\n",
      "        [3.1401, 3.1237, 3.0615, 3.1390, 3.1766],\n",
      "        [2.8399, 2.9717, 2.8053, 2.9631, 2.9386],\n",
      "        [2.6965, 2.9896, 2.7531, 2.9042, 2.8099]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.1018, 3.0349, 2.9951, 3.0505, 3.1294],\n",
      "        [2.8651, 2.9975, 2.8170, 2.9955, 2.9566],\n",
      "        [2.7222, 2.8724, 2.9036, 2.8686, 2.8422],\n",
      "        [2.9132, 3.1387, 3.0432, 3.0425, 3.0167],\n",
      "        [2.8488, 2.9795, 2.7958, 2.9699, 2.9388],\n",
      "        [2.8026, 2.9721, 2.8568, 2.9563, 3.0067],\n",
      "        [2.7911, 2.7736, 2.8207, 2.8656, 2.8229],\n",
      "        [2.7676, 2.9973, 2.8044, 2.9494, 2.8435],\n",
      "        [2.9396, 3.0567, 2.9157, 3.0425, 3.1015],\n",
      "        [2.9656, 3.1293, 2.9435, 3.1714, 3.0993],\n",
      "        [2.8508, 2.8360, 2.9666, 2.9606, 3.0530],\n",
      "        [2.8169, 2.8723, 2.9148, 2.9200, 2.9436],\n",
      "        [2.9261, 3.2126, 3.0903, 3.0770, 3.1739],\n",
      "        [2.7023, 3.0865, 2.9566, 2.8801, 3.0993],\n",
      "        [2.9094, 2.9734, 2.9597, 2.9958, 3.0609],\n",
      "        [2.7703, 3.1287, 2.9434, 2.9846, 3.1007],\n",
      "        [2.8910, 3.2259, 2.9435, 3.1506, 3.1260],\n",
      "        [2.8805, 2.9476, 2.9285, 2.9632, 3.0346],\n",
      "        [2.7980, 3.0971, 3.0338, 2.8499, 3.0534],\n",
      "        [3.4584, 3.6117, 3.2206, 3.2970, 3.2142],\n",
      "        [3.4039, 3.5864, 3.1554, 3.2520, 3.2061],\n",
      "        [2.8620, 3.0054, 2.7784, 2.8881, 2.9496],\n",
      "        [3.0212, 3.0647, 3.0218, 3.1170, 3.2018],\n",
      "        [2.8691, 3.0353, 2.8668, 2.8959, 2.9952],\n",
      "        [2.6998, 2.8777, 2.7977, 2.7926, 2.8477],\n",
      "        [2.9656, 3.1293, 2.9435, 3.1714, 3.0993],\n",
      "        [2.9766, 3.0970, 2.9788, 2.9591, 3.0288],\n",
      "        [2.9326, 3.1198, 3.0018, 3.1420, 3.0614],\n",
      "        [2.8220, 2.8713, 2.9150, 2.9176, 2.9447],\n",
      "        [2.6869, 2.9410, 2.9025, 2.8337, 2.8644],\n",
      "        [2.9925, 3.2570, 3.0623, 3.2379, 3.2302],\n",
      "        [3.0773, 2.9970, 3.0773, 3.1958, 3.0917],\n",
      "        [2.7647, 3.1127, 2.9221, 2.9816, 3.0712],\n",
      "        [3.0329, 3.1743, 3.1159, 3.1699, 3.2144],\n",
      "        [2.8925, 2.8518, 2.9401, 2.9541, 2.9498],\n",
      "        [2.8189, 2.9590, 2.8098, 2.9276, 2.9224],\n",
      "        [3.0506, 3.2172, 3.1917, 3.1363, 3.0130],\n",
      "        [2.9656, 3.1293, 2.9435, 3.1714, 3.0993],\n",
      "        [2.8619, 3.0405, 2.9040, 3.0267, 2.9681],\n",
      "        [2.7483, 3.1222, 3.0112, 2.9396, 3.1210],\n",
      "        [2.8325, 2.9032, 2.9385, 2.9414, 2.9777],\n",
      "        [2.7400, 2.9780, 2.7675, 2.9041, 2.8239],\n",
      "        [2.7330, 2.8918, 2.9449, 2.8966, 2.8369],\n",
      "        [2.8386, 2.8385, 2.9503, 2.9120, 2.9412],\n",
      "        [3.0484, 3.0458, 3.1081, 3.1329, 2.9849],\n",
      "        [2.7251, 2.8963, 2.8049, 2.8192, 2.8724],\n",
      "        [2.8388, 2.8551, 2.9893, 2.9649, 2.9685],\n",
      "        [2.9529, 2.9512, 2.9980, 3.0953, 2.9236],\n",
      "        [2.6956, 2.9415, 2.9064, 2.8374, 2.8696],\n",
      "        [3.0520, 2.8376, 2.9875, 3.2598, 3.2719],\n",
      "        [2.8342, 2.8709, 2.9246, 2.9167, 2.9479],\n",
      "        [2.7468, 2.7639, 2.8262, 2.8672, 2.8166],\n",
      "        [2.9862, 3.1439, 3.0506, 3.0943, 3.0696],\n",
      "        [3.0031, 3.1055, 3.0607, 2.9998, 3.0840],\n",
      "        [2.8388, 2.8573, 2.9291, 2.9216, 2.9497],\n",
      "        [2.8333, 2.9604, 2.8057, 2.9289, 2.9383],\n",
      "        [2.7186, 3.1065, 2.9676, 2.8925, 3.1099],\n",
      "        [3.2357, 3.3704, 3.0952, 3.1191, 3.1185],\n",
      "        [2.8324, 2.9060, 2.9923, 2.8655, 3.0857],\n",
      "        [2.7582, 3.1200, 2.9446, 2.9591, 3.1127],\n",
      "        [2.8920, 2.8564, 2.9462, 2.9677, 2.9641],\n",
      "        [2.8311, 2.8916, 2.9315, 2.9391, 2.9700],\n",
      "        [2.7471, 2.8570, 2.9054, 2.8996, 2.8304],\n",
      "        [3.0907, 3.0834, 3.0973, 3.1896, 3.0194]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.8238, 2.8920, 2.9293, 2.9415, 2.9664],\n",
      "        [3.1504, 3.1254, 3.0653, 3.1680, 3.1917],\n",
      "        [2.9594, 3.1056, 2.9522, 3.0295, 3.0581],\n",
      "        [3.0239, 2.9231, 2.9671, 2.9743, 3.0126],\n",
      "        [2.8398, 2.8520, 2.9454, 2.9263, 2.9403],\n",
      "        [2.7259, 2.8757, 2.9074, 2.8730, 2.8476],\n",
      "        [3.0346, 3.0020, 2.9971, 2.9542, 2.9308],\n",
      "        [2.8321, 2.8882, 2.9300, 2.9302, 2.9565],\n",
      "        [2.7141, 2.8162, 2.8556, 2.8369, 2.8364],\n",
      "        [3.2527, 3.3700, 2.9870, 3.1327, 3.0493],\n",
      "        [3.0147, 2.9842, 3.0334, 3.1123, 3.0324],\n",
      "        [2.9364, 3.2153, 3.0135, 3.0667, 3.0950],\n",
      "        [3.1534, 3.1005, 3.1651, 3.3027, 3.1975],\n",
      "        [2.7407, 2.9134, 2.8062, 2.8425, 2.8838],\n",
      "        [2.6913, 2.9863, 2.8427, 2.6803, 2.9152],\n",
      "        [2.9738, 3.1062, 2.9473, 3.1234, 3.2130],\n",
      "        [2.9644, 3.1915, 2.9827, 2.8774, 3.0747],\n",
      "        [2.7628, 2.9428, 2.8956, 3.0184, 2.8872],\n",
      "        [2.7286, 2.8977, 2.8096, 2.8199, 2.8714],\n",
      "        [2.8224, 2.8678, 2.8780, 2.9685, 2.8742],\n",
      "        [2.6668, 2.8510, 2.7922, 2.7554, 2.8250],\n",
      "        [2.6540, 2.7522, 2.7848, 2.7462, 2.7773],\n",
      "        [2.7750, 2.9206, 2.8477, 2.8874, 2.9117],\n",
      "        [2.8101, 2.9611, 3.0596, 2.8934, 2.9691],\n",
      "        [2.9832, 2.9874, 3.0981, 3.0067, 2.8538],\n",
      "        [2.5599, 2.7549, 2.8084, 2.7317, 2.8291],\n",
      "        [2.7540, 2.8706, 2.7812, 2.9183, 2.8654],\n",
      "        [2.7573, 2.8938, 2.8017, 2.9016, 2.8587],\n",
      "        [3.1252, 3.0980, 3.0811, 3.2537, 3.1934],\n",
      "        [2.8686, 2.8734, 3.0052, 2.9839, 3.0378],\n",
      "        [3.1581, 2.9399, 2.9951, 3.4725, 3.3162],\n",
      "        [3.2314, 3.3538, 2.9863, 3.1248, 3.0570],\n",
      "        [2.8641, 2.8926, 2.9938, 2.9796, 2.9970],\n",
      "        [2.9502, 2.9265, 2.9621, 2.8999, 2.8378],\n",
      "        [2.8597, 3.1232, 2.9025, 3.0988, 3.0470],\n",
      "        [2.6915, 2.7214, 2.7954, 2.8748, 2.8080],\n",
      "        [2.8545, 2.9024, 2.8235, 2.9203, 3.0452],\n",
      "        [2.7214, 2.8714, 2.9059, 2.8675, 2.8413],\n",
      "        [3.1298, 2.9877, 3.1033, 3.2206, 3.1410],\n",
      "        [2.8424, 2.8606, 2.9329, 2.9262, 2.9551],\n",
      "        [2.8257, 2.8833, 2.9242, 2.9308, 2.9535],\n",
      "        [3.0390, 3.1359, 2.9706, 3.0632, 3.1922],\n",
      "        [2.9537, 3.0640, 3.0764, 3.0366, 3.0641],\n",
      "        [2.7022, 2.9655, 2.9191, 2.8451, 2.8870],\n",
      "        [2.6766, 2.9407, 2.9995, 2.8448, 2.9548],\n",
      "        [2.9024, 3.1022, 2.9741, 2.9505, 3.0540],\n",
      "        [2.8797, 3.0656, 2.9336, 3.0375, 2.9740],\n",
      "        [2.8163, 2.9180, 2.9069, 2.9306, 3.0569],\n",
      "        [2.8263, 2.9409, 2.8935, 2.9010, 2.9321],\n",
      "        [3.1855, 3.2567, 3.1209, 3.4249, 3.2979],\n",
      "        [3.0062, 3.2729, 3.0807, 3.2469, 3.2479],\n",
      "        [2.8779, 3.0322, 2.8556, 2.9038, 2.9910],\n",
      "        [2.8424, 2.9813, 2.8873, 3.0124, 3.0002],\n",
      "        [2.8286, 2.8977, 2.9302, 2.9406, 2.9621],\n",
      "        [2.8369, 2.9637, 2.8095, 2.9334, 2.9438],\n",
      "        [2.7401, 2.9428, 2.8480, 2.8642, 2.9349],\n",
      "        [2.7618, 2.9158, 2.8039, 2.8620, 2.8830],\n",
      "        [2.9589, 3.0908, 3.0362, 3.1541, 3.0364],\n",
      "        [2.9170, 3.1421, 3.0474, 3.0473, 3.0222],\n",
      "        [2.7336, 2.8668, 2.9015, 2.8647, 2.8488],\n",
      "        [3.0533, 3.1977, 3.1786, 3.1293, 2.9873],\n",
      "        [2.7324, 2.9844, 3.0734, 2.9236, 3.0129],\n",
      "        [2.7474, 2.9346, 2.9872, 2.9057, 3.0166],\n",
      "        [2.8604, 2.9951, 2.8106, 2.9877, 2.9526]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.9475, 2.9569, 2.9411, 3.1161, 3.0647],\n",
      "        [2.7029, 2.9496, 2.9164, 2.8547, 2.8911],\n",
      "        [2.6473, 2.8384, 2.8232, 2.8267, 2.8605],\n",
      "        [2.8063, 2.9994, 2.8563, 3.0324, 2.8964],\n",
      "        [2.7850, 2.9428, 2.9065, 3.0152, 2.8913],\n",
      "        [2.8195, 2.8106, 2.8712, 2.8822, 3.0225],\n",
      "        [2.8063, 2.8645, 2.8841, 2.9568, 2.8753],\n",
      "        [2.9309, 2.9045, 2.9852, 2.8974, 2.9522],\n",
      "        [2.8268, 2.9675, 2.8103, 2.9306, 2.9353],\n",
      "        [2.8242, 2.9608, 2.8137, 2.9143, 2.9326],\n",
      "        [3.2630, 3.4827, 3.0422, 3.1559, 3.0666],\n",
      "        [2.9405, 3.1377, 3.0633, 3.0850, 3.1614],\n",
      "        [2.8092, 3.0085, 2.8586, 3.0302, 2.8977],\n",
      "        [2.7641, 2.8437, 2.9081, 2.9240, 2.9454],\n",
      "        [2.8707, 2.8179, 2.9196, 2.8456, 2.8848],\n",
      "        [3.2181, 3.0332, 3.1844, 3.6058, 3.5486],\n",
      "        [3.1349, 3.2378, 3.1140, 3.3396, 3.2201],\n",
      "        [2.8558, 2.8695, 2.9584, 2.9347, 2.9634],\n",
      "        [2.8445, 2.9743, 2.8133, 2.9579, 2.9460],\n",
      "        [2.7104, 2.8665, 2.8827, 2.8414, 2.8531],\n",
      "        [3.0673, 3.0597, 3.0799, 3.1791, 3.1155],\n",
      "        [3.1528, 3.2783, 3.1543, 3.3929, 3.3015],\n",
      "        [2.9363, 3.0482, 2.9160, 3.0326, 3.1076],\n",
      "        [2.7935, 2.9265, 2.9941, 3.0047, 3.1071],\n",
      "        [2.8400, 2.9666, 2.8142, 2.9374, 2.9487],\n",
      "        [2.8574, 3.1040, 2.9753, 2.9730, 2.8801],\n",
      "        [2.9341, 3.0168, 3.0207, 2.9978, 3.0433],\n",
      "        [3.2751, 3.4446, 3.0513, 3.1321, 3.0863],\n",
      "        [2.7583, 2.8035, 2.8534, 2.8689, 2.8522],\n",
      "        [2.6601, 2.9243, 2.7099, 2.8668, 2.7726],\n",
      "        [3.0519, 2.9118, 2.9685, 3.3318, 3.2042],\n",
      "        [3.1328, 2.9907, 3.1080, 3.2253, 3.1459],\n",
      "        [2.7470, 2.9072, 2.8082, 2.8468, 2.8799],\n",
      "        [2.8666, 2.8826, 2.9973, 2.9903, 3.0211],\n",
      "        [2.7189, 2.9033, 2.9287, 2.8698, 2.8785],\n",
      "        [2.8325, 2.9631, 2.8906, 2.9086, 2.9526],\n",
      "        [2.8897, 3.0333, 2.8384, 2.9186, 2.9882],\n",
      "        [2.7149, 2.8505, 2.8758, 2.8424, 2.8509],\n",
      "        [2.7917, 3.1961, 3.0589, 2.9537, 2.9738],\n",
      "        [2.8149, 2.9156, 3.0242, 3.0372, 3.1261],\n",
      "        [2.9587, 3.0586, 2.9172, 3.0011, 3.1630],\n",
      "        [3.1410, 2.9526, 3.0006, 3.4415, 3.3028],\n",
      "        [2.8811, 3.0352, 2.8602, 2.9081, 2.9959],\n",
      "        [2.9948, 3.1275, 2.9331, 3.0248, 3.1158],\n",
      "        [2.8094, 2.9785, 2.8653, 2.9651, 3.0169],\n",
      "        [2.7042, 2.8891, 2.8112, 2.8551, 2.8521],\n",
      "        [2.8984, 3.0414, 2.8851, 3.0142, 3.0180],\n",
      "        [2.8141, 2.9123, 2.7299, 2.9911, 2.8003],\n",
      "        [2.7585, 2.8265, 2.7483, 2.9142, 2.7893],\n",
      "        [2.7064, 2.8838, 2.8060, 2.8009, 2.8580],\n",
      "        [2.8627, 3.1618, 3.0475, 3.0137, 2.9751],\n",
      "        [3.0244, 2.9272, 2.9610, 3.2514, 3.1521],\n",
      "        [3.0058, 2.9704, 2.9831, 2.9171, 2.8921],\n",
      "        [2.7429, 2.8758, 2.9207, 2.8779, 2.8672],\n",
      "        [2.8512, 2.9691, 2.9660, 2.9358, 2.8698],\n",
      "        [2.8440, 3.0966, 2.9581, 2.9465, 2.8719],\n",
      "        [2.7275, 2.8223, 2.8630, 2.8499, 2.8479],\n",
      "        [3.2994, 3.5115, 3.0593, 3.1647, 3.1359],\n",
      "        [2.7121, 2.8060, 2.8173, 2.8181, 2.8374],\n",
      "        [2.9638, 2.9321, 3.0174, 3.0410, 3.0046],\n",
      "        [2.8891, 3.2346, 3.0053, 3.1419, 3.1709],\n",
      "        [2.8597, 2.9873, 2.8192, 2.9830, 2.9555],\n",
      "        [2.8203, 2.8531, 2.7777, 2.8842, 3.0123],\n",
      "        [3.1176, 3.2213, 3.1152, 3.1730, 3.2708]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.1262, 3.2080, 3.1287, 3.1640, 3.2397],\n",
      "        [2.9556, 3.0738, 3.0913, 3.0450, 3.0808],\n",
      "        [3.0564, 3.0806, 3.1140, 3.0344, 2.9225],\n",
      "        [2.8045, 2.9483, 2.8076, 2.9186, 2.9107],\n",
      "        [3.0067, 3.0756, 3.0427, 3.0776, 3.1716],\n",
      "        [2.6850, 2.8666, 2.8039, 2.7819, 2.8452],\n",
      "        [2.7178, 2.8546, 2.8801, 2.8461, 2.8553],\n",
      "        [2.9929, 3.1289, 3.0825, 3.0317, 2.9390],\n",
      "        [2.6463, 2.8437, 2.8323, 2.8153, 2.8705],\n",
      "        [3.0276, 3.1350, 2.9583, 3.0570, 3.1661],\n",
      "        [2.7137, 2.9525, 2.8735, 2.8823, 3.0425],\n",
      "        [2.9732, 2.9499, 3.0165, 3.0467, 3.0045],\n",
      "        [3.1395, 2.9941, 3.1052, 3.5396, 3.4719],\n",
      "        [2.7386, 2.9121, 2.9734, 2.9011, 2.8585],\n",
      "        [2.9462, 3.1234, 2.9385, 3.0360, 3.0600],\n",
      "        [2.7646, 2.7750, 2.8405, 2.8786, 2.8386],\n",
      "        [2.9037, 3.1737, 3.0292, 3.0704, 3.1843],\n",
      "        [3.0006, 2.8894, 2.8747, 2.8979, 3.0374],\n",
      "        [2.8860, 3.0354, 2.8509, 2.9137, 2.9936],\n",
      "        [2.8726, 3.0074, 2.8171, 3.0046, 2.9701],\n",
      "        [2.9961, 3.1548, 3.0639, 3.1072, 3.0849],\n",
      "        [3.0937, 2.8485, 3.0144, 3.3089, 3.3163],\n",
      "        [3.1526, 3.1812, 3.0621, 3.1885, 3.2852],\n",
      "        [2.8363, 2.8691, 2.9285, 2.9244, 2.9569],\n",
      "        [2.8789, 3.0565, 2.9207, 3.0337, 2.9855],\n",
      "        [3.0514, 3.2127, 3.1694, 3.1153, 2.9833],\n",
      "        [2.8405, 3.0581, 2.8960, 2.8905, 3.0087],\n",
      "        [2.7093, 2.8878, 2.8102, 2.8046, 2.8624],\n",
      "        [2.7814, 2.9394, 2.8179, 2.8868, 2.9120],\n",
      "        [2.9224, 2.9834, 2.9709, 2.9852, 2.9991],\n",
      "        [2.8688, 3.0734, 2.9383, 3.0976, 2.9838],\n",
      "        [2.9358, 3.0898, 3.0157, 3.0056, 2.9230],\n",
      "        [2.9904, 3.1738, 3.0840, 3.1008, 3.0859],\n",
      "        [2.7163, 2.8045, 2.8538, 2.8320, 2.8293],\n",
      "        [2.9223, 3.1687, 3.0761, 3.0740, 3.2410],\n",
      "        [2.8255, 2.9638, 2.8180, 2.9448, 2.9379],\n",
      "        [2.8908, 3.0541, 2.8988, 3.0365, 3.0072],\n",
      "        [2.8078, 3.1080, 3.0469, 2.8632, 3.0687],\n",
      "        [2.9238, 3.0115, 2.8909, 3.0168, 3.0100],\n",
      "        [2.7554, 2.9077, 2.7856, 2.9217, 2.8851],\n",
      "        [3.0831, 3.2407, 3.0182, 2.9894, 3.0355],\n",
      "        [3.1120, 2.8454, 3.0123, 3.3333, 3.3317],\n",
      "        [3.2819, 3.0227, 3.1522, 3.5917, 3.5512],\n",
      "        [2.9797, 3.0337, 3.0178, 2.9909, 2.8432],\n",
      "        [3.0743, 3.0766, 3.0835, 3.2098, 3.1258],\n",
      "        [2.9383, 2.7845, 3.0845, 3.0088, 3.0011],\n",
      "        [2.8456, 2.8590, 2.9499, 2.9300, 2.9507],\n",
      "        [3.0504, 3.2099, 3.1713, 3.1121, 2.9922],\n",
      "        [2.8387, 2.8241, 2.9109, 2.9267, 3.0461],\n",
      "        [3.0199, 3.0306, 3.1353, 3.0646, 2.9118],\n",
      "        [2.7538, 2.7974, 2.8528, 2.8683, 2.8457],\n",
      "        [3.1721, 3.3403, 3.1090, 3.0825, 3.1578],\n",
      "        [3.0156, 3.0890, 3.1078, 3.2027, 3.0460],\n",
      "        [2.8469, 2.9751, 2.9528, 2.9014, 2.8848],\n",
      "        [2.6600, 2.7590, 2.7934, 2.7537, 2.7865],\n",
      "        [2.8318, 2.8819, 2.9279, 2.9303, 2.9595],\n",
      "        [2.9687, 3.0335, 3.0106, 2.9770, 2.8295],\n",
      "        [3.0619, 2.8483, 3.0006, 3.2721, 3.2867],\n",
      "        [2.7727, 2.9618, 2.8430, 2.9842, 2.8880],\n",
      "        [2.9900, 3.1706, 2.9998, 3.0823, 3.0922],\n",
      "        [2.9255, 2.9734, 2.9658, 2.9894, 2.9792],\n",
      "        [2.9444, 3.0281, 2.9453, 2.9929, 2.9983],\n",
      "        [2.9012, 3.2371, 2.9569, 3.1632, 3.1413],\n",
      "        [3.0812, 2.9669, 2.9740, 3.0171, 3.0890]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.9513, 3.1303, 2.9513, 3.0251, 3.0657],\n",
      "        [3.0429, 3.0163, 3.0744, 3.1424, 3.0691],\n",
      "        [2.8453, 2.8696, 2.9969, 2.9751, 2.9968],\n",
      "        [2.9971, 3.0761, 3.0630, 3.0734, 3.1922],\n",
      "        [2.9483, 3.1288, 3.0733, 3.0977, 3.1362],\n",
      "        [2.7432, 2.8301, 2.8718, 2.8621, 2.8602],\n",
      "        [2.9286, 2.9816, 2.9701, 2.9968, 2.9928],\n",
      "        [2.7334, 2.9959, 2.9402, 2.8716, 2.9357],\n",
      "        [2.9252, 2.9880, 2.9750, 2.9887, 3.0032],\n",
      "        [2.7558, 2.9584, 2.8597, 2.8813, 2.9513],\n",
      "        [2.9033, 2.9518, 2.9517, 3.0365, 3.0017],\n",
      "        [2.9254, 3.1734, 3.0804, 3.0776, 3.2452],\n",
      "        [2.8218, 2.9734, 2.9047, 3.0064, 3.0199],\n",
      "        [2.8377, 3.2074, 2.9414, 3.1396, 3.1109],\n",
      "        [2.9040, 3.2457, 2.9695, 3.1738, 3.1577],\n",
      "        [2.7661, 2.8368, 2.7595, 2.9222, 2.8187],\n",
      "        [2.8610, 2.9876, 2.9732, 2.9366, 2.8845],\n",
      "        [3.0482, 3.1482, 2.9842, 3.0751, 3.2059],\n",
      "        [2.8112, 2.9586, 2.8173, 2.9264, 2.9207],\n",
      "        [2.9721, 3.0993, 2.9611, 3.1063, 3.0738],\n",
      "        [3.0442, 3.1162, 3.1160, 3.1386, 3.0861],\n",
      "        [2.7649, 3.0810, 3.0380, 2.9393, 3.1234],\n",
      "        [3.0377, 3.2467, 3.0674, 3.2310, 3.2024],\n",
      "        [3.2398, 3.3661, 2.9994, 3.1368, 3.0705],\n",
      "        [2.8750, 3.0557, 2.9216, 3.0428, 2.9869],\n",
      "        [2.8634, 2.9965, 2.8248, 2.9854, 2.9638],\n",
      "        [2.6175, 2.8076, 2.8444, 2.7757, 2.8715],\n",
      "        [2.7379, 2.8202, 2.8656, 2.8562, 2.8525],\n",
      "        [2.9789, 3.1447, 2.9616, 3.1878, 3.1193],\n",
      "        [3.2777, 3.3998, 2.9962, 3.1599, 3.0503],\n",
      "        [2.7297, 2.8606, 2.9893, 2.8684, 2.9862],\n",
      "        [2.8281, 2.9383, 2.8593, 2.8894, 2.9138],\n",
      "        [2.7209, 2.9076, 2.9313, 2.8712, 2.8820],\n",
      "        [2.7459, 2.9066, 2.9619, 2.9123, 2.8563],\n",
      "        [2.9697, 2.9761, 2.9232, 3.1547, 3.0962],\n",
      "        [2.9808, 3.0823, 3.0677, 3.0144, 3.0763],\n",
      "        [2.9565, 3.0693, 2.9438, 3.0634, 3.1224],\n",
      "        [2.8120, 2.9303, 2.8539, 2.8673, 2.9035],\n",
      "        [2.9906, 3.0346, 2.9893, 3.0965, 3.1652],\n",
      "        [2.7777, 2.8647, 2.9223, 2.9401, 2.9643],\n",
      "        [3.0602, 3.2744, 3.0644, 3.2176, 3.2677],\n",
      "        [2.8367, 2.9333, 2.8894, 3.0027, 2.9807],\n",
      "        [2.8874, 3.1668, 3.0968, 3.0882, 3.1631],\n",
      "        [2.9579, 3.1249, 2.9402, 3.1580, 3.0827],\n",
      "        [2.9100, 2.9086, 3.0552, 3.1527, 3.2418],\n",
      "        [2.9422, 3.0572, 2.9247, 3.0399, 3.1162],\n",
      "        [3.1203, 3.0509, 3.0220, 3.0760, 3.1474],\n",
      "        [3.0839, 2.9714, 2.9781, 3.0208, 3.0933],\n",
      "        [2.7526, 2.9108, 2.8169, 2.8527, 2.8853],\n",
      "        [2.9108, 2.9360, 3.0598, 3.0210, 3.0511],\n",
      "        [2.9934, 3.1371, 2.9338, 3.0259, 3.1137],\n",
      "        [2.7304, 2.8827, 2.9189, 2.8785, 2.8549],\n",
      "        [2.8195, 2.9063, 2.8952, 2.8757, 2.9379],\n",
      "        [2.8585, 2.9861, 2.8255, 2.9625, 2.9678],\n",
      "        [2.7961, 2.7822, 2.8337, 2.8812, 2.8347],\n",
      "        [2.8512, 2.8327, 2.9577, 2.9470, 3.0518],\n",
      "        [3.4110, 3.5931, 3.1700, 3.2617, 3.2181],\n",
      "        [3.1452, 3.1028, 3.0675, 3.2682, 3.1762],\n",
      "        [2.8482, 2.9782, 2.8192, 2.9594, 2.9546],\n",
      "        [2.9425, 2.9383, 2.9998, 2.9262, 2.9256],\n",
      "        [2.7338, 2.8366, 2.8745, 2.8525, 2.8587],\n",
      "        [2.8538, 2.9875, 2.9479, 2.9184, 2.9842],\n",
      "        [3.0989, 2.8615, 3.0116, 3.3123, 3.3302],\n",
      "        [2.8677, 3.0792, 2.9573, 3.0998, 2.9812]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.8312, 2.9721, 2.8260, 2.9519, 2.9457],\n",
      "        [2.8561, 2.9839, 2.8170, 2.9713, 2.9424],\n",
      "        [2.7739, 2.8000, 2.8565, 2.8906, 2.8563],\n",
      "        [2.8591, 2.9712, 2.8736, 3.0188, 2.9787],\n",
      "        [2.8420, 2.8777, 2.9364, 2.9318, 2.9646],\n",
      "        [3.1625, 3.2627, 3.1593, 3.2173, 3.3166],\n",
      "        [2.8686, 2.9763, 3.1097, 3.0193, 3.1248],\n",
      "        [2.6779, 2.8631, 2.7105, 2.8589, 2.8015],\n",
      "        [2.7334, 2.9086, 2.8204, 2.8318, 2.8803],\n",
      "        [2.8340, 3.1920, 3.0834, 3.0136, 3.0043],\n",
      "        [2.7365, 2.8405, 2.8783, 2.8564, 2.8624],\n",
      "        [2.9138, 2.8787, 3.0802, 3.0601, 3.0199],\n",
      "        [3.0338, 3.1681, 3.1681, 3.0707, 2.9299],\n",
      "        [2.8179, 2.8762, 2.8954, 2.9736, 2.8952],\n",
      "        [2.8701, 2.8630, 2.9971, 2.9917, 3.0826],\n",
      "        [2.7112, 2.8983, 2.8970, 2.8503, 2.8687],\n",
      "        [2.9831, 3.0090, 3.0321, 2.9893, 2.9113],\n",
      "        [3.0407, 3.0743, 3.0761, 3.1503, 3.0362],\n",
      "        [2.8757, 2.9087, 3.0107, 2.9950, 3.0143],\n",
      "        [3.2074, 3.1757, 3.1668, 3.2566, 3.2738],\n",
      "        [2.8613, 2.9901, 2.8295, 2.9663, 2.9715],\n",
      "        [3.0026, 2.9315, 2.9442, 3.2724, 3.1475],\n",
      "        [3.4130, 3.5736, 3.1943, 3.2595, 3.1853],\n",
      "        [2.6905, 2.8747, 2.8116, 2.7889, 2.8528],\n",
      "        [2.7763, 2.8347, 2.8859, 2.8852, 2.8598],\n",
      "        [2.8860, 3.1664, 3.0978, 3.0892, 3.1644],\n",
      "        [2.9519, 2.9362, 3.1054, 3.0918, 3.0352],\n",
      "        [2.9835, 3.0414, 3.0245, 2.9966, 2.8504],\n",
      "        [3.0528, 3.0944, 3.2156, 3.0519, 2.9903],\n",
      "        [3.0497, 3.1944, 3.1388, 3.1908, 3.2381],\n",
      "        [2.9622, 2.9432, 2.9787, 2.9169, 2.8555],\n",
      "        [2.8728, 3.0019, 2.8185, 2.9953, 2.9578],\n",
      "        [2.8402, 2.9086, 2.9475, 2.9546, 2.9778],\n",
      "        [2.7676, 3.0959, 2.9551, 2.7831, 3.0720],\n",
      "        [2.7348, 2.8361, 2.8739, 2.8575, 2.8614],\n",
      "        [2.9624, 3.0742, 2.9280, 3.0076, 3.1806],\n",
      "        [2.8396, 2.9066, 3.0219, 2.8665, 3.1160],\n",
      "        [2.8590, 2.9931, 2.8304, 2.9873, 2.9654],\n",
      "        [2.8866, 2.8954, 3.0092, 2.9554, 2.9918],\n",
      "        [2.8022, 2.7738, 2.8239, 2.8809, 2.8255],\n",
      "        [3.0832, 3.0106, 3.0770, 3.1791, 3.1110],\n",
      "        [2.8443, 2.9085, 3.0290, 2.8420, 3.1249],\n",
      "        [2.9384, 3.0106, 2.9703, 3.1311, 3.0155],\n",
      "        [3.0447, 2.8609, 2.8600, 2.9003, 3.0444],\n",
      "        [2.7713, 3.0868, 2.9469, 2.7670, 3.0413],\n",
      "        [2.7848, 2.9410, 2.8181, 2.8872, 2.9126],\n",
      "        [3.0149, 3.1446, 3.1072, 3.0539, 2.9563],\n",
      "        [2.8524, 2.8823, 2.9544, 2.9429, 2.9718],\n",
      "        [2.8494, 2.9507, 2.9151, 2.9319, 2.9712],\n",
      "        [2.9096, 3.1825, 3.0376, 3.0780, 3.1922],\n",
      "        [3.1703, 2.9564, 3.0130, 3.4875, 3.3336],\n",
      "        [2.7732, 3.0274, 2.9309, 2.9428, 3.1178],\n",
      "        [2.8969, 3.0414, 2.8364, 2.9288, 2.9943],\n",
      "        [2.8508, 2.9354, 2.9495, 2.9285, 3.1350],\n",
      "        [2.8805, 3.0177, 2.7995, 2.9105, 2.9689],\n",
      "        [2.9211, 3.1498, 2.9825, 3.1479, 3.0854],\n",
      "        [2.6945, 2.8746, 2.8092, 2.7905, 2.8515],\n",
      "        [3.1446, 3.0637, 3.0432, 3.1170, 3.1605],\n",
      "        [2.8474, 2.9222, 2.9602, 2.9707, 2.9956],\n",
      "        [3.1625, 3.1134, 3.0946, 3.1725, 3.1664],\n",
      "        [2.9428, 2.9306, 3.0015, 2.9226, 2.9449],\n",
      "        [2.8716, 3.1392, 2.9197, 3.1141, 3.0642],\n",
      "        [2.7718, 2.9212, 2.8180, 2.8692, 2.8943],\n",
      "        [3.1026, 3.1896, 3.0480, 3.1579, 3.2410]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.0040, 3.1231, 3.0713, 2.9984, 3.0998],\n",
      "        [2.8442, 2.8874, 2.9385, 2.9400, 2.9698],\n",
      "        [3.0523, 3.2099, 3.0912, 3.0008, 3.1502],\n",
      "        [2.8129, 2.8903, 3.0509, 2.8180, 3.1055],\n",
      "        [2.6971, 2.8782, 2.8126, 2.7947, 2.8548],\n",
      "        [2.7783, 3.0030, 2.9456, 2.8223, 2.8864],\n",
      "        [3.0750, 2.9503, 2.9023, 2.9762, 3.0738],\n",
      "        [2.7520, 2.9231, 2.8248, 2.8600, 2.8935],\n",
      "        [3.1641, 3.3081, 3.1680, 3.4253, 3.3255],\n",
      "        [2.8945, 3.0479, 2.8625, 2.9255, 3.0047],\n",
      "        [2.8720, 2.9880, 2.8744, 2.9729, 2.9998],\n",
      "        [2.7303, 2.9193, 2.9445, 2.8849, 2.8944],\n",
      "        [3.0040, 3.1243, 3.0023, 3.0110, 3.0627],\n",
      "        [2.8524, 2.8938, 2.9489, 2.9409, 2.9736],\n",
      "        [2.7721, 2.8449, 2.7671, 2.9303, 2.8261],\n",
      "        [2.8809, 3.0194, 2.8289, 3.0161, 2.9813],\n",
      "        [3.1942, 3.1489, 3.1005, 3.1986, 3.2088],\n",
      "        [2.9512, 3.2356, 3.0348, 3.0867, 3.1161],\n",
      "        [3.0434, 3.2553, 3.0754, 3.2393, 3.2097],\n",
      "        [2.8208, 2.8171, 2.9770, 2.7996, 3.0209],\n",
      "        [3.0640, 2.9437, 2.9861, 3.3322, 3.2185],\n",
      "        [2.7260, 2.7764, 2.8430, 2.8667, 2.8563],\n",
      "        [2.7048, 2.9632, 2.9266, 2.8571, 2.8906],\n",
      "        [3.0391, 3.0890, 3.0467, 3.1436, 3.2294],\n",
      "        [3.0498, 3.1245, 3.1238, 3.1474, 3.0932],\n",
      "        [3.0002, 3.1766, 2.9563, 3.0246, 3.1128],\n",
      "        [2.8439, 2.9786, 2.9434, 2.9430, 2.9967],\n",
      "        [2.9480, 3.0413, 3.0418, 3.0388, 3.1437],\n",
      "        [2.8564, 2.8614, 2.9742, 2.9354, 2.9667],\n",
      "        [2.8049, 2.9581, 2.8308, 2.8968, 2.9329],\n",
      "        [3.0052, 2.9732, 2.9812, 3.2866, 3.1893],\n",
      "        [2.7392, 2.8441, 2.8818, 2.8607, 2.8657],\n",
      "        [2.8686, 2.8592, 2.9909, 2.9846, 3.0790],\n",
      "        [3.1284, 2.9832, 3.0105, 3.4233, 3.2879],\n",
      "        [2.9096, 2.9335, 3.0524, 3.0302, 3.0571],\n",
      "        [2.7974, 2.9480, 2.8249, 2.8998, 2.9286],\n",
      "        [2.8582, 2.8893, 3.0171, 2.9904, 3.0101],\n",
      "        [2.9395, 2.9841, 2.9232, 3.0795, 3.0416],\n",
      "        [2.9234, 3.0932, 2.9490, 3.0686, 3.0332],\n",
      "        [2.7462, 3.0042, 3.0941, 2.9433, 3.0335],\n",
      "        [2.7925, 2.9460, 2.8322, 2.8867, 2.9342],\n",
      "        [2.8393, 3.1448, 3.0355, 3.0370, 3.1624],\n",
      "        [2.8770, 3.0125, 2.8283, 3.0221, 2.9769],\n",
      "        [2.9812, 2.9956, 3.0293, 2.9859, 2.9158],\n",
      "        [2.7639, 2.9315, 2.9835, 2.9224, 2.8847],\n",
      "        [3.0002, 3.2073, 3.0261, 3.0980, 3.1161],\n",
      "        [2.8493, 2.8955, 2.9450, 2.9416, 2.9724],\n",
      "        [2.8863, 3.0168, 2.9719, 2.9971, 3.0500],\n",
      "        [2.8344, 3.1804, 2.9709, 3.0724, 3.1223],\n",
      "        [2.7789, 2.8383, 2.8894, 2.8895, 2.8631],\n",
      "        [2.8443, 2.8926, 2.9436, 2.9510, 2.9805],\n",
      "        [2.8833, 3.0197, 2.8419, 3.0192, 2.9829],\n",
      "        [2.7193, 2.9167, 2.9120, 2.8675, 2.8920],\n",
      "        [2.9965, 3.1186, 3.0011, 2.9628, 3.0544],\n",
      "        [2.8046, 2.9578, 2.8221, 2.9171, 2.9250],\n",
      "        [2.8749, 3.0140, 2.8315, 3.0069, 2.9733],\n",
      "        [2.9455, 3.0336, 3.0369, 3.0136, 3.0591],\n",
      "        [3.0335, 3.1527, 2.9764, 3.0576, 3.1718],\n",
      "        [2.7389, 3.0035, 2.9476, 2.8797, 2.9430],\n",
      "        [2.7966, 2.9592, 2.9224, 3.0304, 2.9066],\n",
      "        [2.9234, 2.8816, 3.1814, 3.0357, 3.1071],\n",
      "        [2.7924, 3.0487, 2.9414, 2.9724, 3.0947],\n",
      "        [3.2826, 3.4081, 3.0037, 3.1684, 3.0574],\n",
      "        [2.9596, 3.0703, 3.1337, 3.1033, 3.1458]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.8465, 3.0843, 2.9938, 2.9002, 3.0632],\n",
      "        [2.7197, 2.8148, 2.8681, 2.8438, 2.8250],\n",
      "        [2.9201, 3.0795, 2.9299, 3.0583, 3.0350],\n",
      "        [3.1138, 3.0183, 3.1096, 3.2227, 3.1280],\n",
      "        [2.6890, 2.8710, 2.8152, 2.7856, 2.8564],\n",
      "        [2.8133, 2.9306, 2.7606, 2.9987, 2.8380],\n",
      "        [2.9009, 2.9255, 3.0579, 3.1228, 3.2191],\n",
      "        [2.8479, 2.9205, 2.9572, 2.9661, 2.9891],\n",
      "        [3.0231, 3.1603, 2.9905, 3.1668, 3.2806],\n",
      "        [2.8955, 3.0618, 2.8866, 2.9315, 3.0194],\n",
      "        [2.9246, 2.9740, 2.9476, 3.0408, 3.1163],\n",
      "        [2.7730, 3.0924, 3.0492, 2.9522, 3.1347],\n",
      "        [2.8376, 2.9988, 3.0990, 2.9193, 3.0096],\n",
      "        [2.8153, 2.9634, 2.8224, 2.9337, 2.9259],\n",
      "        [3.0564, 3.1599, 2.9956, 3.0876, 3.2172],\n",
      "        [2.8846, 2.8379, 2.9387, 2.8647, 2.9043],\n",
      "        [2.8155, 2.8938, 3.0543, 2.8220, 3.1096],\n",
      "        [2.8723, 2.8770, 2.8658, 3.0286, 2.9000],\n",
      "        [3.0911, 2.9828, 2.9890, 3.0341, 3.1048],\n",
      "        [2.8013, 2.7802, 2.9145, 2.9116, 2.9852],\n",
      "        [2.8593, 2.8834, 2.8781, 3.0205, 2.9017],\n",
      "        [3.1972, 3.1696, 3.1337, 3.2288, 3.2313],\n",
      "        [2.7054, 2.9712, 3.0413, 2.8527, 2.9724],\n",
      "        [2.7900, 2.9111, 2.9206, 2.8628, 2.9167],\n",
      "        [2.9873, 3.1561, 2.9732, 3.2004, 3.1310],\n",
      "        [2.9519, 2.9253, 3.0112, 2.9135, 3.0011],\n",
      "        [2.7011, 2.8865, 2.8209, 2.8081, 2.8699],\n",
      "        [2.9576, 3.0343, 3.0588, 3.0384, 3.0624],\n",
      "        [3.0666, 2.9472, 2.9895, 3.3361, 3.2225],\n",
      "        [3.0465, 3.2626, 3.0787, 3.2394, 3.2164],\n",
      "        [2.8582, 2.8552, 2.8509, 3.0288, 2.8762],\n",
      "        [2.7574, 2.9353, 2.8297, 2.8652, 2.9083],\n",
      "        [2.8838, 3.0779, 2.8998, 3.1299, 2.9430],\n",
      "        [2.8980, 3.1742, 3.1111, 3.1073, 3.1715],\n",
      "        [2.9481, 2.9379, 3.0085, 2.9310, 2.9523],\n",
      "        [2.8548, 2.9861, 2.9170, 2.9370, 2.9831],\n",
      "        [2.8294, 2.9359, 3.0437, 3.0565, 3.1459],\n",
      "        [2.9759, 3.0926, 3.1073, 3.0130, 2.9692],\n",
      "        [2.7965, 2.7810, 2.9651, 2.7472, 3.0149],\n",
      "        [2.6966, 2.8760, 2.7192, 2.8712, 2.8112],\n",
      "        [2.7672, 2.8895, 2.9211, 2.8439, 2.8972],\n",
      "        [2.9329, 3.0009, 2.9820, 3.0060, 3.0126],\n",
      "        [3.1581, 3.1119, 3.1093, 3.1661, 3.1673],\n",
      "        [2.8971, 2.8848, 3.0680, 3.0586, 3.0047],\n",
      "        [3.1366, 3.0769, 3.1433, 3.2758, 3.1783],\n",
      "        [2.9812, 3.2153, 3.0071, 2.9020, 3.0997],\n",
      "        [2.8830, 3.0317, 2.8063, 2.9159, 2.9793],\n",
      "        [2.8416, 2.9991, 2.9171, 3.0097, 3.0333],\n",
      "        [3.1562, 3.1378, 3.0650, 3.1670, 3.1874],\n",
      "        [2.9873, 3.1561, 2.9732, 3.2004, 3.1310],\n",
      "        [2.7261, 2.9073, 2.9168, 2.8725, 2.8946],\n",
      "        [2.7507, 2.8890, 2.9251, 2.8878, 2.8736],\n",
      "        [3.0079, 2.9387, 2.9513, 3.2806, 3.1550],\n",
      "        [2.8249, 3.1142, 3.0392, 2.8946, 3.0531],\n",
      "        [2.9287, 3.0242, 3.0531, 3.0333, 3.0615],\n",
      "        [2.7210, 2.9821, 2.9414, 2.8759, 2.9212],\n",
      "        [2.7172, 2.9267, 2.9139, 2.8582, 2.8810],\n",
      "        [3.0135, 2.9215, 2.9541, 3.3120, 3.1680],\n",
      "        [2.8524, 2.8375, 2.9438, 2.9533, 3.0592],\n",
      "        [3.0662, 3.2378, 3.1013, 3.0068, 3.1759],\n",
      "        [2.8880, 2.8882, 3.0101, 2.9842, 2.9876],\n",
      "        [2.7453, 2.9196, 2.8329, 2.8426, 2.8959],\n",
      "        [2.6832, 2.8725, 2.8152, 2.7778, 2.8492],\n",
      "        [2.8433, 2.8432, 2.9637, 2.9337, 2.9497]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.7225, 2.9056, 2.8276, 2.8251, 2.8812],\n",
      "        [3.1887, 3.3229, 2.9937, 3.1025, 3.0989],\n",
      "        [2.8639, 2.9260, 2.9648, 2.9811, 3.0119],\n",
      "        [2.8799, 3.0091, 2.8322, 3.0095, 2.9706],\n",
      "        [2.8628, 2.8566, 2.9864, 2.9792, 3.0733],\n",
      "        [2.9381, 3.1469, 3.0053, 3.1673, 3.0923],\n",
      "        [2.7795, 2.9309, 2.8279, 2.8829, 2.9054],\n",
      "        [2.7499, 2.8368, 2.8799, 2.8732, 2.8705],\n",
      "        [2.8665, 3.0073, 2.8390, 2.9979, 2.9724],\n",
      "        [2.8734, 3.2133, 2.9907, 3.1159, 3.1473],\n",
      "        [2.7818, 2.8099, 2.8662, 2.9046, 2.8671],\n",
      "        [2.9371, 3.0340, 2.9296, 3.0503, 3.0506],\n",
      "        [2.9844, 3.1563, 2.9433, 3.0374, 3.1126],\n",
      "        [2.7632, 2.9291, 2.8301, 2.8711, 2.9032],\n",
      "        [2.7944, 2.9455, 2.8745, 2.9160, 2.9401],\n",
      "        [2.8542, 3.0773, 2.9142, 2.9125, 3.0278],\n",
      "        [2.8190, 2.8587, 2.9374, 2.9065, 2.9422],\n",
      "        [2.9963, 3.1164, 3.0911, 3.1198, 3.0732],\n",
      "        [2.9817, 3.0363, 3.0023, 3.0968, 3.1749],\n",
      "        [2.6645, 2.8449, 2.8032, 2.7658, 2.8365],\n",
      "        [3.1645, 3.2623, 3.1542, 3.2171, 3.3279],\n",
      "        [3.0979, 3.0201, 3.1022, 3.2326, 3.1210],\n",
      "        [2.8549, 2.9154, 2.9638, 2.9758, 3.0084],\n",
      "        [3.0010, 3.1457, 2.9975, 3.1202, 3.0992],\n",
      "        [2.8737, 2.8658, 2.9973, 2.9943, 3.0867],\n",
      "        [2.9502, 3.0363, 2.9295, 3.0158, 3.2004],\n",
      "        [2.7224, 2.8178, 2.8711, 2.8495, 2.8287],\n",
      "        [3.1754, 3.0593, 3.0959, 3.5691, 3.4724],\n",
      "        [2.7163, 2.9642, 2.9292, 2.8662, 2.8970],\n",
      "        [2.8984, 3.2644, 2.9828, 3.1820, 3.1723],\n",
      "        [2.7889, 2.8792, 2.9365, 2.9583, 2.9793],\n",
      "        [3.3943, 3.5998, 3.2015, 3.3046, 3.2038],\n",
      "        [3.1697, 3.1241, 3.1048, 3.1885, 3.1781],\n",
      "        [2.7410, 2.8965, 2.9326, 2.8961, 2.8698],\n",
      "        [2.7269, 2.9609, 2.9340, 2.8830, 2.9098],\n",
      "        [2.8653, 2.8799, 2.8738, 3.0315, 2.8937],\n",
      "        [2.8811, 2.9154, 3.0229, 3.0049, 3.0363],\n",
      "        [3.0481, 3.0915, 3.2130, 3.0402, 2.9767],\n",
      "        [2.7158, 2.9586, 2.9321, 2.8682, 2.8971],\n",
      "        [2.8619, 2.8864, 2.8811, 3.0263, 2.9054],\n",
      "        [2.9640, 3.0498, 3.0194, 3.1694, 3.0524],\n",
      "        [2.7004, 2.9665, 3.0254, 2.8677, 2.9772],\n",
      "        [2.7395, 2.9066, 2.8261, 2.8426, 2.8833],\n",
      "        [3.0935, 2.9859, 2.9920, 3.0405, 3.1085],\n",
      "        [2.8565, 2.9329, 2.9699, 2.9764, 3.0114],\n",
      "        [3.0379, 2.9371, 2.9838, 3.0000, 3.0348],\n",
      "        [2.8344, 2.9208, 2.8938, 2.8846, 2.9669],\n",
      "        [2.8833, 2.9059, 3.0198, 3.0155, 3.0444],\n",
      "        [2.7765, 2.8502, 2.7728, 2.9392, 2.8332],\n",
      "        [2.7590, 2.9436, 2.8925, 3.0136, 2.8733],\n",
      "        [3.2120, 3.2191, 3.1454, 3.2745, 3.2677],\n",
      "        [3.1720, 3.1005, 3.1455, 3.3058, 3.2329],\n",
      "        [2.7758, 2.7580, 2.9502, 2.7242, 2.9991],\n",
      "        [2.8271, 2.9305, 3.0388, 3.0487, 3.1407],\n",
      "        [2.9727, 3.1539, 3.0620, 3.1979, 3.0890],\n",
      "        [2.7229, 3.0206, 2.7857, 2.9409, 2.8466],\n",
      "        [2.8609, 2.9794, 2.8737, 3.0391, 2.9919],\n",
      "        [3.0125, 3.2445, 3.0584, 3.2058, 3.1947],\n",
      "        [3.1173, 3.1968, 3.0592, 3.1760, 3.2531],\n",
      "        [2.8492, 2.9850, 2.9499, 2.9528, 3.0047],\n",
      "        [3.0068, 3.0198, 3.0692, 3.1572, 2.9944],\n",
      "        [2.7604, 2.8201, 2.8719, 2.8827, 2.8670],\n",
      "        [2.9787, 3.0957, 3.1106, 3.0188, 2.9730],\n",
      "        [3.0114, 3.1338, 3.0024, 3.0332, 3.0793]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.1257, 3.1395, 3.1350, 3.2663, 3.1075],\n",
      "        [2.9884, 3.0078, 3.1064, 3.0145, 2.8790],\n",
      "        [3.0444, 2.9519, 2.9979, 3.0112, 3.0457],\n",
      "        [3.0158, 3.0573, 3.0906, 3.1328, 2.9631],\n",
      "        [2.8586, 2.8868, 3.0147, 2.9981, 3.0156],\n",
      "        [3.1084, 3.2003, 3.0531, 3.1608, 3.2678],\n",
      "        [2.8606, 2.8897, 2.9574, 2.9577, 2.9858],\n",
      "        [2.8549, 2.9220, 3.0429, 2.8621, 3.1407],\n",
      "        [2.8414, 2.9826, 2.9661, 3.0614, 2.9766],\n",
      "        [3.1458, 3.1957, 3.1020, 3.3218, 3.2483],\n",
      "        [2.8108, 2.9651, 2.8347, 2.9267, 2.9350],\n",
      "        [2.6456, 2.8498, 2.8555, 2.8209, 2.8868],\n",
      "        [2.8284, 2.8084, 2.9403, 2.9453, 2.9978],\n",
      "        [2.7545, 2.8516, 2.8983, 2.9005, 2.8855],\n",
      "        [2.8223, 2.9616, 2.8302, 2.9346, 2.9290],\n",
      "        [2.9755, 3.1959, 3.1072, 3.1433, 3.2290],\n",
      "        [2.7969, 2.9482, 2.8783, 2.9212, 2.9444],\n",
      "        [2.7391, 3.0099, 2.9593, 2.8992, 2.9492],\n",
      "        [2.8458, 2.9133, 3.0464, 2.8734, 3.1361],\n",
      "        [3.0518, 3.1792, 3.1540, 3.0983, 2.9904],\n",
      "        [2.7621, 2.8469, 2.9085, 2.8953, 2.8529],\n",
      "        [2.9928, 3.1621, 2.9806, 3.2118, 3.1395],\n",
      "        [2.9699, 3.0870, 2.9625, 3.0870, 3.1416],\n",
      "        [2.8298, 3.1888, 2.9862, 3.0825, 3.1474],\n",
      "        [2.9556, 2.9557, 3.0177, 2.9500, 2.9446],\n",
      "        [3.0092, 3.0228, 3.0733, 3.1628, 2.9987],\n",
      "        [2.9645, 3.2918, 3.1380, 3.1497, 3.2474],\n",
      "        [2.8566, 2.9944, 2.8437, 2.9813, 2.9739],\n",
      "        [2.8510, 2.8425, 2.9305, 2.9489, 3.0670],\n",
      "        [2.8565, 2.9000, 2.9560, 2.9588, 2.9874],\n",
      "        [2.8704, 2.9000, 2.9742, 2.9647, 2.9954],\n",
      "        [2.9893, 3.1280, 3.0907, 3.1188, 3.1042],\n",
      "        [2.7470, 2.8984, 2.9110, 2.8787, 2.9065],\n",
      "        [3.0449, 3.1813, 3.1829, 3.0901, 2.9456],\n",
      "        [2.8484, 2.8985, 2.9474, 2.9540, 2.9801],\n",
      "        [2.8364, 2.9834, 2.9569, 3.0593, 2.9596],\n",
      "        [2.8775, 2.8827, 2.8726, 3.0396, 2.9077],\n",
      "        [2.9848, 3.1617, 3.1054, 3.1354, 3.0837],\n",
      "        [2.8208, 2.8998, 3.0612, 2.8335, 3.1178],\n",
      "        [3.0731, 2.9711, 2.9872, 3.0353, 3.0879],\n",
      "        [3.0210, 3.0492, 3.2258, 3.0025, 3.0046],\n",
      "        [3.2838, 3.4067, 3.0067, 3.1670, 3.0741],\n",
      "        [2.7097, 2.8095, 2.8713, 2.8485, 2.8060],\n",
      "        [2.9724, 3.1386, 2.9563, 3.1784, 3.0984],\n",
      "        [2.9660, 2.9547, 3.0204, 3.0369, 3.0076],\n",
      "        [3.0494, 3.2101, 2.9584, 3.0384, 3.1078],\n",
      "        [2.8500, 2.9201, 3.0357, 2.8867, 3.1317],\n",
      "        [2.9579, 2.9323, 3.0126, 2.9336, 2.9974],\n",
      "        [2.9799, 2.9925, 2.9476, 3.1795, 3.1147],\n",
      "        [3.0073, 3.1269, 3.0994, 3.2202, 3.0702],\n",
      "        [3.0438, 2.8828, 2.8882, 2.9236, 3.0527],\n",
      "        [2.7789, 3.0329, 2.9430, 2.9564, 3.1218],\n",
      "        [2.6667, 2.8636, 2.8488, 2.8562, 2.8879],\n",
      "        [2.7152, 2.7524, 2.8347, 2.9097, 2.8509],\n",
      "        [2.6634, 2.8491, 2.8080, 2.7578, 2.8275],\n",
      "        [2.8355, 2.9848, 2.8415, 2.9527, 2.9569],\n",
      "        [2.8015, 3.1078, 2.9222, 2.8973, 2.8936],\n",
      "        [2.8582, 2.9354, 2.9743, 2.9905, 3.0109],\n",
      "        [2.7706, 2.8245, 2.8729, 2.8965, 2.8709],\n",
      "        [2.8576, 3.1207, 2.9831, 2.9714, 2.8979],\n",
      "        [2.7126, 3.0145, 2.8727, 2.7145, 2.9465],\n",
      "        [2.8002, 3.0580, 2.9519, 2.9879, 3.1065],\n",
      "        [2.7473, 2.9430, 2.8451, 2.8668, 2.9152],\n",
      "        [2.9030, 2.9275, 3.0394, 3.0105, 3.0449]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.7321, 2.7823, 2.8520, 2.8778, 2.8730],\n",
      "        [2.8787, 2.8721, 3.0047, 3.0043, 3.0946],\n",
      "        [2.8647, 2.9917, 3.1312, 3.0260, 3.1415],\n",
      "        [2.7933, 2.9707, 2.9194, 3.0523, 2.9070],\n",
      "        [3.0336, 3.0657, 3.1176, 3.1242, 3.0055],\n",
      "        [2.8201, 3.0714, 2.9353, 2.9433, 2.9403],\n",
      "        [2.5849, 2.7861, 2.8416, 2.7698, 2.8646],\n",
      "        [2.8323, 2.9368, 3.0464, 3.0586, 3.1488],\n",
      "        [2.9091, 2.9393, 3.0382, 3.0050, 3.0639],\n",
      "        [2.7977, 2.9201, 2.9309, 2.8784, 2.9287],\n",
      "        [2.8665, 2.9869, 2.8830, 2.9741, 3.0014],\n",
      "        [3.1409, 3.0763, 3.1450, 3.2916, 3.1762],\n",
      "        [3.1903, 3.3672, 3.1357, 3.1162, 3.1856],\n",
      "        [2.9331, 2.9959, 2.9814, 3.0988, 3.0343],\n",
      "        [2.8154, 3.2268, 3.0909, 2.9893, 3.0062],\n",
      "        [2.7338, 2.9163, 2.9271, 2.8882, 2.9064],\n",
      "        [2.8620, 2.9181, 2.9929, 2.9835, 3.0081],\n",
      "        [2.8203, 2.7953, 2.9343, 2.9400, 2.9943],\n",
      "        [2.9977, 3.0834, 3.0893, 3.0619, 3.1002],\n",
      "        [3.0108, 3.2824, 3.1680, 3.1693, 3.2576],\n",
      "        [2.8766, 3.0663, 2.8968, 3.1248, 2.9429],\n",
      "        [2.9424, 3.0120, 2.9847, 3.1279, 3.0343],\n",
      "        [3.1840, 3.0281, 3.1375, 3.5897, 3.5039],\n",
      "        [2.9771, 3.1340, 3.0904, 3.1192, 3.1293],\n",
      "        [2.7842, 2.8862, 2.9347, 2.9488, 2.8779],\n",
      "        [2.9957, 3.1181, 3.0957, 3.1285, 3.0762],\n",
      "        [2.8611, 2.8902, 3.0183, 3.0029, 3.0194],\n",
      "        [3.2781, 3.0596, 3.2131, 3.6735, 3.5795],\n",
      "        [2.8540, 2.9302, 2.9651, 2.9810, 2.9984],\n",
      "        [2.8764, 3.0095, 2.8409, 3.0108, 2.9784],\n",
      "        [3.0792, 3.1842, 3.0291, 3.1365, 3.2481],\n",
      "        [2.9605, 2.9358, 3.0163, 2.9384, 3.0012],\n",
      "        [2.9660, 2.9632, 3.0253, 2.9486, 2.9714],\n",
      "        [2.8064, 2.9381, 2.8588, 2.9545, 2.9504],\n",
      "        [2.8510, 2.9157, 2.9590, 2.9711, 2.9897],\n",
      "        [2.7223, 2.9672, 2.9372, 2.8761, 2.9051],\n",
      "        [2.8660, 3.0024, 2.8433, 2.9924, 2.9778],\n",
      "        [3.0807, 3.0988, 3.1183, 3.2099, 3.1512],\n",
      "        [3.2113, 3.2920, 3.1590, 3.4704, 3.3357],\n",
      "        [3.1224, 3.2032, 3.0672, 3.1865, 3.2613],\n",
      "        [2.7289, 2.9631, 2.9381, 2.8790, 2.9030],\n",
      "        [2.7882, 2.9226, 2.8391, 2.9424, 2.9070],\n",
      "        [3.3194, 3.5432, 3.0900, 3.2022, 3.1680],\n",
      "        [3.0770, 3.2968, 3.0873, 3.2461, 3.2917],\n",
      "        [2.8152, 2.7897, 2.8408, 2.9048, 2.8442],\n",
      "        [2.7958, 3.0318, 2.8408, 2.9915, 2.8849],\n",
      "        [2.9692, 2.9633, 3.0154, 3.0390, 3.0034],\n",
      "        [2.7125, 2.8959, 2.8348, 2.8151, 2.8785],\n",
      "        [2.7985, 2.9592, 2.8453, 2.8993, 2.9415],\n",
      "        [3.2860, 3.4101, 3.0104, 3.1720, 3.0779],\n",
      "        [2.9569, 3.0431, 2.9975, 3.1728, 3.0405],\n",
      "        [2.6692, 2.8668, 2.8523, 2.8609, 2.8917],\n",
      "        [2.8317, 2.8317, 2.9562, 2.9307, 2.9367],\n",
      "        [3.0493, 3.2024, 3.1800, 3.1099, 2.9666],\n",
      "        [3.2415, 3.0648, 3.2171, 3.6416, 3.5813],\n",
      "        [2.8590, 2.9034, 2.9596, 2.9636, 2.9912],\n",
      "        [3.0744, 2.9567, 3.0004, 3.3516, 3.2342],\n",
      "        [2.8528, 2.9533, 2.9108, 3.0304, 3.0041],\n",
      "        [3.1515, 3.2121, 3.0914, 3.2086, 3.2932],\n",
      "        [2.8813, 3.0156, 2.8493, 3.0176, 2.9875],\n",
      "        [2.8403, 2.9867, 2.8394, 2.9702, 2.9524],\n",
      "        [2.8597, 2.9082, 2.9588, 2.9615, 2.9879],\n",
      "        [2.8800, 2.8860, 2.8761, 3.0444, 2.9115],\n",
      "        [2.8798, 2.9343, 2.8579, 2.9591, 3.0807]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.7725, 2.9385, 3.0641, 2.9371, 3.0654],\n",
      "        [2.7764, 2.9344, 2.8137, 2.9566, 2.9172],\n",
      "        [2.9390, 3.0367, 3.0672, 3.0547, 3.0790],\n",
      "        [3.4277, 3.5950, 3.2165, 3.2913, 3.2111],\n",
      "        [3.0501, 3.1879, 3.1901, 3.1000, 2.9550],\n",
      "        [3.1885, 3.0031, 3.0433, 3.5127, 3.3756],\n",
      "        [2.7814, 2.8509, 2.7819, 2.9562, 2.8713],\n",
      "        [3.0083, 3.0592, 3.0140, 3.1328, 3.1943],\n",
      "        [3.0851, 3.1945, 3.0386, 3.1480, 3.2594],\n",
      "        [2.8181, 3.2300, 3.0944, 2.9945, 3.0118],\n",
      "        [2.9716, 2.9664, 3.0187, 3.0442, 3.0087],\n",
      "        [2.9838, 3.0918, 2.9515, 3.0418, 3.1998],\n",
      "        [3.0092, 3.1881, 3.0215, 3.1273, 3.1231],\n",
      "        [2.8219, 2.9173, 2.9283, 2.8958, 2.9580],\n",
      "        [2.9955, 3.1043, 3.1526, 3.1547, 3.2181],\n",
      "        [3.1070, 2.9975, 3.0050, 3.0603, 3.1154],\n",
      "        [3.0863, 2.9659, 2.9191, 3.0035, 3.0948],\n",
      "        [2.9782, 3.0418, 2.8864, 3.1195, 3.1482],\n",
      "        [2.7771, 2.8012, 2.8663, 2.9158, 2.8621],\n",
      "        [2.8890, 3.2007, 3.0973, 3.1057, 3.2129],\n",
      "        [3.0146, 2.9015, 2.8952, 2.9332, 3.0559],\n",
      "        [2.9388, 3.1360, 3.0141, 2.9841, 3.1164],\n",
      "        [2.7811, 2.8319, 2.8853, 2.9081, 2.8865],\n",
      "        [2.9582, 3.0458, 2.9406, 3.0310, 3.2138],\n",
      "        [2.9234, 2.9512, 3.0631, 3.0444, 3.0797],\n",
      "        [2.7982, 3.0347, 2.8440, 2.9964, 2.8903],\n",
      "        [2.8343, 2.9524, 2.9383, 2.9846, 3.0757],\n",
      "        [2.7603, 2.8315, 2.8819, 2.8967, 2.8772],\n",
      "        [3.0189, 2.8657, 2.8991, 2.9518, 3.0185],\n",
      "        [2.7344, 2.9801, 2.9019, 2.9196, 3.0741],\n",
      "        [2.7955, 2.9306, 2.8418, 2.9510, 2.9087],\n",
      "        [2.8744, 2.8162, 2.9157, 2.8556, 2.8841],\n",
      "        [2.7859, 2.8228, 2.8802, 2.9134, 2.8830],\n",
      "        [2.8696, 3.0053, 2.8417, 3.0111, 2.9828],\n",
      "        [2.8665, 2.9797, 2.9073, 3.0202, 3.0966],\n",
      "        [2.8984, 2.9478, 2.9929, 2.8932, 2.8441],\n",
      "        [2.7956, 2.8912, 2.9322, 2.9730, 2.8908],\n",
      "        [2.7991, 2.9044, 2.9307, 2.8475, 3.0561],\n",
      "        [2.7969, 2.8810, 2.9457, 2.9521, 2.9803],\n",
      "        [2.7886, 3.0469, 2.9518, 2.9732, 3.1422],\n",
      "        [3.0817, 3.1874, 3.0326, 3.1418, 3.2536],\n",
      "        [2.9694, 3.0525, 2.9580, 3.0491, 3.2175],\n",
      "        [2.7310, 2.9493, 2.9335, 2.8822, 2.9017],\n",
      "        [2.9270, 2.8890, 2.9851, 3.0084, 2.9766],\n",
      "        [2.9590, 3.2526, 3.1351, 3.1278, 3.2227],\n",
      "        [2.8534, 2.8543, 2.9278, 2.9516, 3.0727],\n",
      "        [2.9111, 2.9594, 2.9983, 2.9061, 2.8556],\n",
      "        [2.8652, 2.9096, 2.9659, 2.9659, 2.9943],\n",
      "        [2.8629, 2.9114, 2.9646, 2.9785, 2.9947],\n",
      "        [2.7847, 2.8636, 2.7803, 2.9578, 2.8361],\n",
      "        [2.8022, 2.9663, 2.8463, 2.9224, 2.9444],\n",
      "        [3.2689, 3.4046, 3.1318, 3.1760, 3.1415],\n",
      "        [2.9224, 2.8965, 2.9938, 3.0051, 3.0196],\n",
      "        [2.7725, 2.7916, 2.8576, 2.9037, 2.8590],\n",
      "        [2.8542, 2.9460, 3.0489, 2.9740, 3.1041],\n",
      "        [2.9008, 2.9313, 3.0336, 2.9989, 3.0510],\n",
      "        [2.6719, 2.8535, 2.8132, 2.7802, 2.8498],\n",
      "        [2.7294, 2.9997, 2.9563, 2.8885, 2.9297],\n",
      "        [3.1556, 3.1213, 3.0873, 3.3069, 3.2037],\n",
      "        [3.0005, 3.0569, 2.8848, 3.1310, 3.1707],\n",
      "        [2.8703, 3.0160, 2.9254, 3.0563, 3.0430],\n",
      "        [2.6800, 2.9892, 3.0541, 2.8581, 3.0112],\n",
      "        [2.8658, 2.8870, 2.9849, 2.9642, 2.9802],\n",
      "        [2.9984, 3.1536, 3.1016, 3.0648, 2.9729]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.0789, 3.2534, 3.1191, 3.0337, 3.1997],\n",
      "        [2.8852, 3.1399, 3.0129, 3.0182, 2.9234],\n",
      "        [2.7493, 2.9293, 2.8441, 2.8691, 2.9129],\n",
      "        [2.8542, 3.0142, 2.9341, 3.0353, 3.0559],\n",
      "        [3.0603, 2.8828, 2.8832, 2.9367, 3.0741],\n",
      "        [2.8881, 2.8846, 3.0210, 3.0224, 3.1100],\n",
      "        [2.8652, 2.9041, 2.9691, 2.9687, 2.9989],\n",
      "        [2.9985, 3.0087, 3.0497, 3.0013, 2.9679],\n",
      "        [3.1145, 3.1755, 3.2090, 3.1548, 3.0596],\n",
      "        [2.8702, 2.9068, 2.9066, 3.0334, 2.9347],\n",
      "        [3.0290, 3.0388, 3.1430, 3.0771, 2.9499],\n",
      "        [2.8960, 3.0373, 2.8493, 3.0452, 3.0087],\n",
      "        [2.7877, 2.8049, 2.8712, 2.9194, 2.8753],\n",
      "        [2.9009, 3.1193, 2.9919, 2.9956, 3.0909],\n",
      "        [2.9109, 3.2588, 3.0051, 3.2038, 3.1934],\n",
      "        [2.7858, 3.1079, 3.0666, 2.9791, 3.1580],\n",
      "        [3.0166, 3.1443, 3.0200, 3.0588, 3.0891],\n",
      "        [3.0130, 3.1819, 3.0286, 3.1477, 3.1319],\n",
      "        [2.9746, 3.1811, 3.1055, 3.1300, 3.2308],\n",
      "        [2.8348, 2.9110, 3.0984, 2.8304, 3.1579],\n",
      "        [2.8713, 2.8799, 2.9940, 2.9642, 2.9928],\n",
      "        [2.8611, 2.8550, 2.9420, 2.9693, 3.0836],\n",
      "        [2.8984, 3.0377, 2.8624, 3.0484, 3.0103],\n",
      "        [2.8688, 2.8899, 2.9811, 2.9705, 2.9878],\n",
      "        [2.7817, 2.8138, 2.8737, 2.9196, 2.8818],\n",
      "        [2.8364, 2.8375, 2.9624, 2.9402, 2.9473],\n",
      "        [2.6825, 2.9920, 3.0572, 2.8628, 3.0173],\n",
      "        [2.8202, 2.9700, 2.8844, 2.9504, 2.9858],\n",
      "        [2.9573, 2.9437, 3.0219, 2.9484, 2.9808],\n",
      "        [2.9054, 2.9440, 3.0492, 3.0463, 3.0667],\n",
      "        [3.0630, 3.1730, 3.0882, 3.1399, 3.2110],\n",
      "        [2.7878, 2.8998, 2.9595, 2.9864, 3.0020],\n",
      "        [3.0132, 3.0221, 3.1770, 3.0405, 2.9754],\n",
      "        [2.8683, 2.8845, 2.9839, 2.9768, 2.9811],\n",
      "        [3.0856, 3.1050, 3.1253, 3.2202, 3.1629],\n",
      "        [2.9708, 2.9691, 3.0318, 2.9586, 2.9824],\n",
      "        [2.9700, 3.0093, 3.0048, 3.0478, 3.0316],\n",
      "        [2.7626, 2.9425, 3.0052, 2.9418, 2.8979],\n",
      "        [3.0555, 2.8814, 3.0262, 3.2662, 3.3045],\n",
      "        [2.8252, 3.0774, 2.9419, 2.9528, 2.9518],\n",
      "        [2.8512, 2.8935, 2.9824, 2.9925, 3.0721],\n",
      "        [2.7611, 2.8922, 2.9151, 2.8957, 2.9199],\n",
      "        [2.9540, 3.3219, 3.0690, 3.2361, 3.2460],\n",
      "        [2.7495, 3.0136, 3.0995, 2.9490, 3.0535],\n",
      "        [2.9379, 3.1078, 2.9699, 3.0907, 3.0681],\n",
      "        [3.2002, 3.3409, 3.0143, 3.1393, 3.1238],\n",
      "        [2.9423, 3.0834, 2.9252, 3.0629, 3.0867],\n",
      "        [2.8403, 2.9666, 2.8893, 2.9114, 2.9464],\n",
      "        [2.8439, 2.9926, 2.9669, 3.0738, 2.9744],\n",
      "        [2.8800, 2.8722, 3.0010, 2.9878, 3.0745],\n",
      "        [2.9392, 2.9006, 3.2023, 3.0658, 3.1349],\n",
      "        [3.2087, 3.1854, 3.1510, 3.2584, 3.2548],\n",
      "        [2.9798, 3.1690, 3.0772, 3.2213, 3.1156],\n",
      "        [2.8189, 2.9663, 2.8389, 2.9315, 2.9388],\n",
      "        [2.9749, 3.2564, 3.0618, 3.1375, 3.1559],\n",
      "        [3.0070, 3.0033, 2.9666, 3.2446, 3.1676],\n",
      "        [2.7318, 3.0025, 2.9593, 2.8930, 2.9357],\n",
      "        [2.8586, 3.0090, 2.9798, 2.9318, 2.9139],\n",
      "        [2.8574, 2.8598, 2.9830, 2.9607, 2.9673],\n",
      "        [2.9339, 2.8855, 2.9706, 3.0169, 2.9618],\n",
      "        [2.8999, 3.0956, 2.9594, 3.0917, 3.0111],\n",
      "        [2.6702, 2.8739, 2.8634, 2.8554, 2.9085],\n",
      "        [2.8752, 2.8916, 2.8873, 3.0512, 2.9126],\n",
      "        [2.8112, 2.9298, 2.8669, 3.0131, 2.9585]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.9734, 2.9765, 3.0206, 3.0477, 3.0237],\n",
      "        [2.7889, 2.8223, 2.8790, 2.9260, 2.8897],\n",
      "        [3.0403, 3.3170, 3.1277, 3.3028, 3.3039],\n",
      "        [2.8089, 2.9553, 2.8440, 2.9247, 2.9376],\n",
      "        [3.0190, 3.1057, 3.0892, 3.0739, 3.1948],\n",
      "        [3.0698, 3.2309, 3.1632, 3.2266, 3.2623],\n",
      "        [2.7793, 2.8194, 2.8772, 2.9204, 2.8829],\n",
      "        [2.7489, 3.0215, 2.9719, 2.9190, 2.9709],\n",
      "        [2.7532, 2.9106, 2.9488, 2.9209, 2.8954],\n",
      "        [2.8754, 2.9368, 3.0003, 3.0048, 3.0253],\n",
      "        [3.0178, 3.1975, 2.9827, 3.0535, 3.1502],\n",
      "        [2.8669, 2.9168, 2.9681, 2.9770, 3.0045],\n",
      "        [3.1580, 3.0315, 3.1383, 3.2408, 3.1939],\n",
      "        [2.8697, 3.1493, 2.9236, 3.1302, 3.0842],\n",
      "        [3.0050, 3.1723, 2.9668, 3.0658, 3.1455],\n",
      "        [3.2093, 3.3102, 3.2142, 3.4506, 3.3335],\n",
      "        [2.9833, 3.2014, 3.1189, 3.1537, 3.2513],\n",
      "        [2.7907, 2.9613, 2.8534, 2.9159, 2.9492],\n",
      "        [2.8712, 2.8925, 2.9840, 2.9762, 2.9935],\n",
      "        [2.8645, 2.9581, 2.8975, 3.0027, 2.9671],\n",
      "        [3.0008, 3.0113, 3.0527, 3.0072, 2.9738],\n",
      "        [2.9945, 3.0596, 2.8974, 3.1304, 3.1642],\n",
      "        [2.7881, 3.1211, 2.9823, 2.8234, 3.1081],\n",
      "        [2.8922, 3.0345, 2.8549, 3.0415, 3.0064],\n",
      "        [2.9729, 3.1579, 2.9741, 3.0820, 3.1044],\n",
      "        [3.1306, 2.9903, 3.0256, 3.4224, 3.2928],\n",
      "        [2.7914, 2.8945, 2.9438, 2.9639, 2.8951],\n",
      "        [2.7222, 2.9836, 2.9491, 2.8914, 2.9242],\n",
      "        [2.8944, 3.0326, 2.8502, 3.0419, 3.0048],\n",
      "        [2.8621, 2.9603, 2.9034, 2.9237, 2.9819],\n",
      "        [2.9763, 2.9720, 3.0248, 3.0548, 3.0203],\n",
      "        [2.8647, 3.0225, 2.9862, 2.9462, 2.9208],\n",
      "        [3.0614, 3.1002, 3.1048, 3.1919, 3.0733],\n",
      "        [2.8872, 3.0925, 2.9609, 2.9944, 3.0911],\n",
      "        [3.0236, 3.0789, 3.0641, 3.0783, 3.2093],\n",
      "        [2.9884, 3.1053, 3.1238, 3.0387, 2.9953],\n",
      "        [3.0198, 3.1302, 3.1176, 3.2378, 3.0894],\n",
      "        [3.0010, 3.1721, 2.9934, 3.2318, 3.1582],\n",
      "        [3.0236, 3.1485, 3.0195, 3.0589, 3.1045],\n",
      "        [2.9345, 2.9643, 3.0842, 3.0524, 3.0917],\n",
      "        [3.0187, 2.9068, 2.9011, 2.9442, 3.0670],\n",
      "        [2.8485, 2.9785, 2.8753, 2.9988, 2.9620],\n",
      "        [3.0899, 3.2001, 3.0450, 3.1587, 3.2715],\n",
      "        [2.8003, 2.8965, 2.9381, 2.9832, 2.9026],\n",
      "        [2.7381, 2.9092, 2.8466, 2.8526, 2.9011],\n",
      "        [3.0941, 3.1128, 3.1216, 3.2556, 3.1590],\n",
      "        [2.8456, 2.9745, 2.9521, 3.0141, 3.0735],\n",
      "        [2.7518, 3.0162, 3.1024, 2.9548, 3.0592],\n",
      "        [3.0540, 3.1698, 2.9948, 3.1051, 3.2110],\n",
      "        [3.0622, 3.2814, 3.0997, 3.2710, 3.2462],\n",
      "        [3.0154, 3.1846, 3.0316, 3.1535, 3.1379],\n",
      "        [3.0233, 2.8758, 2.9072, 2.9693, 3.0311],\n",
      "        [2.9492, 3.0447, 2.9254, 3.0641, 3.0540],\n",
      "        [2.8960, 3.1077, 2.9748, 3.1450, 3.0282],\n",
      "        [3.1951, 3.0553, 3.1530, 3.6058, 3.5219],\n",
      "        [2.8211, 2.9006, 2.9308, 2.9930, 2.9163],\n",
      "        [2.8354, 2.9012, 2.9225, 3.0070, 2.9238],\n",
      "        [3.0957, 3.2468, 2.9825, 3.0792, 3.1287],\n",
      "        [2.8630, 2.8722, 3.0011, 2.8997, 3.0490],\n",
      "        [3.0125, 3.1714, 2.9768, 3.0721, 3.1612],\n",
      "        [3.0558, 3.2432, 3.0929, 3.0230, 3.1780],\n",
      "        [3.1600, 3.1142, 3.1263, 3.1936, 3.2030],\n",
      "        [3.3898, 3.5441, 3.2363, 3.3042, 3.2668],\n",
      "        [2.8331, 3.1337, 2.9802, 2.9676, 2.9204]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.9733, 3.1902, 3.1210, 3.1365, 3.0953],\n",
      "        [3.1580, 3.2109, 3.1197, 3.3494, 3.2762],\n",
      "        [2.7973, 3.1466, 3.0448, 3.0283, 3.1697],\n",
      "        [3.0838, 2.9854, 3.0030, 3.0628, 3.1135],\n",
      "        [2.7318, 2.9427, 3.0791, 2.8893, 3.0877],\n",
      "        [2.7774, 2.9454, 2.8490, 2.9006, 2.9337],\n",
      "        [2.7938, 2.8159, 2.8788, 2.9220, 2.8987],\n",
      "        [2.7412, 2.9053, 2.9234, 2.8960, 2.9069],\n",
      "        [3.0204, 3.2144, 3.1198, 3.1529, 3.1345],\n",
      "        [2.9890, 2.9987, 3.0489, 3.1636, 2.9878],\n",
      "        [2.8637, 3.1048, 3.0166, 2.9381, 3.0978],\n",
      "        [2.8420, 3.1349, 3.0620, 2.9332, 3.0879],\n",
      "        [3.2713, 3.4200, 3.1475, 3.1878, 3.1845],\n",
      "        [2.8693, 3.0960, 2.9985, 2.9466, 3.0911],\n",
      "        [2.7737, 2.9604, 2.9120, 3.0434, 2.9029],\n",
      "        [2.7737, 2.9604, 2.9120, 3.0434, 2.9029],\n",
      "        [2.8087, 3.1760, 2.9950, 3.0511, 3.1654],\n",
      "        [2.9363, 2.9684, 3.0936, 3.0695, 3.0962],\n",
      "        [2.8487, 2.9685, 2.8928, 3.0126, 2.9758],\n",
      "        [2.8922, 2.8908, 3.0265, 3.0363, 3.1235],\n",
      "        [3.1827, 3.1419, 3.1246, 3.2234, 3.2091],\n",
      "        [2.8445, 2.9365, 2.9283, 2.9233, 2.9835],\n",
      "        [2.9839, 3.0673, 2.9725, 3.0585, 3.0489],\n",
      "        [2.8670, 3.0635, 2.9065, 3.1151, 2.9592],\n",
      "        [2.8748, 2.9117, 2.9122, 3.0441, 2.9458],\n",
      "        [3.0211, 3.1082, 3.0920, 3.0795, 3.2002],\n",
      "        [3.1715, 3.1586, 3.0877, 3.2083, 3.2217],\n",
      "        [2.9626, 3.1895, 3.1159, 3.1392, 3.0834],\n",
      "        [2.8912, 3.0043, 3.1402, 3.0649, 3.1666],\n",
      "        [3.1691, 3.0323, 3.1453, 3.5920, 3.5214],\n",
      "        [2.9841, 2.9700, 3.0084, 2.9614, 2.8965],\n",
      "        [2.9947, 3.0603, 3.1375, 3.0647, 3.0319],\n",
      "        [2.7553, 2.9345, 2.8489, 2.8747, 2.9219],\n",
      "        [2.9058, 3.0434, 2.8706, 3.0579, 3.0259],\n",
      "        [2.8276, 2.9412, 2.7759, 3.0317, 2.8667],\n",
      "        [2.9009, 3.1059, 2.9836, 3.0128, 3.0947],\n",
      "        [2.9476, 3.1829, 3.0957, 3.1079, 3.0726],\n",
      "        [2.9252, 2.9568, 3.0782, 3.0542, 3.0844],\n",
      "        [2.8855, 2.9212, 3.0326, 3.0239, 3.0402],\n",
      "        [3.1877, 3.1464, 3.2157, 3.3703, 3.2584],\n",
      "        [2.9771, 2.9566, 3.0409, 2.9512, 3.0465],\n",
      "        [2.9195, 3.0905, 2.9378, 3.0887, 3.0566],\n",
      "        [2.7938, 2.8858, 2.7925, 2.9705, 2.8981],\n",
      "        [2.8705, 2.8663, 2.9590, 2.9226, 2.9512],\n",
      "        [2.8924, 2.8427, 2.9469, 2.8839, 2.9207],\n",
      "        [2.7123, 2.9004, 2.8397, 2.8315, 2.8942],\n",
      "        [2.8610, 2.9541, 3.0576, 2.9903, 3.1211],\n",
      "        [2.8688, 2.9543, 2.9082, 3.0496, 2.9940],\n",
      "        [2.8886, 2.9148, 2.9974, 2.9665, 3.0536],\n",
      "        [3.0948, 2.8965, 3.0475, 3.3251, 3.3449],\n",
      "        [2.8724, 2.9674, 2.9782, 2.9759, 3.1768],\n",
      "        [2.7786, 2.8850, 2.8168, 2.9653, 2.8443],\n",
      "        [2.8906, 2.9392, 3.0217, 3.0320, 3.0455],\n",
      "        [2.7902, 2.7749, 2.9689, 2.7545, 3.0290],\n",
      "        [2.9589, 3.0076, 2.9491, 3.1202, 3.0795],\n",
      "        [2.9489, 2.9147, 3.2114, 3.0794, 3.1566],\n",
      "        [2.9989, 3.1649, 2.9581, 3.0633, 3.1432],\n",
      "        [3.0637, 3.1028, 3.1078, 3.1973, 3.0788],\n",
      "        [2.8776, 2.9392, 3.0030, 3.0101, 3.0306],\n",
      "        [2.9349, 3.0241, 3.0120, 3.0248, 3.0545],\n",
      "        [3.0904, 3.2425, 3.2289, 3.1908, 3.0485],\n",
      "        [3.0153, 3.0858, 2.9155, 3.1557, 3.1797],\n",
      "        [2.8483, 2.9874, 2.8491, 2.9791, 2.9831],\n",
      "        [2.8558, 2.8986, 2.9881, 3.0035, 3.0831]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.8967, 3.0397, 2.8603, 3.0519, 3.0164],\n",
      "        [2.9776, 2.9772, 3.0403, 2.9753, 2.9983],\n",
      "        [2.9259, 2.9675, 2.9893, 3.0636, 3.0511],\n",
      "        [2.9588, 3.1726, 3.1487, 3.1317, 3.0824],\n",
      "        [2.8464, 2.9531, 2.7720, 3.0493, 2.8581],\n",
      "        [2.9493, 3.0915, 2.9340, 3.0793, 3.1032],\n",
      "        [2.7969, 2.8964, 2.9621, 3.0014, 3.0241],\n",
      "        [2.8620, 3.1721, 3.0652, 3.0852, 3.2062],\n",
      "        [2.9097, 3.0852, 2.9204, 2.9673, 3.0648],\n",
      "        [3.1443, 3.1610, 3.1749, 3.3156, 3.2421],\n",
      "        [2.9855, 3.1502, 3.1069, 3.1512, 3.1566],\n",
      "        [2.8965, 3.0285, 2.8544, 3.0448, 3.0058],\n",
      "        [2.8776, 3.0158, 2.8580, 3.0179, 3.0048],\n",
      "        [2.8495, 3.0013, 2.8596, 2.9827, 2.9878],\n",
      "        [2.9089, 3.1150, 2.9812, 3.0180, 3.1069],\n",
      "        [2.8813, 3.2141, 3.0865, 3.0454, 3.0099],\n",
      "        [3.0102, 2.9788, 3.0671, 3.1107, 3.0617],\n",
      "        [3.0298, 3.0750, 3.1096, 3.1653, 2.9943],\n",
      "        [3.2650, 3.4017, 3.0365, 3.1928, 3.1209],\n",
      "        [3.1868, 3.3369, 3.2014, 3.4771, 3.3717],\n",
      "        [3.2118, 3.1243, 3.1957, 3.3778, 3.2645],\n",
      "        [2.7435, 2.9081, 2.9260, 2.9012, 2.9117],\n",
      "        [2.8000, 2.9884, 2.9450, 3.0827, 2.9494],\n",
      "        [2.8761, 2.8562, 2.9547, 2.9145, 2.9417],\n",
      "        [2.8006, 3.1269, 3.0172, 3.0275, 3.1417],\n",
      "        [2.7059, 2.8897, 2.7447, 2.9229, 2.8471],\n",
      "        [2.9052, 3.0455, 2.8708, 3.0644, 3.0261],\n",
      "        [3.0173, 3.0705, 3.0255, 3.1556, 3.2165],\n",
      "        [2.7760, 2.9633, 2.9147, 3.0487, 2.9076],\n",
      "        [2.8711, 2.9108, 2.9768, 2.9870, 3.0139],\n",
      "        [2.7145, 2.9032, 2.8422, 2.8366, 2.8990],\n",
      "        [2.8624, 2.8734, 2.9620, 2.9350, 2.9644],\n",
      "        [2.7724, 2.8840, 2.9344, 2.9305, 2.8940],\n",
      "        [2.8165, 3.1252, 2.9410, 2.9274, 2.9254],\n",
      "        [3.0862, 2.9709, 3.0156, 3.3777, 3.2609],\n",
      "        [2.8905, 3.1331, 3.0092, 3.0199, 2.9370],\n",
      "        [2.8517, 3.0000, 2.8540, 2.9955, 2.9793],\n",
      "        [2.8794, 2.9410, 2.9978, 2.8943, 2.8376],\n",
      "        [2.8231, 2.9835, 2.9593, 3.0735, 2.9590],\n",
      "        [2.7341, 2.9655, 2.9439, 2.9001, 2.9256],\n",
      "        [2.8999, 2.9472, 3.0787, 3.1730, 3.2537],\n",
      "        [3.1916, 3.1403, 3.1779, 3.2523, 3.2556],\n",
      "        [3.0866, 3.1899, 3.0298, 3.1307, 3.2603],\n",
      "        [2.7740, 2.9402, 2.9977, 2.9656, 2.9079],\n",
      "        [3.1515, 3.2016, 3.0938, 3.2434, 3.3123],\n",
      "        [2.8660, 2.9442, 2.9800, 3.0077, 3.0252],\n",
      "        [2.8256, 2.9740, 2.8470, 2.9472, 2.9546],\n",
      "        [2.7559, 2.9256, 2.8473, 2.8771, 2.9185],\n",
      "        [2.8754, 3.0113, 2.8553, 3.0123, 3.0047],\n",
      "        [2.9218, 3.0934, 2.9406, 3.0941, 3.0615],\n",
      "        [2.8778, 2.8673, 2.9934, 3.0019, 3.1010],\n",
      "        [2.8511, 2.9714, 2.8954, 3.0178, 2.9808],\n",
      "        [3.0348, 3.1700, 3.0133, 3.1900, 3.2148],\n",
      "        [3.0074, 3.1317, 2.9940, 3.1554, 3.1217],\n",
      "        [2.9951, 3.1386, 3.0872, 3.2228, 3.1010],\n",
      "        [2.8455, 3.1856, 3.0105, 3.0886, 3.1927],\n",
      "        [2.8728, 2.9041, 3.0329, 3.0289, 3.0459],\n",
      "        [2.9121, 2.9437, 3.0646, 3.0660, 3.0844],\n",
      "        [2.8711, 2.8607, 2.9686, 2.9962, 3.0973],\n",
      "        [2.8811, 2.9464, 2.9873, 3.0180, 3.0467],\n",
      "        [2.7855, 2.9447, 2.8249, 2.9764, 2.9391],\n",
      "        [2.8281, 3.2413, 3.1066, 3.0156, 3.0350],\n",
      "        [2.9904, 2.9863, 3.0272, 2.9260, 2.9044],\n",
      "        [3.2541, 3.0798, 3.2332, 3.6690, 3.6090]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.9801, 3.1666, 2.9824, 3.0975, 3.1191],\n",
      "        [2.8452, 2.9092, 2.9296, 3.0282, 2.9460],\n",
      "        [2.7956, 3.0535, 2.9641, 2.9931, 3.1569],\n",
      "        [3.1171, 3.0533, 3.1330, 3.2444, 3.1551],\n",
      "        [3.0254, 3.0354, 3.1962, 3.0658, 3.0040],\n",
      "        [2.8770, 2.9738, 2.9835, 2.9869, 3.1860],\n",
      "        [2.7489, 2.8451, 2.8953, 2.8924, 2.8881],\n",
      "        [2.9850, 3.1310, 3.0807, 3.0954, 2.9959],\n",
      "        [3.0119, 3.1009, 3.1072, 3.0939, 3.1325],\n",
      "        [2.8814, 2.9084, 3.0449, 3.0392, 3.0408],\n",
      "        [2.7426, 3.0019, 2.9619, 2.9150, 2.9536],\n",
      "        [2.8457, 3.1434, 2.9972, 2.9963, 2.9384],\n",
      "        [2.9121, 3.0886, 2.9230, 2.9723, 3.0692],\n",
      "        [2.9093, 3.2777, 3.0518, 3.2043, 3.2226],\n",
      "        [2.9720, 2.9765, 3.0388, 2.9865, 2.9795],\n",
      "        [3.0482, 3.0836, 3.1361, 3.1563, 3.0378],\n",
      "        [2.9402, 3.0614, 2.9364, 3.0681, 3.1381],\n",
      "        [2.9720, 3.0268, 3.1187, 3.1334, 3.0672],\n",
      "        [2.8078, 2.9667, 2.8577, 2.9409, 2.9716],\n",
      "        [2.7412, 2.9279, 2.8513, 2.8642, 2.9209],\n",
      "        [3.0346, 3.0706, 3.2408, 3.0416, 3.0351],\n",
      "        [3.0017, 3.1831, 3.1281, 3.1728, 3.1211],\n",
      "        [2.8180, 2.9579, 3.0272, 2.9709, 3.0481],\n",
      "        [2.8811, 2.9094, 2.9054, 3.0670, 2.9446],\n",
      "        [2.8717, 3.0698, 2.9117, 3.1251, 2.9686],\n",
      "        [3.0125, 2.9824, 3.0697, 3.1157, 3.0661],\n",
      "        [3.0115, 3.1366, 3.0037, 3.1601, 3.1344],\n",
      "        [3.0249, 2.9958, 3.0882, 3.1451, 3.0896],\n",
      "        [2.7685, 2.9633, 2.8833, 2.9907, 2.9395],\n",
      "        [2.9692, 3.1330, 3.0600, 3.0703, 2.9825],\n",
      "        [2.8684, 3.1112, 3.0218, 2.9488, 3.1072],\n",
      "        [3.1843, 3.2254, 3.1071, 3.2537, 3.3452],\n",
      "        [2.9741, 2.9526, 3.0397, 2.9613, 3.0443],\n",
      "        [3.0356, 2.9026, 3.0429, 3.2418, 3.3022],\n",
      "        [3.0453, 3.1775, 3.0157, 3.1970, 3.2352],\n",
      "        [2.8289, 2.9869, 2.8614, 2.9461, 2.9804],\n",
      "        [3.0865, 3.0435, 3.0400, 3.1198, 3.1631],\n",
      "        [3.0472, 3.2184, 2.9887, 3.0817, 3.1540],\n",
      "        [2.7352, 2.9159, 2.8519, 2.8609, 2.9314],\n",
      "        [3.1988, 3.0464, 3.1562, 3.6216, 3.5353],\n",
      "        [2.7042, 2.8947, 2.7425, 2.9100, 2.8512],\n",
      "        [2.9199, 3.0847, 2.9014, 2.9809, 3.0570],\n",
      "        [2.9425, 3.1064, 2.9591, 3.1054, 3.0788],\n",
      "        [3.0461, 3.1597, 3.1182, 3.0777, 3.1594],\n",
      "        [3.0604, 2.9746, 3.0094, 3.3174, 3.2147],\n",
      "        [3.0912, 3.3170, 3.1060, 3.2774, 3.3296],\n",
      "        [3.0236, 3.2175, 3.1281, 3.1655, 3.1462],\n",
      "        [2.9311, 3.2190, 3.0752, 3.1272, 3.2382],\n",
      "        [2.7495, 2.8820, 2.9163, 2.9064, 2.9088],\n",
      "        [2.7954, 3.0063, 2.9162, 2.9599, 3.0132],\n",
      "        [2.7788, 2.9607, 2.8567, 2.9102, 2.9517],\n",
      "        [2.9187, 3.2887, 3.0087, 3.2234, 3.2132],\n",
      "        [2.9705, 2.8566, 3.1157, 3.0834, 3.0866],\n",
      "        [3.1535, 3.1703, 3.1760, 3.3079, 3.2550],\n",
      "        [2.9720, 3.0957, 2.9651, 3.0994, 3.1713],\n",
      "        [2.8651, 2.9192, 2.9682, 2.9900, 3.0146],\n",
      "        [2.7813, 2.9781, 3.0374, 3.0146, 3.1073],\n",
      "        [3.0353, 3.1362, 3.1364, 3.2596, 3.1045],\n",
      "        [3.0064, 3.0622, 3.0208, 3.1540, 3.2125],\n",
      "        [3.1098, 3.0453, 3.1144, 3.2371, 3.1633],\n",
      "        [3.2880, 3.4214, 3.0398, 3.2058, 3.1177],\n",
      "        [2.8912, 2.8415, 2.9416, 2.8825, 2.9203],\n",
      "        [2.8540, 3.1297, 3.0535, 2.9320, 3.1144],\n",
      "        [2.8785, 2.8596, 2.9573, 2.9193, 2.9460]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.9573, 3.0606, 2.9535, 3.0996, 3.0991],\n",
      "        [2.9059, 2.9539, 3.0838, 3.1832, 3.2620],\n",
      "        [2.9007, 2.9404, 3.0326, 3.0415, 3.0499],\n",
      "        [2.8719, 3.1143, 3.0243, 2.9542, 3.1112],\n",
      "        [2.8772, 3.1041, 2.9417, 2.9599, 3.0721],\n",
      "        [2.7457, 2.9906, 3.0492, 2.9373, 3.0427],\n",
      "        [2.8672, 2.9451, 2.9842, 3.0190, 3.0378],\n",
      "        [2.9661, 3.0543, 3.0885, 3.0977, 3.0760],\n",
      "        [2.8392, 2.9144, 3.0886, 2.8540, 3.1656],\n",
      "        [2.8800, 3.0152, 2.9470, 2.9884, 3.0313],\n",
      "        [3.1647, 3.0682, 3.0432, 3.1625, 3.1854],\n",
      "        [2.9748, 3.2708, 3.1525, 3.1597, 3.2541],\n",
      "        [3.0184, 3.0264, 3.0806, 3.1972, 3.0304],\n",
      "        [2.7908, 2.9176, 2.9807, 3.0297, 3.0433],\n",
      "        [2.8641, 2.8671, 3.0107, 2.8867, 3.0731],\n",
      "        [2.8751, 3.0730, 2.9140, 3.1301, 2.9726],\n",
      "        [3.1261, 3.0653, 3.1557, 3.3012, 3.1873],\n",
      "        [2.7803, 2.9543, 2.8565, 2.9088, 2.9423],\n",
      "        [2.8922, 2.8895, 2.8860, 3.0828, 2.9270],\n",
      "        [3.0628, 2.9756, 3.0213, 3.0549, 3.0841],\n",
      "        [2.7697, 2.8850, 2.9193, 2.9240, 2.9301],\n",
      "        [2.9147, 3.1215, 2.9863, 3.0285, 3.1152],\n",
      "        [2.7386, 2.9190, 2.8542, 2.8658, 2.9354],\n",
      "        [2.8999, 3.1704, 2.9503, 2.8670, 3.0752],\n",
      "        [2.9649, 3.1793, 3.1539, 3.1418, 3.0910],\n",
      "        [2.9353, 3.2025, 3.0616, 3.1273, 3.2377],\n",
      "        [3.4419, 3.6132, 3.2343, 3.3248, 3.2435],\n",
      "        [2.9235, 3.0878, 2.9039, 2.9861, 3.0610],\n",
      "        [2.7781, 2.8905, 2.9392, 2.9402, 2.9025],\n",
      "        [3.0496, 3.1628, 3.1208, 3.0830, 3.1635],\n",
      "        [3.1920, 3.2896, 3.2086, 3.4339, 3.2875],\n",
      "        [2.9741, 2.8296, 3.1293, 3.0763, 3.0631],\n",
      "        [2.9348, 3.1891, 3.0000, 3.1987, 3.1368],\n",
      "        [2.8630, 3.1225, 3.0391, 2.9442, 3.1127],\n",
      "        [2.9044, 2.9376, 3.0253, 3.0184, 3.0707],\n",
      "        [2.8575, 3.0065, 2.8590, 3.0053, 2.9876],\n",
      "        [3.1205, 3.0565, 3.1357, 3.2497, 3.1594],\n",
      "        [2.9700, 2.9585, 3.0355, 2.9754, 3.0050],\n",
      "        [2.7241, 2.9095, 2.8446, 2.8478, 2.9061],\n",
      "        [3.0515, 3.3292, 3.1390, 3.3244, 3.3233],\n",
      "        [2.9224, 3.2919, 3.0113, 3.2287, 3.2173],\n",
      "        [3.1084, 3.1288, 3.1379, 3.2884, 3.1876],\n",
      "        [3.2295, 3.0714, 3.1929, 3.6594, 3.5689],\n",
      "        [3.0320, 3.1566, 3.1061, 3.0560, 3.1523],\n",
      "        [3.0010, 3.1452, 3.0924, 3.2334, 3.1095],\n",
      "        [2.7990, 2.9443, 2.8549, 2.9746, 2.9306],\n",
      "        [2.9222, 3.2093, 3.1400, 3.1564, 3.2235],\n",
      "        [2.8579, 2.9709, 2.9611, 3.0091, 3.1282],\n",
      "        [3.1569, 3.2182, 3.0889, 3.2290, 3.3210],\n",
      "        [2.8171, 2.8659, 2.9193, 2.9599, 2.9117],\n",
      "        [2.5859, 2.8008, 2.8584, 2.7872, 2.8728],\n",
      "        [3.1663, 3.2208, 3.1283, 3.3660, 3.2905],\n",
      "        [3.0275, 3.0408, 3.1499, 3.0802, 2.9443],\n",
      "        [3.0823, 3.2396, 3.2246, 3.2102, 3.0933],\n",
      "        [2.8555, 3.0142, 2.9459, 3.0704, 3.0778],\n",
      "        [2.7004, 2.8905, 2.8416, 2.8171, 2.8964],\n",
      "        [2.7175, 2.8205, 2.8497, 2.8423, 2.8793],\n",
      "        [2.8205, 3.0818, 2.9755, 3.0296, 3.1458],\n",
      "        [2.8690, 2.9638, 3.0651, 3.0067, 3.1342],\n",
      "        [2.7938, 3.0475, 2.9683, 2.9942, 3.1570],\n",
      "        [3.0874, 3.1430, 3.1959, 3.3034, 3.1259],\n",
      "        [2.8486, 2.8919, 2.9703, 2.9561, 2.9921],\n",
      "        [2.7793, 2.9548, 2.8574, 2.9137, 2.9448],\n",
      "        [2.8525, 2.9457, 2.9358, 2.9384, 2.9966]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.9547, 3.0195, 3.0037, 3.1420, 3.0740],\n",
      "        [2.7981, 3.1228, 3.0773, 3.0088, 3.1820],\n",
      "        [2.8198, 3.0169, 2.9080, 3.0152, 2.9341],\n",
      "        [3.0146, 3.1251, 3.1725, 3.1934, 3.2532],\n",
      "        [3.0923, 3.3140, 3.0965, 3.2819, 3.3192],\n",
      "        [3.1199, 3.1301, 3.1376, 3.2892, 3.2034],\n",
      "        [3.0172, 3.1894, 3.0077, 3.2605, 3.1843],\n",
      "        [2.9574, 3.0342, 3.0196, 3.0886, 3.1432],\n",
      "        [3.0293, 2.9264, 2.9095, 2.9643, 3.0930],\n",
      "        [2.8307, 2.9214, 2.9553, 3.0066, 2.9408],\n",
      "        [2.8926, 3.0215, 3.0169, 3.0153, 2.9397],\n",
      "        [2.8860, 3.0153, 3.1539, 3.0693, 3.1809],\n",
      "        [2.9613, 3.0324, 3.0184, 3.0613, 3.0651],\n",
      "        [2.9498, 3.0124, 2.9999, 3.1346, 3.0666],\n",
      "        [2.7538, 2.8559, 2.8669, 2.8921, 2.9078],\n",
      "        [2.8015, 2.7872, 2.9784, 2.7761, 3.0454],\n",
      "        [2.8802, 2.9519, 2.9903, 3.0279, 3.0486],\n",
      "        [2.8528, 3.0626, 3.0027, 2.9219, 2.9701],\n",
      "        [2.8051, 2.8980, 2.8020, 2.9910, 2.9148],\n",
      "        [2.8989, 2.9370, 3.0410, 3.0491, 3.0671],\n",
      "        [2.8889, 2.9127, 3.0085, 3.0123, 3.0273],\n",
      "        [3.0324, 3.0749, 3.0848, 3.0697, 2.9649],\n",
      "        [2.9766, 2.9709, 3.0415, 2.9906, 3.0029],\n",
      "        [2.9479, 2.9811, 3.1036, 3.0915, 3.1128],\n",
      "        [2.8660, 3.1559, 2.9547, 2.8536, 3.1094],\n",
      "        [3.0542, 3.2284, 2.9952, 3.0940, 3.1631],\n",
      "        [3.4457, 3.6403, 3.2166, 3.3381, 3.2840],\n",
      "        [3.0295, 2.8788, 2.9132, 2.9981, 3.0430],\n",
      "        [2.7653, 2.9034, 3.0320, 2.9373, 3.0461],\n",
      "        [3.0205, 3.1289, 3.1217, 3.1802, 3.0871],\n",
      "        [3.0317, 3.1154, 3.1209, 3.1790, 3.0582],\n",
      "        [2.9371, 3.1413, 3.0206, 3.0372, 3.1232],\n",
      "        [3.0253, 3.1557, 3.0396, 3.0461, 3.1100],\n",
      "        [2.7431, 2.9748, 2.9509, 2.9157, 2.9378],\n",
      "        [2.7154, 2.8363, 2.8476, 2.8451, 2.8786],\n",
      "        [2.9450, 2.9013, 2.9958, 3.0397, 2.9950],\n",
      "        [2.7785, 2.8512, 2.9000, 2.9333, 2.9101],\n",
      "        [3.0755, 3.1155, 3.1185, 3.2199, 3.0962],\n",
      "        [3.1098, 3.1758, 3.1134, 3.3030, 3.1818],\n",
      "        [2.8305, 2.8495, 2.9147, 2.9608, 2.9107],\n",
      "        [2.7388, 2.7782, 2.8597, 2.9557, 2.8930],\n",
      "        [2.7792, 2.9208, 2.9567, 2.9445, 2.9253],\n",
      "        [2.9325, 3.1751, 3.0365, 3.1194, 3.2314],\n",
      "        [2.7617, 2.9545, 2.9796, 2.9452, 2.9513],\n",
      "        [2.9658, 3.3146, 3.0734, 3.2595, 3.2562],\n",
      "        [2.8519, 2.8547, 2.9774, 2.9719, 2.9738],\n",
      "        [3.0156, 3.1861, 3.0020, 3.2512, 3.1731],\n",
      "        [2.8594, 2.8422, 2.9774, 2.9979, 3.0492],\n",
      "        [2.8539, 2.9604, 3.0687, 3.1011, 3.1880],\n",
      "        [2.8685, 3.1715, 3.0327, 3.1121, 3.1993],\n",
      "        [2.8618, 3.0041, 2.9881, 3.1060, 3.0002],\n",
      "        [3.0888, 3.1323, 3.0884, 3.1371, 3.1982],\n",
      "        [2.7843, 2.9975, 2.9030, 2.9477, 3.0094],\n",
      "        [2.8524, 3.0307, 2.9173, 3.0427, 3.0868],\n",
      "        [2.7981, 2.9144, 2.8382, 3.0016, 2.9366],\n",
      "        [2.9059, 3.0490, 2.8676, 3.0679, 3.0282],\n",
      "        [2.9144, 3.0548, 2.8782, 3.0805, 3.0379],\n",
      "        [3.0868, 3.2929, 3.0903, 3.0257, 3.1583],\n",
      "        [2.9782, 3.2738, 3.1549, 3.1662, 3.2578],\n",
      "        [2.8955, 2.8923, 2.8882, 3.0889, 2.9305],\n",
      "        [2.9848, 3.1927, 3.1175, 3.1662, 3.2339],\n",
      "        [2.9953, 2.9821, 3.0183, 2.9830, 2.9129],\n",
      "        [2.9368, 2.9695, 3.0882, 3.0762, 3.1009],\n",
      "        [3.0203, 3.1469, 3.1149, 3.2547, 3.1118]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.1470, 2.8914, 3.0445, 3.4215, 3.4069],\n",
      "        [2.8080, 2.9618, 2.8595, 2.9385, 2.9557],\n",
      "        [2.7390, 2.8844, 2.7920, 2.9450, 2.8576],\n",
      "        [3.1654, 3.1193, 3.0910, 3.1789, 3.2196],\n",
      "        [2.8810, 3.0270, 2.8713, 3.0327, 3.0165],\n",
      "        [3.2259, 3.1888, 3.1401, 3.2753, 3.2676],\n",
      "        [2.7745, 2.9321, 2.9656, 2.9578, 2.9278],\n",
      "        [3.0758, 3.2396, 2.9880, 3.0917, 3.1543],\n",
      "        [2.8453, 3.0975, 2.9614, 2.9906, 2.9845],\n",
      "        [3.0713, 3.1875, 3.0117, 3.1383, 3.2376],\n",
      "        [2.9449, 3.0971, 2.9423, 3.0977, 3.0924],\n",
      "        [2.9932, 2.9897, 3.0407, 3.0881, 3.0456],\n",
      "        [2.9580, 3.0223, 3.0069, 3.1478, 3.0773],\n",
      "        [3.1035, 3.2107, 3.0560, 3.1859, 3.2924],\n",
      "        [3.0510, 3.0785, 3.1193, 3.2002, 2.9906],\n",
      "        [2.8229, 2.9766, 2.9063, 2.9723, 2.9907],\n",
      "        [2.8833, 2.9294, 2.9847, 3.0120, 3.0326],\n",
      "        [2.7691, 2.8835, 2.8793, 2.9199, 2.9288],\n",
      "        [3.2857, 3.4287, 3.0625, 3.2328, 3.1559],\n",
      "        [2.9176, 3.0575, 2.8814, 3.0860, 3.0412],\n",
      "        [2.8510, 3.1602, 3.0983, 2.9468, 3.1399],\n",
      "        [2.8797, 2.8896, 3.0122, 2.9284, 3.0755],\n",
      "        [2.9606, 3.0369, 3.0227, 3.0945, 3.1466],\n",
      "        [2.8025, 2.8543, 2.9066, 2.9504, 2.9226],\n",
      "        [2.9922, 3.0760, 2.9809, 3.0929, 3.2551],\n",
      "        [3.1353, 3.1743, 3.1507, 3.3183, 3.1859],\n",
      "        [2.9952, 3.1398, 3.0889, 3.1131, 3.0070],\n",
      "        [2.8085, 2.9117, 2.9592, 2.9957, 2.9207],\n",
      "        [3.0095, 3.0755, 3.1510, 3.0924, 3.0521],\n",
      "        [2.8755, 2.9695, 3.0705, 3.0191, 3.1411],\n",
      "        [2.8234, 2.9885, 2.8677, 2.9637, 2.9813],\n",
      "        [2.8837, 2.9695, 2.9212, 3.0762, 3.0146],\n",
      "        [3.0055, 3.3237, 3.1545, 3.2145, 3.3233],\n",
      "        [3.0160, 2.9967, 3.0733, 3.1280, 3.0843],\n",
      "        [2.9243, 3.0664, 2.8761, 3.0949, 3.0453],\n",
      "        [3.0206, 3.1769, 3.0149, 3.1062, 3.1413],\n",
      "        [2.8192, 2.9402, 2.8688, 2.9885, 2.9410],\n",
      "        [3.1159, 2.9858, 3.0310, 3.4342, 3.2968],\n",
      "        [2.7519, 2.9248, 2.9344, 2.9179, 2.9274],\n",
      "        [2.9891, 3.0297, 3.0236, 3.0871, 3.0627],\n",
      "        [3.1978, 3.2537, 3.1625, 3.4138, 3.3198],\n",
      "        [3.2764, 3.4136, 3.0473, 3.2152, 3.1365],\n",
      "        [3.0206, 3.1921, 3.0110, 3.2663, 3.1877],\n",
      "        [3.0218, 3.1450, 3.0118, 3.1770, 3.1454],\n",
      "        [2.8473, 3.1218, 3.0787, 2.9787, 3.2614],\n",
      "        [2.9091, 3.0517, 2.8708, 3.0734, 3.0314],\n",
      "        [2.7803, 3.0430, 3.1337, 3.0115, 3.0911],\n",
      "        [2.9035, 2.9300, 3.0103, 2.9941, 3.0737],\n",
      "        [2.8438, 2.9640, 2.7940, 3.0587, 2.8910],\n",
      "        [2.9302, 3.0933, 2.9096, 2.9980, 3.0681],\n",
      "        [2.9243, 3.0664, 2.8761, 3.0949, 3.0453],\n",
      "        [2.9851, 3.2644, 3.0682, 3.1660, 3.1756],\n",
      "        [2.8140, 2.9839, 3.0467, 3.0574, 3.1476],\n",
      "        [2.9676, 3.0250, 3.0165, 3.0709, 3.0484],\n",
      "        [2.8262, 2.9833, 2.8703, 2.9523, 2.9926],\n",
      "        [2.9769, 3.0536, 3.0139, 3.2050, 3.0783],\n",
      "        [3.2365, 3.0772, 3.1988, 3.6722, 3.5758],\n",
      "        [2.9555, 3.2031, 3.1344, 3.1069, 3.1869],\n",
      "        [2.9739, 3.1144, 2.9479, 3.1119, 3.1451],\n",
      "        [2.8909, 3.2677, 3.1089, 3.0361, 3.0770],\n",
      "        [2.7502, 2.9431, 2.8648, 2.9354, 2.9263],\n",
      "        [2.9067, 2.9060, 3.0395, 3.0641, 3.1431],\n",
      "        [2.8067, 2.8244, 2.8894, 2.9571, 2.9053],\n",
      "        [2.6925, 2.8752, 2.8336, 2.8202, 2.8867]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.9914, 3.0452, 3.1341, 3.1507, 3.0951],\n",
      "        [2.9773, 3.3454, 3.0924, 3.2820, 3.2816],\n",
      "        [3.0429, 3.0153, 3.0245, 3.3615, 3.2506],\n",
      "        [3.1865, 3.2363, 3.1128, 3.2634, 3.3524],\n",
      "        [2.8058, 2.8814, 2.8031, 2.9978, 2.8650],\n",
      "        [3.0675, 2.9716, 3.0196, 3.0677, 3.0870],\n",
      "        [2.8903, 3.0959, 2.9324, 3.1658, 2.9874],\n",
      "        [3.0234, 3.1947, 3.0142, 3.2723, 3.1908],\n",
      "        [3.1900, 3.1510, 3.1485, 3.2446, 3.2252],\n",
      "        [2.8616, 2.9222, 2.9953, 3.0356, 3.1089],\n",
      "        [2.8789, 2.9468, 2.9880, 3.0272, 3.0361],\n",
      "        [2.7824, 3.0002, 2.8457, 2.9947, 2.9472],\n",
      "        [2.8487, 2.9961, 2.8643, 2.9867, 2.9959],\n",
      "        [3.0319, 3.0836, 3.0811, 3.0865, 2.9486],\n",
      "        [3.0505, 3.1107, 3.1037, 3.1698, 3.2590],\n",
      "        [2.8535, 2.9539, 2.9559, 2.9576, 3.0017],\n",
      "        [2.7584, 2.9224, 2.9389, 2.9280, 2.9300],\n",
      "        [2.8957, 3.0184, 2.9052, 3.0244, 3.0490],\n",
      "        [2.8780, 2.9304, 2.9791, 3.0131, 3.0282],\n",
      "        [2.8870, 3.0743, 2.9576, 3.0598, 3.1116],\n",
      "        [2.8770, 2.8807, 3.0012, 3.0019, 3.0045],\n",
      "        [2.8972, 2.9138, 2.9085, 3.0946, 2.9464],\n",
      "        [2.9139, 3.0527, 2.8707, 3.0945, 3.0380],\n",
      "        [2.9357, 2.9682, 3.0663, 3.0597, 3.1087],\n",
      "        [2.6119, 2.8136, 2.8688, 2.8213, 2.9099],\n",
      "        [3.1403, 3.3256, 3.1104, 3.0975, 3.1401],\n",
      "        [2.9979, 3.1128, 3.1783, 3.1795, 3.2088],\n",
      "        [3.0828, 2.9845, 3.0122, 3.0753, 3.1153],\n",
      "        [2.8741, 3.1502, 3.0100, 3.0240, 2.9450],\n",
      "        [3.0146, 3.1944, 3.1399, 3.1962, 3.1361],\n",
      "        [2.8371, 3.1047, 2.9954, 3.0434, 3.1895],\n",
      "        [2.8059, 2.8205, 2.8831, 2.9607, 2.9097],\n",
      "        [2.8310, 3.1861, 3.0151, 3.0738, 3.2028],\n",
      "        [2.8590, 3.1674, 3.0763, 3.0971, 3.1863],\n",
      "        [2.9476, 2.9165, 3.0061, 3.0515, 3.0355],\n",
      "        [2.7969, 2.9636, 3.0893, 2.9858, 3.1048],\n",
      "        [2.8913, 2.8708, 2.9681, 2.9423, 2.9596],\n",
      "        [2.8851, 2.9350, 2.9877, 3.0197, 3.0368],\n",
      "        [2.9140, 3.2219, 3.1096, 3.1050, 3.0556],\n",
      "        [3.0752, 3.2138, 3.2161, 3.1493, 2.9958],\n",
      "        [3.3256, 3.4436, 3.0607, 3.2430, 3.1254],\n",
      "        [3.0218, 3.0858, 3.0699, 3.0769, 2.9140],\n",
      "        [2.6708, 2.8709, 2.8835, 2.8722, 2.9207],\n",
      "        [2.7705, 2.9397, 2.8601, 2.9034, 2.9366],\n",
      "        [2.7574, 3.0194, 2.9762, 2.9465, 2.9777],\n",
      "        [2.8600, 3.2209, 3.0193, 3.1422, 3.1970],\n",
      "        [2.7919, 3.0390, 3.1420, 2.9997, 3.1167],\n",
      "        [2.8706, 2.8776, 3.0187, 2.9030, 3.0825],\n",
      "        [3.0213, 3.1539, 3.1427, 3.1684, 3.1975],\n",
      "        [2.7986, 2.8493, 2.9048, 2.9524, 2.9160],\n",
      "        [2.8663, 2.9861, 2.9088, 3.0448, 2.9995],\n",
      "        [2.8465, 2.8079, 2.8588, 2.9577, 2.8917],\n",
      "        [3.0914, 3.1985, 3.0367, 3.1592, 3.2764],\n",
      "        [3.0082, 3.1255, 3.1433, 3.0775, 3.0239],\n",
      "        [2.8469, 2.8404, 2.9085, 2.9879, 2.9152],\n",
      "        [3.0114, 3.0919, 2.9354, 3.1561, 3.1785],\n",
      "        [2.8842, 3.0842, 2.9634, 3.0455, 3.1027],\n",
      "        [3.0009, 2.9859, 3.0252, 2.9929, 2.9185],\n",
      "        [2.7308, 3.0026, 3.0636, 2.9388, 3.0390],\n",
      "        [2.7603, 3.0326, 2.9835, 2.9531, 2.9900],\n",
      "        [2.8203, 2.9776, 2.8682, 2.9629, 2.9854],\n",
      "        [2.7811, 2.9743, 2.8939, 3.0127, 2.9536],\n",
      "        [2.8083, 2.9347, 2.8722, 2.9776, 2.9388],\n",
      "        [2.8863, 2.9571, 2.9966, 3.0396, 3.0548]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.9691, 3.0716, 2.9649, 3.1228, 3.1117],\n",
      "        [2.6145, 2.8166, 2.8715, 2.8263, 2.9126],\n",
      "        [2.7741, 3.0390, 3.1244, 2.9985, 3.0899],\n",
      "        [3.0936, 3.2512, 3.1885, 3.2747, 3.3004],\n",
      "        [2.8136, 2.9257, 2.9848, 3.0363, 3.0395],\n",
      "        [2.9550, 2.9202, 3.2222, 3.0998, 3.1577],\n",
      "        [2.8207, 3.0172, 2.8979, 3.0715, 2.9638],\n",
      "        [2.8839, 3.0794, 2.9555, 3.0579, 3.1075],\n",
      "        [2.7826, 3.1721, 3.0541, 3.0112, 3.2012],\n",
      "        [2.8536, 2.9952, 2.8640, 2.9963, 2.9804],\n",
      "        [2.7817, 2.9606, 2.8719, 2.9179, 2.9623],\n",
      "        [2.9117, 3.1811, 2.9618, 2.8899, 3.0877],\n",
      "        [2.9730, 3.2281, 3.1354, 3.1683, 3.3186],\n",
      "        [2.8033, 2.9289, 2.9924, 3.0529, 3.0561],\n",
      "        [2.9118, 3.0422, 3.0975, 3.0865, 3.1236],\n",
      "        [3.0546, 3.0651, 3.1689, 3.1278, 2.9871],\n",
      "        [2.8187, 3.1444, 3.0347, 3.0610, 3.1627],\n",
      "        [3.1404, 3.2359, 3.0899, 3.2268, 3.3221],\n",
      "        [3.2752, 3.0617, 3.1588, 3.6106, 3.5687],\n",
      "        [3.1556, 3.1463, 3.0792, 3.1955, 3.1855],\n",
      "        [3.2545, 3.0361, 3.1368, 3.6116, 3.5486],\n",
      "        [2.9217, 2.8786, 2.9800, 2.9397, 2.9630],\n",
      "        [2.9012, 3.1011, 2.9714, 3.0428, 3.1167],\n",
      "        [2.9165, 3.0557, 2.8735, 3.0997, 3.0407],\n",
      "        [3.2233, 3.3664, 3.0398, 3.1897, 3.1616],\n",
      "        [3.1040, 2.9888, 3.0323, 3.4118, 3.2814],\n",
      "        [2.8622, 3.1556, 3.0813, 2.9731, 3.1142],\n",
      "        [2.8791, 3.2417, 3.1354, 3.0984, 3.0753],\n",
      "        [3.4589, 3.6588, 3.2298, 3.3641, 3.3018],\n",
      "        [3.0804, 3.1412, 3.1703, 3.1609, 3.2443],\n",
      "        [3.0244, 3.0888, 3.0727, 3.0823, 2.9166],\n",
      "        [2.9307, 2.9634, 3.0819, 3.0958, 3.1087],\n",
      "        [2.8169, 3.1879, 3.0165, 3.0658, 3.2034],\n",
      "        [3.0349, 3.0888, 3.0418, 3.1911, 3.2379],\n",
      "        [3.0485, 3.2828, 3.0989, 3.2761, 3.2527],\n",
      "        [2.9581, 3.1206, 2.9735, 3.1337, 3.0957],\n",
      "        [2.8363, 3.1370, 2.9771, 2.9780, 2.9322],\n",
      "        [2.9752, 2.9818, 3.0207, 2.9655, 2.8975],\n",
      "        [2.7491, 2.9343, 2.8628, 2.8877, 2.9350],\n",
      "        [2.8845, 2.9369, 2.9885, 3.0307, 3.0431],\n",
      "        [2.9383, 3.1466, 3.0091, 3.0467, 3.1296],\n",
      "        [3.0111, 3.3295, 3.1606, 3.2262, 3.3293],\n",
      "        [2.7120, 2.8982, 2.8517, 2.8398, 2.9051],\n",
      "        [2.8646, 3.1454, 3.0801, 2.9499, 3.1292],\n",
      "        [2.9144, 3.0572, 2.8766, 3.0844, 3.0370],\n",
      "        [2.8925, 2.9154, 3.0120, 3.0180, 3.0214],\n",
      "        [2.8081, 2.8374, 2.8947, 2.9674, 2.9133],\n",
      "        [2.7572, 2.9302, 2.9399, 2.9285, 2.9331],\n",
      "        [2.7646, 2.8960, 2.9295, 2.9336, 2.9253],\n",
      "        [2.8796, 2.8838, 3.0039, 3.0073, 3.0071],\n",
      "        [3.1612, 3.1989, 3.1705, 3.3693, 3.2198],\n",
      "        [2.9165, 3.0557, 2.8735, 3.0997, 3.0407],\n",
      "        [2.8930, 2.9680, 3.0909, 3.1598, 3.2432],\n",
      "        [2.7404, 2.8247, 2.8908, 2.8855, 2.8540],\n",
      "        [3.0534, 3.1910, 3.0064, 3.1231, 3.2099],\n",
      "        [2.8563, 2.9804, 2.9049, 2.9517, 2.9747],\n",
      "        [2.7654, 2.9095, 2.9348, 2.9344, 2.9302],\n",
      "        [2.9083, 3.0472, 2.8774, 3.0710, 3.0347],\n",
      "        [2.7723, 2.9028, 2.9353, 2.9378, 2.9321],\n",
      "        [2.7515, 2.9829, 2.9594, 2.9318, 2.9469],\n",
      "        [3.0563, 3.0841, 3.1253, 3.2116, 2.9964],\n",
      "        [2.9255, 2.9294, 3.0719, 3.1004, 3.1642],\n",
      "        [2.8927, 3.0340, 2.8692, 3.0595, 3.0158],\n",
      "        [2.8790, 3.0395, 2.9590, 3.0847, 3.0928]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.0345, 3.2020, 3.1628, 3.1408, 3.0507],\n",
      "        [3.0489, 2.8958, 2.9285, 3.0129, 3.0615],\n",
      "        [3.4589, 3.6270, 3.2494, 3.3545, 3.2597],\n",
      "        [3.0801, 3.2005, 3.0271, 3.1433, 3.2408],\n",
      "        [3.0568, 3.1533, 3.1539, 3.2943, 3.1240],\n",
      "        [2.7394, 2.9300, 2.8665, 2.8788, 2.9288],\n",
      "        [2.9405, 3.2018, 3.0009, 3.2212, 3.1489],\n",
      "        [3.1972, 3.2391, 3.1282, 3.3012, 3.3598],\n",
      "        [2.9439, 3.1637, 3.0330, 3.1283, 3.2257],\n",
      "        [2.9152, 2.9195, 2.9089, 3.1074, 2.9611],\n",
      "        [2.8002, 2.8593, 2.9118, 2.9553, 2.9242],\n",
      "        [3.0458, 3.2720, 3.0683, 3.0079, 3.1723],\n",
      "        [2.9128, 2.9379, 3.0172, 3.0345, 3.0489],\n",
      "        [3.2167, 3.1733, 3.2405, 3.4173, 3.2911],\n",
      "        [2.9108, 3.0419, 3.0275, 3.0308, 2.9573],\n",
      "        [2.9012, 2.9080, 3.0206, 3.0181, 3.0307],\n",
      "        [2.7623, 3.0594, 2.8242, 3.0101, 2.9056],\n",
      "        [2.9068, 3.0321, 3.0286, 3.0370, 2.9510],\n",
      "        [2.9930, 3.2849, 3.1671, 3.1885, 3.2698],\n",
      "        [2.9563, 2.9829, 3.0935, 3.1045, 3.1243],\n",
      "        [3.1805, 3.2470, 3.1481, 3.4172, 3.3209],\n",
      "        [2.8363, 2.9802, 2.8676, 2.9711, 2.9708],\n",
      "        [2.8991, 2.9552, 3.0121, 2.9249, 2.8578],\n",
      "        [2.8015, 2.8172, 2.8847, 2.9584, 2.8998],\n",
      "        [2.7617, 2.9442, 2.8667, 2.8953, 2.9398],\n",
      "        [2.7597, 2.9503, 2.9490, 2.9336, 2.9386],\n",
      "        [2.7749, 2.9472, 2.8712, 2.9139, 2.9648],\n",
      "        [2.7588, 2.9473, 2.9464, 2.9354, 2.9389],\n",
      "        [2.9397, 2.9275, 3.1121, 3.1383, 3.0667],\n",
      "        [3.2250, 3.4021, 3.1715, 3.1836, 3.2384],\n",
      "        [2.7247, 2.9138, 2.8567, 2.8529, 2.9114],\n",
      "        [3.0997, 3.2041, 3.0426, 3.1695, 3.2818],\n",
      "        [2.8491, 2.9659, 2.8960, 3.0541, 3.0047],\n",
      "        [2.9325, 3.1350, 3.0007, 3.0567, 3.1304],\n",
      "        [2.8198, 3.0810, 2.8658, 3.0176, 2.9235],\n",
      "        [2.9103, 2.9053, 3.0368, 3.0652, 3.1403],\n",
      "        [2.7371, 2.9228, 2.8599, 2.8721, 2.9223],\n",
      "        [2.9784, 3.0462, 3.1059, 3.1347, 3.1023],\n",
      "        [2.9882, 2.9691, 3.0495, 2.9990, 3.0340],\n",
      "        [3.0533, 3.0954, 3.1293, 3.2044, 3.0180],\n",
      "        [2.9744, 3.1496, 3.0683, 3.0981, 2.9961],\n",
      "        [2.8988, 2.9706, 3.0936, 3.1648, 3.2456],\n",
      "        [3.1384, 3.1444, 3.0246, 3.2104, 3.2620],\n",
      "        [2.8350, 3.1991, 3.0182, 3.0952, 3.1938],\n",
      "        [2.7343, 3.0033, 2.7719, 2.9784, 2.8572],\n",
      "        [2.7189, 2.9167, 2.8871, 2.9297, 2.9552],\n",
      "        [3.0471, 3.2547, 3.2237, 3.2224, 3.0867],\n",
      "        [3.1285, 3.1382, 3.1473, 3.3098, 3.2077],\n",
      "        [2.8665, 2.9056, 2.9845, 2.9841, 3.0071],\n",
      "        [2.8552, 2.9086, 2.9803, 2.9924, 3.0121],\n",
      "        [3.2211, 3.0640, 3.1736, 3.6574, 3.5543],\n",
      "        [2.7922, 3.0033, 3.0648, 2.9865, 3.0841],\n",
      "        [3.1752, 3.1110, 3.1821, 3.3588, 3.2302],\n",
      "        [2.8737, 2.9800, 3.0887, 3.1369, 3.2084],\n",
      "        [2.9338, 2.9751, 3.0055, 3.0677, 3.0748],\n",
      "        [2.8890, 2.9229, 2.9919, 3.0210, 3.0300],\n",
      "        [2.9757, 3.0431, 3.0302, 3.0833, 3.0765],\n",
      "        [2.8896, 2.9595, 2.9994, 3.0445, 3.0468],\n",
      "        [2.9577, 3.2982, 3.0191, 3.2593, 3.2212],\n",
      "        [3.0674, 3.1765, 3.1353, 3.1114, 3.1790],\n",
      "        [2.8982, 2.9179, 3.0146, 3.0228, 3.0238],\n",
      "        [3.0186, 3.0107, 3.0470, 2.9832, 2.9287],\n",
      "        [2.8986, 3.0313, 2.8741, 3.0493, 3.0278],\n",
      "        [3.0464, 3.1933, 2.9924, 3.1200, 3.1900]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.9612, 3.0114, 3.0096, 3.1350, 3.0782],\n",
      "        [2.9071, 3.0429, 2.8803, 3.0703, 3.0276],\n",
      "        [2.7669, 2.9486, 2.8691, 2.9000, 2.9421],\n",
      "        [2.9109, 2.9238, 2.9164, 3.1093, 2.9536],\n",
      "        [2.9078, 2.9015, 3.0296, 3.0591, 3.1328],\n",
      "        [2.9027, 2.9289, 3.0084, 3.0513, 3.1068],\n",
      "        [2.7687, 2.9841, 2.9652, 2.9436, 2.9499],\n",
      "        [2.8577, 2.9955, 3.0614, 3.1094, 3.1920],\n",
      "        [2.8627, 2.9331, 3.1048, 2.8883, 3.1831],\n",
      "        [3.2162, 3.1525, 3.2016, 3.4422, 3.3413],\n",
      "        [2.8076, 2.9677, 2.8725, 2.9457, 2.9609],\n",
      "        [3.0162, 3.2023, 3.1087, 3.2828, 3.1581],\n",
      "        [2.8249, 2.9241, 2.9700, 3.0160, 2.9313],\n",
      "        [3.5080, 3.6741, 3.3055, 3.4346, 3.3026],\n",
      "        [2.9670, 2.8438, 3.1219, 3.1221, 3.1405],\n",
      "        [2.7950, 2.8805, 2.9223, 2.9505, 2.9303],\n",
      "        [2.9042, 2.9751, 3.0962, 3.1700, 3.2479],\n",
      "        [2.7948, 2.9843, 2.9017, 3.0273, 2.9611],\n",
      "        [2.9232, 2.8702, 2.9707, 2.9324, 2.9504],\n",
      "        [3.0455, 3.1972, 2.9872, 3.1197, 3.1821],\n",
      "        [2.8900, 3.0465, 2.9644, 3.0945, 3.0975],\n",
      "        [3.0457, 3.1131, 2.9410, 3.2043, 3.2113],\n",
      "        [2.8682, 3.0661, 2.9208, 3.1330, 2.9819],\n",
      "        [2.7723, 3.0049, 2.9763, 2.9594, 2.9721],\n",
      "        [2.8060, 2.9924, 2.8918, 3.0252, 2.9652],\n",
      "        [2.9450, 2.9751, 3.0775, 3.0741, 3.1043],\n",
      "        [2.7932, 2.8998, 2.9333, 2.9539, 2.9474],\n",
      "        [2.8840, 3.0255, 2.8791, 3.0424, 3.0176],\n",
      "        [2.9015, 3.0325, 2.8801, 3.0391, 3.0329],\n",
      "        [3.2024, 3.2434, 3.1310, 3.3064, 3.3622],\n",
      "        [3.0187, 3.1737, 3.1282, 3.1907, 3.1836],\n",
      "        [2.8038, 3.0122, 2.9172, 2.9740, 3.0229],\n",
      "        [2.7914, 2.9040, 2.9553, 2.9668, 2.9159],\n",
      "        [3.0407, 3.1813, 3.1313, 3.1295, 3.0094],\n",
      "        [2.9837, 3.0506, 3.1085, 3.1398, 3.1046],\n",
      "        [2.9448, 3.0080, 3.0706, 3.0902, 3.1750],\n",
      "        [3.0543, 3.2233, 3.0614, 3.1975, 3.1789],\n",
      "        [2.9254, 3.0642, 2.8819, 3.0941, 3.0417],\n",
      "        [3.1063, 3.3080, 3.1053, 3.0530, 3.1724],\n",
      "        [3.0043, 3.1966, 3.1335, 3.1937, 3.2309],\n",
      "        [2.9027, 2.9247, 3.0075, 3.0370, 3.0293],\n",
      "        [3.0549, 2.9517, 2.9346, 3.0042, 3.1148],\n",
      "        [3.1659, 3.1095, 3.0693, 3.1742, 3.2239],\n",
      "        [2.7697, 2.9669, 2.9605, 2.9537, 2.9614],\n",
      "        [2.9389, 3.1097, 2.9427, 3.0104, 3.0910],\n",
      "        [2.9228, 3.0491, 3.1031, 3.0965, 3.1284],\n",
      "        [2.8380, 2.9861, 2.8665, 2.9740, 2.9736],\n",
      "        [2.9793, 3.2034, 3.0749, 3.0724, 3.1579],\n",
      "        [3.0377, 3.2053, 3.0227, 3.2880, 3.1985],\n",
      "        [3.4254, 3.6109, 3.2352, 3.3594, 3.2442],\n",
      "        [2.9963, 3.0847, 3.0881, 3.1037, 3.1284],\n",
      "        [3.0543, 2.9001, 2.9310, 3.0180, 3.0636],\n",
      "        [2.7434, 2.9216, 2.7622, 2.9497, 2.8750],\n",
      "        [2.9334, 3.1117, 2.9607, 3.0087, 3.0980],\n",
      "        [3.1800, 3.2929, 3.1864, 3.2836, 3.3599],\n",
      "        [2.8864, 3.0112, 2.9106, 3.0310, 3.0377],\n",
      "        [2.8345, 3.1870, 2.9990, 3.0955, 3.1657],\n",
      "        [3.0458, 3.0936, 3.0892, 3.1020, 2.9560],\n",
      "        [2.8027, 2.9720, 2.8723, 2.9399, 2.9595],\n",
      "        [2.9165, 3.0474, 2.8771, 3.0784, 3.0307],\n",
      "        [2.8415, 2.9846, 2.8701, 2.9759, 2.9731],\n",
      "        [2.9483, 3.2917, 3.0367, 3.2642, 3.2366],\n",
      "        [3.0394, 3.0041, 3.0887, 3.1553, 3.0873],\n",
      "        [3.0752, 3.2006, 3.1352, 3.1045, 3.1848]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.0553, 3.2128, 3.1258, 3.2314, 3.1665],\n",
      "        [2.8837, 2.8613, 2.9935, 3.0301, 3.0653],\n",
      "        [2.9074, 2.9822, 3.1006, 3.1787, 3.2509],\n",
      "        [2.8152, 2.8400, 2.8984, 2.9775, 2.9135],\n",
      "        [2.9043, 3.0397, 2.8830, 3.0385, 3.0287],\n",
      "        [2.9729, 3.0008, 3.1202, 3.1248, 3.1294],\n",
      "        [3.3270, 3.1052, 3.2554, 3.7541, 3.6361],\n",
      "        [2.8793, 3.1622, 3.0914, 2.9881, 3.1194],\n",
      "        [2.8974, 2.9370, 2.9972, 3.0455, 3.0455],\n",
      "        [2.9850, 3.1583, 3.0736, 3.1087, 3.0015],\n",
      "        [2.8646, 3.2156, 3.0983, 3.1227, 3.2419],\n",
      "        [2.9064, 2.8971, 2.9957, 3.0495, 3.1311],\n",
      "        [3.0220, 3.1857, 3.0006, 3.2592, 3.1599],\n",
      "        [2.8980, 2.8877, 2.9724, 3.0295, 3.1254],\n",
      "        [3.0578, 3.1978, 3.0030, 3.1341, 3.2032],\n",
      "        [3.0180, 3.1332, 3.0073, 3.1671, 3.2029],\n",
      "        [2.8862, 2.9928, 2.9806, 3.0477, 3.1484],\n",
      "        [3.0877, 3.3011, 3.1176, 3.3213, 3.2691],\n",
      "        [3.1203, 3.0000, 3.0403, 3.4278, 3.2890],\n",
      "        [3.0557, 3.0636, 3.1743, 3.1232, 2.9466],\n",
      "        [3.0343, 3.0415, 3.0843, 3.0659, 3.0001],\n",
      "        [2.8671, 3.0101, 2.8746, 3.0064, 3.0062],\n",
      "        [2.8094, 2.9767, 2.8744, 2.9565, 2.9699],\n",
      "        [3.0929, 3.3078, 3.1129, 3.3137, 3.2791],\n",
      "        [2.9658, 2.9901, 3.1051, 3.1259, 3.1280],\n",
      "        [2.9655, 2.9364, 3.0290, 3.0752, 3.0690],\n",
      "        [3.0968, 3.2561, 3.0021, 3.1183, 3.1678],\n",
      "        [3.2591, 3.0948, 3.2132, 3.7015, 3.5893],\n",
      "        [2.9662, 2.9353, 3.0228, 3.0864, 3.0600],\n",
      "        [3.1181, 3.0687, 3.0612, 3.1655, 3.1869],\n",
      "        [2.8478, 3.0077, 2.9703, 3.1168, 2.9773],\n",
      "        [2.7472, 2.9311, 2.8647, 2.8818, 2.9275],\n",
      "        [2.8979, 3.0272, 2.8696, 3.0486, 3.0035],\n",
      "        [2.9271, 3.1770, 3.0467, 3.0834, 2.9697],\n",
      "        [3.5129, 3.6781, 3.3082, 3.4403, 3.3058],\n",
      "        [3.0080, 3.3185, 3.1435, 3.2226, 3.3539],\n",
      "        [2.9151, 3.0006, 3.0760, 3.0736, 3.1583],\n",
      "        [2.8923, 2.8895, 3.0290, 2.9254, 3.0933],\n",
      "        [3.0811, 3.3518, 3.1596, 3.3641, 3.3447],\n",
      "        [2.8009, 2.8871, 2.9207, 2.9554, 2.9158],\n",
      "        [3.0751, 3.1020, 3.1685, 3.1499, 3.0503],\n",
      "        [3.0143, 3.0014, 3.0628, 3.1179, 3.0669],\n",
      "        [2.9057, 2.9509, 2.9975, 3.0365, 3.0423],\n",
      "        [2.9740, 2.9222, 3.0022, 3.0817, 3.0050],\n",
      "        [2.9527, 3.1035, 2.9117, 3.0287, 3.0815],\n",
      "        [2.8348, 3.1554, 3.0434, 3.0763, 3.1705],\n",
      "        [3.0131, 3.0781, 2.9203, 3.1062, 3.1861],\n",
      "        [2.8233, 2.8981, 2.8100, 3.0189, 2.8638],\n",
      "        [3.1910, 3.2558, 3.1537, 3.4281, 3.3265],\n",
      "        [2.8777, 3.1912, 3.0699, 3.1096, 3.2209],\n",
      "        [3.1141, 3.1520, 3.1051, 3.1710, 3.2151],\n",
      "        [3.0650, 3.0476, 3.0274, 3.3546, 3.2431],\n",
      "        [2.8000, 2.8845, 2.9247, 2.9556, 2.9333],\n",
      "        [2.9167, 2.8553, 2.9504, 2.9244, 2.9329],\n",
      "        [2.9077, 2.9415, 3.0046, 3.0395, 3.0438],\n",
      "        [3.0544, 3.1739, 3.0564, 3.0807, 3.1284],\n",
      "        [2.8345, 2.8925, 2.9405, 2.9814, 2.9346],\n",
      "        [3.4370, 3.6574, 3.1860, 3.3337, 3.2863],\n",
      "        [2.9168, 3.0552, 2.8852, 3.0806, 3.0360],\n",
      "        [2.9631, 3.2113, 3.0199, 3.2375, 3.1573],\n",
      "        [2.9282, 2.8743, 2.9732, 2.9378, 2.9533],\n",
      "        [2.8530, 3.0138, 2.9759, 3.1232, 2.9773],\n",
      "        [2.7138, 2.9361, 3.0639, 2.8965, 3.0532],\n",
      "        [3.0672, 2.9741, 3.0044, 3.4036, 3.2348]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.8565, 3.1575, 2.9685, 2.9805, 2.9579],\n",
      "        [2.7718, 2.9777, 2.9649, 2.9520, 2.9501],\n",
      "        [3.0555, 3.1053, 3.1636, 3.1347, 3.0068],\n",
      "        [3.0154, 3.2045, 3.1386, 3.2048, 3.2368],\n",
      "        [3.1503, 3.1534, 3.1581, 3.3275, 3.2246],\n",
      "        [2.9330, 3.1167, 3.0048, 3.0339, 3.1271],\n",
      "        [2.8162, 2.8713, 2.9190, 2.9706, 2.9320],\n",
      "        [3.0366, 3.0432, 2.9863, 3.2637, 3.1773],\n",
      "        [3.1717, 3.3127, 3.0233, 3.1615, 3.1699],\n",
      "        [2.9664, 3.0005, 3.0155, 3.1180, 3.0826],\n",
      "        [2.9882, 3.0800, 3.1062, 3.1309, 3.1331],\n",
      "        [3.0758, 3.1029, 3.2752, 3.0956, 3.0718],\n",
      "        [2.7780, 3.0714, 2.8311, 3.0249, 2.9134],\n",
      "        [3.1305, 3.2311, 3.0730, 3.2185, 3.3093],\n",
      "        [3.1511, 3.2439, 3.0943, 3.2415, 3.3382],\n",
      "        [2.7403, 2.9257, 2.8636, 2.8677, 2.9192],\n",
      "        [2.9475, 3.1364, 2.9962, 3.1622, 3.0592],\n",
      "        [3.0480, 3.1656, 3.1386, 3.2113, 3.1361],\n",
      "        [2.9231, 3.0442, 3.0359, 3.0530, 2.9590],\n",
      "        [3.0863, 3.1133, 3.1615, 3.2068, 3.0655],\n",
      "        [2.9637, 3.1089, 2.9109, 3.0338, 3.0791],\n",
      "        [2.9343, 2.9580, 3.0276, 3.0303, 3.0940],\n",
      "        [2.8318, 2.9011, 2.8188, 3.0238, 2.8990],\n",
      "        [3.0629, 3.0646, 3.2146, 3.1138, 3.0239],\n",
      "        [2.8181, 3.0572, 2.8420, 3.0207, 2.9238],\n",
      "        [3.1848, 3.1946, 3.2038, 3.3717, 3.2770],\n",
      "        [2.9169, 2.9468, 2.9405, 3.1022, 2.9818],\n",
      "        [3.0041, 3.1606, 3.0821, 3.1190, 3.0081],\n",
      "        [2.9567, 3.2140, 3.0086, 3.2373, 3.1569],\n",
      "        [3.4039, 3.5505, 3.1872, 3.3036, 3.2026],\n",
      "        [3.0489, 3.2134, 3.0278, 3.2992, 3.2044],\n",
      "        [2.9129, 2.9685, 3.0131, 3.0676, 3.0744],\n",
      "        [2.7752, 2.9908, 2.9698, 2.9634, 2.9672],\n",
      "        [3.0045, 2.9931, 3.1557, 3.2024, 3.0684],\n",
      "        [2.9117, 3.0921, 2.9709, 3.0858, 3.1249],\n",
      "        [2.9362, 3.2018, 2.9793, 3.2180, 3.1418],\n",
      "        [3.1551, 3.0410, 3.0432, 3.1402, 3.1679],\n",
      "        [2.7817, 2.9073, 2.9339, 2.9499, 2.9313],\n",
      "        [2.7959, 3.0537, 3.1347, 3.0194, 3.1001],\n",
      "        [3.0285, 3.0933, 3.0675, 3.0850, 2.9057],\n",
      "        [2.7735, 2.9774, 3.1082, 2.9481, 3.1228],\n",
      "        [2.9053, 3.0372, 2.9610, 3.0217, 3.0439],\n",
      "        [2.7676, 2.7974, 2.8691, 2.9906, 2.9004],\n",
      "        [2.8010, 2.9662, 2.9892, 2.9959, 2.9524],\n",
      "        [2.9137, 2.9368, 3.0133, 3.0624, 3.1124],\n",
      "        [3.1492, 3.3121, 3.0861, 3.1029, 3.1216],\n",
      "        [3.0737, 2.9320, 3.0671, 3.2928, 3.3286],\n",
      "        [2.7798, 2.8742, 2.9129, 2.9351, 2.8903],\n",
      "        [2.8996, 2.9957, 2.9914, 3.0460, 3.1722],\n",
      "        [2.9696, 3.2289, 3.0835, 3.1716, 3.2612],\n",
      "        [2.9582, 3.0027, 3.0099, 3.1110, 3.0804],\n",
      "        [2.9944, 3.0211, 3.1248, 3.1791, 3.0854],\n",
      "        [2.9158, 2.9708, 3.0105, 3.0536, 3.0589],\n",
      "        [3.0178, 3.0147, 3.0526, 3.1139, 3.0651],\n",
      "        [2.9923, 2.9503, 3.2415, 3.1403, 3.1936],\n",
      "        [2.9184, 2.9381, 2.9285, 3.1148, 2.9712],\n",
      "        [3.0033, 3.2632, 3.1654, 3.2059, 3.3506],\n",
      "        [2.9300, 3.0619, 2.8875, 3.0913, 3.0451],\n",
      "        [3.2967, 3.5048, 3.0612, 3.2067, 3.1674],\n",
      "        [2.8448, 3.0163, 2.9613, 3.1308, 2.9648],\n",
      "        [3.3019, 3.4331, 3.0637, 3.2475, 3.1531],\n",
      "        [3.0050, 3.2255, 3.1471, 3.1997, 3.1224],\n",
      "        [3.0770, 3.3430, 3.1475, 3.3651, 3.3351],\n",
      "        [2.8828, 2.8765, 3.0303, 2.9000, 3.0949]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.7863, 3.0293, 2.9889, 2.9736, 2.9901],\n",
      "        [2.8923, 2.9436, 3.0106, 3.0678, 3.1240],\n",
      "        [2.8499, 2.9985, 2.8828, 2.9932, 3.0005],\n",
      "        [3.4650, 3.7004, 3.2410, 3.4148, 3.2817],\n",
      "        [2.7622, 2.9379, 2.8667, 2.8940, 2.9310],\n",
      "        [2.9182, 2.9674, 3.0358, 3.0705, 3.0680],\n",
      "        [3.0264, 3.3475, 3.1877, 3.2437, 3.3149],\n",
      "        [2.8732, 2.8656, 2.9195, 3.0167, 2.9197],\n",
      "        [2.9200, 2.9563, 3.0059, 3.0470, 3.0483],\n",
      "        [2.7859, 2.9780, 2.9674, 2.9696, 2.9692],\n",
      "        [3.1047, 3.3150, 3.1179, 3.3255, 3.2841],\n",
      "        [2.9401, 2.9288, 3.0577, 3.0998, 3.1586],\n",
      "        [3.2001, 3.1370, 3.2026, 3.3831, 3.2548],\n",
      "        [2.9506, 3.0830, 2.8616, 3.0185, 3.0490],\n",
      "        [2.7249, 2.9429, 3.0685, 2.9076, 3.0578],\n",
      "        [2.7810, 3.0271, 2.9876, 2.9716, 2.9853],\n",
      "        [2.7752, 2.8689, 2.8801, 2.9166, 2.9164],\n",
      "        [2.9022, 3.1819, 2.9768, 2.8968, 3.1308],\n",
      "        [2.7671, 2.8424, 2.9025, 2.9103, 2.8664],\n",
      "        [2.8853, 2.9421, 2.9557, 3.0755, 2.9674],\n",
      "        [3.0379, 3.2516, 3.1566, 3.2375, 3.2963],\n",
      "        [2.8744, 3.0068, 3.0687, 3.1265, 3.1998],\n",
      "        [3.0739, 3.0342, 3.1262, 3.2061, 3.1310],\n",
      "        [2.8797, 3.0063, 2.9734, 3.1048, 3.0576],\n",
      "        [3.4378, 3.5858, 3.2733, 3.3791, 3.3138],\n",
      "        [2.9768, 3.1981, 2.9935, 2.9350, 3.0670],\n",
      "        [2.8352, 2.9022, 2.8174, 3.0275, 2.8799],\n",
      "        [3.0411, 3.1749, 3.1174, 3.2846, 3.1352],\n",
      "        [2.7728, 3.0315, 3.0968, 2.9552, 3.0476],\n",
      "        [2.8970, 2.8846, 2.9431, 3.0043, 3.1130],\n",
      "        [2.9365, 3.1691, 3.0390, 3.0801, 2.9715],\n",
      "        [2.8098, 2.8886, 2.9284, 2.9672, 2.9344],\n",
      "        [2.9306, 2.9507, 3.0327, 3.0194, 3.0433],\n",
      "        [2.8903, 2.9879, 2.7990, 3.1054, 2.8912],\n",
      "        [2.9226, 2.9235, 3.0300, 3.0402, 3.0405],\n",
      "        [2.8075, 2.9150, 2.9621, 2.9826, 2.9236],\n",
      "        [2.8054, 2.9667, 3.0005, 2.9979, 2.9636],\n",
      "        [3.2831, 3.0549, 3.1498, 3.6408, 3.5611],\n",
      "        [3.0513, 3.1455, 3.1832, 3.1394, 3.0534],\n",
      "        [2.8320, 2.9936, 3.0400, 3.0258, 2.9641],\n",
      "        [3.0547, 3.2169, 3.0302, 3.3051, 3.2066],\n",
      "        [3.1575, 3.0758, 3.1573, 3.3316, 3.1925],\n",
      "        [3.1278, 3.1645, 3.2817, 3.1684, 3.0730],\n",
      "        [2.8780, 3.3079, 3.1438, 3.0789, 3.0772],\n",
      "        [3.0890, 3.2725, 3.0709, 3.0450, 3.0960],\n",
      "        [3.0383, 3.1891, 3.1129, 3.2847, 3.1485],\n",
      "        [3.0607, 3.1816, 3.0615, 3.0891, 3.1317],\n",
      "        [3.2160, 3.0325, 3.0795, 3.5731, 3.3880],\n",
      "        [3.2060, 3.0725, 3.1749, 3.3123, 3.2406],\n",
      "        [2.9140, 3.2479, 3.0492, 3.1928, 3.2324],\n",
      "        [2.8633, 3.0086, 2.8808, 3.0014, 3.0048],\n",
      "        [3.2183, 3.2544, 3.1386, 3.3236, 3.3705],\n",
      "        [3.0394, 3.0458, 2.9950, 3.2711, 3.1789],\n",
      "        [3.0304, 3.0070, 3.0403, 3.0245, 2.9336],\n",
      "        [2.9847, 3.0064, 3.1182, 3.1245, 3.1349],\n",
      "        [3.1705, 2.9246, 3.0847, 3.4282, 3.4016],\n",
      "        [2.9613, 2.9427, 3.1219, 3.1600, 3.0767],\n",
      "        [3.0126, 3.0957, 3.0954, 3.1205, 3.1364],\n",
      "        [3.2189, 3.0728, 3.1787, 3.6623, 3.5596],\n",
      "        [3.2477, 3.3601, 3.2456, 3.5201, 3.3840],\n",
      "        [3.1905, 3.1980, 3.2064, 3.3778, 3.2793],\n",
      "        [3.0706, 3.1723, 3.1538, 3.3113, 3.1341],\n",
      "        [2.7503, 2.8621, 2.8673, 2.8852, 2.9000],\n",
      "        [2.9192, 2.9411, 3.0130, 3.0490, 3.0454]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.0581, 3.0791, 3.0957, 3.1082, 2.9928],\n",
      "        [2.9019, 3.0399, 3.0072, 3.1554, 3.0257],\n",
      "        [2.9712, 3.1833, 3.0451, 3.1560, 3.2379],\n",
      "        [3.1885, 3.1244, 3.0787, 3.1973, 3.2344],\n",
      "        [2.8840, 3.0245, 2.8774, 3.0373, 2.9996],\n",
      "        [3.2841, 3.2499, 3.2326, 3.3876, 3.3598],\n",
      "        [2.9335, 3.0661, 2.8920, 3.0973, 3.0428],\n",
      "        [2.9500, 3.2476, 3.1284, 3.1438, 3.0740],\n",
      "        [3.3170, 3.4644, 3.2029, 3.2562, 3.2659],\n",
      "        [3.0951, 3.2547, 3.0183, 3.1433, 3.1854],\n",
      "        [3.3587, 3.4673, 3.0788, 3.2814, 3.1433],\n",
      "        [2.7913, 2.9818, 2.9695, 2.9753, 2.9712],\n",
      "        [3.3218, 3.4553, 3.0838, 3.2773, 3.1770],\n",
      "        [2.9407, 2.9635, 3.0437, 3.0721, 3.0898],\n",
      "        [2.9243, 2.9818, 3.0167, 3.0775, 3.0739],\n",
      "        [2.9764, 3.2095, 3.0641, 3.1727, 3.2593],\n",
      "        [3.1192, 3.0095, 3.0296, 3.1141, 3.1328],\n",
      "        [2.9398, 3.1266, 2.9822, 3.0834, 3.1243],\n",
      "        [3.0412, 3.1891, 3.1380, 3.2138, 3.1938],\n",
      "        [3.0186, 2.8919, 3.1440, 3.1442, 3.1174],\n",
      "        [3.2054, 3.1409, 3.2050, 3.3896, 3.2570],\n",
      "        [3.1185, 3.2376, 3.2052, 3.2001, 3.0585],\n",
      "        [2.9136, 2.9857, 2.9168, 3.0962, 3.0067],\n",
      "        [2.8851, 2.9485, 3.1140, 2.9116, 3.1930],\n",
      "        [2.8029, 2.9849, 3.0022, 2.9921, 2.9754],\n",
      "        [2.9862, 2.8364, 3.1213, 3.1110, 3.0743],\n",
      "        [3.0376, 3.1908, 3.1391, 3.2186, 3.1932],\n",
      "        [2.9555, 3.1267, 2.9705, 3.0313, 3.1080],\n",
      "        [3.0286, 3.0172, 3.0715, 3.0429, 3.0337],\n",
      "        [3.0673, 3.0435, 3.0566, 3.0297, 2.9659],\n",
      "        [3.2624, 3.1648, 3.2294, 3.4465, 3.3032],\n",
      "        [2.7970, 2.9379, 2.9545, 2.9653, 2.9477],\n",
      "        [2.9442, 3.1239, 3.0096, 3.0456, 3.1314],\n",
      "        [2.7844, 2.9630, 2.8812, 2.9261, 2.9542],\n",
      "        [2.8784, 2.8601, 3.0266, 2.8805, 3.0943],\n",
      "        [2.7691, 2.9469, 2.8739, 2.9094, 2.9442],\n",
      "        [2.9279, 2.9540, 2.9450, 3.1136, 2.9859],\n",
      "        [2.9064, 2.9029, 3.0356, 2.9411, 3.0997],\n",
      "        [2.8886, 3.0019, 2.9190, 2.9827, 2.9891],\n",
      "        [2.8164, 2.9991, 2.9108, 3.0490, 2.9709],\n",
      "        [3.0549, 3.0249, 3.0939, 3.1735, 3.1046],\n",
      "        [2.7913, 2.9818, 2.9695, 2.9753, 2.9712],\n",
      "        [2.8433, 2.9090, 2.8236, 3.0351, 2.9035],\n",
      "        [2.7819, 3.0445, 2.9940, 2.9662, 2.9838],\n",
      "        [2.8518, 3.0054, 2.8898, 2.9841, 2.9888],\n",
      "        [2.7845, 2.9845, 3.1128, 2.9596, 3.1268],\n",
      "        [3.0588, 3.2176, 3.0269, 3.3019, 3.1975],\n",
      "        [2.9282, 2.9799, 3.0281, 2.9584, 2.8720],\n",
      "        [2.8509, 2.9271, 2.9850, 3.0517, 3.0403],\n",
      "        [3.1062, 3.1372, 3.1123, 3.1823, 3.2703],\n",
      "        [3.0745, 3.0723, 3.2196, 3.1261, 3.0278],\n",
      "        [2.9145, 2.9480, 3.0042, 3.0629, 3.0523],\n",
      "        [2.9510, 2.9661, 3.0730, 3.1187, 3.1139],\n",
      "        [2.9992, 3.0683, 3.1014, 3.1393, 3.1174],\n",
      "        [2.9186, 2.9514, 2.9983, 3.0507, 3.0458],\n",
      "        [3.0594, 3.1730, 3.1433, 3.2233, 3.1404],\n",
      "        [2.8119, 2.9734, 2.9935, 3.0070, 2.9566],\n",
      "        [2.7919, 2.9344, 2.9456, 2.9595, 2.9433],\n",
      "        [2.9601, 3.1545, 3.0130, 3.0845, 3.1427],\n",
      "        [2.7916, 3.0332, 2.9911, 2.9793, 2.9921],\n",
      "        [2.7934, 3.0291, 2.9467, 3.0053, 3.1303],\n",
      "        [2.7734, 2.8645, 2.9179, 2.9400, 2.8724],\n",
      "        [3.0664, 3.1128, 3.1683, 3.1465, 3.0110],\n",
      "        [2.8770, 2.8420, 2.8852, 2.9941, 2.9055]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.1282, 3.1962, 3.1906, 3.2702, 3.1790],\n",
      "        [2.9283, 3.1420, 3.0353, 3.0246, 3.1347],\n",
      "        [2.9215, 3.0079, 2.9407, 3.0028, 3.0299],\n",
      "        [2.8760, 3.0257, 2.9815, 2.9313, 2.9986],\n",
      "        [2.8688, 3.0139, 2.8921, 2.9997, 3.0151],\n",
      "        [2.9503, 2.9373, 3.0619, 3.1150, 3.1656],\n",
      "        [2.8704, 2.9965, 3.0584, 3.0371, 3.0811],\n",
      "        [3.0615, 3.0601, 3.0916, 3.0918, 3.0218],\n",
      "        [2.8779, 3.1330, 3.0172, 3.0875, 3.2094],\n",
      "        [2.9471, 3.1356, 2.9888, 3.0313, 3.1188],\n",
      "        [3.1665, 3.0826, 3.1664, 3.3387, 3.1986],\n",
      "        [3.1938, 3.1279, 3.0809, 3.2036, 3.2373],\n",
      "        [2.9035, 3.2437, 3.0555, 3.1709, 3.2375],\n",
      "        [3.1254, 3.2817, 3.0231, 3.1614, 3.1891],\n",
      "        [2.7906, 2.9701, 2.9599, 2.9675, 2.9533],\n",
      "        [3.0781, 3.2538, 3.0757, 3.2128, 3.1865],\n",
      "        [3.0672, 3.2204, 3.0273, 3.3071, 3.1975],\n",
      "        [3.0428, 3.0911, 2.9285, 3.2034, 3.1929],\n",
      "        [2.8608, 3.2097, 3.0254, 3.1251, 3.2031],\n",
      "        [2.9212, 2.9820, 3.0865, 2.9934, 3.2012],\n",
      "        [2.8363, 3.0118, 3.0699, 3.0452, 3.1145],\n",
      "        [2.8877, 3.0199, 2.8757, 3.0297, 2.9946],\n",
      "        [3.0657, 3.2246, 3.0348, 3.3174, 3.2112],\n",
      "        [2.9018, 2.9818, 2.9629, 2.9976, 3.0260],\n",
      "        [2.9258, 2.9705, 3.0087, 3.0674, 3.0602],\n",
      "        [2.9694, 3.1009, 2.8840, 3.0391, 3.0650],\n",
      "        [2.9821, 3.2360, 3.1248, 3.1626, 3.0958],\n",
      "        [2.8813, 2.9889, 2.9098, 3.0863, 3.0192],\n",
      "        [2.9053, 3.0263, 2.9905, 3.1111, 3.1002],\n",
      "        [2.9346, 2.9488, 2.9350, 3.1322, 2.9778],\n",
      "        [2.8094, 3.0346, 3.0816, 3.0015, 3.0800],\n",
      "        [2.8476, 3.0022, 2.8828, 2.9873, 2.9898],\n",
      "        [2.9657, 2.9856, 3.0779, 3.0930, 3.1101],\n",
      "        [2.8100, 2.9676, 2.8786, 2.9445, 2.9561],\n",
      "        [3.1993, 2.9287, 3.0871, 3.4651, 3.4211],\n",
      "        [3.0836, 3.1518, 3.1251, 3.2473, 3.2711],\n",
      "        [2.9314, 2.9411, 3.0261, 3.0627, 3.0389],\n",
      "        [2.9717, 2.9498, 3.1263, 3.1719, 3.0811],\n",
      "        [3.0845, 3.0445, 3.0446, 3.4073, 3.2704],\n",
      "        [3.0108, 3.0690, 3.1203, 3.1690, 3.1170],\n",
      "        [2.9543, 3.0808, 2.8887, 3.1223, 3.0523],\n",
      "        [2.9953, 3.1925, 3.0581, 3.0931, 3.1573],\n",
      "        [3.2192, 3.2551, 3.1327, 3.3251, 3.3566],\n",
      "        [2.7985, 2.9507, 2.9577, 2.9698, 2.9497],\n",
      "        [2.9238, 2.9549, 3.0004, 3.0568, 3.0482],\n",
      "        [2.9681, 2.9873, 3.0973, 3.1395, 3.1220],\n",
      "        [3.1319, 3.2272, 3.0578, 3.2043, 3.2969],\n",
      "        [2.7994, 2.8380, 2.8990, 2.9728, 2.9369],\n",
      "        [2.7874, 3.0208, 2.9852, 2.9714, 2.9717],\n",
      "        [2.8875, 3.0049, 3.1138, 3.0787, 3.1421],\n",
      "        [2.9090, 2.9373, 2.8549, 3.0127, 3.1057],\n",
      "        [3.2070, 3.1339, 3.1971, 3.3944, 3.2458],\n",
      "        [2.8293, 3.1615, 3.0059, 2.8946, 3.1425],\n",
      "        [3.0464, 3.2520, 3.1593, 3.2391, 3.3015],\n",
      "        [3.0123, 3.0704, 3.0330, 3.2272, 3.1006],\n",
      "        [2.9544, 2.9741, 3.0533, 3.0808, 3.1002],\n",
      "        [3.0026, 3.1724, 3.0789, 3.1312, 3.0060],\n",
      "        [3.0617, 3.1032, 3.0511, 3.2245, 3.2471],\n",
      "        [2.8510, 2.9313, 2.8267, 3.0432, 2.9404],\n",
      "        [2.9140, 3.1592, 3.0681, 3.0065, 3.1430],\n",
      "        [2.9371, 2.9608, 3.0196, 3.0655, 3.0614],\n",
      "        [2.6519, 2.8414, 2.8878, 2.8632, 2.9292],\n",
      "        [3.1030, 3.1741, 3.1855, 3.3400, 3.1407],\n",
      "        [2.8277, 2.9557, 2.9900, 3.0098, 2.9537]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.9915, 3.0066, 3.1075, 3.1408, 3.1312],\n",
      "        [2.8032, 2.9546, 2.9596, 2.9752, 2.9527],\n",
      "        [2.9985, 2.8656, 3.1353, 3.1561, 3.1557],\n",
      "        [3.0576, 3.0580, 2.9951, 3.2872, 3.1870],\n",
      "        [2.7826, 2.9549, 2.8816, 2.9119, 2.9464],\n",
      "        [2.9324, 3.0051, 2.9455, 3.1298, 3.0407],\n",
      "        [3.0314, 3.1172, 3.1059, 3.1694, 3.2298],\n",
      "        [2.7478, 2.8409, 2.8635, 2.8790, 2.8806],\n",
      "        [3.0515, 3.1968, 3.1423, 3.2260, 3.1995],\n",
      "        [3.1164, 3.1354, 3.1372, 3.3183, 3.1784],\n",
      "        [3.0990, 3.3580, 3.1570, 3.3894, 3.3451],\n",
      "        [2.9277, 3.1549, 3.0554, 3.0219, 3.1448],\n",
      "        [3.1231, 3.2744, 3.0137, 3.1479, 3.1802],\n",
      "        [2.9407, 2.9426, 3.0499, 3.0796, 3.0570],\n",
      "        [2.9499, 3.1341, 2.9864, 3.0951, 3.1300],\n",
      "        [2.8172, 2.9176, 2.9422, 2.9781, 2.9472],\n",
      "        [3.0201, 3.3296, 3.1818, 3.2440, 3.3475],\n",
      "        [2.9396, 3.0470, 2.9309, 3.1497, 3.0707],\n",
      "        [2.8978, 3.0380, 2.8872, 3.0531, 3.0112],\n",
      "        [3.0474, 3.0950, 2.9306, 3.2091, 3.1961],\n",
      "        [2.8909, 2.9741, 2.9734, 2.9903, 3.0207],\n",
      "        [3.0734, 3.2042, 3.1453, 3.1647, 3.0255],\n",
      "        [2.7986, 2.8831, 2.9257, 2.9574, 2.9050],\n",
      "        [2.9254, 3.0408, 2.9957, 3.0175, 3.0603],\n",
      "        [2.8575, 2.9557, 3.0043, 3.0807, 3.0597],\n",
      "        [2.7981, 2.9777, 2.8887, 2.9886, 2.9520],\n",
      "        [2.9988, 2.9477, 3.2496, 3.1475, 3.1858],\n",
      "        [3.0637, 3.2163, 2.9989, 3.1481, 3.1912],\n",
      "        [2.8690, 2.9798, 2.9791, 2.9777, 2.9970],\n",
      "        [2.8506, 3.2202, 3.1051, 3.0921, 3.2334],\n",
      "        [2.8108, 2.9184, 2.9032, 2.9627, 2.9468],\n",
      "        [2.9528, 3.2815, 3.0510, 3.2312, 3.2244],\n",
      "        [2.9053, 2.9989, 2.8050, 3.1218, 2.8986],\n",
      "        [2.7754, 2.9563, 2.8815, 2.9154, 2.9461],\n",
      "        [2.8658, 3.0309, 2.9702, 3.1539, 2.9741],\n",
      "        [2.8129, 2.9925, 3.0061, 3.0032, 2.9809],\n",
      "        [2.9494, 3.2094, 3.0892, 3.1988, 3.2582],\n",
      "        [2.9278, 2.9868, 3.0159, 3.0843, 3.0645],\n",
      "        [3.0000, 3.0197, 3.1313, 3.1545, 3.1417],\n",
      "        [2.9681, 2.9420, 3.0760, 3.1348, 3.1711],\n",
      "        [2.9590, 3.1470, 3.0019, 3.0964, 3.1405],\n",
      "        [2.9328, 2.9694, 3.0086, 3.0655, 3.0547],\n",
      "        [2.7981, 2.9555, 2.9547, 2.9719, 2.9528],\n",
      "        [3.0667, 3.1074, 3.0532, 3.2303, 3.2505],\n",
      "        [2.8880, 2.9894, 2.8110, 3.1088, 2.9114],\n",
      "        [3.2427, 3.2266, 3.1548, 3.3072, 3.2951],\n",
      "        [2.9770, 2.9978, 3.0910, 3.1089, 3.1198],\n",
      "        [2.7963, 3.0385, 2.9938, 2.9884, 2.9928],\n",
      "        [3.0689, 3.1853, 3.0576, 3.0818, 3.1295],\n",
      "        [3.0651, 3.2256, 3.0051, 3.1540, 3.1924],\n",
      "        [3.3679, 3.4744, 3.0831, 3.2937, 3.1492],\n",
      "        [3.0671, 3.1635, 3.2027, 3.2573, 3.2835],\n",
      "        [3.0162, 3.0866, 2.9881, 3.1840, 3.1306],\n",
      "        [2.9508, 3.0766, 2.8962, 3.1139, 3.0547],\n",
      "        [2.9562, 2.8928, 2.9816, 2.9745, 2.9657],\n",
      "        [3.0696, 3.1807, 3.1476, 3.2355, 3.1462],\n",
      "        [2.9197, 3.0557, 2.8894, 3.0652, 3.0347],\n",
      "        [2.9570, 3.0866, 2.8954, 3.1273, 3.0570],\n",
      "        [2.9516, 2.9725, 3.0415, 3.0793, 3.0971],\n",
      "        [3.0904, 3.1331, 3.1050, 3.1715, 3.2623],\n",
      "        [3.3786, 3.1145, 3.2336, 3.7357, 3.6480],\n",
      "        [3.0578, 3.1184, 3.0852, 3.1142, 2.9239],\n",
      "        [3.1793, 3.1056, 3.1875, 3.3709, 3.2220],\n",
      "        [2.8534, 2.8736, 2.9185, 3.0116, 2.9394]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.8195, 2.9880, 2.8872, 2.9621, 2.9725],\n",
      "        [2.9593, 2.8976, 2.9860, 2.9720, 2.9683],\n",
      "        [2.9777, 2.9724, 3.0885, 3.1667, 3.0987],\n",
      "        [3.1222, 3.2330, 3.0466, 3.1891, 3.2620],\n",
      "        [2.9402, 2.9728, 3.0142, 3.0697, 3.0586],\n",
      "        [2.9816, 3.0029, 3.0930, 3.1139, 3.1227],\n",
      "        [2.8403, 3.0086, 2.8896, 2.9835, 2.9909],\n",
      "        [2.8781, 3.0229, 2.8960, 3.0097, 3.0210],\n",
      "        [2.8469, 3.0434, 2.9315, 3.0177, 3.0444],\n",
      "        [2.9312, 3.3021, 3.1386, 3.0870, 3.0995],\n",
      "        [2.9545, 3.1393, 2.9884, 3.1001, 3.1329],\n",
      "        [3.2004, 2.9316, 3.0714, 3.4848, 3.4348],\n",
      "        [2.8305, 2.9276, 2.9691, 3.0069, 2.9322],\n",
      "        [3.0851, 3.2370, 3.1346, 3.2530, 3.1819],\n",
      "        [3.0905, 3.1652, 3.1317, 3.1723, 3.2509],\n",
      "        [2.9409, 3.0652, 3.0287, 3.0429, 2.9823],\n",
      "        [3.2377, 3.2705, 3.1475, 3.3478, 3.3814],\n",
      "        [3.0220, 3.0798, 3.0370, 3.2378, 3.1067],\n",
      "        [2.7999, 2.9791, 2.9637, 2.9776, 2.9592],\n",
      "        [2.9398, 3.0630, 2.8920, 3.0920, 3.0481],\n",
      "        [3.0708, 3.1997, 3.1484, 3.2361, 3.1812],\n",
      "        [2.9127, 2.9602, 3.0190, 3.0906, 3.1345],\n",
      "        [2.7775, 2.9539, 2.8768, 2.9132, 2.9424],\n",
      "        [3.0867, 2.9628, 2.9422, 3.0388, 3.1209],\n",
      "        [3.0756, 3.2341, 3.0390, 3.3282, 3.2175],\n",
      "        [2.7983, 3.0173, 2.9792, 2.9784, 2.9699],\n",
      "        [2.9393, 3.0607, 2.9784, 3.0584, 3.0671],\n",
      "        [2.9785, 2.9983, 3.1025, 3.1460, 3.1317],\n",
      "        [2.9637, 3.0902, 2.8942, 3.1475, 3.0635],\n",
      "        [2.9255, 3.0155, 3.0023, 3.0747, 3.1852],\n",
      "        [2.9620, 3.0359, 3.0416, 3.0711, 3.2699],\n",
      "        [2.8320, 3.0376, 2.8679, 3.0462, 2.9728],\n",
      "        [2.9412, 3.0184, 3.0199, 3.0658, 3.2258],\n",
      "        [2.8550, 2.8937, 2.9326, 3.0088, 2.9508],\n",
      "        [2.8061, 3.0458, 2.9969, 2.9952, 3.0004],\n",
      "        [3.0302, 3.2843, 3.1765, 3.2355, 3.3635],\n",
      "        [3.0987, 3.2222, 3.0534, 3.2746, 3.2610],\n",
      "        [2.9492, 3.1357, 2.9927, 3.0919, 3.1400],\n",
      "        [3.0053, 3.1146, 3.1834, 3.1783, 3.2024],\n",
      "        [2.9522, 2.9328, 3.0458, 3.0875, 3.1331],\n",
      "        [3.0171, 3.2508, 3.0396, 2.9872, 3.1703],\n",
      "        [3.0459, 3.0133, 3.0815, 3.0427, 3.0954],\n",
      "        [2.8457, 3.0275, 3.0726, 3.0930, 3.1472],\n",
      "        [2.9811, 2.9587, 3.1303, 3.1824, 3.0871],\n",
      "        [2.7970, 2.9779, 2.9679, 2.9772, 2.9562],\n",
      "        [3.0434, 3.0300, 3.0777, 3.0601, 3.0423],\n",
      "        [3.0394, 3.2237, 3.0955, 3.2992, 3.1763],\n",
      "        [3.0969, 3.0717, 3.0407, 3.3895, 3.2585],\n",
      "        [3.0744, 3.2071, 3.0395, 3.2757, 3.3249],\n",
      "        [2.8574, 2.9858, 3.0194, 3.0472, 2.9588],\n",
      "        [3.0179, 3.0754, 3.0484, 3.1281, 3.0976],\n",
      "        [3.1403, 3.2901, 3.1601, 3.1333, 3.2404],\n",
      "        [3.0921, 3.0870, 3.2338, 3.1469, 3.0432],\n",
      "        [3.2338, 3.1929, 3.1463, 3.4200, 3.2732],\n",
      "        [3.1108, 3.2250, 3.0311, 3.1887, 3.2479],\n",
      "        [2.9090, 3.1049, 3.0323, 2.9872, 3.0022],\n",
      "        [2.8835, 3.0788, 3.2067, 3.0712, 3.2271],\n",
      "        [3.1769, 3.0880, 3.1632, 3.3537, 3.1991],\n",
      "        [2.8569, 2.9206, 2.8289, 3.0503, 2.9110],\n",
      "        [3.1018, 3.0648, 3.0644, 3.0643, 2.9941],\n",
      "        [2.8058, 2.9652, 2.8866, 2.9397, 2.9548],\n",
      "        [2.8011, 2.9916, 2.9738, 2.9863, 2.9724],\n",
      "        [3.0050, 2.9456, 3.0149, 3.1158, 3.0201],\n",
      "        [2.7446, 2.9590, 3.0767, 2.9296, 3.0678]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.9472, 3.0063, 3.0843, 3.0310, 3.2057],\n",
      "        [2.9329, 2.9711, 3.0169, 3.0829, 3.0623],\n",
      "        [2.8763, 3.1013, 2.8918, 3.0984, 2.9593],\n",
      "        [2.8324, 3.1643, 3.0020, 2.9003, 3.1474],\n",
      "        [2.9102, 3.2056, 3.1279, 3.0128, 3.1724],\n",
      "        [2.8493, 2.9490, 2.8573, 3.0512, 2.8827],\n",
      "        [2.9508, 2.9867, 3.0073, 3.0630, 3.1088],\n",
      "        [3.0943, 3.0639, 3.0614, 3.0572, 2.9900],\n",
      "        [2.9580, 3.0023, 3.0541, 3.1202, 3.0941],\n",
      "        [2.9458, 2.9203, 3.0168, 3.0900, 3.1459],\n",
      "        [3.0143, 3.0286, 3.1367, 3.1653, 3.1498],\n",
      "        [2.9988, 3.1892, 3.0533, 3.1085, 3.1587],\n",
      "        [3.0543, 3.0281, 3.0505, 3.0511, 2.9467],\n",
      "        [3.1061, 3.1270, 3.2805, 3.1277, 3.0767],\n",
      "        [3.0512, 3.0577, 3.0258, 3.2662, 3.1703],\n",
      "        [2.8395, 3.0233, 3.0716, 3.0568, 3.1188],\n",
      "        [2.9465, 2.9972, 3.0360, 2.9787, 2.8828],\n",
      "        [2.8678, 3.1145, 3.0062, 3.0820, 3.2107],\n",
      "        [3.1931, 3.2438, 3.2588, 3.2616, 3.1243],\n",
      "        [2.9566, 2.9422, 3.0566, 3.1146, 3.1634],\n",
      "        [2.8640, 3.1833, 3.0281, 2.9217, 3.1643],\n",
      "        [2.8618, 2.9939, 2.8876, 3.0475, 2.9684],\n",
      "        [2.7426, 2.9127, 2.8603, 2.8651, 2.9000],\n",
      "        [3.0615, 3.1691, 3.1674, 3.1900, 3.1752],\n",
      "        [2.8044, 2.9837, 2.9655, 2.9819, 2.9618],\n",
      "        [3.0987, 3.0586, 3.0506, 3.4228, 3.2790],\n",
      "        [2.9343, 3.0087, 3.1415, 3.1946, 3.1277],\n",
      "        [2.9903, 3.0564, 3.0191, 3.1280, 3.1523],\n",
      "        [3.3428, 3.4709, 3.1845, 3.2876, 3.2126],\n",
      "        [3.0135, 3.2496, 3.1637, 3.1728, 3.2187],\n",
      "        [2.9228, 3.0514, 3.0208, 3.1761, 3.0344],\n",
      "        [2.8133, 2.8515, 2.9047, 2.9875, 2.9454],\n",
      "        [3.3505, 3.4725, 3.0773, 3.2897, 3.1613],\n",
      "        [2.7876, 2.9638, 2.8814, 2.9292, 2.9549],\n",
      "        [2.9916, 3.1502, 2.9816, 3.1813, 3.1083],\n",
      "        [3.1746, 3.1752, 3.1686, 3.3619, 3.2324],\n",
      "        [3.0100, 3.1194, 3.1854, 3.1830, 3.2050],\n",
      "        [2.9062, 3.3089, 3.1461, 3.1149, 3.0909],\n",
      "        [2.8304, 3.0865, 3.0132, 3.0078, 3.0352],\n",
      "        [3.2008, 3.3367, 3.0364, 3.1955, 3.1852],\n",
      "        [2.9398, 3.0674, 2.9005, 3.0956, 3.0509],\n",
      "        [2.9571, 3.0794, 2.8944, 3.1207, 3.0514],\n",
      "        [3.1512, 3.1808, 3.1199, 3.2107, 3.2349],\n",
      "        [3.1790, 3.0632, 3.0538, 3.1709, 3.1916],\n",
      "        [3.0350, 3.0064, 3.0697, 3.0497, 3.0572],\n",
      "        [3.2411, 3.1962, 3.1488, 3.4194, 3.2777],\n",
      "        [3.1708, 3.1894, 3.1257, 3.2351, 3.2365],\n",
      "        [3.0488, 3.2236, 3.1516, 3.2442, 3.2355],\n",
      "        [2.8973, 3.1038, 3.0187, 2.9730, 2.9909],\n",
      "        [2.9735, 2.9178, 3.0025, 2.9940, 2.9882],\n",
      "        [2.9421, 3.1166, 2.9838, 3.1187, 3.1401],\n",
      "        [2.9511, 2.9290, 3.0474, 3.0984, 3.1544],\n",
      "        [2.9650, 3.0736, 2.8671, 3.1271, 2.9583],\n",
      "        [2.9521, 3.0295, 3.0907, 3.1130, 3.1771],\n",
      "        [2.8426, 3.0036, 2.8888, 2.9811, 2.9800],\n",
      "        [2.8498, 2.9095, 2.9386, 3.0072, 2.9538],\n",
      "        [3.2904, 3.0922, 3.1900, 3.7269, 3.5691],\n",
      "        [3.0539, 3.1082, 2.9390, 3.2275, 3.2184],\n",
      "        [2.8496, 3.0997, 2.8759, 3.0659, 2.9459],\n",
      "        [2.8595, 2.8983, 2.9344, 3.0132, 2.9533],\n",
      "        [2.9682, 3.1569, 3.0058, 3.1059, 3.1461],\n",
      "        [2.8755, 2.9843, 2.8962, 3.0499, 2.9718],\n",
      "        [2.8434, 3.0438, 2.8739, 3.0534, 2.9794],\n",
      "        [2.8455, 2.9742, 3.0017, 3.0210, 2.9737]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.0693, 3.1785, 3.0835, 3.1795, 3.2273],\n",
      "        [3.2120, 3.1011, 3.1785, 3.3246, 3.2369],\n",
      "        [2.8177, 2.8557, 2.9065, 2.9922, 2.9486],\n",
      "        [3.0983, 3.1729, 3.1437, 3.2243, 3.2948],\n",
      "        [3.0049, 3.3057, 3.1411, 3.2234, 3.2866],\n",
      "        [3.0685, 3.0518, 3.0687, 3.0363, 2.9555],\n",
      "        [2.8426, 2.9449, 2.9165, 3.0000, 2.9675],\n",
      "        [2.9599, 3.0630, 2.9466, 3.1574, 3.0777],\n",
      "        [3.2268, 3.2299, 3.2177, 3.4007, 3.3049],\n",
      "        [2.8564, 3.0102, 3.1169, 3.0495, 3.1358],\n",
      "        [3.0299, 3.0744, 3.0469, 3.1415, 3.0835],\n",
      "        [2.8284, 3.0529, 3.0894, 3.0218, 3.0919],\n",
      "        [3.2744, 3.1068, 3.1969, 3.7160, 3.5811],\n",
      "        [3.0148, 3.1643, 2.9994, 3.1930, 3.1247],\n",
      "        [2.8097, 3.0096, 2.9772, 2.9863, 2.9704],\n",
      "        [2.8691, 2.9490, 2.8340, 3.0621, 2.9519],\n",
      "        [3.2904, 3.3804, 3.2661, 3.5633, 3.3995],\n",
      "        [3.0957, 3.2141, 3.0620, 3.1786, 3.1626],\n",
      "        [3.0940, 3.1823, 3.2072, 3.1860, 3.0714],\n",
      "        [2.9359, 3.0513, 2.9275, 3.0766, 3.0621],\n",
      "        [2.9178, 2.9468, 3.0065, 3.0382, 3.0333],\n",
      "        [2.9162, 3.1115, 2.9417, 3.1778, 3.0072],\n",
      "        [3.0486, 3.0314, 3.0508, 3.0423, 2.9372],\n",
      "        [3.0319, 3.1011, 2.9878, 3.1970, 3.1380],\n",
      "        [2.9899, 3.1396, 2.9475, 3.0618, 3.1056],\n",
      "        [3.0550, 3.0343, 3.0796, 3.1619, 3.0885],\n",
      "        [2.8182, 2.9899, 2.8927, 2.9527, 2.9806],\n",
      "        [2.8282, 2.9966, 2.8907, 2.9710, 2.9783],\n",
      "        [3.0751, 3.1939, 3.0400, 3.2506, 3.1744],\n",
      "        [2.9746, 3.1040, 3.0314, 3.1193, 3.1306],\n",
      "        [2.9478, 3.0618, 2.9324, 3.0915, 3.0722],\n",
      "        [3.1834, 3.0675, 3.0556, 3.1758, 3.1952],\n",
      "        [3.0654, 3.0626, 3.0936, 3.2633, 3.0435],\n",
      "        [2.8637, 2.9239, 2.9625, 3.0229, 2.9432],\n",
      "        [2.9512, 2.9647, 3.0267, 3.0802, 3.0585],\n",
      "        [2.9132, 3.1022, 2.9394, 3.1798, 3.0057],\n",
      "        [2.8670, 3.0632, 2.9542, 3.0457, 3.0590],\n",
      "        [2.7776, 2.9487, 2.7820, 3.0073, 2.8958],\n",
      "        [2.9498, 3.0740, 3.0323, 3.0522, 2.9884],\n",
      "        [3.1685, 2.9498, 3.0833, 3.4243, 3.3886],\n",
      "        [2.9926, 3.1424, 2.9411, 3.0674, 3.1032],\n",
      "        [2.9503, 2.9173, 2.9952, 3.0066, 2.9907],\n",
      "        [2.7785, 2.8867, 2.8784, 2.9148, 2.9159],\n",
      "        [2.8369, 3.1685, 3.0039, 2.9051, 3.1506],\n",
      "        [3.0918, 3.0563, 3.0282, 3.3888, 3.2503],\n",
      "        [2.9952, 3.2057, 3.0549, 3.1824, 3.2523],\n",
      "        [3.2829, 3.3670, 3.2518, 3.5423, 3.3643],\n",
      "        [3.0829, 3.2413, 3.0421, 3.3366, 3.2204],\n",
      "        [2.9405, 2.9991, 3.0196, 3.1056, 3.0747],\n",
      "        [2.9394, 2.9939, 3.0157, 3.0916, 3.0676],\n",
      "        [3.2202, 3.2242, 3.2194, 3.4136, 3.2969],\n",
      "        [2.9658, 3.1538, 2.9967, 3.0513, 3.1309],\n",
      "        [2.8459, 2.9097, 2.9396, 3.0138, 2.9547],\n",
      "        [2.9430, 3.1272, 2.9487, 3.2087, 3.0142],\n",
      "        [2.9236, 3.0505, 2.8916, 3.0726, 3.0373],\n",
      "        [3.0584, 3.1863, 3.1819, 3.2173, 3.1733],\n",
      "        [3.0652, 3.1412, 2.9829, 3.2226, 3.1869],\n",
      "        [2.9437, 3.1308, 2.9913, 3.1090, 3.1345],\n",
      "        [3.2538, 3.2822, 3.1476, 3.3440, 3.3930],\n",
      "        [2.9423, 3.0062, 3.0215, 3.1007, 3.0749],\n",
      "        [2.7737, 2.9535, 2.8768, 2.9026, 2.9373],\n",
      "        [2.9381, 2.9824, 3.0091, 3.0808, 3.0619],\n",
      "        [3.0160, 3.1329, 3.0124, 3.1844, 3.1759],\n",
      "        [2.9726, 3.0989, 2.8979, 3.1565, 3.0694]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.7467, 2.9284, 2.8661, 2.8750, 2.9117],\n",
      "        [3.1497, 3.2043, 3.2212, 3.3814, 3.1676],\n",
      "        [2.8389, 2.9796, 2.9699, 3.0022, 2.9904],\n",
      "        [2.9504, 3.0231, 2.9528, 3.1488, 3.0526],\n",
      "        [2.9625, 2.9953, 3.0254, 3.0836, 3.1159],\n",
      "        [3.0892, 3.2473, 3.0448, 3.3428, 3.2267],\n",
      "        [2.7467, 2.9284, 2.8661, 2.8750, 2.9117],\n",
      "        [2.9814, 3.1656, 2.9659, 3.2643, 3.0363],\n",
      "        [2.8386, 2.9339, 2.9506, 2.9991, 2.9604],\n",
      "        [2.8192, 3.0585, 3.0021, 3.0091, 3.0094],\n",
      "        [3.3226, 3.1351, 3.2205, 3.7527, 3.5828],\n",
      "        [2.9770, 3.0449, 3.0501, 3.0861, 3.2801],\n",
      "        [3.2074, 3.3479, 3.0393, 3.2033, 3.1920],\n",
      "        [2.9313, 2.9589, 2.8644, 3.0369, 3.1198],\n",
      "        [3.5126, 3.6716, 3.2749, 3.4178, 3.2918],\n",
      "        [3.1911, 3.1147, 3.1751, 3.3398, 3.2063],\n",
      "        [3.0483, 3.0383, 3.0789, 3.0806, 3.0281],\n",
      "        [2.9656, 3.0865, 3.0508, 3.0894, 2.9874],\n",
      "        [2.9993, 3.0189, 3.0952, 3.1297, 3.1434],\n",
      "        [3.0186, 2.9628, 3.2474, 3.1613, 3.1851],\n",
      "        [2.9812, 2.9854, 3.0390, 3.1242, 3.1306],\n",
      "        [3.0569, 3.0477, 3.0688, 3.1572, 3.0872],\n",
      "        [2.7777, 2.9573, 2.8784, 2.9074, 2.9403],\n",
      "        [3.1632, 3.1957, 3.2969, 3.2077, 3.0913],\n",
      "        [3.0145, 3.2586, 2.9796, 3.1727, 3.1233],\n",
      "        [3.0639, 3.1827, 3.1828, 3.2437, 3.1966],\n",
      "        [2.8840, 2.9777, 2.9858, 2.9621, 3.1295],\n",
      "        [2.9190, 2.8896, 2.9991, 3.0716, 3.0785],\n",
      "        [3.1011, 3.2755, 3.0854, 3.2380, 3.2017],\n",
      "        [3.0494, 3.3325, 3.1916, 3.2491, 3.3002],\n",
      "        [3.1356, 3.2459, 3.0525, 3.2040, 3.2711],\n",
      "        [2.9578, 2.9704, 3.0846, 3.1319, 3.0886],\n",
      "        [2.9178, 3.2050, 3.0304, 3.0748, 2.9849],\n",
      "        [2.9290, 3.0445, 3.0010, 3.1221, 3.1365],\n",
      "        [3.1032, 3.2149, 3.0748, 3.1541, 3.1594],\n",
      "        [3.0135, 3.0522, 3.0310, 3.1894, 3.1057],\n",
      "        [3.0892, 3.2473, 3.0448, 3.3428, 3.2267],\n",
      "        [3.1030, 2.9382, 2.9492, 3.0836, 3.0769],\n",
      "        [3.2467, 3.2058, 3.1520, 3.4362, 3.2826],\n",
      "        [2.9523, 2.9386, 3.0317, 3.0764, 3.0579],\n",
      "        [2.9597, 2.9372, 3.0509, 3.1082, 3.1608],\n",
      "        [3.2161, 3.1049, 3.1803, 3.3301, 3.2400],\n",
      "        [3.0047, 3.2361, 3.0757, 3.2044, 3.2769],\n",
      "        [3.2005, 3.2832, 3.1180, 3.2930, 3.3553],\n",
      "        [2.9941, 3.2390, 3.0177, 3.2783, 3.1729],\n",
      "        [3.2454, 3.3782, 3.0528, 3.2213, 3.1915],\n",
      "        [2.9128, 3.3385, 3.1588, 3.1170, 3.0966],\n",
      "        [2.8737, 3.1251, 2.8881, 3.0736, 2.9527],\n",
      "        [2.9429, 3.0169, 3.1450, 3.2046, 3.1341],\n",
      "        [3.0027, 3.2323, 3.0721, 3.2005, 3.2729],\n",
      "        [3.0709, 3.2061, 3.0287, 3.1995, 3.1771],\n",
      "        [3.0648, 2.9357, 3.1799, 3.1837, 3.1453],\n",
      "        [3.0872, 3.2453, 3.0439, 3.3418, 3.2235],\n",
      "        [3.0335, 3.2350, 3.0724, 3.3036, 3.1835],\n",
      "        [2.8178, 2.9061, 2.9281, 2.9753, 2.9117],\n",
      "        [2.7836, 2.9559, 2.8786, 2.9155, 2.9476],\n",
      "        [3.2672, 3.3621, 3.2413, 3.3756, 3.4229],\n",
      "        [2.9717, 3.2096, 3.1023, 3.2045, 3.2690],\n",
      "        [2.9559, 3.0146, 3.0878, 3.0411, 3.2122],\n",
      "        [3.0844, 3.1760, 3.1975, 3.1765, 3.0730],\n",
      "        [2.8786, 3.0527, 2.9886, 3.1778, 3.0012],\n",
      "        [2.9751, 3.0957, 2.8933, 3.1386, 3.0566],\n",
      "        [3.0796, 3.3041, 3.0774, 3.0443, 3.1927],\n",
      "        [2.9979, 3.2440, 2.9616, 3.1612, 3.1016]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.1059, 3.1611, 3.1869, 3.1853, 3.0194],\n",
      "        [2.8748, 2.9190, 2.9561, 3.0350, 2.9455],\n",
      "        [2.8153, 3.0334, 2.9861, 2.9967, 2.9816],\n",
      "        [2.9015, 3.1884, 3.0063, 3.0457, 2.9668],\n",
      "        [2.8153, 2.9912, 2.8937, 2.9596, 2.9740],\n",
      "        [2.9602, 3.2252, 2.9786, 3.2417, 3.1488],\n",
      "        [2.9594, 3.0681, 2.9412, 3.0978, 3.0837],\n",
      "        [2.8638, 3.0596, 2.9385, 3.0363, 3.0564],\n",
      "        [3.1955, 3.1155, 3.1796, 3.3786, 3.2198],\n",
      "        [2.9740, 3.0161, 2.9177, 3.0844, 3.1621],\n",
      "        [3.1365, 3.1370, 3.2091, 3.2397, 3.0619],\n",
      "        [2.9600, 3.0916, 3.0508, 3.0945, 2.9981],\n",
      "        [3.2064, 3.3789, 3.1425, 3.1731, 3.1787],\n",
      "        [3.0122, 3.2515, 3.0409, 3.2911, 3.1846],\n",
      "        [2.9201, 2.9668, 2.9506, 3.0190, 3.0801],\n",
      "        [3.2145, 3.1290, 3.0850, 3.2244, 3.2430],\n",
      "        [3.2276, 3.2519, 3.2008, 3.4432, 3.2562],\n",
      "        [2.9085, 2.8704, 2.8981, 3.0288, 2.9254],\n",
      "        [3.0597, 3.0868, 3.0576, 3.1678, 3.1038],\n",
      "        [2.9464, 2.9899, 3.0126, 3.0905, 3.0677],\n",
      "        [3.1042, 3.2578, 3.0833, 3.2662, 3.2052],\n",
      "        [3.0885, 3.3134, 3.0856, 3.2476, 3.2101],\n",
      "        [2.9585, 2.9246, 2.9986, 3.0164, 2.9965],\n",
      "        [2.9810, 2.9995, 3.0643, 3.1104, 3.1183],\n",
      "        [3.0957, 3.0886, 3.1213, 3.2910, 3.0793],\n",
      "        [2.9920, 3.3446, 3.0967, 3.3035, 3.2748],\n",
      "        [2.8072, 3.0970, 2.9343, 2.8429, 3.0299],\n",
      "        [2.9288, 2.9366, 3.0002, 3.0372, 3.0199],\n",
      "        [3.1466, 2.9587, 3.0798, 3.3875, 3.3749],\n",
      "        [3.1190, 3.2427, 3.0366, 3.1931, 3.2457],\n",
      "        [2.8185, 3.0985, 2.8468, 3.0799, 2.9363],\n",
      "        [3.1608, 3.3053, 3.2658, 3.3049, 3.1421],\n",
      "        [3.0044, 3.1619, 2.9871, 3.1959, 3.1174],\n",
      "        [3.0973, 3.0768, 3.0125, 3.3538, 3.2256],\n",
      "        [2.9941, 3.1227, 2.9100, 3.1722, 3.0855],\n",
      "        [2.9378, 3.0295, 3.0073, 3.0916, 3.1945],\n",
      "        [2.8457, 2.9463, 2.9573, 3.0121, 2.9770],\n",
      "        [2.7994, 2.8836, 2.9220, 2.9645, 2.8869],\n",
      "        [2.8433, 3.0022, 3.0061, 3.0410, 2.9769],\n",
      "        [2.9286, 3.0201, 3.1062, 3.1878, 3.2316],\n",
      "        [2.8972, 3.1442, 3.0181, 3.1210, 3.1935],\n",
      "        [3.1174, 3.2027, 3.1807, 3.3606, 3.1579],\n",
      "        [2.9462, 2.9846, 3.0099, 3.0869, 3.0652],\n",
      "        [2.9921, 3.1839, 3.0266, 3.1203, 3.1635],\n",
      "        [2.8494, 3.0278, 3.0261, 3.0473, 2.9987],\n",
      "        [2.8480, 3.0276, 2.9237, 3.0836, 2.9908],\n",
      "        [3.1530, 3.3522, 3.1533, 3.3901, 3.3120],\n",
      "        [2.9323, 2.9209, 3.0181, 3.0639, 3.0288],\n",
      "        [2.8566, 3.0089, 3.0406, 3.0635, 2.9647],\n",
      "        [2.9169, 3.0451, 2.8912, 3.0612, 3.0146],\n",
      "        [3.3419, 3.4677, 3.0822, 3.2968, 3.1784],\n",
      "        [3.0807, 3.0633, 3.0633, 3.0427, 2.9685],\n",
      "        [2.9594, 2.9559, 3.0451, 3.0814, 3.0621],\n",
      "        [2.9534, 2.9893, 3.0186, 3.0936, 3.0739],\n",
      "        [2.9635, 2.9802, 3.0296, 3.0919, 3.0727],\n",
      "        [2.9057, 3.0515, 3.0046, 3.1735, 3.0137],\n",
      "        [3.1679, 3.3251, 3.2587, 3.2786, 3.0966],\n",
      "        [2.9138, 3.3123, 3.1543, 3.1193, 3.0930],\n",
      "        [2.9548, 3.1284, 2.9892, 3.1330, 3.1493],\n",
      "        [3.1550, 3.2221, 3.2024, 3.3023, 3.1976],\n",
      "        [3.2456, 3.2016, 3.1475, 3.4373, 3.2864],\n",
      "        [2.9309, 3.2704, 3.0675, 3.2011, 3.2558],\n",
      "        [2.9942, 3.1650, 3.0095, 3.1937, 3.0959],\n",
      "        [2.9935, 3.1097, 2.9075, 3.1622, 3.0716]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.0974, 3.2544, 3.0484, 3.3525, 3.2324],\n",
      "        [3.2374, 3.3403, 3.2129, 3.3515, 3.3946],\n",
      "        [2.9918, 3.0137, 3.1096, 3.1663, 3.1399],\n",
      "        [2.9398, 3.1988, 3.0982, 3.0347, 3.1701],\n",
      "        [3.1430, 3.0405, 3.0620, 3.1526, 3.1360],\n",
      "        [3.0735, 3.2027, 3.1244, 3.2023, 3.0556],\n",
      "        [2.9971, 3.1570, 2.9679, 3.0736, 3.1242],\n",
      "        [2.7781, 2.9506, 2.8789, 2.9075, 2.9418],\n",
      "        [2.8927, 3.1160, 2.8983, 3.1174, 2.9713],\n",
      "        [2.9456, 2.9942, 3.0143, 3.0981, 3.0694],\n",
      "        [2.8945, 3.0429, 2.9040, 3.0256, 3.0266],\n",
      "        [3.0672, 3.0452, 3.0848, 3.1767, 3.0971],\n",
      "        [2.9324, 3.2793, 3.0542, 3.2217, 3.2375],\n",
      "        [2.8292, 3.0519, 2.9995, 3.0200, 3.0048],\n",
      "        [3.0954, 3.2523, 3.0475, 3.3515, 3.2292],\n",
      "        [2.9824, 3.1110, 2.9062, 3.1552, 3.0742],\n",
      "        [3.1970, 3.1073, 3.1722, 3.3798, 3.2140],\n",
      "        [3.1130, 3.1307, 3.1536, 3.2757, 3.0317],\n",
      "        [2.8661, 2.9243, 2.9453, 3.0260, 2.9655],\n",
      "        [3.0515, 3.0324, 3.1756, 3.2553, 3.0956],\n",
      "        [2.9603, 3.0875, 2.8985, 3.1299, 3.0527],\n",
      "        [3.1542, 3.2122, 3.1898, 3.3003, 3.1862],\n",
      "        [3.2979, 3.1977, 3.2453, 3.4927, 3.3277],\n",
      "        [2.8082, 2.8959, 2.9319, 2.9781, 2.8951],\n",
      "        [3.4060, 3.1404, 3.2453, 3.7671, 3.6658],\n",
      "        [3.1222, 3.0843, 3.0732, 3.0879, 3.0092],\n",
      "        [3.2237, 3.1118, 3.1838, 3.3402, 3.2457],\n",
      "        [3.1690, 3.2583, 3.2402, 3.2483, 3.1234],\n",
      "        [2.9474, 2.9357, 2.9846, 3.0792, 3.1527],\n",
      "        [3.2745, 3.1947, 3.2204, 3.4601, 3.3330],\n",
      "        [2.9633, 2.9754, 3.0317, 3.0948, 3.0668],\n",
      "        [3.1103, 2.9448, 2.9525, 3.0928, 3.0827],\n",
      "        [2.9591, 3.0066, 3.0384, 2.9905, 2.8918],\n",
      "        [2.9597, 3.0722, 2.9374, 3.1056, 3.0806],\n",
      "        [2.7870, 3.0716, 3.1125, 2.9825, 3.0997],\n",
      "        [3.0036, 3.0563, 3.0946, 3.1549, 3.2095],\n",
      "        [2.7752, 3.0336, 2.7927, 3.0215, 2.8866],\n",
      "        [3.1582, 3.2945, 3.2384, 3.2466, 3.0509],\n",
      "        [3.1421, 3.1603, 3.1485, 3.3495, 3.1964],\n",
      "        [2.6656, 2.8644, 2.8978, 2.8795, 2.9219],\n",
      "        [2.9305, 3.0529, 3.0073, 3.1708, 3.0868],\n",
      "        [2.8654, 2.9194, 2.9449, 3.0236, 2.9630],\n",
      "        [3.1090, 3.2230, 3.0754, 3.1816, 3.1643],\n",
      "        [3.1888, 3.1949, 3.1816, 3.3899, 3.2411],\n",
      "        [3.1877, 3.1782, 3.1769, 3.3561, 3.2392],\n",
      "        [2.9657, 3.0720, 2.9416, 3.1782, 3.0882],\n",
      "        [2.9190, 2.9606, 3.0077, 3.0610, 3.0467],\n",
      "        [3.0872, 3.2038, 3.0632, 3.1017, 3.1438],\n",
      "        [2.9561, 3.0822, 2.9074, 3.1142, 3.0626],\n",
      "        [2.8495, 2.9495, 2.9589, 3.0169, 2.9797],\n",
      "        [2.8292, 3.0519, 2.9995, 3.0200, 3.0048],\n",
      "        [2.8255, 3.0700, 3.0032, 3.0117, 3.0083],\n",
      "        [3.0351, 3.1632, 2.9824, 3.1866, 3.1623],\n",
      "        [2.8544, 2.9394, 2.9607, 3.0341, 2.9739],\n",
      "        [3.1230, 3.2460, 3.0384, 3.1982, 3.2484],\n",
      "        [3.0974, 3.2544, 3.0484, 3.3525, 3.2324],\n",
      "        [2.9051, 3.0504, 3.0459, 3.0991, 3.2014],\n",
      "        [3.0811, 3.2902, 3.1745, 3.2864, 3.3221],\n",
      "        [3.0222, 2.9719, 3.0383, 3.1419, 3.0520],\n",
      "        [3.1034, 3.2510, 3.1289, 3.2746, 3.1928],\n",
      "        [3.1021, 3.0757, 3.0715, 3.0698, 2.9896],\n",
      "        [3.3755, 3.4925, 3.0728, 3.3077, 3.1658],\n",
      "        [3.4940, 3.6935, 3.2753, 3.4581, 3.3046],\n",
      "        [3.0058, 3.1467, 2.9345, 3.0863, 3.1115]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.8212, 3.0802, 3.0108, 3.0094, 3.0102],\n",
      "        [3.0705, 2.9961, 3.2463, 3.2210, 3.2311],\n",
      "        [3.0001, 3.0182, 3.0933, 3.1321, 3.1341],\n",
      "        [2.8497, 3.0337, 2.9091, 3.0013, 3.0079],\n",
      "        [2.9675, 2.9899, 2.9622, 3.1575, 3.0122],\n",
      "        [3.0915, 3.3148, 3.0838, 3.0586, 3.2018],\n",
      "        [3.1155, 3.2455, 3.0294, 3.1981, 3.2370],\n",
      "        [2.9614, 3.0110, 3.0287, 3.1085, 3.0806],\n",
      "        [3.1167, 3.2776, 3.1646, 3.2811, 3.2064],\n",
      "        [3.0647, 3.2251, 3.0215, 3.3181, 3.1878],\n",
      "        [2.9563, 3.0395, 3.0224, 3.0988, 3.2227],\n",
      "        [2.9957, 3.0174, 3.1123, 3.1707, 3.1432],\n",
      "        [3.2014, 3.2871, 3.1182, 3.3010, 3.3696],\n",
      "        [2.9792, 3.2389, 3.0082, 2.9674, 3.1646],\n",
      "        [3.0610, 3.1345, 3.0040, 3.1654, 3.2974],\n",
      "        [3.0975, 3.1151, 3.1135, 3.1539, 3.0197],\n",
      "        [3.2839, 3.1793, 3.2294, 3.4842, 3.3545],\n",
      "        [2.9563, 3.0395, 3.0224, 3.0988, 3.2227],\n",
      "        [2.8657, 2.9928, 3.0110, 3.0440, 2.9891],\n",
      "        [2.9410, 2.9296, 3.0273, 3.0769, 3.0369],\n",
      "        [2.9154, 3.0519, 2.9396, 3.0723, 3.0630],\n",
      "        [2.8902, 3.0193, 2.9028, 3.0852, 2.9879],\n",
      "        [3.1138, 2.9484, 2.9551, 3.0970, 3.0861],\n",
      "        [2.9862, 3.0842, 3.1936, 3.1837, 3.2340],\n",
      "        [2.8120, 2.8995, 2.9345, 2.9823, 2.8984],\n",
      "        [3.0066, 3.0264, 3.1044, 3.1424, 3.1405],\n",
      "        [2.9173, 3.0160, 2.7989, 3.1379, 2.9095],\n",
      "        [2.9537, 3.1211, 3.0661, 3.1093, 3.2004],\n",
      "        [3.1758, 3.3325, 3.2632, 3.2885, 3.1028],\n",
      "        [2.8617, 2.9239, 2.9472, 3.0322, 2.9665],\n",
      "        [2.9801, 3.1019, 3.0341, 3.1288, 3.1271],\n",
      "        [3.1039, 3.2559, 3.0255, 3.1908, 3.2206],\n",
      "        [3.2992, 3.3823, 3.2607, 3.5635, 3.3770],\n",
      "        [3.2482, 3.1178, 3.2006, 3.3754, 3.2693],\n",
      "        [3.1122, 3.2647, 3.0878, 3.2755, 3.2113],\n",
      "        [3.3060, 3.2541, 3.1787, 3.3683, 3.3185],\n",
      "        [3.1407, 3.3994, 3.1864, 3.4288, 3.3791],\n",
      "        [3.1909, 3.2085, 3.1354, 3.2594, 3.2530],\n",
      "        [2.8915, 2.9634, 3.0031, 3.0970, 3.0663],\n",
      "        [3.0131, 3.0815, 3.0325, 3.1518, 3.1732],\n",
      "        [2.9546, 2.9837, 2.8863, 3.0636, 3.1383],\n",
      "        [2.8809, 2.9197, 2.9441, 3.0373, 2.9700],\n",
      "        [3.4522, 3.5926, 3.2109, 3.3637, 3.2350],\n",
      "        [2.8604, 3.0262, 3.0607, 3.0651, 2.9778],\n",
      "        [2.9722, 2.9743, 2.9426, 3.1750, 2.9896],\n",
      "        [3.2493, 3.2223, 3.1856, 3.4435, 3.3242],\n",
      "        [3.0208, 3.2370, 3.0137, 2.9860, 3.0950],\n",
      "        [3.1714, 3.1999, 3.1296, 3.2350, 3.2513],\n",
      "        [2.9315, 3.0609, 2.8930, 3.0875, 3.0262],\n",
      "        [3.1106, 3.2739, 3.0838, 3.2598, 3.2084],\n",
      "        [3.0277, 2.8934, 3.1486, 3.1890, 3.1762],\n",
      "        [3.0976, 3.1927, 3.2172, 3.2924, 3.3047],\n",
      "        [2.9644, 2.9730, 3.0435, 3.0954, 3.0612],\n",
      "        [3.2801, 3.2273, 3.2719, 3.4965, 3.3308],\n",
      "        [3.0684, 3.1353, 3.0064, 3.1686, 3.2834],\n",
      "        [2.8112, 2.9824, 2.8942, 2.9433, 2.9669],\n",
      "        [2.9535, 2.9898, 3.0265, 3.1067, 3.0773],\n",
      "        [2.9868, 3.2450, 3.0021, 3.2747, 3.1720],\n",
      "        [3.1038, 3.1318, 3.1191, 3.1601, 3.0066],\n",
      "        [3.3017, 3.2017, 3.2487, 3.4975, 3.3313],\n",
      "        [3.1579, 3.1232, 3.0947, 3.1364, 3.0573],\n",
      "        [2.8265, 2.9981, 2.8945, 2.9634, 2.9777],\n",
      "        [3.2149, 3.2402, 3.1920, 3.4130, 3.2341],\n",
      "        [2.9207, 3.0470, 3.0890, 3.1786, 3.2280]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.0093, 3.1366, 2.9026, 3.0814, 3.0918],\n",
      "        [3.3261, 3.3230, 3.2213, 3.4400, 3.3748],\n",
      "        [2.9316, 3.0691, 2.9029, 3.0887, 3.0347],\n",
      "        [3.0782, 3.3940, 3.2111, 3.3008, 3.3475],\n",
      "        [2.9547, 2.9914, 2.9761, 3.1451, 3.0025],\n",
      "        [2.9583, 2.9526, 3.0133, 3.0504, 3.0285],\n",
      "        [2.8800, 2.8888, 2.9270, 3.0475, 2.9460],\n",
      "        [3.5288, 3.6857, 3.2844, 3.4371, 3.3047],\n",
      "        [2.9064, 2.9683, 3.0033, 3.0932, 3.0707],\n",
      "        [2.8694, 3.0193, 3.0473, 3.0765, 2.9741],\n",
      "        [2.8306, 3.0701, 3.0091, 3.0244, 3.0169],\n",
      "        [3.2770, 3.2595, 3.1710, 3.3457, 3.3217],\n",
      "        [2.8874, 3.0125, 3.0330, 3.0787, 2.9800],\n",
      "        [2.9198, 3.0610, 2.9085, 3.0508, 3.0403],\n",
      "        [3.0631, 3.1706, 3.0164, 3.2104, 3.2327],\n",
      "        [3.2393, 2.9646, 3.1056, 3.5093, 3.4476],\n",
      "        [2.9714, 3.1660, 3.0346, 3.0735, 3.1528],\n",
      "        [2.8358, 2.9733, 2.9650, 3.0066, 2.9725],\n",
      "        [2.9999, 3.1240, 2.9222, 3.1763, 3.0903],\n",
      "        [2.9989, 2.9398, 3.0146, 3.0220, 3.0061],\n",
      "        [3.0917, 3.3953, 3.1974, 3.3114, 3.3753],\n",
      "        [3.1117, 3.1479, 3.1190, 3.1743, 2.9964],\n",
      "        [2.9078, 3.2594, 3.0529, 3.1728, 3.2360],\n",
      "        [3.0829, 3.2606, 3.1658, 3.2753, 3.2752],\n",
      "        [2.9715, 3.0939, 2.9086, 3.1289, 3.0690],\n",
      "        [3.1065, 3.2618, 3.0538, 3.3611, 3.2391],\n",
      "        [3.0742, 3.2408, 3.0327, 3.2068, 3.1797],\n",
      "        [3.0152, 3.3643, 3.0602, 3.3350, 3.2753],\n",
      "        [2.8860, 3.2541, 3.1225, 3.1303, 3.2580],\n",
      "        [3.2420, 3.2431, 3.2312, 3.4386, 3.3129],\n",
      "        [3.1286, 3.2989, 3.1772, 3.2761, 3.1991],\n",
      "        [3.1188, 3.1560, 3.2071, 3.2128, 3.0800],\n",
      "        [2.8560, 3.0318, 3.0259, 3.0535, 3.0014],\n",
      "        [2.9414, 3.2867, 3.0596, 3.2302, 3.2441],\n",
      "        [3.3995, 3.5048, 3.0998, 3.3324, 3.1738],\n",
      "        [2.8592, 2.9312, 2.9500, 3.0202, 2.9655],\n",
      "        [2.9740, 2.9844, 2.9525, 3.1740, 3.0047],\n",
      "        [2.9668, 3.0860, 2.9092, 3.1080, 3.0717],\n",
      "        [2.8830, 2.9470, 2.8354, 3.0811, 2.8990],\n",
      "        [3.1861, 3.3423, 3.2717, 3.2974, 3.1201],\n",
      "        [3.2035, 3.0854, 3.0661, 3.1989, 3.2111],\n",
      "        [3.1174, 3.1852, 3.1683, 3.2802, 3.1124],\n",
      "        [2.9707, 3.0497, 3.0332, 3.0985, 3.2478],\n",
      "        [2.8742, 3.0319, 2.9055, 3.0140, 3.0132],\n",
      "        [2.9028, 3.0110, 2.9945, 3.0134, 3.0208],\n",
      "        [3.1202, 3.2535, 3.0273, 3.1988, 3.2326],\n",
      "        [2.8798, 2.9891, 2.9946, 2.9939, 3.0011],\n",
      "        [2.9820, 2.9597, 3.0596, 3.1198, 3.1538],\n",
      "        [3.2840, 3.3659, 3.2602, 3.5488, 3.3484],\n",
      "        [3.0615, 3.2735, 3.1737, 3.2640, 3.1571],\n",
      "        [3.3107, 3.2576, 3.1813, 3.3724, 3.3218],\n",
      "        [2.8706, 2.9962, 3.0134, 3.0479, 2.9923],\n",
      "        [3.1552, 3.2808, 3.2548, 3.2379, 3.0428],\n",
      "        [2.9559, 2.9428, 2.9898, 3.0875, 3.1592],\n",
      "        [2.9688, 2.9789, 3.0366, 3.1084, 3.0677],\n",
      "        [3.2003, 3.1980, 3.1821, 3.3916, 3.2515],\n",
      "        [2.8401, 2.9192, 2.9414, 2.9966, 2.9483],\n",
      "        [3.2485, 3.2487, 3.2294, 3.4256, 3.3209],\n",
      "        [3.1723, 3.3624, 3.1363, 3.1269, 3.2126],\n",
      "        [2.8160, 2.9857, 2.8966, 2.9470, 2.9700],\n",
      "        [2.9820, 3.1011, 2.9065, 3.1475, 3.0695],\n",
      "        [3.1079, 3.2576, 3.0462, 3.3507, 3.2254],\n",
      "        [2.8288, 2.9888, 2.8932, 2.9641, 2.9727],\n",
      "        [2.9888, 3.1070, 3.0450, 3.1082, 3.1085]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.0744, 3.0531, 3.0634, 3.0684, 2.9548],\n",
      "        [3.1098, 3.2466, 3.0592, 3.2025, 3.1939],\n",
      "        [3.1729, 3.2228, 3.2332, 3.4038, 3.1832],\n",
      "        [3.0058, 3.1278, 2.9245, 3.1797, 3.0931],\n",
      "        [3.1277, 3.2332, 3.1565, 3.1661, 3.2129],\n",
      "        [2.8179, 2.9889, 2.8950, 2.9588, 2.9760],\n",
      "        [3.1492, 3.2149, 3.2074, 3.3886, 3.1720],\n",
      "        [3.1244, 3.2933, 3.0969, 3.2595, 3.2170],\n",
      "        [3.1067, 3.1492, 2.9530, 3.2711, 3.2625],\n",
      "        [2.8934, 3.0163, 3.0353, 3.0821, 2.9829],\n",
      "        [3.2904, 3.3807, 3.2537, 3.3988, 3.4387],\n",
      "        [3.0107, 3.1985, 3.0361, 3.1372, 3.1757],\n",
      "        [2.8387, 3.1184, 2.8591, 3.0840, 2.9481],\n",
      "        [2.9361, 3.1513, 3.0918, 3.1185, 3.1095],\n",
      "        [2.9977, 3.0118, 3.0794, 3.1275, 3.1277],\n",
      "        [2.9374, 3.1945, 3.1260, 3.0772, 3.3153],\n",
      "        [2.8458, 3.1009, 3.0218, 3.0398, 3.0403],\n",
      "        [2.9369, 3.1571, 3.1026, 3.1195, 3.1236],\n",
      "        [3.0397, 2.9870, 3.0560, 3.1470, 3.0908],\n",
      "        [3.1613, 3.1778, 3.1781, 3.3645, 3.2066],\n",
      "        [3.0093, 2.9956, 3.1089, 3.1871, 3.2107],\n",
      "        [2.8362, 3.0310, 2.9894, 3.0118, 2.9884],\n",
      "        [2.9214, 2.9220, 2.9595, 3.0592, 2.9659],\n",
      "        [3.1266, 3.3215, 3.2600, 3.3055, 3.1319],\n",
      "        [2.9688, 3.0026, 3.0259, 3.1161, 3.0893],\n",
      "        [3.2825, 3.2636, 3.1735, 3.3494, 3.3248],\n",
      "        [2.7391, 2.9229, 2.9224, 2.9395, 2.9616],\n",
      "        [3.0170, 3.2847, 3.1911, 3.2652, 3.2830],\n",
      "        [3.0985, 3.0776, 3.0724, 3.0594, 2.9804],\n",
      "        [2.8548, 2.9673, 2.9712, 3.0196, 2.9786],\n",
      "        [2.9606, 2.9953, 2.9784, 3.1485, 3.0054],\n",
      "        [3.0997, 3.0613, 3.1163, 3.2242, 3.1312],\n",
      "        [2.9576, 3.1222, 3.0597, 3.1070, 3.2062],\n",
      "        [3.1244, 3.2990, 3.1809, 3.2817, 3.2118],\n",
      "        [2.9805, 3.0858, 2.9445, 3.1117, 3.0980],\n",
      "        [3.2453, 2.9685, 3.1080, 3.5129, 3.4504],\n",
      "        [2.9800, 3.0248, 3.0587, 3.1345, 3.1037],\n",
      "        [2.9790, 2.9832, 3.0519, 3.1074, 3.0733],\n",
      "        [2.9954, 3.0168, 3.0807, 3.1504, 3.1097],\n",
      "        [2.8898, 2.9957, 3.0312, 3.1388, 3.1032],\n",
      "        [3.0300, 3.2157, 3.0683, 3.1401, 3.1805],\n",
      "        [2.8628, 3.0224, 2.9081, 2.9943, 3.0022],\n",
      "        [2.9990, 3.1199, 2.9091, 3.1671, 3.0817],\n",
      "        [3.0117, 3.2145, 3.0773, 3.1547, 3.0141],\n",
      "        [3.0069, 3.1297, 2.8871, 3.0760, 3.0829],\n",
      "        [3.2916, 3.4128, 3.2651, 3.5931, 3.4377],\n",
      "        [2.8905, 2.9014, 2.9310, 3.0498, 2.9591],\n",
      "        [3.0487, 3.2129, 3.1001, 3.1785, 3.0366],\n",
      "        [3.1260, 3.3025, 3.1781, 3.2799, 3.2096],\n",
      "        [3.1505, 3.4391, 3.1379, 3.4315, 3.3800],\n",
      "        [3.3162, 3.2616, 3.1837, 3.3760, 3.3249],\n",
      "        [3.3664, 3.5077, 3.2272, 3.3120, 3.3000],\n",
      "        [2.9154, 3.1588, 3.0314, 3.1278, 3.2448],\n",
      "        [3.0826, 3.0445, 3.0984, 3.0799, 3.1191],\n",
      "        [2.8178, 3.0737, 3.0929, 3.0248, 3.1261],\n",
      "        [2.8789, 3.1077, 3.1828, 3.0911, 3.1659],\n",
      "        [3.0346, 3.0467, 3.1280, 3.1863, 3.1686],\n",
      "        [3.1307, 2.9611, 2.9654, 3.0889, 3.1304],\n",
      "        [2.8769, 2.9210, 2.9453, 3.0327, 2.9679],\n",
      "        [2.9125, 2.9722, 3.0057, 3.0967, 3.0735],\n",
      "        [2.8315, 3.0290, 2.9902, 3.0149, 2.9830],\n",
      "        [2.9750, 3.0931, 2.9082, 3.1265, 3.0716],\n",
      "        [3.3022, 3.4652, 3.2084, 3.2681, 3.2851],\n",
      "        [2.8725, 2.9951, 3.0095, 3.0544, 2.9836]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.9421, 3.1614, 3.1059, 3.1227, 3.1263],\n",
      "        [3.2438, 3.2167, 3.1193, 3.2856, 3.2391],\n",
      "        [3.2422, 3.1722, 3.1046, 3.2535, 3.2730],\n",
      "        [2.8531, 2.9661, 2.9665, 3.0178, 2.9745],\n",
      "        [3.0760, 3.0606, 3.0933, 3.1056, 3.0455],\n",
      "        [3.1866, 3.2119, 3.1377, 3.2458, 3.2603],\n",
      "        [3.2390, 3.3049, 3.1437, 3.3398, 3.3630],\n",
      "        [3.0335, 3.2596, 3.0901, 3.2296, 3.2947],\n",
      "        [3.1730, 3.1348, 3.1029, 3.1471, 3.0661],\n",
      "        [3.0736, 3.1469, 3.1241, 3.1829, 3.1735],\n",
      "        [3.0123, 3.0080, 3.1116, 3.1731, 3.1705],\n",
      "        [3.0869, 3.0078, 3.2546, 3.2319, 3.2399],\n",
      "        [3.0149, 3.1808, 2.9993, 3.0867, 3.1467],\n",
      "        [2.8831, 3.0287, 2.9061, 3.0198, 3.0051],\n",
      "        [2.8420, 3.0093, 2.9023, 2.9735, 2.9863],\n",
      "        [2.9825, 3.1742, 3.0403, 3.0802, 3.1584],\n",
      "        [3.1299, 3.1805, 3.1996, 3.2060, 3.0340],\n",
      "        [2.8978, 2.9553, 2.8481, 3.0878, 2.9376],\n",
      "        [3.1292, 3.0942, 3.0790, 3.0914, 3.0141],\n",
      "        [3.1618, 3.1865, 3.1384, 3.2397, 3.3084],\n",
      "        [3.0933, 3.1473, 3.0977, 3.1521, 2.9456],\n",
      "        [3.0795, 3.1541, 3.0425, 3.1718, 3.1231],\n",
      "        [2.9695, 2.9534, 3.0001, 3.0963, 3.1694],\n",
      "        [3.1437, 3.2618, 3.0499, 3.2137, 3.2607],\n",
      "        [2.9651, 2.9483, 3.0607, 2.9984, 3.1347],\n",
      "        [3.0615, 3.1131, 3.1446, 3.2194, 3.1497],\n",
      "        [3.0179, 3.0432, 3.0428, 3.1513, 3.1221],\n",
      "        [2.9657, 3.0098, 3.0252, 3.1132, 3.0813],\n",
      "        [3.2120, 3.1294, 3.1723, 3.3583, 3.2328],\n",
      "        [2.9708, 3.0464, 3.1159, 3.1210, 3.1977],\n",
      "        [2.8438, 3.1225, 2.8624, 3.0870, 2.9508],\n",
      "        [2.9550, 3.2249, 3.0516, 3.1086, 2.9951],\n",
      "        [3.0143, 3.2448, 3.0029, 3.1947, 3.1441],\n",
      "        [3.2106, 3.2175, 3.1996, 3.3995, 3.2590],\n",
      "        [3.1203, 3.2110, 3.1494, 3.1747, 3.2115],\n",
      "        [2.9511, 3.0595, 2.9520, 3.0433, 3.0323],\n",
      "        [3.3581, 3.5567, 3.0927, 3.2760, 3.2077],\n",
      "        [2.8875, 2.9084, 2.9374, 3.0500, 2.9606],\n",
      "        [3.0718, 3.0370, 3.0878, 3.0851, 3.0809],\n",
      "        [3.1318, 3.2620, 3.0332, 3.2057, 3.2382],\n",
      "        [2.9468, 3.0092, 3.0029, 3.1294, 3.0181],\n",
      "        [3.0915, 3.1870, 3.2247, 3.2773, 3.2623],\n",
      "        [2.9062, 2.9504, 2.9721, 3.0518, 2.9762],\n",
      "        [3.0969, 3.1944, 3.0212, 3.1824, 3.2976],\n",
      "        [2.8192, 2.8976, 2.9318, 2.9723, 2.8959],\n",
      "        [2.8096, 2.9118, 2.8934, 2.9428, 2.9364],\n",
      "        [2.8678, 3.0266, 2.9112, 2.9974, 3.0048],\n",
      "        [2.9615, 3.0878, 2.9136, 3.0906, 3.0609],\n",
      "        [2.8438, 3.1225, 2.8624, 3.0870, 2.9508],\n",
      "        [3.1299, 3.2955, 3.1799, 3.2742, 3.1962],\n",
      "        [3.1075, 3.2307, 3.1688, 3.2763, 3.2042],\n",
      "        [3.4050, 3.5744, 3.1566, 3.3220, 3.2196],\n",
      "        [2.8870, 2.8820, 2.9263, 3.0473, 2.9449],\n",
      "        [2.8801, 2.8844, 2.9206, 3.0408, 2.9460],\n",
      "        [3.1544, 3.2193, 3.2108, 3.3919, 3.1748],\n",
      "        [3.0536, 3.2044, 3.0389, 3.2305, 3.1556],\n",
      "        [3.1333, 3.2853, 3.0980, 3.2763, 3.2245],\n",
      "        [2.9485, 3.0540, 3.0060, 3.1414, 3.1480],\n",
      "        [2.8881, 3.1718, 2.9324, 2.8838, 3.1027],\n",
      "        [3.0712, 3.0401, 3.0877, 3.0900, 3.0668],\n",
      "        [2.8554, 2.9575, 2.9237, 3.0045, 2.9760],\n",
      "        [2.9820, 3.0539, 3.0400, 3.1053, 3.2530],\n",
      "        [3.1219, 3.1621, 3.1945, 3.2029, 3.0457],\n",
      "        [2.8827, 2.9290, 2.9475, 3.0394, 2.9722]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5210, 3.7139, 3.2917, 3.4774, 3.3212],\n",
      "        [2.8858, 3.0373, 2.9098, 3.0166, 3.0070],\n",
      "        [2.9050, 3.2675, 3.1327, 3.1401, 3.2672],\n",
      "        [3.0490, 3.2243, 3.0962, 3.1802, 3.0369],\n",
      "        [3.1713, 3.3639, 3.1567, 3.3987, 3.3153],\n",
      "        [3.4131, 3.1722, 3.2954, 3.8375, 3.6823],\n",
      "        [3.1613, 3.2684, 3.1761, 3.1879, 3.2341],\n",
      "        [2.8551, 2.9657, 2.9670, 3.0174, 2.9733],\n",
      "        [2.9547, 3.0137, 3.0069, 3.1322, 3.0214],\n",
      "        [2.9822, 3.0153, 2.9967, 3.0743, 3.1241],\n",
      "        [2.9226, 3.0018, 3.0145, 3.0980, 2.9929],\n",
      "        [2.9954, 3.1922, 3.0249, 3.2552, 3.0972],\n",
      "        [2.8740, 3.2507, 3.0884, 3.0917, 3.2551],\n",
      "        [2.9892, 2.9896, 3.0532, 3.1148, 3.0738],\n",
      "        [3.0496, 3.1486, 2.9973, 3.1879, 3.2079],\n",
      "        [3.2273, 3.1423, 3.1954, 3.3688, 3.2277],\n",
      "        [3.1194, 3.1189, 3.1887, 3.1723, 2.9813],\n",
      "        [2.9869, 3.1093, 3.0557, 3.0915, 3.0121],\n",
      "        [3.0312, 3.0378, 3.1179, 3.1675, 3.1486],\n",
      "        [3.0099, 3.0182, 3.0614, 3.1009, 3.1365],\n",
      "        [2.9956, 3.0097, 3.0471, 3.1180, 3.0967],\n",
      "        [3.1063, 3.2055, 3.1894, 3.2281, 3.2025],\n",
      "        [3.1552, 3.1661, 3.3124, 3.1697, 3.1126],\n",
      "        [3.0487, 2.9836, 3.0481, 3.1484, 3.0555],\n",
      "        [2.9399, 2.9971, 2.9952, 3.1241, 3.0005],\n",
      "        [2.8849, 2.9747, 2.9927, 3.0495, 2.9679],\n",
      "        [3.2728, 3.1347, 3.2145, 3.3898, 3.2817],\n",
      "        [2.9370, 3.1168, 2.9554, 3.1844, 3.0245],\n",
      "        [2.8793, 2.9467, 2.9603, 3.0289, 2.9779],\n",
      "        [2.8935, 2.8915, 2.9275, 3.0444, 2.9511],\n",
      "        [3.1261, 3.2749, 3.0638, 3.3709, 3.2482],\n",
      "        [2.9284, 3.0705, 3.0076, 3.1916, 3.0211],\n",
      "        [2.9025, 2.9509, 2.8510, 3.0933, 2.9653],\n",
      "        [2.9382, 3.0731, 2.9094, 3.0804, 3.0408],\n",
      "        [2.9638, 3.0901, 2.9136, 3.1149, 3.0520],\n",
      "        [3.1547, 3.2988, 3.1886, 3.2782, 3.2005],\n",
      "        [3.0466, 2.9988, 3.0592, 3.1629, 3.1046],\n",
      "        [3.1380, 3.2966, 3.0493, 3.1975, 3.2295],\n",
      "        [3.2013, 3.0638, 3.0779, 3.5062, 3.3335],\n",
      "        [3.1195, 3.2622, 3.0263, 3.1962, 3.2245],\n",
      "        [2.9152, 3.0105, 2.9141, 3.0844, 2.9964],\n",
      "        [3.1376, 3.3082, 3.1885, 3.2879, 3.2180],\n",
      "        [3.1208, 3.1535, 3.0788, 3.2788, 3.2852],\n",
      "        [3.1396, 3.1601, 3.1960, 3.2151, 3.0945],\n",
      "        [3.0073, 3.1198, 3.0547, 3.1178, 3.1176],\n",
      "        [2.9983, 3.0857, 2.9539, 3.1850, 3.0944],\n",
      "        [2.9570, 3.0243, 2.9392, 3.1390, 3.0340],\n",
      "        [2.9891, 2.9989, 3.0357, 3.1130, 3.0882],\n",
      "        [3.4356, 3.1615, 3.2613, 3.7866, 3.6813],\n",
      "        [2.8787, 2.9665, 2.9920, 3.0472, 2.9621],\n",
      "        [2.8330, 3.0811, 3.1121, 3.0366, 3.0955],\n",
      "        [3.0839, 3.0653, 3.0974, 3.1085, 3.0489],\n",
      "        [2.9800, 3.0251, 3.0359, 3.1244, 3.0913],\n",
      "        [2.9511, 3.0297, 3.0015, 3.0499, 3.0569],\n",
      "        [2.8588, 3.1097, 3.0292, 3.0457, 3.0464],\n",
      "        [2.9025, 2.9565, 2.8480, 3.0883, 2.9192],\n",
      "        [3.2083, 3.1931, 3.2302, 3.3377, 3.1308],\n",
      "        [3.1623, 3.0507, 3.0493, 3.4898, 3.2903],\n",
      "        [2.9577, 3.0547, 3.0117, 3.1307, 3.1712],\n",
      "        [3.0817, 3.1017, 3.0697, 3.1813, 3.1057],\n",
      "        [2.9387, 3.0677, 2.9515, 3.0853, 3.0748],\n",
      "        [3.3101, 3.1424, 3.2221, 3.7518, 3.6073],\n",
      "        [2.8877, 3.0779, 2.8952, 3.0898, 3.0074],\n",
      "        [2.9933, 3.0945, 2.9516, 3.1176, 3.1039]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.9141, 2.9066, 2.9420, 3.0592, 2.9654],\n",
      "        [3.1822, 3.1915, 3.1900, 3.3744, 3.2160],\n",
      "        [2.9741, 3.0567, 3.1352, 3.2285, 3.2617],\n",
      "        [3.1170, 3.1669, 3.1146, 3.1643, 2.9605],\n",
      "        [2.9395, 3.1111, 2.9923, 3.1723, 3.0500],\n",
      "        [2.9970, 3.0669, 3.0468, 3.1115, 3.2601],\n",
      "        [2.8927, 3.0079, 3.0205, 3.0635, 2.9927],\n",
      "        [2.9977, 3.0239, 3.0801, 3.1455, 3.1125],\n",
      "        [2.9865, 3.3233, 3.1870, 3.1960, 3.1326],\n",
      "        [2.9666, 3.0792, 3.1995, 3.1472, 3.2228],\n",
      "        [2.9231, 3.2089, 3.0099, 3.0484, 2.9823],\n",
      "        [3.1349, 3.2543, 3.1757, 3.2162, 3.0626],\n",
      "        [2.8590, 3.1056, 3.0296, 3.0308, 3.0304],\n",
      "        [3.0738, 3.1198, 3.0760, 3.1737, 3.1311],\n",
      "        [2.9696, 3.0046, 3.0465, 3.1360, 3.1672],\n",
      "        [2.9231, 3.2245, 3.0863, 3.1560, 3.2195],\n",
      "        [3.3130, 3.3868, 3.2053, 3.6008, 3.4169],\n",
      "        [3.3276, 3.4243, 3.2865, 3.5971, 3.4305],\n",
      "        [2.9675, 3.2374, 3.0616, 3.1193, 3.0118],\n",
      "        [3.2159, 3.1975, 3.2342, 3.3412, 3.1339],\n",
      "        [2.9142, 3.0434, 2.9114, 3.0385, 3.0164],\n",
      "        [2.9032, 3.1804, 2.9402, 2.8899, 3.1090],\n",
      "        [3.0377, 3.0658, 3.0728, 3.0518, 2.9520],\n",
      "        [3.3684, 3.1679, 3.2441, 3.7860, 3.6070],\n",
      "        [3.0033, 3.1214, 2.9253, 3.1570, 3.0836],\n",
      "        [2.8888, 2.9787, 2.9395, 3.0343, 2.9944],\n",
      "        [3.0987, 3.1268, 3.1866, 3.2521, 3.1544],\n",
      "        [3.1337, 3.2792, 3.0677, 3.3743, 3.2514],\n",
      "        [3.0287, 3.1415, 2.9379, 3.1878, 3.1067],\n",
      "        [3.0498, 3.0575, 3.1450, 3.1897, 3.1652],\n",
      "        [2.8641, 3.0757, 3.0179, 3.0407, 3.0235],\n",
      "        [3.1638, 3.2183, 3.1494, 3.2770, 3.3101],\n",
      "        [2.9817, 3.0304, 3.1292, 3.0383, 3.2337],\n",
      "        [3.1560, 3.1084, 3.0916, 3.1091, 3.0278],\n",
      "        [2.9637, 3.0855, 2.9145, 3.0930, 3.0540],\n",
      "        [2.9441, 3.0675, 2.9096, 3.0687, 3.0303],\n",
      "        [2.8589, 3.0255, 2.9176, 3.0375, 2.9875],\n",
      "        [3.1155, 3.1067, 3.0311, 3.3396, 3.2224],\n",
      "        [2.9845, 3.0415, 2.9501, 3.1561, 3.0481],\n",
      "        [3.0357, 3.1534, 2.9162, 3.0941, 3.1037],\n",
      "        [2.8756, 3.0306, 2.9129, 3.0002, 3.0027],\n",
      "        [2.8950, 3.0829, 2.9597, 3.0566, 3.0748],\n",
      "        [3.2698, 3.2613, 3.2462, 3.4525, 3.3256],\n",
      "        [2.8660, 3.1138, 3.0330, 3.0489, 3.0495],\n",
      "        [3.2732, 3.1882, 3.2320, 3.4558, 3.2866],\n",
      "        [3.2990, 3.1354, 3.2168, 3.7350, 3.6031],\n",
      "        [2.8958, 3.0361, 3.0606, 3.0892, 2.9862],\n",
      "        [3.5875, 3.7364, 3.3192, 3.4909, 3.3486],\n",
      "        [3.1337, 3.2792, 3.0677, 3.3743, 3.2514],\n",
      "        [2.9786, 3.0249, 3.0392, 3.1306, 3.0924],\n",
      "        [2.8884, 2.9949, 2.9860, 3.0351, 3.0124],\n",
      "        [2.9928, 3.3386, 3.0469, 3.3221, 3.2409],\n",
      "        [3.0505, 3.2291, 3.0795, 3.1495, 3.1899],\n",
      "        [3.1908, 3.3347, 3.0557, 3.2185, 3.2278],\n",
      "        [2.9107, 3.0090, 3.0425, 3.1482, 3.1124],\n",
      "        [2.9708, 3.0344, 2.9783, 3.0424, 3.0788],\n",
      "        [2.9838, 3.0295, 3.1283, 3.0372, 3.2454],\n",
      "        [2.8170, 2.9915, 2.9321, 3.0168, 3.0084],\n",
      "        [3.0302, 3.1896, 3.0072, 3.0928, 3.1533],\n",
      "        [2.8562, 3.0537, 3.0067, 3.0341, 3.0127],\n",
      "        [3.1093, 3.2125, 3.1986, 3.2319, 3.2128],\n",
      "        [2.9925, 3.1025, 2.9224, 3.1205, 3.0834],\n",
      "        [3.0888, 3.1557, 3.1320, 3.1891, 3.1799],\n",
      "        [2.8614, 3.0375, 3.0021, 3.0350, 3.0125]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.9255, 3.1274, 3.0400, 2.9970, 3.0081],\n",
      "        [2.9130, 2.9204, 2.9500, 3.0611, 2.9767],\n",
      "        [2.9809, 3.0693, 2.9604, 3.0671, 3.0431],\n",
      "        [2.8301, 2.9859, 2.8083, 3.0440, 2.9254],\n",
      "        [3.0635, 3.2332, 3.1036, 3.1866, 3.0429],\n",
      "        [3.1368, 3.2185, 3.2380, 3.3131, 3.3231],\n",
      "        [2.9607, 3.2910, 3.1462, 3.2069, 3.2950],\n",
      "        [3.1844, 3.2002, 3.1498, 3.2490, 3.3184],\n",
      "        [3.1757, 3.3698, 3.1553, 3.3887, 3.3171],\n",
      "        [3.0008, 3.1605, 3.0133, 3.1621, 3.1732],\n",
      "        [3.2927, 3.3194, 3.1982, 3.4960, 3.3660],\n",
      "        [2.9650, 3.0381, 3.0086, 3.0560, 3.0627],\n",
      "        [3.2013, 3.3249, 3.2609, 3.2720, 3.0723],\n",
      "        [3.0659, 3.1284, 3.1063, 3.1656, 3.2372],\n",
      "        [3.1387, 3.2817, 3.0705, 3.3763, 3.2511],\n",
      "        [3.3614, 3.4789, 3.1018, 3.3067, 3.2193],\n",
      "        [3.0487, 3.1011, 3.0477, 3.1722, 3.1867],\n",
      "        [2.9857, 3.0139, 2.9947, 3.0695, 3.1159],\n",
      "        [2.8604, 3.0497, 3.0054, 3.0272, 3.0004],\n",
      "        [3.1214, 3.2528, 3.1764, 3.2810, 3.2393],\n",
      "        [2.9756, 3.1483, 3.0690, 3.1288, 3.1545],\n",
      "        [3.0271, 3.0126, 3.0734, 3.1482, 3.1636],\n",
      "        [3.1335, 3.0930, 3.1257, 3.2391, 3.1389],\n",
      "        [3.1103, 3.0625, 3.1131, 3.0925, 3.1309],\n",
      "        [2.9926, 3.0637, 2.9745, 3.0589, 3.0712],\n",
      "        [3.0653, 3.2929, 3.0058, 3.2061, 3.1502],\n",
      "        [2.8059, 2.9808, 2.9385, 2.9978, 3.0044],\n",
      "        [2.9933, 3.0108, 3.0325, 3.1138, 3.0873],\n",
      "        [3.1492, 3.2863, 3.1666, 3.3021, 3.2187],\n",
      "        [2.9830, 3.1006, 2.9247, 3.0994, 3.0700],\n",
      "        [3.1339, 3.1180, 3.1270, 3.1516, 3.0642],\n",
      "        [3.1449, 3.2410, 3.1851, 3.2925, 3.1914],\n",
      "        [3.0792, 3.1551, 3.0167, 3.2197, 3.1709],\n",
      "        [3.0116, 2.9781, 3.0773, 3.1441, 3.1923],\n",
      "        [3.2333, 3.0756, 3.0900, 3.5472, 3.3603],\n",
      "        [2.9779, 3.0837, 3.0260, 3.1696, 3.1419],\n",
      "        [3.1581, 3.4054, 3.2558, 3.3339, 3.3700],\n",
      "        [2.9697, 3.2502, 3.1577, 3.0570, 3.2068],\n",
      "        [3.1640, 3.2356, 3.2059, 3.3907, 3.1828],\n",
      "        [3.1488, 3.2646, 3.0907, 3.2865, 3.2160],\n",
      "        [2.8458, 3.0915, 3.1080, 3.0373, 3.1381],\n",
      "        [3.1566, 2.9783, 2.9795, 3.1008, 3.1427],\n",
      "        [3.1060, 3.1582, 3.1546, 3.2140, 3.1826],\n",
      "        [3.0887, 3.1480, 3.1529, 3.2193, 3.1477],\n",
      "        [2.8384, 3.0002, 2.9062, 2.9586, 2.9776],\n",
      "        [3.0207, 3.1130, 2.9703, 3.1451, 3.1219],\n",
      "        [3.0091, 3.0123, 3.0531, 3.1210, 3.0962],\n",
      "        [3.1577, 3.2116, 3.1604, 3.3085, 3.3160],\n",
      "        [2.9504, 2.9143, 2.9351, 3.0612, 2.9622],\n",
      "        [3.0063, 2.9776, 3.0754, 3.1467, 3.1865],\n",
      "        [3.1292, 3.1611, 3.0923, 3.2727, 3.2942],\n",
      "        [3.2729, 2.9863, 3.1226, 3.5254, 3.4619],\n",
      "        [3.1706, 3.2787, 3.2109, 3.2423, 3.0861],\n",
      "        [2.8606, 3.0647, 3.0094, 3.0249, 3.0057],\n",
      "        [3.2025, 3.2559, 3.2285, 3.3331, 3.2224],\n",
      "        [3.1770, 3.2331, 3.2226, 3.4013, 3.1846],\n",
      "        [3.4507, 3.5891, 3.2120, 3.3665, 3.2373],\n",
      "        [2.9644, 3.1749, 3.1174, 3.1319, 3.1358],\n",
      "        [3.0014, 2.9718, 3.0510, 3.1314, 3.1813],\n",
      "        [2.9538, 3.0455, 2.9445, 3.1433, 3.0611],\n",
      "        [3.2076, 3.3090, 3.1768, 3.2981, 3.3500],\n",
      "        [2.9941, 3.1043, 3.0387, 3.1154, 3.1209],\n",
      "        [3.2654, 3.0980, 3.1015, 3.5690, 3.3814],\n",
      "        [2.9914, 3.0939, 3.0283, 3.0697, 3.0996]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2013, 3.2313, 3.2290, 3.2658, 3.3087],\n",
      "        [3.5338, 3.7339, 3.2435, 3.4434, 3.3518],\n",
      "        [3.1607, 3.1011, 3.1575, 3.2779, 3.1687],\n",
      "        [3.2103, 3.2243, 3.3138, 3.2187, 3.0958],\n",
      "        [3.1539, 3.1013, 3.0590, 3.4311, 3.2835],\n",
      "        [3.0028, 3.1319, 3.0619, 3.0894, 3.0147],\n",
      "        [3.4191, 3.6310, 3.1628, 3.3575, 3.2124],\n",
      "        [3.0207, 3.3655, 3.1744, 3.1511, 3.1469],\n",
      "        [3.0796, 3.1049, 3.0422, 3.2227, 3.2409],\n",
      "        [3.2051, 3.3444, 3.0626, 3.2242, 3.2341],\n",
      "        [3.1287, 3.0912, 3.0597, 3.3421, 3.2103],\n",
      "        [3.0168, 3.0355, 2.9293, 3.1073, 3.1843],\n",
      "        [3.1301, 3.2448, 3.2037, 3.2674, 3.1946],\n",
      "        [2.8634, 3.0734, 3.0182, 3.0369, 3.0138],\n",
      "        [3.0430, 3.0011, 3.1117, 3.1910, 3.2128],\n",
      "        [2.8758, 2.9991, 2.9848, 3.0245, 2.9906],\n",
      "        [2.9157, 2.8996, 2.9403, 3.0586, 2.9573],\n",
      "        [3.1464, 3.2868, 3.0738, 3.3790, 3.2548],\n",
      "        [3.1660, 3.1933, 3.1414, 3.2287, 3.3073],\n",
      "        [3.0171, 3.0234, 3.0574, 3.1269, 3.1059],\n",
      "        [2.8990, 2.9795, 2.9818, 3.0411, 3.0044],\n",
      "        [2.9281, 3.0525, 2.9180, 3.0439, 3.0226],\n",
      "        [2.9625, 3.0530, 2.8517, 3.1628, 2.9572],\n",
      "        [2.9157, 2.8996, 2.9403, 3.0586, 2.9573],\n",
      "        [3.3005, 3.3246, 3.2018, 3.4989, 3.3696],\n",
      "        [2.9735, 2.9293, 3.0301, 3.1135, 3.1195],\n",
      "        [3.0074, 3.0411, 3.0514, 3.1311, 3.1018],\n",
      "        [2.9418, 3.0728, 2.9187, 3.0627, 3.0410],\n",
      "        [3.0247, 3.1337, 2.9319, 3.1680, 3.0963],\n",
      "        [3.1484, 3.2888, 3.0747, 3.3801, 3.2580],\n",
      "        [2.9562, 3.2258, 3.0337, 3.0777, 2.9940],\n",
      "        [2.8583, 3.0941, 3.1214, 3.0388, 3.0985],\n",
      "        [3.2854, 3.2782, 3.2475, 3.4542, 3.3267],\n",
      "        [3.0446, 3.1990, 3.0141, 3.0985, 3.1597],\n",
      "        [3.2349, 3.2719, 3.2294, 3.3136, 3.3623],\n",
      "        [3.1429, 3.3505, 3.1137, 3.2799, 3.2383],\n",
      "        [3.0305, 3.1323, 2.9252, 3.1741, 3.0878],\n",
      "        [3.0013, 3.0305, 3.0428, 3.1273, 3.0963],\n",
      "        [3.0539, 3.1797, 2.9649, 3.1042, 3.1321],\n",
      "        [2.8767, 3.0958, 2.9884, 3.0718, 3.1781],\n",
      "        [3.1585, 3.3576, 3.1228, 3.1055, 3.2332],\n",
      "        [3.0721, 3.0933, 3.0599, 3.2260, 3.1363],\n",
      "        [3.0110, 3.0360, 3.0232, 3.0982, 3.1412],\n",
      "        [2.9848, 3.2343, 3.1365, 3.0508, 3.1935],\n",
      "        [2.9949, 3.2222, 3.1071, 3.0683, 3.1896],\n",
      "        [2.9209, 2.9113, 2.9410, 3.0570, 2.9670],\n",
      "        [2.8330, 2.9958, 2.9060, 2.9417, 2.9702],\n",
      "        [3.2271, 3.3051, 3.1208, 3.3009, 3.3624],\n",
      "        [3.0150, 3.0111, 3.1132, 3.1684, 3.1185],\n",
      "        [3.0272, 3.1330, 2.9350, 3.1726, 3.0966],\n",
      "        [3.1514, 3.2485, 3.1024, 3.1418, 3.1809],\n",
      "        [3.0178, 3.0636, 3.0618, 3.1600, 3.1311],\n",
      "        [3.4023, 3.6030, 3.1434, 3.3321, 3.1994],\n",
      "        [2.8983, 2.9825, 2.9839, 3.0430, 3.0043],\n",
      "        [2.9791, 3.1262, 2.9824, 3.1583, 3.1573],\n",
      "        [3.1143, 3.4008, 3.1928, 3.3111, 3.4104],\n",
      "        [3.0173, 3.1330, 3.0085, 3.2076, 3.1506],\n",
      "        [3.1142, 3.0890, 3.0976, 3.1941, 3.1178],\n",
      "        [3.3995, 3.1893, 3.3074, 3.8149, 3.6855],\n",
      "        [3.1887, 3.1458, 3.1818, 3.3346, 3.1915],\n",
      "        [2.9138, 3.1303, 3.2009, 3.1061, 3.1812],\n",
      "        [2.8256, 2.9857, 2.9037, 2.9317, 2.9701],\n",
      "        [3.0106, 3.0125, 3.0460, 3.1218, 3.0974],\n",
      "        [3.1430, 3.2296, 3.0470, 3.2194, 3.3007]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2019, 3.0825, 3.0823, 3.4516, 3.2960],\n",
      "        [2.9860, 2.9543, 3.0767, 2.9816, 3.1493],\n",
      "        [2.9223, 2.9040, 2.9432, 3.0610, 2.9604],\n",
      "        [2.8691, 2.8727, 2.9163, 3.0693, 2.9538],\n",
      "        [3.2247, 3.3509, 3.2495, 3.3830, 3.3687],\n",
      "        [2.9538, 3.0789, 2.9323, 3.0609, 3.0631],\n",
      "        [3.0651, 3.2036, 3.0181, 3.2304, 3.1478],\n",
      "        [3.3993, 3.5094, 3.1134, 3.3318, 3.2095],\n",
      "        [3.0751, 3.1952, 3.0088, 3.2123, 3.1635],\n",
      "        [3.0315, 3.0379, 3.1071, 3.1692, 3.1416],\n",
      "        [2.9641, 3.0888, 2.9248, 3.0861, 3.0510],\n",
      "        [3.0109, 2.9883, 3.0743, 3.0423, 3.1462],\n",
      "        [3.1536, 3.2396, 3.0776, 3.2893, 3.2171],\n",
      "        [2.9490, 3.2483, 3.0933, 3.1658, 3.2495],\n",
      "        [3.0151, 3.0326, 3.0475, 3.1237, 3.0994],\n",
      "        [2.9316, 2.9751, 2.8683, 3.1009, 2.9092],\n",
      "        [2.9826, 3.0155, 3.0003, 3.1494, 3.0204],\n",
      "        [3.4437, 3.1915, 3.3098, 3.8496, 3.6951],\n",
      "        [3.0984, 3.2807, 3.1052, 3.3430, 3.2175],\n",
      "        [2.8620, 3.0153, 2.9191, 2.9670, 2.9911],\n",
      "        [2.9449, 2.9981, 3.0292, 3.1220, 3.0908],\n",
      "        [2.9630, 3.1375, 3.2450, 3.1251, 3.2698],\n",
      "        [2.9034, 3.0502, 2.9276, 3.0149, 3.0270],\n",
      "        [3.0565, 3.0278, 3.1349, 3.2211, 3.2324],\n",
      "        [2.8749, 3.0892, 3.0232, 3.0311, 3.0200],\n",
      "        [2.9468, 3.0356, 2.9307, 3.0966, 3.0111],\n",
      "        [3.0449, 3.2268, 3.0742, 3.2928, 3.1185],\n",
      "        [3.1362, 3.2626, 3.1828, 3.2862, 3.2462],\n",
      "        [2.9193, 3.1321, 2.8887, 3.0987, 2.9786],\n",
      "        [3.1391, 3.2301, 3.2093, 3.1928, 3.0956],\n",
      "        [2.9391, 2.9372, 2.9601, 3.0721, 2.9857],\n",
      "        [3.2656, 3.2495, 3.1553, 3.2998, 3.2720],\n",
      "        [3.0161, 3.1150, 3.0821, 3.1309, 3.0156],\n",
      "        [2.8825, 3.0035, 2.9878, 3.0269, 2.9938],\n",
      "        [2.8800, 3.0391, 2.9275, 3.0454, 2.9970],\n",
      "        [3.2493, 3.2304, 3.2073, 3.4137, 3.2737],\n",
      "        [3.0590, 3.1884, 2.9817, 3.1055, 3.1425],\n",
      "        [3.0803, 3.3946, 3.0937, 3.3638, 3.3056],\n",
      "        [3.1320, 3.0894, 3.1217, 3.2203, 3.1341],\n",
      "        [3.2401, 3.3625, 3.3092, 3.3379, 3.1424],\n",
      "        [3.0769, 3.0020, 3.0612, 3.1597, 3.0678],\n",
      "        [2.9843, 3.2598, 3.1641, 3.0623, 3.2138],\n",
      "        [2.8980, 2.9792, 2.9804, 3.0344, 2.9921],\n",
      "        [2.8648, 2.9780, 2.8521, 3.0507, 2.9272],\n",
      "        [3.1854, 3.1852, 3.3267, 3.1818, 3.1254],\n",
      "        [3.0153, 3.0885, 3.0197, 3.1124, 3.1052],\n",
      "        [2.8715, 3.0192, 2.9200, 2.9841, 3.0127],\n",
      "        [3.0802, 3.0171, 3.1869, 3.2459, 3.1525],\n",
      "        [3.1534, 3.2771, 3.1904, 3.2265, 3.0844],\n",
      "        [3.0196, 3.0111, 3.0851, 3.1256, 3.0935],\n",
      "        [3.3002, 3.1723, 3.1121, 3.2907, 3.2683],\n",
      "        [3.1151, 3.1697, 3.0303, 3.1909, 3.3219],\n",
      "        [2.9025, 3.0237, 3.0011, 3.0400, 3.0239],\n",
      "        [3.0284, 3.0364, 3.0686, 3.1309, 3.1448],\n",
      "        [3.0372, 3.2567, 3.1359, 3.2443, 3.3038],\n",
      "        [3.1502, 3.3727, 3.1212, 3.2847, 3.2362],\n",
      "        [3.2260, 3.3448, 3.2520, 3.3865, 3.3773],\n",
      "        [3.0667, 3.3764, 3.0923, 3.3584, 3.2985],\n",
      "        [3.1289, 3.1700, 3.1150, 3.1661, 2.9617],\n",
      "        [3.3137, 3.3292, 3.1869, 3.4035, 3.4250],\n",
      "        [3.0509, 3.2805, 2.9871, 3.1726, 3.1264],\n",
      "        [3.1222, 3.1703, 3.0326, 3.1940, 3.3078],\n",
      "        [3.2768, 3.3105, 3.1839, 3.4816, 3.3439],\n",
      "        [2.8814, 3.1074, 3.0313, 3.0403, 3.0366]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.0495, 3.0411, 3.1190, 3.1926, 3.1673],\n",
      "        [3.1245, 3.2868, 3.1372, 3.3573, 3.2227],\n",
      "        [2.8830, 3.0583, 3.1590, 3.0321, 3.1794],\n",
      "        [2.9229, 2.9406, 2.9594, 3.0585, 2.9794],\n",
      "        [2.9012, 2.9971, 2.9900, 3.0373, 2.9985],\n",
      "        [2.9817, 3.0890, 2.9233, 3.0976, 3.0476],\n",
      "        [3.1789, 3.3115, 3.1853, 3.3090, 3.2326],\n",
      "        [3.5434, 3.7021, 3.2953, 3.4621, 3.3127],\n",
      "        [3.0714, 3.0763, 3.1506, 3.1969, 3.1805],\n",
      "        [3.1163, 2.9650, 3.1900, 3.2173, 3.1711],\n",
      "        [2.9995, 3.0935, 3.0360, 3.1645, 3.1730],\n",
      "        [2.9957, 3.2533, 3.1436, 3.0806, 3.1853],\n",
      "        [3.1943, 3.3340, 3.0677, 3.2194, 3.2403],\n",
      "        [3.0574, 3.0275, 3.1324, 3.2082, 3.2321],\n",
      "        [2.9754, 3.0932, 2.9264, 3.0876, 3.0577],\n",
      "        [3.1457, 3.3048, 3.2146, 3.3186, 3.2080],\n",
      "        [3.1654, 3.2957, 3.0557, 3.2203, 3.2490],\n",
      "        [3.0186, 2.9955, 3.0485, 3.0728, 3.0608],\n",
      "        [3.0441, 3.1521, 2.9370, 3.1874, 3.1048],\n",
      "        [3.2104, 3.3176, 3.2811, 3.2635, 3.0674],\n",
      "        [3.1144, 3.0675, 3.1083, 3.1081, 3.0857],\n",
      "        [3.1601, 3.2956, 3.0800, 3.3853, 3.2613],\n",
      "        [3.3225, 3.1127, 3.1298, 3.6561, 3.4431],\n",
      "        [3.1255, 3.3799, 3.2262, 3.2976, 3.3438],\n",
      "        [2.8904, 3.0203, 3.0007, 3.0350, 3.0008],\n",
      "        [3.0941, 3.2986, 3.0954, 3.3390, 3.2222],\n",
      "        [3.0362, 3.1159, 2.9839, 3.2048, 3.1181],\n",
      "        [2.9094, 3.0470, 3.0387, 3.0781, 3.0109],\n",
      "        [2.8289, 2.9832, 2.9043, 2.9274, 2.9572],\n",
      "        [3.2110, 3.3416, 3.0569, 3.2109, 3.2280],\n",
      "        [2.9557, 3.0449, 3.0199, 3.0372, 3.0452],\n",
      "        [3.0999, 3.1419, 3.0888, 3.2153, 3.2239],\n",
      "        [3.0057, 3.1134, 3.0631, 3.2309, 3.0959],\n",
      "        [3.0351, 2.9999, 3.0943, 3.1670, 3.2057],\n",
      "        [3.0165, 3.0373, 3.0129, 3.0891, 3.1399],\n",
      "        [3.2798, 3.1570, 3.2200, 3.4122, 3.2612],\n",
      "        [2.9814, 3.0759, 3.1587, 3.1463, 3.1930],\n",
      "        [3.2842, 3.1993, 3.1248, 3.2711, 3.2933],\n",
      "        [2.9922, 3.0888, 2.9555, 3.1139, 3.0863],\n",
      "        [3.1309, 3.1655, 2.9785, 3.2805, 3.2612],\n",
      "        [3.0248, 3.0013, 3.0771, 3.1188, 3.0947],\n",
      "        [3.0297, 3.0309, 3.1226, 3.1762, 3.1404],\n",
      "        [3.0284, 3.0437, 3.0452, 3.1150, 3.1524],\n",
      "        [2.8446, 3.0091, 2.9449, 3.0284, 3.0209],\n",
      "        [3.0172, 3.0998, 3.1245, 3.1809, 3.1933],\n",
      "        [2.9015, 3.0589, 3.0478, 3.0635, 3.0299],\n",
      "        [3.0673, 3.1882, 2.9710, 3.1103, 3.1384],\n",
      "        [2.9689, 3.0966, 3.0245, 2.9973, 3.0562],\n",
      "        [3.0248, 3.1124, 2.9735, 3.1347, 3.1170],\n",
      "        [2.8918, 3.1308, 3.0512, 3.0476, 3.0478],\n",
      "        [3.1783, 3.3180, 3.1258, 3.2806, 3.2478],\n",
      "        [3.0475, 3.2146, 3.0446, 3.1584, 3.1896],\n",
      "        [3.2789, 3.2624, 3.1558, 3.3092, 3.2898],\n",
      "        [3.1760, 3.2850, 3.0595, 3.2275, 3.2652],\n",
      "        [3.0605, 3.2462, 3.1014, 3.1761, 3.0360],\n",
      "        [2.9511, 3.1118, 2.9580, 3.1742, 3.0319],\n",
      "        [3.2501, 3.2355, 3.2113, 3.4132, 3.2649],\n",
      "        [2.9165, 3.1471, 3.2018, 3.1283, 3.1682],\n",
      "        [3.0105, 3.2510, 3.0756, 3.1359, 3.0165],\n",
      "        [2.9221, 3.1006, 2.9722, 3.0681, 3.0874],\n",
      "        [2.8075, 2.9599, 2.9544, 2.9803, 3.0072],\n",
      "        [3.0272, 3.1348, 3.0603, 3.1127, 3.1243],\n",
      "        [3.0788, 3.2750, 3.0426, 3.0144, 3.1224],\n",
      "        [3.2222, 3.2552, 3.2582, 3.4257, 3.2060]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.1629, 3.3806, 3.1283, 3.2918, 3.2430],\n",
      "        [3.0834, 3.2913, 3.1149, 3.2510, 3.3175],\n",
      "        [3.0634, 3.2880, 2.9939, 3.1797, 3.1330],\n",
      "        [2.9904, 3.1864, 3.1197, 3.1431, 3.1355],\n",
      "        [3.1618, 3.1577, 3.1461, 3.1860, 3.0513],\n",
      "        [2.9333, 3.1427, 3.2108, 3.1155, 3.1909],\n",
      "        [3.3202, 3.4315, 3.0925, 3.2678, 3.2318],\n",
      "        [2.9236, 3.0280, 3.0284, 3.0660, 3.0066],\n",
      "        [3.1662, 3.2995, 3.0839, 3.3888, 3.2651],\n",
      "        [3.1976, 3.4604, 3.1663, 3.4388, 3.3905],\n",
      "        [3.2429, 3.3775, 3.2966, 3.3221, 3.1347],\n",
      "        [3.2054, 3.0145, 2.9848, 3.0984, 3.1780],\n",
      "        [3.0109, 2.9781, 3.0096, 3.1040, 3.1827],\n",
      "        [3.0429, 3.1964, 2.9912, 3.2884, 3.0644],\n",
      "        [3.1567, 3.2481, 3.0813, 3.3006, 3.2178],\n",
      "        [3.0177, 3.1331, 3.0679, 3.0901, 3.0234],\n",
      "        [3.0289, 3.0308, 3.0610, 3.1335, 3.1071],\n",
      "        [3.0957, 3.3566, 3.1648, 3.2780, 3.3345],\n",
      "        [3.1968, 3.1916, 3.3255, 3.1864, 3.1232],\n",
      "        [3.0019, 3.3262, 3.0904, 3.2585, 3.2725],\n",
      "        [2.9460, 3.0197, 3.0479, 3.1555, 3.1071],\n",
      "        [3.4236, 3.1619, 3.2310, 3.7302, 3.6407],\n",
      "        [2.9582, 3.0294, 3.0248, 3.0066, 3.1689],\n",
      "        [2.9443, 3.0746, 2.9294, 3.0550, 3.0442],\n",
      "        [2.9966, 3.2587, 3.0698, 3.1212, 3.0251],\n",
      "        [2.9121, 3.1391, 3.1900, 3.1080, 3.1608],\n",
      "        [3.2077, 3.4739, 3.1674, 3.4568, 3.4062],\n",
      "        [3.2689, 3.1661, 3.2203, 3.4216, 3.2578],\n",
      "        [3.1748, 2.9950, 2.9908, 3.1216, 3.1357],\n",
      "        [2.9969, 3.0665, 2.8497, 3.1838, 2.9499],\n",
      "        [2.8637, 2.9182, 2.9509, 2.9820, 2.9188],\n",
      "        [3.0836, 3.0799, 3.1614, 3.2047, 3.1813],\n",
      "        [3.0417, 2.9547, 3.0185, 3.0200, 3.0063],\n",
      "        [3.0539, 3.0987, 3.0895, 3.1327, 3.3216],\n",
      "        [2.9338, 2.9270, 2.9536, 3.0683, 2.9763],\n",
      "        [3.0433, 3.0306, 3.0820, 3.1377, 3.1115],\n",
      "        [2.9766, 2.9312, 2.9478, 3.0730, 2.9754],\n",
      "        [2.9902, 3.0774, 2.9672, 3.0560, 3.0458],\n",
      "        [3.0527, 3.0492, 3.1008, 3.1515, 3.1557],\n",
      "        [3.0503, 3.1472, 2.9313, 3.1832, 3.0963],\n",
      "        [3.1741, 3.2601, 3.0880, 3.3007, 3.2171],\n",
      "        [3.0842, 3.3015, 3.1231, 3.2541, 3.3187],\n",
      "        [3.1364, 3.0973, 3.1115, 3.2106, 3.1242],\n",
      "        [3.0323, 3.2742, 3.0155, 3.2827, 3.1855],\n",
      "        [3.0217, 3.1441, 3.0715, 3.0987, 3.0247],\n",
      "        [2.9506, 3.0162, 3.0281, 3.1124, 2.9987],\n",
      "        [2.9008, 3.0080, 2.9977, 3.0397, 3.0017],\n",
      "        [2.8872, 3.0969, 3.0300, 3.0380, 3.0266],\n",
      "        [3.0046, 3.3213, 3.1060, 3.2431, 3.2939],\n",
      "        [3.1713, 3.0268, 2.9847, 3.0971, 3.1720],\n",
      "        [3.0240, 3.0235, 3.0633, 3.1363, 3.1067],\n",
      "        [3.1988, 3.2414, 3.1663, 3.2927, 3.3274],\n",
      "        [3.3203, 3.2531, 3.1889, 3.4810, 3.3250],\n",
      "        [3.0356, 3.0296, 3.0659, 3.1328, 3.1093],\n",
      "        [3.1683, 3.3016, 3.0848, 3.3898, 3.2684],\n",
      "        [2.9474, 3.0507, 3.0629, 3.1062, 3.0084],\n",
      "        [2.8517, 3.0076, 2.9155, 2.9508, 2.9798],\n",
      "        [3.0996, 3.3507, 3.1685, 3.2791, 3.3393],\n",
      "        [3.1852, 3.0417, 2.9999, 3.1044, 3.1926],\n",
      "        [2.9383, 2.9265, 2.9560, 3.0743, 2.9734],\n",
      "        [3.3698, 3.2464, 3.2854, 3.5316, 3.3640],\n",
      "        [3.0884, 3.3654, 3.1825, 3.2759, 3.3307],\n",
      "        [3.0607, 3.2088, 3.0438, 3.2403, 3.1298],\n",
      "        [3.1762, 3.1927, 3.1065, 3.3048, 3.3142]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.0775, 3.2063, 2.9995, 3.1195, 3.1566],\n",
      "        [3.1113, 3.1760, 3.0334, 3.2347, 3.1878],\n",
      "        [2.9130, 3.0660, 3.0553, 3.0698, 3.0369],\n",
      "        [3.0202, 3.1409, 2.9445, 3.1509, 3.0951],\n",
      "        [3.0357, 3.1350, 2.9417, 3.1591, 3.1003],\n",
      "        [3.1750, 3.2437, 3.2020, 3.3129, 3.1743],\n",
      "        [3.0139, 3.2582, 3.1516, 3.0708, 3.2152],\n",
      "        [2.9909, 3.1001, 2.9338, 3.0996, 3.0731],\n",
      "        [3.1136, 3.0849, 3.0877, 3.0756, 2.9720],\n",
      "        [3.2869, 3.3123, 3.3063, 3.3231, 3.1754],\n",
      "        [3.6001, 3.7652, 3.3041, 3.4847, 3.3832],\n",
      "        [3.1752, 3.3008, 3.0810, 3.3826, 3.2582],\n",
      "        [3.2177, 3.1962, 3.2668, 3.2747, 3.0629],\n",
      "        [3.1888, 3.1357, 3.1047, 3.1203, 3.0510],\n",
      "        [3.2018, 3.3570, 3.1281, 3.1316, 3.1593],\n",
      "        [3.2668, 3.1644, 3.2020, 3.3830, 3.2591],\n",
      "        [3.0429, 3.0795, 3.0754, 3.1724, 3.1445],\n",
      "        [2.9952, 3.0184, 2.9904, 3.0621, 3.1213],\n",
      "        [3.0425, 3.1329, 3.0936, 3.1442, 3.0248],\n",
      "        [3.1719, 3.3030, 3.0878, 3.3919, 3.2687],\n",
      "        [2.9636, 3.0327, 3.0284, 3.0095, 3.1723],\n",
      "        [3.1024, 3.1935, 3.0579, 3.2387, 3.2223],\n",
      "        [2.8971, 3.1550, 2.8909, 3.1104, 2.9763],\n",
      "        [2.9551, 3.1795, 2.9305, 3.1210, 2.9967],\n",
      "        [3.0926, 3.0240, 3.0763, 3.1700, 3.1124],\n",
      "        [3.3772, 3.4527, 3.3263, 3.6352, 3.4662],\n",
      "        [3.0279, 3.1159, 3.0220, 3.1108, 3.1176],\n",
      "        [3.2485, 3.3129, 3.1200, 3.2805, 3.3598],\n",
      "        [3.0332, 3.1303, 2.9389, 3.1532, 3.1000],\n",
      "        [2.9840, 3.0961, 2.9749, 3.1061, 3.0972],\n",
      "        [3.1959, 3.3854, 3.1712, 3.3906, 3.3300],\n",
      "        [3.0352, 3.0517, 3.0365, 3.1104, 3.1547],\n",
      "        [3.0350, 3.0190, 3.0765, 3.1356, 3.0959],\n",
      "        [2.9841, 3.0595, 2.8588, 3.1731, 2.9652],\n",
      "        [3.0052, 3.1105, 2.9433, 3.1309, 3.0831],\n",
      "        [3.0532, 3.1492, 3.0785, 3.1389, 3.1407],\n",
      "        [3.6398, 3.7746, 3.3747, 3.5458, 3.3797],\n",
      "        [2.9820, 2.9345, 2.9514, 3.0758, 2.9788],\n",
      "        [2.9473, 3.0326, 2.9116, 3.1192, 3.0238],\n",
      "        [3.1857, 3.1586, 3.2373, 3.2225, 3.0123],\n",
      "        [3.1366, 3.3405, 3.2188, 3.2919, 3.3935],\n",
      "        [3.1939, 3.1335, 3.1114, 3.1267, 3.0478],\n",
      "        [3.0075, 3.3297, 3.0942, 3.2615, 3.2759],\n",
      "        [3.1734, 3.1779, 3.1554, 3.1950, 3.0417],\n",
      "        [3.3574, 3.2789, 3.3136, 3.5351, 3.3690],\n",
      "        [3.2655, 3.2467, 3.2241, 3.4311, 3.2804],\n",
      "        [2.9252, 2.9770, 2.9791, 3.0480, 2.9831],\n",
      "        [3.1501, 3.1177, 3.1440, 3.3144, 3.0882],\n",
      "        [3.0324, 3.1202, 2.9755, 3.1438, 3.1183],\n",
      "        [2.8979, 3.0500, 2.9379, 3.0552, 3.0069],\n",
      "        [3.2026, 3.1952, 3.3294, 3.1896, 3.1268],\n",
      "        [3.2676, 3.2421, 3.2185, 3.4239, 3.2840],\n",
      "        [3.1422, 3.1230, 3.0718, 3.3252, 3.2206],\n",
      "        [3.0360, 3.0502, 2.9459, 3.1107, 3.1854],\n",
      "        [3.1157, 3.1004, 3.1846, 3.2369, 3.2046],\n",
      "        [3.3062, 3.3220, 3.1824, 3.3930, 3.4115],\n",
      "        [3.1352, 3.2813, 3.0668, 3.2217, 3.2021],\n",
      "        [3.0082, 2.9729, 3.0569, 3.1069, 3.0678],\n",
      "        [2.9757, 2.9253, 3.0707, 2.9342, 3.1483],\n",
      "        [3.3400, 3.1617, 3.2380, 3.7534, 3.6225],\n",
      "        [3.2411, 3.2469, 3.1656, 3.2702, 3.2880],\n",
      "        [3.1298, 3.1657, 3.0893, 3.3299, 3.1612],\n",
      "        [2.8255, 2.9817, 2.9064, 2.9209, 2.9543],\n",
      "        [2.9436, 2.9298, 2.9595, 3.0772, 2.9767]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.8972, 3.0321, 2.9302, 2.9963, 3.0067],\n",
      "        [3.1965, 3.1276, 3.1018, 3.4855, 3.3322],\n",
      "        [3.3113, 3.3253, 3.1869, 3.3957, 3.4147],\n",
      "        [3.0081, 3.1764, 3.0838, 3.0523, 3.0585],\n",
      "        [2.9032, 2.9631, 2.9732, 3.0247, 2.9579],\n",
      "        [2.9888, 2.9387, 3.0799, 2.9616, 3.1518],\n",
      "        [3.3310, 3.2202, 3.1652, 3.3257, 3.3128],\n",
      "        [2.9263, 3.1534, 3.0633, 3.0682, 3.0891],\n",
      "        [3.0745, 3.2804, 3.0360, 3.2216, 3.1731],\n",
      "        [3.0195, 3.1237, 2.9454, 3.1168, 3.0899],\n",
      "        [2.9727, 3.0861, 2.9825, 3.0933, 3.0743],\n",
      "        [3.1867, 3.2345, 3.1644, 3.2698, 3.3130],\n",
      "        [2.9625, 3.0574, 2.9401, 3.1094, 3.0326],\n",
      "        [2.9670, 3.0624, 2.9396, 3.1132, 3.0287],\n",
      "        [3.0329, 3.1189, 3.0264, 3.1135, 3.1208],\n",
      "        [3.0155, 3.3280, 3.1143, 3.2489, 3.3007],\n",
      "        [3.0596, 3.0195, 3.1173, 3.1913, 3.2267],\n",
      "        [2.9079, 2.9174, 2.9541, 3.0469, 2.9973],\n",
      "        [2.9264, 3.0765, 3.0641, 3.0867, 3.0365],\n",
      "        [3.0438, 3.0663, 3.0939, 3.1643, 3.1359],\n",
      "        [3.0268, 3.1459, 3.0326, 3.1989, 3.1708],\n",
      "        [2.8999, 3.0526, 3.0173, 3.0396, 3.0143],\n",
      "        [3.0978, 3.0272, 3.0807, 3.1726, 3.1155],\n",
      "        [3.2789, 3.1334, 3.1061, 3.2352, 3.2414],\n",
      "        [3.1903, 3.3297, 3.0783, 3.2219, 3.2551],\n",
      "        [2.8304, 2.9846, 2.9107, 2.9235, 2.9573],\n",
      "        [2.8999, 3.0526, 3.0173, 3.0396, 3.0143],\n",
      "        [3.1650, 3.1042, 3.1520, 3.2545, 3.1631],\n",
      "        [3.0446, 3.1455, 2.9428, 3.1837, 3.1050],\n",
      "        [3.5301, 3.6968, 3.2496, 3.4298, 3.3222],\n",
      "        [3.2640, 3.3777, 3.3249, 3.3511, 3.1560],\n",
      "        [2.9887, 3.1048, 2.9458, 3.0834, 3.0747],\n",
      "        [2.9839, 2.9259, 3.0243, 3.1023, 3.1120],\n",
      "        [2.8886, 2.9980, 2.8843, 3.0748, 2.9335],\n",
      "        [2.9884, 3.1486, 2.9841, 3.2080, 3.0500],\n",
      "        [3.0400, 3.0840, 3.1330, 3.0910, 3.2572],\n",
      "        [3.2154, 3.0209, 2.9926, 3.1038, 3.1849],\n",
      "        [3.0151, 3.2534, 3.1547, 3.0662, 3.2105],\n",
      "        [3.0944, 3.0866, 3.1695, 3.2103, 3.1878],\n",
      "        [3.0686, 3.2413, 3.0897, 3.3056, 3.1318],\n",
      "        [2.8745, 3.0229, 2.9267, 2.9756, 2.9971],\n",
      "        [2.9488, 3.0328, 3.0316, 3.0264, 3.0355],\n",
      "        [3.1722, 3.2611, 3.1119, 3.1523, 3.1878],\n",
      "        [3.3615, 3.4698, 3.3033, 3.6412, 3.4800],\n",
      "        [3.1283, 3.3413, 3.2114, 3.2878, 3.3996],\n",
      "        [3.1810, 3.1334, 3.0579, 3.4011, 3.2694],\n",
      "        [3.1870, 3.1995, 3.1146, 3.3105, 3.3212],\n",
      "        [3.1937, 3.3277, 3.2066, 3.3195, 3.2454],\n",
      "        [2.9827, 3.0050, 3.0600, 3.1307, 3.1735],\n",
      "        [3.3450, 3.1250, 3.1403, 3.6579, 3.4592],\n",
      "        [3.0265, 2.9910, 3.0771, 3.1232, 3.0786],\n",
      "        [3.1728, 3.2955, 3.0560, 3.2208, 3.2510],\n",
      "        [3.0780, 3.0807, 3.0751, 3.1781, 3.1514],\n",
      "        [3.0309, 3.0845, 3.1479, 3.1481, 3.2277],\n",
      "        [3.1212, 3.1423, 3.0956, 3.2022, 3.1434],\n",
      "        [3.1433, 3.0909, 3.2286, 3.2929, 3.1828],\n",
      "        [3.1779, 2.9895, 2.9919, 3.1269, 3.1331],\n",
      "        [3.1673, 3.1482, 3.1515, 3.1777, 3.0604],\n",
      "        [3.0249, 3.0359, 3.0138, 3.1779, 3.0371],\n",
      "        [2.8973, 3.0730, 3.0264, 3.0446, 3.0202],\n",
      "        [3.1790, 3.1280, 3.1139, 3.1113, 3.0311],\n",
      "        [2.9640, 3.0665, 2.9424, 3.1215, 3.0252],\n",
      "        [3.0780, 3.0807, 3.0751, 3.1781, 3.1514],\n",
      "        [3.1793, 3.3082, 3.0932, 3.3957, 3.2753]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.0362, 3.0469, 3.0711, 3.1540, 3.1263],\n",
      "        [3.1086, 3.0209, 3.0697, 3.1834, 3.0771],\n",
      "        [3.2509, 3.2532, 3.1741, 3.2753, 3.2945],\n",
      "        [3.0496, 3.3614, 3.2241, 3.2217, 3.1696],\n",
      "        [2.9972, 2.9345, 3.0379, 3.1136, 3.1187],\n",
      "        [3.3012, 3.1705, 3.2366, 3.4235, 3.2744],\n",
      "        [3.1824, 3.3079, 3.0916, 3.3888, 3.2671],\n",
      "        [3.0136, 3.0898, 3.0442, 3.1569, 3.2001],\n",
      "        [3.0005, 3.1059, 2.9421, 3.1045, 3.0791],\n",
      "        [2.9701, 3.0368, 3.0637, 3.1545, 3.1212],\n",
      "        [3.2020, 3.1293, 3.1915, 3.2993, 3.2005],\n",
      "        [3.0422, 3.0450, 3.0672, 3.1407, 3.1188],\n",
      "        [3.3643, 3.2822, 3.3218, 3.5391, 3.3735],\n",
      "        [3.1072, 3.1153, 3.0820, 3.2435, 3.1558],\n",
      "        [2.9537, 3.0582, 2.9154, 3.1237, 3.0390],\n",
      "        [3.0453, 3.0480, 3.0698, 3.1375, 3.1163],\n",
      "        [3.2703, 3.4403, 3.2037, 3.4299, 3.4277],\n",
      "        [2.9434, 3.1119, 3.1413, 3.1011, 3.1640],\n",
      "        [3.3318, 3.2762, 3.2344, 3.4851, 3.3661],\n",
      "        [3.3225, 3.2362, 3.1742, 3.3100, 3.3141],\n",
      "        [2.9758, 3.0855, 2.9360, 3.0765, 3.0493],\n",
      "        [2.9447, 2.9642, 2.9841, 3.0641, 3.0020],\n",
      "        [3.0191, 3.3162, 3.1095, 3.2421, 3.2973],\n",
      "        [3.1589, 3.2020, 3.1378, 3.3603, 3.1941],\n",
      "        [2.9619, 3.0906, 2.9492, 3.0701, 3.0608],\n",
      "        [3.2233, 3.3112, 3.1240, 3.3581, 3.3284],\n",
      "        [3.1519, 3.1070, 3.1237, 3.2186, 3.1337],\n",
      "        [2.8582, 3.0055, 2.9277, 2.9436, 2.9818],\n",
      "        [3.1528, 3.3165, 3.2071, 3.3050, 3.3273],\n",
      "        [2.8832, 3.0258, 2.9285, 2.9799, 2.9987],\n",
      "        [2.9615, 3.1146, 3.2424, 3.1137, 3.2593],\n",
      "        [3.0324, 3.1202, 3.0531, 3.0894, 3.1227],\n",
      "        [2.9629, 2.9579, 2.9822, 3.0803, 3.0044],\n",
      "        [3.1887, 2.9994, 3.0001, 3.1226, 3.1439],\n",
      "        [2.9405, 3.0713, 2.9416, 3.0422, 3.0352],\n",
      "        [3.1321, 3.0382, 3.2883, 3.2347, 3.2585],\n",
      "        [3.0480, 3.0047, 3.1001, 3.1664, 3.2091],\n",
      "        [3.2409, 3.3107, 3.1957, 3.3137, 3.3337],\n",
      "        [3.0483, 3.0667, 3.0777, 3.1507, 3.1298],\n",
      "        [3.1332, 3.3443, 3.2157, 3.2902, 3.4026],\n",
      "        [3.0150, 3.0132, 3.0594, 3.0971, 3.0854],\n",
      "        [3.3885, 3.3263, 3.2549, 3.4364, 3.3825],\n",
      "        [3.4206, 3.2011, 3.2747, 3.8099, 3.6328],\n",
      "        [2.7653, 2.9227, 2.9470, 2.9397, 2.9924],\n",
      "        [3.0417, 3.0729, 3.0773, 3.1613, 3.1300],\n",
      "        [3.0058, 3.2138, 3.0469, 3.1193, 3.0721],\n",
      "        [3.0566, 3.1522, 2.9416, 3.1848, 3.1093],\n",
      "        [3.2051, 3.0739, 3.0745, 3.5078, 3.3078],\n",
      "        [2.9412, 3.0773, 3.1055, 3.1048, 3.0191],\n",
      "        [3.0405, 3.1329, 2.9506, 3.1431, 3.1090],\n",
      "        [3.0348, 3.1304, 3.0265, 3.1155, 3.1152],\n",
      "        [3.2923, 3.3516, 3.2465, 3.3418, 3.3603],\n",
      "        [2.9584, 2.9887, 3.0140, 3.0802, 2.9955],\n",
      "        [3.1886, 3.2893, 3.1185, 3.2622, 3.2149],\n",
      "        [2.9107, 3.1198, 3.0525, 3.0619, 3.0593],\n",
      "        [3.1197, 3.2193, 3.0312, 3.2314, 3.2064],\n",
      "        [3.0958, 3.2034, 2.9794, 3.1300, 3.1507],\n",
      "        [2.8389, 2.9793, 2.9120, 2.9250, 2.9545],\n",
      "        [3.0579, 3.1290, 3.0003, 3.2162, 3.1313],\n",
      "        [2.8984, 2.8931, 2.9446, 3.0854, 2.9813],\n",
      "        [3.2858, 3.1758, 3.0974, 3.2557, 3.2600],\n",
      "        [3.0000, 2.9469, 2.9637, 3.0817, 2.9920],\n",
      "        [3.0235, 3.1743, 3.0850, 3.1552, 3.1411],\n",
      "        [2.9861, 3.0728, 2.9717, 3.1661, 3.0820]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.0297, 3.0908, 3.0605, 3.1438, 3.2446],\n",
      "        [3.2705, 3.2468, 3.2390, 3.3983, 3.2914],\n",
      "        [2.9760, 3.2829, 3.1517, 3.1899, 3.2823],\n",
      "        [3.0105, 3.0664, 3.0371, 3.0786, 3.0881],\n",
      "        [3.0740, 3.0702, 3.1385, 3.2007, 3.1653],\n",
      "        [3.3514, 3.2701, 3.2326, 3.3750, 3.3203],\n",
      "        [3.1988, 3.2767, 3.1097, 3.3119, 3.2400],\n",
      "        [3.1822, 3.3010, 3.0643, 3.2263, 3.2567],\n",
      "        [3.0855, 3.2346, 3.0694, 3.2629, 3.1324],\n",
      "        [3.2909, 3.2749, 3.2649, 3.3982, 3.2915],\n",
      "        [3.2812, 3.1730, 3.2147, 3.3910, 3.2679],\n",
      "        [3.0979, 3.1370, 3.0803, 3.1952, 3.2181],\n",
      "        [3.1424, 3.1404, 3.1059, 3.2105, 3.1373],\n",
      "        [2.9991, 2.9301, 2.9498, 3.0794, 2.9740],\n",
      "        [2.9852, 3.0980, 2.9546, 3.0784, 3.0816],\n",
      "        [3.1485, 3.1041, 3.1404, 3.1308, 3.0911],\n",
      "        [2.9068, 3.1086, 3.0460, 3.0488, 3.0386],\n",
      "        [3.1368, 3.2330, 3.0382, 3.2454, 3.2356],\n",
      "        [3.1869, 3.3104, 3.0955, 3.3918, 3.2699],\n",
      "        [3.6426, 3.7735, 3.3541, 3.5185, 3.3789],\n",
      "        [3.5946, 3.8050, 3.3186, 3.5446, 3.3702],\n",
      "        [2.9323, 3.1225, 3.1477, 3.0849, 3.1481],\n",
      "        [3.0810, 3.0510, 3.1517, 3.2050, 3.2051],\n",
      "        [2.9857, 3.0536, 3.0341, 3.0606, 3.0609],\n",
      "        [3.1942, 3.2715, 3.1043, 3.3118, 3.2294],\n",
      "        [2.9943, 3.1139, 3.0497, 3.2270, 3.0520],\n",
      "        [2.9673, 3.1813, 3.0638, 3.1416, 3.2588],\n",
      "        [3.1202, 3.3144, 3.1156, 3.3534, 3.2382],\n",
      "        [3.1509, 3.2395, 3.2153, 3.2654, 3.2374],\n",
      "        [3.1660, 3.3140, 3.2136, 3.3154, 3.3167],\n",
      "        [3.1552, 3.4265, 3.2201, 3.3323, 3.4332],\n",
      "        [3.1249, 3.1013, 3.1922, 3.2412, 3.2112],\n",
      "        [3.0494, 3.0368, 3.0713, 3.1417, 3.1190],\n",
      "        [2.8833, 3.0280, 2.9344, 2.9808, 3.0024],\n",
      "        [2.9830, 3.0389, 3.0506, 3.1269, 3.0243],\n",
      "        [3.1123, 3.0367, 3.2097, 3.2639, 3.1713],\n",
      "        [3.0095, 3.0889, 2.9828, 3.0667, 3.0578],\n",
      "        [3.0169, 3.2706, 3.0862, 3.1323, 3.0373],\n",
      "        [3.0700, 3.2771, 3.1596, 3.2626, 3.3232],\n",
      "        [3.0294, 3.1135, 2.9774, 3.1590, 3.0787],\n",
      "        [2.9028, 2.8954, 2.9483, 3.0883, 2.9839],\n",
      "        [3.0777, 3.1825, 2.9307, 3.1083, 3.1232],\n",
      "        [3.2184, 3.3179, 3.1218, 3.3705, 3.4315],\n",
      "        [3.1789, 3.2001, 3.1530, 3.2023, 3.0025],\n",
      "        [3.2487, 3.2716, 3.2788, 3.4403, 3.2229],\n",
      "        [3.0873, 3.0861, 3.0830, 3.1834, 3.1569],\n",
      "        [2.9672, 2.9603, 2.9859, 3.0831, 3.0070],\n",
      "        [3.1887, 3.3137, 3.1013, 3.4012, 3.2811],\n",
      "        [2.9523, 2.9281, 2.9624, 3.0724, 2.9816],\n",
      "        [2.9120, 3.0403, 3.0186, 3.0444, 3.0166],\n",
      "        [3.0708, 3.4033, 3.1016, 3.3654, 3.2973],\n",
      "        [3.0005, 3.1083, 2.9458, 3.1015, 3.0733],\n",
      "        [2.8431, 2.9816, 2.9156, 2.9278, 2.9571],\n",
      "        [2.8608, 3.0881, 2.8431, 3.0663, 2.9320],\n",
      "        [3.0785, 3.1735, 2.9674, 3.2145, 3.1305],\n",
      "        [3.1571, 3.3880, 3.1651, 3.2851, 3.2741],\n",
      "        [3.0716, 3.1659, 2.9535, 3.2168, 3.1242],\n",
      "        [3.3111, 3.0194, 3.1385, 3.5497, 3.4896],\n",
      "        [2.9089, 3.0578, 3.0251, 3.0449, 3.0198],\n",
      "        [3.1037, 3.3035, 3.1314, 3.2620, 3.3296],\n",
      "        [3.1700, 3.1241, 3.1149, 3.0942, 3.0180],\n",
      "        [3.2007, 3.1671, 3.2456, 3.2268, 3.0392],\n",
      "        [3.2631, 3.3216, 3.1327, 3.2886, 3.3687],\n",
      "        [3.3265, 3.3039, 3.2754, 3.4754, 3.3496]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.1650, 3.0027, 3.2379, 3.2431, 3.2012],\n",
      "        [3.2628, 3.3752, 3.2776, 3.4045, 3.3917],\n",
      "        [3.1600, 3.1076, 3.1394, 3.2270, 3.1475],\n",
      "        [3.3968, 3.3320, 3.2623, 3.4424, 3.3891],\n",
      "        [2.9487, 3.1642, 3.2255, 3.1465, 3.1835],\n",
      "        [3.2159, 3.4424, 3.2971, 3.3684, 3.3988],\n",
      "        [3.1730, 3.2715, 3.0882, 3.2589, 3.2324],\n",
      "        [3.0184, 3.0519, 3.1949, 3.0037, 3.2783],\n",
      "        [3.1357, 3.1732, 3.0476, 3.2612, 3.1970],\n",
      "        [2.9115, 3.1303, 3.1714, 3.0538, 3.1242],\n",
      "        [3.1819, 3.2899, 3.1220, 3.2828, 3.2159],\n",
      "        [3.1129, 3.0979, 3.1748, 3.2244, 3.2092],\n",
      "        [2.9562, 2.9309, 2.9658, 3.0749, 2.9849],\n",
      "        [3.0560, 3.0879, 3.0951, 3.1805, 3.1505],\n",
      "        [3.0327, 3.0938, 3.1720, 3.2572, 3.2932],\n",
      "        [3.2014, 3.2828, 3.1306, 3.2315, 3.2144],\n",
      "        [3.2916, 3.1419, 3.1174, 3.2433, 3.2508],\n",
      "        [3.1409, 3.2361, 3.0419, 3.2481, 3.2392],\n",
      "        [3.6189, 3.7779, 3.3210, 3.4959, 3.3962],\n",
      "        [3.2112, 3.1706, 3.2940, 3.2212, 3.1004],\n",
      "        [3.1816, 3.3728, 3.1376, 3.1050, 3.2495],\n",
      "        [3.0779, 3.0452, 3.1057, 3.1736, 3.1923],\n",
      "        [3.1057, 3.3026, 3.1314, 3.2607, 3.3291],\n",
      "        [3.0970, 3.3368, 3.2408, 3.3045, 3.3257],\n",
      "        [2.9392, 3.0101, 3.0325, 3.0757, 2.9982],\n",
      "        [3.4104, 3.3796, 3.2719, 3.4831, 3.4231],\n",
      "        [3.1408, 3.1350, 3.0864, 3.2956, 3.1875],\n",
      "        [3.1971, 3.2946, 3.1259, 3.2678, 3.2210],\n",
      "        [3.1016, 3.3417, 3.2440, 3.3080, 3.3285],\n",
      "        [3.1692, 3.2134, 3.0446, 3.2877, 3.2461],\n",
      "        [3.2532, 3.1024, 3.0950, 3.2058, 3.2171],\n",
      "        [3.0020, 2.9471, 3.0910, 2.9695, 3.1606],\n",
      "        [3.1845, 3.1506, 3.1596, 3.1773, 3.0934],\n",
      "        [3.3730, 3.2880, 3.3296, 3.5448, 3.3800],\n",
      "        [3.0565, 3.1958, 3.1145, 3.1748, 3.1144],\n",
      "        [3.1022, 3.4166, 3.1119, 3.3776, 3.3198],\n",
      "        [3.0289, 3.2706, 3.0962, 3.1437, 3.0335],\n",
      "        [3.1917, 3.1363, 3.1251, 3.1192, 3.0402],\n",
      "        [2.9616, 3.0409, 3.0428, 3.0342, 3.0443],\n",
      "        [3.1103, 3.0940, 3.1725, 3.2200, 3.1983],\n",
      "        [2.9242, 3.0224, 3.0170, 3.0530, 3.0170],\n",
      "        [3.0601, 3.0507, 3.0864, 3.1495, 3.1310],\n",
      "        [3.0820, 3.0540, 3.0967, 3.1835, 3.1857],\n",
      "        [3.0671, 3.1603, 2.9608, 3.1906, 3.1216],\n",
      "        [3.1006, 3.3289, 3.2015, 3.2512, 3.1608],\n",
      "        [3.1476, 3.0959, 3.1355, 3.1336, 3.0994],\n",
      "        [3.0309, 3.1223, 3.0719, 3.2457, 3.1181],\n",
      "        [2.9487, 3.0146, 3.0322, 3.0809, 3.0024],\n",
      "        [2.9967, 3.0686, 2.9748, 3.1795, 3.0839],\n",
      "        [3.1564, 3.3995, 3.2509, 3.3150, 3.3636],\n",
      "        [3.1112, 3.0404, 3.0984, 3.1944, 3.1388],\n",
      "        [3.1886, 3.3138, 3.0745, 3.2352, 3.2619],\n",
      "        [3.2115, 3.1449, 3.1268, 3.1373, 3.0601],\n",
      "        [2.9744, 2.9593, 2.9857, 3.0919, 3.0074],\n",
      "        [3.0302, 3.0616, 3.1731, 3.0491, 3.2621],\n",
      "        [2.7572, 2.9231, 2.9519, 2.9281, 2.9710],\n",
      "        [2.9840, 3.0907, 2.9432, 3.0819, 3.0551],\n",
      "        [3.1548, 3.3058, 3.1611, 3.3744, 3.2424],\n",
      "        [2.8971, 2.9354, 2.9714, 3.0019, 2.9403],\n",
      "        [2.9486, 2.9797, 2.9981, 3.0763, 3.0125],\n",
      "        [3.0498, 3.0963, 3.0035, 3.1657, 3.0872],\n",
      "        [3.2036, 3.3423, 3.1456, 3.2980, 3.2586],\n",
      "        [3.0475, 3.1974, 3.0088, 3.2720, 3.0729],\n",
      "        [2.9747, 3.1588, 3.0718, 3.0223, 3.0370]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.0234, 3.1236, 2.9540, 3.1240, 3.0880],\n",
      "        [2.9702, 2.9751, 2.9988, 3.0835, 3.0170],\n",
      "        [3.0473, 3.0457, 3.0690, 3.1422, 3.1185],\n",
      "        [3.1958, 3.1566, 3.1833, 3.3496, 3.1369],\n",
      "        [3.1633, 3.1961, 3.0642, 3.2181, 3.3326],\n",
      "        [2.9279, 3.1213, 3.1521, 3.0885, 3.1472],\n",
      "        [3.0440, 3.3505, 3.0758, 3.3246, 3.2510],\n",
      "        [3.0630, 3.0473, 3.0894, 3.1492, 3.1272],\n",
      "        [3.0809, 3.2360, 3.0725, 3.1787, 3.2119],\n",
      "        [3.1160, 3.3374, 3.1627, 3.2763, 3.3424],\n",
      "        [3.0307, 3.1323, 2.9568, 3.1491, 3.0891],\n",
      "        [3.1491, 3.0864, 3.1362, 3.1233, 3.1216],\n",
      "        [3.0601, 3.0076, 3.1031, 3.1650, 3.2180],\n",
      "        [3.1744, 3.2947, 3.0840, 3.3719, 3.2450],\n",
      "        [3.0494, 3.1971, 3.0454, 3.1836, 3.1982],\n",
      "        [2.9175, 3.1076, 3.0525, 3.0675, 3.0513],\n",
      "        [2.9918, 3.1403, 3.0040, 3.1538, 3.0329],\n",
      "        [3.2239, 3.2374, 3.1961, 3.3077, 3.3584],\n",
      "        [3.2876, 3.4145, 3.1663, 3.2096, 3.2026],\n",
      "        [2.9189, 3.1687, 2.9113, 3.1236, 2.9904],\n",
      "        [3.2346, 3.2235, 3.2204, 3.3929, 3.2574],\n",
      "        [3.0921, 3.1751, 2.9674, 3.2190, 3.1267],\n",
      "        [2.9734, 3.1370, 3.0177, 3.1124, 3.1212],\n",
      "        [3.3395, 3.2399, 3.2853, 3.4908, 3.3362],\n",
      "        [3.0076, 3.0815, 2.8845, 3.1877, 2.9840],\n",
      "        [3.2269, 3.4778, 3.1918, 3.4565, 3.4095],\n",
      "        [3.3970, 3.3161, 3.2352, 3.4182, 3.3720],\n",
      "        [2.9071, 3.1222, 3.0566, 3.0544, 3.0464],\n",
      "        [3.0679, 3.1560, 2.9593, 3.1913, 3.1155],\n",
      "        [3.0636, 3.0329, 2.9979, 3.2224, 3.0384],\n",
      "        [3.1496, 2.9862, 3.2176, 3.2373, 3.1929],\n",
      "        [3.4726, 3.5685, 3.1406, 3.3780, 3.2147],\n",
      "        [3.0037, 2.9483, 2.9712, 3.0893, 2.9933],\n",
      "        [3.2582, 3.4217, 3.2173, 3.4458, 3.3718],\n",
      "        [3.0727, 3.1612, 3.0903, 3.1773, 3.1771],\n",
      "        [2.9791, 3.2617, 3.0955, 2.9948, 3.2291],\n",
      "        [2.9665, 3.1050, 3.1436, 3.1340, 3.1881],\n",
      "        [2.8934, 2.9291, 2.9658, 2.9914, 2.9348],\n",
      "        [3.0510, 2.9956, 3.0723, 3.1554, 3.2089],\n",
      "        [2.9886, 3.1042, 2.9618, 3.0770, 3.0788],\n",
      "        [3.1822, 3.1158, 3.1678, 3.2656, 3.1747],\n",
      "        [2.9533, 3.0465, 3.0608, 3.0949, 3.0270],\n",
      "        [2.9083, 2.8972, 2.9461, 3.0922, 2.9779],\n",
      "        [2.9852, 3.2480, 3.0509, 3.0802, 3.0167],\n",
      "        [3.1264, 3.0771, 3.1865, 3.2675, 3.2039],\n",
      "        [2.9168, 3.1233, 3.0613, 3.0592, 3.0519],\n",
      "        [3.1968, 3.3196, 3.1095, 3.4072, 3.2874],\n",
      "        [2.9170, 3.1625, 2.9076, 3.1355, 2.9910],\n",
      "        [3.0749, 3.1634, 3.0986, 3.1527, 3.1558],\n",
      "        [3.1968, 3.3196, 3.1095, 3.4072, 3.2874],\n",
      "        [3.0430, 3.0054, 3.0913, 3.1356, 3.0909],\n",
      "        [3.0539, 3.0565, 3.0791, 3.1513, 3.1290],\n",
      "        [3.0014, 3.1175, 3.0516, 3.0171, 3.0782],\n",
      "        [3.0161, 3.3272, 3.1848, 3.2366, 3.3278],\n",
      "        [3.0575, 3.2154, 3.0235, 3.2939, 3.0805],\n",
      "        [3.1542, 3.2082, 3.1757, 3.2532, 3.3039],\n",
      "        [3.4043, 3.4650, 3.3184, 3.6351, 3.4724],\n",
      "        [3.2685, 3.3257, 3.3017, 3.3038, 3.1776],\n",
      "        [3.3864, 3.1542, 3.1650, 3.7016, 3.5072],\n",
      "        [3.0587, 3.1248, 3.0247, 3.1986, 3.2282],\n",
      "        [3.0475, 3.0381, 3.0766, 3.1414, 3.1162],\n",
      "        [3.1845, 3.2648, 3.1057, 3.3175, 3.2361],\n",
      "        [3.0587, 3.1584, 3.1109, 3.1523, 3.0542],\n",
      "        [3.0423, 3.0990, 3.0706, 3.1520, 3.2537]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.9085, 3.0109, 2.9037, 3.0887, 2.9469],\n",
      "        [3.6209, 3.7495, 3.3464, 3.4881, 3.3572],\n",
      "        [3.3774, 3.5025, 3.2300, 3.2987, 3.2826],\n",
      "        [3.0708, 3.0558, 3.1001, 3.1584, 3.1372],\n",
      "        [3.1318, 3.3715, 3.1979, 3.2998, 3.3605],\n",
      "        [2.9882, 3.1351, 2.9899, 3.1973, 3.0558],\n",
      "        [3.1832, 3.1499, 3.0695, 3.3731, 3.2596],\n",
      "        [3.1868, 3.1519, 3.1697, 3.1820, 3.0863],\n",
      "        [3.4100, 3.4637, 3.3432, 3.6415, 3.4682],\n",
      "        [2.8239, 2.9763, 2.9779, 2.9833, 3.0069],\n",
      "        [3.2741, 3.3828, 3.2908, 3.4180, 3.4000],\n",
      "        [3.0957, 3.1776, 2.9714, 3.2225, 3.1292],\n",
      "        [3.2924, 3.3100, 3.2229, 3.4580, 3.2872],\n",
      "        [3.1461, 3.1673, 3.1100, 3.3193, 3.1778],\n",
      "        [3.4198, 3.4551, 3.3002, 3.6799, 3.4902],\n",
      "        [3.1946, 3.2628, 3.0858, 3.2496, 3.3315],\n",
      "        [3.2143, 3.2773, 3.2376, 3.4181, 3.2179],\n",
      "        [2.9161, 3.0576, 2.9566, 3.0186, 3.0310],\n",
      "        [2.9074, 2.9634, 2.9546, 3.0062, 2.9911],\n",
      "        [3.5011, 3.7136, 3.2375, 3.4340, 3.2905],\n",
      "        [3.2738, 3.2837, 3.3056, 3.4662, 3.2416],\n",
      "        [3.0837, 3.3173, 3.0702, 3.3316, 3.2275],\n",
      "        [3.0505, 3.0596, 3.0772, 3.1518, 3.1253],\n",
      "        [3.3816, 3.4319, 3.2544, 3.6385, 3.4564],\n",
      "        [3.4870, 3.5659, 3.1588, 3.3809, 3.2237],\n",
      "        [3.0560, 3.1433, 2.9661, 3.1551, 3.1201],\n",
      "        [2.9753, 3.0031, 2.8994, 3.1274, 2.9790],\n",
      "        [3.0609, 3.1513, 2.9655, 3.1761, 3.1174],\n",
      "        [3.0509, 3.0482, 3.0731, 3.1457, 3.1210],\n",
      "        [3.0635, 3.1585, 3.0918, 3.1365, 3.1491],\n",
      "        [3.1299, 3.1384, 3.0792, 3.2530, 3.2725],\n",
      "        [3.1461, 3.1491, 3.0609, 3.2885, 3.1980],\n",
      "        [3.0286, 3.2882, 3.1995, 3.0906, 3.2423],\n",
      "        [3.2977, 3.1793, 3.2426, 3.4413, 3.2753],\n",
      "        [3.2940, 3.3535, 3.2418, 3.3688, 3.3968],\n",
      "        [3.0683, 3.0683, 3.0912, 3.1495, 3.1776],\n",
      "        [2.8689, 2.9274, 2.9343, 2.9596, 2.9514],\n",
      "        [2.9239, 3.1221, 3.0626, 3.0643, 3.0562],\n",
      "        [3.0686, 3.1654, 3.0471, 3.2372, 3.1815],\n",
      "        [2.9516, 3.0953, 2.9886, 3.1439, 3.0484],\n",
      "        [3.3354, 3.3514, 3.1983, 3.3871, 3.4303],\n",
      "        [3.1765, 3.1400, 3.1628, 3.3350, 3.1094],\n",
      "        [3.2017, 3.3179, 3.1060, 3.4005, 3.2763],\n",
      "        [3.2069, 3.2621, 3.2768, 3.2589, 3.1359],\n",
      "        [3.1080, 3.2684, 3.1036, 3.1777, 3.2250],\n",
      "        [3.3005, 3.2627, 3.2471, 3.4436, 3.3111],\n",
      "        [3.2005, 3.3222, 3.1137, 3.4108, 3.2900],\n",
      "        [3.0288, 3.3935, 3.2199, 3.1935, 3.1600],\n",
      "        [3.2918, 3.1450, 3.1236, 3.2475, 3.2628],\n",
      "        [3.1798, 3.2153, 3.0344, 3.2926, 3.2754],\n",
      "        [3.0344, 3.0750, 3.0219, 3.0771, 3.1155],\n",
      "        [3.0393, 3.1849, 3.1008, 3.1677, 3.1526],\n",
      "        [3.4038, 3.3558, 3.2433, 3.4389, 3.3822],\n",
      "        [3.3333, 3.4619, 3.2259, 3.2532, 3.3055],\n",
      "        [3.0834, 3.1232, 3.1148, 3.1535, 3.3425],\n",
      "        [3.1957, 3.2646, 3.1060, 3.3171, 3.2364],\n",
      "        [3.1632, 3.4013, 3.1771, 3.2982, 3.2766],\n",
      "        [2.9529, 3.0963, 3.0909, 3.1079, 3.0573],\n",
      "        [3.0951, 3.3073, 3.0222, 3.2003, 3.1537],\n",
      "        [3.1234, 3.1661, 3.1474, 3.1977, 3.2713],\n",
      "        [3.2571, 3.2813, 3.2572, 3.3591, 3.2436],\n",
      "        [2.7645, 2.9282, 2.9602, 2.9345, 2.9761],\n",
      "        [3.0230, 3.1061, 3.0576, 3.1966, 3.1621],\n",
      "        [2.9285, 3.1168, 3.0623, 3.0756, 3.0602]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2168, 3.3745, 3.1729, 3.3129, 3.2803],\n",
      "        [3.4118, 3.4702, 3.3269, 3.6429, 3.4789],\n",
      "        [2.9478, 3.1332, 3.1640, 3.0976, 3.1602],\n",
      "        [3.0632, 3.2396, 3.1163, 3.1197, 3.2159],\n",
      "        [3.1317, 3.2125, 3.0866, 3.2593, 3.2432],\n",
      "        [3.1206, 3.4244, 3.1716, 3.3766, 3.3509],\n",
      "        [3.0633, 3.2379, 3.0522, 3.1165, 3.1834],\n",
      "        [3.0071, 2.9419, 3.0469, 3.1194, 3.1288],\n",
      "        [3.1414, 3.1905, 3.0435, 3.2398, 3.1815],\n",
      "        [2.9195, 3.0598, 2.9603, 3.0217, 3.0343],\n",
      "        [3.3511, 3.1470, 3.1559, 3.6403, 3.4483],\n",
      "        [3.0853, 3.2879, 3.1760, 3.2757, 3.3356],\n",
      "        [3.0651, 3.1115, 3.0954, 3.1509, 3.3015],\n",
      "        [3.3500, 3.1790, 3.2646, 3.4255, 3.3273],\n",
      "        [3.2134, 3.2482, 3.2317, 3.3327, 3.1665],\n",
      "        [3.0642, 3.0474, 3.0870, 3.1541, 3.1308],\n",
      "        [3.1975, 3.2163, 3.1469, 3.3252, 3.3506],\n",
      "        [3.1840, 3.1516, 3.0799, 3.3780, 3.2626],\n",
      "        [3.0085, 2.9780, 3.0179, 3.1060, 3.0146],\n",
      "        [3.1932, 3.2856, 3.2269, 3.3221, 3.2524],\n",
      "        [3.0710, 3.1399, 3.0101, 3.2378, 3.1478],\n",
      "        [3.2311, 3.2425, 3.2041, 3.3151, 3.3647],\n",
      "        [3.1959, 3.2768, 3.1353, 3.1701, 3.2054],\n",
      "        [3.0932, 3.2398, 3.0371, 3.3327, 3.1007],\n",
      "        [2.9367, 2.9979, 3.0130, 3.0615, 3.0143],\n",
      "        [3.3383, 3.3052, 3.2774, 3.4761, 3.2620],\n",
      "        [3.0449, 3.1438, 2.9735, 3.1563, 3.1071],\n",
      "        [3.0652, 3.1559, 2.9702, 3.1895, 3.1179],\n",
      "        [3.0645, 3.0637, 3.0896, 3.1669, 3.1325],\n",
      "        [2.8588, 2.9988, 2.9314, 2.9413, 2.9726],\n",
      "        [3.0637, 3.0706, 3.0641, 3.1313, 3.1758],\n",
      "        [2.8179, 2.9613, 2.9862, 2.9711, 3.0239],\n",
      "        [3.1661, 3.2905, 3.0871, 3.3745, 3.2446],\n",
      "        [2.9108, 2.9655, 2.9583, 3.0093, 2.9943],\n",
      "        [3.0783, 3.0648, 3.1246, 3.1723, 3.1719],\n",
      "        [3.0705, 3.0695, 2.9707, 3.1396, 3.2175],\n",
      "        [3.2859, 3.3486, 3.1702, 3.3412, 3.4037],\n",
      "        [3.6579, 3.7858, 3.3711, 3.5321, 3.3921],\n",
      "        [3.0134, 3.0772, 2.8618, 3.1906, 2.9633],\n",
      "        [3.1397, 3.1886, 3.1944, 3.2449, 3.2200],\n",
      "        [3.0749, 3.1607, 2.9671, 3.1979, 3.1212],\n",
      "        [3.0106, 3.1101, 2.9567, 3.1062, 3.0698],\n",
      "        [3.3172, 3.0300, 3.1699, 3.5362, 3.4833],\n",
      "        [3.1714, 3.3177, 3.2286, 3.3209, 3.3253],\n",
      "        [2.9270, 3.0685, 2.9660, 3.0753, 3.0271],\n",
      "        [3.4741, 3.5628, 3.1412, 3.3681, 3.2257],\n",
      "        [3.2819, 3.3972, 3.3368, 3.3396, 3.1729],\n",
      "        [3.1497, 3.1696, 3.1139, 3.3226, 3.1812],\n",
      "        [3.2356, 3.3607, 3.1042, 3.2464, 3.2681],\n",
      "        [3.4001, 3.4720, 3.3397, 3.6385, 3.4738],\n",
      "        [2.9450, 3.0539, 3.0642, 3.0909, 3.0232],\n",
      "        [3.2140, 3.2891, 3.1456, 3.2234, 3.2238],\n",
      "        [3.0367, 3.2798, 3.1798, 3.1085, 3.2142],\n",
      "        [3.2021, 3.1438, 3.1372, 3.1293, 3.0488],\n",
      "        [3.2353, 3.3566, 3.1024, 3.2455, 3.2665],\n",
      "        [2.9594, 3.0219, 3.0444, 3.0906, 3.0108],\n",
      "        [3.0317, 3.1921, 3.1072, 3.0704, 3.0762],\n",
      "        [2.9946, 3.0979, 2.9551, 3.0915, 3.0635],\n",
      "        [2.9288, 3.0329, 3.0258, 3.0567, 3.0240],\n",
      "        [3.1381, 3.3226, 3.1318, 3.3677, 3.2507],\n",
      "        [2.9795, 3.0570, 2.9688, 3.1097, 3.0362],\n",
      "        [3.1876, 3.2459, 3.0808, 3.2325, 3.3390],\n",
      "        [3.1597, 3.1849, 3.1179, 3.3509, 3.1823],\n",
      "        [3.0293, 3.0451, 3.0385, 3.1795, 3.0508]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.0036, 3.0664, 3.0551, 3.0757, 3.0755],\n",
      "        [3.0655, 3.0657, 3.0915, 3.1568, 3.1329],\n",
      "        [3.2528, 3.1162, 3.1272, 3.4848, 3.3294],\n",
      "        [3.2206, 3.2941, 3.2226, 3.2179, 3.2664],\n",
      "        [3.0478, 3.1042, 3.0820, 3.1599, 3.2600],\n",
      "        [2.9003, 3.0397, 2.9560, 2.9926, 3.0164],\n",
      "        [2.9228, 3.0625, 2.9657, 3.0245, 3.0372],\n",
      "        [3.1538, 3.1909, 3.2038, 3.2582, 3.1886],\n",
      "        [3.1166, 3.2903, 3.1342, 3.2604, 3.3230],\n",
      "        [3.2618, 3.2684, 3.1968, 3.3747, 3.4027],\n",
      "        [3.2554, 3.3939, 3.2212, 3.2073, 3.3122],\n",
      "        [2.9553, 3.2470, 3.0816, 2.9775, 3.2145],\n",
      "        [2.8811, 3.0182, 2.9489, 2.9672, 3.0019],\n",
      "        [2.9828, 3.0597, 2.9743, 3.1125, 3.0392],\n",
      "        [2.9899, 3.2693, 3.1092, 3.0047, 3.2379],\n",
      "        [3.1911, 3.2845, 3.2103, 3.3969, 3.2248],\n",
      "        [3.4071, 3.3242, 3.2490, 3.4289, 3.3819],\n",
      "        [3.0518, 3.0515, 2.9545, 3.1205, 3.1953],\n",
      "        [3.0601, 3.1371, 3.0553, 3.1341, 3.1412],\n",
      "        [3.2925, 3.3973, 3.3561, 3.3725, 3.1772],\n",
      "        [3.0507, 3.0720, 3.0934, 3.1721, 3.1357],\n",
      "        [2.9260, 3.0678, 3.0436, 3.0617, 3.0347],\n",
      "        [3.1316, 3.3338, 3.0572, 3.2451, 3.1910],\n",
      "        [2.9445, 3.0252, 3.0306, 3.0664, 3.0288],\n",
      "        [3.1332, 3.2944, 3.1453, 3.1922, 3.2426],\n",
      "        [3.0057, 3.2172, 2.9982, 2.9377, 3.1160],\n",
      "        [3.0562, 3.1493, 2.9711, 3.1693, 3.1134],\n",
      "        [3.3906, 3.4864, 3.1384, 3.3118, 3.2566],\n",
      "        [2.9475, 3.0114, 3.0238, 3.0671, 3.0253],\n",
      "        [3.0930, 3.0750, 3.1473, 3.1815, 3.1846],\n",
      "        [3.0549, 3.1580, 3.1046, 3.1168, 3.0510],\n",
      "        [3.2814, 3.3881, 3.3010, 3.4245, 3.4066],\n",
      "        [3.2497, 3.4665, 3.2612, 3.4894, 3.4399],\n",
      "        [3.0546, 3.1968, 3.1169, 3.1774, 3.1542],\n",
      "        [2.9595, 3.1259, 2.9492, 3.1305, 3.0488],\n",
      "        [3.1185, 3.3480, 3.2655, 3.3274, 3.3373],\n",
      "        [3.0939, 3.1860, 2.9755, 3.2263, 3.1436],\n",
      "        [3.0357, 3.0473, 3.0434, 3.1884, 3.0616],\n",
      "        [2.9322, 3.0356, 3.0313, 3.0596, 3.0270],\n",
      "        [3.2091, 3.0141, 3.0218, 3.1538, 3.1460],\n",
      "        [3.1422, 3.2608, 3.1025, 3.2786, 3.2059],\n",
      "        [2.9748, 2.9812, 3.0061, 3.0911, 3.0188],\n",
      "        [3.0512, 3.0083, 3.1025, 3.1407, 3.1026],\n",
      "        [3.2711, 3.3293, 3.1472, 3.3043, 3.3814],\n",
      "        [3.2920, 3.2782, 3.2051, 3.3195, 3.3154],\n",
      "        [3.1709, 3.1098, 3.2583, 3.3140, 3.2036],\n",
      "        [3.0685, 3.0751, 3.0952, 3.1717, 3.1403],\n",
      "        [3.1743, 3.1184, 3.1575, 3.2399, 3.1592],\n",
      "        [3.1187, 3.2190, 3.0049, 3.1485, 3.1688],\n",
      "        [3.0869, 3.0389, 3.1464, 3.2119, 3.2470],\n",
      "        [2.9711, 2.9358, 2.9859, 3.0932, 2.9932],\n",
      "        [3.0590, 3.0740, 3.0933, 3.1678, 3.1361],\n",
      "        [3.0645, 3.1602, 3.1126, 3.1364, 3.0591],\n",
      "        [3.0599, 3.0512, 3.0857, 3.1505, 3.1278],\n",
      "        [3.0472, 3.1264, 3.0052, 3.1525, 3.1309],\n",
      "        [3.0732, 3.1642, 2.9742, 3.1931, 3.1253],\n",
      "        [3.2391, 3.3637, 3.1100, 3.2494, 3.2712],\n",
      "        [3.0624, 3.2125, 3.0697, 3.1863, 3.2053],\n",
      "        [3.2199, 3.1575, 3.1379, 3.1440, 3.0752],\n",
      "        [3.0812, 3.1703, 2.9784, 3.2032, 3.1331],\n",
      "        [3.0331, 3.0628, 3.2131, 3.0168, 3.2899],\n",
      "        [3.0698, 3.0561, 3.1034, 3.1614, 3.1348],\n",
      "        [3.0567, 3.1896, 3.1370, 3.1694, 3.2615],\n",
      "        [3.2086, 3.1525, 3.0876, 3.4218, 3.2898]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.1335, 3.1339, 3.1128, 3.2648, 3.1765],\n",
      "        [3.3765, 3.1470, 3.1760, 3.6811, 3.4823],\n",
      "        [3.2218, 3.3639, 3.2538, 3.3365, 3.2687],\n",
      "        [3.0194, 2.9603, 3.1138, 2.9848, 3.1747],\n",
      "        [3.1641, 3.2383, 3.0908, 3.2678, 3.2914],\n",
      "        [3.0147, 3.1274, 3.0700, 3.0296, 3.0901],\n",
      "        [3.2603, 3.1933, 3.1690, 3.1976, 3.1205],\n",
      "        [2.9353, 3.0381, 3.0364, 3.0622, 3.0297],\n",
      "        [3.2855, 3.4065, 3.3417, 3.3520, 3.1654],\n",
      "        [3.0695, 3.0512, 3.1067, 3.1597, 3.1331],\n",
      "        [3.1283, 3.0491, 3.1150, 3.1955, 3.1385],\n",
      "        [2.9267, 3.1488, 3.0856, 3.0693, 3.0712],\n",
      "        [3.0582, 3.3602, 3.0951, 3.3369, 3.2628],\n",
      "        [3.3271, 3.1895, 3.2677, 3.4455, 3.2962],\n",
      "        [3.0213, 3.1913, 3.1022, 3.0571, 3.0679],\n",
      "        [3.0180, 3.1735, 3.2955, 3.1613, 3.3062],\n",
      "        [3.2826, 3.3362, 3.3216, 3.3164, 3.1896],\n",
      "        [2.9874, 3.1290, 3.1643, 3.1451, 3.2053],\n",
      "        [3.1771, 3.3438, 3.2554, 3.3207, 3.2294],\n",
      "        [2.9386, 3.1243, 3.0769, 3.0842, 3.0692],\n",
      "        [2.9349, 3.1423, 3.0806, 3.0758, 3.0728],\n",
      "        [2.9104, 3.0487, 2.9632, 3.0102, 3.0298],\n",
      "        [3.0708, 3.1061, 3.1678, 3.1152, 3.2811],\n",
      "        [3.2587, 3.3966, 3.2265, 3.2100, 3.3151],\n",
      "        [3.3325, 3.0254, 3.1584, 3.5741, 3.5113],\n",
      "        [3.3746, 3.3698, 3.2339, 3.4265, 3.4685],\n",
      "        [2.9827, 3.0079, 2.9097, 3.1337, 2.9664],\n",
      "        [3.0382, 3.1974, 3.1180, 3.0761, 3.0821],\n",
      "        [3.1258, 3.0272, 3.1041, 3.1880, 3.0948],\n",
      "        [3.1627, 2.9656, 3.2470, 3.2365, 3.1766],\n",
      "        [3.0687, 3.0683, 3.0968, 3.1594, 3.1356],\n",
      "        [3.4518, 3.5474, 3.1635, 3.3682, 3.2471],\n",
      "        [3.0602, 3.0988, 3.2258, 3.2796, 3.2040],\n",
      "        [2.9709, 3.0847, 3.1199, 3.1331, 3.0324],\n",
      "        [2.9711, 3.0614, 3.0857, 3.1039, 3.0501],\n",
      "        [2.9941, 3.0870, 2.9761, 3.1443, 3.0481],\n",
      "        [3.1753, 3.1959, 3.0237, 3.2314, 3.2817],\n",
      "        [3.0359, 3.0503, 3.0493, 3.1850, 3.0566],\n",
      "        [3.0901, 3.0415, 3.1517, 3.2145, 3.2498],\n",
      "        [3.3686, 3.3113, 3.2145, 3.3945, 3.3585],\n",
      "        [3.2229, 3.1834, 3.2730, 3.2454, 3.0567],\n",
      "        [3.0469, 3.2834, 3.1200, 3.1591, 3.0482],\n",
      "        [2.9305, 3.1023, 3.0656, 3.0775, 3.0584],\n",
      "        [3.0727, 3.0473, 3.1337, 3.1606, 3.1291],\n",
      "        [3.1582, 3.1482, 3.1097, 3.3112, 3.2019],\n",
      "        [3.0766, 3.0576, 3.1081, 3.1614, 3.1386],\n",
      "        [3.3036, 3.2787, 3.2707, 3.4520, 3.3144],\n",
      "        [3.0966, 3.0732, 3.1655, 3.2247, 3.2006],\n",
      "        [3.0711, 3.0690, 3.1006, 3.1725, 3.1384],\n",
      "        [2.9295, 3.0650, 2.9675, 3.0219, 3.0374],\n",
      "        [3.1632, 2.9965, 3.2364, 3.2496, 3.2045],\n",
      "        [3.2015, 3.2173, 3.1809, 3.2229, 3.0214],\n",
      "        [3.1035, 3.1278, 3.1342, 3.1049, 2.9916],\n",
      "        [3.1296, 3.1100, 3.2046, 3.2502, 3.2216],\n",
      "        [3.3129, 3.2916, 3.2927, 3.4174, 3.3110],\n",
      "        [3.0303, 3.3378, 3.2040, 3.2496, 3.3398],\n",
      "        [3.1099, 3.1147, 3.1309, 3.0950, 2.9974],\n",
      "        [3.2110, 3.3300, 3.1290, 3.4198, 3.2995],\n",
      "        [3.3940, 3.2532, 3.3107, 3.5492, 3.4193],\n",
      "        [3.0661, 3.0915, 3.1054, 3.1812, 3.1481],\n",
      "        [3.0856, 3.3652, 3.2179, 3.2224, 3.1377],\n",
      "        [2.9658, 3.0888, 2.9711, 3.0625, 3.0551],\n",
      "        [3.0951, 3.1271, 3.1328, 3.1631, 3.3529],\n",
      "        [3.0172, 2.9583, 2.9895, 3.1014, 3.0048]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.0254, 3.1937, 3.1070, 3.0603, 3.0705],\n",
      "        [3.0475, 3.0163, 3.0844, 3.1102, 3.0887],\n",
      "        [2.9527, 3.0308, 3.0452, 3.0750, 3.0355],\n",
      "        [3.0784, 3.2110, 3.1428, 3.1938, 3.1316],\n",
      "        [3.0000, 3.0647, 2.9805, 3.1334, 3.0469],\n",
      "        [3.0758, 3.1194, 3.1115, 3.1600, 3.3102],\n",
      "        [3.3917, 3.5139, 3.2502, 3.3112, 3.2949],\n",
      "        [3.0791, 3.0442, 3.1416, 3.1756, 3.1393],\n",
      "        [3.1049, 3.2651, 3.1306, 3.3324, 3.1581],\n",
      "        [3.1582, 3.3175, 3.1607, 3.3823, 3.2554],\n",
      "        [3.1105, 3.2004, 2.9933, 3.2443, 3.1547],\n",
      "        [3.0763, 3.0519, 3.1130, 3.1621, 3.1323],\n",
      "        [2.9914, 3.1106, 2.9836, 3.0935, 3.0832],\n",
      "        [3.3123, 3.1856, 3.2593, 3.4510, 3.2831],\n",
      "        [2.9936, 3.0672, 3.1146, 3.1978, 3.1589],\n",
      "        [2.9473, 3.0055, 3.0283, 3.0700, 3.0224],\n",
      "        [3.0756, 3.0227, 3.0003, 3.2400, 3.0373],\n",
      "        [3.1421, 3.1153, 3.2115, 3.2510, 3.2209],\n",
      "        [2.9249, 3.1345, 3.0798, 3.0694, 3.0603],\n",
      "        [3.2952, 3.4154, 3.3527, 3.3600, 3.1823],\n",
      "        [3.0888, 3.1496, 3.0361, 3.2401, 3.1543],\n",
      "        [2.8828, 2.9368, 2.9529, 2.9709, 2.9624],\n",
      "        [3.0030, 3.0464, 3.0936, 3.1776, 3.1501],\n",
      "        [2.9963, 3.2688, 3.2118, 3.1745, 3.3031],\n",
      "        [3.1222, 3.3237, 3.0491, 3.2390, 3.1743],\n",
      "        [3.2153, 3.3325, 3.1340, 3.4230, 3.3020],\n",
      "        [3.1342, 3.0410, 3.1147, 3.1977, 3.1059],\n",
      "        [3.2893, 3.3934, 3.3118, 3.4305, 3.4122],\n",
      "        [2.9904, 2.9722, 3.0095, 3.1063, 3.0221],\n",
      "        [3.0808, 3.0601, 3.1129, 3.1645, 3.1411],\n",
      "        [3.3329, 3.2340, 3.1755, 3.3082, 3.3324],\n",
      "        [2.9850, 3.0051, 3.0432, 3.1014, 3.0154],\n",
      "        [3.2541, 3.2733, 3.2076, 3.3644, 3.4091],\n",
      "        [3.0861, 3.0349, 3.1453, 3.2020, 3.2415],\n",
      "        [3.0900, 3.1692, 2.9765, 3.2063, 3.1246],\n",
      "        [3.0768, 3.0498, 3.1386, 3.1637, 3.1316],\n",
      "        [3.2148, 3.2257, 3.1957, 3.2359, 3.0452],\n",
      "        [3.1958, 3.2885, 3.2629, 3.3095, 3.2372],\n",
      "        [3.0958, 3.3845, 3.1474, 3.3302, 3.3092],\n",
      "        [3.2509, 3.2828, 3.2855, 3.4474, 3.2330],\n",
      "        [3.0023, 3.3018, 3.1839, 3.2119, 3.3031],\n",
      "        [3.1988, 3.3402, 3.2682, 3.3554, 3.2461],\n",
      "        [3.0665, 3.0893, 3.1829, 3.1004, 3.2797],\n",
      "        [2.9344, 3.0917, 3.2101, 3.0669, 3.2143],\n",
      "        [3.1679, 3.1594, 3.1376, 3.2321, 3.1578],\n",
      "        [3.3149, 3.1973, 3.2687, 3.4552, 3.2918],\n",
      "        [3.1924, 3.3038, 3.2405, 3.3313, 3.2860],\n",
      "        [3.4448, 3.1714, 3.2543, 3.7605, 3.6526],\n",
      "        [2.9064, 2.9565, 2.9673, 2.9969, 2.9939],\n",
      "        [3.1456, 3.1536, 3.1221, 3.2944, 3.1816],\n",
      "        [3.1068, 3.1924, 3.0011, 3.2343, 3.1552],\n",
      "        [3.0896, 3.0742, 3.1341, 3.1767, 3.1823],\n",
      "        [3.2028, 3.1717, 3.1873, 3.2110, 3.0852],\n",
      "        [3.2612, 3.1881, 3.1619, 3.1847, 3.0997],\n",
      "        [3.2788, 3.3347, 3.1576, 3.3102, 3.3869],\n",
      "        [3.1135, 3.0963, 3.1936, 3.2388, 3.2130],\n",
      "        [2.9923, 2.9781, 3.0167, 3.1041, 3.0269],\n",
      "        [3.4845, 3.5719, 3.1570, 3.3770, 3.2344],\n",
      "        [3.0961, 3.0779, 3.1538, 3.1838, 3.1854],\n",
      "        [3.1056, 3.0916, 3.1918, 3.2349, 3.2069],\n",
      "        [2.9205, 3.1395, 3.1703, 3.0821, 3.1843],\n",
      "        [3.2772, 3.4341, 3.2422, 3.4616, 3.3865],\n",
      "        [3.0760, 3.0763, 2.9895, 3.1393, 3.2137],\n",
      "        [3.2721, 3.2918, 3.2774, 3.3717, 3.2562]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3364, 3.3195, 3.2825, 3.4838, 3.3039],\n",
      "        [3.2401, 3.3234, 3.1541, 3.3730, 3.3482],\n",
      "        [2.9713, 3.1074, 3.0123, 3.1581, 3.0628],\n",
      "        [3.3990, 3.2978, 3.3140, 3.4419, 3.3959],\n",
      "        [3.1350, 3.3115, 3.0983, 3.0527, 3.1615],\n",
      "        [3.2283, 3.3373, 3.2339, 3.3503, 3.2690],\n",
      "        [3.1226, 3.2285, 3.0413, 3.1478, 3.1856],\n",
      "        [3.0579, 3.1396, 3.1046, 3.2672, 3.1382],\n",
      "        [2.9822, 2.9479, 2.9973, 3.0960, 3.0045],\n",
      "        [3.1828, 3.1707, 3.1469, 3.2449, 3.1777],\n",
      "        [3.0623, 3.1907, 3.1404, 3.1686, 3.2700],\n",
      "        [3.4023, 3.4429, 3.3501, 3.6172, 3.4168],\n",
      "        [2.9448, 3.0906, 3.0700, 3.0841, 3.0637],\n",
      "        [3.0305, 3.1960, 3.1115, 3.0632, 3.0738],\n",
      "        [2.9062, 2.9718, 2.9675, 2.9966, 2.9928],\n",
      "        [3.0298, 3.1268, 2.9842, 3.1282, 3.1027],\n",
      "        [2.9195, 3.0532, 2.9722, 3.0159, 3.0353],\n",
      "        [3.0795, 3.1074, 3.0442, 3.2287, 3.1287],\n",
      "        [3.0823, 3.0511, 3.1300, 3.1654, 3.1326],\n",
      "        [2.9366, 3.1317, 3.0808, 3.0721, 3.0618],\n",
      "        [3.1295, 3.2648, 3.1240, 3.2835, 3.1679],\n",
      "        [3.2613, 3.2523, 3.2159, 3.2988, 3.3714],\n",
      "        [2.8341, 2.9711, 3.0060, 2.9823, 3.0351],\n",
      "        [3.0509, 3.0364, 3.0993, 3.1240, 3.1115],\n",
      "        [3.0139, 3.0589, 3.0863, 3.1508, 3.0475],\n",
      "        [3.0951, 3.1714, 2.9810, 3.2090, 3.1278],\n",
      "        [3.0970, 3.1591, 3.0300, 3.1932, 3.1708],\n",
      "        [2.9792, 3.0946, 2.9839, 3.0688, 3.0668],\n",
      "        [3.0778, 3.0862, 3.1136, 3.1756, 3.1474],\n",
      "        [3.0882, 3.1257, 3.1847, 3.2059, 3.2621],\n",
      "        [3.0600, 3.2040, 3.1466, 3.1850, 3.2244],\n",
      "        [3.0508, 3.0007, 3.0453, 3.1222, 3.2097],\n",
      "        [3.3058, 3.4049, 3.3715, 3.3813, 3.1859],\n",
      "        [3.2093, 3.3072, 3.1547, 3.3043, 3.2362],\n",
      "        [3.2488, 3.3600, 3.2639, 3.3332, 3.2573],\n",
      "        [2.9789, 2.9433, 2.9950, 3.0930, 3.0021],\n",
      "        [3.4767, 3.1963, 3.2856, 3.7655, 3.6763],\n",
      "        [3.2499, 3.3456, 3.2351, 3.2173, 3.2920],\n",
      "        [2.9924, 3.0069, 2.9219, 3.1445, 3.0182],\n",
      "        [3.1403, 3.3518, 3.1934, 3.2977, 3.3600],\n",
      "        [3.0052, 3.0669, 2.9849, 3.1361, 3.0501],\n",
      "        [2.8910, 3.1076, 2.8774, 3.0888, 2.9539],\n",
      "        [3.0842, 3.1058, 3.1280, 3.1938, 3.1756],\n",
      "        [3.2186, 3.3327, 3.1378, 3.4248, 3.3022],\n",
      "        [3.1874, 3.2112, 3.0933, 3.2364, 3.3500],\n",
      "        [3.2249, 3.3330, 3.1146, 3.2597, 3.2900],\n",
      "        [3.0660, 3.3597, 3.1382, 3.2983, 3.2946],\n",
      "        [3.0430, 2.9749, 3.0868, 3.1501, 3.1516],\n",
      "        [3.3597, 3.2449, 3.3037, 3.5086, 3.3411],\n",
      "        [3.0299, 3.0957, 2.9113, 3.2049, 3.0004],\n",
      "        [3.1819, 3.2114, 3.1484, 3.3799, 3.2000],\n",
      "        [3.3810, 3.2938, 3.2497, 3.5164, 3.3640],\n",
      "        [3.0010, 3.0298, 2.9312, 3.1615, 3.0445],\n",
      "        [3.2562, 3.2852, 3.2902, 3.4504, 3.2365],\n",
      "        [3.1898, 3.2103, 3.1731, 3.2082, 3.0048],\n",
      "        [3.1815, 3.3094, 3.1157, 3.2536, 3.2341],\n",
      "        [3.2165, 3.0645, 3.0309, 3.1246, 3.2142],\n",
      "        [3.0819, 3.0881, 3.1211, 3.1925, 3.1721],\n",
      "        [3.1045, 3.0915, 3.1746, 3.2248, 3.1889],\n",
      "        [2.9921, 2.9524, 2.9991, 3.1057, 3.0173],\n",
      "        [2.8642, 2.9951, 3.0097, 3.0177, 3.0456],\n",
      "        [3.0518, 3.1974, 3.1310, 3.1811, 3.1703],\n",
      "        [3.0409, 2.9901, 3.0299, 3.1036, 3.2025],\n",
      "        [3.1581, 3.2055, 3.0851, 3.2642, 3.2154]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.1219, 3.1963, 3.1385, 3.2224, 3.2285],\n",
      "        [3.6281, 3.8248, 3.3574, 3.5441, 3.3869],\n",
      "        [3.2369, 3.3638, 3.2637, 3.3348, 3.2595],\n",
      "        [3.1415, 3.3369, 3.1815, 3.2922, 3.3577],\n",
      "        [3.2900, 3.2739, 3.3838, 3.2681, 3.1454],\n",
      "        [3.2010, 3.2336, 3.0819, 3.3118, 3.2698],\n",
      "        [3.0474, 3.2388, 3.0920, 3.1483, 3.1019],\n",
      "        [2.9966, 3.0626, 2.9630, 3.1525, 3.0579],\n",
      "        [2.9511, 3.0576, 3.0597, 3.0750, 3.0422],\n",
      "        [3.2237, 3.3349, 3.1421, 3.4274, 3.3052],\n",
      "        [3.1883, 3.4160, 3.2061, 3.3157, 3.2948],\n",
      "        [2.9328, 3.1777, 3.0254, 2.9196, 3.1034],\n",
      "        [2.9468, 3.0612, 2.9832, 3.0331, 3.0404],\n",
      "        [3.0787, 3.0913, 3.1171, 3.1947, 3.1567],\n",
      "        [3.1870, 3.3262, 3.1986, 3.3991, 3.2662],\n",
      "        [3.3649, 3.2472, 3.3080, 3.5113, 3.3442],\n",
      "        [3.0767, 3.0723, 3.1156, 3.1838, 3.1555],\n",
      "        [3.0050, 3.2099, 2.9825, 3.1544, 3.0306],\n",
      "        [3.2981, 3.1284, 3.0654, 3.2093, 3.2539],\n",
      "        [3.0899, 3.0259, 3.1447, 3.1911, 3.2391],\n",
      "        [3.1534, 3.0981, 3.2318, 3.3900, 3.4214],\n",
      "        [3.2730, 3.3812, 3.1180, 3.2519, 3.2704],\n",
      "        [3.0612, 3.1192, 3.0277, 3.1155, 3.0944],\n",
      "        [2.9873, 2.9980, 3.0343, 3.0957, 3.0351],\n",
      "        [3.0887, 3.1046, 3.1827, 3.1265, 3.2929],\n",
      "        [3.2896, 3.2797, 3.2189, 3.3074, 3.3259],\n",
      "        [2.9575, 3.0201, 3.0024, 3.0613, 3.0358],\n",
      "        [2.8774, 3.0028, 2.9537, 2.9530, 2.9822],\n",
      "        [3.2520, 3.2557, 3.2300, 3.3305, 3.3806],\n",
      "        [3.3381, 3.4377, 3.1360, 3.2877, 3.2713],\n",
      "        [3.2227, 3.2097, 3.2081, 3.2303, 3.0779],\n",
      "        [3.2258, 3.3369, 3.1430, 3.4285, 3.3085],\n",
      "        [3.0606, 3.1315, 3.0964, 3.2059, 3.2159],\n",
      "        [3.3752, 3.4682, 3.1495, 3.3058, 3.2712],\n",
      "        [3.0761, 3.1169, 3.1119, 3.1697, 3.2944],\n",
      "        [3.1890, 3.1842, 3.2605, 3.3056, 3.2100],\n",
      "        [3.1592, 3.3352, 3.1566, 3.3820, 3.2655],\n",
      "        [2.9208, 3.0570, 2.9798, 3.0133, 3.0346],\n",
      "        [2.9773, 3.1104, 3.1188, 3.1248, 3.0748],\n",
      "        [3.1506, 3.3041, 3.1645, 3.2040, 3.2547],\n",
      "        [2.9860, 3.0345, 2.9510, 3.1400, 2.9767],\n",
      "        [3.0750, 3.0741, 3.1057, 3.1691, 3.1432],\n",
      "        [3.2306, 3.2934, 3.1452, 3.3384, 3.2561],\n",
      "        [3.3761, 3.3870, 3.2773, 3.5715, 3.4360],\n",
      "        [3.1932, 3.1270, 3.1779, 3.2479, 3.1763],\n",
      "        [3.0781, 3.1191, 3.0632, 3.2324, 3.1657],\n",
      "        [3.2258, 3.3369, 3.1430, 3.4285, 3.3085],\n",
      "        [3.1202, 3.2459, 3.0811, 3.1462, 3.2094],\n",
      "        [3.0965, 3.1456, 3.0314, 3.2406, 3.1524],\n",
      "        [2.9528, 3.1310, 3.0901, 3.0925, 3.0777],\n",
      "        [2.9206, 2.9593, 3.0096, 3.0289, 2.9554],\n",
      "        [3.0160, 3.1205, 2.9932, 3.0971, 3.0987],\n",
      "        [3.0165, 3.1131, 3.0293, 3.1244, 3.1056],\n",
      "        [2.9365, 3.0643, 2.9790, 3.0270, 3.0436],\n",
      "        [3.0910, 3.1763, 2.9968, 3.2086, 3.1380],\n",
      "        [3.0940, 3.2945, 3.1455, 3.1893, 3.0654],\n",
      "        [3.2399, 3.3290, 3.1174, 3.2659, 3.3016],\n",
      "        [2.9490, 3.1267, 3.0866, 3.0780, 3.0622],\n",
      "        [3.0769, 3.2311, 3.1278, 3.3405, 3.1654],\n",
      "        [3.4939, 3.5769, 3.1657, 3.3826, 3.2409],\n",
      "        [3.0383, 3.1254, 2.9770, 3.1337, 3.0864],\n",
      "        [3.5325, 3.7132, 3.2488, 3.4171, 3.3344],\n",
      "        [3.2457, 3.0997, 3.1192, 3.5371, 3.3365],\n",
      "        [3.0669, 3.1581, 2.9896, 3.1648, 3.1242]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.9569, 2.9466, 3.0049, 3.0805, 3.0315],\n",
      "        [3.1220, 3.3736, 3.2610, 3.3179, 3.3762],\n",
      "        [3.1945, 3.4220, 3.2940, 3.3420, 3.3902],\n",
      "        [3.0361, 2.9893, 3.0410, 3.1275, 3.0304],\n",
      "        [3.2149, 3.1360, 3.2049, 3.2887, 3.1979],\n",
      "        [3.2379, 3.3415, 3.2422, 3.3552, 3.2749],\n",
      "        [2.9554, 3.1464, 3.1000, 3.0931, 3.0906],\n",
      "        [3.2733, 3.4779, 3.2852, 3.5031, 3.4546],\n",
      "        [3.2428, 3.3061, 3.1678, 3.2522, 3.2500],\n",
      "        [3.1715, 3.1953, 3.0885, 3.2876, 3.2228],\n",
      "        [3.0858, 3.2191, 3.1741, 3.1904, 3.3033],\n",
      "        [2.9893, 2.9942, 3.0301, 3.0990, 3.0350],\n",
      "        [3.3447, 3.2867, 3.2879, 3.4308, 3.2299],\n",
      "        [2.9600, 3.1713, 3.1097, 3.1033, 3.1066],\n",
      "        [3.1500, 3.3761, 3.2184, 3.3084, 3.3707],\n",
      "        [3.0106, 3.0517, 3.0875, 3.1517, 3.0395],\n",
      "        [3.6499, 3.7693, 3.3806, 3.5093, 3.3797],\n",
      "        [3.3239, 3.2880, 3.2888, 3.4634, 3.3266],\n",
      "        [3.0688, 3.0144, 3.0688, 3.1447, 3.2250],\n",
      "        [3.0597, 3.0047, 3.0534, 3.1272, 3.2156],\n",
      "        [3.2308, 3.2781, 3.2603, 3.3512, 3.2138],\n",
      "        [3.1222, 3.0680, 3.1748, 3.2084, 3.1574],\n",
      "        [3.3303, 3.2039, 3.2814, 3.4635, 3.3012],\n",
      "        [3.0622, 3.2943, 3.2090, 3.1258, 3.2324],\n",
      "        [3.2780, 3.3589, 3.3476, 3.3069, 3.1129],\n",
      "        [3.1039, 3.1558, 3.0487, 3.2476, 3.1631],\n",
      "        [3.0021, 2.9935, 3.0344, 3.1064, 3.0397],\n",
      "        [3.0628, 3.0908, 3.0533, 3.0961, 3.1357],\n",
      "        [2.9574, 3.1328, 3.0940, 3.0947, 3.0803],\n",
      "        [2.9855, 2.9491, 3.0022, 3.0999, 3.0082],\n",
      "        [3.2374, 3.3167, 3.1656, 3.3388, 3.2714],\n",
      "        [3.0987, 3.1768, 3.0025, 3.2147, 3.1451],\n",
      "        [3.0897, 3.0829, 3.1560, 3.2006, 3.1706],\n",
      "        [3.0819, 3.1482, 3.0776, 3.1473, 3.1551],\n",
      "        [3.2421, 3.2152, 3.2509, 3.3535, 3.1106],\n",
      "        [2.9325, 2.9558, 3.0103, 3.0272, 2.9652],\n",
      "        [2.9946, 3.1796, 3.2719, 3.1554, 3.2317],\n",
      "        [3.0024, 3.0571, 3.0963, 3.1458, 3.0345],\n",
      "        [3.1220, 3.3669, 3.2447, 3.2649, 3.1759],\n",
      "        [3.1054, 3.0513, 3.0286, 3.2483, 3.0708],\n",
      "        [3.2110, 3.1418, 3.1896, 3.2739, 3.1823],\n",
      "        [3.0025, 3.0175, 2.9333, 3.1454, 2.9548],\n",
      "        [2.9429, 2.9192, 2.9913, 3.1165, 3.0124],\n",
      "        [3.2267, 3.3227, 3.2594, 3.2750, 3.1346],\n",
      "        [3.1780, 3.2582, 3.0835, 3.2745, 3.2655],\n",
      "        [3.0902, 3.1696, 2.9980, 3.2054, 3.1349],\n",
      "        [2.9899, 3.1138, 3.0559, 3.2262, 3.0380],\n",
      "        [3.0359, 3.2795, 3.0859, 3.1082, 3.0601],\n",
      "        [3.0483, 3.1164, 3.2232, 3.1892, 3.2374],\n",
      "        [3.3992, 3.3057, 3.2710, 3.4237, 3.3603],\n",
      "        [3.1394, 3.3018, 3.1575, 3.2741, 3.3372],\n",
      "        [3.3173, 3.3242, 3.3028, 3.3649, 3.4161],\n",
      "        [3.1354, 3.1104, 3.1938, 3.2154, 3.2247],\n",
      "        [3.0881, 3.0849, 3.0924, 3.1483, 3.1938],\n",
      "        [3.2064, 3.3355, 3.2330, 3.4265, 3.2705],\n",
      "        [3.0668, 3.1184, 3.0989, 3.1828, 3.2560],\n",
      "        [3.3125, 3.2902, 3.2287, 3.3345, 3.3311],\n",
      "        [3.4798, 3.6565, 3.2146, 3.3823, 3.2523],\n",
      "        [3.2658, 3.2309, 3.3970, 3.2268, 3.1714],\n",
      "        [3.2255, 3.3162, 3.1479, 3.2667, 3.2603],\n",
      "        [3.3607, 3.0412, 3.1964, 3.5763, 3.5151],\n",
      "        [3.1884, 3.2039, 3.0375, 3.2373, 3.2821],\n",
      "        [3.2341, 3.2968, 3.2610, 3.3461, 3.2481],\n",
      "        [3.4275, 3.3363, 3.2727, 3.4443, 3.3980]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2354, 3.3423, 3.2948, 3.2924, 3.1694],\n",
      "        [3.1131, 3.0516, 3.1743, 3.2241, 3.2610],\n",
      "        [2.9883, 3.1895, 3.2716, 3.1734, 3.2150],\n",
      "        [3.2778, 3.4797, 3.2903, 3.5053, 3.4572],\n",
      "        [2.9944, 3.0950, 3.1419, 3.1458, 3.0461],\n",
      "        [3.2215, 3.1801, 3.2050, 3.2210, 3.0970],\n",
      "        [3.0256, 3.1978, 2.9980, 3.1933, 3.0484],\n",
      "        [3.1909, 3.3540, 3.2733, 3.3364, 3.2321],\n",
      "        [3.1511, 3.0660, 3.1502, 3.2112, 3.1759],\n",
      "        [3.1994, 3.2282, 3.2615, 3.2347, 3.1372],\n",
      "        [3.2423, 3.3062, 3.1759, 3.2599, 3.2430],\n",
      "        [3.1708, 3.1828, 3.1540, 3.2363, 3.1905],\n",
      "        [3.2279, 3.3559, 3.1482, 3.2704, 3.2981],\n",
      "        [3.0916, 3.0565, 3.1301, 3.1769, 3.1380],\n",
      "        [3.2451, 3.3054, 3.2711, 3.4444, 3.2440],\n",
      "        [2.8480, 2.9768, 3.0185, 2.9889, 3.0430],\n",
      "        [3.0448, 3.1335, 3.0012, 3.1250, 3.1189],\n",
      "        [3.4839, 3.6586, 3.2195, 3.3845, 3.2549],\n",
      "        [3.0469, 3.1290, 2.9855, 3.1380, 3.0914],\n",
      "        [3.2329, 3.3387, 3.1511, 3.4319, 3.3106],\n",
      "        [3.2825, 3.4076, 3.2492, 3.2233, 3.3295],\n",
      "        [3.2915, 3.0551, 3.1927, 3.4736, 3.4552],\n",
      "        [3.1196, 3.0841, 3.1879, 3.2375, 3.2145],\n",
      "        [3.2499, 3.2706, 3.2407, 3.3661, 3.3773],\n",
      "        [3.5479, 3.2304, 3.3521, 3.8485, 3.7453],\n",
      "        [3.0722, 3.1544, 3.0010, 3.1521, 3.1264],\n",
      "        [3.5408, 3.6504, 3.2924, 3.4224, 3.2972],\n",
      "        [2.9901, 3.1879, 3.2716, 3.1749, 3.2113],\n",
      "        [3.1264, 3.0699, 3.1796, 3.2104, 3.1599],\n",
      "        [3.0625, 3.0583, 3.0538, 3.1100, 3.1655],\n",
      "        [2.9714, 3.0387, 3.0622, 3.0846, 3.0467],\n",
      "        [3.1229, 3.0175, 3.1086, 3.0909, 3.0766],\n",
      "        [3.3926, 3.3013, 3.2624, 3.5297, 3.3708],\n",
      "        [3.0944, 3.1005, 3.1310, 3.1981, 3.1739],\n",
      "        [3.4163, 3.5009, 3.1664, 3.3277, 3.2738],\n",
      "        [2.9954, 3.1766, 2.9588, 3.1455, 3.0267],\n",
      "        [2.9622, 3.1721, 3.1196, 3.0921, 3.0946],\n",
      "        [3.2490, 3.3284, 3.1311, 3.2735, 3.3144],\n",
      "        [3.6542, 3.7956, 3.3656, 3.5184, 3.4191],\n",
      "        [3.3218, 3.3262, 3.3078, 3.3671, 3.4187],\n",
      "        [3.2385, 3.2987, 3.2660, 3.3483, 3.2507],\n",
      "        [3.1456, 3.2320, 3.0328, 3.1640, 3.1857],\n",
      "        [3.3063, 3.4000, 3.3265, 3.4341, 3.4213],\n",
      "        [2.8873, 3.0138, 2.9626, 2.9587, 2.9913],\n",
      "        [3.1325, 3.1250, 3.1530, 3.1075, 3.0111],\n",
      "        [2.9581, 3.0484, 3.0581, 3.0748, 3.0433],\n",
      "        [3.0828, 3.1002, 3.0313, 3.2120, 3.1073],\n",
      "        [3.0786, 3.1797, 3.2728, 3.1482, 3.1835],\n",
      "        [3.1653, 3.1314, 3.2443, 3.2633, 3.2394],\n",
      "        [3.3690, 3.3712, 3.2363, 3.4095, 3.4546],\n",
      "        [3.1122, 3.0913, 3.1726, 3.2170, 3.1794],\n",
      "        [2.9580, 3.1526, 3.1024, 3.0883, 3.0863],\n",
      "        [2.9860, 3.1386, 2.9758, 3.1454, 3.0647],\n",
      "        [3.0729, 3.0162, 3.0736, 3.1468, 3.2276],\n",
      "        [2.9154, 3.0502, 3.0131, 3.0726, 3.0673],\n",
      "        [3.2742, 3.0436, 3.0329, 3.1390, 3.2310],\n",
      "        [3.1914, 3.4931, 3.2332, 3.4452, 3.4036],\n",
      "        [2.9065, 3.0337, 2.9755, 2.9808, 3.0217],\n",
      "        [3.2685, 3.3345, 3.2630, 3.2498, 3.2989],\n",
      "        [3.2035, 3.2271, 3.1217, 3.2478, 3.1911],\n",
      "        [3.1725, 3.0673, 3.3613, 3.2706, 3.2904],\n",
      "        [3.1365, 3.1802, 3.1495, 3.2053, 3.1913],\n",
      "        [2.9520, 3.0805, 3.0704, 3.0768, 3.0509],\n",
      "        [3.0992, 3.1081, 3.2228, 3.3133, 3.3581]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.1607, 3.4067, 3.2554, 3.3207, 3.3786],\n",
      "        [3.1249, 3.2004, 3.0070, 3.2433, 3.1633],\n",
      "        [3.2176, 3.1519, 3.1679, 3.1273, 3.0533],\n",
      "        [3.4625, 3.4770, 3.3448, 3.7067, 3.5194],\n",
      "        [3.0645, 3.1451, 2.9984, 3.1503, 3.1161],\n",
      "        [3.0931, 3.2665, 3.1728, 3.1328, 3.2467],\n",
      "        [3.2304, 3.1987, 3.2159, 3.2307, 3.0995],\n",
      "        [3.2539, 3.3624, 3.2701, 3.3589, 3.2871],\n",
      "        [3.2609, 3.3338, 3.1388, 3.2784, 3.3208],\n",
      "        [3.0444, 3.1810, 3.0435, 3.2477, 3.0920],\n",
      "        [3.2400, 3.1718, 3.1278, 3.4498, 3.3234],\n",
      "        [3.3526, 3.0482, 3.2082, 3.5561, 3.5058],\n",
      "        [3.1041, 3.1786, 3.0056, 3.2100, 3.1449],\n",
      "        [3.2546, 3.3346, 3.1312, 3.2723, 3.3103],\n",
      "        [3.2731, 3.2358, 3.4078, 3.2349, 3.1800],\n",
      "        [3.2069, 3.1546, 3.2038, 3.1931, 3.1175],\n",
      "        [3.2390, 3.2277, 3.2186, 3.2471, 3.0734],\n",
      "        [3.3131, 3.1313, 3.1692, 3.5679, 3.3986],\n",
      "        [2.9414, 3.0608, 2.9925, 3.0158, 3.0430],\n",
      "        [3.0189, 2.9837, 3.0345, 3.1219, 3.0384],\n",
      "        [3.2779, 3.2434, 3.2916, 3.3448, 3.1742],\n",
      "        [3.1750, 3.1311, 3.2466, 3.2737, 3.2458],\n",
      "        [3.3891, 3.4740, 3.1630, 3.3123, 3.2798],\n",
      "        [3.0586, 2.9975, 3.0470, 3.1128, 3.2142],\n",
      "        [3.0140, 2.9350, 3.1161, 2.9442, 3.1701],\n",
      "        [3.2967, 3.0568, 3.1973, 3.4754, 3.4583],\n",
      "        [3.2607, 3.1970, 3.3471, 3.2527, 3.1318],\n",
      "        [3.4481, 3.5298, 3.1727, 3.3457, 3.2721],\n",
      "        [3.3212, 3.2939, 3.2381, 3.3389, 3.3373],\n",
      "        [3.2547, 3.1700, 3.1765, 3.1685, 3.0927],\n",
      "        [3.0643, 3.1253, 3.1284, 3.1891, 3.0964],\n",
      "        [3.2057, 3.2103, 3.0524, 3.3275, 3.3127],\n",
      "        [3.1182, 3.1717, 2.9772, 3.2235, 3.0505],\n",
      "        [3.4262, 3.5063, 3.3697, 3.6837, 3.5248],\n",
      "        [3.0995, 3.0813, 3.1278, 3.1875, 3.1556],\n",
      "        [3.3230, 3.2763, 3.2946, 3.4330, 3.3292],\n",
      "        [3.2289, 3.2259, 3.0514, 3.3396, 3.3357],\n",
      "        [3.0110, 3.0141, 2.9386, 3.1528, 3.0291],\n",
      "        [3.1017, 3.4119, 3.2593, 3.1943, 3.1984],\n",
      "        [3.7151, 3.8307, 3.4382, 3.5657, 3.4432],\n",
      "        [3.2373, 3.2967, 3.3009, 3.3562, 3.3439],\n",
      "        [3.4057, 3.1599, 3.2039, 3.6957, 3.4992],\n",
      "        [3.1968, 3.4948, 3.2379, 3.4472, 3.4069],\n",
      "        [3.4950, 3.2458, 3.3925, 3.8696, 3.7433],\n",
      "        [3.1173, 3.0032, 3.0977, 3.0748, 3.0619],\n",
      "        [3.1907, 3.3762, 3.2767, 3.3275, 3.4414],\n",
      "        [3.1083, 3.2415, 3.1073, 3.1967, 3.2375],\n",
      "        [2.9859, 3.0079, 3.0472, 3.0903, 3.0394],\n",
      "        [3.2431, 3.1645, 3.1716, 3.1567, 3.0852],\n",
      "        [3.7241, 3.8366, 3.4425, 3.5778, 3.4422],\n",
      "        [3.1794, 3.2900, 3.2040, 3.2497, 3.1164],\n",
      "        [3.2081, 3.4165, 3.2201, 3.3185, 3.3098],\n",
      "        [3.1302, 3.2749, 3.1535, 3.3441, 3.1728],\n",
      "        [3.0715, 3.0120, 3.1258, 3.1498, 3.1119],\n",
      "        [3.3333, 3.3311, 3.2662, 3.4832, 3.3148],\n",
      "        [3.0893, 3.0944, 3.1286, 3.1927, 3.1629],\n",
      "        [3.2062, 3.1603, 3.1383, 3.3663, 3.2643],\n",
      "        [3.0147, 3.0061, 3.0603, 3.1180, 3.0288],\n",
      "        [3.2018, 3.4305, 3.3050, 3.3421, 3.3900],\n",
      "        [3.5186, 3.6157, 3.3242, 3.4203, 3.3524],\n",
      "        [3.0937, 3.0266, 3.1211, 3.1875, 3.2440],\n",
      "        [3.2403, 3.3425, 3.1566, 3.4349, 3.3172],\n",
      "        [3.0719, 3.2933, 3.2204, 3.1294, 3.2355],\n",
      "        [3.0989, 3.0459, 3.1491, 3.1643, 3.1437]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2190, 3.4791, 3.3209, 3.3774, 3.4292],\n",
      "        [3.0738, 3.3000, 3.1458, 3.1665, 3.0765],\n",
      "        [3.0213, 3.1142, 3.0019, 3.1050, 3.0879],\n",
      "        [3.2304, 3.2230, 3.1806, 3.3337, 3.3620],\n",
      "        [3.1003, 3.1724, 3.0051, 3.2095, 3.1367],\n",
      "        [3.1143, 3.0849, 3.1884, 3.2184, 3.1885],\n",
      "        [3.1494, 3.3646, 3.2969, 3.3383, 3.3625],\n",
      "        [3.1038, 3.0897, 3.1347, 3.1937, 3.1626],\n",
      "        [3.0939, 3.1211, 3.2144, 3.1898, 3.2731],\n",
      "        [3.0849, 3.0270, 3.1403, 3.1610, 3.1212],\n",
      "        [3.1192, 3.0562, 3.0418, 3.2540, 3.0800],\n",
      "        [3.1925, 3.3554, 3.2638, 3.3105, 3.2381],\n",
      "        [2.9922, 3.2632, 3.1181, 2.9969, 3.2377],\n",
      "        [3.0109, 3.0663, 3.0952, 3.0653, 3.0785],\n",
      "        [2.9757, 3.0267, 3.0191, 3.0690, 3.0475],\n",
      "        [3.1391, 3.2529, 3.0989, 3.1545, 3.2217],\n",
      "        [3.0817, 3.1587, 3.1322, 3.2773, 3.1329],\n",
      "        [3.0184, 3.0242, 2.9437, 3.1516, 3.0080],\n",
      "        [3.3450, 3.2091, 3.2949, 3.4697, 3.3111],\n",
      "        [3.3685, 3.3633, 3.2693, 3.5373, 3.4047],\n",
      "        [3.4176, 3.4524, 3.3456, 3.4574, 3.5194],\n",
      "        [3.0975, 3.1532, 3.1471, 3.2129, 3.1418],\n",
      "        [2.9568, 2.9241, 3.0043, 3.1221, 3.0214],\n",
      "        [2.9240, 3.0429, 2.8868, 3.0808, 2.9854],\n",
      "        [3.5584, 3.2339, 3.3615, 3.8522, 3.7522],\n",
      "        [3.0745, 3.1568, 3.0110, 3.1643, 3.1295],\n",
      "        [3.0784, 3.1419, 3.1132, 3.2278, 3.2064],\n",
      "        [3.5031, 3.5789, 3.1952, 3.3932, 3.2611],\n",
      "        [3.0766, 3.0957, 3.0665, 3.1016, 3.1448],\n",
      "        [3.2801, 3.2949, 3.3128, 3.4617, 3.2524],\n",
      "        [3.1052, 3.0159, 3.1082, 3.1022, 3.0827],\n",
      "        [3.3431, 3.3747, 3.2287, 3.3808, 3.4546],\n",
      "        [3.1505, 3.2336, 3.0449, 3.1681, 3.1978],\n",
      "        [3.1051, 3.0615, 3.1646, 3.1767, 3.1493],\n",
      "        [3.2493, 3.3403, 3.2413, 3.3582, 3.2803],\n",
      "        [3.0669, 3.2456, 3.1101, 3.1562, 3.1140],\n",
      "        [3.3390, 3.2847, 3.1635, 3.3639, 3.3853],\n",
      "        [2.9676, 3.1334, 3.1036, 3.0858, 3.0741],\n",
      "        [3.3637, 3.3810, 3.2451, 3.4085, 3.4393],\n",
      "        [3.3617, 3.3291, 3.3052, 3.4951, 3.3197],\n",
      "        [3.0183, 2.9831, 3.0350, 3.1195, 3.0401],\n",
      "        [3.2153, 3.0299, 3.2922, 3.2752, 3.2362],\n",
      "        [3.0870, 3.0884, 3.1302, 3.1916, 3.1593],\n",
      "        [3.0645, 2.9839, 3.1116, 3.1664, 3.1780],\n",
      "        [3.2940, 3.3540, 3.3245, 3.3229, 3.1692],\n",
      "        [2.9353, 3.0551, 2.9904, 3.0109, 3.0390],\n",
      "        [3.1636, 3.0614, 3.1491, 3.2170, 3.1386],\n",
      "        [2.9784, 3.0791, 2.9958, 3.0555, 3.0593],\n",
      "        [3.2130, 3.4574, 3.2818, 3.3682, 3.4731],\n",
      "        [3.3079, 3.3173, 3.3193, 3.3933, 3.2901],\n",
      "        [2.9546, 3.0709, 2.9956, 3.0347, 3.0552],\n",
      "        [3.3203, 3.4054, 3.3400, 3.4445, 3.4312],\n",
      "        [3.2012, 3.2270, 3.1408, 3.2385, 3.1966],\n",
      "        [3.2527, 3.1711, 3.1748, 3.1498, 3.0972],\n",
      "        [3.3383, 3.1695, 3.1718, 3.2780, 3.2887],\n",
      "        [3.2430, 3.3420, 3.1602, 3.4356, 3.3176],\n",
      "        [3.5801, 3.6749, 3.3875, 3.4725, 3.4149],\n",
      "        [3.1042, 3.1038, 3.1399, 3.2018, 3.1807],\n",
      "        [3.0491, 3.1825, 3.0477, 3.2494, 3.0956],\n",
      "        [3.1424, 3.1161, 3.1411, 3.2184, 3.1956],\n",
      "        [2.8240, 2.9536, 3.0067, 2.9758, 3.0322],\n",
      "        [3.0486, 3.1363, 3.0031, 3.1370, 3.1070],\n",
      "        [3.2088, 3.1296, 3.1649, 3.1512, 3.0432],\n",
      "        [3.0366, 3.1148, 2.9991, 3.1147, 3.0887]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.0007, 3.3202, 3.2028, 3.1706, 3.3304],\n",
      "        [3.1649, 3.4237, 3.1969, 3.3839, 3.3494],\n",
      "        [3.0857, 3.1507, 3.1305, 3.2795, 3.1565],\n",
      "        [2.9719, 3.1356, 3.1075, 3.0873, 3.0774],\n",
      "        [3.2751, 3.3383, 3.1562, 3.2835, 3.3399],\n",
      "        [3.1241, 3.1053, 3.1821, 3.2289, 3.1983],\n",
      "        [3.0681, 3.1340, 3.2013, 3.2579, 3.3130],\n",
      "        [3.2505, 3.2381, 3.2989, 3.2716, 3.1224],\n",
      "        [3.0088, 3.0925, 3.1469, 3.1446, 3.0520],\n",
      "        [3.1001, 3.1552, 3.0948, 3.1545, 3.1676],\n",
      "        [2.9282, 3.0449, 2.8905, 3.0823, 2.9886],\n",
      "        [3.1435, 3.3301, 3.0722, 3.2267, 3.1867],\n",
      "        [3.0103, 3.0486, 2.9758, 3.1513, 2.9819],\n",
      "        [3.3839, 3.0520, 3.2030, 3.5965, 3.5487],\n",
      "        [3.1695, 3.1903, 3.1742, 3.2225, 3.2088],\n",
      "        [3.1948, 3.1912, 3.1608, 3.3468, 3.2117],\n",
      "        [2.9400, 2.9593, 3.0254, 3.0274, 2.9709],\n",
      "        [3.1848, 3.1883, 3.1668, 3.2417, 3.2007],\n",
      "        [3.1038, 3.1076, 3.1411, 3.1997, 3.1724],\n",
      "        [3.3983, 3.2000, 3.3221, 3.4913, 3.3603],\n",
      "        [3.2962, 3.3402, 3.1669, 3.3101, 3.3733],\n",
      "        [3.0797, 3.2085, 3.1569, 3.1937, 3.1891],\n",
      "        [3.2001, 3.1230, 3.2898, 3.3398, 3.1850],\n",
      "        [3.2817, 3.5038, 3.2488, 3.4877, 3.4467],\n",
      "        [3.0565, 3.2544, 3.1456, 3.2071, 3.3206],\n",
      "        [3.0921, 3.1800, 3.0171, 3.1941, 3.1449],\n",
      "        [3.2228, 3.2136, 3.2792, 3.2634, 3.1376],\n",
      "        [3.6431, 3.7929, 3.3961, 3.5476, 3.4005],\n",
      "        [3.0973, 3.0779, 3.1243, 3.1750, 3.1556],\n",
      "        [3.1049, 3.1694, 3.0114, 3.1963, 3.1497],\n",
      "        [3.2277, 3.2397, 3.0849, 3.3197, 3.3095],\n",
      "        [3.2305, 3.1741, 3.1198, 3.3999, 3.2927],\n",
      "        [3.2587, 3.3487, 3.2010, 3.3550, 3.2980],\n",
      "        [3.1855, 3.2839, 3.1445, 3.3072, 3.2255],\n",
      "        [3.0473, 3.1304, 3.0073, 3.1264, 3.1163],\n",
      "        [3.2621, 3.3960, 3.2200, 3.3368, 3.3108],\n",
      "        [3.1075, 3.0316, 3.1199, 3.1178, 3.1009],\n",
      "        [3.2113, 3.4345, 3.3138, 3.3455, 3.3972],\n",
      "        [3.0191, 3.1381, 3.1969, 3.2015, 3.2506],\n",
      "        [3.1154, 3.0406, 3.1675, 3.2029, 3.2594],\n",
      "        [3.2274, 3.3598, 3.2811, 3.3441, 3.3994],\n",
      "        [3.0733, 3.1487, 3.0064, 3.1535, 3.1229],\n",
      "        [3.1554, 3.1704, 3.1431, 3.2338, 3.2619],\n",
      "        [3.1674, 3.2472, 3.0950, 3.2664, 3.2246],\n",
      "        [3.1301, 3.0940, 3.1783, 3.1990, 3.2101],\n",
      "        [3.1359, 3.3033, 3.1795, 3.2165, 3.0890],\n",
      "        [3.0583, 2.9887, 3.0464, 3.1433, 3.0315],\n",
      "        [3.3209, 3.4097, 3.3381, 3.4373, 3.4266],\n",
      "        [3.0695, 3.0053, 3.1229, 3.1407, 3.1027],\n",
      "        [3.0981, 3.1876, 3.1482, 3.1470, 3.0797],\n",
      "        [3.1521, 3.3443, 3.1430, 3.3739, 3.2727],\n",
      "        [3.2003, 3.3802, 3.2855, 3.3309, 3.4486],\n",
      "        [3.0936, 3.2154, 3.0578, 3.3011, 3.0986],\n",
      "        [2.9964, 3.0343, 3.0882, 3.1113, 3.0341],\n",
      "        [3.2789, 3.2884, 3.2474, 3.3440, 3.3855],\n",
      "        [3.0731, 3.1082, 2.9244, 3.2289, 3.0016],\n",
      "        [3.2774, 3.3718, 3.2906, 3.3458, 3.2763],\n",
      "        [3.0978, 3.0847, 3.0933, 3.1409, 3.1993],\n",
      "        [3.1764, 3.4373, 3.1652, 3.4136, 3.3472],\n",
      "        [3.3430, 3.3795, 3.2935, 3.3970, 3.4320],\n",
      "        [3.2255, 3.2327, 3.2081, 3.2271, 3.0321],\n",
      "        [3.1304, 3.3312, 3.1128, 3.3535, 3.2566],\n",
      "        [3.3225, 3.3092, 3.3581, 3.4953, 3.2774],\n",
      "        [3.1217, 3.0937, 3.1642, 3.1934, 3.2045]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2663, 3.3988, 3.2238, 3.3383, 3.3139],\n",
      "        [3.2395, 3.1883, 3.2216, 3.2279, 3.1103],\n",
      "        [2.9426, 2.9717, 2.9994, 3.0124, 3.0175],\n",
      "        [3.3554, 3.3062, 3.2444, 3.3595, 3.3408],\n",
      "        [3.2203, 3.1394, 3.2035, 3.2590, 3.1948],\n",
      "        [3.0140, 2.9563, 3.0285, 3.1150, 3.0223],\n",
      "        [3.0710, 3.0038, 3.0587, 3.1178, 3.2242],\n",
      "        [3.3072, 3.1346, 3.1566, 3.2432, 3.2611],\n",
      "        [3.1497, 3.0866, 3.2139, 3.2752, 3.2036],\n",
      "        [3.1122, 3.0854, 3.1391, 3.1778, 3.1633],\n",
      "        [3.1131, 3.0704, 3.1496, 3.1998, 3.2304],\n",
      "        [3.0606, 3.2571, 3.1494, 3.2085, 3.3236],\n",
      "        [3.3224, 3.1404, 3.0902, 3.2213, 3.2733],\n",
      "        [3.2043, 3.0154, 3.2751, 3.2691, 3.2313],\n",
      "        [3.4520, 3.3839, 3.2988, 3.4713, 3.4228],\n",
      "        [3.3015, 3.3691, 3.3700, 3.3156, 3.1287],\n",
      "        [3.2442, 3.1545, 3.2272, 3.3006, 3.2197],\n",
      "        [3.1089, 3.1412, 3.1063, 3.1672, 3.1682],\n",
      "        [3.0466, 3.1687, 3.0601, 3.1848, 3.0707],\n",
      "        [3.2154, 3.2747, 3.2832, 3.3031, 3.2825],\n",
      "        [3.0396, 3.0741, 3.1339, 3.1954, 3.1690],\n",
      "        [3.2898, 3.4326, 3.2540, 3.4508, 3.3895],\n",
      "        [3.0233, 3.0256, 2.9466, 3.1521, 2.9922],\n",
      "        [3.4580, 3.4782, 3.3849, 3.6513, 3.4723],\n",
      "        [3.0303, 3.1518, 3.3124, 3.1543, 3.3061],\n",
      "        [3.3457, 3.2750, 3.3004, 3.4452, 3.3362],\n",
      "        [3.1194, 3.1403, 3.2147, 3.2203, 3.2841],\n",
      "        [3.4192, 3.1666, 3.2164, 3.7004, 3.5090],\n",
      "        [3.2266, 3.1543, 3.1891, 3.1352, 3.0558],\n",
      "        [3.2321, 3.2797, 3.2940, 3.2954, 3.2789],\n",
      "        [3.3278, 3.1240, 3.1813, 3.5888, 3.4110],\n",
      "        [3.4044, 3.2675, 3.2294, 3.3559, 3.3258],\n",
      "        [2.9033, 3.0138, 2.9773, 2.9634, 2.9998],\n",
      "        [3.1412, 3.2163, 2.9963, 3.1454, 3.1685],\n",
      "        [3.1013, 3.0806, 3.1281, 3.1764, 3.1586],\n",
      "        [3.2219, 3.4627, 3.2901, 3.3713, 3.4797],\n",
      "        [3.3005, 3.3429, 3.1708, 3.3116, 3.3765],\n",
      "        [3.1477, 3.3329, 3.0760, 3.2281, 3.1897],\n",
      "        [3.2697, 3.4070, 3.3749, 3.3808, 3.2161],\n",
      "        [3.1031, 3.1047, 3.1440, 3.2022, 3.1797],\n",
      "        [3.2278, 3.2823, 3.2995, 3.2959, 3.2863],\n",
      "        [3.2726, 3.2543, 3.2431, 3.3555, 3.4109],\n",
      "        [3.2309, 3.1512, 3.1520, 3.4002, 3.2771],\n",
      "        [3.2931, 3.2535, 3.2798, 3.4266, 3.2992],\n",
      "        [2.9762, 3.0359, 3.0665, 3.0827, 3.0481],\n",
      "        [3.2366, 3.2951, 3.1786, 3.1861, 3.2354],\n",
      "        [3.2851, 3.3857, 3.1553, 3.2717, 3.3012],\n",
      "        [3.1143, 3.4049, 3.1484, 3.3866, 3.3152],\n",
      "        [3.1189, 3.0785, 3.1537, 3.1848, 3.1646],\n",
      "        [3.3263, 3.3556, 3.3627, 3.3363, 3.2173],\n",
      "        [3.1078, 3.1814, 3.1563, 3.1593, 3.0895],\n",
      "        [3.2637, 3.3138, 3.2881, 3.4514, 3.2577],\n",
      "        [3.1259, 3.4124, 3.1521, 3.3822, 3.3357],\n",
      "        [3.0517, 3.0541, 3.1157, 3.1700, 3.1557],\n",
      "        [2.8836, 3.0018, 3.0395, 3.0138, 3.0698],\n",
      "        [3.5102, 3.2112, 3.3167, 3.7791, 3.6977],\n",
      "        [3.2539, 3.3490, 3.1691, 3.4398, 3.3273],\n",
      "        [3.1334, 3.1991, 3.0163, 3.2385, 3.1630],\n",
      "        [3.0799, 3.1463, 3.0056, 3.1707, 3.1105],\n",
      "        [3.2641, 3.2576, 3.2819, 3.3671, 3.1744],\n",
      "        [3.1064, 3.0434, 3.1621, 3.0979, 3.2093],\n",
      "        [3.3277, 3.2888, 3.3227, 3.2851, 3.1278],\n",
      "        [2.9221, 3.1207, 2.9046, 3.1014, 2.9742],\n",
      "        [2.8758, 3.0018, 3.0301, 3.0106, 3.0422]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.1877, 3.1447, 3.2645, 3.2718, 3.2570],\n",
      "        [3.4573, 3.5032, 3.3963, 3.6687, 3.5152],\n",
      "        [3.0339, 3.2873, 3.2441, 3.1894, 3.3284],\n",
      "        [3.0434, 3.3430, 3.1718, 3.2284, 3.3403],\n",
      "        [3.0350, 3.1943, 3.1358, 3.0601, 3.0835],\n",
      "        [3.3379, 3.3064, 3.4290, 3.3098, 3.1947],\n",
      "        [3.0650, 3.1501, 3.1266, 3.2640, 3.1112],\n",
      "        [3.1316, 3.1944, 3.1510, 3.2111, 3.2203],\n",
      "        [3.1851, 3.4494, 3.1814, 3.4248, 3.3677],\n",
      "        [3.1407, 3.0824, 3.1716, 3.2106, 3.2381],\n",
      "        [3.0833, 3.0709, 3.0733, 3.1190, 3.1837],\n",
      "        [3.1219, 3.1810, 3.1742, 3.1926, 3.0837],\n",
      "        [3.0643, 3.1134, 2.9421, 3.2196, 3.0251],\n",
      "        [3.1850, 3.0719, 3.3842, 3.2654, 3.3010],\n",
      "        [3.1473, 3.2128, 3.0380, 3.2524, 3.1839],\n",
      "        [3.2133, 3.2366, 3.1520, 3.2436, 3.2076],\n",
      "        [3.2685, 3.3748, 3.1601, 3.2607, 3.3151],\n",
      "        [3.2679, 3.3882, 3.2975, 3.3588, 3.3015],\n",
      "        [3.0982, 3.3476, 3.2319, 3.2757, 3.3588],\n",
      "        [3.1451, 3.2210, 2.9998, 3.1474, 3.1731],\n",
      "        [3.0490, 3.3081, 3.1861, 3.2245, 3.3190],\n",
      "        [3.0344, 3.1528, 3.2072, 3.1666, 3.2371],\n",
      "        [3.1786, 3.0639, 3.1415, 3.2247, 3.1279],\n",
      "        [3.1049, 3.1125, 3.0508, 3.2205, 3.1250],\n",
      "        [2.9664, 2.9295, 3.0050, 3.1253, 3.0201],\n",
      "        [3.1537, 3.2540, 3.0898, 3.1613, 3.2223],\n",
      "        [3.4206, 3.3948, 3.2772, 3.4489, 3.5020],\n",
      "        [3.1063, 3.1057, 3.1443, 3.1996, 3.1775],\n",
      "        [3.3038, 3.3530, 3.1815, 3.3027, 3.3762],\n",
      "        [2.9456, 3.1443, 2.9118, 3.1237, 2.9830],\n",
      "        [2.9729, 3.1314, 3.1057, 3.0863, 3.0795],\n",
      "        [2.9657, 3.1547, 3.1161, 3.0873, 3.0890],\n",
      "        [3.1515, 3.2625, 3.1103, 3.1596, 3.2330],\n",
      "        [3.5105, 3.5975, 3.3237, 3.3953, 3.3520],\n",
      "        [2.9032, 3.0264, 2.9834, 2.9661, 3.0098],\n",
      "        [3.1482, 3.0669, 3.2065, 3.2502, 3.2835],\n",
      "        [3.1045, 3.2162, 3.1855, 3.1954, 3.2980],\n",
      "        [3.2325, 3.2504, 3.1112, 3.3250, 3.2934],\n",
      "        [2.9025, 3.0167, 2.9773, 2.9619, 3.0004],\n",
      "        [3.1064, 3.0785, 3.1396, 3.1905, 3.1708],\n",
      "        [3.1788, 3.0763, 3.2785, 3.3036, 3.2205],\n",
      "        [3.0082, 3.1265, 3.1469, 3.1377, 3.0977],\n",
      "        [3.1295, 3.0955, 3.1714, 3.1955, 3.2119],\n",
      "        [3.1549, 3.3016, 3.1926, 3.2307, 3.1030],\n",
      "        [3.0956, 3.1715, 3.0253, 3.1826, 3.1437],\n",
      "        [3.2521, 3.2947, 3.1449, 3.2802, 3.3726],\n",
      "        [3.0898, 3.1528, 3.3028, 3.2133, 3.3004],\n",
      "        [3.4440, 3.1622, 3.2198, 3.7376, 3.5315],\n",
      "        [3.1412, 3.4422, 3.1732, 3.4053, 3.3479],\n",
      "        [3.4615, 3.3006, 3.3739, 3.5865, 3.4309],\n",
      "        [3.4429, 3.2778, 3.3541, 3.5728, 3.4539],\n",
      "        [2.9698, 3.0871, 3.0110, 3.0477, 3.0705],\n",
      "        [2.8314, 2.9557, 3.0089, 2.9782, 3.0310],\n",
      "        [3.2336, 3.1630, 3.1833, 3.1342, 3.0678],\n",
      "        [3.1428, 3.2112, 3.1565, 3.2205, 3.2363],\n",
      "        [3.1511, 3.2848, 3.1546, 3.3519, 3.1943],\n",
      "        [3.0969, 3.0366, 3.1513, 3.1658, 3.1318],\n",
      "        [3.2416, 3.2753, 3.1360, 3.2598, 3.3767],\n",
      "        [3.0650, 3.1501, 3.1266, 3.2640, 3.1112],\n",
      "        [3.0201, 2.9893, 3.0437, 3.1185, 3.0437],\n",
      "        [3.1131, 3.0871, 3.1402, 3.1832, 3.1706],\n",
      "        [3.3900, 3.4954, 3.2848, 3.2851, 3.3482],\n",
      "        [3.2256, 3.0916, 3.3667, 3.3052, 3.3257],\n",
      "        [3.1105, 3.1011, 3.1717, 3.2044, 3.1910]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2625, 3.2977, 3.2893, 3.3644, 3.2393],\n",
      "        [3.0390, 3.1048, 3.1503, 3.1583, 3.0738],\n",
      "        [2.9070, 3.0207, 2.9804, 2.9637, 3.0044],\n",
      "        [3.0029, 3.0336, 3.0713, 3.0995, 3.0626],\n",
      "        [3.1238, 3.1262, 3.2153, 3.1421, 3.3208],\n",
      "        [3.0816, 3.0168, 3.1331, 3.1457, 3.1140],\n",
      "        [2.9641, 2.9925, 3.0506, 3.0637, 2.9933],\n",
      "        [3.0276, 2.9769, 3.0360, 3.1174, 3.0410],\n",
      "        [3.4427, 3.4794, 3.3774, 3.4806, 3.5366],\n",
      "        [2.9707, 3.0006, 3.0149, 3.0451, 3.0385],\n",
      "        [3.1548, 3.2120, 3.0309, 3.2540, 3.1735],\n",
      "        [2.9508, 2.9802, 3.0057, 3.0162, 3.0260],\n",
      "        [3.0674, 3.1518, 3.0237, 3.1289, 3.1326],\n",
      "        [3.1440, 3.3529, 3.1308, 3.3636, 3.2725],\n",
      "        [3.3226, 3.4003, 3.3665, 3.3375, 3.1525],\n",
      "        [3.1671, 3.3790, 3.3119, 3.3455, 3.3783],\n",
      "        [3.2599, 3.3556, 3.1469, 3.2749, 3.3145],\n",
      "        [3.1367, 3.1814, 3.0654, 3.2103, 3.2004],\n",
      "        [3.0316, 2.9892, 3.0437, 3.1248, 3.0484],\n",
      "        [3.1643, 3.2582, 3.0852, 3.1696, 3.2205],\n",
      "        [2.9976, 3.0553, 3.0848, 3.0950, 3.0684],\n",
      "        [3.0075, 3.0455, 3.0779, 3.1019, 3.0791],\n",
      "        [3.2574, 3.2308, 3.2403, 3.2457, 3.1058],\n",
      "        [2.8921, 3.0106, 3.0461, 3.0176, 3.0784],\n",
      "        [3.2573, 3.3350, 3.1759, 3.2791, 3.2848],\n",
      "        [3.1556, 3.2250, 3.0335, 3.2642, 3.1875],\n",
      "        [3.1951, 3.3707, 3.2991, 3.2830, 3.3325],\n",
      "        [3.1316, 3.0557, 3.1768, 3.1991, 3.2464],\n",
      "        [3.2727, 3.2837, 3.2881, 3.3629, 3.2105],\n",
      "        [3.2763, 3.3705, 3.2135, 3.3507, 3.3147],\n",
      "        [3.1149, 3.1594, 3.2166, 3.2361, 3.2622],\n",
      "        [3.0555, 3.0954, 3.1041, 3.1011, 3.1132],\n",
      "        [3.0787, 3.1305, 3.0524, 3.1071, 3.1099],\n",
      "        [3.3446, 3.3834, 3.2287, 3.3710, 3.4474],\n",
      "        [3.2592, 3.2732, 3.2780, 3.2886, 3.2903],\n",
      "        [3.1202, 3.2272, 3.2041, 3.2119, 3.1329],\n",
      "        [3.1408, 3.1036, 3.1945, 3.2041, 3.2189],\n",
      "        [3.1814, 3.1562, 3.2484, 3.2924, 3.1991],\n",
      "        [3.1804, 3.0754, 3.1636, 3.2237, 3.1535],\n",
      "        [3.1174, 3.0860, 3.1453, 3.1793, 3.1704],\n",
      "        [3.1419, 3.2083, 3.0246, 3.2575, 3.1770],\n",
      "        [3.1396, 3.0691, 3.1976, 3.2345, 3.2828],\n",
      "        [3.2703, 3.2911, 3.2660, 3.2903, 3.3732],\n",
      "        [2.9665, 3.0440, 2.9601, 3.1189, 2.9896],\n",
      "        [3.0433, 3.2946, 3.2531, 3.1956, 3.3374],\n",
      "        [3.0543, 3.1470, 3.2086, 3.2324, 3.2913],\n",
      "        [3.1689, 3.3488, 3.0902, 3.2590, 3.2077],\n",
      "        [3.6395, 3.7331, 3.4234, 3.5246, 3.4491],\n",
      "        [3.2672, 3.3278, 3.1997, 3.2810, 3.2697],\n",
      "        [3.1184, 3.1791, 3.1083, 3.1690, 3.1815],\n",
      "        [3.0508, 3.0724, 3.1095, 3.1839, 3.0714],\n",
      "        [3.2373, 3.2547, 3.1146, 3.3268, 3.2977],\n",
      "        [2.9771, 3.1205, 3.1048, 3.0904, 3.0783],\n",
      "        [3.0533, 3.3428, 3.1648, 3.2499, 3.3258],\n",
      "        [3.1518, 3.2269, 3.1660, 3.2373, 3.2495],\n",
      "        [3.0853, 3.0526, 3.1297, 3.1377, 3.1348],\n",
      "        [3.2626, 3.3582, 3.1761, 3.4438, 3.3364],\n",
      "        [3.1499, 3.2836, 3.1585, 3.2165, 3.2620],\n",
      "        [3.0650, 3.1496, 3.0171, 3.1438, 3.1217],\n",
      "        [3.2023, 3.1626, 3.2692, 3.3217, 3.2137],\n",
      "        [3.2774, 3.3505, 3.1510, 3.2811, 3.3299],\n",
      "        [3.1233, 3.3295, 3.1036, 3.3345, 3.2506],\n",
      "        [3.0696, 3.1544, 3.1299, 3.2658, 3.1154],\n",
      "        [2.9244, 3.0517, 3.0386, 3.0610, 3.0822]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.1479, 3.3259, 3.2367, 3.3077, 3.3828],\n",
      "        [3.0391, 3.0923, 3.0262, 3.1392, 3.0804],\n",
      "        [3.1639, 3.3101, 3.1993, 3.2343, 3.1113],\n",
      "        [3.3994, 3.3997, 3.2703, 3.4291, 3.4801],\n",
      "        [3.1406, 3.2053, 3.1657, 3.1915, 3.2087],\n",
      "        [3.0306, 2.9839, 3.0446, 3.1273, 3.0416],\n",
      "        [3.0691, 3.1533, 3.0201, 3.1454, 3.1254],\n",
      "        [3.0949, 3.0770, 3.1613, 3.2008, 3.2535],\n",
      "        [3.4644, 3.2476, 3.3419, 3.8246, 3.6950],\n",
      "        [3.1210, 3.1896, 3.0223, 3.2180, 3.1552],\n",
      "        [3.1357, 3.2777, 3.1399, 3.3277, 3.1862],\n",
      "        [3.1030, 3.1593, 3.0574, 3.1796, 3.1724],\n",
      "        [3.2571, 3.1677, 3.2373, 3.3061, 3.2325],\n",
      "        [2.9629, 3.0785, 3.0094, 3.0343, 3.0681],\n",
      "        [3.0218, 2.9693, 3.0329, 3.1118, 3.0353],\n",
      "        [3.1409, 3.1852, 3.0684, 3.2120, 3.2041],\n",
      "        [3.2187, 3.1463, 3.1807, 3.1460, 3.0492],\n",
      "        [3.0587, 3.0850, 3.1247, 3.1697, 3.0813],\n",
      "        [3.0321, 3.1163, 2.9928, 3.1641, 3.0987],\n",
      "        [2.9447, 3.0594, 2.9030, 3.0888, 3.0035],\n",
      "        [3.2306, 3.2497, 3.2888, 3.2468, 3.1630],\n",
      "        [3.2615, 3.2347, 3.2434, 3.2474, 3.1097],\n",
      "        [3.0199, 3.2106, 3.2982, 3.1856, 3.2405],\n",
      "        [3.0787, 3.1539, 3.0190, 3.1493, 3.1378],\n",
      "        [3.1391, 3.2283, 3.2027, 3.2175, 3.1480],\n",
      "        [3.3068, 3.3636, 3.2066, 3.4054, 3.3915],\n",
      "        [3.1270, 3.1773, 3.0607, 3.1886, 3.1914],\n",
      "        [3.1440, 3.1902, 2.9981, 3.2334, 3.0727],\n",
      "        [3.1647, 3.0824, 3.2649, 3.2961, 3.2049],\n",
      "        [3.0292, 3.0081, 3.0595, 3.1165, 3.0578],\n",
      "        [3.3095, 3.1474, 3.1702, 3.2475, 3.2675],\n",
      "        [3.2959, 3.3730, 3.2749, 3.2370, 3.3269],\n",
      "        [3.4643, 3.3792, 3.3366, 3.4886, 3.4500],\n",
      "        [3.2292, 3.4412, 3.2421, 3.3325, 3.3265],\n",
      "        [3.1240, 3.2388, 3.1975, 3.2194, 3.1591],\n",
      "        [3.1446, 3.0227, 3.1167, 3.0924, 3.0842],\n",
      "        [3.1218, 3.1077, 3.1232, 3.1631, 3.2230],\n",
      "        [3.2030, 3.2998, 3.1588, 3.3142, 3.2415],\n",
      "        [3.1097, 3.1712, 3.0146, 3.1918, 3.1351],\n",
      "        [3.0844, 3.0759, 3.1328, 3.1624, 3.1712],\n",
      "        [3.2352, 3.3768, 3.3063, 3.3467, 3.2716],\n",
      "        [3.1132, 3.2246, 3.1920, 3.1991, 3.3066],\n",
      "        [3.3110, 3.5017, 3.3183, 3.5177, 3.4841],\n",
      "        [3.1358, 3.0596, 3.1798, 3.2007, 3.2502],\n",
      "        [3.1182, 3.2561, 3.1644, 3.3569, 3.1965],\n",
      "        [3.0036, 3.0674, 3.1954, 3.1136, 3.1917],\n",
      "        [3.1098, 3.1590, 3.1110, 3.1566, 3.1586],\n",
      "        [3.2520, 3.2013, 3.2315, 3.2335, 3.1233],\n",
      "        [3.1140, 3.0936, 3.1380, 3.1819, 3.1713],\n",
      "        [3.1221, 3.0753, 3.1651, 3.1794, 3.1593],\n",
      "        [3.1278, 3.0804, 3.0716, 3.2547, 3.1016],\n",
      "        [2.9879, 3.1849, 3.1362, 3.0989, 3.1154],\n",
      "        [3.3013, 3.3532, 3.1722, 3.3056, 3.3702],\n",
      "        [3.3416, 3.3711, 3.2108, 3.3328, 3.4289],\n",
      "        [3.2495, 3.4352, 3.3494, 3.3548, 3.4049],\n",
      "        [3.2202, 3.2516, 3.2450, 3.2934, 3.3586],\n",
      "        [3.3653, 3.2196, 3.3060, 3.4776, 3.3273],\n",
      "        [3.0742, 3.1537, 3.0189, 3.1434, 3.1293],\n",
      "        [3.0537, 3.1416, 3.0168, 3.1244, 3.1187],\n",
      "        [2.9310, 2.9640, 2.9939, 2.9917, 2.9981],\n",
      "        [3.1219, 3.1057, 3.1489, 3.1928, 3.1848],\n",
      "        [3.1098, 3.0393, 3.1753, 3.0738, 3.2261],\n",
      "        [3.0735, 3.1526, 3.0222, 3.1468, 3.1359],\n",
      "        [3.1301, 3.0895, 3.1566, 3.1861, 3.1778]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2596, 3.2216, 3.2418, 3.2436, 3.1262],\n",
      "        [3.1230, 3.1742, 3.1687, 3.2237, 3.1644],\n",
      "        [3.1185, 3.3475, 3.2097, 3.2990, 3.3582],\n",
      "        [2.9999, 3.0369, 3.0745, 3.0938, 3.0624],\n",
      "        [3.2495, 3.3799, 3.2996, 3.3536, 3.4194],\n",
      "        [3.4341, 3.4065, 3.2878, 3.4548, 3.5141],\n",
      "        [3.2736, 3.1780, 3.1658, 3.4969, 3.3663],\n",
      "        [3.1659, 3.2242, 3.1774, 3.2415, 3.2631],\n",
      "        [3.1210, 3.1143, 3.1524, 3.1996, 3.1841],\n",
      "        [3.3113, 3.2207, 3.2095, 3.2101, 3.1422],\n",
      "        [3.3159, 3.1366, 3.1712, 3.6036, 3.3994],\n",
      "        [2.9847, 3.1826, 3.1369, 3.0961, 3.1137],\n",
      "        [3.1274, 3.0789, 3.1669, 3.1877, 3.1639],\n",
      "        [3.2890, 3.2033, 3.1829, 3.5078, 3.3814],\n",
      "        [3.3615, 3.2298, 3.1794, 3.3082, 3.3288],\n",
      "        [3.0572, 3.3098, 3.1992, 3.2284, 3.3101],\n",
      "        [3.1327, 3.2434, 3.1909, 3.2184, 3.1731],\n",
      "        [3.4310, 3.1817, 3.2325, 3.7152, 3.5188],\n",
      "        [3.0360, 3.1195, 2.9965, 3.1663, 3.1021],\n",
      "        [3.1239, 3.1217, 3.1588, 3.2071, 3.1902],\n",
      "        [3.2207, 3.1358, 3.2082, 3.1682, 3.1627],\n",
      "        [3.1094, 3.0479, 3.1613, 3.1714, 3.1429],\n",
      "        [3.0550, 3.1661, 3.1226, 3.2780, 3.1125],\n",
      "        [3.1924, 3.0868, 3.1779, 3.2266, 3.1877],\n",
      "        [3.1708, 3.1289, 3.2333, 3.2417, 3.2405],\n",
      "        [3.6566, 3.8179, 3.3475, 3.4943, 3.4340],\n",
      "        [3.4968, 3.5015, 3.3723, 3.7206, 3.5488],\n",
      "        [3.0392, 3.0799, 3.0023, 3.1757, 3.0874],\n",
      "        [3.2828, 3.2194, 3.3313, 3.2769, 3.0811],\n",
      "        [3.2157, 3.1836, 3.1627, 3.3390, 3.2454],\n",
      "        [3.4126, 3.3513, 3.3654, 3.5286, 3.4226],\n",
      "        [3.0888, 3.0049, 3.1326, 3.1769, 3.1998],\n",
      "        [3.1384, 3.1997, 3.0294, 3.2301, 3.1693],\n",
      "        [3.3003, 3.3593, 3.1994, 3.3976, 3.4035],\n",
      "        [2.9892, 3.0877, 3.0203, 3.0512, 3.0738],\n",
      "        [2.9631, 3.1824, 3.2471, 3.0769, 3.2095],\n",
      "        [3.1212, 3.2420, 3.1174, 3.2238, 3.2538],\n",
      "        [3.0840, 3.1527, 3.0194, 3.1555, 3.1225],\n",
      "        [3.3299, 3.2932, 3.2967, 3.4109, 3.2536],\n",
      "        [3.0689, 2.9850, 3.1609, 2.9872, 3.2165],\n",
      "        [3.1476, 3.2737, 3.1346, 3.1602, 3.2502],\n",
      "        [3.1795, 3.1372, 3.2463, 3.2529, 3.2492],\n",
      "        [3.2827, 3.4037, 3.3054, 3.3631, 3.3114],\n",
      "        [3.2261, 3.2258, 3.1827, 3.3846, 3.2326],\n",
      "        [3.3174, 3.3649, 3.1922, 3.3086, 3.3882],\n",
      "        [3.1389, 3.0681, 3.1931, 3.2261, 3.2820],\n",
      "        [3.1275, 3.0941, 3.1559, 3.1892, 3.1794],\n",
      "        [3.3573, 3.4368, 3.4177, 3.4031, 3.2244],\n",
      "        [2.9881, 3.0111, 3.0618, 3.0745, 3.0278],\n",
      "        [3.1221, 3.0542, 3.1440, 3.1919, 3.2768],\n",
      "        [3.0807, 3.1522, 3.0147, 3.1521, 3.1199],\n",
      "        [3.0587, 3.0792, 3.1420, 3.2021, 3.1910],\n",
      "        [3.1892, 3.2444, 3.2343, 3.3172, 3.3029],\n",
      "        [3.2671, 3.3083, 3.1812, 3.3526, 3.2975],\n",
      "        [3.3465, 3.4432, 3.3974, 3.3798, 3.2096],\n",
      "        [3.1476, 3.2167, 3.0345, 3.2460, 3.1805],\n",
      "        [3.0675, 3.1485, 3.0242, 3.1355, 3.1350],\n",
      "        [3.2059, 3.2989, 3.1623, 3.3087, 3.2526],\n",
      "        [3.0577, 3.3349, 3.2321, 3.2371, 3.3448],\n",
      "        [3.2009, 3.3663, 3.1962, 3.3994, 3.3003],\n",
      "        [3.1141, 3.2043, 3.3033, 3.1627, 3.2126],\n",
      "        [3.0239, 3.2140, 3.3021, 3.1878, 3.2440],\n",
      "        [3.4126, 3.3513, 3.3654, 3.5286, 3.4226],\n",
      "        [3.1987, 3.4615, 3.1921, 3.4305, 3.3795]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.1217, 3.1203, 3.2460, 3.1131, 3.3399],\n",
      "        [3.0936, 3.2529, 3.2210, 3.2040, 3.2146],\n",
      "        [2.9637, 3.0788, 3.0142, 3.0263, 3.0642],\n",
      "        [3.0338, 3.1732, 3.0729, 3.1359, 3.1715],\n",
      "        [3.2319, 3.1594, 3.2250, 3.1789, 3.1558],\n",
      "        [3.1281, 3.2491, 3.2147, 3.2104, 3.3407],\n",
      "        [3.4408, 3.4780, 3.3590, 3.6249, 3.4631],\n",
      "        [3.3347, 3.4111, 3.3787, 3.3435, 3.1632],\n",
      "        [3.1343, 3.0958, 3.0924, 3.2467, 3.1193],\n",
      "        [3.2722, 3.3223, 3.2986, 3.3633, 3.2793],\n",
      "        [2.9140, 3.0361, 3.0481, 3.0405, 3.0694],\n",
      "        [3.1497, 3.2822, 3.1499, 3.2084, 3.2737],\n",
      "        [3.2435, 3.1488, 3.2282, 3.1639, 3.2209],\n",
      "        [3.0165, 3.0955, 3.1059, 3.1045, 3.1059],\n",
      "        [3.1242, 3.1039, 3.1597, 3.2049, 3.1934],\n",
      "        [3.2256, 3.1361, 3.2132, 3.1655, 3.1798],\n",
      "        [3.1323, 3.1950, 3.0312, 3.2267, 3.1711],\n",
      "        [3.2684, 3.3840, 3.1845, 3.2870, 3.3308],\n",
      "        [3.3476, 3.4294, 3.3640, 3.4513, 3.4553],\n",
      "        [3.3213, 3.3681, 3.1971, 3.3107, 3.3916],\n",
      "        [3.2406, 3.1689, 3.2066, 3.1253, 3.0731],\n",
      "        [3.1616, 3.0449, 3.1430, 3.1071, 3.1085],\n",
      "        [3.1411, 3.0628, 3.0571, 3.2687, 3.0857],\n",
      "        [3.3034, 3.3116, 3.2703, 3.3563, 3.4100],\n",
      "        [3.4217, 3.2297, 3.3378, 3.4700, 3.3825],\n",
      "        [3.2639, 3.0920, 3.0809, 3.1579, 3.2523],\n",
      "        [3.3246, 3.4078, 3.3829, 3.3414, 3.1658],\n",
      "        [3.3594, 3.3032, 3.3260, 3.4482, 3.3611],\n",
      "        [3.2580, 3.1662, 3.2452, 3.3073, 3.2331],\n",
      "        [3.1270, 3.2531, 3.1327, 3.2189, 3.2554],\n",
      "        [3.0748, 3.0645, 3.1520, 3.1835, 3.2430],\n",
      "        [3.1391, 3.0627, 3.1896, 3.2142, 3.2819],\n",
      "        [3.2854, 3.2544, 3.3197, 3.2923, 3.1907],\n",
      "        [3.0814, 3.2765, 3.1682, 3.2186, 3.3434],\n",
      "        [3.0935, 3.0082, 3.1335, 3.1727, 3.1910],\n",
      "        [3.1473, 3.4328, 3.1712, 3.3920, 3.3554],\n",
      "        [3.1516, 3.1035, 3.1795, 3.1739, 3.2278],\n",
      "        [3.2235, 3.0035, 3.3038, 3.2658, 3.2226],\n",
      "        [3.1041, 3.2307, 3.1793, 3.2052, 3.2121],\n",
      "        [3.0008, 3.1986, 3.1536, 3.1085, 3.1269],\n",
      "        [3.0452, 3.0856, 3.1350, 3.1642, 3.0693],\n",
      "        [3.1115, 3.2305, 3.1734, 3.2069, 3.2096],\n",
      "        [3.1348, 3.2709, 3.1660, 3.1614, 3.2601],\n",
      "        [3.0192, 3.1775, 3.2334, 3.1327, 3.2130],\n",
      "        [3.5049, 3.2089, 3.3092, 3.7866, 3.6965],\n",
      "        [3.2951, 3.2110, 3.2078, 3.1987, 3.1431],\n",
      "        [3.1498, 3.1190, 3.2073, 3.2337, 3.2123],\n",
      "        [3.0861, 3.0060, 3.0719, 3.1566, 3.0644],\n",
      "        [3.2735, 3.1979, 3.1587, 3.4644, 3.3528],\n",
      "        [3.4035, 3.2941, 3.2623, 3.3655, 3.3878],\n",
      "        [3.4808, 3.3159, 3.3892, 3.5947, 3.4470],\n",
      "        [3.0941, 3.1515, 3.1299, 3.2352, 3.2183],\n",
      "        [3.0474, 3.1446, 3.0342, 3.1191, 3.1260],\n",
      "        [3.1775, 3.2574, 3.0760, 3.1723, 3.2199],\n",
      "        [3.1512, 3.0795, 3.2092, 3.2405, 3.2933],\n",
      "        [3.1698, 3.1062, 3.2323, 3.2850, 3.2229],\n",
      "        [3.0919, 3.1457, 3.2630, 3.2077, 3.2721],\n",
      "        [3.0234, 3.2903, 3.1455, 3.0149, 3.2692],\n",
      "        [3.2391, 3.1653, 3.2123, 3.2697, 3.2015],\n",
      "        [3.1205, 3.0985, 3.1583, 3.1963, 3.1837],\n",
      "        [3.1222, 3.1056, 3.1497, 3.1901, 3.1809],\n",
      "        [3.7600, 3.8643, 3.4753, 3.5939, 3.4748],\n",
      "        [3.4085, 3.0744, 3.2253, 3.6074, 3.5706],\n",
      "        [3.1623, 3.1280, 3.2444, 3.2613, 3.2510]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.1262, 3.0969, 3.1590, 3.2003, 3.1895],\n",
      "        [3.0245, 3.2913, 3.1488, 3.0116, 3.2672],\n",
      "        [3.2026, 3.1891, 3.1564, 3.2957, 3.3352],\n",
      "        [3.2511, 3.1695, 3.2339, 3.2878, 3.2216],\n",
      "        [3.1552, 3.3552, 3.2456, 3.3286, 3.3955],\n",
      "        [3.0814, 3.0213, 3.0838, 3.1478, 3.0688],\n",
      "        [3.2761, 3.3703, 3.1919, 3.4510, 3.3480],\n",
      "        [3.0892, 3.1668, 3.0276, 3.1695, 3.1344],\n",
      "        [3.1452, 3.2062, 3.0384, 3.2339, 3.1762],\n",
      "        [3.1462, 3.3300, 3.1951, 3.2120, 3.1080],\n",
      "        [3.2413, 3.2600, 3.3020, 3.2530, 3.1736],\n",
      "        [3.1344, 3.3406, 3.1152, 3.3417, 3.2655],\n",
      "        [3.2782, 3.3724, 3.1929, 3.4520, 3.3512],\n",
      "        [3.1637, 3.2295, 3.0548, 3.2631, 3.1975],\n",
      "        [3.1697, 3.2255, 3.0469, 3.2618, 3.1877],\n",
      "        [3.7544, 3.8620, 3.4755, 3.5839, 3.4800],\n",
      "        [3.2722, 3.3136, 3.1832, 3.3566, 3.2964],\n",
      "        [3.3108, 3.2649, 3.4365, 3.2495, 3.2041],\n",
      "        [3.0198, 3.0990, 3.1101, 3.1064, 3.1097],\n",
      "        [3.0730, 3.2607, 3.0636, 2.9713, 3.1680],\n",
      "        [3.7323, 3.8384, 3.4484, 3.5723, 3.4539],\n",
      "        [3.1229, 3.3971, 3.1918, 3.3237, 3.3394],\n",
      "        [3.1369, 3.1170, 3.1522, 3.1801, 3.2386],\n",
      "        [3.2216, 3.3798, 3.2942, 3.3234, 3.2593],\n",
      "        [3.3815, 3.3144, 3.3262, 3.4859, 3.3757],\n",
      "        [2.9797, 3.0503, 2.9570, 3.1142, 3.0097],\n",
      "        [3.2391, 3.4404, 3.2485, 3.3489, 3.3371],\n",
      "        [3.1108, 3.1134, 3.2933, 3.0569, 3.3491],\n",
      "        [3.2107, 3.2179, 3.1983, 3.2826, 3.3123],\n",
      "        [2.8561, 2.9806, 3.0360, 2.9901, 3.0610],\n",
      "        [3.0543, 3.1184, 3.1660, 3.1662, 3.0882],\n",
      "        [3.2573, 3.2965, 3.1542, 3.2649, 3.4010],\n",
      "        [3.2872, 3.3339, 3.1996, 3.3610, 3.3090],\n",
      "        [3.2627, 3.2114, 3.2444, 3.2398, 3.1342],\n",
      "        [3.3130, 3.3238, 3.3446, 3.4772, 3.2840],\n",
      "        [3.4335, 3.3253, 3.2955, 3.5451, 3.4111],\n",
      "        [2.9917, 3.1891, 3.1456, 3.1000, 3.1207],\n",
      "        [3.0342, 3.1243, 3.0306, 3.0987, 3.1053],\n",
      "        [3.1724, 3.1559, 3.1921, 3.1255, 3.0469],\n",
      "        [3.1233, 3.2409, 3.1843, 3.2120, 3.2085],\n",
      "        [3.4760, 3.2583, 3.3554, 3.8307, 3.7057],\n",
      "        [3.0948, 3.1564, 3.1308, 3.2472, 3.1971],\n",
      "        [3.3019, 3.2572, 3.2986, 3.3864, 3.1553],\n",
      "        [3.2400, 3.1547, 3.3259, 3.3483, 3.2572],\n",
      "        [2.9928, 3.1642, 3.1321, 3.0972, 3.1055],\n",
      "        [3.0067, 3.0434, 3.0832, 3.0977, 3.0694],\n",
      "        [3.2603, 3.3302, 3.2791, 3.4321, 3.2803],\n",
      "        [3.2307, 3.2618, 3.2580, 3.3002, 3.3700],\n",
      "        [3.1042, 3.1725, 3.0321, 3.1718, 3.1563],\n",
      "        [3.3216, 3.1613, 3.1953, 3.5184, 3.3821],\n",
      "        [3.0875, 3.1585, 3.0235, 3.1559, 3.1267],\n",
      "        [3.1131, 3.1842, 3.0393, 3.1702, 3.1620],\n",
      "        [2.9222, 3.0433, 3.0014, 2.9755, 3.0276],\n",
      "        [3.2050, 3.2599, 3.1606, 3.2960, 3.3002],\n",
      "        [3.2534, 3.2911, 3.3587, 3.3611, 3.3680],\n",
      "        [3.2383, 3.1419, 3.2194, 3.1734, 3.2015],\n",
      "        [3.2403, 3.1675, 3.2272, 3.1824, 3.1723],\n",
      "        [3.2619, 3.2517, 3.2115, 3.3497, 3.3937],\n",
      "        [3.0053, 3.0752, 3.0994, 3.0989, 3.0805],\n",
      "        [3.1148, 3.2226, 3.1099, 3.2266, 3.2511],\n",
      "        [3.0641, 3.0974, 3.1570, 3.2073, 3.1924],\n",
      "        [3.1556, 3.1176, 3.2104, 3.2120, 3.2334],\n",
      "        [3.1916, 3.4539, 3.2082, 3.4270, 3.3874],\n",
      "        [3.1546, 3.3495, 3.1319, 3.0597, 3.2395]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2644, 3.1747, 3.2537, 3.3124, 3.2406],\n",
      "        [2.9699, 2.9881, 3.0544, 3.0434, 2.9998],\n",
      "        [3.2458, 3.0569, 3.3271, 3.2911, 3.2667],\n",
      "        [3.1047, 3.0936, 3.0961, 3.1324, 3.2068],\n",
      "        [2.9920, 3.1086, 3.0332, 3.0603, 3.0919],\n",
      "        [3.0441, 3.0289, 3.0751, 3.1279, 3.0748],\n",
      "        [3.2060, 3.1605, 3.2729, 3.2820, 3.2720],\n",
      "        [2.9955, 3.1534, 3.1283, 3.0991, 3.1013],\n",
      "        [3.1326, 3.1954, 3.0449, 3.1974, 3.1818],\n",
      "        [3.1825, 3.1952, 3.1695, 3.2513, 3.2882],\n",
      "        [3.2930, 3.3747, 3.1835, 3.2949, 3.3560],\n",
      "        [3.2021, 3.3263, 3.2286, 3.2637, 3.1434],\n",
      "        [3.3140, 3.0785, 3.0747, 3.1619, 3.2728],\n",
      "        [3.1333, 3.2615, 3.1412, 3.2241, 3.2630],\n",
      "        [3.1375, 3.1055, 3.1688, 3.1963, 3.1900],\n",
      "        [3.1438, 3.1477, 3.2685, 3.3380, 3.3981],\n",
      "        [3.3635, 3.2000, 3.2043, 3.2943, 3.3309],\n",
      "        [3.0402, 3.0155, 3.0720, 3.1253, 3.0690],\n",
      "        [3.4213, 3.2079, 3.2363, 3.6810, 3.5051],\n",
      "        [3.1539, 3.2201, 3.1826, 3.2013, 3.2233],\n",
      "        [3.1378, 3.0602, 3.1811, 3.2087, 3.2781],\n",
      "        [3.5596, 3.6508, 3.3643, 3.4412, 3.3916],\n",
      "        [3.3703, 3.5095, 3.3061, 3.4865, 3.5104],\n",
      "        [3.0022, 3.0829, 3.1001, 3.0961, 3.0826],\n",
      "        [3.1929, 3.3266, 3.2064, 3.2311, 3.2937],\n",
      "        [3.2336, 3.1566, 3.2250, 3.1842, 3.1682],\n",
      "        [2.9937, 3.1333, 3.1238, 3.0995, 3.0937],\n",
      "        [3.2913, 3.2859, 3.3092, 3.3827, 3.2027],\n",
      "        [2.9827, 3.0546, 2.9608, 3.1172, 3.0131],\n",
      "        [3.1396, 3.0941, 3.1986, 3.1942, 3.1817],\n",
      "        [3.3509, 3.4358, 3.4189, 3.4137, 3.2665],\n",
      "        [3.1577, 3.2192, 3.0381, 3.2456, 3.1787],\n",
      "        [3.0295, 3.0885, 3.1087, 3.1126, 3.1113],\n",
      "        [3.4302, 3.3690, 3.3772, 3.5231, 3.4426],\n",
      "        [3.3216, 3.3784, 3.2245, 3.4151, 3.4064],\n",
      "        [3.5472, 3.6170, 3.2177, 3.4095, 3.2881],\n",
      "        [3.1195, 3.1961, 3.0406, 3.1903, 3.1683],\n",
      "        [3.1133, 3.1761, 3.3266, 3.2263, 3.3227],\n",
      "        [3.1358, 3.0923, 3.1729, 3.1980, 3.1771],\n",
      "        [3.0362, 3.1340, 3.0379, 3.0964, 3.1135],\n",
      "        [3.2775, 3.2620, 3.2574, 3.2674, 3.1113],\n",
      "        [3.1067, 3.2397, 3.0891, 3.2899, 3.1327],\n",
      "        [3.1621, 3.1484, 3.1903, 3.1148, 3.0380],\n",
      "        [3.4676, 3.2423, 3.3582, 3.8273, 3.7114],\n",
      "        [3.3071, 3.3731, 3.3362, 3.3213, 3.1885],\n",
      "        [3.1060, 3.0418, 3.1005, 3.1516, 3.2592],\n",
      "        [3.0850, 3.1693, 3.0346, 3.1601, 3.1417],\n",
      "        [3.1088, 3.0436, 3.1584, 3.1647, 3.1447],\n",
      "        [3.0263, 3.0440, 3.0859, 3.1092, 3.0794],\n",
      "        [3.0026, 3.0312, 3.0411, 3.0722, 3.0690],\n",
      "        [3.2541, 3.1744, 3.2380, 3.2910, 3.2252],\n",
      "        [3.2161, 3.2847, 3.1296, 3.2871, 3.2823],\n",
      "        [2.9584, 3.0731, 2.9186, 3.0977, 3.0169],\n",
      "        [3.0392, 3.1400, 3.0394, 3.1026, 3.1225],\n",
      "        [3.1289, 3.3594, 3.2239, 3.3065, 3.3692],\n",
      "        [3.2321, 3.5043, 3.2661, 3.4560, 3.4252],\n",
      "        [3.0692, 3.0908, 3.1554, 3.2094, 3.2018],\n",
      "        [3.0207, 3.0517, 3.0907, 3.1104, 3.0803],\n",
      "        [3.2708, 3.1882, 3.2488, 3.3151, 3.2369],\n",
      "        [3.0319, 3.1328, 3.0341, 3.0959, 3.1073],\n",
      "        [3.1459, 3.2071, 3.0485, 3.2162, 3.1925],\n",
      "        [3.5195, 3.5954, 3.2296, 3.4038, 3.3032],\n",
      "        [3.1225, 3.4332, 3.3105, 3.2513, 3.2241],\n",
      "        [3.2924, 3.3982, 3.1842, 3.2736, 3.3375]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.1039, 3.2718, 3.2458, 3.2148, 3.2403],\n",
      "        [3.3322, 3.2894, 3.3036, 3.4575, 3.3257],\n",
      "        [3.6642, 3.7923, 3.4187, 3.5377, 3.4110],\n",
      "        [3.4134, 3.3998, 3.2931, 3.4588, 3.4991],\n",
      "        [3.2790, 3.2741, 3.2612, 3.2722, 3.1018],\n",
      "        [3.5412, 3.6154, 3.2346, 3.4155, 3.2992],\n",
      "        [3.0049, 3.0869, 3.1047, 3.0997, 3.0858],\n",
      "        [3.1501, 3.0749, 3.0699, 3.2774, 3.0963],\n",
      "        [3.1708, 3.0571, 3.1559, 3.1158, 3.1191],\n",
      "        [3.2469, 3.2285, 3.3183, 3.3360, 3.2592],\n",
      "        [3.1339, 3.1300, 3.1705, 3.2106, 3.1982],\n",
      "        [3.3928, 3.2826, 3.2410, 3.3466, 3.3921],\n",
      "        [3.1362, 3.0753, 3.1976, 3.1208, 3.2382],\n",
      "        [3.1375, 3.1428, 3.1770, 3.2202, 3.2061],\n",
      "        [3.3106, 3.2746, 3.3434, 3.3133, 3.2028],\n",
      "        [3.0663, 3.1311, 3.0417, 3.1730, 3.1070],\n",
      "        [3.1250, 3.2132, 3.0519, 3.2139, 3.1773],\n",
      "        [3.1130, 3.2024, 3.0548, 3.1975, 3.1650],\n",
      "        [3.2797, 3.3694, 3.1665, 3.2838, 3.3351],\n",
      "        [3.1952, 3.4813, 3.2096, 3.4320, 3.3932],\n",
      "        [3.1220, 3.3249, 3.2496, 3.1417, 3.2964],\n",
      "        [3.1809, 3.3294, 3.2217, 3.2477, 3.1295],\n",
      "        [2.9599, 3.0811, 3.0230, 3.0152, 3.0635],\n",
      "        [3.0056, 3.1909, 3.1491, 3.1134, 3.1290],\n",
      "        [3.1497, 3.1232, 3.1876, 3.2062, 3.2402],\n",
      "        [3.2927, 3.2860, 3.2646, 3.3085, 3.4084],\n",
      "        [3.3699, 3.3023, 3.3703, 3.4272, 3.2403],\n",
      "        [2.9233, 3.0482, 3.0610, 3.0492, 3.0800],\n",
      "        [3.1725, 3.2391, 3.0663, 3.2689, 3.2089],\n",
      "        [3.0800, 3.1632, 3.0417, 3.1461, 3.1485],\n",
      "        [3.2087, 3.1647, 3.2776, 3.2857, 3.2752],\n",
      "        [3.2808, 3.3436, 3.3305, 3.3549, 3.3622],\n",
      "        [3.1198, 3.4016, 3.2231, 3.3122, 3.3831],\n",
      "        [3.0933, 3.1378, 3.0691, 3.2211, 3.1604],\n",
      "        [3.1302, 3.2219, 3.1830, 3.1677, 3.1137],\n",
      "        [3.2880, 3.3780, 3.2819, 3.3805, 3.3180],\n",
      "        [3.3067, 3.0918, 3.0942, 3.1682, 3.2694],\n",
      "        [3.2012, 3.1634, 3.2694, 3.2778, 3.2805],\n",
      "        [3.0389, 3.1379, 3.0425, 3.1000, 3.1166],\n",
      "        [3.0755, 3.1615, 3.0489, 3.1332, 3.1547],\n",
      "        [3.0011, 3.1820, 3.1484, 3.1088, 3.1197],\n",
      "        [3.2446, 3.3710, 3.2572, 3.4296, 3.3163],\n",
      "        [3.3294, 3.2737, 3.3806, 3.3411, 3.1470],\n",
      "        [3.4497, 3.1995, 3.2491, 3.7187, 3.5389],\n",
      "        [3.3629, 3.3991, 3.2482, 3.3796, 3.4636],\n",
      "        [3.0986, 3.0352, 3.0897, 3.1369, 3.2552],\n",
      "        [3.1796, 3.1454, 3.2594, 3.2738, 3.2676],\n",
      "        [3.2044, 3.3599, 3.2211, 3.3139, 3.3975],\n",
      "        [3.0800, 3.1632, 3.0417, 3.1461, 3.1485],\n",
      "        [3.2836, 3.3836, 3.3449, 3.3190, 3.2150],\n",
      "        [3.4735, 3.3580, 3.4273, 3.6051, 3.4611],\n",
      "        [3.0931, 3.1669, 3.0322, 3.1626, 3.1333],\n",
      "        [3.2335, 3.0469, 3.3066, 3.2879, 3.2613],\n",
      "        [3.1556, 3.2732, 3.1029, 3.3543, 3.1497],\n",
      "        [3.3923, 3.2581, 3.3518, 3.5117, 3.3685],\n",
      "        [3.1403, 3.2074, 3.0493, 3.2221, 3.1824],\n",
      "        [3.1653, 3.3456, 3.2605, 3.3215, 3.4009],\n",
      "        [3.1783, 3.1518, 3.2510, 3.2749, 3.2628],\n",
      "        [3.4269, 3.2921, 3.3652, 3.5430, 3.3970],\n",
      "        [3.0809, 3.1476, 3.2193, 3.1735, 3.2203],\n",
      "        [3.1084, 3.3114, 3.2729, 3.1716, 3.4310],\n",
      "        [3.3154, 3.4138, 3.1860, 3.2896, 3.3300],\n",
      "        [3.2749, 3.0671, 3.0970, 3.1842, 3.2248],\n",
      "        [3.1433, 3.0523, 3.1470, 3.1236, 3.1186]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4068, 3.0919, 3.2408, 3.6077, 3.5666],\n",
      "        [3.2184, 3.3514, 3.2293, 3.2255, 3.3294],\n",
      "        [3.1431, 3.0737, 3.0680, 3.2779, 3.0952],\n",
      "        [3.3339, 3.3967, 3.3697, 3.3494, 3.2122],\n",
      "        [3.2237, 3.2203, 3.2055, 3.2684, 3.2293],\n",
      "        [3.4814, 3.4217, 3.3357, 3.4957, 3.4612],\n",
      "        [3.1277, 3.1648, 3.1655, 3.2081, 3.3289],\n",
      "        [3.2441, 3.5397, 3.2894, 3.4750, 3.4524],\n",
      "        [3.1535, 3.1262, 3.2317, 3.2435, 3.2291],\n",
      "        [3.4140, 3.3113, 3.2801, 3.3784, 3.4036],\n",
      "        [3.0680, 3.3276, 3.1907, 3.0498, 3.3020],\n",
      "        [3.1420, 3.2603, 3.1453, 3.2458, 3.2790],\n",
      "        [3.2248, 3.2415, 3.1461, 3.3187, 3.2727],\n",
      "        [3.0925, 3.2230, 3.0914, 3.2714, 3.1324],\n",
      "        [3.0679, 3.3162, 3.1797, 3.0310, 3.2699],\n",
      "        [2.9732, 3.1737, 2.9416, 3.1423, 3.0106],\n",
      "        [3.1406, 3.0647, 3.1749, 3.2164, 3.2843],\n",
      "        [2.9455, 3.1035, 3.2349, 3.0563, 3.2023],\n",
      "        [3.1565, 3.1271, 3.2037, 3.2157, 3.2418],\n",
      "        [3.0542, 3.0988, 3.0237, 3.1894, 3.1046],\n",
      "        [3.0890, 3.0118, 3.0622, 3.1426, 3.0651],\n",
      "        [3.1161, 3.3416, 3.2677, 3.1584, 3.2845],\n",
      "        [3.6015, 3.2779, 3.4080, 3.8774, 3.7933],\n",
      "        [3.3114, 3.1574, 3.2031, 3.2561, 3.2605],\n",
      "        [2.9337, 3.0474, 3.0107, 2.9844, 3.0321],\n",
      "        [3.2348, 3.0203, 3.3213, 3.2780, 3.2370],\n",
      "        [3.2866, 3.3860, 3.2068, 3.4627, 3.3622],\n",
      "        [3.2744, 3.2198, 3.2583, 3.2357, 3.1705],\n",
      "        [3.3214, 3.2810, 3.4595, 3.2631, 3.2244],\n",
      "        [3.2941, 3.2449, 3.2959, 3.4156, 3.2219],\n",
      "        [3.1750, 3.2248, 3.1992, 3.2077, 3.2421],\n",
      "        [3.0225, 3.0904, 3.2212, 3.1297, 3.2124],\n",
      "        [3.1819, 3.2859, 3.1232, 3.1817, 3.2526],\n",
      "        [3.1138, 3.1005, 3.1875, 3.2173, 3.2749],\n",
      "        [3.1449, 3.1014, 3.1944, 3.2000, 3.1866],\n",
      "        [3.4449, 3.4258, 3.3367, 3.5843, 3.4783],\n",
      "        [3.1337, 3.1226, 3.1673, 3.2024, 3.1955],\n",
      "        [3.1138, 3.0327, 3.1634, 3.1912, 3.2161],\n",
      "        [3.1114, 3.1224, 3.2947, 3.0623, 3.3542],\n",
      "        [3.2888, 3.1982, 3.1883, 3.5111, 3.3840],\n",
      "        [3.2990, 3.2397, 3.3502, 3.2878, 3.1173],\n",
      "        [3.1331, 3.1376, 3.2634, 3.1256, 3.3547],\n",
      "        [3.2656, 3.4009, 3.3227, 3.3685, 3.4381],\n",
      "        [3.0519, 3.1277, 3.0172, 3.1837, 3.1179],\n",
      "        [3.5574, 3.6365, 3.2340, 3.4337, 3.2908],\n",
      "        [3.2488, 3.4753, 3.3556, 3.3699, 3.4354],\n",
      "        [3.0375, 2.9939, 3.0574, 3.1300, 3.0567],\n",
      "        [3.2866, 3.3860, 3.2068, 3.4627, 3.3622],\n",
      "        [3.0285, 3.0755, 3.1276, 3.1316, 3.0722],\n",
      "        [3.2854, 3.0767, 3.1053, 3.1849, 3.2513],\n",
      "        [3.2759, 3.0702, 3.0985, 3.1997, 3.2127],\n",
      "        [3.3121, 3.3820, 3.3456, 3.3288, 3.1961],\n",
      "        [3.1378, 3.1401, 3.1792, 3.2283, 3.2096],\n",
      "        [3.2634, 3.3605, 3.1805, 3.4269, 3.3192],\n",
      "        [3.2146, 3.4828, 3.2157, 3.4453, 3.3979],\n",
      "        [3.0934, 3.0266, 3.0849, 3.1665, 3.0681],\n",
      "        [3.0625, 3.1314, 3.1790, 3.1764, 3.0988],\n",
      "        [3.5148, 3.5228, 3.3958, 3.7361, 3.5693],\n",
      "        [3.0843, 3.3834, 3.2047, 3.2729, 3.3570],\n",
      "        [3.5382, 3.6203, 3.3484, 3.4185, 3.3562],\n",
      "        [3.1928, 3.3769, 3.1202, 3.2773, 3.2328],\n",
      "        [3.1623, 3.2361, 3.0567, 3.2599, 3.1979],\n",
      "        [3.1609, 3.1360, 3.2247, 3.2460, 3.2271],\n",
      "        [3.2866, 3.3860, 3.2068, 3.4627, 3.3622]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3930, 3.3324, 3.3438, 3.5002, 3.3926],\n",
      "        [2.9740, 3.2091, 3.2742, 3.0987, 3.2266],\n",
      "        [3.0920, 3.1880, 3.1560, 3.2888, 3.1348],\n",
      "        [2.9181, 3.0413, 3.0785, 3.0384, 3.1074],\n",
      "        [3.0647, 3.2570, 3.1717, 3.2057, 3.3433],\n",
      "        [3.3481, 3.3507, 3.3893, 3.5072, 3.3125],\n",
      "        [3.2985, 3.3556, 3.3297, 3.4775, 3.2985],\n",
      "        [3.2880, 3.2941, 3.1272, 3.3802, 3.3779],\n",
      "        [3.0861, 3.0089, 3.1860, 3.0043, 3.2384],\n",
      "        [3.1370, 3.1474, 3.2574, 3.1434, 3.3443],\n",
      "        [2.8503, 2.9928, 3.0504, 2.9861, 3.0484],\n",
      "        [3.1562, 3.1516, 3.2167, 3.2506, 3.2383],\n",
      "        [3.1181, 3.0909, 3.1689, 3.1625, 3.1710],\n",
      "        [3.1489, 3.1120, 3.1818, 3.2061, 3.2021],\n",
      "        [3.1414, 3.1462, 3.1854, 3.2247, 3.2130],\n",
      "        [2.9756, 3.0951, 3.0362, 3.0334, 3.0897],\n",
      "        [3.2328, 3.2080, 3.1895, 3.3564, 3.2678],\n",
      "        [3.1237, 3.1359, 3.2763, 3.1111, 3.3432],\n",
      "        [3.0397, 2.9979, 3.0613, 3.1330, 3.0612],\n",
      "        [3.1368, 3.3423, 3.2046, 3.2132, 3.1176],\n",
      "        [3.0144, 3.0785, 3.1107, 3.1113, 3.0903],\n",
      "        [3.0053, 3.1594, 3.1421, 3.1214, 3.1227],\n",
      "        [3.2624, 3.3237, 3.3405, 3.3214, 3.3251],\n",
      "        [3.1386, 3.2665, 3.1443, 3.2415, 3.2767],\n",
      "        [3.1658, 3.0498, 3.1460, 3.1114, 3.1095],\n",
      "        [3.1691, 3.4425, 3.2245, 3.3722, 3.3729],\n",
      "        [3.1756, 3.1860, 3.2123, 3.1490, 3.0564],\n",
      "        [3.0112, 3.1080, 3.1228, 3.1104, 3.0979],\n",
      "        [3.3711, 3.5132, 3.3050, 3.4891, 3.5036],\n",
      "        [3.0136, 3.1815, 3.1535, 3.1281, 3.1337],\n",
      "        [3.1422, 3.1804, 3.1456, 3.1921, 3.2060],\n",
      "        [3.0798, 3.3448, 3.2256, 3.2481, 3.3536],\n",
      "        [3.0169, 3.1246, 3.0477, 3.0844, 3.1262],\n",
      "        [3.3636, 3.4454, 3.3893, 3.4710, 3.4841],\n",
      "        [3.0476, 3.1728, 3.2380, 3.1871, 3.2611],\n",
      "        [3.3615, 3.3979, 3.4048, 3.3625, 3.2570],\n",
      "        [3.2784, 3.2836, 3.2390, 3.3794, 3.4272],\n",
      "        [3.4348, 3.3083, 3.2692, 3.3827, 3.3683],\n",
      "        [3.1384, 3.1387, 3.1790, 3.2171, 3.2068],\n",
      "        [3.2504, 3.1724, 3.3434, 3.3620, 3.2727],\n",
      "        [3.2718, 3.1877, 3.2668, 3.3225, 3.2523],\n",
      "        [3.2914, 3.2918, 3.1291, 3.3801, 3.3789],\n",
      "        [3.1460, 3.2587, 3.2378, 3.2333, 3.1630],\n",
      "        [3.4180, 3.0925, 3.2581, 3.6089, 3.5680],\n",
      "        [3.3861, 3.3289, 3.3404, 3.4982, 3.3839],\n",
      "        [3.0594, 3.2059, 3.1143, 3.1707, 3.2001],\n",
      "        [3.0923, 3.1378, 2.9460, 3.2381, 3.0313],\n",
      "        [3.1107, 3.1185, 3.2861, 3.0660, 3.3471],\n",
      "        [3.0320, 3.0791, 3.1123, 3.1249, 3.1082],\n",
      "        [3.1397, 3.2077, 3.0579, 3.2073, 3.1932],\n",
      "        [3.0195, 3.1219, 3.0412, 3.0826, 3.1024],\n",
      "        [3.3308, 3.2953, 3.3207, 3.4528, 3.3410],\n",
      "        [3.1410, 3.3841, 3.2802, 3.3081, 3.4012],\n",
      "        [3.1516, 3.3455, 3.2112, 3.2198, 3.1219],\n",
      "        [3.3302, 3.2525, 3.2473, 3.2441, 3.1893],\n",
      "        [3.0832, 3.2780, 3.0808, 2.9847, 3.1830],\n",
      "        [3.1998, 3.4035, 3.3083, 3.3131, 3.2453],\n",
      "        [3.4373, 3.5211, 3.2156, 3.3427, 3.3296],\n",
      "        [3.1113, 3.0840, 3.1630, 3.1588, 3.1643],\n",
      "        [3.1211, 3.4149, 3.2160, 3.3333, 3.3691],\n",
      "        [3.2471, 3.2541, 3.1003, 3.2715, 3.3377],\n",
      "        [3.3204, 3.4267, 3.1965, 3.2971, 3.3401],\n",
      "        [3.1572, 3.0411, 3.1371, 3.0915, 3.0991],\n",
      "        [3.0056, 3.1478, 3.2833, 3.1075, 3.2756]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.0048, 3.1243, 3.0477, 3.0683, 3.1054],\n",
      "        [3.0232, 3.1466, 3.1708, 3.1372, 3.1272],\n",
      "        [3.0250, 3.0727, 3.0692, 3.1088, 3.1033],\n",
      "        [3.2201, 3.1849, 3.3069, 3.2982, 3.2955],\n",
      "        [3.1538, 3.1645, 3.2874, 3.3515, 3.4146],\n",
      "        [3.2805, 3.3564, 3.3256, 3.3780, 3.3321],\n",
      "        [3.3248, 3.3877, 3.3268, 3.2863, 3.3573],\n",
      "        [3.1524, 3.1488, 3.1937, 3.2205, 3.2213],\n",
      "        [3.1162, 3.1946, 3.0640, 3.2033, 3.1779],\n",
      "        [3.0050, 3.1693, 3.1464, 3.1126, 3.1174],\n",
      "        [3.1152, 3.3244, 3.2883, 3.1819, 3.4448],\n",
      "        [3.3016, 3.3866, 3.1849, 3.3014, 3.3562],\n",
      "        [3.0165, 3.1343, 3.1446, 3.1272, 3.1256],\n",
      "        [3.1755, 3.4839, 3.2177, 3.4327, 3.3877],\n",
      "        [3.2890, 3.3920, 3.2160, 3.4684, 3.3688],\n",
      "        [3.3049, 3.4067, 3.2537, 3.3760, 3.3502],\n",
      "        [3.0979, 3.2376, 3.3815, 3.2098, 3.3768],\n",
      "        [3.0970, 3.0156, 3.1493, 3.1798, 3.2063],\n",
      "        [3.4309, 3.3062, 3.2848, 3.4031, 3.4163],\n",
      "        [3.1434, 3.0822, 3.1929, 3.1957, 3.1935],\n",
      "        [3.1501, 3.0646, 3.1609, 3.1333, 3.1318],\n",
      "        [3.0119, 3.1808, 3.1552, 3.1170, 3.1229],\n",
      "        [3.4236, 3.5363, 3.3286, 3.3131, 3.3890],\n",
      "        [3.2777, 3.4028, 3.3507, 3.4025, 3.3191],\n",
      "        [3.1347, 3.0704, 3.1566, 3.2069, 3.2957],\n",
      "        [2.9821, 3.0124, 3.0768, 3.0673, 3.0151],\n",
      "        [3.0333, 3.1383, 3.1670, 3.1574, 3.1135],\n",
      "        [3.0357, 3.0601, 3.1041, 3.1226, 3.0958],\n",
      "        [3.2741, 3.2336, 3.2711, 3.2507, 3.1565],\n",
      "        [3.0820, 3.3487, 3.2317, 3.2517, 3.3587],\n",
      "        [3.3277, 3.4790, 3.3020, 3.4804, 3.4345],\n",
      "        [3.1174, 3.4581, 3.3279, 3.2413, 3.2357],\n",
      "        [3.0586, 3.1063, 3.0329, 3.1957, 3.1137],\n",
      "        [3.1259, 3.1398, 3.2822, 3.1148, 3.3483],\n",
      "        [3.2054, 3.1129, 3.1989, 3.2427, 3.2081],\n",
      "        [3.1905, 3.3060, 3.1787, 3.3129, 3.2349],\n",
      "        [3.0489, 2.9993, 3.0726, 3.1430, 3.0651],\n",
      "        [3.4107, 3.0894, 3.2432, 3.6204, 3.5800],\n",
      "        [2.9335, 3.0532, 3.0163, 2.9872, 3.0372],\n",
      "        [3.1486, 3.1125, 3.1917, 3.2062, 3.1991],\n",
      "        [3.2316, 3.3812, 3.2423, 3.4287, 3.3271],\n",
      "        [2.9778, 3.0130, 3.0420, 3.0399, 3.0591],\n",
      "        [3.3036, 3.2479, 3.3602, 3.2946, 3.1270],\n",
      "        [3.2860, 3.3708, 3.2156, 3.3040, 3.3195],\n",
      "        [3.3801, 3.4900, 3.4697, 3.4383, 3.2852],\n",
      "        [2.9725, 3.0262, 3.0379, 3.0371, 3.0550],\n",
      "        [3.2627, 3.4752, 3.2861, 3.3777, 3.3710],\n",
      "        [3.1419, 3.2114, 3.0634, 3.2108, 3.1981],\n",
      "        [3.1760, 3.2201, 3.3579, 3.2946, 3.3672],\n",
      "        [3.3496, 3.2639, 3.3284, 3.4263, 3.3240],\n",
      "        [2.9335, 3.0532, 3.0163, 2.9872, 3.0372],\n",
      "        [3.2670, 3.1958, 3.1984, 3.4290, 3.3208],\n",
      "        [3.0494, 3.1461, 3.2029, 3.1811, 3.1023],\n",
      "        [3.1174, 3.1887, 3.1709, 3.2845, 3.2225],\n",
      "        [3.0159, 3.1852, 3.1590, 3.1316, 3.1386],\n",
      "        [3.1136, 3.0878, 3.1687, 3.1623, 3.1693],\n",
      "        [3.1427, 3.0875, 3.2070, 3.1266, 3.2526],\n",
      "        [3.0692, 3.1044, 3.1528, 3.1888, 3.0979],\n",
      "        [3.1244, 3.1730, 3.1668, 3.2213, 3.3170],\n",
      "        [3.0155, 3.0432, 3.0932, 3.0988, 3.0739],\n",
      "        [3.0612, 3.1860, 3.2469, 3.2316, 3.2972],\n",
      "        [3.4203, 3.4121, 3.3072, 3.4690, 3.5131],\n",
      "        [3.3223, 3.4263, 3.2004, 3.2998, 3.3435],\n",
      "        [3.1461, 3.1450, 3.1895, 3.2183, 3.2128]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2881, 3.3657, 3.3312, 3.3817, 3.3414],\n",
      "        [2.8706, 3.0046, 3.0630, 3.0097, 3.0848],\n",
      "        [3.1476, 3.1175, 3.2452, 3.2511, 3.2411],\n",
      "        [3.1445, 3.2817, 3.1658, 3.2414, 3.2848],\n",
      "        [3.1100, 3.0546, 3.1753, 3.1722, 3.1515],\n",
      "        [3.1519, 3.0681, 3.1660, 3.1365, 3.1362],\n",
      "        [3.4407, 3.3800, 3.3058, 3.4510, 3.4422],\n",
      "        [3.5089, 3.5470, 3.4331, 3.7051, 3.5686],\n",
      "        [3.2507, 3.5516, 3.3053, 3.4852, 3.4670],\n",
      "        [3.2422, 3.1675, 3.2454, 3.1923, 3.1948],\n",
      "        [3.2439, 3.5252, 3.2920, 3.4736, 3.4471],\n",
      "        [3.1556, 3.1681, 3.2925, 3.3547, 3.4191],\n",
      "        [3.3718, 3.4721, 3.4427, 3.3985, 3.2559],\n",
      "        [3.1524, 3.2996, 3.1994, 3.1841, 3.2898],\n",
      "        [3.0589, 3.0668, 3.1252, 3.1489, 3.0868],\n",
      "        [3.1426, 3.0857, 3.1811, 3.2162, 3.3096],\n",
      "        [3.2757, 3.1951, 3.2779, 3.3293, 3.2619],\n",
      "        [3.1792, 3.4748, 3.2667, 3.3920, 3.4256],\n",
      "        [3.0194, 3.0991, 3.1264, 3.1186, 3.1047],\n",
      "        [3.1592, 3.2301, 3.0663, 3.2537, 3.2005],\n",
      "        [3.2259, 3.3446, 3.2645, 3.2861, 3.1716],\n",
      "        [3.1438, 3.1495, 3.2065, 3.1113, 3.0299],\n",
      "        [3.2453, 3.2407, 3.0803, 3.3439, 3.3593],\n",
      "        [3.0185, 3.2259, 3.1848, 3.1303, 3.1547],\n",
      "        [3.2601, 3.2592, 3.1114, 3.3554, 3.3548],\n",
      "        [3.0752, 3.1686, 3.0621, 3.1509, 3.1617],\n",
      "        [3.1446, 3.1770, 3.1382, 3.2749, 3.2320],\n",
      "        [3.0560, 3.1168, 3.1517, 3.0996, 3.1313],\n",
      "        [3.1394, 3.1148, 3.1843, 3.2043, 3.2018],\n",
      "        [3.0378, 3.0827, 3.1407, 3.1441, 3.0841],\n",
      "        [3.2897, 3.3598, 3.3500, 3.3686, 3.3804],\n",
      "        [3.1892, 3.1689, 3.1994, 3.2536, 3.2504],\n",
      "        [3.2246, 3.2433, 3.2267, 3.3035, 3.3387],\n",
      "        [3.2020, 3.3606, 3.2308, 3.3152, 3.4016],\n",
      "        [3.2564, 3.1892, 3.2533, 3.2943, 3.2379],\n",
      "        [3.1662, 3.1294, 3.2196, 3.1842, 3.2081],\n",
      "        [3.0742, 3.3278, 3.1946, 3.0410, 3.2841],\n",
      "        [3.0503, 3.1706, 3.1282, 3.2657, 3.1005],\n",
      "        [3.1254, 3.1225, 3.1385, 3.1647, 3.2351],\n",
      "        [3.0375, 3.1212, 3.1374, 3.1327, 3.1419],\n",
      "        [3.1419, 3.1436, 3.1893, 3.2226, 3.2148],\n",
      "        [3.0293, 3.0984, 3.1262, 3.1264, 3.1197],\n",
      "        [3.1492, 3.1195, 3.1870, 3.2104, 3.2108],\n",
      "        [3.4365, 3.3083, 3.3844, 3.5566, 3.4163],\n",
      "        [3.1670, 3.1475, 3.2396, 3.2558, 3.2414],\n",
      "        [3.2760, 3.4715, 3.3922, 3.3824, 3.4415],\n",
      "        [3.3309, 3.2919, 3.4747, 3.2697, 3.2362],\n",
      "        [3.1463, 3.1234, 3.1891, 3.2095, 3.2095],\n",
      "        [3.1399, 3.1341, 3.1822, 3.2122, 3.2097],\n",
      "        [3.0699, 3.3418, 3.2029, 3.0647, 3.3241],\n",
      "        [3.1380, 3.1269, 3.1905, 3.2181, 3.2123],\n",
      "        [3.3020, 3.4007, 3.3216, 3.4102, 3.3411],\n",
      "        [3.1460, 3.2240, 3.2029, 3.1846, 3.1391],\n",
      "        [3.2127, 3.4161, 3.2747, 3.3414, 3.4306],\n",
      "        [3.1844, 3.2580, 3.0716, 3.2865, 3.2185],\n",
      "        [3.0572, 3.1492, 3.0320, 3.1894, 3.1327],\n",
      "        [3.1013, 3.1822, 3.0508, 3.1754, 3.1506],\n",
      "        [3.0188, 3.1061, 3.1324, 3.1188, 3.1080],\n",
      "        [3.0782, 3.1748, 3.0565, 3.1500, 3.1529],\n",
      "        [3.0702, 3.3918, 3.2928, 3.2423, 3.3952],\n",
      "        [3.1147, 3.1259, 3.2973, 3.0730, 3.3567],\n",
      "        [3.2048, 3.3733, 3.1784, 3.0985, 3.2310],\n",
      "        [3.3417, 3.1822, 3.2072, 3.2761, 3.3129],\n",
      "        [3.3815, 3.3845, 3.3785, 3.4076, 3.4834]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.0863, 3.1897, 3.2578, 3.2641, 3.3346],\n",
      "        [3.0312, 3.1260, 3.1659, 3.1504, 3.1064],\n",
      "        [3.3258, 3.4372, 3.2124, 3.3077, 3.3538],\n",
      "        [3.1809, 3.1598, 3.2815, 3.2869, 3.2840],\n",
      "        [3.1991, 3.1801, 3.2921, 3.2836, 3.2927],\n",
      "        [3.1607, 3.1336, 3.2088, 3.2214, 3.2247],\n",
      "        [3.1512, 3.4328, 3.2471, 3.3635, 3.4044],\n",
      "        [3.0361, 3.1305, 3.1678, 3.1563, 3.1130],\n",
      "        [3.0086, 3.1373, 3.1398, 3.1183, 3.1148],\n",
      "        [3.1394, 3.1695, 3.3206, 3.3346, 3.2832],\n",
      "        [3.3421, 3.4675, 3.3233, 3.2670, 3.3970],\n",
      "        [3.2083, 3.0084, 3.3056, 3.2697, 3.2383],\n",
      "        [3.2146, 3.3794, 3.2451, 3.3311, 3.4198],\n",
      "        [3.1700, 3.2417, 3.0665, 3.2658, 3.2035],\n",
      "        [3.6975, 3.8909, 3.4422, 3.5942, 3.4634],\n",
      "        [3.1178, 3.0648, 3.1292, 3.1724, 3.2855],\n",
      "        [3.2290, 3.2289, 3.2166, 3.3550, 3.2675],\n",
      "        [3.0883, 3.1606, 3.0848, 3.1991, 3.1765],\n",
      "        [3.2804, 3.3444, 3.2204, 3.3847, 3.3278],\n",
      "        [3.1260, 3.2644, 3.2224, 3.2375, 3.2667],\n",
      "        [3.4558, 3.3690, 3.3500, 3.4724, 3.4365],\n",
      "        [3.3727, 3.2994, 3.3323, 3.3757, 3.5337],\n",
      "        [3.0424, 3.3222, 3.1832, 3.0410, 3.3021],\n",
      "        [3.1005, 3.1962, 3.1793, 3.2973, 3.1588],\n",
      "        [3.0468, 3.1235, 3.1708, 3.1613, 3.1162],\n",
      "        [3.1857, 3.3322, 3.2034, 3.2488, 3.3145],\n",
      "        [3.1474, 3.1906, 3.1607, 3.2026, 3.2193],\n",
      "        [3.0746, 3.3383, 3.3068, 3.2285, 3.3819],\n",
      "        [3.2999, 3.3340, 3.3157, 3.3240, 3.4201],\n",
      "        [3.4016, 3.3019, 3.2653, 3.3639, 3.4171],\n",
      "        [3.3390, 3.5748, 3.3136, 3.5445, 3.5203],\n",
      "        [3.0377, 3.0862, 3.1253, 3.1332, 3.1218],\n",
      "        [3.2154, 3.4660, 3.3255, 3.3622, 3.4421],\n",
      "        [3.3486, 3.3463, 3.3822, 3.3630, 3.4328],\n",
      "        [3.1556, 3.4581, 3.2064, 3.4229, 3.3682],\n",
      "        [3.4380, 3.3115, 3.3890, 3.5603, 3.4206],\n",
      "        [3.1388, 3.2623, 3.2227, 3.2339, 3.2551],\n",
      "        [2.9372, 3.0691, 3.0316, 2.9982, 3.0548],\n",
      "        [3.0719, 3.1180, 3.1874, 3.2407, 3.2170],\n",
      "        [3.4040, 3.4383, 3.3006, 3.4269, 3.5108],\n",
      "        [3.3863, 3.3405, 3.3571, 3.5048, 3.3866],\n",
      "        [2.9821, 3.0100, 3.0814, 3.0633, 3.0239],\n",
      "        [3.2148, 3.3499, 3.2582, 3.2851, 3.1698],\n",
      "        [3.1649, 3.1338, 3.2144, 3.2217, 3.2247],\n",
      "        [3.0644, 3.0375, 3.0965, 3.1575, 3.0979],\n",
      "        [3.2334, 3.2046, 3.3187, 3.3539, 3.2574],\n",
      "        [3.2552, 3.2773, 3.2349, 3.4303, 3.2756],\n",
      "        [3.2818, 3.2346, 3.2781, 3.2493, 3.1892],\n",
      "        [3.0154, 3.1533, 3.1523, 3.1326, 3.1358],\n",
      "        [3.2920, 3.3987, 3.2262, 3.4756, 3.3777],\n",
      "        [3.1306, 3.3538, 3.2173, 3.2145, 3.1287],\n",
      "        [3.3148, 3.4407, 3.3511, 3.3924, 3.3414],\n",
      "        [3.0488, 3.0734, 3.1378, 3.1448, 3.0837],\n",
      "        [3.2710, 3.2273, 3.1861, 3.4386, 3.3476],\n",
      "        [3.2481, 3.3491, 3.2823, 3.2980, 3.1876],\n",
      "        [3.1478, 3.1278, 3.1936, 3.2105, 3.2135],\n",
      "        [3.0655, 2.9913, 3.1814, 2.9839, 3.2304],\n",
      "        [3.5003, 3.4309, 3.4249, 3.5599, 3.5442],\n",
      "        [3.1851, 3.1544, 3.2089, 3.2325, 3.2613],\n",
      "        [3.0447, 3.0080, 3.0763, 3.1432, 3.0747],\n",
      "        [3.1822, 3.2395, 3.2190, 3.2215, 3.2611],\n",
      "        [3.0533, 3.0326, 3.0941, 3.1530, 3.0900],\n",
      "        [3.0008, 3.2078, 3.2610, 3.1346, 3.2615],\n",
      "        [3.1505, 3.2383, 3.2234, 3.2214, 3.1472]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.0456, 3.0627, 3.1167, 3.1500, 3.1095],\n",
      "        [3.2495, 3.2928, 3.3070, 3.3702, 3.3759],\n",
      "        [2.9826, 3.1101, 3.0538, 3.0521, 3.0994],\n",
      "        [3.0375, 3.1475, 3.1806, 3.1684, 3.1264],\n",
      "        [3.0342, 3.0770, 3.1227, 3.1347, 3.1098],\n",
      "        [3.2046, 3.3667, 3.2398, 3.3230, 3.4104],\n",
      "        [3.2108, 3.1114, 3.2071, 3.2521, 3.1855],\n",
      "        [3.0477, 3.1588, 3.0657, 3.1318, 3.1437],\n",
      "        [3.2674, 3.2216, 3.2774, 3.4053, 3.2075],\n",
      "        [3.2267, 3.1799, 3.2240, 3.1600, 3.0812],\n",
      "        [3.1702, 3.1637, 3.0965, 3.2123, 3.3109],\n",
      "        [3.2225, 3.1219, 3.4425, 3.3042, 3.3541],\n",
      "        [3.0446, 3.0769, 3.1241, 3.1409, 3.1139],\n",
      "        [3.4079, 3.4439, 3.3138, 3.4487, 3.5046],\n",
      "        [3.1927, 3.2066, 3.2724, 3.2842, 3.3649],\n",
      "        [3.4500, 3.4443, 3.3295, 3.4739, 3.5497],\n",
      "        [3.2754, 3.3404, 3.3623, 3.2894, 3.2171],\n",
      "        [3.2284, 3.3507, 3.2738, 3.2941, 3.1808],\n",
      "        [3.1564, 3.2368, 3.0766, 3.2538, 3.2101],\n",
      "        [3.1528, 3.4498, 3.3534, 3.3025, 3.2680],\n",
      "        [3.2152, 3.2073, 3.2114, 3.3244, 3.2615],\n",
      "        [3.3705, 3.3555, 3.3110, 3.3866, 3.4108],\n",
      "        [3.2225, 3.1619, 3.3055, 3.3391, 3.2998],\n",
      "        [3.1756, 3.1601, 3.2638, 3.2781, 3.2675],\n",
      "        [3.3132, 3.2415, 3.2299, 3.5398, 3.4223],\n",
      "        [3.3109, 3.4231, 3.2750, 3.3738, 3.3678],\n",
      "        [3.4704, 3.5866, 3.3465, 3.3698, 3.3803],\n",
      "        [3.2251, 3.4044, 3.2440, 3.4318, 3.3419],\n",
      "        [3.3706, 3.4594, 3.4101, 3.4865, 3.5031],\n",
      "        [3.1552, 3.1717, 3.2688, 3.1791, 3.3705],\n",
      "        [3.3026, 3.4162, 3.2623, 3.3813, 3.3563],\n",
      "        [3.3860, 3.5348, 3.3411, 3.5133, 3.5371],\n",
      "        [3.1380, 3.1412, 3.1917, 3.2230, 3.2181],\n",
      "        [3.1651, 3.1315, 3.2218, 3.2240, 3.2231],\n",
      "        [3.2534, 3.5579, 3.3150, 3.4933, 3.4760],\n",
      "        [3.0166, 3.2121, 3.1761, 3.1342, 3.1548],\n",
      "        [3.2955, 3.4038, 3.2317, 3.4810, 3.3858],\n",
      "        [3.2946, 3.3071, 3.1473, 3.3949, 3.3964],\n",
      "        [3.1643, 3.3193, 3.1921, 3.3621, 3.2309],\n",
      "        [3.1708, 3.2531, 3.0804, 3.2774, 3.2204],\n",
      "        [3.1504, 3.1648, 3.2086, 3.2429, 3.2359],\n",
      "        [3.1300, 3.1984, 3.1061, 3.2131, 3.2152],\n",
      "        [3.2279, 3.4019, 3.2441, 3.4334, 3.3423],\n",
      "        [3.0531, 3.0619, 3.1170, 3.1457, 3.1094],\n",
      "        [3.1743, 3.3537, 3.2381, 3.2534, 3.1483],\n",
      "        [3.2857, 3.2211, 3.2463, 3.1951, 3.1407],\n",
      "        [3.1549, 3.1217, 3.2199, 3.2243, 3.2175],\n",
      "        [3.1368, 3.1274, 3.1443, 3.2598, 3.1436],\n",
      "        [3.0545, 3.0354, 3.0983, 3.1570, 3.0946],\n",
      "        [3.0322, 3.2422, 3.1957, 3.1549, 3.1888],\n",
      "        [3.1210, 3.3704, 3.3168, 3.1625, 3.3403],\n",
      "        [3.1493, 3.1158, 3.2140, 3.2125, 3.2024],\n",
      "        [2.9632, 3.0915, 3.0468, 3.0253, 3.0885],\n",
      "        [3.0441, 3.1733, 3.0989, 3.2101, 3.1387],\n",
      "        [3.1547, 3.2360, 3.0739, 3.2645, 3.2098],\n",
      "        [3.2656, 3.3116, 3.1939, 3.2904, 3.4366],\n",
      "        [3.1053, 3.0066, 3.0622, 3.1557, 3.0774],\n",
      "        [3.1471, 3.1829, 3.1470, 3.2826, 3.2407],\n",
      "        [3.4815, 3.4725, 3.3914, 3.6401, 3.5269],\n",
      "        [3.0292, 3.0818, 3.0825, 3.1196, 3.1161],\n",
      "        [3.1518, 3.2386, 3.2047, 3.2065, 3.2453],\n",
      "        [3.2840, 3.2848, 3.1243, 3.3844, 3.4039],\n",
      "        [3.0805, 3.1719, 3.0606, 3.1542, 3.1502],\n",
      "        [3.0897, 3.1973, 3.1671, 3.0892, 3.1697]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.1529, 3.2336, 3.0819, 3.2567, 3.2098],\n",
      "        [3.0777, 3.3480, 3.2192, 3.0715, 3.3294],\n",
      "        [2.9644, 3.0939, 3.0505, 3.0290, 3.0925],\n",
      "        [3.2951, 3.2311, 3.1968, 3.4872, 3.3805],\n",
      "        [3.2172, 3.3849, 3.2535, 3.3390, 3.4287],\n",
      "        [3.1489, 3.0942, 3.2108, 3.2099, 3.2105],\n",
      "        [3.0412, 3.3832, 3.2615, 3.2050, 3.3956],\n",
      "        [3.2968, 3.4064, 3.2359, 3.4849, 3.3901],\n",
      "        [3.0415, 3.0910, 3.1532, 3.1555, 3.0967],\n",
      "        [3.4082, 3.5064, 3.2265, 3.3428, 3.3521],\n",
      "        [3.3538, 3.3496, 3.3096, 3.3658, 3.4127],\n",
      "        [3.0235, 3.3620, 3.2492, 3.1912, 3.3836],\n",
      "        [3.1682, 3.2718, 3.2577, 3.2558, 3.1973],\n",
      "        [3.2467, 3.4189, 3.3386, 3.3588, 3.3095],\n",
      "        [3.1546, 3.2988, 3.1422, 3.3675, 3.1776],\n",
      "        [3.0548, 3.0434, 3.1080, 3.1532, 3.1027],\n",
      "        [3.1851, 3.2739, 3.2233, 3.2776, 3.3017],\n",
      "        [3.1543, 3.1634, 3.2306, 3.2522, 3.2499],\n",
      "        [3.0470, 3.0133, 3.0844, 3.1507, 3.0834],\n",
      "        [3.1137, 3.0630, 3.1879, 3.1832, 3.1639],\n",
      "        [3.1774, 3.1535, 3.2553, 3.2473, 3.2763],\n",
      "        [3.1217, 3.1232, 3.1489, 3.2535, 3.1517],\n",
      "        [3.1470, 3.1267, 3.2074, 3.2266, 3.2230],\n",
      "        [3.1461, 3.0943, 3.1943, 3.2278, 3.3231],\n",
      "        [3.4164, 3.1017, 3.2614, 3.6344, 3.5971],\n",
      "        [3.0121, 3.1455, 3.1504, 3.1244, 3.1231],\n",
      "        [3.1647, 3.3637, 3.2375, 3.2446, 3.1466],\n",
      "        [3.4437, 3.3301, 3.4070, 3.5753, 3.4416],\n",
      "        [3.3091, 3.3377, 3.3236, 3.4199, 3.4578],\n",
      "        [3.2968, 3.4064, 3.2359, 3.4849, 3.3901],\n",
      "        [3.0908, 3.1998, 3.1711, 3.0930, 3.1741],\n",
      "        [3.1644, 3.1703, 3.2164, 3.2554, 3.2589],\n",
      "        [3.0033, 3.1285, 3.0631, 3.0797, 3.1198],\n",
      "        [3.1229, 3.0655, 3.2269, 3.0804, 3.2724],\n",
      "        [3.1130, 3.1538, 3.1626, 3.1581, 3.1911],\n",
      "        [3.1917, 3.3061, 3.1520, 3.2035, 3.2804],\n",
      "        [3.2842, 3.2401, 3.2866, 3.2572, 3.1984],\n",
      "        [3.3030, 3.3842, 3.2527, 3.3914, 3.3494],\n",
      "        [3.0832, 3.1856, 3.0792, 3.1503, 3.1757],\n",
      "        [3.0086, 3.1609, 3.1593, 3.1276, 3.1267],\n",
      "        [3.1431, 3.1254, 3.0631, 3.1842, 3.2829],\n",
      "        [3.2461, 3.1890, 3.2342, 3.1840, 3.0976],\n",
      "        [3.3298, 3.3428, 3.3408, 3.4028, 3.4691],\n",
      "        [3.1724, 3.2470, 3.0748, 3.2737, 3.2122],\n",
      "        [3.3071, 3.3990, 3.2042, 3.3166, 3.3743],\n",
      "        [3.2371, 3.3150, 3.3291, 3.3955, 3.3757],\n",
      "        [3.1529, 3.3210, 3.2324, 3.1905, 3.3134],\n",
      "        [3.0816, 3.2156, 3.1038, 3.2670, 3.1499],\n",
      "        [3.1260, 3.3624, 3.2199, 3.2137, 3.1450],\n",
      "        [3.0542, 3.2098, 3.1182, 3.1699, 3.2142],\n",
      "        [3.1989, 3.1775, 3.2792, 3.2674, 3.3016],\n",
      "        [3.1195, 3.1443, 3.3063, 3.1065, 3.3622],\n",
      "        [3.1906, 3.3379, 3.2182, 3.3939, 3.2518],\n",
      "        [3.0880, 3.2235, 3.1217, 3.2274, 3.1298],\n",
      "        [3.1191, 3.0999, 3.1870, 3.1770, 3.1867],\n",
      "        [3.1598, 3.1976, 3.2792, 3.2655, 3.3483],\n",
      "        [3.1201, 3.0702, 3.1376, 3.1803, 3.2948],\n",
      "        [3.3946, 3.3450, 3.3646, 3.5170, 3.4077],\n",
      "        [3.1585, 3.2424, 3.0849, 3.2622, 3.2157],\n",
      "        [3.3374, 3.2683, 3.2713, 3.2627, 3.2136],\n",
      "        [3.2968, 3.4064, 3.2359, 3.4849, 3.3901],\n",
      "        [3.0271, 3.1369, 3.0637, 3.1004, 3.1238],\n",
      "        [3.4625, 3.2248, 3.2821, 3.7428, 3.5695],\n",
      "        [3.3725, 3.4846, 3.4494, 3.4173, 3.2556]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3346, 3.4939, 3.3249, 3.4989, 3.4574],\n",
      "        [3.3025, 3.3388, 3.3110, 3.3668, 3.4391],\n",
      "        [3.1930, 3.3086, 3.1558, 3.2069, 3.2853],\n",
      "        [3.2961, 3.4055, 3.2339, 3.4791, 3.3838],\n",
      "        [3.1083, 3.0443, 3.1198, 3.1931, 3.1102],\n",
      "        [3.3326, 3.2891, 3.3110, 3.3888, 3.5202],\n",
      "        [3.3960, 3.3475, 3.3684, 3.5205, 3.4127],\n",
      "        [3.2959, 3.4068, 3.2388, 3.4874, 3.3918],\n",
      "        [3.1298, 3.2080, 3.3682, 3.2582, 3.3619],\n",
      "        [3.3232, 3.4050, 3.3783, 3.3545, 3.2303],\n",
      "        [3.1845, 3.2749, 3.0652, 3.1919, 3.2349],\n",
      "        [3.4843, 3.4778, 3.3995, 3.6475, 3.5366],\n",
      "        [3.1247, 3.0741, 3.1977, 3.1949, 3.1821],\n",
      "        [3.2631, 3.2738, 3.1328, 3.3793, 3.3897],\n",
      "        [3.2177, 3.2123, 3.2192, 3.3316, 3.2707],\n",
      "        [3.2885, 3.3384, 3.3904, 3.3207, 3.2375],\n",
      "        [3.3069, 3.3974, 3.3614, 3.3388, 3.2201],\n",
      "        [3.1798, 3.1369, 3.2359, 3.2550, 3.2995],\n",
      "        [3.1365, 3.2042, 3.1087, 3.2423, 3.1881],\n",
      "        [3.1934, 3.4481, 3.3629, 3.3781, 3.4628],\n",
      "        [3.1640, 3.2408, 3.0828, 3.2686, 3.2179],\n",
      "        [3.2757, 3.4031, 3.3240, 3.4806, 3.3480],\n",
      "        [3.0802, 3.1791, 3.0782, 3.1656, 3.1788],\n",
      "        [3.1463, 3.2149, 3.1649, 3.2028, 3.2351],\n",
      "        [3.0201, 3.1256, 3.1492, 3.1319, 3.1244],\n",
      "        [3.2492, 3.5366, 3.3098, 3.4890, 3.4653],\n",
      "        [3.1599, 3.0473, 3.1514, 3.1102, 3.1142],\n",
      "        [3.2250, 3.1669, 3.3133, 3.3462, 3.3089],\n",
      "        [3.4682, 3.3740, 3.4150, 3.5086, 3.4948],\n",
      "        [3.1518, 3.1208, 3.2216, 3.2194, 3.2112],\n",
      "        [3.3233, 3.2672, 3.4401, 3.3101, 3.2170],\n",
      "        [3.1826, 3.2644, 3.0996, 3.2978, 3.2394],\n",
      "        [2.9273, 3.0592, 3.1051, 3.0598, 3.1336],\n",
      "        [3.2841, 3.3523, 3.2326, 3.3958, 3.3415],\n",
      "        [3.1983, 3.2269, 3.2109, 3.2842, 3.3297],\n",
      "        [3.0691, 3.0842, 3.0150, 3.1989, 3.0767],\n",
      "        [3.3550, 3.3521, 3.3134, 3.3694, 3.4181],\n",
      "        [3.0786, 3.3389, 3.2115, 3.0559, 3.3018],\n",
      "        [3.2948, 3.3844, 3.3461, 3.3306, 3.2085],\n",
      "        [3.1629, 3.2432, 3.0904, 3.2695, 3.2249],\n",
      "        [3.3035, 3.3421, 3.3283, 3.3359, 3.4352],\n",
      "        [3.3134, 3.4282, 3.2830, 3.3810, 3.3770],\n",
      "        [3.0877, 3.3875, 3.2139, 3.2910, 3.3559],\n",
      "        [3.2855, 3.2425, 3.2904, 3.2606, 3.2033],\n",
      "        [3.7241, 3.8766, 3.4583, 3.5842, 3.5132],\n",
      "        [3.3002, 3.2210, 3.2203, 3.5357, 3.4158],\n",
      "        [3.0521, 3.1635, 3.0767, 3.1274, 3.1508],\n",
      "        [3.0844, 3.1879, 3.0827, 3.1537, 3.1803],\n",
      "        [3.4555, 3.3617, 3.3404, 3.5811, 3.4567],\n",
      "        [3.1264, 3.2165, 3.0791, 3.2260, 3.1910],\n",
      "        [3.2308, 3.4215, 3.3613, 3.3271, 3.3902],\n",
      "        [3.1060, 3.3435, 3.1968, 3.1824, 3.1274],\n",
      "        [3.2094, 3.3843, 3.1951, 3.1134, 3.2487],\n",
      "        [3.1372, 3.2217, 3.2178, 3.3296, 3.2231],\n",
      "        [3.3708, 3.3695, 3.4343, 3.5445, 3.3483],\n",
      "        [3.2339, 3.2637, 3.1840, 3.3449, 3.3062],\n",
      "        [3.1611, 3.2001, 3.2831, 3.2690, 3.3534],\n",
      "        [3.5122, 3.2665, 3.3908, 3.8804, 3.7381],\n",
      "        [3.4541, 3.4096, 3.3540, 3.4784, 3.4900],\n",
      "        [3.1846, 3.1677, 3.2937, 3.2981, 3.2978],\n",
      "        [3.2268, 3.4652, 3.3201, 3.3758, 3.4596],\n",
      "        [3.4829, 3.3531, 3.4135, 3.6003, 3.5023],\n",
      "        [3.0366, 3.0818, 3.1302, 3.1417, 3.1186],\n",
      "        [3.2793, 3.3798, 3.3445, 3.3920, 3.3807]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3118, 3.3203, 3.3557, 3.4125, 3.2490],\n",
      "        [3.1861, 3.3232, 3.1562, 3.4063, 3.2019],\n",
      "        [3.0873, 3.1244, 3.2018, 3.2448, 3.2465],\n",
      "        [3.0259, 3.3667, 3.2580, 3.1978, 3.3942],\n",
      "        [3.1244, 3.2721, 3.1328, 3.3242, 3.1752],\n",
      "        [3.1832, 3.2668, 3.2251, 3.2693, 3.3024],\n",
      "        [3.3661, 3.3509, 3.4884, 3.3323, 3.2373],\n",
      "        [3.1461, 3.1474, 3.2036, 3.2301, 3.2331],\n",
      "        [3.1490, 3.2888, 3.2652, 3.2522, 3.3917],\n",
      "        [3.0271, 3.0219, 3.1004, 3.1467, 3.1158],\n",
      "        [3.4385, 3.3949, 3.4054, 3.5553, 3.3722],\n",
      "        [3.1304, 3.2080, 3.1945, 3.2811, 3.2856],\n",
      "        [3.2360, 3.2452, 3.2421, 3.2966, 3.2675],\n",
      "        [3.0733, 3.2498, 3.2037, 3.1084, 3.1514],\n",
      "        [3.1659, 3.1129, 3.2513, 3.2676, 3.3368],\n",
      "        [3.1296, 3.1680, 3.1595, 3.1635, 3.2132],\n",
      "        [3.2167, 3.0415, 3.3326, 3.3185, 3.3342],\n",
      "        [3.0792, 3.3488, 3.3248, 3.2432, 3.4018],\n",
      "        [3.0518, 3.2595, 3.3614, 3.2297, 3.2986],\n",
      "        [3.0656, 3.0253, 3.0976, 3.1677, 3.1084],\n",
      "        [3.3150, 3.4040, 3.2203, 3.3284, 3.3948],\n",
      "        [3.2857, 3.4446, 3.3713, 3.4160, 3.4922],\n",
      "        [3.2085, 3.3409, 3.2300, 3.3475, 3.2620],\n",
      "        [3.2154, 3.1916, 3.3166, 3.3190, 3.3192],\n",
      "        [3.4597, 3.2278, 3.2923, 3.7561, 3.5731],\n",
      "        [3.1690, 3.1387, 3.2340, 3.2340, 3.2373],\n",
      "        [3.3066, 3.2701, 3.3332, 3.4441, 3.2616],\n",
      "        [3.1563, 3.4432, 3.2646, 3.3781, 3.4240],\n",
      "        [3.1669, 3.1646, 3.2099, 3.2246, 3.2979],\n",
      "        [3.0703, 3.1666, 3.0754, 3.1485, 3.1562],\n",
      "        [3.1981, 3.1740, 3.2917, 3.2834, 3.2954],\n",
      "        [3.4166, 3.3605, 3.3854, 3.4920, 3.3207],\n",
      "        [3.1407, 3.1344, 3.1563, 3.2699, 3.1576],\n",
      "        [3.3359, 3.4961, 3.3297, 3.5020, 3.4629],\n",
      "        [3.2973, 3.4090, 3.2435, 3.4906, 3.3972],\n",
      "        [3.4396, 3.2420, 3.2826, 3.7150, 3.5490],\n",
      "        [3.0799, 3.3411, 3.2160, 3.0590, 3.3072],\n",
      "        [3.2985, 3.4135, 3.3870, 3.3515, 3.2587],\n",
      "        [3.2712, 3.2288, 3.2901, 3.4156, 3.2226],\n",
      "        [3.1286, 3.3670, 3.2284, 3.2202, 3.1552],\n",
      "        [3.3796, 3.2336, 3.2503, 3.3301, 3.3798],\n",
      "        [3.0421, 3.0991, 3.1435, 3.1494, 3.1403],\n",
      "        [3.1321, 3.1898, 3.1939, 3.2429, 3.3458],\n",
      "        [3.1475, 3.2304, 3.0897, 3.2259, 3.2179],\n",
      "        [3.1575, 3.1581, 3.2125, 3.2441, 3.2422],\n",
      "        [3.1745, 3.2601, 3.0925, 3.2876, 3.2344],\n",
      "        [3.3519, 3.2664, 3.2703, 3.3640, 3.3967],\n",
      "        [2.9758, 3.1042, 2.9599, 3.1302, 3.0577],\n",
      "        [3.1921, 3.1929, 3.2407, 3.1637, 3.0942],\n",
      "        [3.4437, 3.3217, 3.4061, 3.5747, 3.4405],\n",
      "        [3.0933, 3.1703, 3.1008, 3.2133, 3.1948],\n",
      "        [3.1621, 3.3662, 3.2442, 3.2450, 3.1549],\n",
      "        [3.2685, 3.2147, 3.2609, 3.1855, 3.1280],\n",
      "        [2.9744, 3.1084, 3.0606, 3.0453, 3.1022],\n",
      "        [3.4810, 3.3820, 3.4610, 3.6474, 3.5093],\n",
      "        [3.0538, 3.0831, 3.1536, 3.1590, 3.1021],\n",
      "        [3.1212, 3.1281, 3.1575, 3.2538, 3.1538],\n",
      "        [3.0077, 3.2168, 3.2900, 3.1552, 3.2443],\n",
      "        [3.0157, 3.1683, 3.3153, 3.1317, 3.3076],\n",
      "        [3.3227, 3.2961, 3.3493, 3.4256, 3.2061],\n",
      "        [3.1415, 3.0871, 3.2366, 3.1182, 3.2841],\n",
      "        [3.0659, 3.0853, 3.0109, 3.2009, 3.0479],\n",
      "        [3.1957, 3.1821, 3.2207, 3.2718, 3.2736],\n",
      "        [3.1607, 3.1560, 3.2167, 3.2293, 3.2882]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2719, 3.3210, 3.2111, 3.3035, 3.4561],\n",
      "        [3.3646, 3.2030, 3.1662, 3.2756, 3.3562],\n",
      "        [3.1743, 3.2337, 3.1341, 3.2587, 3.2660],\n",
      "        [3.0634, 3.0326, 3.1089, 3.1733, 3.1040],\n",
      "        [2.8794, 3.0194, 3.0874, 3.0298, 3.1114],\n",
      "        [3.1116, 3.2051, 3.0796, 3.2095, 3.1853],\n",
      "        [3.1649, 3.1065, 3.2474, 3.2566, 3.3388],\n",
      "        [2.9946, 3.1311, 3.0869, 3.1236, 3.1305],\n",
      "        [3.1191, 3.1262, 3.2002, 3.2097, 3.2346],\n",
      "        [3.2700, 3.0976, 3.3764, 3.3314, 3.3188],\n",
      "        [3.2673, 3.2980, 3.2149, 3.3075, 3.2807],\n",
      "        [3.2785, 3.2395, 3.2070, 3.4556, 3.3713],\n",
      "        [3.1998, 3.2834, 3.0927, 3.2094, 3.2543],\n",
      "        [3.2676, 3.3365, 3.2189, 3.3609, 3.4019],\n",
      "        [3.1593, 3.4592, 3.3708, 3.3159, 3.2877],\n",
      "        [3.4764, 3.4010, 3.3705, 3.5010, 3.4739],\n",
      "        [3.0200, 3.1344, 3.1559, 3.1330, 3.1345],\n",
      "        [3.2380, 3.2435, 3.2460, 3.2953, 3.2629],\n",
      "        [3.1333, 3.2765, 3.2438, 3.2550, 3.2916],\n",
      "        [3.1447, 3.0890, 3.1874, 3.2310, 3.3294],\n",
      "        [3.1361, 3.2073, 3.1221, 3.2259, 3.2337],\n",
      "        [3.2684, 3.4517, 3.3812, 3.3940, 3.5277],\n",
      "        [3.2657, 3.2305, 3.2280, 3.4242, 3.3507],\n",
      "        [3.1096, 3.1293, 3.1699, 3.2424, 3.1511],\n",
      "        [3.3329, 3.4452, 3.2319, 3.3238, 3.3760],\n",
      "        [3.1864, 3.2685, 3.1083, 3.3036, 3.2494],\n",
      "        [3.1578, 3.2400, 3.0942, 3.2658, 3.2243],\n",
      "        [3.0151, 3.1420, 3.0765, 3.0917, 3.1361],\n",
      "        [3.1207, 3.4232, 3.3274, 3.3249, 3.4473],\n",
      "        [3.1594, 3.1514, 3.2169, 3.2451, 3.2424],\n",
      "        [3.2210, 3.2838, 3.1781, 3.3072, 3.3614],\n",
      "        [3.1522, 3.2295, 3.0934, 3.2346, 3.2297],\n",
      "        [3.0790, 3.1560, 3.0852, 3.2024, 3.1551],\n",
      "        [3.1492, 3.1371, 3.2128, 3.2411, 3.2426],\n",
      "        [3.1610, 3.3150, 3.2256, 3.2054, 3.3188],\n",
      "        [3.0717, 3.1280, 3.1911, 3.2068, 3.1245],\n",
      "        [3.1793, 3.2606, 3.0938, 3.3058, 3.2428],\n",
      "        [3.1486, 3.1494, 3.2078, 3.2328, 3.2379],\n",
      "        [3.1532, 3.2209, 3.2324, 3.2686, 3.2248],\n",
      "        [3.1894, 3.2696, 3.1109, 3.3027, 3.2541],\n",
      "        [3.2291, 3.1335, 3.4515, 3.3149, 3.3659],\n",
      "        [3.1359, 3.3698, 3.2412, 3.2365, 3.1632],\n",
      "        [3.0695, 3.0646, 3.1294, 3.1668, 3.1303],\n",
      "        [3.1509, 3.1711, 3.2937, 3.1704, 3.3941],\n",
      "        [3.3008, 3.3510, 3.4172, 3.4304, 3.4749],\n",
      "        [3.3547, 3.3270, 3.3702, 3.4948, 3.3743],\n",
      "        [3.0676, 3.0815, 3.1497, 3.1694, 3.1139],\n",
      "        [3.0443, 3.0753, 3.1327, 3.1467, 3.1238],\n",
      "        [3.1224, 3.1703, 2.9995, 3.2804, 3.0766],\n",
      "        [3.0338, 3.1647, 3.2000, 3.1613, 3.1584],\n",
      "        [3.0015, 3.0437, 3.1165, 3.1114, 3.0575],\n",
      "        [3.0646, 3.3095, 3.1129, 3.0052, 3.2559],\n",
      "        [3.1522, 3.2295, 3.0934, 3.2346, 3.2297],\n",
      "        [3.1790, 3.2602, 3.0920, 3.2907, 3.2375],\n",
      "        [3.1600, 3.1602, 3.2167, 3.2469, 3.2470],\n",
      "        [3.1186, 3.0695, 3.1999, 3.1919, 3.1781],\n",
      "        [3.3394, 3.2672, 3.2718, 3.2558, 3.2052],\n",
      "        [3.4615, 3.4536, 3.3792, 3.6162, 3.5231],\n",
      "        [3.2164, 3.1364, 3.2362, 3.2805, 3.2549],\n",
      "        [3.3248, 3.4648, 3.2829, 3.2312, 3.2905],\n",
      "        [3.2796, 3.3859, 3.3546, 3.4027, 3.3907],\n",
      "        [3.1532, 3.3073, 3.2338, 3.4042, 3.2607],\n",
      "        [3.0567, 3.0651, 3.1248, 3.1593, 3.1253],\n",
      "        [3.2259, 3.2050, 3.3366, 3.3208, 3.3252]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.1343, 3.1715, 3.1672, 3.1687, 3.2220],\n",
      "        [3.1710, 3.2267, 3.1387, 3.3173, 3.2600],\n",
      "        [3.1249, 3.2131, 3.0881, 3.2090, 3.2037],\n",
      "        [3.0691, 3.0449, 3.1181, 3.1758, 3.1233],\n",
      "        [3.2033, 3.3265, 3.2143, 3.3393, 3.2721],\n",
      "        [3.4335, 3.1171, 3.2986, 3.6376, 3.6088],\n",
      "        [3.1794, 3.0734, 3.1882, 3.1329, 3.1500],\n",
      "        [3.4501, 3.4599, 3.3592, 3.4903, 3.5622],\n",
      "        [3.3272, 3.4949, 3.3360, 3.4935, 3.4678],\n",
      "        [3.2820, 3.3455, 3.3753, 3.3516, 3.3595],\n",
      "        [3.1595, 3.0972, 3.2345, 3.2487, 3.3324],\n",
      "        [3.3861, 3.3701, 3.5120, 3.3662, 3.2740],\n",
      "        [3.2173, 3.1990, 3.2321, 3.3117, 3.2832],\n",
      "        [3.1483, 3.1673, 3.3093, 3.1608, 3.3908],\n",
      "        [3.1012, 3.0328, 3.2256, 3.0342, 3.2794],\n",
      "        [3.0845, 3.3448, 3.2241, 3.0643, 3.3165],\n",
      "        [3.1816, 3.2622, 3.0976, 3.3082, 3.2471],\n",
      "        [3.2370, 3.4275, 3.3740, 3.3356, 3.4048],\n",
      "        [3.3907, 3.2781, 3.2460, 3.3573, 3.3997],\n",
      "        [3.2349, 3.1905, 3.2439, 3.1754, 3.1043],\n",
      "        [3.1436, 3.2210, 3.2011, 3.1872, 3.2541],\n",
      "        [3.2677, 3.2111, 3.2746, 3.3153, 3.2635],\n",
      "        [3.3044, 3.4149, 3.2528, 3.4972, 3.4100],\n",
      "        [3.1523, 3.2206, 3.1771, 3.2112, 3.2492],\n",
      "        [3.0205, 3.1720, 3.3233, 3.1368, 3.3166],\n",
      "        [3.3105, 3.4145, 3.2313, 3.3305, 3.3964],\n",
      "        [3.3386, 3.5430, 3.3776, 3.5636, 3.5411],\n",
      "        [3.3773, 3.3798, 3.4473, 3.5550, 3.3680],\n",
      "        [3.1578, 3.1266, 3.2339, 3.2274, 3.2253],\n",
      "        [3.1432, 3.2276, 3.2306, 3.3379, 3.2379],\n",
      "        [3.1617, 3.1531, 3.2207, 3.2476, 3.2468],\n",
      "        [3.1039, 3.0641, 3.1440, 3.1851, 3.1261],\n",
      "        [3.2201, 3.1953, 3.3247, 3.3242, 3.3283],\n",
      "        [3.0610, 3.2101, 3.0715, 3.2081, 3.1594],\n",
      "        [3.2836, 3.4174, 3.3659, 3.4119, 3.4471],\n",
      "        [3.1269, 3.1527, 3.3228, 3.1186, 3.3820],\n",
      "        [3.0251, 3.1497, 3.0862, 3.1018, 3.1554],\n",
      "        [3.0793, 3.3497, 3.3277, 3.2442, 3.4072],\n",
      "        [3.3080, 3.3738, 3.3659, 3.4122, 3.3487],\n",
      "        [3.1466, 3.1522, 3.2122, 3.2383, 3.2418],\n",
      "        [3.3013, 3.1045, 3.1488, 3.2180, 3.3007],\n",
      "        [3.2993, 3.2990, 3.3111, 3.3080, 3.1670],\n",
      "        [3.2854, 3.0916, 3.1395, 3.2267, 3.2703],\n",
      "        [3.2882, 3.3005, 3.2995, 3.2990, 3.1327],\n",
      "        [3.2858, 3.3587, 3.2587, 3.2409, 3.3159],\n",
      "        [3.1786, 3.1745, 3.1170, 3.2275, 3.3343],\n",
      "        [3.0639, 3.0476, 3.1181, 3.1704, 3.1185],\n",
      "        [3.0172, 3.1739, 3.1753, 3.1411, 3.1476],\n",
      "        [3.0207, 3.1332, 3.0827, 3.0971, 3.1347],\n",
      "        [3.2255, 3.3822, 3.2728, 3.2734, 3.3588],\n",
      "        [3.1626, 3.2272, 3.1298, 3.2377, 3.2573],\n",
      "        [3.2330, 3.2057, 3.3418, 3.3244, 3.3321],\n",
      "        [3.3024, 3.2436, 3.2211, 3.5095, 3.4136],\n",
      "        [3.1004, 3.2094, 3.1872, 3.1053, 3.1998],\n",
      "        [2.9804, 3.1076, 2.9672, 3.1351, 3.0661],\n",
      "        [3.1601, 3.2494, 3.2251, 3.2222, 3.2698],\n",
      "        [3.1469, 3.0907, 3.1912, 3.2335, 3.3339],\n",
      "        [3.2927, 3.0991, 3.1445, 3.2204, 3.2783],\n",
      "        [3.1738, 3.4667, 3.3819, 3.3202, 3.3030],\n",
      "        [3.1539, 3.2356, 3.0998, 3.2597, 3.2286],\n",
      "        [3.1505, 3.1943, 3.2197, 3.2382, 3.3978],\n",
      "        [3.1977, 3.3986, 3.1574, 3.2832, 3.2696],\n",
      "        [3.1514, 3.0894, 3.2096, 3.2433, 3.3303],\n",
      "        [3.2193, 3.1223, 3.2271, 3.2671, 3.2084]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.1712, 3.1837, 3.3235, 3.3764, 3.4544],\n",
      "        [3.1904, 3.2720, 3.2365, 3.2770, 3.3153],\n",
      "        [3.3853, 3.3153, 3.3625, 3.3986, 3.5678],\n",
      "        [3.2677, 3.2929, 3.2635, 3.4525, 3.3083],\n",
      "        [3.2140, 3.1877, 3.3164, 3.3020, 3.3169],\n",
      "        [3.0772, 3.1715, 3.0864, 3.1559, 3.1687],\n",
      "        [3.1527, 3.1351, 3.0828, 3.1978, 3.3059],\n",
      "        [3.0274, 3.2240, 3.1988, 3.1519, 3.1810],\n",
      "        [3.2959, 3.3104, 3.2847, 3.4135, 3.4770],\n",
      "        [3.0194, 3.2087, 3.1896, 3.1422, 3.1643],\n",
      "        [3.1623, 3.1180, 3.2426, 3.2242, 3.2350],\n",
      "        [3.1928, 3.0913, 3.2075, 3.1535, 3.1722],\n",
      "        [3.2961, 3.3790, 3.3650, 3.4074, 3.3746],\n",
      "        [2.9939, 3.1225, 3.0751, 3.0721, 3.1254],\n",
      "        [3.2263, 3.2198, 3.2354, 3.3423, 3.2892],\n",
      "        [3.1910, 3.2716, 3.1156, 3.3084, 3.2575],\n",
      "        [3.0740, 3.1365, 3.0675, 3.2185, 3.1562],\n",
      "        [3.1460, 3.0960, 3.1881, 3.2250, 3.3379],\n",
      "        [3.2252, 3.2956, 3.3081, 3.3683, 3.3733],\n",
      "        [3.1429, 3.1459, 3.1755, 3.1968, 3.2868],\n",
      "        [3.4270, 3.1223, 3.2888, 3.6414, 3.6156],\n",
      "        [3.0196, 3.1450, 3.0834, 3.0963, 3.1439],\n",
      "        [3.3533, 3.4598, 3.2294, 3.3207, 3.3737],\n",
      "        [3.1291, 3.1970, 3.1355, 3.1680, 3.1918],\n",
      "        [3.1868, 3.1580, 3.2465, 3.2260, 3.2973],\n",
      "        [3.0741, 3.0678, 3.1366, 3.1715, 3.1385],\n",
      "        [3.1752, 3.0832, 3.1977, 3.1566, 3.1663],\n",
      "        [3.2354, 3.4727, 3.3365, 3.3866, 3.4783],\n",
      "        [3.5166, 3.5483, 3.4740, 3.7122, 3.5641],\n",
      "        [3.4325, 3.3418, 3.3294, 3.4153, 3.4606],\n",
      "        [3.2689, 3.3033, 3.3636, 3.2997, 3.2346],\n",
      "        [3.2988, 3.4173, 3.3838, 3.4262, 3.3635],\n",
      "        [3.0633, 3.2117, 3.0749, 3.2102, 3.1631],\n",
      "        [3.1922, 3.3416, 3.2375, 3.2717, 3.3409],\n",
      "        [3.1828, 3.1609, 3.2713, 3.2575, 3.2950],\n",
      "        [3.0478, 3.1042, 3.1731, 3.1666, 3.1207],\n",
      "        [3.1143, 3.1324, 3.1770, 3.2472, 3.1592],\n",
      "        [3.3212, 3.3100, 3.3624, 3.4206, 3.2383],\n",
      "        [3.4297, 3.2313, 3.2838, 3.6851, 3.5337],\n",
      "        [3.2464, 3.2576, 3.3363, 3.3485, 3.3157],\n",
      "        [3.3084, 3.3733, 3.2788, 3.2808, 3.3350],\n",
      "        [3.0230, 3.1334, 3.1595, 3.1390, 3.1421],\n",
      "        [3.0639, 3.0740, 3.1402, 3.1631, 3.1364],\n",
      "        [3.5766, 3.6658, 3.2818, 3.4690, 3.3423],\n",
      "        [3.0752, 3.0888, 3.0317, 3.2078, 3.0493],\n",
      "        [3.1923, 3.2111, 3.2551, 3.1812, 3.1017],\n",
      "        [3.2641, 3.1969, 3.2893, 3.2139, 3.2564],\n",
      "        [3.2086, 3.3045, 3.1431, 3.2203, 3.2864],\n",
      "        [3.1458, 3.0886, 3.1928, 3.2301, 3.3357],\n",
      "        [3.0462, 3.1648, 3.0926, 3.1246, 3.1696],\n",
      "        [3.4590, 3.2695, 3.4104, 3.5511, 3.4529],\n",
      "        [3.1928, 3.0913, 3.2075, 3.1535, 3.1722],\n",
      "        [3.3293, 3.5430, 3.4458, 3.4581, 3.5315],\n",
      "        [3.2171, 3.3658, 3.2652, 3.2752, 3.3544],\n",
      "        [3.1826, 3.2414, 3.0679, 3.2830, 3.1407],\n",
      "        [3.1256, 3.3067, 3.2997, 3.2552, 3.2974],\n",
      "        [3.1565, 3.2172, 3.2499, 3.2765, 3.2198],\n",
      "        [3.3068, 3.4165, 3.2565, 3.4995, 3.4140],\n",
      "        [3.2778, 3.3604, 3.3929, 3.3770, 3.3587],\n",
      "        [3.1529, 3.1716, 3.1291, 3.2747, 3.2027],\n",
      "        [3.2585, 3.1955, 3.2826, 3.2266, 3.2262],\n",
      "        [3.2254, 3.1251, 3.2200, 3.2782, 3.2055],\n",
      "        [3.0976, 3.2330, 3.1407, 3.2412, 3.1519],\n",
      "        [3.3811, 3.3682, 3.3356, 3.4053, 3.4411]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2408, 3.2822, 3.1822, 3.3248, 3.3028],\n",
      "        [3.3191, 3.4461, 3.3826, 3.4082, 3.3696],\n",
      "        [3.1596, 3.2488, 3.2449, 3.2196, 3.1799],\n",
      "        [3.1382, 3.2805, 3.2555, 3.2529, 3.3187],\n",
      "        [3.1976, 3.2767, 3.0868, 3.2066, 3.2538],\n",
      "        [3.4418, 3.4550, 3.3519, 3.4844, 3.5587],\n",
      "        [3.1583, 3.2957, 3.2828, 3.2623, 3.4098],\n",
      "        [3.0702, 3.0373, 3.1212, 3.1798, 3.1157],\n",
      "        [3.2252, 3.1342, 3.2446, 3.2778, 3.2311],\n",
      "        [3.1148, 3.2130, 3.2131, 3.3206, 3.1945],\n",
      "        [3.0854, 3.4128, 3.3338, 3.2707, 3.4377],\n",
      "        [3.0796, 3.2032, 3.2921, 3.2254, 3.3145],\n",
      "        [3.0327, 3.0656, 3.1343, 3.1292, 3.1162],\n",
      "        [3.5003, 3.3953, 3.4876, 3.6472, 3.5231],\n",
      "        [3.2854, 3.2443, 3.2197, 3.4623, 3.3832],\n",
      "        [3.5173, 3.4851, 3.4305, 3.5887, 3.5716],\n",
      "        [3.3070, 3.4159, 3.2610, 3.5005, 3.4144],\n",
      "        [3.1840, 3.1282, 3.2798, 3.2893, 3.3613],\n",
      "        [3.4613, 3.2710, 3.4159, 3.5532, 3.4566],\n",
      "        [3.4987, 3.5297, 3.4761, 3.6951, 3.5358],\n",
      "        [3.1560, 3.0925, 3.2185, 3.2476, 3.3380],\n",
      "        [3.1549, 3.1951, 3.3124, 3.2546, 3.3712],\n",
      "        [3.1409, 3.2171, 3.3900, 3.2707, 3.3841],\n",
      "        [3.0329, 3.2328, 3.2085, 3.1643, 3.1949],\n",
      "        [3.2757, 3.3919, 3.2366, 3.3420, 3.3514],\n",
      "        [3.2303, 3.4832, 3.3596, 3.3867, 3.4783],\n",
      "        [3.4476, 3.3302, 3.3297, 3.4353, 3.4665],\n",
      "        [3.0751, 3.0917, 3.0266, 3.2099, 3.0634],\n",
      "        [3.0437, 3.0977, 3.1527, 3.1474, 3.1408],\n",
      "        [3.0705, 3.0679, 3.1356, 3.1714, 3.1350],\n",
      "        [3.2463, 3.2730, 3.1991, 3.3562, 3.3268],\n",
      "        [3.1659, 3.1360, 3.2346, 3.2362, 3.2427],\n",
      "        [3.2054, 3.3657, 3.2806, 3.2894, 3.1889],\n",
      "        [3.3821, 3.3832, 3.4568, 3.5595, 3.3762],\n",
      "        [3.0835, 3.2851, 3.2233, 3.2401, 3.3948],\n",
      "        [3.0218, 3.1464, 3.0883, 3.0983, 3.1473],\n",
      "        [3.2378, 3.4743, 3.3418, 3.3887, 3.4820],\n",
      "        [3.1742, 3.2534, 3.2586, 3.2449, 3.1762],\n",
      "        [3.3819, 3.3790, 3.4575, 3.5577, 3.3721],\n",
      "        [3.1307, 3.1463, 3.3364, 3.1014, 3.3972],\n",
      "        [3.4567, 3.5483, 3.2654, 3.3770, 3.3796],\n",
      "        [3.0337, 3.1049, 3.1578, 3.1450, 3.1383],\n",
      "        [3.3201, 3.3836, 3.2788, 3.3204, 3.3542],\n",
      "        [3.1510, 3.3506, 3.2917, 3.1901, 3.3509],\n",
      "        [3.3437, 3.5786, 3.3476, 3.5509, 3.5414],\n",
      "        [3.4092, 3.2941, 3.2920, 3.3790, 3.4413],\n",
      "        [3.3209, 3.4160, 3.2495, 3.3408, 3.4197],\n",
      "        [3.1551, 3.1697, 3.3177, 3.1643, 3.4104],\n",
      "        [3.5238, 3.5718, 3.5055, 3.7491, 3.6221],\n",
      "        [3.0306, 3.1343, 3.1697, 3.1443, 3.1456],\n",
      "        [3.2982, 3.4592, 3.3911, 3.4371, 3.5093],\n",
      "        [3.1237, 3.1931, 3.2271, 3.2611, 3.1978],\n",
      "        [3.3323, 3.2812, 3.3295, 3.3582, 3.5358],\n",
      "        [3.5151, 3.6038, 3.2745, 3.4105, 3.3727],\n",
      "        [3.2960, 3.2733, 3.3176, 3.2958, 3.2002],\n",
      "        [3.1128, 3.2769, 3.2288, 3.1374, 3.1855],\n",
      "        [3.3051, 3.2185, 3.3215, 3.3650, 3.2998],\n",
      "        [3.0349, 3.1184, 3.1630, 3.1458, 3.1432],\n",
      "        [3.2880, 3.3423, 3.2234, 3.3134, 3.4665],\n",
      "        [2.8701, 3.0192, 3.0973, 3.0194, 3.0954],\n",
      "        [3.4320, 3.2329, 3.2892, 3.6871, 3.5372],\n",
      "        [3.1084, 3.2176, 3.2573, 3.2636, 3.3837],\n",
      "        [3.1548, 3.1487, 3.2171, 3.2354, 3.2467],\n",
      "        [3.1395, 3.1002, 3.2072, 3.1853, 3.2000]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2925, 3.3633, 3.2724, 3.2469, 3.3267],\n",
      "        [3.1965, 3.2140, 3.2650, 3.1851, 3.1084],\n",
      "        [3.4599, 3.2799, 3.4148, 3.5221, 3.4581],\n",
      "        [2.9855, 3.1160, 3.0807, 3.0564, 3.1208],\n",
      "        [3.1860, 3.2681, 3.1140, 3.2989, 3.2539],\n",
      "        [3.1917, 3.4132, 3.2194, 3.4208, 3.3550],\n",
      "        [3.3154, 3.3881, 3.2878, 3.3385, 3.3523],\n",
      "        [3.4163, 3.3618, 3.4001, 3.5374, 3.4477],\n",
      "        [3.1235, 3.0719, 3.1518, 3.1796, 3.3187],\n",
      "        [3.1461, 3.2331, 3.2356, 3.3413, 3.2313],\n",
      "        [3.1063, 3.1268, 3.2172, 3.2265, 3.2432],\n",
      "        [2.9402, 3.0694, 3.1305, 3.0739, 3.1579],\n",
      "        [3.5897, 3.7276, 3.3610, 3.4570, 3.3976],\n",
      "        [3.0695, 3.2504, 3.0617, 3.2099, 3.1255],\n",
      "        [3.4635, 3.3854, 3.4013, 3.5916, 3.5145],\n",
      "        [3.3890, 3.4838, 3.4472, 3.5124, 3.5330],\n",
      "        [3.3115, 3.4196, 3.2671, 3.5036, 3.4211],\n",
      "        [3.0702, 3.2019, 3.2923, 3.2233, 3.3132],\n",
      "        [3.1057, 3.1990, 3.1016, 3.1879, 3.2073],\n",
      "        [3.1573, 3.2392, 3.1171, 3.2557, 3.2422],\n",
      "        [3.3488, 3.2674, 3.3481, 3.4393, 3.3477],\n",
      "        [3.2424, 3.2654, 3.2715, 3.3342, 3.3850],\n",
      "        [3.0149, 2.9834, 3.0985, 3.1684, 3.1107],\n",
      "        [3.4717, 3.2364, 3.3148, 3.7671, 3.5926],\n",
      "        [3.1322, 3.2744, 3.2504, 3.2451, 3.3151],\n",
      "        [3.2954, 3.3830, 3.2629, 3.3462, 3.3626],\n",
      "        [3.4092, 3.3581, 3.3965, 3.5352, 3.4389],\n",
      "        [3.3157, 3.3498, 3.3389, 3.3822, 3.4666],\n",
      "        [3.3236, 3.4698, 3.3205, 3.4008, 3.4071],\n",
      "        [3.3665, 3.4554, 3.4590, 3.3961, 3.2267],\n",
      "        [3.0908, 3.2948, 3.2311, 3.2494, 3.4105],\n",
      "        [3.7778, 3.8981, 3.5589, 3.6616, 3.5384],\n",
      "        [3.0635, 3.2679, 3.3835, 3.2409, 3.3185],\n",
      "        [3.2103, 3.5149, 3.3189, 3.4583, 3.4645],\n",
      "        [3.3497, 3.2038, 3.2549, 3.3047, 3.3516],\n",
      "        [3.2457, 3.3259, 3.1984, 3.3336, 3.3474],\n",
      "        [3.5356, 3.3121, 3.4602, 3.9130, 3.8032],\n",
      "        [3.4439, 3.4565, 3.3570, 3.4862, 3.5620],\n",
      "        [3.1464, 3.2336, 3.1139, 3.2410, 3.2279],\n",
      "        [3.3325, 3.3740, 3.4025, 3.5176, 3.3542],\n",
      "        [3.1844, 3.4846, 3.2498, 3.4444, 3.4280],\n",
      "        [3.4562, 3.4132, 3.4435, 3.5805, 3.4981],\n",
      "        [3.1661, 3.1316, 3.2457, 3.2396, 3.2372],\n",
      "        [3.1846, 3.1691, 3.2830, 3.2853, 3.2853],\n",
      "        [3.1764, 3.3178, 3.2152, 3.2641, 3.3417],\n",
      "        [3.1014, 3.1973, 3.1087, 3.1750, 3.2134],\n",
      "        [3.3639, 3.4383, 3.4395, 3.3955, 3.2774],\n",
      "        [3.3585, 3.4397, 3.4659, 3.3785, 3.2202],\n",
      "        [3.3096, 3.4181, 3.2398, 3.3342, 3.4005],\n",
      "        [3.1187, 3.2027, 3.0923, 3.2043, 3.1920],\n",
      "        [3.5029, 3.3270, 3.3910, 3.8692, 3.7493],\n",
      "        [3.1253, 3.1930, 3.2284, 3.2522, 3.1902],\n",
      "        [3.1650, 3.1263, 3.2437, 3.2416, 3.2311],\n",
      "        [3.0921, 3.1670, 3.1019, 3.2147, 3.1658],\n",
      "        [3.2110, 3.2376, 3.2380, 3.2992, 3.3565],\n",
      "        [3.1996, 3.1321, 3.2971, 3.3086, 3.3693],\n",
      "        [3.3700, 3.2890, 3.3780, 3.4591, 3.3728],\n",
      "        [3.1658, 3.1702, 3.2382, 3.2509, 3.2611],\n",
      "        [3.4588, 3.5498, 3.2704, 3.3788, 3.3829],\n",
      "        [3.3288, 3.2573, 3.2645, 3.5613, 3.4566],\n",
      "        [3.1667, 3.2539, 3.2389, 3.2284, 3.2810],\n",
      "        [3.1368, 3.2531, 3.1693, 3.2774, 3.3161],\n",
      "        [3.3167, 3.4021, 3.2884, 3.4008, 3.3850],\n",
      "        [3.1733, 3.2831, 3.2847, 3.2686, 3.2233]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2650, 3.2637, 3.1279, 3.3752, 3.4049],\n",
      "        [3.0356, 3.2253, 3.2155, 3.1650, 3.1974],\n",
      "        [3.0841, 3.0121, 3.2237, 3.0118, 3.2712],\n",
      "        [3.1393, 3.0811, 3.2614, 3.1008, 3.3051],\n",
      "        [3.0436, 3.1633, 3.1016, 3.1283, 3.1660],\n",
      "        [3.0330, 3.1053, 3.1612, 3.1453, 3.1398],\n",
      "        [3.1356, 3.2025, 3.1496, 3.1742, 3.2012],\n",
      "        [3.4635, 3.4979, 3.4502, 3.4961, 3.5562],\n",
      "        [3.2069, 3.1841, 3.3254, 3.3227, 3.3280],\n",
      "        [3.1819, 3.2606, 3.1191, 3.2879, 3.2545],\n",
      "        [3.3661, 3.4411, 3.4443, 3.3980, 3.2805],\n",
      "        [3.0748, 3.2725, 3.0891, 3.2274, 3.1369],\n",
      "        [3.1020, 3.3487, 3.2102, 3.1750, 3.1496],\n",
      "        [3.4740, 3.3909, 3.3955, 3.5027, 3.4839],\n",
      "        [3.5023, 3.4212, 3.3965, 3.5228, 3.5213],\n",
      "        [3.3740, 3.3826, 3.4146, 3.4547, 3.3822],\n",
      "        [3.2151, 3.1933, 3.3141, 3.2877, 3.3347],\n",
      "        [3.3220, 3.3836, 3.2766, 3.4133, 3.3805],\n",
      "        [3.3171, 3.3781, 3.2709, 3.4131, 3.3697],\n",
      "        [3.0344, 3.2362, 3.3356, 3.1545, 3.2612],\n",
      "        [3.0264, 3.1958, 3.1967, 3.1473, 3.1659],\n",
      "        [3.1708, 3.1605, 3.2392, 3.2561, 3.2607],\n",
      "        [3.3005, 3.4698, 3.2775, 3.2024, 3.3388],\n",
      "        [3.1546, 3.1430, 3.0970, 3.2040, 3.3164],\n",
      "        [3.3149, 3.3791, 3.2936, 3.2870, 3.3448],\n",
      "        [3.5379, 3.3151, 3.4650, 3.9156, 3.8061],\n",
      "        [2.9646, 3.0867, 3.0680, 3.0396, 3.1057],\n",
      "        [3.3985, 3.1395, 3.3148, 3.5873, 3.5887],\n",
      "        [3.2025, 3.3242, 3.2057, 3.2230, 3.3222],\n",
      "        [3.2565, 3.1581, 3.4836, 3.3460, 3.4103],\n",
      "        [3.0339, 3.2294, 3.2129, 3.1581, 3.1904],\n",
      "        [3.5272, 3.4599, 3.4754, 3.5941, 3.5980],\n",
      "        [3.4240, 3.4667, 3.4231, 3.4512, 3.5103],\n",
      "        [3.2812, 3.1061, 3.3985, 3.3425, 3.3370],\n",
      "        [3.2058, 3.3305, 3.2082, 3.2226, 3.3257],\n",
      "        [3.2101, 3.2252, 3.3123, 3.3092, 3.4045],\n",
      "        [3.2485, 3.3552, 3.2503, 3.3651, 3.3322],\n",
      "        [3.0225, 3.1503, 3.1005, 3.1076, 3.1555],\n",
      "        [3.1901, 3.2689, 3.1139, 3.3017, 3.2552],\n",
      "        [3.3862, 3.4302, 3.4649, 3.4028, 3.3137],\n",
      "        [3.0801, 3.1326, 3.0830, 3.2296, 3.1614],\n",
      "        [3.3480, 3.4134, 3.2649, 3.3650, 3.4546],\n",
      "        [3.1934, 3.1638, 3.2615, 3.2324, 3.3071],\n",
      "        [3.1496, 3.3749, 3.2611, 3.2428, 3.1709],\n",
      "        [3.1554, 3.2878, 3.1564, 3.3649, 3.1919],\n",
      "        [3.5010, 3.2892, 3.4334, 3.8753, 3.7785],\n",
      "        [3.2497, 3.3596, 3.2508, 3.3729, 3.3247],\n",
      "        [3.1774, 3.1634, 3.2549, 3.2515, 3.3060],\n",
      "        [3.6573, 3.7628, 3.4323, 3.5146, 3.4281],\n",
      "        [3.1364, 3.3531, 3.3442, 3.2178, 3.4980],\n",
      "        [3.1446, 3.5174, 3.3911, 3.2808, 3.2949],\n",
      "        [3.1860, 3.4003, 3.2228, 3.1130, 3.3481],\n",
      "        [3.2831, 3.5378, 3.3929, 3.4379, 3.5770],\n",
      "        [3.0615, 3.1752, 3.1030, 3.1483, 3.1738],\n",
      "        [3.0629, 3.1425, 3.2033, 3.1770, 3.1544],\n",
      "        [3.0349, 3.2363, 3.2202, 3.1652, 3.2032],\n",
      "        [3.1647, 3.2219, 3.3091, 3.2953, 3.3469],\n",
      "        [3.0374, 3.2118, 3.2095, 3.1666, 3.1872],\n",
      "        [3.2034, 3.1812, 3.3056, 3.2759, 3.3168],\n",
      "        [3.3518, 3.2066, 3.2596, 3.3072, 3.3547],\n",
      "        [3.3205, 3.2814, 3.3608, 3.4582, 3.2857],\n",
      "        [3.4435, 3.3831, 3.4311, 3.5331, 3.3448],\n",
      "        [3.3014, 3.3935, 3.2838, 3.3815, 3.3517],\n",
      "        [3.2224, 3.3857, 3.2141, 3.3319, 3.3282]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.1640, 3.3005, 3.2080, 3.2840, 3.3365],\n",
      "        [3.1909, 3.2494, 3.0856, 3.2927, 3.1524],\n",
      "        [3.2761, 3.2063, 3.4067, 3.4049, 3.3318],\n",
      "        [3.2339, 3.3724, 3.3100, 3.3178, 3.2139],\n",
      "        [3.1615, 3.2393, 3.2327, 3.2435, 3.2858],\n",
      "        [3.1444, 3.3806, 3.2595, 3.2378, 3.1811],\n",
      "        [3.2236, 3.2859, 3.3102, 3.3632, 3.3977],\n",
      "        [3.3133, 3.4227, 3.2751, 3.5088, 3.4236],\n",
      "        [2.9808, 3.1902, 2.9980, 3.1641, 3.0635],\n",
      "        [3.1106, 3.0394, 3.1946, 3.2076, 3.2531],\n",
      "        [3.0253, 3.1795, 3.1955, 3.1525, 3.1574],\n",
      "        [3.5266, 3.5799, 3.5134, 3.7708, 3.6400],\n",
      "        [3.2954, 3.3810, 3.4028, 3.3948, 3.3592],\n",
      "        [3.1057, 3.1581, 3.1962, 3.1638, 3.1979],\n",
      "        [3.4160, 3.2812, 3.3997, 3.5396, 3.4152],\n",
      "        [3.0716, 3.2196, 3.0926, 3.2199, 3.1749],\n",
      "        [3.3105, 3.2626, 3.3475, 3.4521, 3.2802],\n",
      "        [3.4638, 3.2852, 3.4238, 3.5281, 3.4639],\n",
      "        [3.0420, 3.0931, 3.1601, 3.1521, 3.1410],\n",
      "        [3.2530, 3.3725, 3.3224, 3.3239, 3.2277],\n",
      "        [3.1523, 3.2074, 3.1586, 3.2716, 3.2270],\n",
      "        [3.4535, 3.3370, 3.3440, 3.4434, 3.4762],\n",
      "        [3.1376, 3.2050, 3.2166, 3.2797, 3.3279],\n",
      "        [3.4626, 3.5552, 3.2793, 3.3849, 3.3886],\n",
      "        [3.5446, 3.3899, 3.4982, 3.6799, 3.5726],\n",
      "        [3.2015, 3.3364, 3.1856, 3.4237, 3.2263],\n",
      "        [3.2391, 3.2081, 3.3494, 3.3342, 3.3414],\n",
      "        [3.0633, 3.1934, 3.1399, 3.2373, 3.1767],\n",
      "        [3.2432, 3.5179, 3.2761, 3.4837, 3.4489],\n",
      "        [3.1553, 3.1685, 3.2416, 3.2622, 3.2637],\n",
      "        [3.3549, 3.2864, 3.3105, 3.2870, 3.2508],\n",
      "        [3.1022, 3.2076, 3.1146, 3.1923, 3.2075],\n",
      "        [3.1379, 3.2175, 3.1054, 3.2367, 3.2040],\n",
      "        [3.3380, 3.1955, 3.2704, 3.3021, 3.3274],\n",
      "        [3.3259, 3.2612, 3.2934, 3.2489, 3.2139],\n",
      "        [3.5066, 3.4023, 3.5023, 3.6553, 3.5325],\n",
      "        [3.2969, 3.3831, 3.3625, 3.4891, 3.3575],\n",
      "        [3.1819, 3.2363, 3.1607, 3.3294, 3.2760],\n",
      "        [3.1561, 3.1476, 3.1860, 3.2871, 3.1826],\n",
      "        [3.1283, 3.1930, 3.1446, 3.1697, 3.1944],\n",
      "        [3.1457, 3.2215, 3.2255, 3.2985, 3.3120],\n",
      "        [3.0276, 3.2165, 3.2076, 3.1521, 3.1762],\n",
      "        [3.3579, 3.2820, 3.3800, 3.4627, 3.3626],\n",
      "        [3.2679, 3.4609, 3.3961, 3.4022, 3.5521],\n",
      "        [3.1705, 3.1263, 3.2614, 3.2340, 3.2470],\n",
      "        [3.2351, 3.4431, 3.3269, 3.3774, 3.4798],\n",
      "        [3.1583, 3.2416, 3.1148, 3.2572, 3.2368],\n",
      "        [3.0288, 3.1598, 3.1847, 3.1497, 3.1575],\n",
      "        [3.1728, 3.4710, 3.3983, 3.3309, 3.3093],\n",
      "        [3.1539, 3.2374, 3.2533, 3.3499, 3.2547],\n",
      "        [3.0517, 3.0983, 3.1626, 3.1584, 3.1498],\n",
      "        [3.1442, 3.1250, 3.2320, 3.2046, 3.2289],\n",
      "        [3.2092, 3.1618, 3.3164, 3.3419, 3.2996],\n",
      "        [3.2865, 3.2318, 3.2815, 3.1999, 3.1613],\n",
      "        [3.3185, 3.4218, 3.3548, 3.4303, 3.3864],\n",
      "        [3.0632, 3.1775, 3.1069, 3.1519, 3.1764],\n",
      "        [3.2669, 3.2039, 3.3020, 3.2368, 3.2387],\n",
      "        [3.1317, 3.2011, 3.3479, 3.2647, 3.3491],\n",
      "        [3.1666, 3.1122, 3.2488, 3.2331, 3.2448],\n",
      "        [3.1319, 3.0627, 3.2156, 3.2280, 3.2658],\n",
      "        [3.2681, 3.3061, 3.2514, 3.3092, 3.3003],\n",
      "        [3.0304, 3.0665, 3.1462, 3.1329, 3.1048],\n",
      "        [3.1563, 3.1454, 3.1011, 3.2075, 3.3191],\n",
      "        [3.3132, 3.2697, 3.3141, 3.3691, 3.5207]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2026, 3.3855, 3.2929, 3.2899, 3.1950],\n",
      "        [3.0383, 3.1443, 3.1863, 3.1553, 3.1574],\n",
      "        [3.0704, 3.0760, 3.1548, 3.1733, 3.1472],\n",
      "        [3.3898, 3.4365, 3.4731, 3.4100, 3.3199],\n",
      "        [3.1944, 3.2301, 3.2800, 3.2576, 3.4878],\n",
      "        [3.2869, 3.3757, 3.3565, 3.3601, 3.2523],\n",
      "        [3.1272, 3.0594, 3.1350, 3.1914, 3.1378],\n",
      "        [3.2923, 3.2301, 3.2597, 3.4712, 3.3775],\n",
      "        [3.4862, 3.5394, 3.4524, 3.6884, 3.5497],\n",
      "        [3.1775, 3.1732, 3.2513, 3.2501, 3.3180],\n",
      "        [3.2164, 3.4177, 3.2474, 3.4437, 3.3710],\n",
      "        [3.0733, 3.0478, 3.1356, 3.1845, 3.1305],\n",
      "        [3.2484, 3.2925, 3.1995, 3.3360, 3.3151],\n",
      "        [3.2332, 3.1447, 3.2589, 3.2947, 3.2399],\n",
      "        [3.1025, 3.2064, 3.1199, 3.1770, 3.2132],\n",
      "        [3.0814, 3.0581, 3.1436, 3.1908, 3.1427],\n",
      "        [3.1916, 3.4050, 3.2158, 3.1188, 3.3167],\n",
      "        [3.2261, 3.4571, 3.4238, 3.4188, 3.4790],\n",
      "        [3.0364, 3.1316, 3.1764, 3.1508, 3.1536],\n",
      "        [3.1640, 3.1166, 3.2309, 3.1965, 3.2117],\n",
      "        [3.1626, 3.1591, 3.2347, 3.2466, 3.2589],\n",
      "        [3.3399, 3.5554, 3.4693, 3.4720, 3.5480],\n",
      "        [3.0864, 3.1427, 3.2202, 3.2246, 3.1479],\n",
      "        [3.2734, 3.4779, 3.4120, 3.4101, 3.5709],\n",
      "        [3.4312, 3.3309, 3.3287, 3.4085, 3.4688],\n",
      "        [3.4677, 3.3879, 3.4107, 3.4934, 3.4826],\n",
      "        [3.1330, 3.0846, 3.2293, 3.2095, 3.2009],\n",
      "        [3.0900, 3.2666, 3.2375, 3.1290, 3.1810],\n",
      "        [3.5483, 3.2707, 3.4007, 3.8468, 3.7768],\n",
      "        [3.3011, 3.3504, 3.2435, 3.3293, 3.4736],\n",
      "        [3.0294, 3.1562, 3.1046, 3.1092, 3.1589],\n",
      "        [3.1682, 3.1148, 3.2516, 3.2632, 3.3543],\n",
      "        [3.1635, 3.1647, 3.2381, 3.2508, 3.2621],\n",
      "        [3.1723, 3.2655, 3.2746, 3.2567, 3.1965],\n",
      "        [3.4691, 3.2815, 3.4340, 3.5642, 3.4690],\n",
      "        [3.0370, 3.1679, 3.1171, 3.1688, 3.1555],\n",
      "        [3.5318, 3.2871, 3.4316, 3.9047, 3.7721],\n",
      "        [3.0374, 3.2355, 3.2205, 3.1650, 3.1962],\n",
      "        [3.3288, 3.2827, 3.4270, 3.3411, 3.1666],\n",
      "        [3.2210, 3.3171, 3.1619, 3.2420, 3.3068],\n",
      "        [3.1547, 3.1072, 3.2493, 3.2300, 3.2275],\n",
      "        [3.2230, 3.3513, 3.3819, 3.3843, 3.3614],\n",
      "        [3.1392, 3.2088, 3.2475, 3.2632, 3.2061],\n",
      "        [3.4007, 3.3457, 3.4584, 3.4624, 3.2926],\n",
      "        [3.1226, 3.3681, 3.2166, 3.1875, 3.1763],\n",
      "        [3.1874, 3.3185, 3.1749, 3.4056, 3.2166],\n",
      "        [3.2522, 3.2832, 3.2226, 3.3689, 3.3407],\n",
      "        [3.0224, 3.0654, 3.1081, 3.1097, 3.1250],\n",
      "        [3.3117, 3.3627, 3.3805, 3.3381, 3.3836],\n",
      "        [3.1550, 3.1474, 3.2601, 3.2716, 3.3255],\n",
      "        [3.0723, 3.0372, 3.1287, 3.1778, 3.1237],\n",
      "        [3.2526, 3.2588, 3.2765, 3.3135, 3.2875],\n",
      "        [3.1902, 3.1602, 3.2761, 3.2232, 3.2602],\n",
      "        [3.5262, 3.3765, 3.4813, 3.6574, 3.5335],\n",
      "        [3.1683, 3.3226, 3.2650, 3.4222, 3.2853],\n",
      "        [3.3250, 3.2540, 3.2944, 3.2449, 3.2063],\n",
      "        [3.2402, 3.2182, 3.3601, 3.3268, 3.3500],\n",
      "        [3.1356, 3.3188, 3.3232, 3.2686, 3.3141],\n",
      "        [3.3115, 3.3125, 3.3378, 3.3235, 3.1874],\n",
      "        [3.3115, 3.3696, 3.2520, 3.3497, 3.4696],\n",
      "        [3.0827, 3.1015, 3.0428, 3.2208, 3.0749],\n",
      "        [3.1756, 3.1161, 3.2632, 3.2671, 3.3584],\n",
      "        [3.3441, 3.2113, 3.2847, 3.3112, 3.3378],\n",
      "        [3.3035, 3.4624, 3.4070, 3.4374, 3.5225]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5389, 3.5792, 3.5189, 3.7524, 3.6212],\n",
      "        [3.1754, 3.4644, 3.3037, 3.4030, 3.4577],\n",
      "        [3.2516, 3.4825, 3.3668, 3.4051, 3.5026],\n",
      "        [3.1920, 3.1637, 3.2798, 3.2270, 3.2633],\n",
      "        [3.1708, 3.1878, 3.2565, 3.2742, 3.2789],\n",
      "        [3.0704, 3.1940, 3.1161, 3.1607, 3.1940],\n",
      "        [3.2786, 3.2017, 3.3087, 3.2367, 3.2818],\n",
      "        [3.4598, 3.5241, 3.4522, 3.5190, 3.6013],\n",
      "        [3.1744, 3.2146, 3.2604, 3.2541, 3.4444],\n",
      "        [3.2818, 3.1102, 3.4102, 3.3509, 3.3435],\n",
      "        [3.1115, 3.2245, 3.2165, 3.1237, 3.2170],\n",
      "        [3.1404, 3.1606, 3.3584, 3.1171, 3.4128],\n",
      "        [3.2089, 3.1629, 3.3292, 3.3335, 3.3946],\n",
      "        [3.1935, 3.1423, 3.3011, 3.3046, 3.3764],\n",
      "        [3.1669, 3.2508, 3.1300, 3.2704, 3.2537],\n",
      "        [3.0310, 3.2454, 3.2289, 3.1622, 3.1975],\n",
      "        [3.1662, 3.1835, 3.2524, 3.2725, 3.2779],\n",
      "        [3.5692, 3.6810, 3.4567, 3.4670, 3.4966],\n",
      "        [3.0888, 3.1862, 3.1113, 3.1724, 3.1868],\n",
      "        [3.5268, 3.4997, 3.4533, 3.6047, 3.5887],\n",
      "        [3.0626, 3.1151, 3.1972, 3.1860, 3.1372],\n",
      "        [3.3418, 3.3173, 3.3890, 3.4504, 3.2396],\n",
      "        [3.1871, 3.0985, 3.2241, 3.1736, 3.1847],\n",
      "        [3.6263, 3.7387, 3.4920, 3.5236, 3.5171],\n",
      "        [3.1751, 3.1756, 3.2401, 3.2433, 3.3214],\n",
      "        [3.1893, 3.2741, 3.2664, 3.2614, 3.3027],\n",
      "        [3.1869, 3.1754, 3.3051, 3.2994, 3.3095],\n",
      "        [3.0053, 3.1370, 3.0995, 3.0885, 3.1432],\n",
      "        [3.1621, 3.2668, 3.2177, 3.3162, 3.3258],\n",
      "        [3.1605, 3.3647, 3.3133, 3.2052, 3.3668],\n",
      "        [3.1805, 3.4902, 3.2625, 3.4620, 3.4197],\n",
      "        [3.3707, 3.3772, 3.3593, 3.4792, 3.5481],\n",
      "        [3.2920, 3.3650, 3.4109, 3.3715, 3.3897],\n",
      "        [3.4880, 3.5430, 3.4562, 3.6922, 3.5529],\n",
      "        [3.3363, 3.3398, 3.3587, 3.4352, 3.5237],\n",
      "        [3.2890, 3.4474, 3.4108, 3.4177, 3.3668],\n",
      "        [3.1815, 3.1640, 3.3177, 3.3008, 3.3024],\n",
      "        [3.0599, 3.1742, 3.2284, 3.2030, 3.1710],\n",
      "        [3.2077, 3.3340, 3.2175, 3.2337, 3.3316],\n",
      "        [3.1518, 3.2405, 3.1242, 3.2317, 3.2396],\n",
      "        [3.3744, 3.2353, 3.2792, 3.3421, 3.3868],\n",
      "        [3.2003, 3.1600, 3.2786, 3.2827, 3.3367],\n",
      "        [3.2899, 3.2387, 3.2889, 3.2068, 3.1678],\n",
      "        [3.2049, 3.5098, 3.3286, 3.4354, 3.4831],\n",
      "        [3.1342, 3.1781, 3.2068, 3.1888, 3.2317],\n",
      "        [3.1347, 3.0879, 3.2328, 3.2132, 3.2038],\n",
      "        [3.2965, 3.3658, 3.3195, 3.3557, 3.4342],\n",
      "        [3.2414, 3.2488, 3.2458, 3.3603, 3.4198],\n",
      "        [3.1389, 3.2294, 3.1169, 3.2278, 3.2259],\n",
      "        [3.0111, 3.1493, 3.1193, 3.1449, 3.1565],\n",
      "        [3.3018, 3.1584, 3.1677, 3.2144, 3.3461],\n",
      "        [3.1933, 3.2801, 3.1299, 3.3118, 3.2658],\n",
      "        [3.1209, 3.2211, 3.1234, 3.1980, 3.2238],\n",
      "        [3.2231, 3.4556, 3.4240, 3.4190, 3.4792],\n",
      "        [3.1706, 3.2505, 3.2789, 3.2617, 3.1847],\n",
      "        [3.3852, 3.3290, 3.4089, 3.4311, 3.5899],\n",
      "        [3.2855, 3.4063, 3.2576, 3.3568, 3.3666],\n",
      "        [3.2669, 3.2136, 3.2793, 3.2148, 3.1394],\n",
      "        [3.2183, 3.2503, 3.2549, 3.3127, 3.3691],\n",
      "        [3.1187, 3.2108, 3.1107, 3.2030, 3.2012],\n",
      "        [2.9640, 3.0893, 3.0784, 3.0345, 3.0964],\n",
      "        [3.0381, 3.1349, 3.1798, 3.1544, 3.1566],\n",
      "        [3.3183, 3.3230, 3.4140, 3.3486, 3.2284],\n",
      "        [3.1404, 3.1606, 3.3584, 3.1171, 3.4128]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3301, 3.3443, 3.3988, 3.4468, 3.2857],\n",
      "        [3.4529, 3.4724, 3.3771, 3.5030, 3.5772],\n",
      "        [3.2176, 3.3139, 3.1323, 3.2326, 3.2888],\n",
      "        [3.0409, 3.2418, 3.2270, 3.1720, 3.2019],\n",
      "        [3.1777, 3.3266, 3.1897, 3.4016, 3.2205],\n",
      "        [3.2531, 3.2754, 3.2890, 3.3173, 3.3146],\n",
      "        [3.1852, 3.2703, 3.2830, 3.2632, 3.1946],\n",
      "        [3.0297, 3.0111, 3.1226, 3.2007, 3.1311],\n",
      "        [3.1646, 3.2742, 3.2647, 3.2271, 3.1919],\n",
      "        [3.3600, 3.2966, 3.3214, 3.2977, 3.2602],\n",
      "        [3.0783, 3.0970, 3.1697, 3.1854, 3.1604],\n",
      "        [3.3004, 3.4511, 3.4029, 3.4259, 3.5126],\n",
      "        [3.2686, 3.2166, 3.2825, 3.2181, 3.1421],\n",
      "        [3.5836, 3.7803, 3.3708, 3.4963, 3.3910],\n",
      "        [2.9940, 3.1254, 3.0997, 3.0708, 3.1322],\n",
      "        [3.1974, 3.2818, 3.1303, 3.3306, 3.2723],\n",
      "        [2.9944, 3.1306, 3.0986, 3.0721, 3.1348],\n",
      "        [3.5106, 3.5474, 3.5025, 3.7142, 3.5549],\n",
      "        [3.1753, 3.1960, 3.2629, 3.2811, 3.2859],\n",
      "        [3.1537, 3.4415, 3.2999, 3.3632, 3.4560],\n",
      "        [3.2249, 3.2144, 3.3507, 3.3261, 3.3461],\n",
      "        [3.3858, 3.4628, 3.3911, 3.4404, 3.5335],\n",
      "        [3.3541, 3.3540, 3.3642, 3.3966, 3.5110],\n",
      "        [3.2348, 3.4342, 3.2770, 3.4600, 3.3871],\n",
      "        [3.3731, 3.4542, 3.4598, 3.4125, 3.2930],\n",
      "        [3.4271, 3.3982, 3.4507, 3.5183, 3.4529],\n",
      "        [3.5058, 3.3797, 3.4630, 3.6317, 3.5440],\n",
      "        [3.0818, 3.2849, 3.1029, 3.2413, 3.1481],\n",
      "        [3.1284, 3.3695, 3.2430, 3.2130, 3.1678],\n",
      "        [3.3951, 3.4977, 3.4632, 3.5230, 3.5454],\n",
      "        [3.1716, 3.1213, 3.2586, 3.2704, 3.3602],\n",
      "        [3.1758, 3.1365, 3.2720, 3.2445, 3.2559],\n",
      "        [3.1834, 3.2248, 3.2716, 3.2548, 3.4686],\n",
      "        [3.3841, 3.5361, 3.3976, 3.5618, 3.5190],\n",
      "        [3.0974, 3.2134, 3.3096, 3.2623, 3.3511],\n",
      "        [3.0459, 3.3909, 3.3005, 3.2259, 3.4316],\n",
      "        [3.1790, 3.1049, 3.2284, 3.1819, 3.1929],\n",
      "        [3.4282, 3.3823, 3.3409, 3.4415, 3.4422],\n",
      "        [3.1545, 3.3916, 3.2789, 3.2616, 3.1937],\n",
      "        [3.1876, 3.1318, 3.2829, 3.2722, 3.3424],\n",
      "        [3.0949, 3.1285, 3.0608, 3.2322, 3.1504],\n",
      "        [3.5983, 3.7438, 3.3810, 3.4737, 3.4127],\n",
      "        [3.1604, 3.1186, 3.2584, 3.2415, 3.2302],\n",
      "        [3.3314, 3.4560, 3.2736, 3.3370, 3.4173],\n",
      "        [3.1769, 3.2161, 3.1716, 3.2892, 3.3803],\n",
      "        [3.0426, 3.2377, 3.2297, 3.1789, 3.2091],\n",
      "        [3.3748, 3.4219, 3.4302, 3.4425, 3.5961],\n",
      "        [3.1567, 3.2426, 3.2605, 3.3568, 3.2441],\n",
      "        [3.1752, 3.1470, 3.2650, 3.2562, 3.2516],\n",
      "        [3.0872, 3.1051, 3.0528, 3.2259, 3.0921],\n",
      "        [3.0216, 3.1145, 3.0577, 3.1882, 3.0798],\n",
      "        [3.1541, 3.2281, 3.1578, 3.2506, 3.2627],\n",
      "        [3.2613, 3.3442, 3.3814, 3.4308, 3.4229],\n",
      "        [3.3326, 3.2145, 3.2562, 3.5938, 3.4468],\n",
      "        [3.0273, 3.1508, 3.1116, 3.1131, 3.1753],\n",
      "        [3.4193, 3.4661, 3.3545, 3.4635, 3.5716],\n",
      "        [3.0101, 3.1477, 3.1098, 3.0991, 3.1529],\n",
      "        [3.5132, 3.5907, 3.5056, 3.7553, 3.6426],\n",
      "        [3.0448, 3.1212, 3.1811, 3.1629, 3.1559],\n",
      "        [3.2413, 3.4026, 3.3069, 3.2963, 3.3859],\n",
      "        [3.2149, 3.1989, 3.3419, 3.3332, 3.3435],\n",
      "        [3.5403, 3.3378, 3.4683, 3.9170, 3.7906],\n",
      "        [3.0982, 3.1688, 3.2439, 3.2332, 3.1665],\n",
      "        [3.2943, 3.3293, 3.2232, 3.4011, 3.3963]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3156, 3.5784, 3.4389, 3.4772, 3.5781],\n",
      "        [3.1477, 3.3698, 3.3638, 3.2359, 3.5141],\n",
      "        [3.1665, 3.1392, 3.2648, 3.2559, 3.2493],\n",
      "        [3.1845, 3.2070, 3.3281, 3.2225, 3.4252],\n",
      "        [3.2819, 3.4882, 3.4234, 3.4213, 3.5805],\n",
      "        [3.1308, 3.3781, 3.2277, 3.1981, 3.1858],\n",
      "        [3.1799, 3.2464, 3.1719, 3.2662, 3.2835],\n",
      "        [3.0870, 3.3344, 3.1532, 3.0335, 3.2890],\n",
      "        [2.9861, 3.0338, 3.0928, 3.0644, 3.0887],\n",
      "        [3.8015, 3.9324, 3.5777, 3.6591, 3.5741],\n",
      "        [3.3132, 3.4103, 3.3028, 3.3992, 3.3672],\n",
      "        [3.1635, 3.2330, 3.1573, 3.2767, 3.2308],\n",
      "        [3.1006, 3.1820, 3.2578, 3.2359, 3.1724],\n",
      "        [3.0309, 3.2347, 3.2247, 3.1660, 3.1899],\n",
      "        [3.0929, 3.2964, 3.2538, 3.2577, 3.4139],\n",
      "        [3.0722, 3.3596, 3.2454, 3.0868, 3.3597],\n",
      "        [3.0963, 3.0644, 3.1535, 3.1925, 3.1575],\n",
      "        [3.2450, 3.2419, 3.2695, 3.3666, 3.3145],\n",
      "        [3.3353, 3.4671, 3.4117, 3.4311, 3.3919],\n",
      "        [3.0505, 3.3945, 3.3046, 3.2297, 3.4352],\n",
      "        [3.3409, 3.4321, 3.2678, 3.3606, 3.4347],\n",
      "        [3.3038, 3.3934, 3.3265, 3.4232, 3.5395],\n",
      "        [3.3990, 3.2144, 3.3012, 3.6700, 3.5192],\n",
      "        [3.3014, 3.2649, 3.2481, 3.4848, 3.4047],\n",
      "        [3.0794, 3.2855, 3.4072, 3.2629, 3.3331],\n",
      "        [3.1804, 3.1400, 3.2760, 3.2483, 3.2594],\n",
      "        [3.0396, 3.1761, 3.2014, 3.1618, 3.1697],\n",
      "        [3.2314, 3.4303, 3.2026, 3.3365, 3.3081],\n",
      "        [3.3846, 3.4009, 3.4723, 3.5660, 3.3889],\n",
      "        [3.1783, 3.1502, 3.2708, 3.2537, 3.2536],\n",
      "        [3.0729, 3.1054, 3.1793, 3.1794, 3.1629],\n",
      "        [3.1457, 3.1533, 3.1866, 3.1991, 3.2926],\n",
      "        [3.1675, 3.2098, 3.1795, 3.1987, 3.2465],\n",
      "        [3.1043, 3.1731, 3.2697, 3.2974, 3.2948],\n",
      "        [3.2941, 3.2193, 3.3300, 3.2367, 3.3117],\n",
      "        [3.2759, 3.3127, 3.3492, 3.3358, 3.3646],\n",
      "        [3.3994, 3.5052, 3.4653, 3.5246, 3.5438],\n",
      "        [3.1472, 3.2186, 3.2584, 3.2738, 3.2154],\n",
      "        [3.0744, 3.0962, 3.1725, 3.1908, 3.1611],\n",
      "        [3.4121, 3.3607, 3.4603, 3.4922, 3.3231],\n",
      "        [3.1819, 3.4712, 3.3112, 3.4103, 3.4642],\n",
      "        [3.1908, 3.3139, 3.3061, 3.2974, 3.2683],\n",
      "        [3.1953, 3.1712, 3.2761, 3.2672, 3.2812],\n",
      "        [3.0598, 3.1415, 3.3012, 3.1874, 3.2857],\n",
      "        [3.1406, 3.2217, 3.2572, 3.2760, 3.2187],\n",
      "        [3.5388, 3.6356, 3.3169, 3.4509, 3.4040],\n",
      "        [3.2882, 3.2303, 3.3208, 3.3446, 3.3000],\n",
      "        [2.9022, 3.0438, 3.1265, 3.0578, 3.1434],\n",
      "        [3.0775, 3.2871, 3.4072, 3.2614, 3.3367],\n",
      "        [3.2110, 3.1133, 3.2414, 3.1777, 3.1969],\n",
      "        [3.3093, 3.3607, 3.2548, 3.3402, 3.4832],\n",
      "        [2.8975, 3.0365, 3.1180, 3.0553, 3.1314],\n",
      "        [3.2521, 3.1970, 3.3637, 3.3814, 3.3526],\n",
      "        [3.1876, 3.1319, 3.2888, 3.2857, 3.3723],\n",
      "        [3.0420, 3.2388, 3.2322, 3.1806, 3.2076],\n",
      "        [3.0147, 3.1367, 3.0040, 3.1656, 3.0964],\n",
      "        [3.2761, 3.2798, 3.1467, 3.3926, 3.4201],\n",
      "        [2.9864, 3.1163, 3.0935, 3.0623, 3.1271],\n",
      "        [3.0813, 3.1646, 3.2364, 3.2041, 3.1835],\n",
      "        [3.4914, 3.2579, 3.3374, 3.7813, 3.6171],\n",
      "        [3.5456, 3.5862, 3.5273, 3.7598, 3.6278],\n",
      "        [3.2457, 3.4766, 3.3604, 3.4006, 3.4979],\n",
      "        [2.9702, 3.0955, 3.0851, 3.0414, 3.1023],\n",
      "        [3.5129, 3.3073, 3.4451, 3.8980, 3.7851]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2014, 3.2800, 3.2675, 3.2952, 3.3274],\n",
      "        [3.3247, 3.3852, 3.2900, 3.4295, 3.3947],\n",
      "        [3.2396, 3.3914, 3.3034, 3.3030, 3.3840],\n",
      "        [3.5244, 3.6106, 3.5144, 3.7790, 3.6595],\n",
      "        [3.3263, 3.4040, 3.4214, 3.4229, 3.4458],\n",
      "        [3.1337, 3.3506, 3.2766, 3.2945, 3.4406],\n",
      "        [3.0762, 3.3629, 3.2492, 3.0903, 3.3629],\n",
      "        [3.1903, 3.2674, 3.2916, 3.2761, 3.1936],\n",
      "        [3.3416, 3.3517, 3.4069, 3.4481, 3.2922],\n",
      "        [3.1347, 3.3814, 3.2315, 3.2014, 3.1890],\n",
      "        [2.9928, 3.1299, 3.1432, 3.1544, 3.1764],\n",
      "        [3.5081, 3.6013, 3.3059, 3.4201, 3.4023],\n",
      "        [3.4744, 3.4876, 3.4017, 3.5205, 3.5954],\n",
      "        [3.2073, 3.2101, 3.2820, 3.1840, 3.1220],\n",
      "        [3.1873, 3.1888, 3.2620, 3.2792, 3.2839],\n",
      "        [3.1998, 3.2466, 3.1755, 3.3359, 3.2818],\n",
      "        [3.3082, 3.3666, 3.2568, 3.3391, 3.4919],\n",
      "        [3.3396, 3.3732, 3.3947, 3.4135, 3.5140],\n",
      "        [3.2406, 3.2215, 3.3657, 3.3378, 3.3497],\n",
      "        [3.0991, 3.1957, 3.1218, 3.1827, 3.1960],\n",
      "        [3.1690, 3.1254, 3.2660, 3.2487, 3.2369],\n",
      "        [3.4699, 3.2737, 3.3331, 3.7508, 3.5900],\n",
      "        [3.3438, 3.3359, 3.4015, 3.4485, 3.2677],\n",
      "        [3.2782, 3.2120, 3.3173, 3.2460, 3.2598],\n",
      "        [3.2911, 3.3146, 3.3226, 3.3073, 3.1423],\n",
      "        [3.1170, 3.2367, 3.2201, 3.3485, 3.1927],\n",
      "        [3.1500, 3.2969, 3.2782, 3.2687, 3.3372],\n",
      "        [3.3095, 3.4581, 3.4111, 3.4334, 3.5195],\n",
      "        [3.2588, 3.4428, 3.3066, 3.4775, 3.3989],\n",
      "        [3.1795, 3.2723, 3.2771, 3.2450, 3.2050],\n",
      "        [3.1786, 3.3202, 3.3163, 3.2883, 3.4360],\n",
      "        [3.2469, 3.5444, 3.3511, 3.4896, 3.5011],\n",
      "        [2.9406, 3.0739, 3.1513, 3.0786, 3.1648],\n",
      "        [3.1766, 3.3010, 3.2153, 3.3080, 3.3506],\n",
      "        [3.1640, 3.2551, 3.1403, 3.2642, 3.2491],\n",
      "        [3.4410, 3.4825, 3.3777, 3.4945, 3.5621],\n",
      "        [3.1243, 3.1492, 3.2448, 3.2502, 3.2649],\n",
      "        [3.2940, 3.3263, 3.2593, 3.3399, 3.3175],\n",
      "        [3.2405, 3.4663, 3.4417, 3.4394, 3.4887],\n",
      "        [3.1738, 3.2107, 3.3866, 3.3845, 3.3440],\n",
      "        [3.2878, 3.2781, 3.2992, 3.3449, 3.3143],\n",
      "        [3.1131, 3.4323, 3.2962, 3.3129, 3.4531],\n",
      "        [3.0968, 3.2997, 3.2575, 3.2611, 3.4171],\n",
      "        [3.3125, 3.2804, 3.3440, 3.3138, 3.2258],\n",
      "        [3.3901, 3.3807, 3.4037, 3.4402, 3.5834],\n",
      "        [3.2113, 3.1845, 3.3256, 3.3288, 3.3397],\n",
      "        [3.2800, 3.2832, 3.1505, 3.3960, 3.4233],\n",
      "        [3.1362, 3.2240, 3.1184, 3.2273, 3.2130],\n",
      "        [3.1012, 3.2108, 3.2916, 3.2413, 3.1928],\n",
      "        [3.1780, 3.1876, 3.2604, 3.2756, 3.2802],\n",
      "        [3.2900, 3.5107, 3.3491, 3.4234, 3.4282],\n",
      "        [3.4248, 3.3691, 3.4266, 3.5324, 3.4553],\n",
      "        [3.3095, 3.3246, 3.4296, 3.3500, 3.3011],\n",
      "        [3.1747, 3.3050, 3.2873, 3.2888, 3.2942],\n",
      "        [3.0359, 3.1573, 3.1189, 3.1202, 3.1818],\n",
      "        [3.5234, 3.4795, 3.4261, 3.5631, 3.5505],\n",
      "        [3.1715, 3.1790, 3.2534, 3.2680, 3.2743],\n",
      "        [3.3858, 3.1569, 3.3321, 3.5641, 3.5789],\n",
      "        [3.2202, 3.3754, 3.2935, 3.4344, 3.2984],\n",
      "        [3.0998, 3.2341, 3.3229, 3.2884, 3.3659],\n",
      "        [3.0426, 3.1763, 3.2023, 3.1669, 3.1730],\n",
      "        [3.2632, 3.4403, 3.3447, 3.3133, 3.4076],\n",
      "        [3.1315, 3.1951, 3.0513, 3.2987, 3.1261],\n",
      "        [3.2771, 3.1057, 3.3955, 3.3542, 3.3440]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.1857, 3.1237, 3.2639, 3.2825, 3.3682],\n",
      "        [3.4172, 3.3633, 3.4776, 3.4803, 3.3097],\n",
      "        [3.1526, 3.2340, 3.3308, 3.3475, 3.4316],\n",
      "        [3.1542, 3.2963, 3.1805, 3.3640, 3.2168],\n",
      "        [3.1882, 3.4126, 3.2173, 3.4173, 3.3582],\n",
      "        [3.3253, 3.4471, 3.4271, 3.4571, 3.3966],\n",
      "        [3.0937, 3.0638, 3.1557, 3.2074, 3.1435],\n",
      "        [3.3390, 3.3798, 3.3880, 3.3794, 3.4894],\n",
      "        [3.1993, 3.2068, 3.3021, 3.3142, 3.3180],\n",
      "        [3.2096, 3.1794, 3.2855, 3.2527, 3.3249],\n",
      "        [3.3119, 3.4007, 3.3342, 3.4299, 3.5469],\n",
      "        [3.1882, 3.1471, 3.2831, 3.2549, 3.2664],\n",
      "        [3.1235, 3.1652, 3.2361, 3.2517, 3.1830],\n",
      "        [3.2572, 3.2294, 3.3717, 3.3556, 3.3613],\n",
      "        [3.2130, 3.4117, 3.3595, 3.3927, 3.4926],\n",
      "        [3.3717, 3.2300, 3.2863, 3.3321, 3.3779],\n",
      "        [3.3618, 3.3138, 3.4499, 3.3805, 3.2336],\n",
      "        [3.3154, 3.2849, 3.3514, 3.3107, 3.2312],\n",
      "        [3.1404, 3.1791, 3.2170, 3.1874, 3.2408],\n",
      "        [3.3404, 3.4084, 3.3204, 3.3364, 3.3742],\n",
      "        [3.1143, 3.1685, 3.2291, 3.1397, 3.3403],\n",
      "        [3.3313, 3.2747, 3.2658, 3.5430, 3.4498],\n",
      "        [3.0660, 3.2477, 3.3372, 3.2100, 3.3031],\n",
      "        [3.3340, 3.4462, 3.2987, 3.5312, 3.4476],\n",
      "        [3.0740, 3.2814, 3.3975, 3.2437, 3.3316],\n",
      "        [3.3977, 3.4438, 3.4410, 3.4557, 3.6254],\n",
      "        [3.3860, 3.3601, 3.4214, 3.5306, 3.4156],\n",
      "        [3.1028, 3.1992, 3.1251, 3.1857, 3.1997],\n",
      "        [3.1996, 3.2197, 3.2817, 3.3080, 3.3179],\n",
      "        [3.3270, 3.5079, 3.3357, 3.4289, 3.4261],\n",
      "        [3.3436, 3.2617, 3.3779, 3.4252, 3.3530],\n",
      "        [3.3317, 3.4440, 3.2978, 3.5301, 3.4443],\n",
      "        [3.1085, 3.4410, 3.3705, 3.2999, 3.4681],\n",
      "        [3.1552, 3.1747, 3.3734, 3.1313, 3.4266],\n",
      "        [3.3041, 3.4347, 3.4098, 3.4429, 3.4637],\n",
      "        [3.5646, 3.5855, 3.4939, 3.8056, 3.6584],\n",
      "        [3.5155, 3.5703, 3.5035, 3.5699, 3.6521],\n",
      "        [3.5206, 3.2561, 3.3449, 3.8232, 3.6421],\n",
      "        [3.0193, 3.1499, 3.1130, 3.1018, 3.1558],\n",
      "        [2.9836, 3.1084, 3.0919, 3.0631, 3.1268],\n",
      "        [3.1367, 3.1670, 3.2292, 3.2649, 3.1932],\n",
      "        [3.1324, 3.2320, 3.1308, 3.2261, 3.2258],\n",
      "        [3.1718, 3.2429, 3.1675, 3.2602, 3.2740],\n",
      "        [3.0533, 3.1961, 3.2184, 3.1845, 3.1980],\n",
      "        [3.1702, 3.3895, 3.3456, 3.2133, 3.3870],\n",
      "        [3.1611, 3.3068, 3.2876, 3.2845, 3.3123],\n",
      "        [3.3430, 3.3552, 3.4108, 3.4572, 3.2966],\n",
      "        [3.4615, 3.4679, 3.4095, 3.6320, 3.5352],\n",
      "        [3.1547, 3.3469, 3.2459, 3.2475, 3.2386],\n",
      "        [3.1802, 3.2635, 3.1407, 3.2634, 3.2622],\n",
      "        [3.1905, 3.1603, 3.2820, 3.2650, 3.2673],\n",
      "        [3.0843, 3.0966, 3.1735, 3.1889, 3.1619],\n",
      "        [3.2762, 3.2631, 3.2744, 3.4202, 3.3466],\n",
      "        [3.0657, 3.1388, 3.1984, 3.1778, 3.1736],\n",
      "        [3.4069, 3.4124, 3.4956, 3.5894, 3.4067],\n",
      "        [3.5402, 3.4782, 3.4998, 3.6173, 3.6173],\n",
      "        [3.0894, 3.2398, 3.1133, 3.2407, 3.1937],\n",
      "        [3.2616, 3.5401, 3.2987, 3.5044, 3.4692],\n",
      "        [3.2469, 3.1643, 3.2776, 3.3018, 3.2801],\n",
      "        [3.2660, 3.3927, 3.3406, 3.3431, 3.2425],\n",
      "        [3.3046, 3.5277, 3.3668, 3.4381, 3.4455],\n",
      "        [3.1402, 3.2895, 3.4618, 3.2698, 3.4503],\n",
      "        [3.4778, 3.3640, 3.3564, 3.4483, 3.4541],\n",
      "        [3.3211, 3.4174, 3.3101, 3.4057, 3.3742]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.1880, 3.2731, 3.1382, 3.3019, 3.2610],\n",
      "        [3.2049, 3.1163, 3.2420, 3.1901, 3.2024],\n",
      "        [3.3676, 3.4865, 3.2870, 3.3631, 3.4232],\n",
      "        [3.2020, 3.5227, 3.4085, 3.2932, 3.3344],\n",
      "        [3.0792, 3.2113, 3.2595, 3.2198, 3.2042],\n",
      "        [3.3357, 3.4469, 3.2961, 3.5247, 3.4409],\n",
      "        [3.1909, 3.1694, 3.2721, 3.2686, 3.2791],\n",
      "        [3.0837, 3.3708, 3.2560, 3.0962, 3.3711],\n",
      "        [3.3764, 3.3523, 3.4374, 3.4430, 3.3089],\n",
      "        [3.4079, 3.3551, 3.4023, 3.4388, 3.6030],\n",
      "        [3.4575, 3.1565, 3.3336, 3.6756, 3.6518],\n",
      "        [3.3661, 3.1491, 3.1751, 3.2380, 3.3720],\n",
      "        [3.2550, 3.1584, 3.2638, 3.3119, 3.2414],\n",
      "        [3.5372, 3.3395, 3.4660, 3.9112, 3.8040],\n",
      "        [3.3348, 3.2951, 3.3405, 3.3928, 3.5456],\n",
      "        [3.1881, 3.1427, 3.2892, 3.1894, 3.3298],\n",
      "        [3.2688, 3.2966, 3.3071, 3.3650, 3.4162],\n",
      "        [3.6442, 3.7582, 3.5111, 3.5409, 3.5358],\n",
      "        [3.2479, 3.2172, 3.3778, 3.4493, 3.5262],\n",
      "        [3.3430, 3.4286, 3.3175, 3.4387, 3.4099],\n",
      "        [3.4936, 3.4519, 3.4177, 3.5253, 3.5505],\n",
      "        [3.1713, 3.2627, 3.1468, 3.2700, 3.2572],\n",
      "        [3.0945, 3.0796, 3.1642, 3.2066, 3.1574],\n",
      "        [3.3595, 3.4976, 3.4472, 3.4486, 3.4167],\n",
      "        [3.3843, 3.4614, 3.4657, 3.4209, 3.3049],\n",
      "        [3.4734, 3.4496, 3.4412, 3.6293, 3.4979],\n",
      "        [3.3241, 3.4844, 3.4294, 3.4584, 3.5439],\n",
      "        [2.9575, 3.0988, 3.1535, 3.0998, 3.1589],\n",
      "        [3.1690, 3.2284, 3.2509, 3.2838, 3.3972],\n",
      "        [3.3493, 3.5013, 3.3550, 3.4307, 3.4376],\n",
      "        [3.1531, 3.2261, 3.3732, 3.2884, 3.3731],\n",
      "        [3.3718, 3.3693, 3.3794, 3.4104, 3.5270],\n",
      "        [3.0775, 3.1889, 3.2551, 3.2164, 3.1977],\n",
      "        [3.4891, 3.4100, 3.4333, 3.5151, 3.5051],\n",
      "        [3.2024, 3.1646, 3.2925, 3.2259, 3.3289],\n",
      "        [3.1637, 3.1640, 3.2802, 3.2861, 3.3625],\n",
      "        [3.1807, 3.3111, 3.2968, 3.2896, 3.3262],\n",
      "        [3.1384, 3.2380, 3.1320, 3.2344, 3.2328],\n",
      "        [3.1873, 3.3334, 3.2440, 3.3003, 3.3595],\n",
      "        [3.2336, 3.3286, 3.1471, 3.2455, 3.3038],\n",
      "        [3.0498, 3.2377, 3.2323, 3.1755, 3.1995],\n",
      "        [3.4322, 3.3776, 3.4341, 3.5384, 3.4636],\n",
      "        [3.1791, 3.1870, 3.2602, 3.2739, 3.2826],\n",
      "        [3.0522, 3.2850, 3.0805, 3.2530, 3.1418],\n",
      "        [3.2054, 3.1905, 3.2962, 3.2849, 3.3304],\n",
      "        [3.3666, 3.3961, 3.3862, 3.4431, 3.5206],\n",
      "        [3.3643, 3.4770, 3.4270, 3.4418, 3.4047],\n",
      "        [3.0353, 3.0782, 3.1648, 3.1486, 3.1003],\n",
      "        [3.4833, 3.5809, 3.3054, 3.4085, 3.4130],\n",
      "        [3.2499, 3.4357, 3.3245, 3.3881, 3.4930],\n",
      "        [3.1146, 3.1669, 3.2610, 3.2964, 3.2865],\n",
      "        [3.3134, 3.3408, 3.2190, 3.4121, 3.4352],\n",
      "        [3.3630, 3.4432, 3.2944, 3.3775, 3.4684],\n",
      "        [3.4839, 3.3743, 3.4767, 3.6230, 3.5031],\n",
      "        [3.1687, 3.2698, 3.2338, 3.3401, 3.3398],\n",
      "        [3.0736, 3.2136, 3.1415, 3.1681, 3.2110],\n",
      "        [3.1849, 3.2077, 3.3479, 3.2115, 3.4295],\n",
      "        [3.0987, 3.0789, 3.1661, 3.2092, 3.1647],\n",
      "        [3.0720, 3.1484, 3.2005, 3.1844, 3.1908],\n",
      "        [3.1949, 3.2803, 3.1404, 3.3150, 3.2727],\n",
      "        [3.3834, 3.4502, 3.3121, 3.3933, 3.4969],\n",
      "        [3.3011, 3.2615, 3.3454, 3.2898, 3.2506],\n",
      "        [3.2980, 3.3270, 3.2562, 3.3392, 3.5085],\n",
      "        [3.0532, 3.0956, 3.1650, 3.1552, 3.1228]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.1935, 3.1618, 3.2803, 3.2739, 3.2644],\n",
      "        [3.2030, 3.1833, 3.2837, 3.2771, 3.2880],\n",
      "        [2.9608, 3.1040, 3.1564, 3.1023, 3.1627],\n",
      "        [3.2765, 3.2896, 3.3015, 3.3407, 3.3224],\n",
      "        [3.0576, 3.2964, 3.0874, 3.2437, 3.1448],\n",
      "        [3.3202, 3.4091, 3.2829, 3.3863, 3.3977],\n",
      "        [3.1864, 3.1796, 3.2575, 3.2667, 3.2815],\n",
      "        [3.1339, 3.2330, 3.1369, 3.2193, 3.2401],\n",
      "        [3.2061, 3.1573, 3.3104, 3.3116, 3.3905],\n",
      "        [3.3501, 3.4224, 3.4256, 3.5478, 3.3895],\n",
      "        [3.3471, 3.4688, 3.3345, 3.4352, 3.4254],\n",
      "        [3.2533, 3.4411, 3.3276, 3.3907, 3.4970],\n",
      "        [3.1296, 3.1223, 3.1999, 3.2279, 3.1744],\n",
      "        [3.1317, 3.2424, 3.1495, 3.2236, 3.2378],\n",
      "        [3.1721, 3.2623, 3.1444, 3.2773, 3.2617],\n",
      "        [3.1093, 3.0745, 3.1641, 3.2122, 3.1598],\n",
      "        [3.1752, 3.3044, 3.2196, 3.3080, 3.3542],\n",
      "        [3.2618, 3.2581, 3.2837, 3.3791, 3.3301],\n",
      "        [3.2245, 3.2482, 3.3008, 3.2165, 3.1419],\n",
      "        [3.2365, 3.3753, 3.2727, 3.3937, 3.3044],\n",
      "        [3.2817, 3.4410, 3.3301, 3.4938, 3.4087],\n",
      "        [3.1419, 3.2379, 3.1767, 3.2424, 3.2706],\n",
      "        [3.1857, 3.2773, 3.1493, 3.2890, 3.2720],\n",
      "        [3.4276, 3.2805, 3.3133, 3.3782, 3.4304],\n",
      "        [3.2603, 3.1759, 3.2944, 3.3116, 3.2952],\n",
      "        [3.3225, 3.2945, 3.3578, 3.3161, 3.2399],\n",
      "        [3.2744, 3.4537, 3.3548, 3.3219, 3.4205],\n",
      "        [3.2104, 3.3447, 3.1984, 3.4286, 3.2407],\n",
      "        [3.3738, 3.2313, 3.2854, 3.6501, 3.4897],\n",
      "        [3.2966, 3.3460, 3.3612, 3.4159, 3.4715],\n",
      "        [3.5406, 3.3452, 3.4693, 3.9139, 3.8082],\n",
      "        [3.0786, 3.2014, 3.1370, 3.1597, 3.2086],\n",
      "        [3.2108, 3.3202, 3.3257, 3.3053, 3.2620],\n",
      "        [3.1895, 3.2139, 3.3500, 3.2127, 3.4447],\n",
      "        [3.0892, 3.1741, 3.2343, 3.2064, 3.1844],\n",
      "        [3.3241, 3.3364, 3.3242, 3.4355, 3.5028],\n",
      "        [3.3418, 3.2795, 3.3129, 3.2470, 3.2318],\n",
      "        [3.1812, 3.1557, 3.2781, 3.2678, 3.2646],\n",
      "        [3.3902, 3.4206, 3.4333, 3.4362, 3.6033],\n",
      "        [3.3133, 3.3881, 3.4318, 3.3906, 3.4116],\n",
      "        [3.3411, 3.4559, 3.3052, 3.5368, 3.4564],\n",
      "        [3.1670, 3.1694, 3.2833, 3.2886, 3.3665],\n",
      "        [3.3306, 3.1923, 3.2006, 3.2470, 3.3779],\n",
      "        [3.0521, 3.2677, 3.2487, 3.1812, 3.2186],\n",
      "        [3.1016, 3.0698, 3.1563, 3.2043, 3.1550],\n",
      "        [3.2832, 3.2726, 3.2806, 3.4256, 3.3551],\n",
      "        [3.0602, 3.2611, 3.2437, 3.1877, 3.2203],\n",
      "        [3.0976, 3.2847, 3.0960, 3.2419, 3.1571],\n",
      "        [3.0304, 3.1590, 3.1168, 3.1090, 3.1628],\n",
      "        [3.0755, 3.2091, 3.2580, 3.2078, 3.2110],\n",
      "        [3.2607, 3.4335, 3.3208, 3.3893, 3.4929],\n",
      "        [3.2715, 3.3378, 3.4497, 3.3855, 3.4381],\n",
      "        [3.3203, 3.1308, 3.1899, 3.2649, 3.3158],\n",
      "        [3.1747, 3.2686, 3.2731, 3.3728, 3.2652],\n",
      "        [3.1886, 3.1950, 3.2667, 3.2790, 3.2892],\n",
      "        [3.2159, 3.1998, 3.3188, 3.2940, 3.3359],\n",
      "        [3.7190, 3.8701, 3.5240, 3.6166, 3.5121],\n",
      "        [3.0386, 3.0832, 3.1676, 3.1511, 3.1042],\n",
      "        [3.1820, 3.1309, 3.2954, 3.1622, 3.3377],\n",
      "        [3.5367, 3.3267, 3.4635, 3.9137, 3.8072],\n",
      "        [3.0959, 3.2267, 3.2082, 3.3249, 3.1761],\n",
      "        [3.3833, 3.2443, 3.3049, 3.6001, 3.4831],\n",
      "        [3.2114, 3.2135, 3.3172, 3.3246, 3.3283],\n",
      "        [3.3861, 3.3442, 3.4690, 3.4288, 3.2855]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.0088, 3.1403, 3.1152, 3.0813, 3.1517],\n",
      "        [3.3038, 3.2306, 3.3407, 3.2513, 3.3193],\n",
      "        [3.0988, 3.2180, 3.1419, 3.1821, 3.2200],\n",
      "        [3.2012, 3.1811, 3.2850, 3.2962, 3.3593],\n",
      "        [3.2523, 3.3907, 3.2950, 3.3940, 3.3207],\n",
      "        [3.2634, 3.4787, 3.3593, 3.4069, 3.5119],\n",
      "        [3.2101, 3.2133, 3.2729, 3.2714, 3.3569],\n",
      "        [3.0921, 3.1170, 3.1893, 3.2055, 3.1798],\n",
      "        [3.3777, 3.3562, 3.5562, 3.3386, 3.3148],\n",
      "        [3.1398, 3.1764, 3.2616, 3.2846, 3.2949],\n",
      "        [3.3390, 3.4297, 3.4184, 3.4478, 3.4249],\n",
      "        [3.3399, 3.4159, 3.3277, 3.2955, 3.3772],\n",
      "        [3.1505, 3.1748, 3.2265, 3.2858, 3.2025],\n",
      "        [3.2577, 3.4597, 3.2986, 3.4790, 3.4101],\n",
      "        [3.2068, 3.1733, 3.2971, 3.2280, 3.3376],\n",
      "        [3.1908, 3.4123, 3.3012, 3.2848, 3.2086],\n",
      "        [3.2081, 3.2282, 3.3750, 3.4163, 3.4983],\n",
      "        [3.3421, 3.4588, 3.3081, 3.5388, 3.4569],\n",
      "        [3.1740, 3.1835, 3.2222, 3.2292, 3.3182],\n",
      "        [3.4520, 3.3373, 3.4599, 3.5893, 3.4695],\n",
      "        [3.3062, 3.3246, 3.2005, 3.4283, 3.4522],\n",
      "        [3.2101, 3.2710, 3.1922, 3.3588, 3.3075],\n",
      "        [3.3197, 3.3513, 3.2260, 3.4177, 3.4429],\n",
      "        [3.3150, 3.4689, 3.4198, 3.4468, 3.5098],\n",
      "        [3.3196, 3.2864, 3.2654, 3.5001, 3.4240],\n",
      "        [3.5439, 3.3504, 3.4732, 3.9173, 3.8120],\n",
      "        [3.3023, 3.4759, 3.4318, 3.4422, 3.3806],\n",
      "        [3.5151, 3.4275, 3.4864, 3.5620, 3.5645],\n",
      "        [3.2331, 3.4043, 3.3037, 3.3057, 3.3950],\n",
      "        [3.2996, 3.2509, 3.3432, 3.2664, 3.2664],\n",
      "        [3.1331, 3.1920, 3.2266, 3.1925, 3.2289],\n",
      "        [3.1437, 3.2045, 3.1661, 3.3084, 3.2502],\n",
      "        [3.2103, 3.1571, 3.3041, 3.2912, 3.3652],\n",
      "        [3.2761, 3.4728, 3.4290, 3.3775, 3.4535],\n",
      "        [3.3273, 3.5350, 3.4783, 3.4493, 3.5242],\n",
      "        [3.4541, 3.5069, 3.4617, 3.4855, 3.5464],\n",
      "        [3.1966, 3.1668, 3.2840, 3.2770, 3.2680],\n",
      "        [3.2054, 3.5198, 3.2878, 3.4841, 3.4456],\n",
      "        [3.5476, 3.6472, 3.3214, 3.4478, 3.4137],\n",
      "        [3.4740, 3.4228, 3.4699, 3.5671, 3.3808],\n",
      "        [3.2269, 3.3141, 3.1658, 3.3470, 3.3016],\n",
      "        [3.1516, 3.2195, 3.1799, 3.1974, 3.2171],\n",
      "        [3.1442, 3.2034, 3.0337, 3.3069, 3.1156],\n",
      "        [3.4774, 3.4201, 3.4801, 3.4954, 3.6744],\n",
      "        [3.1284, 3.2293, 3.1830, 3.2300, 3.2480],\n",
      "        [3.0898, 3.1367, 3.2061, 3.2124, 3.1910],\n",
      "        [3.0590, 3.2164, 3.3771, 3.1778, 3.3639],\n",
      "        [3.2569, 3.1790, 3.2876, 3.3104, 3.2921],\n",
      "        [3.2131, 3.5137, 3.4393, 3.3621, 3.3528],\n",
      "        [3.4058, 3.3555, 3.4074, 3.4287, 3.6006],\n",
      "        [3.1924, 3.2608, 3.3015, 3.3148, 3.2642],\n",
      "        [3.2191, 3.4457, 3.3652, 3.4159, 3.5070],\n",
      "        [3.2477, 3.4848, 3.4498, 3.4421, 3.5060],\n",
      "        [3.0942, 3.1106, 3.1833, 3.1972, 3.1737],\n",
      "        [3.3461, 3.3414, 3.3776, 3.3453, 3.2389],\n",
      "        [3.1321, 3.4457, 3.2986, 3.3438, 3.4492],\n",
      "        [3.0718, 3.1873, 3.1302, 3.1520, 3.1880],\n",
      "        [3.5040, 3.4578, 3.4208, 3.5499, 3.5647],\n",
      "        [3.1213, 3.1897, 3.2810, 3.3111, 3.3171],\n",
      "        [3.1968, 3.1959, 3.2724, 3.2795, 3.2967],\n",
      "        [3.2043, 3.2897, 3.1551, 3.3175, 3.2861],\n",
      "        [3.3066, 3.3247, 3.2010, 3.3478, 3.4396],\n",
      "        [3.4402, 3.4183, 3.3827, 3.4616, 3.4824],\n",
      "        [3.1748, 3.1327, 3.2240, 3.2506, 3.3734]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2576, 3.2456, 3.3829, 3.3526, 3.3692],\n",
      "        [3.4459, 3.3184, 3.4354, 3.5676, 3.4452],\n",
      "        [3.3989, 3.3812, 3.4362, 3.5418, 3.4311],\n",
      "        [3.4434, 3.4238, 3.3863, 3.4645, 3.4861],\n",
      "        [3.1937, 3.2697, 3.2333, 3.2551, 3.3000],\n",
      "        [3.4144, 3.4077, 3.5587, 3.3841, 3.3019],\n",
      "        [3.0815, 3.2190, 3.2652, 3.2135, 3.2177],\n",
      "        [3.4305, 3.5927, 3.4085, 3.5655, 3.6006],\n",
      "        [3.1496, 3.3234, 3.2774, 3.1768, 3.2299],\n",
      "        [3.4305, 3.3840, 3.4921, 3.4919, 3.3257],\n",
      "        [3.0747, 3.1922, 3.1336, 3.1547, 3.1911],\n",
      "        [3.1907, 3.1943, 3.2778, 3.2851, 3.2958],\n",
      "        [3.1038, 3.0948, 3.1742, 3.2147, 3.1681],\n",
      "        [3.2122, 3.1980, 3.2913, 3.2848, 3.3038],\n",
      "        [3.2577, 3.4806, 3.4114, 3.3886, 3.3414],\n",
      "        [3.1513, 3.4056, 3.2488, 3.2154, 3.2080],\n",
      "        [3.3426, 3.2672, 3.3718, 3.4063, 3.3444],\n",
      "        [3.1909, 3.3288, 3.3250, 3.2965, 3.4335],\n",
      "        [3.3373, 3.6061, 3.4605, 3.4957, 3.6014],\n",
      "        [3.1471, 3.4580, 3.3155, 3.3412, 3.4749],\n",
      "        [3.2403, 3.2028, 3.3519, 3.3744, 3.3348],\n",
      "        [3.2467, 3.3656, 3.2201, 3.2656, 3.3467],\n",
      "        [3.6084, 3.7052, 3.3303, 3.4939, 3.3950],\n",
      "        [3.3006, 3.3565, 3.3894, 3.4309, 3.4538],\n",
      "        [3.3263, 3.1409, 3.1970, 3.2707, 3.3230],\n",
      "        [3.4010, 3.4544, 3.4570, 3.4648, 3.6234],\n",
      "        [3.2557, 3.4406, 3.2654, 3.1655, 3.3146],\n",
      "        [2.9868, 3.1285, 3.1075, 3.0594, 3.1290],\n",
      "        [3.3474, 3.4664, 3.3127, 3.5428, 3.4636],\n",
      "        [3.2175, 3.2238, 3.3245, 3.3306, 3.3354],\n",
      "        [3.2801, 3.3625, 3.3872, 3.4325, 3.4402],\n",
      "        [3.3216, 3.3955, 3.4362, 3.3436, 3.2892],\n",
      "        [3.2249, 3.5042, 3.4047, 3.3442, 3.3028],\n",
      "        [3.0652, 3.1134, 3.1453, 3.1539, 3.1684],\n",
      "        [3.2275, 3.2528, 3.3164, 3.2141, 3.1478],\n",
      "        [3.3723, 3.4600, 3.3053, 3.3861, 3.4796],\n",
      "        [3.4406, 3.3261, 3.4239, 3.5305, 3.4525],\n",
      "        [3.3658, 3.3751, 3.3885, 3.4617, 3.5547],\n",
      "        [3.3937, 3.5333, 3.4090, 3.3319, 3.4791],\n",
      "        [3.5215, 3.5794, 3.5017, 3.5657, 3.6672],\n",
      "        [3.1866, 3.2093, 3.2775, 3.2941, 3.2990],\n",
      "        [3.3105, 3.2772, 3.3559, 3.2984, 3.2618],\n",
      "        [3.1766, 3.2624, 3.2617, 3.3299, 3.3475],\n",
      "        [3.2817, 3.2936, 3.3003, 3.4196, 3.3481],\n",
      "        [3.2010, 3.1478, 3.2927, 3.2931, 3.3844],\n",
      "        [3.2365, 3.3284, 3.1640, 3.3587, 3.3091],\n",
      "        [3.1998, 3.2823, 3.2367, 3.2644, 3.3023],\n",
      "        [3.0944, 3.2156, 3.1397, 3.1779, 3.2077],\n",
      "        [3.1122, 3.1337, 3.0763, 3.2471, 3.1165],\n",
      "        [3.2334, 3.3035, 3.3021, 3.2856, 3.3432],\n",
      "        [3.3859, 3.3686, 3.4483, 3.4516, 3.3202],\n",
      "        [3.1267, 3.4073, 3.2945, 3.1277, 3.4010],\n",
      "        [3.0386, 3.1744, 3.1295, 3.1252, 3.1811],\n",
      "        [3.2845, 3.4139, 3.3591, 3.3561, 3.2638],\n",
      "        [3.2697, 3.2560, 3.3922, 3.3564, 3.3822],\n",
      "        [3.1780, 3.2857, 3.2442, 3.3483, 3.3507],\n",
      "        [3.2010, 3.2163, 3.2829, 3.2889, 3.3021],\n",
      "        [3.3564, 3.3928, 3.4243, 3.4606, 3.3391],\n",
      "        [3.3696, 3.3521, 3.4187, 3.4757, 3.2693],\n",
      "        [3.0031, 3.1804, 3.3347, 3.1312, 3.2969],\n",
      "        [3.4506, 3.4326, 3.3841, 3.4702, 3.5007],\n",
      "        [3.3236, 3.3958, 3.4334, 3.3959, 3.4111],\n",
      "        [3.1794, 3.2080, 3.4119, 3.1480, 3.4600],\n",
      "        [3.2979, 3.2553, 3.3393, 3.2761, 3.2590]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2233, 3.3087, 3.1510, 3.3312, 3.2850],\n",
      "        [3.0353, 3.2903, 3.3771, 3.1773, 3.3230],\n",
      "        [3.2064, 3.2806, 3.1894, 3.2837, 3.3109],\n",
      "        [3.1937, 3.2392, 3.4069, 3.4018, 3.3666],\n",
      "        [3.3502, 3.4713, 3.3161, 3.5454, 3.4667],\n",
      "        [3.4963, 3.2954, 3.3525, 3.7670, 3.6147],\n",
      "        [3.2372, 3.2073, 3.3595, 3.3448, 3.3850],\n",
      "        [3.2469, 3.2743, 3.3565, 3.3488, 3.4472],\n",
      "        [3.1780, 3.4271, 3.2992, 3.2718, 3.2195],\n",
      "        [3.2415, 3.2133, 3.3423, 3.2975, 3.3173],\n",
      "        [3.0830, 3.1725, 3.3250, 3.2075, 3.3104],\n",
      "        [3.2456, 3.2411, 3.2904, 3.3241, 3.3375],\n",
      "        [3.1815, 3.3422, 3.2971, 3.2988, 3.3311],\n",
      "        [3.2393, 3.2022, 3.3608, 3.3619, 3.4268],\n",
      "        [3.3611, 3.3251, 3.4630, 3.3727, 3.2024],\n",
      "        [3.2095, 3.1077, 3.2245, 3.1647, 3.1812],\n",
      "        [2.9253, 3.0745, 3.1498, 3.0777, 3.1675],\n",
      "        [3.0999, 3.1205, 3.1899, 3.2023, 3.1799],\n",
      "        [3.2042, 3.1549, 3.1702, 3.3554, 3.1939],\n",
      "        [3.1800, 3.1943, 3.2874, 3.3015, 3.3761],\n",
      "        [3.3111, 3.3473, 3.3224, 3.4976, 3.3598],\n",
      "        [3.3655, 3.2914, 3.3214, 3.6319, 3.5179],\n",
      "        [3.1969, 3.2184, 3.2934, 3.1794, 3.1143],\n",
      "        [3.5022, 3.4313, 3.4474, 3.5266, 3.5206],\n",
      "        [3.1981, 3.2713, 3.3084, 3.3200, 3.2704],\n",
      "        [3.1984, 3.2161, 3.3097, 3.3049, 3.3240],\n",
      "        [3.1218, 3.3379, 3.2763, 3.2824, 3.4431],\n",
      "        [3.3411, 3.4733, 3.4453, 3.4709, 3.4152],\n",
      "        [3.4001, 3.1784, 3.3426, 3.5785, 3.6004],\n",
      "        [3.3950, 3.3599, 3.4800, 3.4374, 3.2958],\n",
      "        [3.2084, 3.1585, 3.3114, 3.3041, 3.3928],\n",
      "        [3.1328, 3.4425, 3.3683, 3.3332, 3.4689],\n",
      "        [3.1486, 3.2706, 3.3113, 3.3064, 3.4326],\n",
      "        [3.0923, 3.1911, 3.2250, 3.2017, 3.2265],\n",
      "        [3.1898, 3.1920, 3.2239, 3.3210, 3.2201],\n",
      "        [3.5373, 3.4475, 3.5452, 3.6892, 3.5698],\n",
      "        [3.4241, 3.5463, 3.5306, 3.4743, 3.3400],\n",
      "        [3.2078, 3.3727, 3.2920, 3.2547, 3.3793],\n",
      "        [3.0609, 3.2762, 3.3588, 3.2014, 3.3016],\n",
      "        [3.3732, 3.5987, 3.5058, 3.5046, 3.5843],\n",
      "        [3.2297, 3.3234, 3.1592, 3.3487, 3.3060],\n",
      "        [3.2708, 3.5359, 3.4129, 3.4299, 3.5261],\n",
      "        [3.2118, 3.2030, 3.2895, 3.2853, 3.3062],\n",
      "        [3.0220, 3.1633, 3.1249, 3.0954, 3.1620],\n",
      "        [3.3274, 3.4447, 3.4223, 3.4530, 3.4514],\n",
      "        [3.1997, 3.3948, 3.3301, 3.2420, 3.3972],\n",
      "        [3.1313, 3.2020, 3.1523, 3.2494, 3.2027],\n",
      "        [3.3446, 3.4614, 3.2826, 3.3686, 3.4436],\n",
      "        [3.0923, 3.1518, 3.2274, 3.2130, 3.1678],\n",
      "        [3.3637, 3.3655, 3.4228, 3.4656, 3.2907],\n",
      "        [3.4212, 3.2601, 3.3252, 3.6742, 3.5417],\n",
      "        [3.1788, 3.2456, 3.1882, 3.2267, 3.2429],\n",
      "        [3.3800, 3.4453, 3.4286, 3.3731, 3.4479],\n",
      "        [3.2396, 3.2497, 3.3077, 3.2145, 3.1569],\n",
      "        [3.3124, 3.5608, 3.4636, 3.4525, 3.5389],\n",
      "        [3.1341, 3.2390, 3.1895, 3.2352, 3.2541],\n",
      "        [3.2057, 3.5038, 3.3359, 3.4310, 3.4903],\n",
      "        [3.1970, 3.1926, 3.2707, 3.2734, 3.2915],\n",
      "        [3.1720, 3.2021, 3.2461, 3.2998, 3.2306],\n",
      "        [3.3472, 3.4260, 3.4262, 3.4575, 3.3996],\n",
      "        [3.0578, 3.2770, 3.3603, 3.2082, 3.3081],\n",
      "        [3.1371, 3.1842, 3.2725, 3.2970, 3.3108],\n",
      "        [3.3590, 3.3809, 3.4284, 3.4712, 3.3156],\n",
      "        [3.2345, 3.3958, 3.2963, 3.3162, 3.3931]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4260, 3.4437, 3.5171, 3.6061, 3.4295],\n",
      "        [3.3303, 3.2791, 3.3576, 3.3885, 3.3375],\n",
      "        [3.4391, 3.5479, 3.5528, 3.5036, 3.3492],\n",
      "        [3.3277, 3.3966, 3.4862, 3.4565, 3.4860],\n",
      "        [3.1665, 3.2191, 3.2397, 3.2181, 3.2652],\n",
      "        [3.2222, 3.2788, 3.1987, 3.3552, 3.3062],\n",
      "        [3.6473, 3.8718, 3.4423, 3.5715, 3.4724],\n",
      "        [3.5094, 3.4778, 3.4348, 3.5393, 3.5692],\n",
      "        [3.2568, 3.2609, 3.2911, 3.3538, 3.3384],\n",
      "        [3.2314, 3.1889, 3.3433, 3.3462, 3.4131],\n",
      "        [3.2076, 3.2619, 3.2945, 3.2841, 3.4803],\n",
      "        [3.1164, 3.1449, 3.0787, 3.2535, 3.1101],\n",
      "        [3.5450, 3.3855, 3.4445, 3.9154, 3.7972],\n",
      "        [3.3122, 3.4494, 3.2914, 3.3700, 3.3918],\n",
      "        [3.1203, 3.1453, 3.0871, 3.2541, 3.1439],\n",
      "        [3.1161, 3.1406, 3.2152, 3.2199, 3.1736],\n",
      "        [3.1555, 3.2602, 3.1489, 3.2398, 3.2504],\n",
      "        [3.1861, 3.2887, 3.2869, 3.3833, 3.2779],\n",
      "        [3.3117, 3.2457, 3.3442, 3.2676, 3.3169],\n",
      "        [3.2167, 3.3732, 3.2664, 3.3066, 3.3891],\n",
      "        [3.3145, 3.5336, 3.4599, 3.4571, 3.6155],\n",
      "        [3.3499, 3.4307, 3.4293, 3.4599, 3.4024],\n",
      "        [3.2435, 3.5150, 3.4386, 3.4358, 3.5395],\n",
      "        [3.0707, 3.2919, 3.2653, 3.1970, 3.2359],\n",
      "        [3.0170, 3.1572, 3.1251, 3.0876, 3.1642],\n",
      "        [3.2817, 3.2953, 3.3021, 3.4165, 3.3460],\n",
      "        [3.0671, 3.2710, 3.2565, 3.1936, 3.2233],\n",
      "        [3.0995, 3.1454, 3.2062, 3.2039, 3.1929],\n",
      "        [3.0640, 3.2461, 3.2407, 3.1872, 3.2079],\n",
      "        [3.1101, 3.1055, 3.1804, 3.2178, 3.1744],\n",
      "        [3.4417, 3.5723, 3.5718, 3.5172, 3.3824],\n",
      "        [3.0731, 3.2900, 3.3825, 3.1961, 3.3050],\n",
      "        [3.3736, 3.4320, 3.4564, 3.5618, 3.4032],\n",
      "        [3.2083, 3.1619, 3.3050, 3.3013, 3.3955],\n",
      "        [3.0375, 3.0789, 3.1646, 3.1299, 3.1048],\n",
      "        [3.2014, 3.2094, 3.2797, 3.2926, 3.3088],\n",
      "        [3.1769, 3.2810, 3.1589, 3.2694, 3.2696],\n",
      "        [3.0713, 3.2130, 3.1540, 3.2020, 3.1916],\n",
      "        [3.0561, 3.1087, 3.1438, 3.1422, 3.1605],\n",
      "        [3.2496, 3.2788, 3.3596, 3.3512, 3.4501],\n",
      "        [3.0497, 3.1016, 3.1806, 3.1615, 3.1162],\n",
      "        [3.4972, 3.4658, 3.5054, 3.6291, 3.5519],\n",
      "        [3.2804, 3.5705, 3.3193, 3.5205, 3.4908],\n",
      "        [3.2131, 3.2464, 3.3054, 3.3215, 3.3328],\n",
      "        [3.2374, 3.2118, 3.3039, 3.3224, 3.3646],\n",
      "        [3.0372, 3.1769, 3.1317, 3.1173, 3.1757],\n",
      "        [3.0501, 3.1450, 3.0690, 3.2021, 3.1157],\n",
      "        [3.3881, 3.6395, 3.4060, 3.5966, 3.5932],\n",
      "        [3.1409, 3.1413, 3.2132, 3.2383, 3.1868],\n",
      "        [3.2112, 3.2284, 3.2976, 3.3113, 3.3334],\n",
      "        [3.2098, 3.1446, 3.2596, 3.2085, 3.2244],\n",
      "        [3.1461, 3.0886, 3.2352, 3.2444, 3.2930],\n",
      "        [3.2720, 3.4935, 3.3692, 3.4147, 3.5209],\n",
      "        [3.0674, 3.2309, 3.3868, 3.1855, 3.3728],\n",
      "        [3.2878, 3.4136, 3.2987, 3.4132, 3.3689],\n",
      "        [3.2066, 3.2965, 3.1549, 3.3194, 3.2869],\n",
      "        [3.2989, 3.2550, 3.3128, 3.2439, 3.1737],\n",
      "        [3.2253, 3.2875, 3.2127, 3.3603, 3.3144],\n",
      "        [3.2521, 3.3752, 3.2266, 3.2704, 3.3525],\n",
      "        [3.4077, 3.4470, 3.4645, 3.4605, 3.6604],\n",
      "        [3.3335, 3.3965, 3.2831, 3.3575, 3.5124],\n",
      "        [3.1905, 3.3026, 3.1621, 3.2980, 3.2825],\n",
      "        [3.4161, 3.5782, 3.4303, 3.5885, 3.5520],\n",
      "        [3.2842, 3.3187, 3.3808, 3.3718, 3.3725]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5000, 3.4775, 3.5020, 3.6266, 3.5488],\n",
      "        [3.2912, 3.3338, 3.2568, 3.4035, 3.3793],\n",
      "        [3.2517, 3.3180, 3.3141, 3.3199, 3.3491],\n",
      "        [3.2197, 3.3556, 3.3365, 3.3218, 3.2992],\n",
      "        [3.0397, 3.1813, 3.1343, 3.1193, 3.1780],\n",
      "        [3.1380, 3.2864, 3.1841, 3.3293, 3.2254],\n",
      "        [3.0710, 3.1979, 3.2238, 3.1856, 3.1963],\n",
      "        [3.1052, 3.0817, 3.1654, 3.2090, 3.1599],\n",
      "        [3.1934, 3.4770, 3.3844, 3.3827, 3.5013],\n",
      "        [3.2082, 3.3016, 3.1624, 3.3083, 3.2904],\n",
      "        [3.0920, 3.1557, 3.2102, 3.1955, 3.1932],\n",
      "        [3.1303, 3.1662, 3.1008, 3.2777, 3.1998],\n",
      "        [3.0741, 3.2843, 3.2597, 3.2003, 3.2349],\n",
      "        [3.2048, 3.3543, 3.2122, 3.4114, 3.2483],\n",
      "        [3.1096, 3.2514, 3.2245, 3.3372, 3.1910],\n",
      "        [3.2443, 3.3420, 3.1729, 3.3655, 3.3174],\n",
      "        [3.3223, 3.5205, 3.4548, 3.4493, 3.5937],\n",
      "        [3.5363, 3.4541, 3.5446, 3.7049, 3.5808],\n",
      "        [3.1029, 3.1359, 3.2014, 3.2149, 3.1911],\n",
      "        [3.3496, 3.4237, 3.3165, 3.4504, 3.4223],\n",
      "        [3.4065, 3.4231, 3.4111, 3.4463, 3.6253],\n",
      "        [3.3505, 3.2984, 3.3298, 3.2686, 3.2391],\n",
      "        [3.1015, 3.1450, 3.2082, 3.2036, 3.1928],\n",
      "        [3.4950, 3.5749, 3.4921, 3.5521, 3.6398],\n",
      "        [3.1546, 3.2231, 3.1785, 3.3180, 3.2614],\n",
      "        [3.1347, 3.2462, 3.1544, 3.2238, 3.2505],\n",
      "        [3.2128, 3.1672, 3.3039, 3.3031, 3.3989],\n",
      "        [3.3328, 3.2839, 3.3604, 3.3907, 3.3401],\n",
      "        [3.6613, 3.7895, 3.5318, 3.5570, 3.5560],\n",
      "        [3.3803, 3.4767, 3.4610, 3.4155, 3.3084],\n",
      "        [3.2090, 3.4461, 3.2397, 3.4354, 3.3816],\n",
      "        [3.1260, 3.2473, 3.3172, 3.2626, 3.2197],\n",
      "        [3.3046, 3.3538, 3.3793, 3.3606, 3.3955],\n",
      "        [3.3799, 3.4031, 3.4105, 3.4560, 3.5526],\n",
      "        [3.4470, 3.6156, 3.4336, 3.5818, 3.6240],\n",
      "        [3.1864, 3.2583, 3.2705, 3.2990, 3.4168],\n",
      "        [3.3162, 3.3266, 3.4358, 3.4250, 3.3713],\n",
      "        [3.0872, 3.2825, 3.3603, 3.2287, 3.3267],\n",
      "        [3.2083, 3.2095, 3.2799, 3.2927, 3.3031],\n",
      "        [3.4017, 3.6587, 3.4106, 3.6170, 3.6118],\n",
      "        [3.4381, 3.5758, 3.3730, 3.3497, 3.3847],\n",
      "        [3.3842, 3.5130, 3.3050, 3.3775, 3.4407],\n",
      "        [3.3541, 3.3344, 3.3696, 3.4067, 3.5421],\n",
      "        [3.2015, 3.2036, 3.2840, 3.2946, 3.3070],\n",
      "        [3.0706, 3.3213, 3.1004, 3.2582, 3.1602],\n",
      "        [3.2035, 3.2085, 3.2770, 3.2833, 3.3005],\n",
      "        [3.0939, 3.2017, 3.2305, 3.1995, 3.2237],\n",
      "        [3.7734, 3.9421, 3.5400, 3.6387, 3.5841],\n",
      "        [3.7302, 3.8607, 3.5730, 3.6331, 3.5899],\n",
      "        [3.3663, 3.3344, 3.4689, 3.3773, 3.2078],\n",
      "        [3.3715, 3.5396, 3.5272, 3.4909, 3.3592],\n",
      "        [3.2047, 3.2877, 3.3044, 3.3213, 3.2893],\n",
      "        [3.1083, 3.3268, 3.4375, 3.2881, 3.3638],\n",
      "        [3.3438, 3.4086, 3.4704, 3.3809, 3.3127],\n",
      "        [3.1038, 3.1692, 3.2340, 3.2199, 3.1791],\n",
      "        [3.0748, 3.1932, 3.2255, 3.1902, 3.1961],\n",
      "        [3.1898, 3.2080, 3.2388, 3.2451, 3.3438],\n",
      "        [3.3556, 3.4807, 3.3220, 3.5499, 3.4722],\n",
      "        [3.3490, 3.3633, 3.3789, 3.3594, 3.2282],\n",
      "        [3.3179, 3.2969, 3.2989, 3.4788, 3.4155],\n",
      "        [3.2153, 3.3046, 3.3175, 3.2974, 3.2214],\n",
      "        [3.1408, 3.1892, 3.2459, 3.2853, 3.1999],\n",
      "        [3.1747, 3.1933, 3.2160, 3.2234, 3.3237],\n",
      "        [3.1532, 3.2216, 3.0696, 3.3178, 3.1467]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3365, 3.4591, 3.4072, 3.5309, 3.4177],\n",
      "        [3.3196, 3.5438, 3.4655, 3.4613, 3.6204],\n",
      "        [3.0814, 3.1704, 3.2144, 3.1921, 3.1915],\n",
      "        [3.4431, 3.4227, 3.4645, 3.5487, 3.4895],\n",
      "        [3.0904, 3.1864, 3.3332, 3.2138, 3.3178],\n",
      "        [3.3826, 3.4802, 3.3176, 3.3951, 3.4904],\n",
      "        [3.2140, 3.2471, 3.3777, 3.2038, 3.4712],\n",
      "        [3.3621, 3.4489, 3.3434, 3.3743, 3.3993],\n",
      "        [3.1471, 3.0974, 3.2401, 3.2436, 3.3033],\n",
      "        [3.2307, 3.3225, 3.1591, 3.3375, 3.2925],\n",
      "        [3.0755, 3.3012, 3.2705, 3.2010, 3.2406],\n",
      "        [3.1255, 3.1589, 3.0888, 3.2620, 3.1378],\n",
      "        [3.2891, 3.3286, 3.3862, 3.3758, 3.3774],\n",
      "        [3.3255, 3.4063, 3.3056, 3.4212, 3.4713],\n",
      "        [3.1646, 3.2426, 3.1944, 3.2087, 3.2305],\n",
      "        [3.2806, 3.3023, 3.2864, 3.3952, 3.4609],\n",
      "        [3.3935, 3.3841, 3.5809, 3.3536, 3.3387],\n",
      "        [3.4287, 3.4235, 3.4736, 3.3946, 3.2704],\n",
      "        [3.2216, 3.3831, 3.2717, 3.3105, 3.3940],\n",
      "        [3.1171, 3.1324, 3.1946, 3.2187, 3.1884],\n",
      "        [3.0528, 3.0915, 3.1715, 3.1407, 3.1163],\n",
      "        [3.3580, 3.4858, 3.3247, 3.5519, 3.4746],\n",
      "        [3.3364, 3.4279, 3.3284, 3.2930, 3.3778],\n",
      "        [3.2324, 3.3293, 3.1641, 3.3454, 3.3033],\n",
      "        [3.1452, 3.4711, 3.3140, 3.3555, 3.4634],\n",
      "        [3.4467, 3.5824, 3.5773, 3.5214, 3.3874],\n",
      "        [3.1830, 3.2243, 3.1870, 3.3113, 3.2485],\n",
      "        [3.3558, 3.4836, 3.3237, 3.5508, 3.4713],\n",
      "        [3.1398, 3.2571, 3.1513, 3.2245, 3.2440],\n",
      "        [3.1157, 3.2602, 3.1764, 3.2762, 3.2250],\n",
      "        [3.4777, 3.4748, 3.4724, 3.6105, 3.4762],\n",
      "        [3.3692, 3.5370, 3.3776, 3.4482, 3.4595],\n",
      "        [3.2874, 3.3531, 3.2612, 3.3898, 3.3850],\n",
      "        [3.1364, 3.2291, 3.1557, 3.2604, 3.2156],\n",
      "        [3.0798, 3.2966, 3.2670, 3.2128, 3.2477],\n",
      "        [3.4048, 3.5761, 3.4201, 3.5771, 3.5406],\n",
      "        [3.1616, 3.2797, 3.2745, 3.3680, 3.2488],\n",
      "        [3.2074, 3.4093, 3.3386, 3.2484, 3.4049],\n",
      "        [3.3637, 3.5561, 3.3698, 3.2757, 3.4477],\n",
      "        [3.3568, 3.4885, 3.4679, 3.4113, 3.3334],\n",
      "        [3.2108, 3.1963, 3.3010, 3.2868, 3.2879],\n",
      "        [3.3560, 3.4255, 3.4945, 3.4879, 3.5438],\n",
      "        [3.2244, 3.3227, 3.2485, 3.3733, 3.3580],\n",
      "        [3.2028, 3.2645, 3.2910, 3.2914, 3.4622],\n",
      "        [3.3475, 3.3682, 3.3374, 3.4633, 3.5188],\n",
      "        [3.1882, 3.3051, 3.2559, 3.3570, 3.3612],\n",
      "        [3.2248, 3.2281, 3.3448, 3.3337, 3.3493],\n",
      "        [3.2130, 3.2278, 3.2798, 3.2771, 3.3614],\n",
      "        [3.2032, 3.2209, 3.2816, 3.2882, 3.3046],\n",
      "        [3.2114, 3.2357, 3.2946, 3.2978, 3.3128],\n",
      "        [2.9947, 3.1481, 3.1753, 3.1372, 3.1879],\n",
      "        [3.3579, 3.3084, 3.3315, 3.2617, 3.2498],\n",
      "        [3.4627, 3.4472, 3.3424, 3.5096, 3.5386],\n",
      "        [3.5094, 3.5273, 3.4234, 3.5432, 3.6375],\n",
      "        [3.5279, 3.3490, 3.4771, 3.9097, 3.8196],\n",
      "        [3.2466, 3.3469, 3.1754, 3.3674, 3.3197],\n",
      "        [3.2350, 3.2870, 3.3247, 3.2957, 3.5320],\n",
      "        [3.3267, 3.3949, 3.2876, 3.3596, 3.5240],\n",
      "        [3.2744, 3.1931, 3.2854, 3.3296, 3.2628],\n",
      "        [3.2307, 3.1425, 3.2577, 3.1862, 3.2110],\n",
      "        [3.2106, 3.2218, 3.2855, 3.2866, 3.3049],\n",
      "        [3.2215, 3.2530, 3.3904, 3.4284, 3.5122],\n",
      "        [3.2211, 3.3139, 3.1632, 3.3289, 3.2933],\n",
      "        [3.3875, 3.4598, 3.4371, 3.3796, 3.4557]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2930, 3.3879, 3.4020, 3.4441, 3.4544],\n",
      "        [3.3561, 3.4520, 3.4531, 3.4490, 3.4790],\n",
      "        [3.1821, 3.1476, 3.2255, 3.2457, 3.3812],\n",
      "        [3.2148, 3.4046, 3.3225, 3.2584, 3.4005],\n",
      "        [3.1484, 3.2195, 3.2434, 3.2063, 3.2453],\n",
      "        [3.2793, 3.5081, 3.3770, 3.4213, 3.5289],\n",
      "        [3.3164, 3.2703, 3.3226, 3.2642, 3.1947],\n",
      "        [3.4171, 3.4341, 3.4012, 3.4363, 3.5039],\n",
      "        [3.2073, 3.1763, 3.2829, 3.2952, 3.4093],\n",
      "        [3.3211, 3.3534, 3.2183, 3.4423, 3.4691],\n",
      "        [3.0041, 3.1494, 3.1183, 3.0710, 3.1401],\n",
      "        [3.7627, 3.9919, 3.5499, 3.7024, 3.5745],\n",
      "        [3.6028, 3.8074, 3.3914, 3.5039, 3.4177],\n",
      "        [3.1112, 3.3380, 3.4426, 3.2912, 3.3728],\n",
      "        [3.0733, 3.2345, 3.2431, 3.2013, 3.2183],\n",
      "        [3.1253, 3.3481, 3.2890, 3.2868, 3.4504],\n",
      "        [3.1952, 3.3586, 3.3327, 3.3125, 3.3983],\n",
      "        [3.3841, 3.3815, 3.4647, 3.4065, 3.3186],\n",
      "        [3.1359, 3.1959, 3.2558, 3.2699, 3.1972],\n",
      "        [3.3581, 3.4883, 3.3262, 3.5534, 3.4744],\n",
      "        [3.2860, 3.2075, 3.5363, 3.3770, 3.4449],\n",
      "        [3.3349, 3.4890, 3.4137, 3.5491, 3.4384],\n",
      "        [3.3546, 3.4814, 3.2940, 3.3777, 3.4547],\n",
      "        [3.0794, 3.2024, 3.2304, 3.1946, 3.2012],\n",
      "        [3.3300, 3.3725, 3.3634, 3.3394, 3.1848],\n",
      "        [3.3573, 3.3182, 3.2936, 3.5662, 3.4790],\n",
      "        [3.1339, 3.2309, 3.2918, 3.2649, 3.2076],\n",
      "        [3.5427, 3.4428, 3.5142, 3.7166, 3.6281],\n",
      "        [3.3660, 3.5608, 3.3723, 3.2782, 3.4508],\n",
      "        [3.2557, 3.3604, 3.1699, 3.2664, 3.3241],\n",
      "        [3.2552, 3.2262, 3.3776, 3.3880, 3.4411],\n",
      "        [3.1802, 3.3918, 3.2741, 3.2699, 3.2677],\n",
      "        [3.3697, 3.3973, 3.3922, 3.4072, 3.5368],\n",
      "        [3.1009, 3.1713, 3.2189, 3.2068, 3.2130],\n",
      "        [3.3388, 3.4639, 3.4097, 3.5334, 3.4208],\n",
      "        [3.0965, 3.1650, 3.2151, 3.1998, 3.1984],\n",
      "        [3.3772, 3.3279, 3.3238, 3.6125, 3.5117],\n",
      "        [3.2422, 3.3424, 3.1831, 3.3609, 3.3184],\n",
      "        [3.1112, 3.3380, 3.4426, 3.2912, 3.3728],\n",
      "        [3.1292, 3.1462, 3.2188, 3.2315, 3.1805],\n",
      "        [3.2228, 3.2815, 3.3698, 3.3353, 3.4367],\n",
      "        [3.3716, 3.5417, 3.3801, 3.4507, 3.4626],\n",
      "        [3.1421, 3.2615, 3.1536, 3.2270, 3.2469],\n",
      "        [3.2277, 3.2166, 3.3135, 3.2949, 3.3107],\n",
      "        [3.1804, 3.2790, 3.1532, 3.2788, 3.2517],\n",
      "        [3.1516, 3.2793, 3.3556, 3.3402, 3.4273],\n",
      "        [3.2129, 3.2192, 3.2849, 3.2972, 3.3085],\n",
      "        [3.1836, 3.1530, 3.2800, 3.2582, 3.2590],\n",
      "        [3.0794, 3.2024, 3.2304, 3.1946, 3.2012],\n",
      "        [3.1057, 3.2383, 3.1541, 3.1940, 3.2232],\n",
      "        [3.1820, 3.2854, 3.1673, 3.2839, 3.2772],\n",
      "        [3.2995, 3.4776, 3.3518, 3.5117, 3.4317],\n",
      "        [3.2176, 3.4584, 3.2492, 3.4403, 3.3865],\n",
      "        [3.3602, 3.3129, 3.3338, 3.2641, 3.2529],\n",
      "        [3.4139, 3.5251, 3.5178, 3.4460, 3.2819],\n",
      "        [3.2477, 3.2178, 3.3474, 3.3272, 3.3164],\n",
      "        [3.3361, 3.4679, 3.3028, 3.5216, 3.4383],\n",
      "        [3.2150, 3.2068, 3.3009, 3.2911, 3.2980],\n",
      "        [3.3386, 3.4324, 3.3308, 3.2954, 3.3809],\n",
      "        [3.4514, 3.4323, 3.4604, 3.5808, 3.4826],\n",
      "        [3.1066, 3.4665, 3.3674, 3.2851, 3.4847],\n",
      "        [3.4066, 3.6690, 3.4159, 3.6215, 3.6174],\n",
      "        [3.5342, 3.6045, 3.5169, 3.5776, 3.6817],\n",
      "        [3.1877, 3.1897, 3.2821, 3.2482, 3.2777]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3364, 3.4235, 3.4524, 3.3574, 3.3059],\n",
      "        [3.5940, 3.3386, 3.4511, 3.8919, 3.8265],\n",
      "        [3.1409, 3.2374, 3.1602, 3.2651, 3.2213],\n",
      "        [3.1903, 3.4508, 3.3125, 3.2829, 3.2333],\n",
      "        [3.2072, 3.4792, 3.3587, 3.4067, 3.4965],\n",
      "        [3.3426, 3.3767, 3.3725, 3.3544, 3.2011],\n",
      "        [3.1330, 3.2607, 3.3244, 3.2694, 3.2277],\n",
      "        [3.3559, 3.3770, 3.3862, 3.3662, 3.2366],\n",
      "        [3.3236, 3.3707, 3.3357, 3.5089, 3.3735],\n",
      "        [3.3018, 3.4819, 3.3541, 3.5141, 3.4346],\n",
      "        [3.1885, 3.5613, 3.4422, 3.3276, 3.3437],\n",
      "        [3.5225, 3.5359, 3.4332, 3.5617, 3.6509],\n",
      "        [3.2177, 3.4071, 3.2613, 3.2567, 3.3707],\n",
      "        [3.0881, 3.3185, 3.2795, 3.2247, 3.2662],\n",
      "        [3.7858, 3.9669, 3.5519, 3.6543, 3.6013],\n",
      "        [3.8146, 3.9671, 3.5901, 3.6805, 3.5888],\n",
      "        [3.1446, 3.4855, 3.3303, 3.3414, 3.4897],\n",
      "        [3.0856, 3.3172, 3.2842, 3.2113, 3.2512],\n",
      "        [3.2291, 3.1597, 3.2685, 3.2126, 3.2295],\n",
      "        [3.2896, 3.2663, 3.3158, 3.2319, 3.1715],\n",
      "        [3.0760, 3.3261, 3.1064, 3.2749, 3.1672],\n",
      "        [3.1843, 3.2894, 3.1695, 3.2862, 3.2799],\n",
      "        [3.1934, 3.2722, 3.2778, 3.3057, 3.4252],\n",
      "        [3.0851, 3.2294, 3.2494, 3.2104, 3.2272],\n",
      "        [2.9894, 3.1415, 3.1894, 3.1249, 3.2130],\n",
      "        [3.1907, 3.2675, 3.2007, 3.2376, 3.2559],\n",
      "        [3.4067, 3.2654, 3.3142, 3.7097, 3.5308],\n",
      "        [3.2320, 3.3348, 3.3106, 3.2999, 3.3486],\n",
      "        [3.2146, 3.3093, 3.2525, 3.2780, 3.3184],\n",
      "        [3.2467, 3.1679, 3.2785, 3.2096, 3.2355],\n",
      "        [3.4007, 3.4410, 3.4060, 3.5036, 3.5973],\n",
      "        [3.1966, 3.2215, 3.2459, 3.2517, 3.3520],\n",
      "        [3.2216, 3.2626, 3.3657, 3.2551, 3.4654],\n",
      "        [3.2020, 3.1935, 3.3011, 3.2876, 3.2876],\n",
      "        [3.1496, 3.3434, 3.1602, 3.3102, 3.2019],\n",
      "        [3.2115, 3.2994, 3.2017, 3.2997, 3.3154],\n",
      "        [3.2170, 3.3619, 3.3539, 3.3201, 3.2737],\n",
      "        [3.3963, 3.3773, 3.4025, 3.4564, 3.6061],\n",
      "        [3.1622, 3.2794, 3.1577, 3.2560, 3.2593],\n",
      "        [3.2947, 3.4009, 3.2608, 3.3848, 3.4051],\n",
      "        [3.0655, 3.2096, 3.1481, 3.1474, 3.2024],\n",
      "        [3.1917, 3.2160, 3.2416, 3.2453, 3.3382],\n",
      "        [3.8467, 3.9978, 3.6230, 3.7052, 3.6153],\n",
      "        [3.1722, 3.4642, 3.3735, 3.3699, 3.4499],\n",
      "        [3.2350, 3.3056, 3.2227, 3.3693, 3.3250],\n",
      "        [3.4795, 3.4461, 3.4733, 3.5570, 3.4012],\n",
      "        [3.2028, 3.2620, 3.2151, 3.2296, 3.2842],\n",
      "        [3.3762, 3.4852, 3.3109, 3.3954, 3.4817],\n",
      "        [3.2172, 3.2807, 3.3046, 3.2929, 3.4914],\n",
      "        [3.2720, 3.4433, 3.3373, 3.3312, 3.4209],\n",
      "        [3.2937, 3.4926, 3.3408, 3.5075, 3.4357],\n",
      "        [3.1223, 3.2955, 3.3689, 3.2566, 3.3603],\n",
      "        [3.1008, 3.2150, 3.2375, 3.2061, 3.2316],\n",
      "        [3.0464, 3.1940, 3.1412, 3.1258, 3.1857],\n",
      "        [3.1760, 3.1481, 3.2757, 3.2518, 3.2477],\n",
      "        [3.2099, 3.2517, 3.3747, 3.2344, 3.4578],\n",
      "        [3.0208, 3.0842, 3.1275, 3.0948, 3.1248],\n",
      "        [3.1088, 3.2601, 3.1903, 3.2828, 3.2263],\n",
      "        [3.2405, 3.3345, 3.4048, 3.3599, 3.4019],\n",
      "        [3.2823, 3.5320, 3.3980, 3.4326, 3.5372],\n",
      "        [3.2282, 3.1905, 3.3237, 3.3080, 3.3849],\n",
      "        [3.3720, 3.4015, 3.3944, 3.4096, 3.5397],\n",
      "        [3.5235, 3.4571, 3.4420, 3.6516, 3.5406],\n",
      "        [3.3605, 3.4926, 3.3285, 3.5558, 3.4773]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2096, 3.3103, 3.2861, 3.2910, 3.3404],\n",
      "        [3.2327, 3.3239, 3.4757, 3.3645, 3.4737],\n",
      "        [3.2633, 3.5958, 3.3848, 3.5136, 3.5271],\n",
      "        [3.1973, 3.3019, 3.2947, 3.3949, 3.3132],\n",
      "        [3.2652, 3.2697, 3.3736, 3.3403, 3.3929],\n",
      "        [3.1817, 3.2014, 3.2840, 3.2610, 3.2893],\n",
      "        [3.0658, 3.0594, 3.1605, 3.2202, 3.1696],\n",
      "        [3.1525, 3.1636, 3.2260, 3.2491, 3.2006],\n",
      "        [3.4573, 3.3594, 3.4445, 3.5462, 3.4731],\n",
      "        [3.3658, 3.3244, 3.3385, 3.2829, 3.2622],\n",
      "        [3.1638, 3.2405, 3.1887, 3.3269, 3.2728],\n",
      "        [3.3434, 3.4728, 3.4153, 3.5379, 3.4273],\n",
      "        [3.1154, 3.2473, 3.1622, 3.1939, 3.2330],\n",
      "        [3.1466, 3.2697, 3.1588, 3.2314, 3.2529],\n",
      "        [3.5268, 3.4693, 3.4574, 3.5570, 3.5470],\n",
      "        [3.1239, 3.3449, 3.1456, 3.2789, 3.1912],\n",
      "        [3.1632, 3.2984, 3.3278, 3.3197, 3.4501],\n",
      "        [3.2194, 3.4134, 3.3281, 3.2629, 3.4069],\n",
      "        [3.4225, 3.4701, 3.4410, 3.4636, 3.6467],\n",
      "        [3.1208, 3.2383, 3.3037, 3.2611, 3.2033],\n",
      "        [3.3833, 3.4748, 3.3860, 3.4333, 3.5271],\n",
      "        [3.4008, 3.3981, 3.5892, 3.3610, 3.3486],\n",
      "        [3.3731, 3.3765, 3.4353, 3.4796, 3.2857],\n",
      "        [3.4065, 3.4064, 3.4448, 3.5440, 3.4577],\n",
      "        [3.8397, 3.9966, 3.6217, 3.6952, 3.6198],\n",
      "        [3.6244, 3.7373, 3.3501, 3.5098, 3.4152],\n",
      "        [3.4100, 3.5010, 3.3436, 3.4179, 3.5288],\n",
      "        [3.2580, 3.3988, 3.2479, 3.2751, 3.3732],\n",
      "        [3.2489, 3.1724, 3.2816, 3.2117, 3.2389],\n",
      "        [3.1668, 3.2177, 3.2615, 3.2915, 3.2277],\n",
      "        [3.6655, 3.8781, 3.4380, 3.5476, 3.5123],\n",
      "        [3.4217, 3.4429, 3.4066, 3.4408, 3.5103],\n",
      "        [3.2321, 3.2443, 3.3259, 3.3108, 3.3622],\n",
      "        [3.2174, 3.2174, 3.3015, 3.2930, 3.3097],\n",
      "        [3.3081, 3.5090, 3.4361, 3.4291, 3.3927],\n",
      "        [3.2062, 3.2163, 3.3121, 3.3163, 3.3894],\n",
      "        [3.5799, 3.6580, 3.5835, 3.8075, 3.6901],\n",
      "        [3.3243, 3.2691, 3.3642, 3.2708, 3.3429],\n",
      "        [3.2224, 3.4006, 3.3084, 3.2680, 3.3965],\n",
      "        [3.2618, 3.2615, 3.3776, 3.3499, 3.3762],\n",
      "        [3.1345, 3.2844, 3.3616, 3.2822, 3.3783],\n",
      "        [3.1854, 3.1913, 3.2814, 3.2488, 3.2770],\n",
      "        [3.6132, 3.7451, 3.4840, 3.5124, 3.5060],\n",
      "        [3.2310, 3.3339, 3.1770, 3.3385, 3.3116],\n",
      "        [3.0576, 3.3165, 3.3935, 3.1869, 3.3456],\n",
      "        [3.0274, 3.1771, 3.1398, 3.0931, 3.1702],\n",
      "        [3.3591, 3.4914, 3.4605, 3.3927, 3.3307],\n",
      "        [3.1895, 3.1635, 3.2903, 3.2666, 3.2674],\n",
      "        [3.1883, 3.3317, 3.2336, 3.3300, 3.3770],\n",
      "        [3.1195, 3.2897, 3.1456, 3.2679, 3.2273],\n",
      "        [3.3580, 3.4331, 3.4330, 3.3831, 3.4365],\n",
      "        [3.3435, 3.4542, 3.4580, 3.4429, 3.4148],\n",
      "        [3.0831, 3.2461, 3.2504, 3.2112, 3.2321],\n",
      "        [3.2440, 3.2392, 3.3207, 3.2845, 3.3651],\n",
      "        [3.2492, 3.2350, 3.3170, 3.3335, 3.3788],\n",
      "        [3.0761, 3.2833, 3.2611, 3.1995, 3.2292],\n",
      "        [3.3102, 3.2250, 3.5202, 3.3940, 3.4614],\n",
      "        [3.2876, 3.3157, 3.2941, 3.4023, 3.4704],\n",
      "        [3.1866, 3.1561, 3.2308, 3.2500, 3.3874],\n",
      "        [3.2242, 3.3261, 3.1775, 3.3358, 3.3088],\n",
      "        [3.5109, 3.3235, 3.3690, 3.7809, 3.6317],\n",
      "        [3.1845, 3.2746, 3.2061, 3.2246, 3.2573],\n",
      "        [3.2059, 3.2354, 3.2900, 3.2981, 3.3136],\n",
      "        [3.3739, 3.4262, 3.4444, 3.4766, 3.3597]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.0106, 3.1611, 3.1260, 3.0780, 3.1500],\n",
      "        [3.0713, 3.2133, 3.1562, 3.1522, 3.2229],\n",
      "        [3.2517, 3.4603, 3.3483, 3.3370, 3.2519],\n",
      "        [3.4131, 3.5705, 3.4321, 3.3507, 3.5038],\n",
      "        [3.0610, 3.2086, 3.1543, 3.1345, 3.2006],\n",
      "        [3.0774, 3.2571, 3.2523, 3.2029, 3.2206],\n",
      "        [3.2315, 3.2345, 3.3134, 3.3033, 3.3276],\n",
      "        [3.4923, 3.4287, 3.4087, 3.4777, 3.5374],\n",
      "        [3.0842, 3.1817, 3.2209, 3.1981, 3.1997],\n",
      "        [3.2185, 3.2285, 3.2980, 3.2922, 3.3163],\n",
      "        [3.4376, 3.4114, 3.4373, 3.4666, 3.6398],\n",
      "        [3.4275, 3.4453, 3.4460, 3.4742, 3.6290],\n",
      "        [3.1491, 3.4944, 3.3372, 3.3462, 3.4973],\n",
      "        [3.2579, 3.5438, 3.4561, 3.4499, 3.5586],\n",
      "        [3.0783, 3.2872, 3.2639, 3.2022, 3.2333],\n",
      "        [3.2063, 3.2802, 3.3969, 3.4107, 3.4894],\n",
      "        [3.5580, 3.6219, 3.4870, 3.7937, 3.6646],\n",
      "        [3.2043, 3.1803, 3.2648, 3.2849, 3.4104],\n",
      "        [3.2942, 3.5397, 3.4033, 3.4453, 3.5514],\n",
      "        [3.1476, 3.2318, 3.1706, 3.2651, 3.2230],\n",
      "        [3.2450, 3.3432, 3.4111, 3.3648, 3.4095],\n",
      "        [3.3407, 3.3793, 3.2325, 3.4505, 3.4842],\n",
      "        [3.4181, 3.4464, 3.4252, 3.4581, 3.6419],\n",
      "        [3.1137, 3.1052, 3.1776, 3.2221, 3.1756],\n",
      "        [3.1119, 3.1772, 3.2312, 3.2332, 3.2177],\n",
      "        [3.3674, 3.5035, 3.3358, 3.5619, 3.4884],\n",
      "        [3.1619, 3.1186, 3.3051, 3.0975, 3.3542],\n",
      "        [3.2171, 3.2454, 3.2741, 3.2760, 3.3707],\n",
      "        [3.0846, 3.2313, 3.1620, 3.1628, 3.2275],\n",
      "        [3.0797, 3.1393, 3.2010, 3.1821, 3.1617],\n",
      "        [3.3611, 3.3421, 3.4080, 3.5029, 3.3415],\n",
      "        [3.4721, 3.4689, 3.5021, 3.5586, 3.5046],\n",
      "        [3.2237, 3.1715, 3.2755, 3.2222, 3.2425],\n",
      "        [3.2216, 3.4175, 3.3311, 3.2656, 3.4111],\n",
      "        [3.2082, 3.4358, 3.3648, 3.2491, 3.4210],\n",
      "        [3.2454, 3.2163, 3.3593, 3.3601, 3.4312],\n",
      "        [3.3088, 3.3192, 3.3102, 3.4504, 3.3863],\n",
      "        [3.2639, 3.3063, 3.3757, 3.3652, 3.4689],\n",
      "        [3.2748, 3.4672, 3.2767, 3.3852, 3.3898],\n",
      "        [3.4318, 3.4801, 3.4965, 3.5169, 3.4609],\n",
      "        [3.1333, 3.1538, 3.2116, 3.2312, 3.2104],\n",
      "        [3.1865, 3.3574, 3.3182, 3.3013, 3.3813],\n",
      "        [3.1648, 3.1969, 3.2944, 3.2909, 3.3797],\n",
      "        [3.3674, 3.5035, 3.3358, 3.5619, 3.4884],\n",
      "        [3.3611, 3.4593, 3.3563, 3.3374, 3.4050],\n",
      "        [3.1437, 3.3025, 3.3664, 3.2840, 3.3882],\n",
      "        [3.2338, 3.2667, 3.3142, 3.3301, 3.3549],\n",
      "        [3.5750, 3.4539, 3.5419, 3.7054, 3.5913],\n",
      "        [3.3431, 3.4808, 3.3114, 3.5289, 3.4489],\n",
      "        [3.2301, 3.3306, 3.1737, 3.3384, 3.3065],\n",
      "        [3.2793, 3.2860, 3.3129, 3.3749, 3.3591],\n",
      "        [3.3477, 3.4247, 3.2999, 3.3714, 3.5310],\n",
      "        [3.1391, 3.1917, 3.1062, 3.2718, 3.1982],\n",
      "        [3.1162, 3.1510, 3.2083, 3.2178, 3.2003],\n",
      "        [3.5558, 3.4307, 3.5214, 3.6913, 3.6139],\n",
      "        [3.0959, 3.2386, 3.1597, 3.1761, 3.2230],\n",
      "        [3.0305, 3.1822, 3.1402, 3.1009, 3.1816],\n",
      "        [3.4202, 3.6012, 3.4272, 3.5796, 3.5651],\n",
      "        [3.3277, 3.3662, 3.2268, 3.4493, 3.4796],\n",
      "        [3.4193, 3.5594, 3.3211, 3.4013, 3.4590],\n",
      "        [3.0394, 3.1886, 3.0417, 3.1960, 3.1357],\n",
      "        [3.0758, 3.2518, 3.2517, 3.2009, 3.2181],\n",
      "        [3.4013, 3.4587, 3.4911, 3.5870, 3.4253],\n",
      "        [3.2841, 3.6068, 3.3922, 3.5235, 3.5458]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[2.9971, 3.1542, 3.1980, 3.1322, 3.2242],\n",
      "        [3.3554, 3.1882, 3.2265, 3.2850, 3.3589],\n",
      "        [3.1294, 3.3530, 3.1510, 3.2843, 3.1989],\n",
      "        [3.4056, 3.3595, 3.3590, 3.3238, 3.2910],\n",
      "        [3.3156, 3.2337, 3.5259, 3.3992, 3.4693],\n",
      "        [3.3878, 3.2138, 3.2245, 3.2697, 3.4046],\n",
      "        [3.3793, 3.4758, 3.4595, 3.5751, 3.4257],\n",
      "        [3.1984, 3.4586, 3.4005, 3.2588, 3.4132],\n",
      "        [3.3816, 3.4184, 3.4507, 3.4837, 3.3406],\n",
      "        [3.3250, 3.6162, 3.4863, 3.4882, 3.6259],\n",
      "        [3.2255, 3.2223, 3.3330, 3.2986, 3.3118],\n",
      "        [3.1322, 3.3475, 3.4590, 3.2850, 3.4063],\n",
      "        [3.4382, 3.5045, 3.5097, 3.4907, 3.7085],\n",
      "        [3.2704, 3.3961, 3.2245, 3.2825, 3.3627],\n",
      "        [3.1915, 3.2363, 3.4122, 3.1648, 3.4706],\n",
      "        [3.3518, 3.3060, 3.3919, 3.4197, 3.3745],\n",
      "        [3.1862, 3.2886, 3.2770, 3.3447, 3.3607],\n",
      "        [3.3635, 3.4839, 3.3343, 3.3948, 3.4351],\n",
      "        [3.2131, 3.3176, 3.2535, 3.2754, 3.3188],\n",
      "        [3.3075, 3.4558, 3.3849, 3.3772, 3.2924],\n",
      "        [3.8545, 4.0122, 3.6325, 3.7130, 3.6275],\n",
      "        [3.2419, 3.2561, 3.3525, 3.3449, 3.3543],\n",
      "        [3.2492, 3.3584, 3.1806, 3.3669, 3.3304],\n",
      "        [3.4906, 3.4976, 3.4868, 3.6229, 3.4944],\n",
      "        [3.5174, 3.4914, 3.4225, 3.5439, 3.5644],\n",
      "        [3.3180, 3.2774, 3.3601, 3.2822, 3.3072],\n",
      "        [3.2258, 3.3153, 3.2106, 3.3018, 3.3351],\n",
      "        [3.1575, 3.2101, 3.2841, 3.2988, 3.3148],\n",
      "        [3.0569, 3.1997, 3.0472, 3.2039, 3.1431],\n",
      "        [3.1982, 3.4642, 3.3216, 3.2902, 3.2450],\n",
      "        [3.3828, 3.5214, 3.3737, 3.4679, 3.4682],\n",
      "        [3.2098, 3.3192, 3.3277, 3.3358, 3.3091],\n",
      "        [3.0830, 3.2596, 3.2531, 3.2018, 3.2238],\n",
      "        [3.1214, 3.3553, 3.4538, 3.3009, 3.3868],\n",
      "        [3.3384, 3.4362, 3.3295, 3.2936, 3.3806],\n",
      "        [3.2266, 3.2451, 3.3044, 3.3125, 3.3264],\n",
      "        [3.4307, 3.6116, 3.4194, 3.3293, 3.4647],\n",
      "        [3.3638, 3.4925, 3.4504, 3.4077, 3.3186],\n",
      "        [3.2280, 3.3357, 3.1778, 3.3331, 3.3111],\n",
      "        [3.1883, 3.3976, 3.3813, 3.3186, 3.3753],\n",
      "        [3.2379, 3.2101, 3.3438, 3.3428, 3.4290],\n",
      "        [3.3680, 3.4676, 3.4474, 3.5593, 3.4229],\n",
      "        [3.2897, 3.5255, 3.3882, 3.4310, 3.5432],\n",
      "        [3.2889, 3.2275, 3.3263, 3.3388, 3.3295],\n",
      "        [3.2175, 3.2467, 3.2991, 3.3057, 3.3239],\n",
      "        [3.2135, 3.2755, 3.4285, 3.4206, 3.3912],\n",
      "        [3.3796, 3.5303, 3.3226, 3.3862, 3.4667],\n",
      "        [3.2230, 3.2365, 3.2959, 3.3066, 3.3223],\n",
      "        [3.2278, 3.4093, 3.3142, 3.2732, 3.4044],\n",
      "        [3.2635, 3.4075, 3.2537, 3.2802, 3.3812],\n",
      "        [3.0848, 3.2619, 3.4055, 3.2015, 3.3942],\n",
      "        [3.1251, 3.1399, 3.2041, 3.2276, 3.1989],\n",
      "        [3.2912, 3.5726, 3.4350, 3.4488, 3.5513],\n",
      "        [3.3218, 3.6379, 3.4098, 3.5648, 3.5627],\n",
      "        [3.4351, 3.4982, 3.4762, 3.4870, 3.6642],\n",
      "        [3.2158, 3.1946, 3.2879, 3.2464, 3.2710],\n",
      "        [3.3195, 3.5230, 3.4439, 3.4365, 3.4114],\n",
      "        [3.2571, 3.2203, 3.3667, 3.3691, 3.4379],\n",
      "        [3.5599, 3.5081, 3.4638, 3.5821, 3.5921],\n",
      "        [3.2411, 3.3432, 3.3089, 3.3307, 3.3743],\n",
      "        [3.5305, 3.3259, 3.3864, 3.8287, 3.6616],\n",
      "        [3.3205, 3.2964, 3.3645, 3.2974, 3.2869],\n",
      "        [3.2510, 3.2494, 3.3675, 3.3645, 3.3867],\n",
      "        [3.3786, 3.4965, 3.4604, 3.4138, 3.3180]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.1325, 3.3575, 3.1534, 3.2882, 3.2022],\n",
      "        [3.2667, 3.4467, 3.3252, 3.4743, 3.3564],\n",
      "        [3.2253, 3.3265, 3.2635, 3.2889, 3.3330],\n",
      "        [3.2027, 3.4878, 3.4075, 3.3906, 3.4910],\n",
      "        [3.2466, 3.2225, 3.3567, 3.3551, 3.4364],\n",
      "        [3.1169, 3.4295, 3.2931, 3.1239, 3.4070],\n",
      "        [3.1218, 3.2600, 3.1664, 3.2142, 3.2457],\n",
      "        [3.5253, 3.4734, 3.4722, 3.5496, 3.5503],\n",
      "        [3.1196, 3.2774, 3.2014, 3.2939, 3.2409],\n",
      "        [3.3725, 3.4677, 3.3614, 3.3463, 3.4136],\n",
      "        [3.1699, 3.2162, 3.2838, 3.2944, 3.3191],\n",
      "        [3.2398, 3.1774, 3.2796, 3.2234, 3.2439],\n",
      "        [3.4302, 3.3833, 3.4542, 3.5214, 3.4457],\n",
      "        [3.5824, 3.4635, 3.5476, 3.7116, 3.5987],\n",
      "        [3.3193, 3.1739, 3.4396, 3.3932, 3.3943],\n",
      "        [3.0960, 3.4697, 3.3555, 3.2726, 3.4895],\n",
      "        [3.3180, 3.1421, 3.4492, 3.3795, 3.3657],\n",
      "        [3.2247, 3.2367, 3.3038, 3.3009, 3.3237],\n",
      "        [3.3042, 3.3955, 3.4862, 3.4170, 3.4770],\n",
      "        [3.3618, 3.3195, 3.3956, 3.4269, 3.3844],\n",
      "        [3.2377, 3.3110, 3.2397, 3.3499, 3.4405],\n",
      "        [3.2158, 3.3487, 3.3167, 3.2727, 3.2490],\n",
      "        [3.3896, 3.5725, 3.5463, 3.5090, 3.3828],\n",
      "        [3.2590, 3.5919, 3.3869, 3.4862, 3.5447],\n",
      "        [3.0875, 3.1532, 3.2010, 3.1874, 3.1633],\n",
      "        [3.2618, 3.2708, 3.3731, 3.3371, 3.3861],\n",
      "        [3.2378, 3.2438, 3.3185, 3.3094, 3.3345],\n",
      "        [3.3361, 3.5716, 3.4820, 3.4776, 3.6417],\n",
      "        [3.1410, 3.1801, 3.1081, 3.2742, 3.1688],\n",
      "        [3.2380, 3.2722, 3.3432, 3.3503, 3.3648],\n",
      "        [3.2373, 3.2510, 3.3615, 3.3459, 3.3588],\n",
      "        [3.1021, 3.2472, 3.1646, 3.1822, 3.2299],\n",
      "        [3.3738, 3.5129, 3.3412, 3.5682, 3.4958],\n",
      "        [3.1471, 3.2522, 3.3050, 3.2783, 3.2251],\n",
      "        [3.3978, 3.3729, 3.5371, 3.3874, 3.3116],\n",
      "        [3.2165, 3.2803, 3.4311, 3.4243, 3.3946],\n",
      "        [3.0966, 3.2078, 3.2369, 3.2091, 3.2161],\n",
      "        [3.1006, 3.2469, 3.1653, 3.1870, 3.2321],\n",
      "        [3.4499, 3.5710, 3.5206, 3.5747, 3.6136],\n",
      "        [3.3705, 3.4018, 3.4697, 3.3978, 3.2885],\n",
      "        [3.2237, 3.2038, 3.3309, 3.2269, 3.3706],\n",
      "        [3.2098, 3.3057, 3.2074, 3.2953, 3.3195],\n",
      "        [3.2356, 3.2832, 3.4087, 3.4478, 3.5330],\n",
      "        [3.0557, 3.2073, 3.1536, 3.1295, 3.2075],\n",
      "        [3.2149, 3.2520, 3.3118, 3.1934, 3.1386],\n",
      "        [3.3793, 3.5833, 3.3864, 3.2917, 3.4686],\n",
      "        [3.2126, 3.2555, 3.3052, 3.3185, 3.3301],\n",
      "        [3.5613, 3.4904, 3.5719, 3.7117, 3.5996],\n",
      "        [3.1055, 3.3147, 3.3794, 3.2468, 3.3498],\n",
      "        [3.3138, 3.4980, 3.3660, 3.5246, 3.4475],\n",
      "        [3.2581, 3.4698, 3.3538, 3.3431, 3.2592],\n",
      "        [3.5247, 3.5548, 3.4401, 3.5590, 3.6588],\n",
      "        [3.2458, 3.2441, 3.3365, 3.2772, 3.3236],\n",
      "        [3.1455, 3.4497, 3.4174, 3.3144, 3.4933],\n",
      "        [3.3882, 3.5094, 3.3194, 3.4037, 3.4901],\n",
      "        [3.3363, 3.3232, 3.3837, 3.3234, 3.2931],\n",
      "        [3.2148, 3.2298, 3.3203, 3.3250, 3.4005],\n",
      "        [3.4534, 3.2185, 3.3744, 3.6477, 3.6472],\n",
      "        [3.1133, 3.1957, 3.2342, 3.2219, 3.2300],\n",
      "        [3.2688, 3.2819, 3.3145, 3.3464, 3.3656],\n",
      "        [3.0953, 3.2972, 3.2743, 3.2265, 3.2544],\n",
      "        [3.2288, 3.3199, 3.2131, 3.3054, 3.3385],\n",
      "        [3.3520, 3.4710, 3.3781, 3.4668, 3.5957],\n",
      "        [3.2125, 3.2113, 3.3121, 3.2983, 3.3018]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4605, 3.4370, 3.5239, 3.5215, 3.3610],\n",
      "        [3.5729, 3.6916, 3.5686, 3.8239, 3.7163],\n",
      "        [3.1636, 3.2894, 3.1799, 3.2404, 3.2859],\n",
      "        [3.2283, 3.3314, 3.2658, 3.2930, 3.3358],\n",
      "        [3.6378, 3.4311, 3.5857, 4.0081, 3.9240],\n",
      "        [3.3870, 3.4838, 3.4398, 3.3706, 3.4664],\n",
      "        [3.1153, 3.2524, 3.2942, 3.2538, 3.2416],\n",
      "        [3.2509, 3.3606, 3.1842, 3.3799, 3.3315],\n",
      "        [3.5094, 3.2232, 3.3761, 3.7246, 3.7141],\n",
      "        [3.2320, 3.2574, 3.1922, 3.2802, 3.4009],\n",
      "        [3.1019, 3.3405, 3.2927, 3.2402, 3.2837],\n",
      "        [3.2217, 3.2528, 3.2999, 3.3078, 3.3275],\n",
      "        [3.3393, 3.6082, 3.4909, 3.4794, 3.5707],\n",
      "        [3.1636, 3.2310, 3.2998, 3.3234, 3.3419],\n",
      "        [3.0934, 3.1956, 3.2282, 3.2082, 3.2092],\n",
      "        [3.2287, 3.2488, 3.3049, 3.3085, 3.3314],\n",
      "        [3.4898, 3.4195, 3.3915, 3.4674, 3.5376],\n",
      "        [3.2967, 3.5555, 3.4119, 3.4479, 3.5549],\n",
      "        [3.4474, 3.3065, 3.3522, 3.7007, 3.5723],\n",
      "        [3.5837, 3.6755, 3.5765, 3.8011, 3.6886],\n",
      "        [3.3769, 3.5182, 3.3438, 3.5723, 3.4986],\n",
      "        [3.1790, 3.4271, 3.3260, 3.3379, 3.4943],\n",
      "        [3.2304, 3.2377, 3.3037, 3.3057, 3.3273],\n",
      "        [3.4659, 3.4562, 3.3417, 3.4950, 3.5604],\n",
      "        [3.1641, 3.2452, 3.2586, 3.2234, 3.2651],\n",
      "        [3.2508, 3.4258, 3.2936, 3.2819, 3.4043],\n",
      "        [3.0034, 3.1638, 3.2028, 3.1400, 3.2302],\n",
      "        [3.4405, 3.6215, 3.4554, 3.6124, 3.5811],\n",
      "        [3.5510, 3.6335, 3.5341, 3.5957, 3.7032],\n",
      "        [3.1304, 3.2886, 3.2457, 3.3582, 3.2162],\n",
      "        [3.5423, 3.3379, 3.3899, 3.8293, 3.6741],\n",
      "        [3.0701, 3.2219, 3.1615, 3.1447, 3.2102],\n",
      "        [3.2252, 3.3958, 3.3649, 3.3322, 3.4912],\n",
      "        [3.4056, 3.5551, 3.3287, 3.4004, 3.4683],\n",
      "        [3.2589, 3.3702, 3.3198, 3.3484, 3.3969],\n",
      "        [3.2422, 3.3518, 3.1874, 3.3511, 3.3253],\n",
      "        [3.1162, 3.3520, 3.4417, 3.2841, 3.3803],\n",
      "        [3.3342, 3.5694, 3.4762, 3.4695, 3.6382],\n",
      "        [3.0915, 3.2330, 3.2439, 3.2072, 3.2213],\n",
      "        [3.1707, 3.3074, 3.2792, 3.3820, 3.2607],\n",
      "        [3.1155, 3.2547, 3.2843, 3.2567, 3.2320],\n",
      "        [3.2068, 3.5433, 3.3488, 3.4373, 3.4992],\n",
      "        [3.2177, 3.2513, 3.2650, 3.2710, 3.3730],\n",
      "        [3.5475, 3.4860, 3.5210, 3.5951, 3.6042],\n",
      "        [3.1659, 3.4010, 3.2067, 3.0853, 3.3077],\n",
      "        [3.4625, 3.4556, 3.4840, 3.5687, 3.5143],\n",
      "        [3.5112, 3.4820, 3.5168, 3.5286, 3.7143],\n",
      "        [3.3142, 3.3156, 3.4335, 3.4119, 3.4234],\n",
      "        [3.3820, 3.3404, 3.3555, 3.3020, 3.2726],\n",
      "        [3.2389, 3.3091, 3.3856, 3.3531, 3.4570],\n",
      "        [3.3662, 3.4008, 3.3559, 3.4839, 3.5426],\n",
      "        [3.2362, 3.2425, 3.3136, 3.3075, 3.3290],\n",
      "        [3.1487, 3.4550, 3.4201, 3.3186, 3.4960],\n",
      "        [3.2291, 3.3394, 3.1839, 3.3397, 3.3125],\n",
      "        [3.2605, 3.1907, 3.2920, 3.2245, 3.2525],\n",
      "        [3.3574, 3.5358, 3.4601, 3.4779, 3.5740],\n",
      "        [3.3191, 3.2536, 3.5547, 3.4120, 3.4838],\n",
      "        [3.2758, 3.4178, 3.2512, 3.2942, 3.3810],\n",
      "        [3.5695, 3.4291, 3.4694, 3.9403, 3.8257],\n",
      "        [3.3618, 3.3715, 3.3978, 3.3649, 3.2792],\n",
      "        [3.3091, 3.3807, 3.4158, 3.4004, 3.4221],\n",
      "        [3.4856, 3.6146, 3.3343, 3.4296, 3.4571],\n",
      "        [3.3571, 3.3460, 3.3942, 3.3406, 3.2922],\n",
      "        [3.3708, 3.5104, 3.4714, 3.4057, 3.3449]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2747, 3.4020, 3.1910, 3.2864, 3.3523],\n",
      "        [3.4066, 3.5162, 3.3639, 3.5249, 3.5615],\n",
      "        [3.3778, 3.5194, 3.3401, 3.5673, 3.4908],\n",
      "        [3.2396, 3.3859, 3.3626, 3.3387, 3.3019],\n",
      "        [3.3704, 3.6641, 3.4939, 3.5302, 3.6403],\n",
      "        [3.2537, 3.3652, 3.1864, 3.3843, 3.3348],\n",
      "        [3.2820, 3.4119, 3.2278, 3.3032, 3.3765],\n",
      "        [3.4406, 3.4663, 3.4568, 3.4893, 3.6430],\n",
      "        [3.1825, 3.3534, 3.2213, 3.3816, 3.2626],\n",
      "        [3.1567, 3.1906, 3.2411, 3.2512, 3.2205],\n",
      "        [3.5260, 3.5062, 3.4298, 3.5569, 3.5740],\n",
      "        [3.3167, 3.4707, 3.3923, 3.3895, 3.3022],\n",
      "        [3.3730, 3.4965, 3.3488, 3.5233, 3.6089],\n",
      "        [3.2749, 3.2897, 3.3892, 3.3561, 3.3981],\n",
      "        [3.5453, 3.3427, 3.3922, 3.8337, 3.6775],\n",
      "        [3.3387, 3.4471, 3.4554, 3.4368, 3.4525],\n",
      "        [3.1530, 3.2616, 3.3095, 3.2869, 3.2313],\n",
      "        [3.5851, 3.7347, 3.4721, 3.4906, 3.5072],\n",
      "        [3.5353, 3.5253, 3.4613, 3.5689, 3.6020],\n",
      "        [3.2538, 3.4305, 3.2959, 3.2864, 3.4078],\n",
      "        [3.1465, 3.2418, 3.1801, 3.2634, 3.2310],\n",
      "        [3.4897, 3.5708, 3.4998, 3.5229, 3.5889],\n",
      "        [3.4075, 3.3911, 3.4976, 3.4257, 3.2875],\n",
      "        [3.2490, 3.3236, 3.2247, 3.3842, 3.3378],\n",
      "        [3.1305, 3.1881, 3.2479, 3.2404, 3.1971],\n",
      "        [3.0563, 3.2092, 3.1526, 3.1341, 3.2025],\n",
      "        [3.2204, 3.2617, 3.3162, 3.2014, 3.1445],\n",
      "        [3.1996, 3.2627, 3.2529, 3.2435, 3.3006],\n",
      "        [3.3135, 3.4571, 3.3253, 3.4335, 3.4086],\n",
      "        [3.3174, 3.3623, 3.4241, 3.4242, 3.4017],\n",
      "        [3.1441, 3.1810, 3.1121, 3.2858, 3.1996],\n",
      "        [3.4498, 3.4606, 3.4941, 3.4186, 3.2973],\n",
      "        [3.0694, 3.2260, 3.1599, 3.1578, 3.2170],\n",
      "        [3.3067, 3.2368, 3.5449, 3.3932, 3.4560],\n",
      "        [3.2367, 3.3498, 3.1849, 3.3450, 3.3205],\n",
      "        [3.2357, 3.2598, 3.3116, 3.3246, 3.3358],\n",
      "        [3.0817, 3.1516, 3.1683, 3.1702, 3.1909],\n",
      "        [3.2996, 3.5395, 3.4404, 3.4215, 3.3877],\n",
      "        [3.4967, 3.4567, 3.4961, 3.5177, 3.6880],\n",
      "        [3.3350, 3.3849, 3.2337, 3.3784, 3.4692],\n",
      "        [3.3155, 3.5376, 3.3415, 3.2325, 3.4495],\n",
      "        [3.4843, 3.4682, 3.4826, 3.6092, 3.5288],\n",
      "        [3.2234, 3.3852, 3.3376, 3.3359, 3.3513],\n",
      "        [3.2209, 3.3566, 3.2788, 3.3732, 3.3917],\n",
      "        [3.2193, 3.3833, 3.2263, 3.4344, 3.2648],\n",
      "        [3.2236, 3.2517, 3.2985, 3.3080, 3.3275],\n",
      "        [3.0895, 3.3304, 3.2870, 3.2204, 3.2619],\n",
      "        [3.1023, 3.3436, 3.2994, 3.2312, 3.2722],\n",
      "        [3.1328, 3.1213, 3.1930, 3.2428, 3.1873],\n",
      "        [3.4419, 3.4212, 3.4458, 3.4656, 3.6432],\n",
      "        [3.1271, 3.3098, 3.1533, 3.2830, 3.2400],\n",
      "        [3.4423, 3.5519, 3.4511, 3.4957, 3.5986],\n",
      "        [3.2870, 3.4134, 3.2244, 3.3027, 3.3713],\n",
      "        [3.3217, 3.3835, 3.4206, 3.4143, 3.3895],\n",
      "        [3.6381, 3.7605, 3.3631, 3.5271, 3.4327],\n",
      "        [3.5081, 3.5475, 3.4595, 3.6776, 3.5906],\n",
      "        [3.1507, 3.3897, 3.3073, 3.3131, 3.4774],\n",
      "        [3.2320, 3.2511, 3.3030, 3.3187, 3.3317],\n",
      "        [3.4478, 3.4665, 3.5932, 3.4188, 3.3409],\n",
      "        [3.1374, 3.1368, 3.2000, 3.2502, 3.1945],\n",
      "        [3.2634, 3.1953, 3.2942, 3.2288, 3.2559],\n",
      "        [3.2869, 3.4956, 3.2978, 3.1984, 3.3514],\n",
      "        [3.4271, 3.6134, 3.4418, 3.6013, 3.5682],\n",
      "        [3.2078, 3.2428, 3.2575, 3.2646, 3.3586]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.1643, 3.3303, 3.2088, 3.3608, 3.2570],\n",
      "        [3.7146, 3.8645, 3.5787, 3.6207, 3.6054],\n",
      "        [3.4240, 3.3148, 3.3469, 3.6446, 3.5303],\n",
      "        [3.3478, 3.2079, 3.4720, 3.4162, 3.4154],\n",
      "        [3.0807, 3.3593, 3.2182, 3.0641, 3.2885],\n",
      "        [3.5283, 3.5192, 3.5358, 3.6630, 3.5897],\n",
      "        [3.1947, 3.1793, 3.2928, 3.2753, 3.2705],\n",
      "        [3.2645, 3.3790, 3.3241, 3.3577, 3.4034],\n",
      "        [3.3939, 3.5782, 3.4011, 3.4774, 3.4899],\n",
      "        [3.1268, 3.2310, 3.2499, 3.2333, 3.2537],\n",
      "        [3.2883, 3.4540, 3.4520, 3.4517, 3.4360],\n",
      "        [3.1401, 3.1409, 3.2020, 3.2548, 3.1974],\n",
      "        [3.1584, 3.3048, 3.3696, 3.3228, 3.4173],\n",
      "        [3.2559, 3.3687, 3.1865, 3.3738, 3.3325],\n",
      "        [3.3528, 3.6443, 3.4693, 3.5139, 3.6579],\n",
      "        [3.1870, 3.1400, 3.1827, 3.2558, 3.1935],\n",
      "        [3.1740, 3.1380, 3.2620, 3.2768, 3.3261],\n",
      "        [3.4144, 3.5206, 3.4578, 3.3968, 3.4896],\n",
      "        [3.2800, 3.4397, 3.3100, 3.4205, 3.3654],\n",
      "        [3.1381, 3.2647, 3.3181, 3.2835, 3.2239],\n",
      "        [3.5273, 3.4843, 3.4652, 3.5657, 3.5511],\n",
      "        [3.3964, 3.5427, 3.4510, 3.5038, 3.4721],\n",
      "        [3.3876, 3.4615, 3.4368, 3.4309, 3.5479],\n",
      "        [3.1417, 3.1522, 3.2094, 3.2541, 3.2144],\n",
      "        [3.4155, 3.5212, 3.3430, 3.4392, 3.5352],\n",
      "        [3.1593, 3.2462, 3.1788, 3.2836, 3.2368],\n",
      "        [3.1832, 3.3502, 3.2593, 3.3728, 3.2906],\n",
      "        [3.3804, 3.5251, 3.3473, 3.5806, 3.5019],\n",
      "        [3.1939, 3.2997, 3.3078, 3.3259, 3.2705],\n",
      "        [3.0942, 3.2588, 3.2544, 3.2171, 3.2307],\n",
      "        [3.2168, 3.2026, 3.3134, 3.2962, 3.2976],\n",
      "        [3.2345, 3.2368, 3.3230, 3.3154, 3.3167],\n",
      "        [3.8571, 4.0259, 3.6380, 3.7190, 3.6419],\n",
      "        [3.3628, 3.5319, 3.4619, 3.4964, 3.5419],\n",
      "        [3.2214, 3.2453, 3.2541, 3.3561, 3.2568],\n",
      "        [3.4042, 3.5750, 3.4934, 3.4970, 3.4695],\n",
      "        [3.2287, 3.2120, 3.3031, 3.3218, 3.4357],\n",
      "        [3.2542, 3.3619, 3.1815, 3.3659, 3.3217],\n",
      "        [3.1868, 3.2548, 3.2629, 3.2357, 3.2951],\n",
      "        [3.6262, 3.4275, 3.5323, 3.9935, 3.8566],\n",
      "        [3.3529, 3.6091, 3.4161, 3.4878, 3.5025],\n",
      "        [3.2100, 3.4823, 3.4084, 3.2771, 3.4290],\n",
      "        [3.2117, 3.5021, 3.4150, 3.4043, 3.5003],\n",
      "        [3.3835, 3.5017, 3.3624, 3.4391, 3.4355],\n",
      "        [3.2745, 3.2630, 3.3859, 3.4126, 3.3747],\n",
      "        [3.2128, 3.3042, 3.2963, 3.3299, 3.4489],\n",
      "        [3.2566, 3.4348, 3.2981, 3.2912, 3.4109],\n",
      "        [3.1355, 3.1413, 3.1994, 3.2487, 3.2002],\n",
      "        [3.3561, 3.3269, 3.3260, 3.5390, 3.4500],\n",
      "        [3.1446, 3.1355, 3.1947, 3.2518, 3.2066],\n",
      "        [3.2029, 3.3060, 3.2877, 3.3487, 3.4038],\n",
      "        [3.1733, 3.2996, 3.1770, 3.2622, 3.2861],\n",
      "        [3.3683, 3.5847, 3.3781, 3.2816, 3.4682],\n",
      "        [3.2598, 3.4769, 3.3535, 3.3509, 3.2661],\n",
      "        [3.0879, 3.2466, 3.1703, 3.1794, 3.2305],\n",
      "        [3.2350, 3.3999, 3.2842, 3.3606, 3.4197],\n",
      "        [3.1693, 3.5049, 3.3212, 3.3815, 3.4638],\n",
      "        [3.2390, 3.2730, 3.3136, 3.3314, 3.3434],\n",
      "        [3.4633, 3.5550, 3.4025, 3.5068, 3.6170],\n",
      "        [3.1203, 3.2081, 3.2582, 3.2456, 3.2062],\n",
      "        [3.2778, 3.3634, 3.3395, 3.3511, 3.3812],\n",
      "        [3.2344, 3.2875, 3.3198, 3.3390, 3.3500],\n",
      "        [3.3593, 3.3306, 3.3857, 3.4221, 3.3722],\n",
      "        [3.2754, 3.4267, 3.2634, 3.2972, 3.3940]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2085, 3.3219, 3.1802, 3.3080, 3.3064],\n",
      "        [3.2084, 3.3633, 3.2509, 3.3560, 3.4002],\n",
      "        [3.1719, 3.4574, 3.2875, 3.2509, 3.2313],\n",
      "        [3.2397, 3.2450, 3.3439, 3.3197, 3.3268],\n",
      "        [3.1336, 3.1773, 3.2218, 3.2412, 3.2188],\n",
      "        [3.4176, 3.3057, 3.3294, 3.6990, 3.5396],\n",
      "        [3.2161, 3.4015, 3.3307, 3.3386, 3.3718],\n",
      "        [3.3608, 3.4604, 3.4697, 3.4381, 3.4546],\n",
      "        [3.1905, 3.4715, 3.3050, 3.2723, 3.2476],\n",
      "        [3.7614, 3.9477, 3.5706, 3.6674, 3.5653],\n",
      "        [3.2038, 3.3043, 3.2222, 3.2506, 3.2803],\n",
      "        [3.3515, 3.6059, 3.4113, 3.4673, 3.4987],\n",
      "        [3.3016, 3.3716, 3.3769, 3.3668, 3.4830],\n",
      "        [3.4742, 3.4688, 3.3481, 3.5085, 3.5702],\n",
      "        [3.3495, 3.3304, 3.3614, 3.2760, 3.2317],\n",
      "        [3.5255, 3.5608, 3.4447, 3.5912, 3.6530],\n",
      "        [3.2420, 3.2899, 3.3247, 3.3470, 3.3642],\n",
      "        [3.1635, 3.4585, 3.3187, 3.1505, 3.4108],\n",
      "        [3.6030, 3.6912, 3.6022, 3.8351, 3.7157],\n",
      "        [3.3411, 3.4250, 3.4074, 3.4648, 3.5236],\n",
      "        [3.4568, 3.5401, 3.5428, 3.4822, 3.3971],\n",
      "        [3.3476, 3.3412, 3.3924, 3.3412, 3.3051],\n",
      "        [3.2904, 3.3020, 3.4075, 3.3878, 3.4076],\n",
      "        [3.1427, 3.1446, 3.2039, 3.2591, 3.2001],\n",
      "        [3.2812, 3.3338, 3.3895, 3.3901, 3.4881],\n",
      "        [3.2264, 3.3647, 3.2829, 3.3822, 3.3976],\n",
      "        [3.0933, 3.3369, 3.3941, 3.2490, 3.3489],\n",
      "        [3.2513, 3.1951, 3.2881, 3.2408, 3.2557],\n",
      "        [3.2780, 3.2455, 3.4281, 3.4316, 3.3666],\n",
      "        [3.2743, 3.4610, 3.3248, 3.3558, 3.4411],\n",
      "        [3.2477, 3.3611, 3.1815, 3.3636, 3.3278],\n",
      "        [3.3140, 3.3500, 3.3321, 3.4544, 3.3836],\n",
      "        [3.3139, 3.3971, 3.2859, 3.4237, 3.4174],\n",
      "        [3.3002, 3.3247, 3.4165, 3.4305, 3.3658],\n",
      "        [3.3170, 3.3206, 3.4348, 3.4218, 3.4303],\n",
      "        [3.3659, 3.4908, 3.4376, 3.5647, 3.4383],\n",
      "        [3.3967, 3.5821, 3.4031, 3.4818, 3.4928],\n",
      "        [3.1720, 3.5087, 3.3233, 3.3858, 3.4666],\n",
      "        [3.2194, 3.2064, 3.3153, 3.3004, 3.3003],\n",
      "        [3.3746, 3.4139, 3.3622, 3.4985, 3.5521],\n",
      "        [3.2332, 3.2889, 3.3936, 3.2626, 3.4957],\n",
      "        [3.0712, 3.2352, 3.1672, 3.1616, 3.2190],\n",
      "        [3.1813, 3.2674, 3.0953, 3.3529, 3.1799],\n",
      "        [3.2697, 3.4882, 3.3627, 3.3606, 3.2716],\n",
      "        [3.3611, 3.6697, 3.5100, 3.5279, 3.6172],\n",
      "        [3.1309, 3.1314, 3.1910, 3.2451, 3.1938],\n",
      "        [3.2454, 3.3016, 3.3358, 3.3590, 3.3702],\n",
      "        [3.0953, 3.2979, 3.2695, 3.2248, 3.2447],\n",
      "        [3.2453, 3.2228, 3.3455, 3.3463, 3.4377],\n",
      "        [3.2814, 3.2932, 3.3942, 3.3765, 3.3990],\n",
      "        [3.2355, 3.2403, 3.3266, 3.3136, 3.3179],\n",
      "        [3.1840, 3.3083, 3.2186, 3.2897, 3.3195],\n",
      "        [3.1906, 3.3155, 3.1741, 3.2963, 3.2816],\n",
      "        [3.2290, 3.2598, 3.3025, 3.3171, 3.3332],\n",
      "        [3.5248, 3.6267, 3.5211, 3.5884, 3.6769],\n",
      "        [3.2395, 3.2162, 3.3347, 3.3388, 3.4324],\n",
      "        [3.2351, 3.2216, 3.3393, 3.2446, 3.3825],\n",
      "        [3.3550, 3.5494, 3.4797, 3.4853, 3.4417],\n",
      "        [3.2449, 3.2350, 3.2238, 3.3928, 3.2489],\n",
      "        [3.2347, 3.2214, 3.3348, 3.2405, 3.3836],\n",
      "        [3.5772, 3.6481, 3.5715, 3.7806, 3.6286],\n",
      "        [3.3717, 3.5010, 3.3607, 3.4584, 3.4330],\n",
      "        [3.4511, 3.5107, 3.4937, 3.5208, 3.7200],\n",
      "        [3.3860, 3.3418, 3.3282, 3.6320, 3.5250]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2556, 3.4530, 3.3136, 3.4666, 3.3536],\n",
      "        [3.3420, 3.3142, 3.3462, 3.2981, 3.2262],\n",
      "        [3.2000, 3.2750, 3.2702, 3.2589, 3.3043],\n",
      "        [3.3951, 3.3683, 3.3665, 3.3272, 3.2953],\n",
      "        [3.1166, 3.2224, 3.2436, 3.2315, 3.2314],\n",
      "        [3.1617, 3.2171, 3.1290, 3.3172, 3.2363],\n",
      "        [3.3684, 3.4174, 3.3957, 3.3894, 3.2308],\n",
      "        [3.4767, 3.6342, 3.6047, 3.5596, 3.4239],\n",
      "        [3.1023, 3.3296, 3.2891, 3.2450, 3.2744],\n",
      "        [3.3688, 3.4577, 3.3165, 3.3990, 3.5529],\n",
      "        [3.1330, 3.2794, 3.1761, 3.2233, 3.2520],\n",
      "        [3.3303, 3.2711, 3.5631, 3.4299, 3.4958],\n",
      "        [3.5319, 3.4472, 3.5191, 3.6707, 3.5505],\n",
      "        [3.3494, 3.3986, 3.2440, 3.3964, 3.4896],\n",
      "        [3.2444, 3.2812, 3.3174, 3.3397, 3.3487],\n",
      "        [3.2753, 3.3899, 3.1957, 3.3987, 3.3466],\n",
      "        [3.3806, 3.5976, 3.3890, 3.4872, 3.4885],\n",
      "        [3.1201, 3.3372, 3.3901, 3.2689, 3.3647],\n",
      "        [3.1345, 3.2491, 3.2783, 3.2586, 3.2361],\n",
      "        [3.4176, 3.5093, 3.4645, 3.4175, 3.4917],\n",
      "        [3.2420, 3.2895, 3.3433, 3.3551, 3.3677],\n",
      "        [3.2403, 3.4081, 3.2881, 3.3689, 3.4251],\n",
      "        [3.3206, 3.5328, 3.4015, 3.3754, 3.4745],\n",
      "        [3.3469, 3.6930, 3.4379, 3.6029, 3.6018],\n",
      "        [3.1091, 3.3434, 3.2925, 3.2509, 3.2828],\n",
      "        [3.4433, 3.4791, 3.4253, 3.4732, 3.5364],\n",
      "        [3.2327, 3.3487, 3.1947, 3.3402, 3.3269],\n",
      "        [3.0642, 3.1551, 3.1593, 3.1511, 3.1818],\n",
      "        [3.2484, 3.2616, 3.3284, 3.3290, 3.3398],\n",
      "        [3.1700, 3.5265, 3.3548, 3.3747, 3.5191],\n",
      "        [3.8103, 4.0094, 3.5754, 3.6889, 3.6326],\n",
      "        [3.2644, 3.3362, 3.3520, 3.3341, 3.5674],\n",
      "        [3.3159, 3.5355, 3.3633, 3.5387, 3.4648],\n",
      "        [3.4223, 3.4204, 3.4259, 3.4895, 3.6366],\n",
      "        [3.4610, 3.4875, 3.4308, 3.4981, 3.5396],\n",
      "        [3.2726, 3.3707, 3.3402, 3.3322, 3.3889],\n",
      "        [3.2745, 3.3813, 3.1989, 3.3937, 3.3398],\n",
      "        [3.4261, 3.4828, 3.4282, 3.5386, 3.6278],\n",
      "        [3.2065, 3.3212, 3.1765, 3.3128, 3.2829],\n",
      "        [3.4035, 3.2399, 3.2372, 3.2957, 3.4220],\n",
      "        [3.1384, 3.2000, 3.2535, 3.2535, 3.2054],\n",
      "        [3.1035, 3.3371, 3.2603, 3.2737, 3.4233],\n",
      "        [3.2082, 3.1905, 3.2494, 3.2805, 3.4125],\n",
      "        [3.1043, 3.2322, 3.2436, 3.2246, 3.2290],\n",
      "        [3.2215, 3.3953, 3.3344, 3.3433, 3.3714],\n",
      "        [3.3832, 3.2677, 3.2527, 3.3022, 3.4372],\n",
      "        [3.4163, 3.5684, 3.3351, 3.4167, 3.4786],\n",
      "        [3.2805, 3.3891, 3.3389, 3.3815, 3.4245],\n",
      "        [3.3828, 3.4495, 3.4520, 3.4330, 3.4632],\n",
      "        [3.2981, 3.3020, 3.4270, 3.5049, 3.5826],\n",
      "        [3.2419, 3.3209, 3.3271, 3.3261, 3.5206],\n",
      "        [3.2067, 3.3810, 3.2312, 3.4223, 3.2765],\n",
      "        [3.1865, 3.3177, 3.1873, 3.2678, 3.2963],\n",
      "        [3.3151, 3.2967, 3.4353, 3.5466, 3.6150],\n",
      "        [3.4430, 3.5089, 3.4984, 3.5031, 3.7026],\n",
      "        [3.2099, 3.3906, 3.2339, 3.4207, 3.2785],\n",
      "        [3.4131, 3.2305, 3.2224, 3.2929, 3.4287],\n",
      "        [3.2562, 3.3742, 3.3326, 3.3329, 3.3775],\n",
      "        [3.0491, 3.2099, 3.1571, 3.1232, 3.1954],\n",
      "        [3.2278, 3.2741, 3.3219, 3.2139, 3.1527],\n",
      "        [3.2250, 3.2110, 3.3396, 3.2132, 3.3897],\n",
      "        [3.2805, 3.2498, 3.4300, 3.4356, 3.3691],\n",
      "        [3.2718, 3.3866, 3.2096, 3.3942, 3.3548],\n",
      "        [3.2447, 3.2545, 3.3170, 3.3254, 3.3393]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2240, 3.2851, 3.4170, 3.2397, 3.4878],\n",
      "        [3.3810, 3.4283, 3.4085, 3.4036, 3.2550],\n",
      "        [3.2669, 3.3401, 3.3538, 3.3379, 3.5697],\n",
      "        [3.3644, 3.4289, 3.2706, 3.4697, 3.4951],\n",
      "        [3.2125, 3.3943, 3.2356, 3.4243, 3.2808],\n",
      "        [3.3484, 3.3391, 3.3693, 3.4043, 3.3685],\n",
      "        [3.7639, 3.9212, 3.6061, 3.6786, 3.6323],\n",
      "        [3.1218, 3.2126, 3.2387, 3.2355, 3.2303],\n",
      "        [3.3573, 3.5140, 3.3349, 3.4160, 3.4451],\n",
      "        [3.2287, 3.5368, 3.4186, 3.4271, 3.5417],\n",
      "        [3.6136, 3.6925, 3.5962, 3.8306, 3.7039],\n",
      "        [3.0296, 3.1905, 3.2109, 3.1780, 3.2407],\n",
      "        [3.2664, 3.4387, 3.3261, 3.3237, 3.4339],\n",
      "        [3.2376, 3.2730, 3.3206, 3.3442, 3.3547],\n",
      "        [3.2746, 3.4459, 3.2594, 3.5073, 3.3079],\n",
      "        [3.4521, 3.5960, 3.4741, 3.3984, 3.5359],\n",
      "        [3.1772, 3.5170, 3.3272, 3.3934, 3.4714],\n",
      "        [3.2512, 3.3674, 3.1987, 3.3701, 3.3370],\n",
      "        [3.2624, 3.2501, 3.3688, 3.3835, 3.4556],\n",
      "        [3.3907, 3.5396, 3.3541, 3.5939, 3.5131],\n",
      "        [3.4058, 3.2437, 3.2389, 3.2994, 3.4242],\n",
      "        [3.1523, 3.2007, 3.2475, 3.2647, 3.2150],\n",
      "        [3.2498, 3.2589, 3.3814, 3.3739, 3.3620],\n",
      "        [3.3379, 3.3129, 3.4735, 3.4923, 3.3700],\n",
      "        [3.2197, 3.2619, 3.3240, 3.3487, 3.4207],\n",
      "        [3.2858, 3.4096, 3.1967, 3.3042, 3.3590],\n",
      "        [3.4112, 3.5355, 3.3395, 3.4349, 3.5181],\n",
      "        [3.1910, 3.3933, 3.3168, 3.2267, 3.2773],\n",
      "        [3.1046, 3.2921, 3.4204, 3.2303, 3.4137],\n",
      "        [3.2173, 3.6080, 3.4673, 3.3638, 3.3774],\n",
      "        [3.3765, 3.2723, 3.2466, 3.3033, 3.4326],\n",
      "        [3.2706, 3.6243, 3.4621, 3.3639, 3.4049],\n",
      "        [3.0494, 3.2251, 3.2053, 3.2051, 3.2484],\n",
      "        [3.3884, 3.5374, 3.3531, 3.5927, 3.5098],\n",
      "        [3.1405, 3.1812, 3.2241, 3.2499, 3.2247],\n",
      "        [3.3232, 3.3909, 3.2938, 3.4485, 3.4204],\n",
      "        [3.5723, 3.6679, 3.5614, 3.6338, 3.7198],\n",
      "        [3.1234, 3.2558, 3.2830, 3.2637, 3.2304],\n",
      "        [3.1525, 3.2030, 3.1106, 3.2985, 3.1506],\n",
      "        [3.2885, 3.4320, 3.2539, 3.3111, 3.3911],\n",
      "        [3.2486, 3.3641, 3.1976, 3.3691, 3.3364],\n",
      "        [3.1415, 3.3861, 3.4690, 3.3300, 3.4067],\n",
      "        [3.4417, 3.4836, 3.4438, 3.4900, 3.6671],\n",
      "        [3.3685, 3.5140, 3.4602, 3.5015, 3.4976],\n",
      "        [3.4246, 3.4955, 3.5097, 3.6193, 3.4500],\n",
      "        [3.4035, 3.4341, 3.4607, 3.5135, 3.3367],\n",
      "        [3.4146, 3.5358, 3.4928, 3.4597, 3.3491],\n",
      "        [3.5602, 3.5077, 3.5312, 3.6188, 3.6186],\n",
      "        [3.2571, 3.3740, 3.2766, 3.4152, 3.3958],\n",
      "        [3.4677, 3.3605, 3.3587, 3.4326, 3.4932],\n",
      "        [3.4111, 3.4970, 3.4919, 3.6079, 3.4470],\n",
      "        [3.2682, 3.3885, 3.1954, 3.3950, 3.3503],\n",
      "        [3.2147, 3.2764, 3.4398, 3.1943, 3.5028],\n",
      "        [3.2330, 3.5639, 3.3527, 3.4623, 3.4981],\n",
      "        [3.3281, 3.3786, 3.4319, 3.4410, 3.4125],\n",
      "        [3.1687, 3.4666, 3.3224, 3.1581, 3.4155],\n",
      "        [3.2272, 3.3285, 3.2172, 3.3453, 3.3006],\n",
      "        [3.2079, 3.4285, 3.3966, 3.3484, 3.3957],\n",
      "        [3.1129, 3.2328, 3.2487, 3.2342, 3.2327],\n",
      "        [3.3523, 3.3969, 3.2400, 3.4706, 3.4868],\n",
      "        [3.2864, 3.3015, 3.3978, 3.3841, 3.4038],\n",
      "        [3.2107, 3.3181, 3.2934, 3.3606, 3.4113],\n",
      "        [3.3694, 3.4991, 3.3914, 3.4926, 3.6136],\n",
      "        [3.3518, 3.4154, 3.3595, 3.5457, 3.4055]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4084, 3.3664, 3.4464, 3.4961, 3.4324],\n",
      "        [3.1152, 3.3627, 3.3083, 3.2515, 3.2851],\n",
      "        [3.2487, 3.2799, 3.3210, 3.3446, 3.3484],\n",
      "        [3.2495, 3.2291, 3.3492, 3.3549, 3.4392],\n",
      "        [3.0898, 3.2122, 3.1200, 3.2626, 3.1512],\n",
      "        [3.3914, 3.4966, 3.3755, 3.3744, 3.4328],\n",
      "        [3.6240, 3.5116, 3.5839, 3.7673, 3.6628],\n",
      "        [3.3429, 3.5590, 3.4614, 3.4687, 3.4356],\n",
      "        [3.1867, 3.2489, 3.3043, 3.3177, 3.3343],\n",
      "        [3.2360, 3.2573, 3.3120, 3.3236, 3.3337],\n",
      "        [3.3908, 3.5410, 3.3548, 3.5961, 3.5119],\n",
      "        [3.6918, 3.9219, 3.4611, 3.5862, 3.5436],\n",
      "        [3.3134, 3.5603, 3.4503, 3.4415, 3.4017],\n",
      "        [3.1930, 3.3393, 3.2977, 3.4130, 3.2777],\n",
      "        [3.3418, 3.3098, 3.3774, 3.3101, 3.3433],\n",
      "        [3.1894, 3.2910, 3.2148, 3.3565, 3.3066],\n",
      "        [3.1309, 3.2761, 3.3053, 3.2785, 3.2579],\n",
      "        [3.1430, 3.2870, 3.1794, 3.2370, 3.2611],\n",
      "        [3.4674, 3.4739, 3.4733, 3.6375, 3.7307],\n",
      "        [3.5161, 3.4679, 3.4283, 3.5147, 3.5634],\n",
      "        [3.1032, 3.2708, 3.2586, 3.2339, 3.2405],\n",
      "        [3.4480, 3.5359, 3.5020, 3.5198, 3.6766],\n",
      "        [3.2349, 3.6036, 3.4716, 3.3914, 3.3854],\n",
      "        [3.1886, 3.3142, 3.1776, 3.2791, 3.2777],\n",
      "        [3.1592, 3.2606, 3.1890, 3.2831, 3.2436],\n",
      "        [3.5543, 3.5882, 3.4923, 3.7193, 3.6353],\n",
      "        [3.1958, 3.3180, 3.1748, 3.2930, 3.2803],\n",
      "        [3.1940, 3.1488, 3.1880, 3.2656, 3.1963],\n",
      "        [3.4751, 3.4035, 3.3462, 3.4575, 3.5051],\n",
      "        [3.2461, 3.2622, 3.3150, 3.3299, 3.3431],\n",
      "        [3.2785, 3.6224, 3.4020, 3.5154, 3.5640],\n",
      "        [3.2794, 3.2698, 3.3743, 3.3688, 3.3521],\n",
      "        [3.1900, 3.2360, 3.3136, 3.3252, 3.4052],\n",
      "        [3.2779, 3.3691, 3.4960, 3.4211, 3.5075],\n",
      "        [3.2335, 3.4749, 3.3848, 3.2847, 3.4474],\n",
      "        [3.2116, 3.3305, 3.3868, 3.4128, 3.4971],\n",
      "        [3.0751, 3.2381, 3.1647, 3.1648, 3.2185],\n",
      "        [3.2202, 3.2414, 3.3098, 3.2897, 3.3140],\n",
      "        [3.3847, 3.4826, 3.3424, 3.4955, 3.4561],\n",
      "        [3.2825, 3.4491, 3.3131, 3.4396, 3.3713],\n",
      "        [3.4206, 3.4060, 3.5600, 3.4204, 3.3386],\n",
      "        [3.1382, 3.2094, 3.2404, 3.2516, 3.2362],\n",
      "        [3.5063, 3.5546, 3.5744, 3.5271, 3.4176],\n",
      "        [3.4696, 3.5632, 3.4034, 3.5151, 3.6207],\n",
      "        [3.3044, 3.2484, 3.3252, 3.3646, 3.3081],\n",
      "        [3.3489, 3.3235, 3.3877, 3.3112, 3.3550],\n",
      "        [3.5510, 3.5409, 3.4669, 3.6099, 3.6206],\n",
      "        [3.3151, 3.3357, 3.4409, 3.4229, 3.4313],\n",
      "        [3.3139, 3.6086, 3.4518, 3.4815, 3.5743],\n",
      "        [3.7363, 3.9407, 3.5150, 3.6348, 3.5685],\n",
      "        [3.2044, 3.1946, 3.2997, 3.2901, 3.2797],\n",
      "        [3.1407, 3.2969, 3.1825, 3.2373, 3.2703],\n",
      "        [3.2401, 3.2766, 3.3223, 3.3475, 3.3568],\n",
      "        [3.4457, 3.3441, 3.3495, 3.4223, 3.4676],\n",
      "        [3.4769, 3.4977, 3.4995, 3.6519, 3.7440],\n",
      "        [3.1023, 3.2944, 3.2707, 3.2377, 3.2465],\n",
      "        [3.2796, 3.4065, 3.3381, 3.3885, 3.4230],\n",
      "        [3.1734, 3.3413, 3.2907, 3.4188, 3.2773],\n",
      "        [3.2230, 3.3199, 3.3037, 3.3454, 3.4586],\n",
      "        [3.2096, 3.2445, 3.3064, 3.2980, 3.3194],\n",
      "        [3.2485, 3.5763, 3.3768, 3.4827, 3.5382],\n",
      "        [3.2402, 3.2700, 3.3094, 3.3291, 3.3415],\n",
      "        [3.3882, 3.5364, 3.3238, 3.4200, 3.4930],\n",
      "        [3.2500, 3.4440, 3.3313, 3.3059, 3.4271]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.1391, 3.2181, 3.2514, 3.2705, 3.2450],\n",
      "        [3.1022, 3.3528, 3.3885, 3.2568, 3.3934],\n",
      "        [3.1430, 3.2999, 3.1840, 3.2402, 3.2721],\n",
      "        [3.2607, 3.2834, 3.3555, 3.3541, 3.3902],\n",
      "        [3.4009, 3.4068, 3.4475, 3.5513, 3.3784],\n",
      "        [3.7192, 3.4508, 3.5712, 4.0219, 3.9541],\n",
      "        [3.3451, 3.4239, 3.3297, 3.3981, 3.3871],\n",
      "        [3.1890, 3.1601, 3.3248, 3.1350, 3.3817],\n",
      "        [3.5400, 3.5582, 3.5223, 3.7010, 3.5511],\n",
      "        [3.1917, 3.2492, 3.2996, 3.3258, 3.3400],\n",
      "        [3.3737, 3.2675, 3.2375, 3.2965, 3.4268],\n",
      "        [3.0666, 3.2271, 3.0610, 3.2339, 3.1626],\n",
      "        [3.1632, 3.1823, 3.2262, 3.2720, 3.2315],\n",
      "        [3.3607, 3.6327, 3.5034, 3.5116, 3.5957],\n",
      "        [3.1676, 3.4836, 3.4349, 3.3471, 3.5143],\n",
      "        [3.6101, 3.5889, 3.5636, 3.6948, 3.6958],\n",
      "        [3.2201, 3.2813, 3.2179, 3.3591, 3.2897],\n",
      "        [3.1911, 3.1890, 3.2421, 3.2837, 3.2271],\n",
      "        [3.2213, 3.4059, 3.3455, 3.3520, 3.3804],\n",
      "        [3.8118, 3.9850, 3.5966, 3.6842, 3.5942],\n",
      "        [3.3758, 3.5060, 3.4448, 3.5789, 3.4473],\n",
      "        [3.5120, 3.5854, 3.4422, 3.5697, 3.6373],\n",
      "        [3.7145, 3.4459, 3.5627, 4.0162, 3.9471],\n",
      "        [3.2824, 3.4002, 3.2007, 3.4083, 3.3527],\n",
      "        [3.2416, 3.2891, 3.3492, 3.3590, 3.3726],\n",
      "        [3.2015, 3.3217, 3.1812, 3.2994, 3.2849],\n",
      "        [3.4910, 3.4761, 3.4912, 3.6035, 3.5306],\n",
      "        [3.4881, 3.5829, 3.4877, 3.5589, 3.6277],\n",
      "        [3.2495, 3.2583, 3.3374, 3.3320, 3.3331],\n",
      "        [3.0983, 3.1123, 3.1785, 3.2736, 3.1941],\n",
      "        [3.4206, 3.5426, 3.3514, 3.4427, 3.5339],\n",
      "        [3.4385, 3.5899, 3.3297, 3.4183, 3.4740],\n",
      "        [3.2197, 3.5126, 3.4422, 3.2821, 3.4727],\n",
      "        [3.3758, 3.5060, 3.4448, 3.5789, 3.4473],\n",
      "        [3.0815, 3.3655, 3.4180, 3.2325, 3.3731],\n",
      "        [3.3246, 3.5108, 3.3789, 3.3624, 3.4856],\n",
      "        [3.3079, 3.5441, 3.3465, 3.5383, 3.4659],\n",
      "        [3.2364, 3.3797, 3.2899, 3.3960, 3.4065],\n",
      "        [3.3745, 3.5063, 3.3949, 3.4991, 3.6178],\n",
      "        [3.4222, 3.5560, 3.4516, 3.3892, 3.5025],\n",
      "        [3.3892, 3.4876, 3.3513, 3.4984, 3.4665],\n",
      "        [3.2351, 3.5043, 3.2952, 3.1855, 3.4315],\n",
      "        [3.4451, 3.2527, 3.3828, 3.6321, 3.6486],\n",
      "        [3.2661, 3.3888, 3.1998, 3.3912, 3.3455],\n",
      "        [3.2105, 3.3264, 3.2955, 3.3796, 3.3847],\n",
      "        [3.3154, 3.5636, 3.4078, 3.4695, 3.5680],\n",
      "        [3.3138, 3.4301, 3.4109, 3.4674, 3.4764],\n",
      "        [3.2661, 3.3888, 3.1998, 3.3912, 3.3455],\n",
      "        [3.0809, 3.2342, 3.0641, 3.2394, 3.1664],\n",
      "        [3.1927, 3.3395, 3.3509, 3.3472, 3.4889],\n",
      "        [3.2468, 3.2556, 3.3316, 3.3333, 3.3280],\n",
      "        [3.3888, 3.3850, 3.4296, 3.5412, 3.3698],\n",
      "        [3.2901, 3.5796, 3.4585, 3.4322, 3.3845],\n",
      "        [3.1934, 3.1646, 3.2034, 3.2732, 3.2117],\n",
      "        [3.3653, 3.5437, 3.4686, 3.5072, 3.5495],\n",
      "        [3.1114, 3.2424, 3.2484, 3.2345, 3.2351],\n",
      "        [3.3174, 3.3390, 3.4425, 3.4259, 3.4332],\n",
      "        [3.2552, 3.4093, 3.3738, 3.3616, 3.3168],\n",
      "        [3.2547, 3.2997, 3.3305, 3.3473, 3.3622],\n",
      "        [3.3686, 3.4340, 3.3307, 3.4232, 3.5770],\n",
      "        [3.6266, 3.5148, 3.5855, 3.7703, 3.6649],\n",
      "        [3.4731, 3.6229, 3.5763, 3.5252, 3.3954],\n",
      "        [3.3932, 3.5442, 3.3565, 3.5991, 3.5139],\n",
      "        [3.1530, 3.1900, 3.2251, 3.2650, 3.2285]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2494, 3.2437, 3.3181, 3.2827, 3.3053],\n",
      "        [3.1605, 3.2103, 3.1199, 3.3064, 3.1680],\n",
      "        [3.1494, 3.2303, 3.1471, 3.3049, 3.1694],\n",
      "        [3.1164, 3.3567, 3.3023, 3.2609, 3.2931],\n",
      "        [3.2165, 3.3374, 3.3910, 3.4192, 3.5008],\n",
      "        [3.4913, 3.6861, 3.4729, 3.6352, 3.6719],\n",
      "        [3.3744, 3.5457, 3.4453, 3.5949, 3.4717],\n",
      "        [3.2885, 3.3110, 3.4108, 3.4197, 3.4196],\n",
      "        [3.2837, 3.4083, 3.1837, 3.3038, 3.3519],\n",
      "        [3.1140, 3.3369, 3.2914, 3.2503, 3.2725],\n",
      "        [3.1845, 3.1593, 3.2726, 3.2930, 3.3443],\n",
      "        [3.1618, 3.2112, 3.1261, 3.3080, 3.1453],\n",
      "        [3.2643, 3.3842, 3.2824, 3.4251, 3.4017],\n",
      "        [3.1576, 3.2906, 3.1594, 3.3137, 3.2646],\n",
      "        [3.2704, 3.2924, 3.3714, 3.3599, 3.3962],\n",
      "        [3.2167, 3.2883, 3.2658, 3.2695, 3.3167],\n",
      "        [3.5507, 3.5483, 3.5462, 3.6721, 3.6128],\n",
      "        [3.2258, 3.5069, 3.3431, 3.3281, 3.2722],\n",
      "        [3.3998, 3.5046, 3.3577, 3.5066, 3.4620],\n",
      "        [3.3979, 3.5502, 3.3602, 3.6039, 3.5190],\n",
      "        [3.4946, 3.5833, 3.4292, 3.5455, 3.6543],\n",
      "        [3.2693, 3.2606, 3.3746, 3.3933, 3.4612],\n",
      "        [3.4024, 3.5513, 3.4334, 3.3792, 3.4878],\n",
      "        [3.4120, 3.5693, 3.4020, 3.4935, 3.4989],\n",
      "        [3.2273, 3.3358, 3.2259, 3.3302, 3.3406],\n",
      "        [3.2410, 3.3615, 3.1985, 3.3327, 3.3299],\n",
      "        [3.1948, 3.2429, 3.3178, 3.3316, 3.4088],\n",
      "        [3.1057, 3.2677, 3.1776, 3.1956, 3.2411],\n",
      "        [3.1644, 3.3139, 3.1928, 3.2652, 3.2868],\n",
      "        [3.2611, 3.2804, 3.3364, 3.3440, 3.3565],\n",
      "        [3.2534, 3.5833, 3.3812, 3.4893, 3.5418],\n",
      "        [3.2469, 3.3574, 3.3421, 3.3734, 3.3351],\n",
      "        [3.5204, 3.4748, 3.4324, 3.5216, 3.5670],\n",
      "        [3.4423, 3.5701, 3.5567, 3.4761, 3.3159],\n",
      "        [3.3239, 3.2693, 3.5609, 3.4234, 3.4776],\n",
      "        [3.3537, 3.3305, 3.3919, 3.3177, 3.3586],\n",
      "        [3.4709, 3.4626, 3.4638, 3.5097, 3.6719],\n",
      "        [3.3129, 3.6289, 3.3925, 3.5470, 3.5418],\n",
      "        [3.3702, 3.5603, 3.4709, 3.5113, 3.5685],\n",
      "        [3.3421, 3.5612, 3.4639, 3.4729, 3.4290],\n",
      "        [3.4654, 3.5776, 3.5690, 3.6954, 3.8366],\n",
      "        [3.2431, 3.4079, 3.2792, 3.3812, 3.4239],\n",
      "        [3.2428, 3.2357, 3.3085, 3.2847, 3.2967],\n",
      "        [3.2783, 3.6355, 3.4685, 3.3737, 3.4113],\n",
      "        [3.2397, 3.4167, 3.3488, 3.3597, 3.3741],\n",
      "        [3.2423, 3.2844, 3.3157, 3.3385, 3.3470],\n",
      "        [3.0802, 3.1469, 3.2015, 3.1836, 3.1512],\n",
      "        [3.4904, 3.6884, 3.4731, 3.6345, 3.6767],\n",
      "        [3.1506, 3.3471, 3.2365, 3.2846, 3.3390],\n",
      "        [3.4817, 3.5048, 3.5039, 3.6585, 3.7479],\n",
      "        [3.1546, 3.1626, 3.2130, 3.2760, 3.2102],\n",
      "        [3.2284, 3.4202, 3.3404, 3.3562, 3.3824],\n",
      "        [3.3926, 3.4512, 3.2744, 3.5133, 3.5271],\n",
      "        [3.4296, 3.5432, 3.4695, 3.4188, 3.5034],\n",
      "        [3.2679, 3.2973, 3.3729, 3.3841, 3.3799],\n",
      "        [3.4298, 3.3245, 3.3390, 3.7162, 3.5501],\n",
      "        [3.2155, 3.3220, 3.2312, 3.2677, 3.2906],\n",
      "        [3.4866, 3.6497, 3.6127, 3.5732, 3.4323],\n",
      "        [3.5030, 3.4961, 3.4120, 3.5271, 3.5251],\n",
      "        [3.1890, 3.3382, 3.2890, 3.2081, 3.3045],\n",
      "        [3.7782, 4.0078, 3.5276, 3.6532, 3.6140],\n",
      "        [3.1395, 3.2311, 3.2096, 3.2519, 3.2450],\n",
      "        [3.3256, 3.5499, 3.3712, 3.5522, 3.4729],\n",
      "        [3.3615, 3.6104, 3.5010, 3.5140, 3.6652]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3798, 3.4354, 3.4953, 3.4265, 3.3763],\n",
      "        [3.1565, 3.3233, 3.2642, 3.3908, 3.2374],\n",
      "        [3.2464, 3.2242, 3.3155, 3.3506, 3.4372],\n",
      "        [3.1760, 3.2905, 3.3249, 3.3167, 3.2493],\n",
      "        [3.5326, 3.5922, 3.4539, 3.5880, 3.6616],\n",
      "        [3.1100, 3.2791, 3.2690, 3.2431, 3.2425],\n",
      "        [3.3077, 3.5803, 3.5066, 3.5107, 3.5666],\n",
      "        [3.2507, 3.3109, 3.4053, 3.2839, 3.5078],\n",
      "        [3.1729, 3.3445, 3.3893, 3.3667, 3.4407],\n",
      "        [3.4039, 3.5266, 3.3764, 3.4635, 3.4507],\n",
      "        [3.2050, 3.1773, 3.3350, 3.1666, 3.3858],\n",
      "        [3.2526, 3.2432, 3.3508, 3.2652, 3.3945],\n",
      "        [3.5410, 3.4973, 3.4896, 3.5828, 3.5806],\n",
      "        [3.2416, 3.2703, 3.2676, 3.3809, 3.2716],\n",
      "        [3.2248, 3.4073, 3.2437, 3.4374, 3.2880],\n",
      "        [3.3959, 3.6151, 3.3994, 3.5040, 3.4983],\n",
      "        [3.1401, 3.2705, 3.2684, 3.2552, 3.2700],\n",
      "        [3.6945, 3.9490, 3.4860, 3.6311, 3.5242],\n",
      "        [3.2571, 3.2651, 3.3423, 3.3384, 3.3363],\n",
      "        [3.3770, 3.2227, 3.2432, 3.3336, 3.3770],\n",
      "        [3.4518, 3.5498, 3.5171, 3.5330, 3.6883],\n",
      "        [3.5064, 3.5136, 3.3797, 3.5631, 3.5850],\n",
      "        [3.3576, 3.4477, 3.4409, 3.4949, 3.5117],\n",
      "        [3.1260, 3.2204, 3.2028, 3.2309, 3.2338],\n",
      "        [3.5291, 3.4116, 3.4992, 3.5914, 3.5366],\n",
      "        [3.2711, 3.4711, 3.3243, 3.4828, 3.3634],\n",
      "        [3.3316, 3.6102, 3.4410, 3.4932, 3.5833],\n",
      "        [3.4034, 3.5533, 3.3627, 3.6071, 3.5206],\n",
      "        [3.2509, 3.3652, 3.1976, 3.3569, 3.3358],\n",
      "        [3.3159, 3.2676, 3.3407, 3.3808, 3.3289],\n",
      "        [3.1919, 3.3037, 3.2106, 3.3235, 3.3078],\n",
      "        [3.3234, 3.5914, 3.4305, 3.4825, 3.5769],\n",
      "        [3.4022, 3.4940, 3.5334, 3.5433, 3.5902],\n",
      "        [3.4775, 3.5887, 3.5802, 3.7203, 3.8375],\n",
      "        [3.3533, 3.4434, 3.4261, 3.4576, 3.5431],\n",
      "        [3.1467, 3.2246, 3.2563, 3.2771, 3.2482],\n",
      "        [3.1888, 3.3222, 3.1974, 3.2740, 3.3069],\n",
      "        [3.1797, 3.2720, 3.2916, 3.2120, 3.4093],\n",
      "        [3.2290, 3.4127, 3.3505, 3.3587, 3.3838],\n",
      "        [3.4191, 3.6149, 3.5678, 3.5474, 3.4080],\n",
      "        [3.2902, 3.3106, 3.3934, 3.3755, 3.4099],\n",
      "        [3.1685, 3.1827, 3.2234, 3.2805, 3.2296],\n",
      "        [3.3747, 3.4900, 3.4958, 3.5041, 3.4836],\n",
      "        [3.3140, 3.2703, 3.3384, 3.3759, 3.3498],\n",
      "        [3.4493, 3.5650, 3.5262, 3.4946, 3.3735],\n",
      "        [3.4089, 3.5651, 3.3916, 3.5036, 3.4887],\n",
      "        [3.0641, 3.2351, 3.2069, 3.2314, 3.2491],\n",
      "        [3.3116, 3.5148, 3.3665, 3.4460, 3.5409],\n",
      "        [3.2142, 3.1873, 3.3007, 3.3283, 3.3658],\n",
      "        [3.1109, 3.2706, 3.1799, 3.1987, 3.2427],\n",
      "        [3.5744, 3.4179, 3.5153, 3.9641, 3.8645],\n",
      "        [3.2064, 3.2793, 3.2761, 3.2601, 3.3097],\n",
      "        [3.1114, 3.3312, 3.2906, 3.2487, 3.2647],\n",
      "        [3.3094, 3.2466, 3.3251, 3.3668, 3.3038],\n",
      "        [3.5760, 3.5428, 3.4846, 3.6178, 3.5929],\n",
      "        [3.2032, 3.4064, 3.3249, 3.2398, 3.2845],\n",
      "        [3.1141, 3.2834, 3.2676, 3.2419, 3.2454],\n",
      "        [3.1969, 3.3423, 3.2978, 3.4151, 3.2821],\n",
      "        [3.4866, 3.3764, 3.3690, 3.4492, 3.4939],\n",
      "        [3.2593, 3.2391, 3.3557, 3.3645, 3.4443],\n",
      "        [3.2388, 3.3296, 3.2413, 3.3674, 3.3169],\n",
      "        [3.1517, 3.2971, 3.1895, 3.2402, 3.2677],\n",
      "        [3.6629, 3.4221, 3.5119, 3.9442, 3.8869],\n",
      "        [3.4630, 3.6566, 3.4434, 3.3724, 3.4927]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2453, 3.3440, 3.2843, 3.3150, 3.3309],\n",
      "        [3.2001, 3.3458, 3.3925, 3.3949, 3.4707],\n",
      "        [3.4314, 3.3371, 3.3669, 3.4072, 3.4275],\n",
      "        [3.3573, 3.5042, 3.4170, 3.4277, 3.3266],\n",
      "        [3.3534, 3.4761, 3.3004, 3.4477, 3.4738],\n",
      "        [3.3552, 3.3265, 3.3855, 3.3272, 3.3361],\n",
      "        [3.1894, 3.3590, 3.2244, 3.3887, 3.2733],\n",
      "        [3.5614, 3.5563, 3.5512, 3.6783, 3.6163],\n",
      "        [3.2404, 3.6587, 3.4869, 3.3834, 3.3947],\n",
      "        [3.2798, 3.3866, 3.3392, 3.3458, 3.3874],\n",
      "        [3.4825, 3.4884, 3.4827, 3.6501, 3.7378],\n",
      "        [3.4001, 3.5617, 3.4951, 3.5343, 3.4728],\n",
      "        [3.1266, 3.3639, 3.3069, 3.2671, 3.2962],\n",
      "        [3.3773, 3.6000, 3.4981, 3.5102, 3.6440],\n",
      "        [3.3227, 3.2636, 3.3230, 3.3855, 3.3076],\n",
      "        [3.1273, 3.1955, 3.2289, 3.2328, 3.2138],\n",
      "        [3.2528, 3.2918, 3.3204, 3.3445, 3.3500],\n",
      "        [3.3738, 3.3599, 3.3659, 3.2960, 3.2527],\n",
      "        [3.3667, 3.2064, 3.4838, 3.4425, 3.4182],\n",
      "        [3.2642, 3.2768, 3.2585, 3.3999, 3.2861],\n",
      "        [3.2312, 3.3501, 3.3164, 3.4191, 3.3689],\n",
      "        [3.1367, 3.2240, 3.2043, 3.2429, 3.2426],\n",
      "        [3.4061, 3.4563, 3.2811, 3.5191, 3.5313],\n",
      "        [3.4042, 3.5208, 3.4905, 3.5038, 3.5233],\n",
      "        [3.3358, 3.5950, 3.4322, 3.4933, 3.5849],\n",
      "        [3.2489, 3.2741, 3.3431, 3.3659, 3.4257],\n",
      "        [3.3156, 3.4480, 3.2433, 3.3351, 3.3914],\n",
      "        [3.2736, 3.3311, 3.3468, 3.3851, 3.3903],\n",
      "        [3.5797, 3.4223, 3.5177, 3.9669, 3.8660],\n",
      "        [3.4094, 3.5533, 3.3572, 3.5996, 3.5083],\n",
      "        [3.2471, 3.4160, 3.2439, 3.4673, 3.2841],\n",
      "        [3.3060, 3.4705, 3.3271, 3.4477, 3.3823],\n",
      "        [3.4414, 3.5522, 3.3602, 3.4671, 3.5526],\n",
      "        [3.2259, 3.2878, 3.4250, 3.2226, 3.4946],\n",
      "        [3.2574, 3.2325, 3.3273, 3.3597, 3.4399],\n",
      "        [3.0969, 3.1670, 3.2131, 3.2117, 3.1596],\n",
      "        [3.2104, 3.3862, 3.2390, 3.4144, 3.2819],\n",
      "        [3.2207, 3.3387, 3.2993, 3.3986, 3.3636],\n",
      "        [3.1937, 3.3263, 3.1996, 3.2768, 3.3084],\n",
      "        [3.1496, 3.2382, 3.2141, 3.2579, 3.2480],\n",
      "        [3.2467, 3.5550, 3.4300, 3.4435, 3.5506],\n",
      "        [3.3636, 3.4168, 3.3598, 3.5442, 3.4081],\n",
      "        [3.2440, 3.5001, 3.4114, 3.2920, 3.4609],\n",
      "        [3.5137, 3.5036, 3.5018, 3.6421, 3.5508],\n",
      "        [3.3239, 3.2736, 3.4630, 3.4666, 3.4044],\n",
      "        [3.4073, 3.5624, 3.3414, 3.4398, 3.5027],\n",
      "        [3.4086, 3.5577, 3.3651, 3.6101, 3.5221],\n",
      "        [3.2764, 3.4576, 3.3073, 3.3760, 3.4335],\n",
      "        [3.1613, 3.2082, 3.2419, 3.2683, 3.2380],\n",
      "        [3.4808, 3.5095, 3.4430, 3.5190, 3.5507],\n",
      "        [3.4479, 3.4610, 3.5013, 3.5184, 3.3785],\n",
      "        [3.4563, 3.6473, 3.4610, 3.6335, 3.5884],\n",
      "        [3.4541, 3.4474, 3.5295, 3.5018, 3.3507],\n",
      "        [3.1969, 3.3078, 3.2128, 3.3263, 3.3092],\n",
      "        [3.1458, 3.2899, 3.3139, 3.2913, 3.2646],\n",
      "        [3.2579, 3.3104, 3.3337, 3.3713, 3.3655],\n",
      "        [3.5137, 3.5036, 3.5018, 3.6421, 3.5508],\n",
      "        [3.2743, 3.2592, 3.3689, 3.3876, 3.4575],\n",
      "        [3.1612, 3.4022, 3.4797, 3.3473, 3.4117],\n",
      "        [3.2652, 3.4582, 3.3404, 3.3186, 3.4339],\n",
      "        [3.2913, 3.4077, 3.2219, 3.4132, 3.3656],\n",
      "        [3.2839, 3.3414, 3.3655, 3.2775, 3.2033],\n",
      "        [3.2623, 3.4709, 3.3601, 3.3137, 3.4443],\n",
      "        [3.2804, 3.2884, 3.3596, 3.3183, 3.3493]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3283, 3.6403, 3.4009, 3.5565, 3.5463],\n",
      "        [3.4064, 3.4001, 3.4401, 3.5543, 3.3761],\n",
      "        [3.2420, 3.3466, 3.2336, 3.3394, 3.3449],\n",
      "        [3.3244, 3.2833, 3.3510, 3.3964, 3.3677],\n",
      "        [3.2105, 3.3368, 3.2354, 3.3159, 3.3341],\n",
      "        [3.6030, 3.5398, 3.5992, 3.7576, 3.6297],\n",
      "        [3.5547, 3.6081, 3.4756, 3.6046, 3.6758],\n",
      "        [3.2640, 3.2704, 3.3418, 3.3459, 3.3339],\n",
      "        [3.3743, 3.3763, 3.3439, 3.5416, 3.4651],\n",
      "        [3.4946, 3.4214, 3.3579, 3.4740, 3.5129],\n",
      "        [3.2673, 3.3376, 3.4014, 3.3101, 3.5043],\n",
      "        [3.3717, 3.4227, 3.2588, 3.4988, 3.5147],\n",
      "        [3.1025, 3.2721, 3.1988, 3.2386, 3.2410],\n",
      "        [3.3424, 3.5258, 3.3896, 3.3756, 3.4918],\n",
      "        [3.3200, 3.4898, 3.4728, 3.4833, 3.4547],\n",
      "        [3.4677, 3.4711, 3.4698, 3.5209, 3.6792],\n",
      "        [3.2492, 3.2787, 3.3454, 3.3692, 3.4148],\n",
      "        [3.2561, 3.3696, 3.3195, 3.3442, 3.3785],\n",
      "        [3.5217, 3.5657, 3.5277, 3.5830, 3.7710],\n",
      "        [3.3691, 3.3965, 3.3701, 3.4297, 3.3922],\n",
      "        [3.3589, 3.3871, 3.3648, 3.4193, 3.3751],\n",
      "        [3.1709, 3.4915, 3.3316, 3.1838, 3.4440],\n",
      "        [3.2688, 3.2981, 3.3332, 3.3604, 3.3563],\n",
      "        [3.4966, 3.3846, 3.3743, 3.4556, 3.4966],\n",
      "        [3.1779, 3.3206, 3.4319, 3.3161, 3.4222],\n",
      "        [3.1089, 3.2289, 3.1311, 3.2784, 3.1589],\n",
      "        [3.3952, 3.5809, 3.4848, 3.5197, 3.5992],\n",
      "        [3.2150, 3.3353, 3.1866, 3.3084, 3.2880],\n",
      "        [3.2567, 3.2835, 3.3179, 3.3408, 3.3455],\n",
      "        [3.2890, 3.4604, 3.3402, 3.3433, 3.4442],\n",
      "        [3.5998, 3.5088, 3.5490, 3.7241, 3.6330],\n",
      "        [3.2832, 3.4033, 3.2103, 3.4038, 3.3514],\n",
      "        [3.6333, 3.8485, 3.3943, 3.5172, 3.4836],\n",
      "        [3.2337, 3.2885, 3.2952, 3.3662, 3.2852],\n",
      "        [3.3866, 3.2305, 3.2483, 3.3397, 3.3796],\n",
      "        [3.7931, 4.0192, 3.5358, 3.6631, 3.6188],\n",
      "        [3.3913, 3.4887, 3.3308, 3.4229, 3.5705],\n",
      "        [3.2477, 3.3615, 3.3117, 3.2999, 3.3639],\n",
      "        [3.3887, 3.5385, 3.3438, 3.5801, 3.4837],\n",
      "        [3.2847, 3.5345, 3.3017, 3.2163, 3.4058],\n",
      "        [3.5317, 3.5145, 3.5127, 3.6137, 3.4447],\n",
      "        [3.7443, 3.8991, 3.5991, 3.6536, 3.6245],\n",
      "        [3.4735, 3.5251, 3.5140, 3.5600, 3.4830],\n",
      "        [3.5796, 3.5233, 3.4819, 3.7023, 3.5875],\n",
      "        [3.5380, 3.4378, 3.3938, 3.5256, 3.5407],\n",
      "        [3.2651, 3.3940, 3.3593, 3.3549, 3.2863],\n",
      "        [3.2576, 3.2957, 3.3236, 3.3478, 3.3513],\n",
      "        [3.1782, 3.1752, 3.2231, 3.2847, 3.2226],\n",
      "        [3.3051, 3.6032, 3.4911, 3.5031, 3.5937],\n",
      "        [3.2568, 3.3733, 3.2100, 3.3625, 3.3390],\n",
      "        [3.1505, 3.2937, 3.3170, 3.2946, 3.2659],\n",
      "        [3.3627, 3.3396, 3.3923, 3.3394, 3.3325],\n",
      "        [3.2594, 3.3119, 3.3351, 3.3663, 3.3647],\n",
      "        [3.3803, 3.4263, 3.4758, 3.4323, 3.3305],\n",
      "        [3.7329, 3.4616, 3.5738, 4.0290, 3.9533],\n",
      "        [3.5112, 3.4164, 3.4989, 3.6332, 3.5124],\n",
      "        [3.3026, 3.3024, 3.3916, 3.3638, 3.3714],\n",
      "        [3.0881, 3.1791, 3.1738, 3.1736, 3.1939],\n",
      "        [3.2350, 3.2237, 3.3229, 3.3182, 3.3039],\n",
      "        [3.5008, 3.4861, 3.5394, 3.5813, 3.4068],\n",
      "        [3.2929, 3.4103, 3.2225, 3.4173, 3.3621],\n",
      "        [3.4595, 3.5734, 3.5318, 3.5011, 3.3764],\n",
      "        [3.3182, 3.4693, 3.3059, 3.4520, 3.4040],\n",
      "        [3.2831, 3.6183, 3.5001, 3.4345, 3.4181]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2694, 3.3252, 3.3434, 3.3748, 3.3697],\n",
      "        [3.5307, 3.2787, 3.4113, 3.7323, 3.7149],\n",
      "        [3.4144, 3.5216, 3.5137, 3.5375, 3.5498],\n",
      "        [3.3452, 3.6027, 3.4396, 3.5014, 3.5885],\n",
      "        [3.5634, 3.3893, 3.4080, 3.8376, 3.6717],\n",
      "        [3.4784, 3.4955, 3.4879, 3.5798, 3.4362],\n",
      "        [3.3856, 3.3462, 3.4101, 3.3302, 3.3955],\n",
      "        [3.5652, 3.4198, 3.5182, 3.6259, 3.5632],\n",
      "        [3.5233, 3.5109, 3.4237, 3.5417, 3.5316],\n",
      "        [3.2457, 3.3655, 3.2076, 3.3281, 3.3268],\n",
      "        [3.5893, 3.4300, 3.5252, 3.9747, 3.8695],\n",
      "        [3.1848, 3.2003, 3.2402, 3.2891, 3.2395],\n",
      "        [3.3283, 3.2702, 3.3408, 3.3846, 3.3180],\n",
      "        [3.1240, 3.2904, 3.2782, 3.2538, 3.2474],\n",
      "        [3.4615, 3.5857, 3.5691, 3.4901, 3.3227],\n",
      "        [3.4220, 3.5241, 3.3921, 3.4200, 3.4502],\n",
      "        [3.6110, 3.5466, 3.6048, 3.7639, 3.6339],\n",
      "        [3.4654, 3.4174, 3.3947, 3.4912, 3.5223],\n",
      "        [3.2455, 3.2445, 3.3141, 3.2985, 3.3035],\n",
      "        [3.5202, 3.5252, 3.3894, 3.5741, 3.5902],\n",
      "        [3.2287, 3.3371, 3.3314, 3.3614, 3.2905],\n",
      "        [3.2733, 3.2840, 3.2655, 3.4078, 3.2896],\n",
      "        [3.2568, 3.2961, 3.2922, 3.3167, 3.3991],\n",
      "        [3.4220, 3.5661, 3.4455, 3.3934, 3.4945],\n",
      "        [3.2109, 3.4559, 3.3419, 3.3855, 3.4839],\n",
      "        [3.2884, 3.3284, 3.3543, 3.2686, 3.1997],\n",
      "        [3.4938, 3.6325, 3.5498, 3.6220, 3.6358],\n",
      "        [3.3939, 3.7054, 3.5327, 3.5602, 3.6352],\n",
      "        [3.3438, 3.2838, 3.5732, 3.4377, 3.4843],\n",
      "        [3.2900, 3.4054, 3.2116, 3.4238, 3.3574],\n",
      "        [3.6892, 3.8411, 3.5406, 3.6050, 3.5645],\n",
      "        [3.2047, 3.3446, 3.2123, 3.3015, 3.3034],\n",
      "        [3.1316, 3.3971, 3.1496, 3.3241, 3.2094],\n",
      "        [3.2655, 3.2482, 3.3405, 3.3660, 3.4461],\n",
      "        [3.1499, 3.3665, 3.4100, 3.2968, 3.3796],\n",
      "        [3.3327, 3.4045, 3.3984, 3.3978, 3.5003],\n",
      "        [3.3934, 3.4867, 3.5404, 3.5271, 3.5422],\n",
      "        [3.4015, 3.5056, 3.3622, 3.5188, 3.4684],\n",
      "        [3.3758, 3.2134, 3.4909, 3.4504, 3.4217],\n",
      "        [3.0924, 3.1825, 3.1776, 3.1780, 3.1961],\n",
      "        [3.2596, 3.2806, 3.1946, 3.3097, 3.4116],\n",
      "        [3.4199, 3.5622, 3.4505, 3.5383, 3.4839],\n",
      "        [3.1499, 3.2311, 3.2526, 3.2622, 3.2427],\n",
      "        [3.3783, 3.3563, 3.3993, 3.4374, 3.3832],\n",
      "        [3.5909, 3.5547, 3.4941, 3.6292, 3.5978],\n",
      "        [3.1278, 3.1966, 3.2345, 3.2363, 3.1973],\n",
      "        [3.2886, 3.4761, 3.3307, 3.3731, 3.4507],\n",
      "        [3.1644, 3.1618, 3.2122, 3.2733, 3.2095],\n",
      "        [3.2702, 3.2838, 3.3308, 3.3500, 3.3530],\n",
      "        [3.2709, 3.2784, 3.3646, 3.3504, 3.3434],\n",
      "        [3.2119, 3.3432, 3.1995, 3.3089, 3.2994],\n",
      "        [3.2156, 3.3023, 3.2261, 3.3853, 3.3131],\n",
      "        [3.3347, 3.2841, 3.3582, 3.3909, 3.3614],\n",
      "        [3.3012, 3.4702, 3.2767, 3.5314, 3.3202],\n",
      "        [3.4723, 3.5140, 3.4482, 3.5852, 3.6425],\n",
      "        [3.3091, 3.3280, 3.4240, 3.4296, 3.4298],\n",
      "        [3.1686, 3.4110, 3.4868, 3.3539, 3.4188],\n",
      "        [3.6779, 3.8117, 3.3956, 3.5850, 3.4517],\n",
      "        [3.4467, 3.5132, 3.4666, 3.4905, 3.6666],\n",
      "        [3.1825, 3.2999, 3.1965, 3.3176, 3.2562],\n",
      "        [3.5651, 3.4905, 3.5494, 3.7061, 3.5784],\n",
      "        [3.1755, 3.4057, 3.1818, 3.3383, 3.2309],\n",
      "        [3.4094, 3.5695, 3.5027, 3.5428, 3.4765],\n",
      "        [3.8151, 4.0600, 3.5920, 3.7387, 3.6120]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2593, 3.5911, 3.4011, 3.4751, 3.5523],\n",
      "        [3.2786, 3.2838, 3.3443, 3.3537, 3.3469],\n",
      "        [3.3993, 3.4570, 3.3506, 3.4466, 3.5875],\n",
      "        [3.4805, 3.4787, 3.4788, 3.5321, 3.6837],\n",
      "        [3.4882, 3.5148, 3.4892, 3.5378, 3.6698],\n",
      "        [3.1824, 3.2767, 3.2941, 3.2431, 3.2729],\n",
      "        [3.2790, 3.2804, 3.3559, 3.3538, 3.3431],\n",
      "        [3.2642, 3.5663, 3.4422, 3.4569, 3.5561],\n",
      "        [3.4606, 3.4165, 3.4593, 3.5553, 3.4537],\n",
      "        [3.2434, 3.2990, 3.4366, 3.2357, 3.5002],\n",
      "        [3.2775, 3.4011, 3.3677, 3.3642, 3.2903],\n",
      "        [3.2489, 3.3078, 3.2679, 3.2802, 3.3404],\n",
      "        [3.5237, 3.5184, 3.5104, 3.6888, 3.7537],\n",
      "        [3.1120, 3.3879, 3.4376, 3.2558, 3.3838],\n",
      "        [3.5021, 3.6366, 3.3597, 3.4621, 3.4859],\n",
      "        [3.5012, 3.6098, 3.6022, 3.7331, 3.8528],\n",
      "        [3.3185, 3.4679, 3.2920, 3.3388, 3.4163],\n",
      "        [3.4189, 3.5202, 3.3935, 3.3754, 3.4430],\n",
      "        [3.4127, 3.3810, 3.4244, 3.4808, 3.4058],\n",
      "        [3.1844, 3.3082, 3.1755, 3.3323, 3.2731],\n",
      "        [3.2435, 3.2254, 3.2727, 3.3137, 3.4284],\n",
      "        [3.6341, 3.6054, 3.5790, 3.7156, 3.7009],\n",
      "        [3.3924, 3.4896, 3.3584, 3.4908, 3.5248],\n",
      "        [3.4992, 3.5170, 3.5158, 3.6414, 3.7424],\n",
      "        [3.2974, 3.4084, 3.2141, 3.4135, 3.3541],\n",
      "        [3.1487, 3.1723, 3.2257, 3.2713, 3.2358],\n",
      "        [3.1700, 3.2340, 3.2605, 3.2766, 3.2481],\n",
      "        [3.2708, 3.2909, 3.3371, 3.3658, 3.3602],\n",
      "        [3.2860, 3.3928, 3.2131, 3.3971, 3.3441],\n",
      "        [3.4414, 3.6316, 3.5828, 3.5635, 3.4153],\n",
      "        [3.5220, 3.4421, 3.4042, 3.5012, 3.5507],\n",
      "        [3.1355, 3.2001, 3.2390, 3.2410, 3.1993],\n",
      "        [3.5449, 3.5057, 3.5289, 3.5667, 3.7150],\n",
      "        [3.0592, 3.2109, 3.1586, 3.1312, 3.1787],\n",
      "        [3.2966, 3.2231, 3.3069, 3.2546, 3.2615],\n",
      "        [3.2842, 3.2713, 3.2489, 3.4285, 3.2676],\n",
      "        [3.3365, 3.3465, 3.4361, 3.4340, 3.4333],\n",
      "        [3.1405, 3.3283, 3.2957, 3.2636, 3.2621],\n",
      "        [3.2740, 3.4456, 3.3978, 3.3845, 3.5201],\n",
      "        [3.4368, 3.4228, 3.5239, 3.4499, 3.2618],\n",
      "        [3.1095, 3.2701, 3.1918, 3.1971, 3.2377],\n",
      "        [3.2299, 3.2778, 3.2905, 3.3666, 3.2672],\n",
      "        [3.2112, 3.2299, 3.2675, 3.3115, 3.2422],\n",
      "        [3.4412, 3.3928, 3.4672, 3.5218, 3.4447],\n",
      "        [3.4454, 3.6101, 3.5008, 3.5405, 3.4880],\n",
      "        [3.2868, 3.5246, 3.3759, 3.3728, 3.2810],\n",
      "        [3.2800, 3.3495, 3.3526, 3.3591, 3.5366],\n",
      "        [3.1592, 3.3059, 3.2035, 3.2426, 3.2758],\n",
      "        [3.2249, 3.3472, 3.2031, 3.3118, 3.3056],\n",
      "        [3.2285, 3.3621, 3.3259, 3.4367, 3.3002],\n",
      "        [3.4215, 3.5396, 3.4865, 3.5314, 3.4923],\n",
      "        [3.3990, 3.2373, 3.2565, 3.3488, 3.3835],\n",
      "        [3.1393, 3.4006, 3.1541, 3.3290, 3.2114],\n",
      "        [3.4511, 3.4930, 3.4644, 3.5326, 3.6085],\n",
      "        [3.4712, 3.5724, 3.3890, 3.4821, 3.5733],\n",
      "        [3.2756, 3.3797, 3.2975, 3.3425, 3.3641],\n",
      "        [3.1815, 3.1805, 3.2289, 3.2944, 3.2184],\n",
      "        [3.1001, 3.1860, 3.1821, 3.1828, 3.1981],\n",
      "        [3.3452, 3.5346, 3.3959, 3.3986, 3.4759],\n",
      "        [3.2104, 3.3370, 3.2111, 3.2894, 3.3139],\n",
      "        [3.4095, 3.4213, 3.4299, 3.4153, 3.3074],\n",
      "        [3.1801, 3.3045, 3.3455, 3.3242, 3.2461],\n",
      "        [3.4284, 3.5308, 3.3868, 3.4542, 3.4581],\n",
      "        [3.2044, 3.3347, 3.2001, 3.2929, 3.2945]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4418, 3.5954, 3.3690, 3.4443, 3.5085],\n",
      "        [3.2528, 3.2637, 3.3294, 3.3172, 3.3210],\n",
      "        [3.5169, 3.5276, 3.5267, 3.6844, 3.7587],\n",
      "        [3.6276, 3.6124, 3.5128, 3.6689, 3.6387],\n",
      "        [3.2380, 3.2007, 3.2538, 3.3278, 3.2373],\n",
      "        [3.2925, 3.4356, 3.3982, 3.3915, 3.3290],\n",
      "        [3.3256, 3.6148, 3.5056, 3.5197, 3.5998],\n",
      "        [3.1793, 3.1693, 3.2216, 3.2839, 3.2131],\n",
      "        [3.2794, 3.3234, 3.3488, 3.3821, 3.3705],\n",
      "        [3.1813, 3.3150, 3.2044, 3.2677, 3.2749],\n",
      "        [3.4337, 3.5733, 3.3828, 3.6296, 3.5299],\n",
      "        [3.2474, 3.3617, 3.2097, 3.3347, 3.3166],\n",
      "        [3.3941, 3.3877, 3.3577, 3.5568, 3.4710],\n",
      "        [3.4931, 3.5393, 3.5661, 3.6725, 3.4798],\n",
      "        [3.2629, 3.5977, 3.3880, 3.4941, 3.5296],\n",
      "        [3.2401, 3.3313, 3.2431, 3.2834, 3.2913],\n",
      "        [3.2774, 3.3807, 3.2196, 3.3632, 3.3475],\n",
      "        [3.4626, 3.5463, 3.4945, 3.4566, 3.5107],\n",
      "        [3.6968, 3.4882, 3.6255, 4.0645, 3.9549],\n",
      "        [3.1689, 3.2516, 3.2903, 3.2921, 3.2297],\n",
      "        [3.2269, 3.3423, 3.2027, 3.3096, 3.2915],\n",
      "        [3.3378, 3.4807, 3.3199, 3.4686, 3.4100],\n",
      "        [3.4258, 3.6345, 3.4192, 3.5262, 3.5073],\n",
      "        [3.2453, 3.3537, 3.3161, 3.4181, 3.3708],\n",
      "        [3.2522, 3.3520, 3.3477, 3.3758, 3.3014],\n",
      "        [3.2493, 3.2739, 3.3322, 3.3296, 3.3334],\n",
      "        [3.7538, 3.4735, 3.5883, 4.0445, 3.9593],\n",
      "        [3.2506, 3.4325, 3.3603, 3.2805, 3.3076],\n",
      "        [3.6229, 3.6492, 3.5517, 3.7907, 3.6759],\n",
      "        [3.3889, 3.3534, 3.4135, 3.3428, 3.3689],\n",
      "        [3.2119, 3.3072, 3.3603, 3.4011, 3.3826],\n",
      "        [3.2034, 3.4390, 3.3441, 3.3658, 3.5038],\n",
      "        [3.2899, 3.3317, 3.3561, 3.3896, 3.3849],\n",
      "        [3.1068, 3.2554, 3.1859, 3.1843, 3.2287],\n",
      "        [3.1359, 3.2892, 3.2019, 3.2250, 3.2538],\n",
      "        [3.3193, 3.4357, 3.3641, 3.4202, 3.4373],\n",
      "        [3.4328, 3.5150, 3.4950, 3.5489, 3.4334],\n",
      "        [3.1799, 3.2021, 3.2412, 3.2884, 3.2300],\n",
      "        [3.4157, 3.5928, 3.4991, 3.5362, 3.6053],\n",
      "        [3.3960, 3.6656, 3.5300, 3.5368, 3.6021],\n",
      "        [3.4029, 3.4844, 3.3459, 3.4371, 3.5785],\n",
      "        [3.4688, 3.4308, 3.4130, 3.4045, 3.3509],\n",
      "        [3.1895, 3.2807, 3.2992, 3.2488, 3.2747],\n",
      "        [3.2484, 3.3472, 3.2369, 3.3442, 3.3358],\n",
      "        [3.8079, 3.9896, 3.6034, 3.7123, 3.5877],\n",
      "        [3.2889, 3.2585, 3.3745, 3.3861, 3.4529],\n",
      "        [3.4984, 3.6750, 3.4948, 3.6683, 3.6126],\n",
      "        [3.6802, 3.8246, 3.5576, 3.5816, 3.5938],\n",
      "        [3.2812, 3.4543, 3.3227, 3.3935, 3.4348],\n",
      "        [3.3190, 3.4304, 3.2308, 3.4417, 3.3724],\n",
      "        [3.5135, 3.6014, 3.4372, 3.5551, 3.6421],\n",
      "        [3.3700, 3.5213, 3.4285, 3.4419, 3.3298],\n",
      "        [3.1193, 3.3921, 3.4430, 3.2622, 3.3856],\n",
      "        [3.2924, 3.3261, 3.3547, 3.3758, 3.3741],\n",
      "        [3.2803, 3.3053, 3.3404, 3.3717, 3.3662],\n",
      "        [3.4497, 3.4100, 3.3779, 3.6860, 3.5622],\n",
      "        [3.5742, 3.7024, 3.3848, 3.5021, 3.4891],\n",
      "        [3.3661, 3.4014, 3.3757, 3.4280, 3.3838],\n",
      "        [3.2860, 3.3221, 3.3505, 3.3734, 3.3655],\n",
      "        [3.2826, 3.3893, 3.2199, 3.3844, 3.3452],\n",
      "        [3.4041, 3.5107, 3.5156, 3.5261, 3.4926],\n",
      "        [3.4346, 3.5689, 3.3749, 3.6192, 3.5161],\n",
      "        [3.3916, 3.3428, 3.4057, 3.3483, 3.3754],\n",
      "        [3.4763, 3.4811, 3.4953, 3.6143, 3.5058]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4558, 3.5647, 3.4049, 3.5790, 3.5757],\n",
      "        [3.1411, 3.1412, 3.2066, 3.3067, 3.2084],\n",
      "        [3.1233, 3.2619, 3.0917, 3.2726, 3.1805],\n",
      "        [3.5048, 3.6054, 3.6066, 3.7372, 3.8428],\n",
      "        [3.2797, 3.3211, 3.3598, 3.2629, 3.1762],\n",
      "        [3.2155, 3.4512, 3.3522, 3.3792, 3.5190],\n",
      "        [3.3949, 3.4719, 3.4660, 3.5262, 3.5237],\n",
      "        [3.4360, 3.4034, 3.3521, 3.6447, 3.5318],\n",
      "        [3.2711, 3.3847, 3.2197, 3.3614, 3.3364],\n",
      "        [3.2270, 3.4564, 3.2482, 3.1457, 3.3394],\n",
      "        [3.1428, 3.2795, 3.1987, 3.2215, 3.2452],\n",
      "        [3.1196, 3.2693, 3.1940, 3.2004, 3.2348],\n",
      "        [3.5488, 3.5810, 3.5472, 3.6058, 3.7800],\n",
      "        [3.1553, 3.3529, 3.3137, 3.2771, 3.2740],\n",
      "        [3.3232, 3.3530, 3.3746, 3.2989, 3.2193],\n",
      "        [3.2892, 3.3928, 3.2245, 3.3898, 3.3479],\n",
      "        [3.3521, 3.2908, 3.3608, 3.4131, 3.3369],\n",
      "        [3.1871, 3.2895, 3.3201, 3.3149, 3.2594],\n",
      "        [3.3703, 3.4149, 3.3861, 3.4300, 3.4080],\n",
      "        [3.3120, 3.3074, 3.3813, 3.3430, 3.3594],\n",
      "        [3.4450, 3.4618, 3.5135, 3.4724, 3.3711],\n",
      "        [3.4009, 3.3914, 3.3624, 3.5622, 3.4737],\n",
      "        [3.3031, 3.2884, 3.3733, 3.3249, 3.4064],\n",
      "        [3.2849, 3.4342, 3.3056, 3.4126, 3.4369],\n",
      "        [3.4647, 3.5734, 3.5257, 3.5008, 3.3682],\n",
      "        [3.4250, 3.3077, 3.2774, 3.3431, 3.4507],\n",
      "        [3.3190, 3.4249, 3.2408, 3.4380, 3.3708],\n",
      "        [3.2145, 3.2926, 3.2155, 3.3347, 3.2628],\n",
      "        [3.6061, 3.5388, 3.5020, 3.7240, 3.5963],\n",
      "        [3.4029, 3.6696, 3.5349, 3.5424, 3.6049],\n",
      "        [3.3767, 3.3748, 3.4753, 3.4736, 3.4561],\n",
      "        [3.2730, 3.3431, 3.4382, 3.4676, 3.5222],\n",
      "        [3.3683, 3.6347, 3.4659, 3.5210, 3.5950],\n",
      "        [3.4610, 3.5735, 3.3734, 3.4783, 3.5378],\n",
      "        [3.2869, 3.3334, 3.4297, 3.3131, 3.5082],\n",
      "        [3.4333, 3.5618, 3.4986, 3.4785, 3.3584],\n",
      "        [3.3084, 3.4409, 3.4065, 3.4027, 3.3364],\n",
      "        [3.1846, 3.2275, 3.2627, 3.2965, 3.2478],\n",
      "        [3.6294, 3.5770, 3.5110, 3.6559, 3.6315],\n",
      "        [3.2508, 3.2101, 3.3196, 3.3481, 3.3645],\n",
      "        [3.1861, 3.3689, 3.2635, 3.3089, 3.3489],\n",
      "        [3.5615, 3.5929, 3.4758, 3.6297, 3.6718],\n",
      "        [3.3257, 3.4340, 3.2355, 3.4471, 3.3751],\n",
      "        [3.3160, 3.4241, 3.2274, 3.4345, 3.3689],\n",
      "        [3.4480, 3.4826, 3.4484, 3.4879, 3.5877],\n",
      "        [3.1496, 3.3058, 3.2912, 3.2688, 3.2568],\n",
      "        [3.2919, 3.3016, 3.3508, 3.3691, 3.3598],\n",
      "        [3.3532, 3.3576, 3.4551, 3.4604, 3.4464],\n",
      "        [3.2425, 3.1873, 3.2194, 3.3072, 3.2191],\n",
      "        [3.4340, 3.3070, 3.2852, 3.3458, 3.4575],\n",
      "        [3.2608, 3.3049, 3.4585, 3.2357, 3.5099],\n",
      "        [3.4986, 3.3618, 3.2996, 3.4148, 3.4816],\n",
      "        [3.6299, 3.6530, 3.5568, 3.7965, 3.6786],\n",
      "        [3.2263, 3.3851, 3.2634, 3.3736, 3.2633],\n",
      "        [3.1961, 3.2842, 3.3038, 3.2540, 3.2773],\n",
      "        [3.1879, 3.3143, 3.2095, 3.2722, 3.2744],\n",
      "        [3.5260, 3.5387, 3.6514, 3.5081, 3.3984],\n",
      "        [3.6562, 3.7401, 3.6347, 3.8990, 3.7500],\n",
      "        [3.4637, 3.2695, 3.2549, 3.3365, 3.4490],\n",
      "        [3.4256, 3.5445, 3.3970, 3.5052, 3.4569],\n",
      "        [3.2957, 3.3204, 3.3548, 3.3866, 3.3688],\n",
      "        [3.2895, 3.3771, 3.2626, 3.3718, 3.3714],\n",
      "        [3.4694, 3.5499, 3.4993, 3.4622, 3.5134],\n",
      "        [3.5349, 3.7122, 3.5009, 3.6664, 3.6857]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "Episode: 1/3, Total Reward: 30\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4626, 3.6282, 3.4225, 3.3735, 3.4158],\n",
      "        [3.2760, 3.6048, 3.3972, 3.5047, 3.5347],\n",
      "        [3.4972, 3.5507, 3.5227, 3.5437, 3.6836],\n",
      "        [3.3143, 3.4798, 3.3332, 3.4060, 3.4459],\n",
      "        [3.5218, 3.6163, 3.6105, 3.7544, 3.8522],\n",
      "        [3.2913, 3.2634, 3.3445, 3.3785, 3.4639],\n",
      "        [3.2951, 3.4567, 3.4121, 3.4010, 3.5272],\n",
      "        [3.3820, 3.5936, 3.3866, 3.2955, 3.4814],\n",
      "        [3.3394, 3.5464, 3.3280, 3.4550, 3.4235],\n",
      "        [3.3182, 3.2346, 3.3183, 3.2782, 3.2685],\n",
      "        [3.2810, 3.2469, 3.3225, 3.3661, 3.4522],\n",
      "        [3.0945, 3.2405, 3.1849, 3.1643, 3.2055],\n",
      "        [3.2890, 3.3261, 3.2577, 3.4114, 3.3175],\n",
      "        [3.3151, 3.4039, 3.5343, 3.4453, 3.5230],\n",
      "        [3.3373, 3.2917, 3.4680, 3.4837, 3.3923],\n",
      "        [3.5537, 3.4559, 3.5441, 3.6872, 3.5452],\n",
      "        [3.0836, 3.2293, 3.2469, 3.2228, 3.2616],\n",
      "        [3.4258, 3.2542, 3.2723, 3.3702, 3.3822],\n",
      "        [3.3664, 3.5989, 3.4869, 3.4857, 3.4221],\n",
      "        [3.3050, 3.3476, 3.4250, 3.3389, 3.5183],\n",
      "        [3.6749, 3.4789, 3.5880, 4.0504, 3.9156],\n",
      "        [3.3127, 3.3102, 3.3717, 3.3791, 3.3713],\n",
      "        [3.2443, 3.3572, 3.2206, 3.3314, 3.3191],\n",
      "        [3.4392, 3.5237, 3.3643, 3.4762, 3.5721],\n",
      "        [3.3920, 3.4056, 3.3874, 3.4450, 3.3861],\n",
      "        [3.8233, 4.0366, 3.5662, 3.7097, 3.6375],\n",
      "        [3.4415, 3.4278, 3.4258, 3.4973, 3.6268],\n",
      "        [3.2099, 3.2416, 3.1546, 3.3433, 3.2050],\n",
      "        [3.2895, 3.3019, 3.3403, 3.3667, 3.3563],\n",
      "        [3.3781, 3.4411, 3.4630, 3.4673, 3.4580],\n",
      "        [3.2044, 3.4700, 3.2498, 3.1448, 3.3783],\n",
      "        [3.2927, 3.3305, 3.3578, 3.3927, 3.3756],\n",
      "        [3.4712, 3.5769, 3.5301, 3.5057, 3.3707],\n",
      "        [3.3108, 3.2430, 3.3274, 3.2925, 3.2812],\n",
      "        [3.3166, 3.3373, 3.2519, 3.3658, 3.4540],\n",
      "        [3.2505, 3.5211, 3.3461, 3.3260, 3.2748],\n",
      "        [3.2915, 3.5651, 3.4235, 3.4909, 3.5497],\n",
      "        [3.1907, 3.2308, 3.2669, 3.3014, 3.2502],\n",
      "        [3.3404, 3.5158, 3.3764, 3.5473, 3.3953],\n",
      "        [3.2000, 3.2049, 3.2482, 3.3056, 3.2354],\n",
      "        [3.4673, 3.4734, 3.5282, 3.4895, 3.3750],\n",
      "        [3.2921, 3.3904, 3.2170, 3.3965, 3.3306],\n",
      "        [3.4041, 3.2272, 3.5096, 3.4716, 3.4305],\n",
      "        [3.6376, 3.5084, 3.5792, 3.7701, 3.6625],\n",
      "        [3.2879, 3.4462, 3.3796, 3.3969, 3.3897],\n",
      "        [3.2263, 3.3804, 3.2503, 3.4177, 3.2855],\n",
      "        [3.3409, 3.3484, 3.3628, 3.4173, 3.4037],\n",
      "        [3.3293, 3.3376, 3.4405, 3.4472, 3.4331],\n",
      "        [3.4270, 3.4572, 3.2817, 3.5371, 3.5495],\n",
      "        [3.2983, 3.3403, 3.3622, 3.3966, 3.3785],\n",
      "        [3.2057, 3.2407, 3.1458, 3.3429, 3.1709],\n",
      "        [3.6572, 3.8048, 3.7279, 3.8256, 3.9465],\n",
      "        [3.2823, 3.3676, 3.2537, 3.3909, 3.3218],\n",
      "        [3.3988, 3.7110, 3.4644, 3.6408, 3.6054],\n",
      "        [3.3616, 3.6589, 3.4245, 3.5829, 3.5575],\n",
      "        [3.4471, 3.5805, 3.3922, 3.6404, 3.5352],\n",
      "        [3.4075, 3.4608, 3.3467, 3.4460, 3.5898],\n",
      "        [3.2443, 3.3776, 3.3858, 3.4011, 3.4998],\n",
      "        [3.1540, 3.3849, 3.3305, 3.2824, 3.2940],\n",
      "        [3.1961, 3.3288, 3.2190, 3.2778, 3.2907],\n",
      "        [3.2583, 3.3607, 3.3250, 3.4291, 3.3758],\n",
      "        [3.3652, 3.4647, 3.4458, 3.5115, 3.4944],\n",
      "        [3.5199, 3.5282, 3.5307, 3.6589, 3.7495],\n",
      "        [3.3738, 3.6185, 3.4589, 3.5232, 3.5975]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2883, 3.3218, 3.3639, 3.2652, 3.1776],\n",
      "        [3.1645, 3.3880, 3.4390, 3.3021, 3.3713],\n",
      "        [3.2950, 3.2968, 3.3509, 3.3700, 3.3544],\n",
      "        [3.3918, 3.5698, 3.4212, 3.6014, 3.4901],\n",
      "        [3.2400, 3.2847, 3.3413, 3.3789, 3.3586],\n",
      "        [3.2679, 3.3626, 3.3337, 3.4247, 3.4039],\n",
      "        [3.4986, 3.5870, 3.4090, 3.5065, 3.5827],\n",
      "        [3.4233, 3.6269, 3.5303, 3.5468, 3.6590],\n",
      "        [3.3181, 3.3079, 3.3792, 3.3824, 3.3669],\n",
      "        [3.2634, 3.3549, 3.3551, 3.3913, 3.3015],\n",
      "        [3.2182, 3.2897, 3.3305, 3.3525, 3.2496],\n",
      "        [3.4490, 3.5592, 3.5025, 3.4861, 3.3506],\n",
      "        [3.4127, 3.5463, 3.3633, 3.6031, 3.4855],\n",
      "        [3.5972, 3.4953, 3.5648, 3.7256, 3.5777],\n",
      "        [3.5929, 3.4154, 3.4340, 3.8646, 3.6807],\n",
      "        [3.2170, 3.1961, 3.2499, 3.3151, 3.2353],\n",
      "        [3.2855, 3.6859, 3.5194, 3.4216, 3.4103],\n",
      "        [3.2781, 3.2958, 3.3717, 3.3948, 3.4442],\n",
      "        [3.3048, 3.4153, 3.3866, 3.3850, 3.2994],\n",
      "        [3.2890, 3.3004, 3.3729, 3.4005, 3.4279],\n",
      "        [3.2224, 3.2139, 3.2595, 3.3213, 3.2472],\n",
      "        [3.4617, 3.4892, 3.4577, 3.4984, 3.5927],\n",
      "        [3.4450, 3.4797, 3.4241, 3.5632, 3.6016],\n",
      "        [3.4825, 3.5317, 3.4915, 3.5210, 3.6782],\n",
      "        [3.2381, 3.4260, 3.2241, 3.3980, 3.2560],\n",
      "        [3.2352, 3.5740, 3.4002, 3.4306, 3.5448],\n",
      "        [3.5388, 3.6609, 3.6309, 3.6010, 3.4173],\n",
      "        [3.4674, 3.6013, 3.4387, 3.5342, 3.5170],\n",
      "        [3.3011, 3.6116, 3.3605, 3.5535, 3.4949],\n",
      "        [3.3393, 3.6627, 3.4439, 3.5638, 3.5857],\n",
      "        [3.4829, 3.4475, 3.6023, 3.4709, 3.3604],\n",
      "        [3.1652, 3.2949, 3.2940, 3.2780, 3.2584],\n",
      "        [3.5686, 3.6226, 3.4819, 3.6157, 3.6575],\n",
      "        [3.4801, 3.6112, 3.5220, 3.5545, 3.4895],\n",
      "        [3.5722, 3.5369, 3.5422, 3.6464, 3.4583],\n",
      "        [3.2273, 3.3003, 3.3248, 3.2499, 3.4249],\n",
      "        [3.2851, 3.3802, 3.5231, 3.4131, 3.4994],\n",
      "        [3.3022, 3.3834, 3.2719, 3.3817, 3.3760],\n",
      "        [3.2311, 3.3124, 3.3684, 3.4163, 3.3931],\n",
      "        [3.1623, 3.3122, 3.3004, 3.2787, 3.2614],\n",
      "        [3.2602, 3.3715, 3.2246, 3.3578, 3.3161],\n",
      "        [3.2188, 3.3373, 3.2201, 3.3027, 3.2907],\n",
      "        [3.7421, 3.9782, 3.5204, 3.6698, 3.5408],\n",
      "        [3.2635, 3.2166, 3.3286, 3.3580, 3.3690],\n",
      "        [3.3028, 3.3060, 3.3568, 3.3758, 3.3630],\n",
      "        [3.2677, 3.3570, 3.2507, 3.3593, 3.3431],\n",
      "        [3.4140, 3.3979, 3.3718, 3.5721, 3.4784],\n",
      "        [3.1262, 3.1996, 3.2009, 3.2035, 3.2069],\n",
      "        [3.2308, 3.3484, 3.2190, 3.3138, 3.3035],\n",
      "        [3.6921, 3.8150, 3.4426, 3.6089, 3.5039],\n",
      "        [3.1126, 3.2638, 3.2399, 3.2684, 3.2649],\n",
      "        [3.1665, 3.3054, 3.2188, 3.2427, 3.2740],\n",
      "        [3.3066, 3.4500, 3.4200, 3.4095, 3.3291],\n",
      "        [3.2652, 3.3639, 3.3300, 3.4345, 3.3781],\n",
      "        [3.7749, 3.4842, 3.6030, 4.0601, 3.9667],\n",
      "        [3.1728, 3.3138, 3.3130, 3.2965, 3.2815],\n",
      "        [3.1842, 3.3375, 3.2301, 3.2747, 3.2913],\n",
      "        [3.3061, 3.2674, 3.3790, 3.3962, 3.4602],\n",
      "        [3.2352, 3.5557, 3.4524, 3.4352, 3.5380],\n",
      "        [3.3019, 3.2576, 3.3576, 3.3935, 3.4542],\n",
      "        [3.2070, 3.3266, 3.3726, 3.3525, 3.2600],\n",
      "        [3.2996, 3.3213, 3.3554, 3.3850, 3.3668],\n",
      "        [3.2330, 3.3834, 3.2553, 3.4229, 3.2877],\n",
      "        [3.2571, 3.2846, 3.2828, 3.3071, 3.3826]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2051, 3.5036, 3.3553, 3.2095, 3.4556],\n",
      "        [3.2619, 3.3642, 3.2286, 3.3434, 3.3262],\n",
      "        [3.5536, 3.5919, 3.5695, 3.5969, 3.7702],\n",
      "        [3.3100, 3.3984, 3.2308, 3.4057, 3.3385],\n",
      "        [3.2977, 3.2566, 3.3362, 3.3814, 3.4599],\n",
      "        [3.4192, 3.4487, 3.2953, 3.4556, 3.5191],\n",
      "        [3.3060, 3.3242, 3.3620, 3.3897, 3.3698],\n",
      "        [3.4749, 3.5743, 3.4215, 3.5942, 3.5835],\n",
      "        [3.3073, 3.3329, 3.3665, 3.3964, 3.3751],\n",
      "        [3.3017, 3.6488, 3.5204, 3.4469, 3.4113],\n",
      "        [3.2695, 3.5557, 3.4504, 3.4641, 3.5083],\n",
      "        [3.0840, 3.2287, 3.2600, 3.2158, 3.2703],\n",
      "        [3.3573, 3.4782, 3.3028, 3.3692, 3.4180],\n",
      "        [3.3733, 3.4855, 3.3313, 3.4725, 3.4365],\n",
      "        [3.2896, 3.3621, 3.3502, 3.3976, 3.4828],\n",
      "        [3.0840, 3.2287, 3.2600, 3.2158, 3.2703],\n",
      "        [3.2687, 3.3231, 3.3190, 3.3156, 3.3328],\n",
      "        [3.2916, 3.5441, 3.3947, 3.3892, 3.2967],\n",
      "        [3.4115, 3.4766, 3.4660, 3.5011, 3.5627],\n",
      "        [3.2150, 3.3556, 3.2517, 3.3726, 3.2882],\n",
      "        [3.3229, 3.2810, 3.3939, 3.3986, 3.4414],\n",
      "        [3.2113, 3.3556, 3.3035, 3.4354, 3.2561],\n",
      "        [3.3243, 3.3108, 3.3857, 3.3870, 3.3698],\n",
      "        [3.2791, 3.3852, 3.2388, 3.3673, 3.3370],\n",
      "        [3.3021, 3.3320, 3.2693, 3.4212, 3.3227],\n",
      "        [3.2549, 3.3655, 3.2276, 3.3450, 3.3162],\n",
      "        [3.4686, 3.6099, 3.4409, 3.5390, 3.5112],\n",
      "        [3.3912, 3.5336, 3.4447, 3.4610, 3.3347],\n",
      "        [3.2946, 3.3618, 3.2814, 3.4098, 3.3361],\n",
      "        [3.4256, 3.5581, 3.3839, 3.4695, 3.4717],\n",
      "        [3.2231, 3.2517, 3.1623, 3.3570, 3.1994],\n",
      "        [3.3107, 3.3410, 3.3737, 3.4045, 3.3819],\n",
      "        [3.2933, 3.6085, 3.4280, 3.5024, 3.5646],\n",
      "        [3.3093, 3.2948, 3.3752, 3.3811, 3.3497],\n",
      "        [3.4752, 3.4107, 3.4932, 3.5489, 3.4569],\n",
      "        [3.3809, 3.3700, 3.4727, 3.4732, 3.4509],\n",
      "        [3.3182, 3.3445, 3.3789, 3.4101, 3.3971],\n",
      "        [3.1115, 3.2939, 3.4209, 3.2331, 3.3680],\n",
      "        [3.7165, 3.4594, 3.5488, 3.9829, 3.9057],\n",
      "        [3.3240, 3.3225, 3.3996, 3.4022, 3.4124],\n",
      "        [3.2395, 3.5253, 3.3841, 3.2334, 3.4751],\n",
      "        [3.2097, 3.1976, 3.2512, 3.3138, 3.2328],\n",
      "        [3.3930, 3.4185, 3.3967, 3.4522, 3.4039],\n",
      "        [3.3776, 3.6904, 3.4619, 3.6121, 3.5973],\n",
      "        [3.2206, 3.3404, 3.2255, 3.3013, 3.2993],\n",
      "        [3.3015, 3.3935, 3.3538, 3.3793, 3.3951],\n",
      "        [3.3152, 3.4088, 3.2451, 3.4231, 3.3627],\n",
      "        [3.4656, 3.4465, 3.4929, 3.6017, 3.4012],\n",
      "        [3.3317, 3.3936, 3.2952, 3.4622, 3.3840],\n",
      "        [3.4847, 3.5831, 3.5419, 3.5157, 3.3761],\n",
      "        [3.5889, 3.7302, 3.5166, 3.4948, 3.5575],\n",
      "        [3.2244, 3.2925, 3.3369, 3.3571, 3.2527],\n",
      "        [3.5556, 3.5385, 3.5453, 3.7086, 3.7663],\n",
      "        [3.1786, 3.3672, 3.3336, 3.3068, 3.2978],\n",
      "        [3.3526, 3.5521, 3.3397, 3.4646, 3.4287],\n",
      "        [3.2454, 3.3941, 3.2792, 3.3881, 3.2709],\n",
      "        [3.6455, 3.5401, 3.5931, 3.8129, 3.6933],\n",
      "        [3.5389, 3.6761, 3.6227, 3.5868, 3.4197],\n",
      "        [3.4720, 3.5970, 3.4384, 3.5518, 3.5158],\n",
      "        [3.2917, 3.4332, 3.3158, 3.4193, 3.4356],\n",
      "        [3.4977, 3.7169, 3.5316, 3.7146, 3.6721],\n",
      "        [3.2113, 3.3556, 3.3035, 3.4354, 3.2561],\n",
      "        [3.2713, 3.3678, 3.3669, 3.4007, 3.3148],\n",
      "        [3.3426, 3.3215, 3.3849, 3.4224, 3.4323]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4241, 3.2360, 3.5271, 3.4856, 3.4395],\n",
      "        [3.2443, 3.5148, 3.3767, 3.2173, 3.4452],\n",
      "        [3.3338, 3.2915, 3.2752, 3.4613, 3.2928],\n",
      "        [3.4291, 3.4661, 3.4146, 3.6067, 3.4362],\n",
      "        [3.4470, 3.2651, 3.2926, 3.3719, 3.4075],\n",
      "        [3.4621, 3.4373, 3.4439, 3.5137, 3.6359],\n",
      "        [3.6127, 3.4140, 3.4449, 3.8719, 3.6892],\n",
      "        [3.3190, 3.3281, 3.3613, 3.3768, 3.4283],\n",
      "        [3.2459, 3.3873, 3.3431, 3.4776, 3.3050],\n",
      "        [3.2110, 3.2727, 3.3166, 3.3218, 3.2483],\n",
      "        [3.2872, 3.3870, 3.2393, 3.3839, 3.3320],\n",
      "        [3.3220, 3.2986, 3.2884, 3.4545, 3.2959],\n",
      "        [3.2625, 3.2920, 3.3510, 3.3798, 3.3662],\n",
      "        [3.1816, 3.3322, 3.3232, 3.3041, 3.2900],\n",
      "        [3.3515, 3.4419, 3.2512, 3.4606, 3.3789],\n",
      "        [3.5899, 3.5815, 3.5601, 3.7145, 3.5474],\n",
      "        [3.3218, 3.2219, 3.3124, 3.2686, 3.2540],\n",
      "        [3.2404, 3.5869, 3.4858, 3.4259, 3.5633],\n",
      "        [3.2939, 3.5472, 3.3924, 3.3801, 3.2974],\n",
      "        [3.3291, 3.4854, 3.3551, 3.4118, 3.4617],\n",
      "        [3.6995, 3.5596, 3.6401, 3.8256, 3.6925],\n",
      "        [3.7004, 3.4350, 3.5313, 3.9863, 3.8877],\n",
      "        [3.5355, 3.6545, 3.6312, 3.6133, 3.4552],\n",
      "        [3.2585, 3.2023, 3.3739, 3.1872, 3.4076],\n",
      "        [3.1940, 3.2751, 3.3031, 3.2965, 3.2651],\n",
      "        [3.4262, 3.5527, 3.3762, 3.6123, 3.4925],\n",
      "        [3.3255, 3.3571, 3.4427, 3.3532, 3.5275],\n",
      "        [3.2421, 3.3887, 3.5474, 3.3637, 3.5147],\n",
      "        [3.4751, 3.6127, 3.3934, 3.4773, 3.5176],\n",
      "        [3.3260, 3.4170, 3.2386, 3.4290, 3.3624],\n",
      "        [3.5653, 3.5444, 3.5561, 3.6870, 3.5664],\n",
      "        [3.7360, 3.8304, 3.4473, 3.6201, 3.4763],\n",
      "        [3.2305, 3.3514, 3.2400, 3.3132, 3.3110],\n",
      "        [3.2592, 3.4799, 3.3794, 3.4220, 3.5016],\n",
      "        [3.1786, 3.4199, 3.1858, 3.3588, 3.2268],\n",
      "        [3.6349, 3.7727, 3.5252, 3.5436, 3.5383],\n",
      "        [3.2964, 3.5644, 3.4780, 3.4783, 3.5384],\n",
      "        [3.2646, 3.3816, 3.4023, 3.4008, 3.5154],\n",
      "        [3.4374, 3.5284, 3.5426, 3.5509, 3.5068],\n",
      "        [3.3213, 3.2740, 3.3879, 3.4049, 3.4677],\n",
      "        [3.3957, 3.4546, 3.3466, 3.4878, 3.4474],\n",
      "        [3.3296, 3.3868, 3.3065, 3.4361, 3.4873],\n",
      "        [3.1193, 3.2537, 3.2016, 3.1852, 3.2235],\n",
      "        [3.6150, 3.5842, 3.5998, 3.7383, 3.6310],\n",
      "        [3.2264, 3.2473, 3.1666, 3.3547, 3.1916],\n",
      "        [3.4362, 3.3872, 3.4447, 3.4871, 3.4097],\n",
      "        [3.2277, 3.2433, 3.1720, 3.3602, 3.2393],\n",
      "        [3.5759, 3.5940, 3.5701, 3.6265, 3.7918],\n",
      "        [3.4678, 3.5902, 3.4104, 3.6551, 3.5446],\n",
      "        [3.4678, 3.5902, 3.4104, 3.6551, 3.5446],\n",
      "        [3.1765, 3.4133, 3.1815, 3.3706, 3.2274],\n",
      "        [3.3144, 3.2976, 3.3825, 3.3790, 3.3517],\n",
      "        [3.3114, 3.3893, 3.2777, 3.3929, 3.3764],\n",
      "        [3.3555, 3.5187, 3.3833, 3.4236, 3.4762],\n",
      "        [3.4100, 3.5062, 3.5081, 3.5719, 3.5320],\n",
      "        [3.3929, 3.3816, 3.4943, 3.4805, 3.4616],\n",
      "        [3.3346, 3.3536, 3.3894, 3.3026, 3.2171],\n",
      "        [3.3196, 3.3221, 3.3698, 3.3847, 3.3713],\n",
      "        [3.2430, 3.3453, 3.2262, 3.3185, 3.2986],\n",
      "        [3.1761, 3.3286, 3.3209, 3.2984, 3.2822],\n",
      "        [3.2295, 3.2506, 3.1717, 3.3570, 3.2138],\n",
      "        [3.3886, 3.4751, 3.3757, 3.4932, 3.4892],\n",
      "        [3.3219, 3.2749, 3.4007, 3.4104, 3.4668],\n",
      "        [3.5419, 3.6571, 3.3917, 3.4943, 3.5017]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2724, 3.3649, 3.2313, 3.3516, 3.3113],\n",
      "        [3.3436, 3.6508, 3.5479, 3.4834, 3.4424],\n",
      "        [3.2877, 3.3717, 3.3518, 3.4386, 3.4138],\n",
      "        [3.6610, 3.5406, 3.5983, 3.7702, 3.6568],\n",
      "        [3.5270, 3.5959, 3.5144, 3.5746, 3.6047],\n",
      "        [3.2838, 3.3658, 3.3769, 3.4171, 3.3226],\n",
      "        [3.5027, 3.5657, 3.5275, 3.4864, 3.5285],\n",
      "        [3.3272, 3.5054, 3.4097, 3.3633, 3.4693],\n",
      "        [3.5581, 3.5285, 3.4120, 3.5794, 3.6092],\n",
      "        [3.4560, 3.5665, 3.5206, 3.5632, 3.5323],\n",
      "        [3.1829, 3.2998, 3.3082, 3.2924, 3.2681],\n",
      "        [3.2817, 3.2257, 3.3501, 3.3778, 3.3910],\n",
      "        [3.3127, 3.4252, 3.3874, 3.3605, 3.2986],\n",
      "        [3.5489, 3.5641, 3.6157, 3.7208, 3.5087],\n",
      "        [3.5929, 3.5465, 3.5611, 3.6606, 3.4686],\n",
      "        [3.3136, 3.4286, 3.5302, 3.3699, 3.4088],\n",
      "        [3.3094, 3.4036, 3.3900, 3.4966, 3.3712],\n",
      "        [3.3375, 3.3370, 3.3972, 3.4040, 3.4323],\n",
      "        [3.3520, 3.6447, 3.4291, 3.5624, 3.5504],\n",
      "        [3.2377, 3.2988, 3.3482, 3.3657, 3.2599],\n",
      "        [3.3047, 3.3944, 3.3757, 3.4947, 3.3744],\n",
      "        [3.0893, 3.2345, 3.2613, 3.2210, 3.2494],\n",
      "        [3.4289, 3.4276, 3.4159, 3.4742, 3.4156],\n",
      "        [3.5295, 3.4630, 3.5286, 3.6117, 3.4988],\n",
      "        [3.2680, 3.3717, 3.2388, 3.3535, 3.3233],\n",
      "        [3.5216, 3.4444, 3.4360, 3.5306, 3.5436],\n",
      "        [3.2371, 3.3508, 3.4779, 3.3605, 3.4450],\n",
      "        [3.5511, 3.5749, 3.5475, 3.5953, 3.7412],\n",
      "        [3.4417, 3.4098, 3.4601, 3.5807, 3.3681],\n",
      "        [3.6634, 3.5931, 3.5390, 3.6798, 3.6469],\n",
      "        [3.1298, 3.3429, 3.1255, 3.3071, 3.1729],\n",
      "        [3.2700, 3.2078, 3.3349, 3.3598, 3.3699],\n",
      "        [3.3059, 3.3889, 3.2371, 3.3945, 3.3311],\n",
      "        [3.3994, 3.3079, 3.6241, 3.4820, 3.5138],\n",
      "        [3.3207, 3.3006, 3.3880, 3.3836, 3.3549],\n",
      "        [3.3883, 3.5830, 3.4398, 3.5163, 3.5903],\n",
      "        [3.6895, 3.8777, 3.4406, 3.5627, 3.5070],\n",
      "        [3.3224, 3.5148, 3.4284, 3.3559, 3.4770],\n",
      "        [3.4972, 3.5457, 3.5350, 3.5391, 3.6796],\n",
      "        [3.3160, 3.3996, 3.2512, 3.3917, 3.3648],\n",
      "        [3.1841, 3.4244, 3.1880, 3.3650, 3.2313],\n",
      "        [3.3243, 3.3474, 3.3853, 3.4135, 3.3888],\n",
      "        [3.2121, 3.4241, 3.3676, 3.3247, 3.3495],\n",
      "        [3.2255, 3.3771, 3.2240, 3.3672, 3.2884],\n",
      "        [3.3580, 3.3191, 3.4312, 3.4287, 3.3828],\n",
      "        [3.2998, 3.3764, 3.2786, 3.3826, 3.3683],\n",
      "        [3.6932, 3.6369, 3.6222, 3.7559, 3.7270],\n",
      "        [3.3402, 3.4297, 3.3936, 3.3993, 3.4130],\n",
      "        [3.4653, 3.5647, 3.4098, 3.4855, 3.4894],\n",
      "        [3.4938, 3.4866, 3.5514, 3.5085, 3.3874],\n",
      "        [3.1682, 3.4207, 3.2819, 3.1379, 3.3278],\n",
      "        [3.2247, 3.3618, 3.3149, 3.4448, 3.2630],\n",
      "        [3.6689, 3.5058, 3.5420, 4.0250, 3.8734],\n",
      "        [3.5234, 3.6487, 3.4000, 3.4990, 3.5171],\n",
      "        [3.2329, 3.2912, 3.2176, 3.3760, 3.2773],\n",
      "        [3.5491, 3.6131, 3.4635, 3.5794, 3.6532],\n",
      "        [3.4863, 3.4871, 3.5213, 3.5794, 3.3707],\n",
      "        [3.5603, 3.5316, 3.5570, 3.6564, 3.5657],\n",
      "        [3.1802, 3.3566, 3.3315, 3.2956, 3.2831],\n",
      "        [3.3212, 3.2958, 3.3842, 3.3919, 3.3504],\n",
      "        [3.7119, 3.7413, 3.6206, 3.9379, 3.7636],\n",
      "        [3.4128, 3.5771, 3.4399, 3.6146, 3.4984],\n",
      "        [3.4779, 3.5543, 3.5292, 3.5747, 3.4856],\n",
      "        [3.4887, 3.6402, 3.4457, 3.3924, 3.4280]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2803, 3.2187, 3.3907, 3.2208, 3.4158],\n",
      "        [3.3126, 3.3916, 3.2429, 3.3985, 3.3351],\n",
      "        [3.2236, 3.3558, 3.3802, 3.3538, 3.3075],\n",
      "        [3.4466, 3.3300, 3.6126, 3.5263, 3.5432],\n",
      "        [3.3278, 3.3421, 3.3841, 3.4095, 3.3860],\n",
      "        [3.3235, 3.3477, 3.4743, 3.3280, 3.5306],\n",
      "        [3.6327, 3.5628, 3.5615, 3.7494, 3.6453],\n",
      "        [3.2430, 3.2078, 3.2732, 3.3322, 3.2489],\n",
      "        [3.4786, 3.5519, 3.5317, 3.5766, 3.4840],\n",
      "        [3.4897, 3.5305, 3.4942, 3.5478, 3.5997],\n",
      "        [3.2305, 3.4406, 3.5353, 3.3984, 3.4437],\n",
      "        [3.1443, 3.2720, 3.2228, 3.2056, 3.2395],\n",
      "        [3.1389, 3.2755, 3.2636, 3.2858, 3.2790],\n",
      "        [3.2642, 3.3889, 3.3435, 3.4819, 3.2964],\n",
      "        [3.4233, 3.2519, 3.5170, 3.4858, 3.4480],\n",
      "        [3.3542, 3.5021, 3.3707, 3.3744, 3.4568],\n",
      "        [3.3391, 3.4216, 3.2555, 3.4321, 3.3632],\n",
      "        [3.5030, 3.3743, 3.4214, 3.4582, 3.4559],\n",
      "        [3.2511, 3.3315, 3.3820, 3.3711, 3.2801],\n",
      "        [3.3423, 3.3530, 3.4203, 3.4434, 3.4187],\n",
      "        [3.4496, 3.3930, 3.4564, 3.4959, 3.4170],\n",
      "        [3.3828, 3.4196, 3.3931, 3.4602, 3.4912],\n",
      "        [3.5418, 3.6518, 3.5418, 3.4684, 3.5748],\n",
      "        [3.2773, 3.4218, 3.2925, 3.4685, 3.3132],\n",
      "        [3.3244, 3.3724, 3.3862, 3.4013, 3.5370],\n",
      "        [3.3048, 3.3327, 3.5055, 3.2643, 3.5411],\n",
      "        [3.5648, 3.5312, 3.4181, 3.5834, 3.6134],\n",
      "        [3.7201, 3.8284, 3.5623, 3.6182, 3.5449],\n",
      "        [3.6780, 3.7181, 3.5783, 3.8982, 3.7314],\n",
      "        [3.2420, 3.2583, 3.3173, 3.3346, 3.2549],\n",
      "        [3.5452, 3.4968, 3.5236, 3.5605, 3.6942],\n",
      "        [3.4737, 3.4874, 3.5485, 3.4901, 3.3435],\n",
      "        [3.3844, 3.5031, 3.3585, 3.5041, 3.4315],\n",
      "        [3.4508, 3.6760, 3.4895, 3.5688, 3.5487],\n",
      "        [3.2511, 3.3315, 3.3820, 3.3711, 3.2801],\n",
      "        [3.5821, 3.7238, 3.5144, 3.4881, 3.4985],\n",
      "        [3.3913, 3.3095, 3.3936, 3.4407, 3.3552],\n",
      "        [3.3250, 3.3368, 3.4107, 3.4196, 3.4057],\n",
      "        [3.2261, 3.5717, 3.4658, 3.3965, 3.5571],\n",
      "        [3.3283, 3.6230, 3.3851, 3.5708, 3.5094],\n",
      "        [3.3558, 3.3081, 3.4414, 3.4596, 3.4916],\n",
      "        [3.3485, 3.5138, 3.3831, 3.5430, 3.3939],\n",
      "        [3.2308, 3.3496, 3.4134, 3.3631, 3.2822],\n",
      "        [3.2315, 3.3645, 3.3209, 3.4491, 3.2671],\n",
      "        [3.4815, 3.5961, 3.4223, 3.6641, 3.5523],\n",
      "        [3.6290, 3.5902, 3.6122, 3.7475, 3.6389],\n",
      "        [3.4404, 3.3868, 3.4472, 3.4818, 3.4083],\n",
      "        [3.2768, 3.3315, 3.2739, 3.4291, 3.3385],\n",
      "        [3.7147, 3.9095, 3.4848, 3.6119, 3.4912],\n",
      "        [3.2583, 3.3251, 3.3375, 3.3005, 3.3166],\n",
      "        [3.4333, 3.7265, 3.4951, 3.6645, 3.6222],\n",
      "        [3.3796, 3.6925, 3.4756, 3.6180, 3.5940],\n",
      "        [3.1995, 3.2864, 3.3128, 3.3010, 3.2698],\n",
      "        [3.3746, 3.3572, 3.4627, 3.4521, 3.4409],\n",
      "        [3.2540, 3.2602, 3.3128, 3.3353, 3.2682],\n",
      "        [3.3301, 3.3122, 3.4364, 3.4352, 3.4079],\n",
      "        [3.3103, 3.4646, 3.4007, 3.4164, 3.4146],\n",
      "        [3.4068, 3.4603, 3.3551, 3.4989, 3.4595],\n",
      "        [3.4919, 3.5947, 3.3948, 3.4998, 3.5375],\n",
      "        [3.3338, 3.3200, 3.3885, 3.3983, 3.3784],\n",
      "        [3.4429, 3.4721, 3.4263, 3.6157, 3.4438],\n",
      "        [3.5409, 3.5598, 3.5685, 3.6114, 3.5112],\n",
      "        [3.3459, 3.3253, 3.4005, 3.4019, 3.3872],\n",
      "        [3.4161, 3.4165, 3.3579, 3.5341, 3.4511]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3480, 3.4282, 3.2674, 3.4421, 3.3802],\n",
      "        [3.4317, 3.5948, 3.5714, 3.5497, 3.4576],\n",
      "        [3.2277, 3.2679, 3.3178, 3.3348, 3.2815],\n",
      "        [3.2490, 3.3125, 3.2567, 3.3496, 3.2823],\n",
      "        [3.2656, 3.3954, 3.3601, 3.4907, 3.3160],\n",
      "        [3.5537, 3.5388, 3.5738, 3.5069, 3.3499],\n",
      "        [3.3629, 3.4355, 3.5018, 3.4680, 3.4746],\n",
      "        [3.6040, 3.2908, 3.4469, 3.8084, 3.7527],\n",
      "        [3.6361, 3.5214, 3.6075, 3.7502, 3.6106],\n",
      "        [3.4623, 3.4019, 3.4625, 3.5066, 3.4210],\n",
      "        [3.2313, 3.3395, 3.2505, 3.2968, 3.3012],\n",
      "        [3.5314, 3.5951, 3.4313, 3.5396, 3.6052],\n",
      "        [3.3746, 3.3386, 3.4480, 3.4158, 3.4017],\n",
      "        [3.5537, 3.6032, 3.5744, 3.5998, 3.7360],\n",
      "        [3.4438, 3.5248, 3.5353, 3.5258, 3.5051],\n",
      "        [3.4834, 3.5564, 3.5682, 3.5866, 3.5793],\n",
      "        [3.3709, 3.4546, 3.2740, 3.4782, 3.3975],\n",
      "        [3.2855, 3.2287, 3.2919, 3.3618, 3.2510],\n",
      "        [3.1930, 3.4022, 3.3645, 3.3085, 3.3143],\n",
      "        [3.1433, 3.2693, 3.2243, 3.2004, 3.2454],\n",
      "        [3.3297, 3.4584, 3.4386, 3.4206, 3.5246],\n",
      "        [3.4638, 3.5935, 3.5127, 3.6584, 3.5078],\n",
      "        [3.3677, 3.3746, 3.4123, 3.3296, 3.2412],\n",
      "        [3.4362, 3.5451, 3.4787, 3.4849, 3.3597],\n",
      "        [3.4597, 3.5899, 3.5390, 3.5805, 3.5710],\n",
      "        [3.4271, 3.4562, 3.5002, 3.5032, 3.4419],\n",
      "        [3.3730, 3.6774, 3.4749, 3.5859, 3.6038],\n",
      "        [3.2023, 3.2341, 3.2877, 3.2861, 3.2461],\n",
      "        [3.2334, 3.2372, 3.2932, 3.3200, 3.2647],\n",
      "        [3.3597, 3.3482, 3.4549, 3.4563, 3.4427],\n",
      "        [3.6349, 3.6394, 3.5263, 3.6579, 3.7192],\n",
      "        [3.3761, 3.3587, 3.4755, 3.4817, 3.4547],\n",
      "        [3.5587, 3.5444, 3.6769, 3.5129, 3.3942],\n",
      "        [3.2719, 3.5742, 3.4003, 3.4659, 3.5123],\n",
      "        [3.3139, 3.5556, 3.4096, 3.3933, 3.3089],\n",
      "        [3.2385, 3.2524, 3.3020, 3.3257, 3.2727],\n",
      "        [3.5022, 3.4227, 3.5166, 3.5662, 3.4717],\n",
      "        [3.2341, 3.2749, 3.2100, 3.3651, 3.2037],\n",
      "        [3.1271, 3.2467, 3.2092, 3.1908, 3.2272],\n",
      "        [3.4777, 3.5500, 3.4452, 3.4387, 3.4704],\n",
      "        [3.3380, 3.3109, 3.4167, 3.3975, 3.3714],\n",
      "        [3.3492, 3.3096, 3.4119, 3.3565, 3.4289],\n",
      "        [3.5925, 3.5448, 3.5659, 3.7010, 3.5847],\n",
      "        [3.1713, 3.2051, 3.2715, 3.2645, 3.1917],\n",
      "        [3.4006, 3.3114, 3.5234, 3.5221, 3.4368],\n",
      "        [3.4819, 3.5922, 3.4219, 3.6593, 3.5467],\n",
      "        [3.3336, 3.3421, 3.3890, 3.4119, 3.3879],\n",
      "        [3.5134, 3.6308, 3.4094, 3.4955, 3.5225],\n",
      "        [3.3808, 3.4673, 3.2685, 3.3808, 3.4007],\n",
      "        [3.3294, 3.4590, 3.4173, 3.4277, 3.4038],\n",
      "        [3.2865, 3.2211, 3.3961, 3.2245, 3.4194],\n",
      "        [3.6909, 3.7924, 3.4516, 3.5919, 3.5174],\n",
      "        [3.7299, 3.8272, 3.4551, 3.6184, 3.4932],\n",
      "        [3.5664, 3.5851, 3.5591, 3.5955, 3.7457],\n",
      "        [3.4258, 3.4121, 3.3992, 3.5532, 3.4510],\n",
      "        [3.3967, 3.3637, 3.5005, 3.5795, 3.6255],\n",
      "        [3.6497, 3.5689, 3.5507, 3.6687, 3.6180],\n",
      "        [3.5033, 3.4351, 3.4221, 3.7225, 3.5872],\n",
      "        [3.2563, 3.3888, 3.4532, 3.4264, 3.4748],\n",
      "        [3.5133, 3.7322, 3.6192, 3.6289, 3.6748],\n",
      "        [3.2476, 3.3762, 3.2879, 3.4197, 3.2992],\n",
      "        [3.5647, 3.5802, 3.5597, 3.6039, 3.7494],\n",
      "        [3.4752, 3.4663, 3.4839, 3.4635, 3.3216],\n",
      "        [3.3412, 3.3782, 3.4020, 3.4018, 3.5636]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3557, 3.6561, 3.4115, 3.6108, 3.5437],\n",
      "        [3.5179, 3.5973, 3.5707, 3.5368, 3.3944],\n",
      "        [3.5881, 3.6336, 3.5022, 3.6154, 3.6944],\n",
      "        [3.4535, 3.4095, 3.4721, 3.4245, 3.3540],\n",
      "        [3.3080, 3.3008, 3.3811, 3.3712, 3.3617],\n",
      "        [3.4480, 3.3807, 3.4627, 3.3842, 3.3971],\n",
      "        [3.3430, 3.4283, 3.3982, 3.3901, 3.4141],\n",
      "        [3.3086, 3.2554, 3.3257, 3.3584, 3.4579],\n",
      "        [3.5422, 3.6561, 3.4168, 3.5116, 3.5282],\n",
      "        [3.4978, 3.6038, 3.5253, 3.5951, 3.5210],\n",
      "        [3.2376, 3.4088, 3.4738, 3.3532, 3.4198],\n",
      "        [3.3829, 3.3630, 3.4820, 3.4818, 3.4617],\n",
      "        [3.2520, 3.2582, 3.1939, 3.3720, 3.1829],\n",
      "        [3.3348, 3.3281, 3.3816, 3.4002, 3.3814],\n",
      "        [3.3435, 3.3276, 3.3863, 3.4110, 3.3857],\n",
      "        [3.5048, 3.6102, 3.4669, 3.5724, 3.5342],\n",
      "        [3.3920, 3.6973, 3.4865, 3.6260, 3.6010],\n",
      "        [3.3431, 3.4032, 3.2998, 3.4040, 3.3993],\n",
      "        [3.2509, 3.2574, 3.1877, 3.3705, 3.2056],\n",
      "        [3.3726, 3.4589, 3.2864, 3.4787, 3.4086],\n",
      "        [3.3436, 3.5975, 3.5077, 3.5150, 3.5943],\n",
      "        [3.4243, 3.5477, 3.4732, 3.4823, 3.3532],\n",
      "        [3.3319, 3.3760, 3.4917, 3.5182, 3.5577],\n",
      "        [3.6199, 3.6388, 3.5240, 3.6534, 3.6998],\n",
      "        [3.4031, 3.3142, 3.4039, 3.4484, 3.3619],\n",
      "        [3.3491, 3.4999, 3.4066, 3.3808, 3.4700],\n",
      "        [3.5173, 3.4697, 3.5037, 3.5354, 3.6781],\n",
      "        [3.4508, 3.3701, 3.4550, 3.3899, 3.4036],\n",
      "        [3.4655, 3.5509, 3.5077, 3.5208, 3.3845],\n",
      "        [3.3541, 3.3300, 3.4056, 3.4095, 3.3943],\n",
      "        [3.5671, 3.6830, 3.5613, 3.4804, 3.6054],\n",
      "        [3.5681, 3.6205, 3.4807, 3.5921, 3.6646],\n",
      "        [3.3452, 3.4238, 3.2674, 3.4355, 3.3751],\n",
      "        [3.2304, 3.4314, 3.5282, 3.3809, 3.4376],\n",
      "        [3.2144, 3.4194, 3.3776, 3.3374, 3.3434],\n",
      "        [3.2855, 3.3054, 3.3795, 3.3914, 3.3769],\n",
      "        [3.6334, 3.5446, 3.5586, 3.6471, 3.6187],\n",
      "        [3.2495, 3.4890, 3.2890, 3.1751, 3.4011],\n",
      "        [3.3556, 3.4740, 3.4451, 3.4445, 3.3844],\n",
      "        [3.5984, 3.5470, 3.5713, 3.7054, 3.5882],\n",
      "        [3.4418, 3.3799, 3.4218, 3.3773, 3.2727],\n",
      "        [3.2619, 3.4654, 3.3946, 3.4080, 3.5320],\n",
      "        [3.3207, 3.3909, 3.3799, 3.4436, 3.4621],\n",
      "        [3.4235, 3.6149, 3.5507, 3.5078, 3.5509],\n",
      "        [3.3118, 3.3775, 3.3697, 3.4378, 3.4554],\n",
      "        [3.3959, 3.2929, 3.3911, 3.4283, 3.3397],\n",
      "        [3.6214, 3.7438, 3.5456, 3.5163, 3.5760],\n",
      "        [3.2009, 3.3389, 3.3423, 3.3145, 3.2965],\n",
      "        [3.6587, 3.4207, 3.4778, 3.9240, 3.7318],\n",
      "        [3.3670, 3.3897, 3.4202, 3.3439, 3.2392],\n",
      "        [3.3652, 3.3438, 3.4357, 3.4259, 3.4387],\n",
      "        [3.3816, 3.5064, 3.3892, 3.5163, 3.4141],\n",
      "        [3.2945, 3.5403, 3.3668, 3.3426, 3.3032],\n",
      "        [3.3494, 3.3017, 3.3015, 3.4747, 3.2972],\n",
      "        [3.2763, 3.3936, 3.3539, 3.4901, 3.3033],\n",
      "        [3.5140, 3.5973, 3.4191, 3.5181, 3.5645],\n",
      "        [3.5797, 3.5392, 3.5748, 3.6689, 3.5775],\n",
      "        [3.5592, 3.7010, 3.5457, 3.7098, 3.6421],\n",
      "        [3.2536, 3.3429, 3.2499, 3.3186, 3.3048],\n",
      "        [3.3310, 3.4148, 3.2703, 3.4177, 3.3700],\n",
      "        [3.2648, 3.3151, 3.2581, 3.3689, 3.2883],\n",
      "        [3.3372, 3.3170, 3.3950, 3.4065, 3.3831],\n",
      "        [3.1957, 3.3149, 3.2454, 3.2589, 3.2794],\n",
      "        [3.2948, 3.1941, 3.2513, 3.3370, 3.2408]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3560, 3.4292, 3.2645, 3.4487, 3.3805],\n",
      "        [3.1535, 3.2697, 3.2325, 3.2085, 3.2482],\n",
      "        [3.5530, 3.5506, 3.5952, 3.5628, 3.6152],\n",
      "        [3.2070, 3.3605, 3.3537, 3.3234, 3.3086],\n",
      "        [3.5045, 3.5372, 3.5240, 3.5264, 3.6051],\n",
      "        [3.4729, 3.4259, 3.3831, 3.6298, 3.5231],\n",
      "        [3.3903, 3.5008, 3.3512, 3.3929, 3.4510],\n",
      "        [3.3244, 3.2811, 3.3768, 3.3542, 3.3392],\n",
      "        [3.2052, 3.3305, 3.3384, 3.3070, 3.2863],\n",
      "        [3.3433, 3.5870, 3.4702, 3.5265, 3.5773],\n",
      "        [3.4564, 3.2734, 3.5580, 3.5051, 3.4684],\n",
      "        [3.2405, 3.3623, 3.2929, 3.3981, 3.3059],\n",
      "        [3.3259, 3.2778, 3.3985, 3.3868, 3.3473],\n",
      "        [3.5419, 3.5040, 3.6963, 3.4779, 3.4249],\n",
      "        [3.4992, 3.5628, 3.4456, 3.5042, 3.4924],\n",
      "        [3.3653, 3.5016, 3.3778, 3.4408, 3.4733],\n",
      "        [3.5877, 3.7064, 3.6907, 3.6459, 3.4769],\n",
      "        [3.2494, 3.3863, 3.2445, 3.3824, 3.3033],\n",
      "        [3.6267, 3.6337, 3.5215, 3.6500, 3.7054],\n",
      "        [3.6509, 3.5634, 3.5666, 3.6597, 3.6169],\n",
      "        [3.5575, 3.5764, 3.5479, 3.5861, 3.7274],\n",
      "        [3.2965, 3.3977, 3.3767, 3.4928, 3.3238],\n",
      "        [3.3517, 3.5147, 3.4310, 3.3792, 3.4845],\n",
      "        [3.5107, 3.4966, 3.5430, 3.5954, 3.3858],\n",
      "        [3.2038, 3.4064, 3.3737, 3.3161, 3.3216],\n",
      "        [3.3260, 3.4203, 3.3654, 3.4796, 3.4470],\n",
      "        [3.2430, 3.3429, 3.2558, 3.3105, 3.3068],\n",
      "        [3.4892, 3.5026, 3.3508, 3.5834, 3.5706],\n",
      "        [3.4297, 3.4843, 3.5828, 3.5240, 3.5432],\n",
      "        [3.3474, 3.5638, 3.3518, 3.5556, 3.4687],\n",
      "        [3.5972, 3.5969, 3.5530, 3.7245, 3.5648],\n",
      "        [3.3335, 3.4558, 3.4364, 3.4181, 3.5310],\n",
      "        [3.4742, 3.5238, 3.6061, 3.5845, 3.5791],\n",
      "        [3.2522, 3.2438, 3.3003, 3.3364, 3.2715],\n",
      "        [3.1878, 3.2192, 3.2897, 3.2814, 3.2050],\n",
      "        [3.4644, 3.3365, 3.6278, 3.5380, 3.5543],\n",
      "        [3.5021, 3.4338, 3.4476, 3.4085, 3.3450],\n",
      "        [3.3321, 3.4683, 3.4412, 3.4327, 3.4821],\n",
      "        [3.4522, 3.4624, 3.3264, 3.5585, 3.5533],\n",
      "        [3.3483, 3.4303, 3.4027, 3.3936, 3.4180],\n",
      "        [3.4084, 3.2232, 3.5159, 3.4957, 3.4894],\n",
      "        [3.0518, 3.1940, 3.2617, 3.1854, 3.2314],\n",
      "        [3.3727, 3.3562, 3.4618, 3.4680, 3.4386],\n",
      "        [3.5043, 3.5630, 3.4500, 3.4872, 3.4954],\n",
      "        [3.2683, 3.3382, 3.3967, 3.3823, 3.2910],\n",
      "        [3.4093, 3.3077, 3.3911, 3.4478, 3.3459],\n",
      "        [3.3671, 3.4408, 3.2715, 3.4633, 3.3880],\n",
      "        [3.3789, 3.2731, 3.3811, 3.3234, 3.3138],\n",
      "        [3.3469, 3.3187, 3.4006, 3.4050, 3.3839],\n",
      "        [3.3369, 3.5996, 3.5038, 3.5099, 3.5907],\n",
      "        [3.5887, 3.5565, 3.5884, 3.7319, 3.7892],\n",
      "        [3.4003, 3.4265, 3.4083, 3.4718, 3.5020],\n",
      "        [3.3386, 3.3155, 3.3895, 3.3988, 3.3787],\n",
      "        [3.2044, 3.3812, 3.3598, 3.3125, 3.3059],\n",
      "        [3.4739, 3.5796, 3.4125, 3.6420, 3.5234],\n",
      "        [3.2896, 3.3900, 3.4636, 3.4592, 3.5103],\n",
      "        [3.6397, 3.5181, 3.4904, 3.5921, 3.5681],\n",
      "        [3.6853, 3.4139, 3.4826, 3.9626, 3.7533],\n",
      "        [3.5865, 3.5654, 3.7029, 3.5507, 3.4296],\n",
      "        [3.5934, 3.6356, 3.5070, 3.6193, 3.6986],\n",
      "        [3.2367, 3.3428, 3.2566, 3.3085, 3.3045],\n",
      "        [3.2964, 3.2328, 3.3012, 3.3694, 3.2580],\n",
      "        [3.4724, 3.6140, 3.5486, 3.5843, 3.6123],\n",
      "        [3.1820, 3.2092, 3.2805, 3.2717, 3.1987]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3243, 3.3504, 3.3448, 3.3411, 3.3716],\n",
      "        [3.2423, 3.3441, 3.2606, 3.3066, 3.3063],\n",
      "        [3.2785, 3.5453, 3.4195, 3.2663, 3.5095],\n",
      "        [3.5622, 3.6324, 3.5478, 3.5975, 3.6647],\n",
      "        [3.6437, 3.5486, 3.5685, 3.6542, 3.6272],\n",
      "        [3.3255, 3.3372, 3.3000, 3.4352, 3.3387],\n",
      "        [3.4228, 3.4891, 3.4971, 3.5547, 3.5276],\n",
      "        [3.5104, 3.6039, 3.4749, 3.5882, 3.5380],\n",
      "        [3.3993, 3.4068, 3.4789, 3.4827, 3.5461],\n",
      "        [3.4983, 3.4272, 3.4429, 3.3977, 3.3415],\n",
      "        [3.2809, 3.3579, 3.2604, 3.3431, 3.3205],\n",
      "        [3.5972, 3.6100, 3.6093, 3.6270, 3.7981],\n",
      "        [3.4499, 3.4806, 3.4120, 3.4735, 3.4357],\n",
      "        [3.5839, 3.4629, 3.4291, 3.5363, 3.5551],\n",
      "        [3.3659, 3.2667, 3.3761, 3.3296, 3.3121],\n",
      "        [3.4239, 3.3974, 3.5247, 3.5031, 3.4816],\n",
      "        [3.4095, 3.6318, 3.5896, 3.5846, 3.6134],\n",
      "        [3.2186, 3.3981, 3.3766, 3.3328, 3.3349],\n",
      "        [3.2659, 3.4599, 3.4071, 3.4107, 3.5366],\n",
      "        [3.4317, 3.4435, 3.4361, 3.4769, 3.4402],\n",
      "        [3.5867, 3.4266, 3.4467, 3.5182, 3.5392],\n",
      "        [3.5144, 3.6530, 3.4950, 3.5729, 3.5519],\n",
      "        [3.3565, 3.5166, 3.4363, 3.3826, 3.4891],\n",
      "        [3.5169, 3.6197, 3.5449, 3.6009, 3.5339],\n",
      "        [3.5187, 3.5393, 3.5306, 3.6188, 3.6389],\n",
      "        [3.5990, 3.5353, 3.5786, 3.6835, 3.5827],\n",
      "        [3.3347, 3.4247, 3.2792, 3.4231, 3.3763],\n",
      "        [3.2205, 3.4096, 3.3787, 3.3368, 3.3387],\n",
      "        [3.5587, 3.6988, 3.5354, 3.6938, 3.6448],\n",
      "        [3.5468, 3.5126, 3.5568, 3.6644, 3.5447],\n",
      "        [3.4938, 3.5541, 3.4571, 3.4287, 3.4816],\n",
      "        [3.3832, 3.3809, 3.4264, 3.3404, 3.2526],\n",
      "        [3.1788, 3.2952, 3.2451, 3.2406, 3.2682],\n",
      "        [3.2607, 3.3851, 3.4646, 3.3967, 3.4553],\n",
      "        [3.4976, 3.4262, 3.3978, 3.6757, 3.5514],\n",
      "        [3.2861, 3.4458, 3.2673, 3.4294, 3.2853],\n",
      "        [3.4641, 3.6591, 3.5761, 3.5787, 3.7076],\n",
      "        [3.3309, 3.3948, 3.3898, 3.4506, 3.4705],\n",
      "        [3.1788, 3.2952, 3.2451, 3.2406, 3.2682],\n",
      "        [3.4329, 3.5103, 3.3732, 3.5061, 3.4914],\n",
      "        [3.3465, 3.3379, 3.3953, 3.4117, 3.3933],\n",
      "        [3.2543, 3.2280, 3.2959, 3.3420, 3.2660],\n",
      "        [3.3720, 3.4277, 3.5850, 3.4834, 3.5548],\n",
      "        [3.1989, 3.1589, 3.2645, 3.3339, 3.2483],\n",
      "        [3.4879, 3.6837, 3.6122, 3.5890, 3.6321],\n",
      "        [3.6269, 3.5965, 3.5942, 3.7393, 3.5716],\n",
      "        [3.3364, 3.3499, 3.5027, 3.3243, 3.5412],\n",
      "        [3.4508, 3.3709, 3.4620, 3.3899, 3.3937],\n",
      "        [3.2086, 3.3678, 3.3569, 3.3140, 3.3024],\n",
      "        [3.3326, 3.4731, 3.4212, 3.4316, 3.4302],\n",
      "        [3.3614, 3.3341, 3.4104, 3.4145, 3.4021],\n",
      "        [3.4666, 3.6988, 3.5900, 3.5866, 3.6401],\n",
      "        [3.3919, 3.4436, 3.4317, 3.4463, 3.4379],\n",
      "        [3.3384, 3.4576, 3.4418, 3.4215, 3.5356],\n",
      "        [3.2894, 3.3054, 3.3862, 3.4120, 3.3883],\n",
      "        [3.2488, 3.2854, 3.2243, 3.3750, 3.2022],\n",
      "        [3.4813, 3.2837, 3.3258, 3.4006, 3.4308],\n",
      "        [3.3425, 3.3392, 3.3962, 3.4150, 3.3931],\n",
      "        [3.2150, 3.2979, 3.3289, 3.3093, 3.2834],\n",
      "        [3.3483, 3.5566, 3.4330, 3.4224, 3.3159],\n",
      "        [3.3699, 3.4445, 3.2812, 3.4661, 3.3940],\n",
      "        [3.3690, 3.4327, 3.2749, 3.4585, 3.3828],\n",
      "        [3.7570, 3.8484, 3.4643, 3.6436, 3.4924],\n",
      "        [3.7459, 3.8486, 3.5944, 3.6338, 3.5898]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2441, 3.2850, 3.2915, 3.3262, 3.2964],\n",
      "        [3.3858, 3.6585, 3.4610, 3.5853, 3.5749],\n",
      "        [3.5059, 3.4847, 3.5118, 3.4844, 3.3482],\n",
      "        [3.4137, 3.6343, 3.5949, 3.5885, 3.6185],\n",
      "        [3.3599, 3.3137, 3.4386, 3.4238, 3.3952],\n",
      "        [3.7263, 3.4695, 3.6010, 4.0717, 3.9106],\n",
      "        [3.3380, 3.4080, 3.4069, 3.5181, 3.3988],\n",
      "        [3.5385, 3.3809, 3.4242, 3.7910, 3.6014],\n",
      "        [3.2789, 3.5434, 3.5276, 3.4323, 3.5686],\n",
      "        [3.7027, 3.5893, 3.6844, 3.8296, 3.6822],\n",
      "        [3.4275, 3.3905, 3.5150, 3.5048, 3.4818],\n",
      "        [3.2362, 3.2711, 3.3235, 3.3234, 3.2873],\n",
      "        [3.6130, 3.5536, 3.5867, 3.7170, 3.6030],\n",
      "        [3.3467, 3.3416, 3.4009, 3.4187, 3.3980],\n",
      "        [3.5582, 3.6460, 3.6359, 3.5723, 3.3759],\n",
      "        [3.1819, 3.2945, 3.2514, 3.2373, 3.2807],\n",
      "        [3.2984, 3.3454, 3.1911, 3.4439, 3.2451],\n",
      "        [3.2394, 3.4079, 3.4844, 3.3616, 3.4260],\n",
      "        [3.4026, 3.5924, 3.4119, 3.6082, 3.5090],\n",
      "        [3.2428, 3.2823, 3.3323, 3.3298, 3.3034],\n",
      "        [3.4916, 3.5390, 3.5933, 3.5110, 3.4117],\n",
      "        [3.6022, 3.5635, 3.5173, 3.6058, 3.5940],\n",
      "        [3.6080, 3.7346, 3.5400, 3.5071, 3.5192],\n",
      "        [3.2342, 3.2770, 3.3268, 3.3202, 3.2869],\n",
      "        [3.6971, 3.6072, 3.5708, 3.7025, 3.6715],\n",
      "        [3.5086, 3.6075, 3.4479, 3.6831, 3.5732],\n",
      "        [3.2999, 3.3118, 3.3941, 3.4022, 3.3903],\n",
      "        [3.3106, 3.3632, 3.3039, 3.3328, 3.3326],\n",
      "        [3.2646, 3.2635, 3.2014, 3.3807, 3.2184],\n",
      "        [3.2882, 3.5503, 3.4668, 3.4600, 3.5352],\n",
      "        [3.5812, 3.5585, 3.5236, 3.5907, 3.6005],\n",
      "        [3.4970, 3.5801, 3.4513, 3.6284, 3.6806],\n",
      "        [3.3839, 3.4539, 3.2983, 3.4835, 3.4096],\n",
      "        [3.3509, 3.4011, 3.4808, 3.4655, 3.4892],\n",
      "        [3.6450, 3.7350, 3.4487, 3.5555, 3.5311],\n",
      "        [3.2753, 3.3377, 3.2709, 3.3810, 3.3129],\n",
      "        [3.4533, 3.3771, 3.5649, 3.5791, 3.4283],\n",
      "        [3.7034, 3.6465, 3.5779, 3.7215, 3.6819],\n",
      "        [3.3715, 3.4183, 3.3226, 3.4383, 3.4258],\n",
      "        [3.1809, 3.3044, 3.2918, 3.3129, 3.3127],\n",
      "        [3.4901, 3.6137, 3.5618, 3.5993, 3.6094],\n",
      "        [3.3087, 3.2003, 3.2653, 3.3474, 3.2537],\n",
      "        [3.2886, 3.3100, 3.3647, 3.4133, 3.2969],\n",
      "        [3.3577, 3.3339, 3.4006, 3.4217, 3.3988],\n",
      "        [3.5135, 3.5632, 3.4494, 3.5822, 3.5259],\n",
      "        [3.2622, 3.3442, 3.2419, 3.3883, 3.3161],\n",
      "        [3.2732, 3.4358, 3.3964, 3.2901, 3.3164],\n",
      "        [3.2126, 3.4105, 3.3832, 3.3230, 3.3310],\n",
      "        [3.5334, 3.6394, 3.4292, 3.5110, 3.5393],\n",
      "        [3.3960, 3.3674, 3.4947, 3.4964, 3.4710],\n",
      "        [3.3765, 3.4455, 3.2833, 3.4853, 3.4026],\n",
      "        [3.3718, 3.4114, 3.3269, 3.4996, 3.4179],\n",
      "        [3.5471, 3.6495, 3.4181, 3.5020, 3.5281],\n",
      "        [3.2677, 3.4434, 3.5658, 3.4008, 3.4832],\n",
      "        [3.4349, 3.4713, 3.3828, 3.5146, 3.4749],\n",
      "        [3.3638, 3.3653, 3.4195, 3.4422, 3.4263],\n",
      "        [3.4640, 3.5337, 3.5547, 3.5409, 3.5219],\n",
      "        [3.4709, 3.7013, 3.5948, 3.5904, 3.6452],\n",
      "        [3.3586, 3.3588, 3.4347, 3.4440, 3.4271],\n",
      "        [3.5833, 3.5783, 3.6487, 3.7447, 3.5341],\n",
      "        [3.3622, 3.4255, 3.2859, 3.4328, 3.4000],\n",
      "        [3.6185, 3.5063, 3.4920, 3.5771, 3.6090],\n",
      "        [3.3284, 3.3443, 3.5124, 3.3044, 3.5418],\n",
      "        [3.2446, 3.4376, 3.5428, 3.3915, 3.4507]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3728, 3.3033, 3.4398, 3.4337, 3.4772],\n",
      "        [3.2776, 3.2904, 3.2152, 3.3916, 3.2834],\n",
      "        [3.4674, 3.4687, 3.4452, 3.6210, 3.4635],\n",
      "        [3.3082, 3.4002, 3.4441, 3.4323, 3.5490],\n",
      "        [3.6796, 3.7651, 3.4605, 3.5768, 3.5343],\n",
      "        [3.3455, 3.4163, 3.2812, 3.4255, 3.3808],\n",
      "        [3.4210, 3.2293, 3.5297, 3.5065, 3.5040],\n",
      "        [3.4810, 3.5571, 3.5277, 3.5328, 3.3995],\n",
      "        [3.5039, 3.4467, 3.5229, 3.6280, 3.4299],\n",
      "        [3.5078, 3.5677, 3.5922, 3.6061, 3.6018],\n",
      "        [3.3543, 3.3279, 3.4002, 3.4101, 3.3971],\n",
      "        [3.3608, 3.4115, 3.3179, 3.4183, 3.4176],\n",
      "        [3.7118, 3.7739, 3.6844, 3.9267, 3.7908],\n",
      "        [3.8988, 4.0629, 3.6913, 3.8049, 3.6646],\n",
      "        [3.4835, 3.7305, 3.5741, 3.6203, 3.7317],\n",
      "        [3.3681, 3.4314, 3.2842, 3.4576, 3.3925],\n",
      "        [3.2512, 3.2054, 3.2856, 3.3399, 3.2587],\n",
      "        [3.5184, 3.6083, 3.4841, 3.5958, 3.5486],\n",
      "        [3.5997, 3.5999, 3.6126, 3.6235, 3.6870],\n",
      "        [3.5030, 3.6144, 3.5836, 3.6135, 3.5301],\n",
      "        [3.6487, 3.7372, 3.4530, 3.5596, 3.5365],\n",
      "        [3.3624, 3.3500, 3.4128, 3.4273, 3.4148],\n",
      "        [3.3681, 3.4314, 3.2842, 3.4576, 3.3925],\n",
      "        [3.5089, 3.5687, 3.5613, 3.6825, 3.5083],\n",
      "        [3.5405, 3.4722, 3.6509, 3.5108, 3.3939],\n",
      "        [3.5214, 3.6488, 3.5728, 3.6030, 3.5450],\n",
      "        [3.3506, 3.3251, 3.4269, 3.4409, 3.4793],\n",
      "        [3.3515, 3.4154, 3.3994, 3.4139, 3.4321],\n",
      "        [3.4738, 3.5323, 3.4385, 3.4105, 3.4638],\n",
      "        [3.6739, 3.5799, 3.5750, 3.6880, 3.6407],\n",
      "        [3.5080, 3.6036, 3.4216, 3.5170, 3.5570],\n",
      "        [3.3440, 3.2816, 3.3761, 3.4047, 3.4959],\n",
      "        [3.4125, 3.4970, 3.3323, 3.4161, 3.4520],\n",
      "        [3.5515, 3.5131, 3.5891, 3.5961, 3.4346],\n",
      "        [3.2935, 3.2685, 3.3383, 3.3725, 3.2904],\n",
      "        [3.5912, 3.7002, 3.6704, 3.6241, 3.4578],\n",
      "        [3.2207, 3.4379, 3.2249, 3.3888, 3.2592],\n",
      "        [3.3507, 3.4442, 3.5658, 3.3967, 3.4381],\n",
      "        [3.3358, 3.3918, 3.3125, 3.4083, 3.3974],\n",
      "        [3.3577, 3.3529, 3.4128, 3.4309, 3.4097],\n",
      "        [3.4905, 3.5846, 3.5581, 3.5957, 3.5623],\n",
      "        [3.2244, 3.4060, 3.3822, 3.3335, 3.3381],\n",
      "        [3.5236, 3.5031, 3.5576, 3.6069, 3.4010],\n",
      "        [3.4408, 3.6054, 3.4623, 3.6350, 3.5313],\n",
      "        [3.3834, 3.3589, 3.4783, 3.4749, 3.4644],\n",
      "        [3.6715, 3.4274, 3.4984, 3.9455, 3.7438],\n",
      "        [3.5807, 3.6749, 3.6729, 3.6464, 3.4894],\n",
      "        [3.2645, 3.2157, 3.2933, 3.3459, 3.2685],\n",
      "        [3.6460, 3.6371, 3.5455, 3.6902, 3.7232],\n",
      "        [3.3147, 3.5499, 3.4048, 3.3735, 3.3182],\n",
      "        [3.2845, 3.6058, 3.5298, 3.4589, 3.5968],\n",
      "        [3.4954, 3.6299, 3.5691, 3.5949, 3.6538],\n",
      "        [3.2532, 3.3591, 3.2725, 3.3215, 3.3305],\n",
      "        [3.3685, 3.4839, 3.4544, 3.4551, 3.4040],\n",
      "        [3.5016, 3.5586, 3.4662, 3.4364, 3.4919],\n",
      "        [3.4187, 3.5709, 3.4538, 3.5248, 3.5969],\n",
      "        [3.3367, 3.3063, 3.4031, 3.3773, 3.3748],\n",
      "        [3.3661, 3.3483, 3.4169, 3.4182, 3.4608],\n",
      "        [3.4045, 3.3705, 3.4915, 3.4744, 3.4660],\n",
      "        [3.3457, 3.3257, 3.2705, 3.3801, 3.4625],\n",
      "        [3.2462, 3.2876, 3.3386, 3.3360, 3.3086],\n",
      "        [3.6060, 3.5657, 3.5216, 3.6100, 3.5997],\n",
      "        [3.3272, 3.3176, 3.3535, 3.4412, 3.3232],\n",
      "        [3.5125, 3.6097, 3.4523, 3.6873, 3.5787]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3008, 3.3343, 3.4161, 3.4430, 3.4198],\n",
      "        [3.5737, 3.7128, 3.5365, 3.4569, 3.5551],\n",
      "        [3.4234, 3.5729, 3.4577, 3.5292, 3.6023],\n",
      "        [3.4234, 3.5729, 3.4577, 3.5292, 3.6023],\n",
      "        [3.7148, 3.7345, 3.6157, 3.9279, 3.7654],\n",
      "        [3.5617, 3.5314, 3.5783, 3.6280, 3.7357],\n",
      "        [3.2465, 3.2798, 3.3360, 3.3309, 3.2991],\n",
      "        [3.3110, 3.3130, 3.3961, 3.4159, 3.4048],\n",
      "        [3.3441, 3.2840, 3.4134, 3.3996, 3.3705],\n",
      "        [3.2925, 3.3267, 3.4131, 3.4523, 3.4153],\n",
      "        [3.5297, 3.6275, 3.4971, 3.5788, 3.5631],\n",
      "        [3.2334, 3.3011, 3.3447, 3.3273, 3.3003],\n",
      "        [3.3399, 3.3232, 3.4288, 3.4396, 3.4887],\n",
      "        [3.2790, 3.2611, 3.3398, 3.3636, 3.2819],\n",
      "        [3.1981, 3.3081, 3.2613, 3.2653, 3.2948],\n",
      "        [3.3835, 3.3569, 3.4648, 3.4683, 3.4421],\n",
      "        [3.5169, 3.6169, 3.4342, 3.5295, 3.5655],\n",
      "        [3.5079, 3.6285, 3.4515, 3.5279, 3.5624],\n",
      "        [3.3584, 3.4255, 3.2839, 3.4513, 3.3864],\n",
      "        [3.6617, 3.4352, 3.4903, 3.9069, 3.7268],\n",
      "        [3.5271, 3.6593, 3.5082, 3.5850, 3.5680],\n",
      "        [3.5514, 3.5675, 3.6129, 3.7190, 3.5207],\n",
      "        [3.4765, 3.5339, 3.4257, 3.5548, 3.5780],\n",
      "        [3.5006, 3.6667, 3.4852, 3.3912, 3.5453],\n",
      "        [3.3511, 3.4668, 3.3308, 3.5451, 3.3437],\n",
      "        [3.2715, 3.2697, 3.2052, 3.3907, 3.2169],\n",
      "        [3.3738, 3.3630, 3.4309, 3.4524, 3.4435],\n",
      "        [3.7126, 3.5244, 3.5827, 4.0561, 3.9083],\n",
      "        [3.3773, 3.5061, 3.4003, 3.4480, 3.5004],\n",
      "        [3.5939, 3.6857, 3.6324, 3.6948, 3.6895],\n",
      "        [3.3890, 3.6785, 3.4878, 3.6082, 3.6071],\n",
      "        [3.5880, 3.3861, 3.4629, 3.8313, 3.6574],\n",
      "        [3.3630, 3.4202, 3.3724, 3.4070, 3.4187],\n",
      "        [3.5579, 3.3907, 3.4340, 3.4898, 3.5181],\n",
      "        [3.4040, 3.3612, 3.4290, 3.4426, 3.4579],\n",
      "        [3.5107, 3.5617, 3.4727, 3.4647, 3.4995],\n",
      "        [3.3775, 3.4016, 3.4938, 3.4724, 3.5403],\n",
      "        [3.1446, 3.2602, 3.2375, 3.1980, 3.2416],\n",
      "        [3.2268, 3.3602, 3.5184, 3.3229, 3.4800],\n",
      "        [3.3797, 3.4249, 3.3349, 3.4449, 3.4363],\n",
      "        [3.2497, 3.2632, 3.3268, 3.3339, 3.2918],\n",
      "        [3.7508, 3.8414, 3.5009, 3.6543, 3.5497],\n",
      "        [3.4373, 3.4265, 3.4122, 3.5348, 3.5678],\n",
      "        [3.2655, 3.2327, 3.3083, 3.3555, 3.2805],\n",
      "        [3.3283, 3.3824, 3.5236, 3.4414, 3.4991],\n",
      "        [3.6651, 3.5347, 3.6376, 3.7751, 3.6399],\n",
      "        [3.4934, 3.4871, 3.3447, 3.5868, 3.5974],\n",
      "        [3.5419, 3.6435, 3.4376, 3.5197, 3.5501],\n",
      "        [3.4420, 3.3253, 3.6637, 3.5139, 3.5495],\n",
      "        [3.3329, 3.4088, 3.2878, 3.4059, 3.3786],\n",
      "        [3.3809, 3.4436, 3.3757, 3.5106, 3.4657],\n",
      "        [3.4427, 3.6099, 3.4662, 3.6379, 3.5363],\n",
      "        [3.5764, 3.5757, 3.6036, 3.6400, 3.5445],\n",
      "        [3.4078, 3.5091, 3.3697, 3.4089, 3.4715],\n",
      "        [3.2579, 3.3216, 3.3764, 3.3564, 3.3070],\n",
      "        [3.7113, 3.5938, 3.6934, 3.8387, 3.6937],\n",
      "        [3.5077, 3.6165, 3.5877, 3.6181, 3.5358],\n",
      "        [3.5037, 3.4981, 3.5067, 3.4973, 3.3231],\n",
      "        [3.8901, 4.0663, 3.6317, 3.7625, 3.6872],\n",
      "        [3.5095, 3.5963, 3.5668, 3.5344, 3.4095],\n",
      "        [3.6028, 3.6903, 3.6895, 3.6481, 3.4641],\n",
      "        [3.4352, 3.5607, 3.4852, 3.4973, 3.3719],\n",
      "        [3.4249, 3.3324, 3.4346, 3.4717, 3.4249],\n",
      "        [3.4293, 3.7104, 3.4643, 3.6572, 3.6170]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4277, 3.5746, 3.4613, 3.5340, 3.6071],\n",
      "        [3.3629, 3.3648, 3.5108, 3.3601, 3.5668],\n",
      "        [3.8250, 3.5271, 3.7044, 4.1627, 4.0195],\n",
      "        [3.5936, 3.5644, 3.5354, 3.6043, 3.6169],\n",
      "        [3.5691, 3.6683, 3.4436, 3.5363, 3.5574],\n",
      "        [3.2808, 3.3264, 3.2864, 3.3764, 3.3139],\n",
      "        [3.2179, 3.3984, 3.3826, 3.3320, 3.3324],\n",
      "        [3.5514, 3.3867, 3.4360, 3.8039, 3.6168],\n",
      "        [3.4900, 3.5456, 3.5793, 3.4938, 3.4119],\n",
      "        [3.4470, 3.6116, 3.4699, 3.6426, 3.5412],\n",
      "        [3.5715, 3.5576, 3.5509, 3.5974, 3.7439],\n",
      "        [3.2525, 3.2898, 3.3629, 3.3558, 3.2867],\n",
      "        [3.4657, 3.3814, 3.4775, 3.4111, 3.4001],\n",
      "        [3.3713, 3.6097, 3.5366, 3.5398, 3.6238],\n",
      "        [3.4169, 3.3822, 3.4952, 3.4739, 3.4932],\n",
      "        [3.5103, 3.4551, 3.5797, 3.4927, 3.3116],\n",
      "        [3.4842, 3.7074, 3.6068, 3.6042, 3.6613],\n",
      "        [3.5626, 3.5620, 3.5352, 3.6477, 3.7070],\n",
      "        [3.2586, 3.3519, 3.2762, 3.3228, 3.3265],\n",
      "        [3.4970, 3.6080, 3.5450, 3.6870, 3.5407],\n",
      "        [3.2363, 3.2894, 3.3428, 3.3307, 3.2999],\n",
      "        [3.3844, 3.4516, 3.3019, 3.4782, 3.4215],\n",
      "        [3.3446, 3.4705, 3.4455, 3.4479, 3.4507],\n",
      "        [3.3965, 3.4596, 3.3098, 3.4964, 3.4250],\n",
      "        [3.2666, 3.2930, 3.2427, 3.3935, 3.2243],\n",
      "        [3.3096, 3.3798, 3.2749, 3.3720, 3.3478],\n",
      "        [3.3575, 3.4266, 3.2957, 3.4408, 3.3985],\n",
      "        [3.2030, 3.2188, 3.3008, 3.2908, 3.2232],\n",
      "        [3.4197, 3.7095, 3.5142, 3.6503, 3.6305],\n",
      "        [3.6931, 3.5820, 3.6362, 3.7226, 3.6950],\n",
      "        [3.5936, 3.5605, 3.5998, 3.7165, 3.8038],\n",
      "        [3.5182, 3.4622, 3.4998, 3.5628, 3.6825],\n",
      "        [3.5079, 3.4998, 3.5103, 3.5020, 3.3280],\n",
      "        [3.8445, 3.5145, 3.6670, 4.1101, 4.0169],\n",
      "        [3.3736, 3.3304, 3.4189, 3.4273, 3.4129],\n",
      "        [3.2067, 3.2091, 3.2955, 3.2756, 3.2248],\n",
      "        [3.7322, 3.6505, 3.6629, 3.7897, 3.7637],\n",
      "        [3.3127, 3.3176, 3.4060, 3.4154, 3.4059],\n",
      "        [3.2794, 3.2552, 3.3277, 3.3583, 3.3031],\n",
      "        [3.4971, 3.2916, 3.3418, 3.4169, 3.4512],\n",
      "        [3.6182, 3.5715, 3.4755, 3.6502, 3.6525],\n",
      "        [3.5284, 3.5228, 3.5712, 3.6222, 3.4365],\n",
      "        [3.7547, 3.4582, 3.5810, 4.0263, 3.9302],\n",
      "        [3.5524, 3.4777, 3.6668, 3.5240, 3.4123],\n",
      "        [3.2288, 3.4009, 3.3890, 3.3376, 3.3392],\n",
      "        [3.2383, 3.3280, 3.2693, 3.2992, 3.3095],\n",
      "        [3.5986, 3.5952, 3.5927, 3.6343, 3.7835],\n",
      "        [3.3579, 3.4175, 3.3682, 3.4015, 3.4126],\n",
      "        [3.3918, 3.3559, 3.4616, 3.4494, 3.4674],\n",
      "        [3.5906, 3.6416, 3.6721, 3.7905, 3.9081],\n",
      "        [3.5737, 3.6657, 3.5721, 3.6715, 3.8019],\n",
      "        [3.2900, 3.3481, 3.4177, 3.4022, 3.3162],\n",
      "        [3.5671, 3.5031, 3.6249, 3.5891, 3.4169],\n",
      "        [3.4751, 3.3931, 3.4890, 3.4082, 3.4259],\n",
      "        [3.9075, 4.0666, 3.6993, 3.8146, 3.6755],\n",
      "        [3.4121, 3.3489, 3.5046, 3.5269, 3.5474],\n",
      "        [3.5273, 3.5389, 3.5723, 3.6145, 3.4629],\n",
      "        [3.4909, 3.5521, 3.5912, 3.5925, 3.5508],\n",
      "        [3.1892, 3.2273, 3.2581, 3.2504, 3.2561],\n",
      "        [3.4795, 3.6322, 3.5853, 3.6004, 3.5127],\n",
      "        [3.6384, 3.3164, 3.4860, 3.8296, 3.7804],\n",
      "        [3.5194, 3.6111, 3.4589, 3.6954, 3.5860],\n",
      "        [3.3327, 3.3184, 3.3473, 3.3631, 3.4353],\n",
      "        [3.4128, 3.4468, 3.4473, 3.4618, 3.4619]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3556, 3.4105, 3.5884, 3.4666, 3.5535],\n",
      "        [3.3995, 3.4513, 3.5370, 3.5002, 3.5111],\n",
      "        [3.4074, 3.7026, 3.5736, 3.4768, 3.4885],\n",
      "        [3.4163, 3.5781, 3.3978, 3.5115, 3.4803],\n",
      "        [3.3410, 3.6274, 3.5502, 3.5350, 3.6354],\n",
      "        [3.3649, 3.4725, 3.4551, 3.4548, 3.4648],\n",
      "        [3.6788, 3.6547, 3.5666, 3.7042, 3.7642],\n",
      "        [3.3533, 3.5991, 3.5161, 3.5168, 3.6120],\n",
      "        [3.3013, 3.4129, 3.3177, 3.4750, 3.3419],\n",
      "        [3.4943, 3.6940, 3.5303, 3.6047, 3.5899],\n",
      "        [3.3903, 3.4540, 3.3004, 3.4865, 3.4186],\n",
      "        [3.2707, 3.2083, 3.3019, 3.3594, 3.2718],\n",
      "        [3.3586, 3.7181, 3.5862, 3.4796, 3.4681],\n",
      "        [3.4696, 3.3830, 3.4807, 3.4153, 3.4044],\n",
      "        [3.5073, 3.4454, 3.5084, 3.4680, 3.3964],\n",
      "        [3.3733, 3.3668, 3.4290, 3.4603, 3.4338],\n",
      "        [3.3364, 3.3199, 3.3506, 3.3672, 3.4397],\n",
      "        [3.4735, 3.5613, 3.5138, 3.5179, 3.3972],\n",
      "        [3.3448, 3.4446, 3.3606, 3.4700, 3.4826],\n",
      "        [3.7167, 3.7966, 3.4727, 3.6060, 3.5445],\n",
      "        [3.5274, 3.5925, 3.4817, 3.5905, 3.5540],\n",
      "        [3.5404, 3.4513, 3.4568, 3.7543, 3.6237],\n",
      "        [3.5706, 3.4654, 3.4819, 3.5702, 3.5880],\n",
      "        [3.5087, 3.6354, 3.5803, 3.6087, 3.6688],\n",
      "        [3.4698, 3.4582, 3.4511, 3.6058, 3.4766],\n",
      "        [3.4367, 3.4545, 3.4632, 3.4782, 3.4735],\n",
      "        [3.3763, 3.3211, 3.4531, 3.4406, 3.4145],\n",
      "        [3.5197, 3.4619, 3.4971, 3.5625, 3.6851],\n",
      "        [3.3436, 3.3873, 3.4014, 3.4529, 3.5096],\n",
      "        [3.5799, 3.3982, 3.3724, 3.4769, 3.5403],\n",
      "        [3.5542, 3.4636, 3.4777, 3.4553, 3.3878],\n",
      "        [3.4748, 3.6327, 3.5705, 3.5754, 3.5157],\n",
      "        [3.4769, 3.5631, 3.5165, 3.5195, 3.3994],\n",
      "        [3.7826, 3.4879, 3.6082, 4.0313, 3.9564],\n",
      "        [3.3692, 3.3659, 3.5136, 3.3635, 3.5832],\n",
      "        [3.5627, 3.6981, 3.5499, 3.7052, 3.6553],\n",
      "        [3.4800, 3.2589, 3.5779, 3.5296, 3.4867],\n",
      "        [3.1385, 3.2550, 3.3060, 3.2600, 3.2932],\n",
      "        [3.3055, 3.5859, 3.5216, 3.4912, 3.5929],\n",
      "        [3.2777, 3.4517, 3.2678, 3.4157, 3.2955],\n",
      "        [3.5339, 3.5219, 3.5253, 3.5556, 3.6519],\n",
      "        [3.4004, 3.4611, 3.3130, 3.5004, 3.4294],\n",
      "        [3.6038, 3.4725, 3.4486, 3.5573, 3.5804],\n",
      "        [3.3561, 3.4722, 3.4429, 3.4543, 3.4524],\n",
      "        [3.2519, 3.3045, 3.3520, 3.3440, 3.3251],\n",
      "        [3.5800, 3.5886, 3.6114, 3.6192, 3.7865],\n",
      "        [3.3886, 3.4188, 3.3418, 3.5168, 3.4382],\n",
      "        [3.2848, 3.2257, 3.3118, 3.3670, 3.2877],\n",
      "        [3.2477, 3.2977, 3.3478, 3.3368, 3.3102],\n",
      "        [3.3648, 3.3590, 3.3257, 3.4692, 3.3742],\n",
      "        [3.6710, 3.6556, 3.5620, 3.6913, 3.7572],\n",
      "        [3.3110, 3.3265, 3.4175, 3.4508, 3.4348],\n",
      "        [3.2302, 3.3418, 3.3622, 3.3308, 3.3154],\n",
      "        [3.4690, 3.6276, 3.5684, 3.5730, 3.5050],\n",
      "        [3.3155, 3.4020, 3.3948, 3.5101, 3.3518],\n",
      "        [3.3194, 3.3063, 3.4167, 3.4257, 3.4795],\n",
      "        [3.5161, 3.5458, 3.5620, 3.5231, 3.5446],\n",
      "        [3.4107, 3.6934, 3.5114, 3.6187, 3.6410],\n",
      "        [3.6203, 3.5625, 3.6046, 3.7403, 3.6116],\n",
      "        [3.3634, 3.3304, 3.4375, 3.4541, 3.4937],\n",
      "        [3.5587, 3.5648, 3.5468, 3.6151, 3.6643],\n",
      "        [3.5187, 3.5649, 3.4796, 3.4734, 3.5088],\n",
      "        [3.3850, 3.3617, 3.4212, 3.4267, 3.4857],\n",
      "        [3.5291, 3.6176, 3.5554, 3.6235, 3.5551]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5450, 3.4527, 3.4597, 3.7586, 3.6276],\n",
      "        [3.3221, 3.2531, 3.3401, 3.3896, 3.3022],\n",
      "        [3.6056, 3.5304, 3.5728, 3.6223, 3.7522],\n",
      "        [3.3202, 3.4032, 3.4917, 3.4879, 3.5436],\n",
      "        [3.2379, 3.3359, 3.2825, 3.2979, 3.3315],\n",
      "        [3.5793, 3.4152, 3.4560, 3.5261, 3.5470],\n",
      "        [3.4171, 3.3762, 3.5123, 3.5179, 3.4946],\n",
      "        [3.4989, 3.5486, 3.5855, 3.5026, 3.4202],\n",
      "        [3.3905, 3.3270, 3.4484, 3.3929, 3.4692],\n",
      "        [3.2458, 3.3057, 3.3540, 3.3402, 3.3133],\n",
      "        [3.3786, 3.3487, 3.4236, 3.4399, 3.4276],\n",
      "        [3.5315, 3.6156, 3.5382, 3.4794, 3.5652],\n",
      "        [3.3057, 3.4142, 3.3206, 3.4794, 3.3457],\n",
      "        [3.2297, 3.3293, 3.2758, 3.2898, 3.3159],\n",
      "        [3.5423, 3.6034, 3.4845, 3.6491, 3.6407],\n",
      "        [3.4172, 3.3249, 3.5391, 3.5459, 3.4522],\n",
      "        [3.6155, 3.5368, 3.6484, 3.6564, 3.4597],\n",
      "        [3.2588, 3.2844, 3.3454, 3.3438, 3.3120],\n",
      "        [3.3054, 3.3686, 3.2820, 3.3675, 3.3488],\n",
      "        [3.3885, 3.4451, 3.3038, 3.4776, 3.4201],\n",
      "        [3.1616, 3.2639, 3.2440, 3.2113, 3.2528],\n",
      "        [3.3439, 3.4964, 3.4955, 3.4565, 3.4636],\n",
      "        [3.5052, 3.4954, 3.5049, 3.4995, 3.3140],\n",
      "        [3.3801, 3.3477, 3.4235, 3.4332, 3.4216],\n",
      "        [3.3843, 3.3166, 3.3328, 3.5064, 3.3338],\n",
      "        [3.3018, 3.3372, 3.2925, 3.4006, 3.3267],\n",
      "        [3.3057, 3.4142, 3.3206, 3.4794, 3.3457],\n",
      "        [3.3552, 3.2907, 3.4249, 3.4142, 3.3791],\n",
      "        [3.5542, 3.6128, 3.4613, 3.5533, 3.6146],\n",
      "        [3.6379, 3.6203, 3.6275, 3.6787, 3.8459],\n",
      "        [3.5390, 3.6555, 3.5869, 3.6211, 3.5640],\n",
      "        [3.7163, 3.4273, 3.5109, 3.9906, 3.7858],\n",
      "        [3.4104, 3.3507, 3.4448, 3.4754, 3.4866],\n",
      "        [3.5219, 3.4184, 3.5202, 3.5665, 3.4739],\n",
      "        [3.4490, 3.5006, 3.5209, 3.5819, 3.5573],\n",
      "        [3.5144, 3.6955, 3.6355, 3.6156, 3.6618],\n",
      "        [3.3492, 3.3612, 3.3665, 3.3656, 3.4001],\n",
      "        [3.3321, 3.2585, 3.3417, 3.3709, 3.4869],\n",
      "        [3.2415, 3.4124, 3.3954, 3.3508, 3.3568],\n",
      "        [3.3976, 3.4390, 3.6083, 3.5089, 3.5837],\n",
      "        [3.6886, 3.6138, 3.5758, 3.7180, 3.7030],\n",
      "        [3.3817, 3.3004, 3.4544, 3.4585, 3.5173],\n",
      "        [3.3087, 3.3815, 3.2946, 3.3662, 3.3805],\n",
      "        [3.2887, 3.4521, 3.5840, 3.4223, 3.5067],\n",
      "        [3.2521, 3.2991, 3.3507, 3.3411, 3.3140],\n",
      "        [3.3387, 3.4023, 3.2882, 3.4057, 3.3812],\n",
      "        [3.3639, 3.5668, 3.5257, 3.3831, 3.5422],\n",
      "        [3.3662, 3.4204, 3.3742, 3.4098, 3.4209],\n",
      "        [3.6441, 3.4751, 3.6048, 3.7268, 3.5965],\n",
      "        [3.2886, 3.2795, 3.2200, 3.4081, 3.2532],\n",
      "        [3.6125, 3.3315, 3.5043, 3.7793, 3.7531],\n",
      "        [3.3939, 3.4518, 3.4426, 3.4430, 3.4611],\n",
      "        [3.4255, 3.5069, 3.3644, 3.4245, 3.4741],\n",
      "        [3.4888, 3.4248, 3.5045, 3.4570, 3.3910],\n",
      "        [3.7036, 3.6054, 3.5869, 3.7150, 3.6697],\n",
      "        [3.3799, 3.6127, 3.5434, 3.5487, 3.6321],\n",
      "        [3.6708, 3.5856, 3.6452, 3.6755, 3.8177],\n",
      "        [3.3779, 3.3682, 3.4320, 3.4648, 3.4377],\n",
      "        [3.5599, 3.3897, 3.4422, 3.8123, 3.6249],\n",
      "        [3.5134, 3.4977, 3.4815, 3.6064, 3.6439],\n",
      "        [3.5707, 3.5188, 3.7266, 3.5122, 3.4613],\n",
      "        [3.5861, 3.5267, 3.5699, 3.6235, 3.7546],\n",
      "        [3.4982, 3.5503, 3.5885, 3.5559, 3.5494],\n",
      "        [3.2320, 3.4094, 3.3901, 3.3422, 3.3450]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4161, 3.4737, 3.2897, 3.4138, 3.4318],\n",
      "        [3.3459, 3.3952, 3.4039, 3.4891, 3.4652],\n",
      "        [3.6437, 3.6661, 3.6253, 3.6593, 3.6891],\n",
      "        [3.3887, 3.3786, 3.5170, 3.3624, 3.5951],\n",
      "        [3.4809, 3.3948, 3.4900, 3.4339, 3.4068],\n",
      "        [3.5383, 3.5133, 3.4865, 3.6325, 3.6542],\n",
      "        [3.6090, 3.5888, 3.6706, 3.7735, 3.5626],\n",
      "        [3.3972, 3.4214, 3.3475, 3.5268, 3.4457],\n",
      "        [3.4156, 3.4683, 3.3072, 3.5138, 3.4334],\n",
      "        [3.5269, 3.5291, 3.5676, 3.5523, 3.5525],\n",
      "        [3.5111, 3.5904, 3.5517, 3.6891, 3.5426],\n",
      "        [3.4014, 3.4552, 3.3035, 3.5117, 3.4296],\n",
      "        [3.4165, 3.7054, 3.5796, 3.4874, 3.4962],\n",
      "        [3.4143, 3.5838, 3.4865, 3.4955, 3.3654],\n",
      "        [3.5115, 3.4524, 3.5125, 3.4919, 3.3783],\n",
      "        [3.2399, 3.4228, 3.4984, 3.3671, 3.4760],\n",
      "        [3.4006, 3.5873, 3.3995, 3.3109, 3.4799],\n",
      "        [3.5545, 3.6141, 3.4561, 3.5586, 3.6067],\n",
      "        [3.2504, 3.3320, 3.2777, 3.3126, 3.3211],\n",
      "        [3.5537, 3.3324, 3.4973, 3.6922, 3.7061],\n",
      "        [3.6079, 3.6373, 3.5174, 3.6319, 3.7067],\n",
      "        [3.5065, 3.2889, 3.3446, 3.4352, 3.4444],\n",
      "        [3.6226, 3.5430, 3.6421, 3.6807, 3.4843],\n",
      "        [3.6323, 3.6123, 3.5855, 3.7609, 3.6031],\n",
      "        [3.3779, 3.2987, 3.4331, 3.4541, 3.5180],\n",
      "        [3.2768, 3.5330, 3.4189, 3.2682, 3.5136],\n",
      "        [3.3779, 3.3686, 3.5192, 3.3735, 3.5906],\n",
      "        [3.6140, 3.5573, 3.5941, 3.7613, 3.8186],\n",
      "        [3.3534, 3.4472, 3.3664, 3.4801, 3.4899],\n",
      "        [3.5223, 3.5682, 3.4855, 3.4803, 3.5145],\n",
      "        [3.5421, 3.5852, 3.5907, 3.7225, 3.5336],\n",
      "        [3.4684, 3.4154, 3.5539, 3.5475, 3.5218],\n",
      "        [3.3094, 3.3698, 3.2846, 3.3728, 3.3522],\n",
      "        [3.1709, 3.2842, 3.3163, 3.2970, 3.3259],\n",
      "        [3.2977, 3.4454, 3.4168, 3.3166, 3.3435],\n",
      "        [3.3951, 3.4458, 3.3100, 3.4875, 3.4239],\n",
      "        [3.2917, 3.3585, 3.2833, 3.3549, 3.3447],\n",
      "        [3.5159, 3.4481, 3.5141, 3.4779, 3.4037],\n",
      "        [3.4670, 3.4373, 3.4031, 3.5790, 3.4981],\n",
      "        [3.5237, 3.5003, 3.4781, 3.6245, 3.6446],\n",
      "        [3.2933, 3.2438, 3.3231, 3.3786, 3.3048],\n",
      "        [3.4362, 3.5243, 3.4052, 3.5515, 3.4795],\n",
      "        [3.7220, 3.6174, 3.5919, 3.7305, 3.7004],\n",
      "        [3.5904, 3.5281, 3.5728, 3.6298, 3.7582],\n",
      "        [3.2373, 3.3798, 3.3811, 3.3443, 3.3347],\n",
      "        [3.3552, 3.3320, 3.3748, 3.3923, 3.4534],\n",
      "        [3.4872, 3.4516, 3.4675, 3.5238, 3.4671],\n",
      "        [3.3786, 3.4314, 3.3017, 3.4614, 3.4136],\n",
      "        [3.3953, 3.3532, 3.4562, 3.4559, 3.4735],\n",
      "        [3.3006, 3.3569, 3.2937, 3.4194, 3.3329],\n",
      "        [3.2814, 3.2652, 3.3397, 3.3639, 3.3125],\n",
      "        [3.7376, 3.7962, 3.7040, 3.9698, 3.8253],\n",
      "        [3.6271, 3.4890, 3.4929, 3.5852, 3.6219],\n",
      "        [3.3294, 3.4079, 3.4610, 3.4558, 3.5714],\n",
      "        [3.5333, 3.6214, 3.6117, 3.5702, 3.4595],\n",
      "        [3.2957, 3.3221, 3.3983, 3.4144, 3.3115],\n",
      "        [3.4248, 3.3829, 3.5068, 3.4861, 3.4927],\n",
      "        [3.4578, 3.4811, 3.4004, 3.5441, 3.5069],\n",
      "        [3.2061, 3.3040, 3.2707, 3.2633, 3.3077],\n",
      "        [3.2826, 3.3852, 3.3662, 3.4956, 3.3137],\n",
      "        [3.5334, 3.5668, 3.4644, 3.6079, 3.5424],\n",
      "        [3.3904, 3.3531, 3.4446, 3.4496, 3.4765],\n",
      "        [3.1959, 3.2918, 3.1633, 3.3366, 3.2407],\n",
      "        [3.7454, 3.5699, 3.6812, 3.8574, 3.7080]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4169, 3.5210, 3.3718, 3.6264, 3.3965],\n",
      "        [3.2432, 3.3559, 3.3783, 3.3578, 3.3399],\n",
      "        [3.2942, 3.2703, 3.2290, 3.4187, 3.2958],\n",
      "        [3.4675, 3.7140, 3.4813, 3.6917, 3.6379],\n",
      "        [3.3317, 3.3101, 3.4247, 3.4420, 3.4897],\n",
      "        [3.5225, 3.4308, 3.5158, 3.5730, 3.4797],\n",
      "        [3.6041, 3.5594, 3.6160, 3.5566, 3.3973],\n",
      "        [3.4000, 3.6728, 3.4501, 3.6539, 3.5885],\n",
      "        [3.3906, 3.3572, 3.4356, 3.4472, 3.4858],\n",
      "        [3.5676, 3.6103, 3.5804, 3.5319, 3.5881],\n",
      "        [3.6336, 3.5671, 3.6060, 3.7833, 3.8300],\n",
      "        [3.3898, 3.3262, 3.3463, 3.5141, 3.3532],\n",
      "        [3.5313, 3.7648, 3.6209, 3.6731, 3.7439],\n",
      "        [3.2339, 3.3184, 3.2760, 3.2973, 3.3134],\n",
      "        [3.6159, 3.4763, 3.4566, 3.5733, 3.5911],\n",
      "        [3.3125, 3.3465, 3.3834, 3.3502, 3.3668],\n",
      "        [3.1934, 3.2970, 3.3102, 3.3366, 3.3292],\n",
      "        [3.3780, 3.3456, 3.4187, 3.4443, 3.4243],\n",
      "        [3.4197, 3.3442, 3.4840, 3.4838, 3.4362],\n",
      "        [3.4948, 3.7319, 3.6201, 3.6433, 3.7390],\n",
      "        [3.4551, 3.3880, 3.4493, 3.3841, 3.2889],\n",
      "        [3.2524, 3.3365, 3.2871, 3.3218, 3.3489],\n",
      "        [3.3173, 3.5612, 3.4918, 3.4943, 3.5655],\n",
      "        [3.7185, 3.7105, 3.7510, 3.9102, 3.9884],\n",
      "        [3.2732, 3.4485, 3.5661, 3.4246, 3.4804],\n",
      "        [3.3780, 3.6410, 3.4705, 3.5834, 3.5864],\n",
      "        [3.8644, 3.9548, 3.7049, 3.7608, 3.7065],\n",
      "        [3.3816, 3.3697, 3.5216, 3.3800, 3.5937],\n",
      "        [3.4254, 3.5241, 3.4277, 3.5627, 3.4582],\n",
      "        [3.5769, 3.5191, 3.7232, 3.5221, 3.4586],\n",
      "        [3.6309, 3.6241, 3.6387, 3.6672, 3.8351],\n",
      "        [3.4025, 3.4576, 3.3083, 3.5024, 3.4289],\n",
      "        [3.2490, 3.3235, 3.3654, 3.3506, 3.3224],\n",
      "        [3.4304, 3.3862, 3.4392, 3.4928, 3.4709],\n",
      "        [3.1048, 3.2134, 3.2957, 3.2419, 3.2975],\n",
      "        [3.2448, 3.4464, 3.2428, 3.4172, 3.2838],\n",
      "        [3.3941, 3.3474, 3.4975, 3.4944, 3.4646],\n",
      "        [3.2903, 3.3550, 3.2641, 3.4209, 3.3461],\n",
      "        [3.4724, 3.4544, 3.5469, 3.5618, 3.5015],\n",
      "        [3.4674, 3.4779, 3.5413, 3.5429, 3.5261],\n",
      "        [3.3639, 3.4243, 3.2990, 3.4389, 3.4051],\n",
      "        [3.4158, 3.4660, 3.3237, 3.5156, 3.4447],\n",
      "        [3.4847, 3.3961, 3.4591, 3.4195, 3.3153],\n",
      "        [3.4656, 3.4370, 3.4496, 3.5842, 3.4777],\n",
      "        [3.3595, 3.4157, 3.3010, 3.4485, 3.4025],\n",
      "        [3.5144, 3.4448, 3.5179, 3.4817, 3.3941],\n",
      "        [3.3872, 3.3725, 3.4396, 3.4704, 3.4431],\n",
      "        [3.3353, 3.3945, 3.2918, 3.4062, 3.3871],\n",
      "        [3.3379, 3.3254, 3.3799, 3.4562, 3.3410],\n",
      "        [3.2665, 3.4465, 3.4215, 3.3852, 3.3991],\n",
      "        [3.5622, 3.6152, 3.4667, 3.5666, 3.6214],\n",
      "        [3.3976, 3.3124, 3.4581, 3.4626, 3.5016],\n",
      "        [3.5226, 3.6980, 3.6408, 3.6280, 3.6685],\n",
      "        [3.8028, 3.8924, 3.6405, 3.7054, 3.6429],\n",
      "        [3.3062, 3.4087, 3.4961, 3.4751, 3.5220],\n",
      "        [3.3686, 3.6247, 3.4883, 3.5597, 3.6205],\n",
      "        [3.3121, 3.5418, 3.4367, 3.2780, 3.5025],\n",
      "        [3.4192, 3.3300, 3.4934, 3.5176, 3.5444],\n",
      "        [3.4503, 3.7172, 3.4798, 3.6818, 3.6372],\n",
      "        [3.4426, 3.5075, 3.3481, 3.4464, 3.4719],\n",
      "        [3.3858, 3.3706, 3.4372, 3.4768, 3.4441],\n",
      "        [3.4163, 3.2887, 3.4134, 3.3631, 3.3527],\n",
      "        [3.2875, 3.4609, 3.5841, 3.4517, 3.4899],\n",
      "        [3.3735, 3.4318, 3.3068, 3.4607, 3.4131]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6779, 3.6660, 3.5812, 3.7147, 3.7591],\n",
      "        [3.6448, 3.5651, 3.5220, 3.6441, 3.6121],\n",
      "        [3.6465, 3.4961, 3.6284, 3.7708, 3.6176],\n",
      "        [3.4858, 3.4639, 3.4614, 3.6284, 3.4901],\n",
      "        [3.5140, 3.4430, 3.4182, 3.6752, 3.5653],\n",
      "        [3.4977, 3.3899, 3.4949, 3.4400, 3.4498],\n",
      "        [3.4382, 3.6641, 3.6073, 3.6176, 3.6775],\n",
      "        [3.4021, 3.4939, 3.4807, 3.4930, 3.4182],\n",
      "        [3.2524, 3.4165, 3.4024, 3.3681, 3.3663],\n",
      "        [3.5534, 3.6076, 3.4922, 3.6671, 3.6502],\n",
      "        [3.4522, 3.6527, 3.6269, 3.6338, 3.6560],\n",
      "        [3.5925, 3.6230, 3.5729, 3.6384, 3.6639],\n",
      "        [3.6354, 3.4747, 3.6070, 3.7425, 3.5954],\n",
      "        [3.5338, 3.6053, 3.5843, 3.5660, 3.4324],\n",
      "        [3.3019, 3.2021, 3.4115, 3.2197, 3.4443],\n",
      "        [3.4173, 3.3585, 3.4550, 3.4451, 3.4843],\n",
      "        [3.5422, 3.6206, 3.4739, 3.7236, 3.6076],\n",
      "        [3.5488, 3.5834, 3.5684, 3.5200, 3.5739],\n",
      "        [3.3910, 3.4425, 3.3060, 3.4841, 3.4210],\n",
      "        [3.5446, 3.4798, 3.5628, 3.6748, 3.4669],\n",
      "        [3.5270, 3.6339, 3.6125, 3.6569, 3.5575],\n",
      "        [3.5449, 3.5166, 3.6190, 3.5679, 3.4391],\n",
      "        [3.5074, 3.7100, 3.6198, 3.6356, 3.6855],\n",
      "        [3.5422, 3.6206, 3.4739, 3.7236, 3.6076],\n",
      "        [3.4737, 3.6736, 3.5548, 3.6103, 3.6739],\n",
      "        [3.5346, 3.4461, 3.4361, 3.7290, 3.6034],\n",
      "        [3.3814, 3.3473, 3.4209, 3.4500, 3.4270],\n",
      "        [3.2859, 3.2136, 3.3117, 3.3807, 3.2845],\n",
      "        [3.5024, 3.7786, 3.5627, 3.7366, 3.6981],\n",
      "        [3.5065, 3.4365, 3.5176, 3.6441, 3.4262],\n",
      "        [3.3545, 3.2781, 3.4150, 3.4161, 3.3784],\n",
      "        [3.2371, 3.3333, 3.2861, 3.3117, 3.3276],\n",
      "        [3.3820, 3.4284, 3.2941, 3.4748, 3.3994],\n",
      "        [3.2853, 3.5954, 3.5206, 3.4574, 3.6109],\n",
      "        [3.6201, 3.6914, 3.6524, 3.7299, 3.7183],\n",
      "        [3.2909, 3.4626, 3.5863, 3.4574, 3.4927],\n",
      "        [3.4416, 3.3122, 3.4293, 3.4767, 3.3846],\n",
      "        [3.4596, 3.5697, 3.5027, 3.5291, 3.3947],\n",
      "        [3.4034, 3.3856, 3.5356, 3.5943, 3.6395],\n",
      "        [3.7385, 3.8290, 3.5997, 3.6382, 3.6118],\n",
      "        [3.2816, 3.3794, 3.4286, 3.4110, 3.3617],\n",
      "        [3.3990, 3.3558, 3.4876, 3.4956, 3.4651],\n",
      "        [3.3516, 3.3880, 3.3375, 3.3791, 3.3754],\n",
      "        [3.3821, 3.4796, 3.4847, 3.4755, 3.5757],\n",
      "        [3.3782, 3.3337, 3.2916, 3.4160, 3.4883],\n",
      "        [3.3004, 3.4198, 3.5110, 3.4222, 3.4846],\n",
      "        [3.5388, 3.5826, 3.4897, 3.5487, 3.5330],\n",
      "        [3.5741, 3.6210, 3.5049, 3.6811, 3.6594],\n",
      "        [3.3319, 3.3974, 3.3013, 3.3932, 3.3885],\n",
      "        [3.3900, 3.3469, 3.4256, 3.4608, 3.4314],\n",
      "        [3.3168, 3.3356, 3.4305, 3.4839, 3.4378],\n",
      "        [3.3884, 3.5806, 3.3872, 3.6007, 3.5107],\n",
      "        [3.5341, 3.5320, 3.5723, 3.5647, 3.5584],\n",
      "        [3.2669, 3.3722, 3.3012, 3.3472, 3.3583],\n",
      "        [3.5440, 3.5923, 3.4868, 3.6198, 3.5622],\n",
      "        [3.3363, 3.4701, 3.4309, 3.3487, 3.3673],\n",
      "        [3.1779, 3.2870, 3.3208, 3.3090, 3.3317],\n",
      "        [3.4269, 3.6990, 3.5224, 3.6413, 3.6544],\n",
      "        [3.2344, 3.1738, 3.2938, 3.3757, 3.2853],\n",
      "        [3.5093, 3.5509, 3.5074, 3.5575, 3.6036],\n",
      "        [3.2465, 3.2535, 3.3236, 3.3322, 3.2697],\n",
      "        [3.5478, 3.6427, 3.4566, 3.5475, 3.5787],\n",
      "        [3.4179, 3.3466, 3.4615, 3.4834, 3.5027],\n",
      "        [3.4188, 3.6713, 3.4874, 3.6248, 3.6082]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5323, 3.7014, 3.6463, 3.6392, 3.6750],\n",
      "        [3.3743, 3.3961, 3.4219, 3.4741, 3.5507],\n",
      "        [3.5230, 3.5679, 3.4515, 3.5678, 3.5478],\n",
      "        [3.2513, 3.3485, 3.3749, 3.3572, 3.3320],\n",
      "        [3.3815, 3.3497, 3.3926, 3.4202, 3.4810],\n",
      "        [3.6921, 3.4456, 3.5107, 3.9414, 3.7522],\n",
      "        [3.1598, 3.2617, 3.3188, 3.2867, 3.3096],\n",
      "        [3.3494, 3.2505, 3.4453, 3.2842, 3.4779],\n",
      "        [3.3660, 3.3864, 3.3380, 3.3990, 3.3806],\n",
      "        [3.4257, 3.4706, 3.4478, 3.4997, 3.5075],\n",
      "        [3.3903, 3.6849, 3.5941, 3.5287, 3.4830],\n",
      "        [3.5483, 3.6204, 3.4776, 3.7241, 3.6099],\n",
      "        [3.6156, 3.6202, 3.6511, 3.6633, 3.8294],\n",
      "        [3.2577, 3.4257, 3.5177, 3.3852, 3.4438],\n",
      "        [3.2624, 3.2850, 3.3089, 3.3447, 3.3199],\n",
      "        [3.4967, 3.4815, 3.3633, 3.5276, 3.5767],\n",
      "        [3.3156, 3.4118, 3.5013, 3.4860, 3.5282],\n",
      "        [3.5462, 3.5808, 3.4841, 3.5548, 3.5388],\n",
      "        [3.7454, 3.7458, 3.6381, 3.9677, 3.7932],\n",
      "        [3.3853, 3.3968, 3.5346, 3.5729, 3.6073],\n",
      "        [3.2633, 3.4378, 3.4230, 3.3778, 3.3787],\n",
      "        [3.4583, 3.4613, 3.4765, 3.5048, 3.4902],\n",
      "        [3.7917, 3.9624, 3.5594, 3.7022, 3.5629],\n",
      "        [3.4639, 3.5696, 3.5089, 3.5345, 3.3961],\n",
      "        [3.6008, 3.4921, 3.5910, 3.6817, 3.5629],\n",
      "        [3.6219, 3.7062, 3.6884, 3.6612, 3.4750],\n",
      "        [3.5896, 3.5307, 3.5917, 3.7151, 3.5887],\n",
      "        [3.3954, 3.3351, 3.4419, 3.4575, 3.4228],\n",
      "        [3.3029, 3.2404, 3.3251, 3.3934, 3.3071],\n",
      "        [3.6569, 3.6704, 3.6333, 3.6773, 3.6988],\n",
      "        [3.4093, 3.4321, 3.3501, 3.4815, 3.4621],\n",
      "        [3.4120, 3.5792, 3.4753, 3.4852, 3.3650],\n",
      "        [3.5993, 3.6202, 3.6350, 3.6696, 3.7807],\n",
      "        [3.4956, 3.5683, 3.5274, 3.5456, 3.4142],\n",
      "        [3.3735, 3.3421, 3.3870, 3.4155, 3.4768],\n",
      "        [3.4340, 3.3897, 3.5156, 3.5374, 3.5068],\n",
      "        [3.4290, 3.3473, 3.4890, 3.4944, 3.4422],\n",
      "        [3.3731, 3.2940, 3.4325, 3.4338, 3.3952],\n",
      "        [3.3767, 3.4186, 3.4157, 3.4073, 3.4474],\n",
      "        [3.3980, 3.3699, 3.4418, 3.4703, 3.4429],\n",
      "        [3.4873, 3.2759, 3.5693, 3.5478, 3.5043],\n",
      "        [3.1976, 3.3690, 3.1809, 3.3702, 3.2316],\n",
      "        [3.5929, 3.6642, 3.6655, 3.6170, 3.4246],\n",
      "        [3.3862, 3.4172, 3.3883, 3.4323, 3.4424],\n",
      "        [3.3922, 3.3777, 3.5162, 3.4049, 3.5847],\n",
      "        [3.4418, 3.4236, 3.5118, 3.5314, 3.5885],\n",
      "        [3.4164, 3.4053, 3.4701, 3.3896, 3.2870],\n",
      "        [3.4172, 3.3643, 3.4779, 3.4800, 3.4883],\n",
      "        [3.2065, 3.3012, 3.2716, 3.2664, 3.2978],\n",
      "        [3.6183, 3.6878, 3.4575, 3.5686, 3.5663],\n",
      "        [3.2186, 3.3080, 3.2778, 3.2795, 3.3168],\n",
      "        [3.5481, 3.6177, 3.5541, 3.6472, 3.5679],\n",
      "        [3.4135, 3.4187, 3.3513, 3.5324, 3.4447],\n",
      "        [3.3417, 3.3918, 3.2881, 3.4160, 3.3709],\n",
      "        [3.5392, 3.4240, 3.5304, 3.5894, 3.4865],\n",
      "        [3.2987, 3.4582, 3.2804, 3.4419, 3.3120],\n",
      "        [3.5145, 3.5092, 3.3919, 3.6018, 3.5910],\n",
      "        [3.6298, 3.6952, 3.6600, 3.7421, 3.7251],\n",
      "        [3.6841, 3.7178, 3.6503, 3.7333, 3.7816],\n",
      "        [3.4799, 3.6333, 3.4706, 3.3826, 3.5550],\n",
      "        [3.5263, 3.3605, 3.3613, 3.4300, 3.5280],\n",
      "        [3.5350, 3.5009, 3.5283, 3.5321, 3.3620],\n",
      "        [3.4423, 3.6574, 3.5797, 3.5657, 3.4800],\n",
      "        [3.3859, 3.4268, 3.3087, 3.4567, 3.4250]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5932, 3.7851, 3.5705, 3.7793, 3.7397],\n",
      "        [3.3346, 3.3896, 3.3000, 3.4055, 3.3898],\n",
      "        [3.5538, 3.6232, 3.4798, 3.7342, 3.6144],\n",
      "        [3.4393, 3.4613, 3.4674, 3.4987, 3.4828],\n",
      "        [3.6464, 3.4773, 3.6128, 3.7530, 3.6021],\n",
      "        [3.4464, 3.6077, 3.4434, 3.6572, 3.5487],\n",
      "        [3.6458, 3.4944, 3.5032, 3.6072, 3.6345],\n",
      "        [3.6956, 3.4839, 3.6332, 3.7502, 3.6512],\n",
      "        [3.4149, 3.6769, 3.4582, 3.6696, 3.5981],\n",
      "        [3.4499, 3.6666, 3.6135, 3.6286, 3.6850],\n",
      "        [3.7014, 3.7039, 3.6644, 3.7285, 3.7494],\n",
      "        [3.2666, 3.3406, 3.2946, 3.3371, 3.3580],\n",
      "        [3.4355, 3.3789, 3.5053, 3.4974, 3.4991],\n",
      "        [3.4343, 3.4790, 3.3001, 3.4388, 3.4444],\n",
      "        [3.4330, 3.3575, 3.4576, 3.5032, 3.5022],\n",
      "        [3.4514, 3.5427, 3.5807, 3.6298, 3.5457],\n",
      "        [3.4051, 3.3822, 3.4508, 3.4904, 3.4568],\n",
      "        [3.4784, 3.3388, 3.6789, 3.5534, 3.5711],\n",
      "        [3.4805, 3.5283, 3.4099, 3.5617, 3.5365],\n",
      "        [3.5191, 3.6860, 3.6220, 3.6476, 3.7602],\n",
      "        [3.1551, 3.2457, 3.3257, 3.2765, 3.3262],\n",
      "        [3.2117, 3.3024, 3.2741, 3.2714, 3.3008],\n",
      "        [3.5068, 3.5103, 3.5793, 3.5278, 3.4283],\n",
      "        [3.5126, 3.4242, 3.4743, 3.4134, 3.3401],\n",
      "        [3.3982, 3.3113, 3.4571, 3.3836, 3.4854],\n",
      "        [3.2189, 3.2365, 3.2760, 3.2852, 3.2797],\n",
      "        [3.5600, 3.6585, 3.6027, 3.6511, 3.5822],\n",
      "        [3.6237, 3.3976, 3.4860, 3.8710, 3.6860],\n",
      "        [3.4809, 3.6822, 3.5571, 3.6195, 3.6756],\n",
      "        [3.3984, 3.3688, 3.4401, 3.4782, 3.4454],\n",
      "        [3.3692, 3.3123, 3.4233, 3.4187, 3.4017],\n",
      "        [3.7256, 3.7412, 3.6642, 3.9149, 3.7382],\n",
      "        [3.6618, 3.5218, 3.5232, 3.6267, 3.6500],\n",
      "        [3.6290, 3.5373, 3.5866, 3.6560, 3.7689],\n",
      "        [3.3717, 3.5553, 3.5586, 3.4507, 3.6861],\n",
      "        [3.6870, 3.7502, 3.4802, 3.6065, 3.5710],\n",
      "        [3.3281, 3.3381, 3.4362, 3.4945, 3.4445],\n",
      "        [3.3373, 3.4066, 3.4022, 3.3297, 3.3951],\n",
      "        [3.3969, 3.5749, 3.4692, 3.4776, 3.3615],\n",
      "        [3.3816, 3.4419, 3.3138, 3.4749, 3.4205],\n",
      "        [3.5252, 3.5546, 3.5958, 3.5837, 3.5578],\n",
      "        [3.5562, 3.5193, 3.6249, 3.5783, 3.4456],\n",
      "        [3.4579, 3.3268, 3.4416, 3.4944, 3.4005],\n",
      "        [3.6729, 3.4372, 3.5034, 3.9103, 3.7248],\n",
      "        [3.3666, 3.5029, 3.5087, 3.4848, 3.4798],\n",
      "        [3.2590, 3.4505, 3.2502, 3.4326, 3.2929],\n",
      "        [3.3821, 3.4198, 3.4184, 3.4123, 3.4506],\n",
      "        [3.5236, 3.6218, 3.5913, 3.6427, 3.6455],\n",
      "        [3.3879, 3.4359, 3.3144, 3.4763, 3.4223],\n",
      "        [3.3969, 3.4210, 3.3496, 3.4650, 3.4495],\n",
      "        [3.2285, 3.2085, 3.3027, 3.2955, 3.2396],\n",
      "        [3.4073, 3.3126, 3.4688, 3.4883, 3.5382],\n",
      "        [3.3841, 3.3647, 3.5731, 3.3393, 3.6078],\n",
      "        [3.3910, 3.2913, 3.4274, 3.4706, 3.5262],\n",
      "        [3.7495, 3.6450, 3.6380, 3.7840, 3.7372],\n",
      "        [3.3330, 3.4991, 3.3361, 3.2398, 3.4159],\n",
      "        [3.4627, 3.4041, 3.4510, 3.5441, 3.4811],\n",
      "        [3.6246, 3.6371, 3.6721, 3.6308, 3.5028],\n",
      "        [3.5467, 3.5585, 3.5627, 3.5351, 3.5756],\n",
      "        [3.3111, 3.4587, 3.5972, 3.4501, 3.5224],\n",
      "        [3.5469, 3.6703, 3.6115, 3.6738, 3.7057],\n",
      "        [3.6037, 3.7656, 3.6254, 3.8021, 3.7605],\n",
      "        [3.2566, 3.3496, 3.3775, 3.3624, 3.3350],\n",
      "        [3.4170, 3.4618, 3.3160, 3.5181, 3.4381]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4359, 3.5260, 3.3828, 3.6482, 3.4095],\n",
      "        [3.3173, 3.2404, 3.3331, 3.3962, 3.3232],\n",
      "        [3.4031, 3.4291, 3.4623, 3.5166, 3.4315],\n",
      "        [3.6463, 3.6599, 3.6147, 3.6998, 3.7287],\n",
      "        [3.4538, 3.5216, 3.3889, 3.4657, 3.4989],\n",
      "        [3.3955, 3.2921, 3.4307, 3.4767, 3.5299],\n",
      "        [3.4445, 3.3585, 3.5147, 3.5641, 3.4812],\n",
      "        [3.6412, 3.5321, 3.5972, 3.6572, 3.7767],\n",
      "        [3.5450, 3.5030, 3.5343, 3.5433, 3.3688],\n",
      "        [3.4508, 3.5714, 3.4991, 3.5253, 3.3868],\n",
      "        [3.3248, 3.3376, 3.4087, 3.3422, 3.5013],\n",
      "        [3.4800, 3.4813, 3.3945, 3.5556, 3.4952],\n",
      "        [3.2992, 3.3345, 3.4101, 3.4156, 3.3420],\n",
      "        [3.4058, 3.3503, 3.4346, 3.4773, 3.4415],\n",
      "        [3.4488, 3.4919, 3.3231, 3.4557, 3.4616],\n",
      "        [3.2759, 3.5785, 3.5024, 3.4480, 3.6093],\n",
      "        [3.4121, 3.4492, 3.3076, 3.5098, 3.4326],\n",
      "        [3.5671, 3.6713, 3.5351, 3.6325, 3.6016],\n",
      "        [3.6327, 3.5952, 3.6849, 3.8043, 3.5795],\n",
      "        [3.3991, 3.3994, 3.4465, 3.4760, 3.6014],\n",
      "        [3.5388, 3.4544, 3.5277, 3.5061, 3.4198],\n",
      "        [3.2982, 3.3626, 3.2979, 3.3706, 3.3588],\n",
      "        [3.4153, 3.3229, 3.4799, 3.5087, 3.5441],\n",
      "        [3.5687, 3.6229, 3.4573, 3.5823, 3.6043],\n",
      "        [3.3237, 3.4788, 3.2974, 3.4529, 3.3206],\n",
      "        [3.5132, 3.2930, 3.6017, 3.5673, 3.5211],\n",
      "        [3.3730, 3.4742, 3.3585, 3.5647, 3.3818],\n",
      "        [3.2561, 3.1902, 3.3084, 3.4090, 3.3020],\n",
      "        [3.3304, 3.4215, 3.6192, 3.4457, 3.5850],\n",
      "        [3.5584, 3.6241, 3.4832, 3.7405, 3.6183],\n",
      "        [3.4216, 3.3968, 3.4621, 3.5140, 3.4824],\n",
      "        [3.3894, 3.3688, 3.5412, 3.3845, 3.5900],\n",
      "        [3.3512, 3.3938, 3.2939, 3.4269, 3.3776],\n",
      "        [3.5521, 3.6176, 3.4770, 3.7317, 3.6088],\n",
      "        [3.8267, 3.5444, 3.7328, 4.1737, 4.0503],\n",
      "        [3.5188, 3.7820, 3.5723, 3.7535, 3.7092],\n",
      "        [3.4971, 3.2778, 3.5753, 3.5590, 3.5112],\n",
      "        [3.5152, 3.4373, 3.4554, 3.6623, 3.5561],\n",
      "        [3.3155, 3.2344, 3.3304, 3.4044, 3.3104],\n",
      "        [3.5011, 3.3454, 3.6679, 3.5742, 3.5926],\n",
      "        [3.3721, 3.4095, 3.3053, 3.4537, 3.4111],\n",
      "        [3.6131, 3.6702, 3.6678, 3.6312, 3.4292],\n",
      "        [3.3915, 3.7276, 3.6066, 3.5217, 3.4929],\n",
      "        [3.4225, 3.5220, 3.4227, 3.5046, 3.5268],\n",
      "        [3.2685, 3.3530, 3.3090, 3.3874, 3.3335],\n",
      "        [3.3860, 3.4428, 3.3171, 3.4809, 3.4241],\n",
      "        [3.4562, 3.5913, 3.4302, 3.3571, 3.4621],\n",
      "        [3.6368, 3.6109, 3.6161, 3.6740, 3.8093],\n",
      "        [3.3887, 3.3655, 3.5764, 3.3456, 3.6115],\n",
      "        [3.5560, 3.6218, 3.4822, 3.7393, 3.6149],\n",
      "        [3.5480, 3.4611, 3.5535, 3.6815, 3.4686],\n",
      "        [3.5584, 3.6229, 3.5548, 3.5142, 3.5853],\n",
      "        [3.3098, 3.5106, 3.3374, 3.2407, 3.4568],\n",
      "        [3.4679, 3.6427, 3.5844, 3.5899, 3.4989],\n",
      "        [3.6134, 3.6513, 3.5880, 3.6585, 3.7143],\n",
      "        [3.5776, 3.6205, 3.4704, 3.5909, 3.6236],\n",
      "        [3.2984, 3.4135, 3.3551, 3.4071, 3.4309],\n",
      "        [3.6575, 3.5207, 3.5150, 3.6241, 3.6547],\n",
      "        [3.5037, 3.4013, 3.4701, 3.4413, 3.3282],\n",
      "        [3.5664, 3.6632, 3.6037, 3.6560, 3.5843],\n",
      "        [3.3315, 3.3758, 3.2977, 3.4002, 3.3680],\n",
      "        [3.5283, 3.6684, 3.6173, 3.6437, 3.7396],\n",
      "        [3.3041, 3.2447, 3.3335, 3.4016, 3.3122],\n",
      "        [3.2411, 3.2191, 3.3169, 3.3157, 3.2522]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3939, 3.4793, 3.3594, 3.5966, 3.3803],\n",
      "        [3.1227, 3.2119, 3.3009, 3.2663, 3.3022],\n",
      "        [3.5625, 3.6248, 3.4864, 3.7462, 3.6227],\n",
      "        [3.6320, 3.6909, 3.7072, 3.7064, 3.5330],\n",
      "        [3.3399, 3.3954, 3.3093, 3.4181, 3.3906],\n",
      "        [3.3038, 3.2622, 3.3481, 3.3941, 3.3274],\n",
      "        [3.1913, 3.2798, 3.3283, 3.3238, 3.3290],\n",
      "        [3.3191, 3.2840, 3.2428, 3.4424, 3.2874],\n",
      "        [3.6377, 3.5390, 3.5935, 3.6694, 3.7775],\n",
      "        [3.3965, 3.3989, 3.4402, 3.4850, 3.5849],\n",
      "        [3.3715, 3.3952, 3.5531, 3.4936, 3.5357],\n",
      "        [3.3991, 3.6210, 3.5557, 3.5811, 3.6506],\n",
      "        [3.7723, 3.5775, 3.6991, 3.8935, 3.7295],\n",
      "        [3.3808, 3.3523, 3.5540, 3.3451, 3.5973],\n",
      "        [3.3929, 3.4306, 3.3134, 3.4810, 3.4226],\n",
      "        [3.2456, 3.2799, 3.2215, 3.3895, 3.2571],\n",
      "        [3.5962, 3.5750, 3.5698, 3.6612, 3.6933],\n",
      "        [3.2478, 3.2420, 3.2935, 3.3204, 3.3004],\n",
      "        [3.6361, 3.5376, 3.5923, 3.6686, 3.7768],\n",
      "        [3.4110, 3.3651, 3.4458, 3.4847, 3.4566],\n",
      "        [3.3008, 3.3058, 3.3879, 3.4088, 3.3230],\n",
      "        [3.5712, 3.6720, 3.5382, 3.6380, 3.6060],\n",
      "        [3.4310, 3.4307, 3.3751, 3.5550, 3.4645],\n",
      "        [3.5456, 3.5062, 3.5010, 3.6472, 3.6684],\n",
      "        [3.5764, 3.3900, 3.4725, 3.5307, 3.5167],\n",
      "        [3.4691, 3.4909, 3.4120, 3.5518, 3.5725],\n",
      "        [3.2450, 3.2198, 3.3199, 3.3209, 3.2563],\n",
      "        [3.3251, 3.2531, 3.3433, 3.4163, 3.3269],\n",
      "        [3.3916, 3.2961, 3.4089, 3.4603, 3.5384],\n",
      "        [3.6548, 3.4961, 3.5094, 3.6192, 3.6428],\n",
      "        [3.4516, 3.5220, 3.3996, 3.4645, 3.5094],\n",
      "        [3.4088, 3.3168, 3.4395, 3.4201, 3.4039],\n",
      "        [3.6578, 3.4927, 3.6185, 3.7405, 3.6035],\n",
      "        [3.4956, 3.4225, 3.5705, 3.5816, 3.5417],\n",
      "        [3.3137, 3.5114, 3.3405, 3.2462, 3.4610],\n",
      "        [3.3429, 3.3911, 3.3063, 3.4168, 3.3975],\n",
      "        [3.4012, 3.4380, 3.3123, 3.5025, 3.4228],\n",
      "        [3.2821, 3.4384, 3.5485, 3.3962, 3.4565],\n",
      "        [3.4025, 3.3644, 3.4724, 3.4977, 3.4733],\n",
      "        [3.5625, 3.6248, 3.4864, 3.7462, 3.6227],\n",
      "        [3.2307, 3.3912, 3.1941, 3.4069, 3.2465],\n",
      "        [3.7580, 3.7461, 3.7161, 3.9477, 3.7473],\n",
      "        [3.5458, 3.5569, 3.6311, 3.5738, 3.4598],\n",
      "        [3.5556, 3.4718, 3.5203, 3.6131, 3.7137],\n",
      "        [3.6473, 3.5455, 3.6687, 3.6979, 3.4842],\n",
      "        [3.4136, 3.4237, 3.3910, 3.5306, 3.5517],\n",
      "        [3.7480, 3.4359, 3.5309, 4.0285, 3.8090],\n",
      "        [3.4621, 3.4482, 3.4553, 3.5413, 3.5602],\n",
      "        [3.2985, 3.2930, 3.3730, 3.4093, 3.3446],\n",
      "        [3.4842, 3.3825, 3.5525, 3.5972, 3.5278],\n",
      "        [3.3995, 3.4343, 3.3207, 3.4959, 3.4306],\n",
      "        [3.4092, 3.3766, 3.4515, 3.5049, 3.4614],\n",
      "        [3.3194, 3.2352, 3.3334, 3.4098, 3.3146],\n",
      "        [3.3915, 3.3963, 3.4378, 3.4827, 3.5820],\n",
      "        [3.5804, 3.6662, 3.6100, 3.6631, 3.5823],\n",
      "        [3.2264, 3.3033, 3.2812, 3.2913, 3.3161],\n",
      "        [3.3731, 3.4098, 3.3071, 3.4496, 3.4126],\n",
      "        [3.7616, 3.7906, 3.7212, 3.9895, 3.8362],\n",
      "        [3.4394, 3.4004, 3.4672, 3.4040, 3.3039],\n",
      "        [3.5647, 3.5861, 3.5999, 3.6621, 3.5595],\n",
      "        [3.5185, 3.4228, 3.4904, 3.4284, 3.3405],\n",
      "        [3.4082, 3.4259, 3.3500, 3.4738, 3.4595],\n",
      "        [3.4219, 3.4147, 3.5227, 3.5258, 3.5778],\n",
      "        [3.4190, 3.4531, 3.3228, 3.5162, 3.4437]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3609, 3.3481, 3.3947, 3.3944, 3.4105],\n",
      "        [3.3055, 3.4063, 3.2883, 3.4513, 3.3588],\n",
      "        [3.4272, 3.6798, 3.4678, 3.6864, 3.6102],\n",
      "        [3.3213, 3.3666, 3.3021, 3.3929, 3.3681],\n",
      "        [3.5074, 3.5298, 3.4468, 3.5923, 3.6126],\n",
      "        [3.5163, 3.4193, 3.4918, 3.4135, 3.3410],\n",
      "        [3.3494, 3.6093, 3.4820, 3.5541, 3.6123],\n",
      "        [3.4992, 3.4615, 3.5641, 3.5951, 3.5230],\n",
      "        [3.9757, 4.0877, 3.7122, 3.8480, 3.7428],\n",
      "        [3.3443, 3.4659, 3.3110, 3.4980, 3.3411],\n",
      "        [3.4352, 3.3752, 3.5136, 3.5369, 3.5100],\n",
      "        [3.3280, 3.4535, 3.4359, 3.3545, 3.3678],\n",
      "        [3.2153, 3.2912, 3.2794, 3.2783, 3.3073],\n",
      "        [3.3607, 3.4509, 3.3572, 3.5494, 3.3817],\n",
      "        [3.6197, 3.4092, 3.3970, 3.5257, 3.5723],\n",
      "        [3.4461, 3.4823, 3.3094, 3.4571, 3.4564],\n",
      "        [3.4359, 3.4711, 3.3242, 3.5453, 3.4586],\n",
      "        [3.6239, 3.6001, 3.6008, 3.6679, 3.7913],\n",
      "        [3.4853, 3.4411, 3.4438, 3.5942, 3.6090],\n",
      "        [3.2959, 3.2774, 3.3578, 3.3909, 3.3316],\n",
      "        [3.3609, 3.4206, 3.4271, 3.5702, 3.3845],\n",
      "        [3.4609, 3.5387, 3.4502, 3.5949, 3.4843],\n",
      "        [3.6581, 3.4805, 3.6223, 3.7704, 3.6139],\n",
      "        [3.5390, 3.6244, 3.5762, 3.7456, 3.5855],\n",
      "        [3.4348, 3.3561, 3.4805, 3.4572, 3.4498],\n",
      "        [3.5910, 3.6539, 3.6143, 3.6606, 3.5783],\n",
      "        [3.7110, 3.6087, 3.5694, 3.7323, 3.6973],\n",
      "        [3.4035, 3.4214, 3.4000, 3.4541, 3.4570],\n",
      "        [3.5666, 3.4565, 3.4966, 3.4811, 3.4055],\n",
      "        [3.3218, 3.2845, 3.2450, 3.4474, 3.2904],\n",
      "        [3.4725, 3.4032, 3.5435, 3.5584, 3.5268],\n",
      "        [3.5997, 3.5824, 3.6462, 3.7805, 3.5629],\n",
      "        [3.3366, 3.6221, 3.5692, 3.5257, 3.6462],\n",
      "        [3.5189, 3.2693, 3.6028, 3.5786, 3.5181],\n",
      "        [3.4029, 3.3914, 3.5727, 3.6006, 3.5186],\n",
      "        [3.3231, 3.4618, 3.6066, 3.4672, 3.5342],\n",
      "        [3.4807, 3.7065, 3.5059, 3.7171, 3.6604],\n",
      "        [3.7632, 3.7505, 3.6511, 3.9918, 3.8090],\n",
      "        [3.3947, 3.3636, 3.4492, 3.3653, 3.2605],\n",
      "        [3.4098, 3.3331, 3.4509, 3.4729, 3.4306],\n",
      "        [3.6428, 3.6677, 3.7181, 3.8654, 3.9531],\n",
      "        [3.5894, 3.4957, 3.5610, 3.6233, 3.7459],\n",
      "        [3.4297, 3.4374, 3.2857, 3.5261, 3.3396],\n",
      "        [3.6604, 3.5743, 3.6238, 3.8176, 3.8518],\n",
      "        [3.6110, 3.5164, 3.6543, 3.6449, 3.4533],\n",
      "        [3.5414, 3.4521, 3.5349, 3.5147, 3.4151],\n",
      "        [3.4423, 3.4732, 3.3404, 3.5482, 3.4655],\n",
      "        [3.4242, 3.3961, 3.4714, 3.5224, 3.4839],\n",
      "        [3.5639, 3.5748, 3.4842, 3.6468, 3.5670],\n",
      "        [3.3667, 3.2743, 3.4222, 3.4331, 3.3810],\n",
      "        [3.4021, 3.4346, 3.3244, 3.4932, 3.4371],\n",
      "        [3.4221, 3.4543, 3.4768, 3.4849, 3.3772],\n",
      "        [3.4102, 3.3333, 3.4554, 3.4770, 3.4295],\n",
      "        [3.5663, 3.6247, 3.4899, 3.7472, 3.6253],\n",
      "        [3.3281, 3.3061, 3.2498, 3.4523, 3.3282],\n",
      "        [3.8074, 3.8760, 3.6661, 3.7063, 3.6910],\n",
      "        [3.3959, 3.3215, 3.4503, 3.4722, 3.4230],\n",
      "        [3.7844, 3.4887, 3.6429, 4.1369, 3.9615],\n",
      "        [3.3549, 3.3977, 3.3487, 3.4451, 3.4321],\n",
      "        [3.5028, 3.4826, 3.5603, 3.5852, 3.5106],\n",
      "        [3.2754, 3.4219, 3.4172, 3.3951, 3.3842],\n",
      "        [3.4026, 3.3604, 3.4409, 3.4858, 3.4487],\n",
      "        [3.6312, 3.5672, 3.6335, 3.5902, 3.4182],\n",
      "        [3.4097, 3.3758, 3.4525, 3.5023, 3.4630]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4357, 3.4537, 3.4614, 3.4864, 3.4924],\n",
      "        [3.4765, 3.5600, 3.4783, 3.6173, 3.4891],\n",
      "        [3.8042, 3.8544, 3.5181, 3.7072, 3.5664],\n",
      "        [3.4466, 3.4762, 3.4623, 3.5283, 3.5266],\n",
      "        [3.5338, 3.3598, 3.6811, 3.6202, 3.6205],\n",
      "        [3.2795, 3.2614, 3.3471, 3.3700, 3.3172],\n",
      "        [3.6403, 3.5747, 3.6323, 3.7798, 3.8455],\n",
      "        [3.1880, 3.2677, 3.3432, 3.3189, 3.3563],\n",
      "        [3.4226, 3.5259, 3.4648, 3.4670, 3.5408],\n",
      "        [3.2792, 3.3564, 3.3174, 3.4045, 3.3454],\n",
      "        [3.2279, 3.3009, 3.1844, 3.3803, 3.2677],\n",
      "        [3.2939, 3.2905, 3.3648, 3.3949, 3.3420],\n",
      "        [3.4276, 3.3212, 3.4773, 3.5016, 3.5260],\n",
      "        [3.6782, 3.5262, 3.5347, 3.6513, 3.6666],\n",
      "        [3.5460, 3.5198, 3.5270, 3.7206, 3.5438],\n",
      "        [3.3160, 3.2803, 3.3623, 3.4118, 3.3435],\n",
      "        [3.2441, 3.2276, 3.3278, 3.3360, 3.2565],\n",
      "        [3.5337, 3.5074, 3.4474, 3.5718, 3.6684],\n",
      "        [3.4458, 3.6782, 3.5056, 3.6590, 3.6319],\n",
      "        [3.5169, 3.4868, 3.3781, 3.5566, 3.5962],\n",
      "        [3.2279, 3.3009, 3.1844, 3.3803, 3.2677],\n",
      "        [3.5418, 3.4308, 3.5244, 3.5948, 3.4929],\n",
      "        [3.3171, 3.2362, 3.3358, 3.4216, 3.3140],\n",
      "        [3.4301, 3.4653, 3.3322, 3.5370, 3.4611],\n",
      "        [3.3054, 3.6043, 3.5247, 3.4814, 3.6365],\n",
      "        [3.2703, 3.3893, 3.4028, 3.3893, 3.3626],\n",
      "        [3.5093, 3.5125, 3.6468, 3.6114, 3.5986],\n",
      "        [3.7124, 3.6681, 3.5906, 3.7487, 3.7939],\n",
      "        [3.4762, 3.3319, 3.4418, 3.5255, 3.4085],\n",
      "        [3.2954, 3.2892, 3.3662, 3.3985, 3.3409],\n",
      "        [3.6626, 3.5759, 3.6339, 3.7993, 3.6489],\n",
      "        [3.4455, 3.4745, 3.3429, 3.5545, 3.4696],\n",
      "        [3.4006, 3.3723, 3.5495, 3.4023, 3.6021],\n",
      "        [3.5843, 3.5624, 3.5788, 3.6992, 3.7021],\n",
      "        [3.4936, 3.4909, 3.4255, 3.5870, 3.5309],\n",
      "        [3.5767, 3.5952, 3.6134, 3.7706, 3.5630],\n",
      "        [3.4278, 3.4234, 3.3862, 3.5404, 3.5709],\n",
      "        [3.4139, 3.4330, 3.4708, 3.5353, 3.4441],\n",
      "        [3.6501, 3.5810, 3.6376, 3.8149, 3.8596],\n",
      "        [3.2763, 3.2992, 3.3668, 3.3851, 3.3344],\n",
      "        [3.4322, 3.4574, 3.3178, 3.5336, 3.4413],\n",
      "        [3.4117, 3.4409, 3.3232, 3.5063, 3.4415],\n",
      "        [3.6457, 3.6640, 3.7140, 3.8760, 3.9497],\n",
      "        [3.3471, 3.3295, 3.4063, 3.4852, 3.3523],\n",
      "        [3.4079, 3.4407, 3.3175, 3.5141, 3.4306],\n",
      "        [3.6007, 3.4925, 3.6995, 3.5885, 3.4535],\n",
      "        [3.4147, 3.6523, 3.4542, 3.6598, 3.5866],\n",
      "        [3.4471, 3.4911, 3.3122, 3.4618, 3.4643],\n",
      "        [3.7150, 3.5515, 3.6743, 3.8433, 3.6866],\n",
      "        [3.5879, 3.3423, 3.5195, 3.7369, 3.7337],\n",
      "        [3.6206, 3.8038, 3.5851, 3.8219, 3.7728],\n",
      "        [3.5755, 3.4458, 3.5655, 3.6503, 3.5301],\n",
      "        [3.3502, 3.3976, 3.3090, 3.4323, 3.3948],\n",
      "        [3.3844, 3.3521, 3.4129, 3.5050, 3.3885],\n",
      "        [3.5696, 3.6277, 3.4919, 3.7585, 3.6309],\n",
      "        [3.6391, 3.5336, 3.6238, 3.6915, 3.7910],\n",
      "        [3.7923, 3.7934, 3.7543, 4.0164, 3.8441],\n",
      "        [3.5879, 3.5219, 3.6256, 3.6065, 3.4680],\n",
      "        [3.4154, 3.5480, 3.5035, 3.4538, 3.5592],\n",
      "        [3.3360, 3.3618, 3.4482, 3.4613, 3.3564],\n",
      "        [3.8935, 3.5294, 3.6998, 4.1698, 4.0570],\n",
      "        [3.6163, 3.6396, 3.6546, 3.6447, 3.4827],\n",
      "        [3.4177, 3.3406, 3.4659, 3.4892, 3.4475],\n",
      "        [3.3619, 3.3190, 3.4441, 3.4817, 3.5146]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2400, 3.3949, 3.2015, 3.4249, 3.2578],\n",
      "        [3.6695, 3.6240, 3.6111, 3.8165, 3.6364],\n",
      "        [3.4760, 3.3325, 3.4551, 3.5244, 3.4193],\n",
      "        [3.3503, 3.4682, 3.3158, 3.5111, 3.3491],\n",
      "        [3.5290, 3.4193, 3.5166, 3.5805, 3.4875],\n",
      "        [3.4270, 3.3574, 3.5190, 3.5405, 3.4928],\n",
      "        [3.4359, 3.3913, 3.4677, 3.5300, 3.4948],\n",
      "        [3.5370, 3.2931, 3.3652, 3.4807, 3.4841],\n",
      "        [3.2855, 3.3248, 3.3866, 3.3980, 3.3519],\n",
      "        [3.8415, 3.5494, 3.7442, 4.1983, 4.0664],\n",
      "        [3.5436, 3.6210, 3.6060, 3.6799, 3.6496],\n",
      "        [3.7243, 3.5894, 3.6221, 3.7505, 3.6895],\n",
      "        [3.4291, 3.3277, 3.4903, 3.5330, 3.5596],\n",
      "        [3.4598, 3.5349, 3.4284, 3.4830, 3.5332],\n",
      "        [3.5453, 3.3015, 3.3712, 3.4755, 3.4929],\n",
      "        [3.5479, 3.5561, 3.4562, 3.5820, 3.6791],\n",
      "        [3.5602, 3.5982, 3.4864, 3.5860, 3.5739],\n",
      "        [3.4236, 3.4115, 3.4664, 3.4979, 3.6415],\n",
      "        [3.6397, 3.6274, 3.6686, 3.7025, 3.8535],\n",
      "        [3.7197, 3.6250, 3.6877, 3.8539, 3.7250],\n",
      "        [3.2467, 3.3178, 3.2901, 3.3226, 3.3300],\n",
      "        [3.4992, 3.4472, 3.4714, 3.6320, 3.5066],\n",
      "        [3.5384, 3.4257, 3.5258, 3.5948, 3.4961],\n",
      "        [3.4526, 3.3542, 3.5053, 3.5297, 3.4640],\n",
      "        [3.6301, 3.6339, 3.5202, 3.6560, 3.7203],\n",
      "        [3.7138, 3.4834, 3.6424, 3.7739, 3.6716],\n",
      "        [3.4166, 3.3170, 3.4707, 3.4142, 3.5045],\n",
      "        [3.6645, 3.4789, 3.6189, 3.7867, 3.6154],\n",
      "        [3.5778, 3.6314, 3.5914, 3.7013, 3.5967],\n",
      "        [3.5077, 3.5769, 3.5386, 3.5778, 3.4335],\n",
      "        [3.4109, 3.4362, 3.3132, 3.5146, 3.4250],\n",
      "        [3.6261, 3.6028, 3.6428, 3.6881, 3.8279],\n",
      "        [3.5677, 3.5980, 3.5047, 3.6147, 3.5617],\n",
      "        [3.6302, 3.6030, 3.6057, 3.6826, 3.7997],\n",
      "        [3.4195, 3.3612, 3.4502, 3.4986, 3.4626],\n",
      "        [3.4350, 3.4586, 3.3199, 3.5406, 3.4450],\n",
      "        [3.5317, 3.3027, 3.6122, 3.5941, 3.5397],\n",
      "        [3.5747, 3.5904, 3.6077, 3.6821, 3.5717],\n",
      "        [3.4447, 3.5258, 3.4639, 3.4969, 3.5539],\n",
      "        [3.4451, 3.4744, 3.3423, 3.5622, 3.4684],\n",
      "        [3.7621, 3.5581, 3.6860, 3.8989, 3.7637],\n",
      "        [3.8186, 3.8707, 3.5143, 3.7277, 3.5573],\n",
      "        [3.5021, 3.5756, 3.5337, 3.5759, 3.4277],\n",
      "        [3.4179, 3.4297, 3.3573, 3.4923, 3.4709],\n",
      "        [3.3687, 3.6195, 3.5020, 3.5645, 3.6446],\n",
      "        [3.5780, 3.5385, 3.6050, 3.6921, 3.4813],\n",
      "        [3.7229, 3.6683, 3.5973, 3.7684, 3.8046],\n",
      "        [3.7449, 3.7457, 3.6890, 3.7940, 3.8430],\n",
      "        [3.5292, 3.4420, 3.4661, 3.6867, 3.5723],\n",
      "        [3.2216, 3.2972, 3.2848, 3.2903, 3.3193],\n",
      "        [3.3049, 3.3808, 3.4412, 3.4449, 3.3807],\n",
      "        [3.5654, 3.4765, 3.5281, 3.6340, 3.7259],\n",
      "        [3.4260, 3.6606, 3.5175, 3.6501, 3.6567],\n",
      "        [3.5580, 3.6007, 3.4983, 3.7106, 3.7420],\n",
      "        [3.4039, 3.4144, 3.3517, 3.5119, 3.4184],\n",
      "        [3.2069, 3.2949, 3.3402, 3.3494, 3.3575],\n",
      "        [3.4215, 3.3522, 3.4567, 3.4957, 3.4557],\n",
      "        [3.3940, 3.4311, 3.3278, 3.4890, 3.4303],\n",
      "        [3.5632, 3.5782, 3.5093, 3.5357, 3.5486],\n",
      "        [3.3848, 3.2783, 3.3845, 3.4457, 3.5308],\n",
      "        [3.4322, 3.4187, 3.5302, 3.5455, 3.5896],\n",
      "        [3.4127, 3.3616, 3.4444, 3.4959, 3.4566],\n",
      "        [3.4819, 3.3393, 3.5871, 3.6163, 3.5126],\n",
      "        [3.5726, 3.6289, 3.4941, 3.7658, 3.6348]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4424, 3.4559, 3.4655, 3.5000, 3.5005],\n",
      "        [3.4405, 3.4664, 3.3269, 3.5547, 3.4600],\n",
      "        [3.3682, 3.3994, 3.3061, 3.4566, 3.3971],\n",
      "        [3.3868, 3.4700, 3.3683, 3.5963, 3.3996],\n",
      "        [3.3379, 3.4568, 3.4424, 3.3743, 3.3801],\n",
      "        [3.8176, 3.8612, 3.5093, 3.7175, 3.5663],\n",
      "        [3.5959, 3.5875, 3.6348, 3.7892, 3.5721],\n",
      "        [3.7997, 3.7959, 3.7589, 4.0312, 3.8525],\n",
      "        [3.2922, 3.3559, 3.3081, 3.3731, 3.3656],\n",
      "        [3.6288, 3.5774, 3.6545, 3.6597, 3.6907],\n",
      "        [3.4252, 3.2947, 3.4279, 3.4233, 3.3846],\n",
      "        [3.6302, 3.7306, 3.5764, 3.5377, 3.6095],\n",
      "        [3.4935, 3.4131, 3.5611, 3.5909, 3.5441],\n",
      "        [3.4580, 3.7186, 3.6075, 3.5523, 3.5346],\n",
      "        [3.1974, 3.2666, 3.2667, 3.2663, 3.2823],\n",
      "        [3.2402, 3.2428, 3.2915, 3.3205, 3.3027],\n",
      "        [3.3790, 3.4095, 3.3094, 3.4780, 3.4058],\n",
      "        [3.3062, 3.3611, 3.4281, 3.4496, 3.3680],\n",
      "        [3.4360, 3.4425, 3.3725, 3.5211, 3.4884],\n",
      "        [3.4342, 3.3235, 3.4813, 3.5149, 3.5337],\n",
      "        [3.4823, 3.4658, 3.5185, 3.5465, 3.6086],\n",
      "        [3.4261, 3.3469, 3.4532, 3.4997, 3.4593],\n",
      "        [3.4199, 3.3369, 3.4618, 3.4964, 3.4411],\n",
      "        [3.2021, 3.2684, 3.2703, 3.2701, 3.2864],\n",
      "        [3.5712, 3.6250, 3.4665, 3.6082, 3.6178],\n",
      "        [3.5759, 3.6287, 3.5674, 3.5456, 3.6060],\n",
      "        [3.4127, 3.4344, 3.3269, 3.4978, 3.4514],\n",
      "        [3.3480, 3.3875, 3.3576, 3.4487, 3.4179],\n",
      "        [3.4257, 3.3125, 3.4702, 3.5170, 3.5579],\n",
      "        [3.3921, 3.4158, 3.5241, 3.5824, 3.6160],\n",
      "        [3.6128, 3.7123, 3.5831, 3.7749, 3.7005],\n",
      "        [3.6714, 3.4980, 3.6283, 3.7666, 3.6198],\n",
      "        [3.5599, 3.5115, 3.5104, 3.6741, 3.6846],\n",
      "        [3.5854, 3.6377, 3.5296, 3.6694, 3.6131],\n",
      "        [3.2609, 3.2468, 3.3027, 3.3447, 3.3158],\n",
      "        [3.5960, 3.6215, 3.5163, 3.7192, 3.6996],\n",
      "        [3.7678, 3.5024, 3.6522, 4.1384, 3.9774],\n",
      "        [3.5538, 3.5861, 3.4872, 3.6012, 3.5738],\n",
      "        [3.2802, 3.3861, 3.4088, 3.4153, 3.3812],\n",
      "        [3.5786, 3.4894, 3.5844, 3.7244, 3.4981],\n",
      "        [3.6533, 3.5637, 3.4908, 3.6884, 3.6983],\n",
      "        [3.4014, 3.4886, 3.4869, 3.5297, 3.5214],\n",
      "        [3.4171, 3.4052, 3.4591, 3.5078, 3.6222],\n",
      "        [3.4144, 3.4270, 3.3585, 3.5030, 3.4663],\n",
      "        [3.4254, 3.4499, 3.3323, 3.5379, 3.4564],\n",
      "        [3.4809, 3.5918, 3.4975, 3.6086, 3.6558],\n",
      "        [3.3225, 3.4117, 3.2998, 3.4740, 3.3759],\n",
      "        [3.2693, 3.3420, 3.3070, 3.3568, 3.3571],\n",
      "        [3.4249, 3.3958, 3.3772, 3.5226, 3.4283],\n",
      "        [3.2775, 3.4067, 3.4148, 3.4042, 3.3786],\n",
      "        [3.3507, 3.4266, 3.4266, 3.5967, 3.3960],\n",
      "        [3.3144, 3.5419, 3.4439, 3.3227, 3.5439],\n",
      "        [3.5764, 3.6301, 3.4961, 3.7723, 3.6391],\n",
      "        [3.3247, 3.3628, 3.4588, 3.4660, 3.3541],\n",
      "        [3.7724, 3.7516, 3.7263, 3.9751, 3.7641],\n",
      "        [3.5479, 3.5071, 3.5318, 3.5613, 3.3529],\n",
      "        [3.2971, 3.3131, 3.3839, 3.4078, 3.3550],\n",
      "        [3.4933, 3.7331, 3.5562, 3.7333, 3.6959],\n",
      "        [3.4857, 3.6491, 3.5975, 3.6222, 3.5198],\n",
      "        [3.4472, 3.6965, 3.5286, 3.6877, 3.6622],\n",
      "        [3.4259, 3.3464, 3.3827, 3.5551, 3.3975],\n",
      "        [3.2294, 3.3076, 3.3336, 3.3885, 3.3620],\n",
      "        [3.6429, 3.6244, 3.6383, 3.7107, 3.8144],\n",
      "        [3.4211, 3.3666, 3.4903, 3.5305, 3.4884]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2576, 3.2351, 3.3361, 3.3656, 3.2738],\n",
      "        [3.7025, 3.5707, 3.6544, 3.7417, 3.8339],\n",
      "        [3.5731, 3.7778, 3.6484, 3.7344, 3.7826],\n",
      "        [3.5331, 3.4292, 3.5084, 3.5828, 3.4936],\n",
      "        [3.5322, 3.5183, 3.5972, 3.5709, 3.4556],\n",
      "        [3.5404, 3.5967, 3.4684, 3.6034, 3.5694],\n",
      "        [3.5454, 3.4278, 3.5295, 3.6068, 3.5039],\n",
      "        [3.8168, 3.8735, 3.6499, 3.7338, 3.6647],\n",
      "        [3.6343, 3.5738, 3.5669, 3.6620, 3.6671],\n",
      "        [3.2864, 3.3871, 3.4097, 3.4104, 3.3724],\n",
      "        [3.6534, 3.5449, 3.6043, 3.7031, 3.7975],\n",
      "        [3.5225, 3.3991, 3.6139, 3.6714, 3.4963],\n",
      "        [3.3872, 3.4107, 3.3132, 3.4888, 3.4077],\n",
      "        [3.4742, 3.5438, 3.4589, 3.6213, 3.5004],\n",
      "        [3.6723, 3.5818, 3.6408, 3.8371, 3.8685],\n",
      "        [3.5589, 3.4816, 3.5465, 3.5643, 3.4180],\n",
      "        [3.4311, 3.5407, 3.4279, 3.4791, 3.5312],\n",
      "        [3.5485, 3.4526, 3.4485, 3.7294, 3.5994],\n",
      "        [3.2023, 3.2779, 3.2757, 3.2767, 3.2963],\n",
      "        [3.2900, 3.4338, 3.4334, 3.4277, 3.4134],\n",
      "        [3.6494, 3.5375, 3.6301, 3.7125, 3.8032],\n",
      "        [3.3197, 3.3048, 3.2748, 3.4675, 3.2849],\n",
      "        [3.4449, 3.2837, 3.4185, 3.4080, 3.3688],\n",
      "        [3.4042, 3.5884, 3.4790, 3.5043, 3.3952],\n",
      "        [3.4559, 3.6813, 3.5117, 3.6782, 3.6439],\n",
      "        [3.3036, 3.2937, 3.3706, 3.4136, 3.3534],\n",
      "        [3.4945, 3.4000, 3.4743, 3.4419, 3.3248],\n",
      "        [3.5651, 3.6026, 3.5023, 3.7227, 3.7501],\n",
      "        [3.3685, 3.4177, 3.5227, 3.5585, 3.5870],\n",
      "        [3.3799, 3.2593, 3.4649, 3.3312, 3.5074],\n",
      "        [3.3616, 3.3578, 3.2307, 3.5283, 3.3047],\n",
      "        [3.4774, 3.7268, 3.5531, 3.7310, 3.6847],\n",
      "        [3.5865, 3.6194, 3.6178, 3.6264, 3.4665],\n",
      "        [3.3580, 3.6199, 3.5044, 3.5633, 3.6513],\n",
      "        [3.5014, 3.4940, 3.4285, 3.6085, 3.5475],\n",
      "        [3.3585, 3.4357, 3.3678, 3.5081, 3.3687],\n",
      "        [3.5526, 3.3083, 3.3770, 3.4942, 3.5022],\n",
      "        [3.3636, 3.3424, 3.4514, 3.5275, 3.4827],\n",
      "        [3.8382, 3.8684, 3.5335, 3.7403, 3.5723],\n",
      "        [3.6335, 3.7315, 3.5783, 3.5435, 3.6133],\n",
      "        [3.5718, 3.6156, 3.6081, 3.6207, 3.4674],\n",
      "        [3.4432, 3.2832, 3.4210, 3.4002, 3.3684],\n",
      "        [3.3163, 3.2932, 3.3743, 3.4236, 3.3569],\n",
      "        [3.9687, 4.1237, 3.7210, 3.9025, 3.7310],\n",
      "        [3.7703, 3.4707, 3.5533, 4.0583, 3.8484],\n",
      "        [3.2118, 3.2763, 3.2730, 3.2915, 3.3085],\n",
      "        [3.4380, 3.2922, 3.4282, 3.4233, 3.3822],\n",
      "        [3.4165, 3.2986, 3.4448, 3.5130, 3.5538],\n",
      "        [3.4884, 3.4120, 3.4686, 3.5872, 3.5083],\n",
      "        [3.3771, 3.4229, 3.4428, 3.5937, 3.4106],\n",
      "        [3.5426, 3.7260, 3.6456, 3.6863, 3.7148],\n",
      "        [3.4854, 3.3439, 3.4651, 3.5489, 3.4398],\n",
      "        [3.3094, 3.4313, 3.5339, 3.4559, 3.4943],\n",
      "        [3.4238, 3.4367, 3.4767, 3.5553, 3.4559],\n",
      "        [3.3033, 3.3637, 3.3159, 3.3862, 3.3848],\n",
      "        [3.4859, 3.3352, 3.4475, 3.5439, 3.4195],\n",
      "        [3.3763, 3.3284, 3.3792, 3.4317, 3.4842],\n",
      "        [3.7713, 3.5034, 3.6541, 4.1439, 3.9810],\n",
      "        [3.7687, 3.6308, 3.6200, 3.7989, 3.7422],\n",
      "        [3.5012, 3.3886, 3.5637, 3.6282, 3.5470],\n",
      "        [3.6135, 3.5873, 3.6549, 3.8075, 3.5792],\n",
      "        [3.4386, 3.3541, 3.4745, 3.5083, 3.4652],\n",
      "        [3.6699, 3.5755, 3.6349, 3.8073, 3.6523],\n",
      "        [3.6195, 3.7926, 3.5894, 3.8228, 3.7687]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4075, 3.5795, 3.5594, 3.4759, 3.5659],\n",
      "        [3.7962, 3.7047, 3.6707, 3.8808, 3.8077],\n",
      "        [3.4319, 3.3808, 3.4636, 3.5237, 3.4765],\n",
      "        [3.4313, 3.6289, 3.5782, 3.6280, 3.6843],\n",
      "        [3.3770, 3.4075, 3.3182, 3.4676, 3.4263],\n",
      "        [3.3196, 3.2806, 3.3681, 3.4370, 3.3550],\n",
      "        [3.2660, 3.2936, 3.2520, 3.4356, 3.2727],\n",
      "        [3.6705, 3.5859, 3.6516, 3.8408, 3.8722],\n",
      "        [3.5331, 3.4972, 3.5174, 3.5514, 3.3364],\n",
      "        [3.7882, 3.9140, 3.5229, 3.6847, 3.6030],\n",
      "        [3.2552, 3.3127, 3.1952, 3.4089, 3.2868],\n",
      "        [3.4296, 3.5135, 3.3922, 3.6554, 3.4214],\n",
      "        [3.5911, 3.6796, 3.5515, 3.6747, 3.6296],\n",
      "        [3.4288, 3.3613, 3.4540, 3.5125, 3.4709],\n",
      "        [3.6214, 3.5335, 3.7517, 3.5898, 3.5007],\n",
      "        [3.2847, 3.3773, 3.4043, 3.4108, 3.3716],\n",
      "        [3.3545, 3.3594, 3.4098, 3.4112, 3.4062],\n",
      "        [3.2954, 3.3094, 3.3783, 3.4124, 3.3542],\n",
      "        [3.4479, 3.3418, 3.5074, 3.5658, 3.5811],\n",
      "        [3.3804, 3.3867, 3.3520, 3.4258, 3.4020],\n",
      "        [3.4600, 3.5996, 3.5682, 3.6482, 3.6928],\n",
      "        [3.4418, 3.4010, 3.5631, 3.6552, 3.6769],\n",
      "        [3.2404, 3.3054, 3.1918, 3.4029, 3.2825],\n",
      "        [3.6324, 3.6720, 3.6871, 3.6722, 3.4471],\n",
      "        [3.6616, 3.7044, 3.6793, 3.7909, 3.7574],\n",
      "        [3.5603, 3.3604, 3.3829, 3.4833, 3.5589],\n",
      "        [3.3797, 3.5390, 3.4857, 3.5492, 3.6413],\n",
      "        [3.7554, 3.7513, 3.6849, 3.9657, 3.7706],\n",
      "        [3.6516, 3.6445, 3.5341, 3.6743, 3.7354],\n",
      "        [3.4880, 3.3534, 3.4757, 3.5591, 3.4829],\n",
      "        [3.4735, 3.5715, 3.5005, 3.6976, 3.4987],\n",
      "        [3.4690, 3.3943, 3.5456, 3.5890, 3.5442],\n",
      "        [3.4679, 3.3822, 3.4703, 3.5318, 3.5171],\n",
      "        [3.2871, 3.3413, 3.3902, 3.4081, 3.3622],\n",
      "        [3.5797, 3.4520, 3.5033, 3.5046, 3.4131],\n",
      "        [3.4187, 3.4370, 3.3302, 3.5081, 3.4582],\n",
      "        [3.5827, 3.6328, 3.4996, 3.7831, 3.6463],\n",
      "        [4.0418, 4.1172, 3.8018, 3.9543, 3.7720],\n",
      "        [3.5390, 3.4273, 3.5139, 3.5948, 3.4921],\n",
      "        [3.2786, 3.3443, 3.3069, 3.3616, 3.3615],\n",
      "        [3.3383, 3.3444, 3.3237, 3.4573, 3.3678],\n",
      "        [3.4248, 3.4449, 3.3257, 3.5421, 3.4546],\n",
      "        [3.7307, 3.6353, 3.6867, 3.8671, 3.7308],\n",
      "        [3.5177, 3.4451, 3.4691, 3.6637, 3.5387],\n",
      "        [3.6373, 3.5755, 3.5685, 3.6674, 3.6704],\n",
      "        [3.4768, 3.4342, 3.5336, 3.5860, 3.6228],\n",
      "        [3.5304, 3.4902, 3.3876, 3.6619, 3.6341],\n",
      "        [3.5740, 3.5435, 3.5976, 3.6237, 3.5969],\n",
      "        [3.5740, 3.5290, 3.5252, 3.7022, 3.7099],\n",
      "        [3.6756, 3.4826, 3.6245, 3.8044, 3.6267],\n",
      "        [3.2669, 3.2492, 3.3060, 3.3547, 3.3227],\n",
      "        [3.7872, 3.5261, 3.6662, 4.1530, 3.9916],\n",
      "        [3.4866, 3.4115, 3.5618, 3.5863, 3.5429],\n",
      "        [3.4981, 3.5805, 3.5314, 3.5889, 3.4308],\n",
      "        [3.5906, 3.6717, 3.6203, 3.6988, 3.6127],\n",
      "        [3.5637, 3.5959, 3.5404, 3.7001, 3.7494],\n",
      "        [3.2817, 3.4247, 3.4219, 3.4160, 3.3916],\n",
      "        [3.2971, 3.2329, 3.3412, 3.4233, 3.3476],\n",
      "        [3.7145, 3.7595, 3.4998, 3.6551, 3.6022],\n",
      "        [3.3944, 3.2920, 3.4441, 3.4755, 3.4159],\n",
      "        [3.5374, 3.4019, 3.5197, 3.4979, 3.4865],\n",
      "        [3.4045, 3.3290, 3.4487, 3.4703, 3.4393],\n",
      "        [3.7565, 3.4981, 3.6533, 4.1314, 3.9841],\n",
      "        [3.6795, 3.4952, 3.6350, 3.8097, 3.6365]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4380, 3.3234, 3.4914, 3.5399, 3.5713],\n",
      "        [3.6875, 3.6737, 3.5792, 3.7397, 3.7785],\n",
      "        [3.4400, 3.4958, 3.5161, 3.5552, 3.4458],\n",
      "        [3.3926, 3.4006, 3.3651, 3.4390, 3.4147],\n",
      "        [3.4940, 3.4153, 3.4737, 3.5967, 3.5143],\n",
      "        [3.5148, 3.5810, 3.5427, 3.5979, 3.4419],\n",
      "        [3.4789, 3.5253, 3.4008, 3.5091, 3.5252],\n",
      "        [3.5629, 3.3618, 3.3865, 3.4878, 3.5617],\n",
      "        [3.2935, 3.3741, 3.4109, 3.4303, 3.3905],\n",
      "        [3.3197, 3.2290, 3.3329, 3.4348, 3.3242],\n",
      "        [3.3973, 3.3413, 3.4018, 3.5373, 3.3907],\n",
      "        [3.6320, 3.3387, 3.5242, 3.8083, 3.7721],\n",
      "        [3.7842, 3.7589, 3.6658, 4.0298, 3.8322],\n",
      "        [3.6807, 3.5776, 3.6392, 3.8214, 3.6703],\n",
      "        [3.6043, 3.6320, 3.4907, 3.6400, 3.6548],\n",
      "        [3.3399, 3.2753, 3.3683, 3.4451, 3.3595],\n",
      "        [3.5356, 3.4986, 3.5209, 3.5559, 3.3392],\n",
      "        [3.2542, 3.3220, 3.3005, 3.3404, 3.3446],\n",
      "        [3.4924, 3.5649, 3.6095, 3.6763, 3.5812],\n",
      "        [3.3174, 3.3462, 3.4016, 3.4341, 3.4009],\n",
      "        [3.6627, 3.6758, 3.7326, 3.9025, 3.9759],\n",
      "        [3.1953, 3.2733, 3.3439, 3.3427, 3.3459],\n",
      "        [3.5350, 3.4873, 3.3860, 3.6570, 3.6192],\n",
      "        [3.5910, 3.6549, 3.5393, 3.6723, 3.6187],\n",
      "        [3.5362, 3.5824, 3.5561, 3.6064, 3.4540],\n",
      "        [3.4577, 3.6218, 3.4503, 3.6942, 3.5756],\n",
      "        [3.4437, 3.5283, 3.4464, 3.5432, 3.5644],\n",
      "        [3.5161, 3.4532, 3.4363, 3.6523, 3.5446],\n",
      "        [3.5014, 3.4351, 3.4742, 3.6258, 3.5170],\n",
      "        [3.5711, 3.5324, 3.4160, 3.6928, 3.6549],\n",
      "        [3.3823, 3.5405, 3.4891, 3.5538, 3.6444],\n",
      "        [3.6621, 3.6707, 3.7258, 3.9063, 3.9680],\n",
      "        [3.4411, 3.3689, 3.5157, 3.5574, 3.5047],\n",
      "        [3.4446, 3.5071, 3.5142, 3.5627, 3.4729],\n",
      "        [3.4370, 3.3697, 3.4633, 3.5307, 3.4758],\n",
      "        [3.5853, 3.6344, 3.5032, 3.7876, 3.6492],\n",
      "        [3.7501, 3.5971, 3.6219, 3.8799, 3.7137],\n",
      "        [3.6797, 3.5820, 3.6379, 3.8537, 3.8744],\n",
      "        [3.3156, 3.2841, 3.3630, 3.4185, 3.3383],\n",
      "        [3.4149, 3.3505, 3.3199, 3.4804, 3.5300],\n",
      "        [3.7463, 3.8147, 3.6186, 3.6771, 3.6426],\n",
      "        [3.3065, 3.3745, 3.4398, 3.4460, 3.3924],\n",
      "        [3.2979, 3.3226, 3.3889, 3.4183, 3.3621],\n",
      "        [3.4316, 3.5082, 3.5234, 3.5471, 3.6416],\n",
      "        [3.5276, 3.4020, 3.5193, 3.4992, 3.4569],\n",
      "        [3.4285, 3.3411, 3.4686, 3.5109, 3.4505],\n",
      "        [3.4089, 3.4515, 3.4295, 3.5917, 3.5303],\n",
      "        [3.4603, 3.4322, 3.5013, 3.5283, 3.7036],\n",
      "        [3.7325, 3.6494, 3.6737, 3.8940, 3.6851],\n",
      "        [3.5513, 3.6977, 3.6464, 3.7022, 3.7956],\n",
      "        [3.4073, 3.3705, 3.5838, 3.3865, 3.6350],\n",
      "        [3.6635, 3.7099, 3.6808, 3.7932, 3.7550],\n",
      "        [3.4910, 3.5000, 3.4286, 3.5924, 3.5984],\n",
      "        [3.2816, 3.2000, 3.3272, 3.4537, 3.3315],\n",
      "        [3.5618, 3.4328, 3.5508, 3.6382, 3.5247],\n",
      "        [3.4296, 3.3880, 3.4696, 3.5429, 3.4922],\n",
      "        [3.5347, 3.4270, 3.5051, 3.4483, 3.3625],\n",
      "        [3.2033, 3.2739, 3.3540, 3.3467, 3.3740],\n",
      "        [3.5178, 3.4669, 3.3532, 3.6427, 3.6220],\n",
      "        [3.4165, 3.3073, 3.4822, 3.4036, 3.5215],\n",
      "        [3.7171, 3.7610, 3.5034, 3.6595, 3.6050],\n",
      "        [3.6793, 3.4888, 3.6316, 3.8128, 3.6348],\n",
      "        [3.4267, 3.4472, 3.3340, 3.5338, 3.4589],\n",
      "        [3.4320, 3.3666, 3.4590, 3.5200, 3.4763]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2977, 3.4381, 3.4416, 3.4406, 3.4221],\n",
      "        [3.3343, 3.2685, 3.3652, 3.4442, 3.3512],\n",
      "        [3.7730, 3.5905, 3.7004, 3.9586, 3.8064],\n",
      "        [3.7003, 3.6491, 3.5930, 3.7824, 3.7883],\n",
      "        [3.3486, 3.3147, 3.2662, 3.4893, 3.3525],\n",
      "        [3.4583, 3.6126, 3.4453, 3.6925, 3.5734],\n",
      "        [3.3982, 3.4828, 3.4787, 3.5274, 3.5255],\n",
      "        [3.6030, 3.5705, 3.5936, 3.7338, 3.7228],\n",
      "        [3.5628, 3.5637, 3.4687, 3.6082, 3.6959],\n",
      "        [3.5319, 3.4014, 3.5236, 3.4988, 3.4732],\n",
      "        [3.4361, 3.3590, 3.4686, 3.5204, 3.4716],\n",
      "        [3.4409, 3.3740, 3.3468, 3.5081, 3.5599],\n",
      "        [3.5614, 3.6121, 3.4807, 3.7568, 3.6109],\n",
      "        [3.6015, 3.4006, 3.4918, 3.5762, 3.5447],\n",
      "        [3.5505, 3.7073, 3.5662, 3.6696, 3.6408],\n",
      "        [3.4483, 3.4005, 3.5675, 3.6596, 3.6816],\n",
      "        [3.3602, 3.4322, 3.3590, 3.5609, 3.3974],\n",
      "        [3.2987, 3.3520, 3.3199, 3.3905, 3.3934],\n",
      "        [3.6793, 3.6687, 3.5765, 3.7376, 3.7866],\n",
      "        [3.2878, 3.3583, 3.4003, 3.4184, 3.3709],\n",
      "        [3.4584, 3.3783, 3.5154, 3.5440, 3.5275],\n",
      "        [3.5637, 3.6083, 3.5889, 3.7699, 3.5926],\n",
      "        [3.6034, 3.3248, 3.3671, 3.4851, 3.5624],\n",
      "        [3.3858, 3.5757, 3.4390, 3.4619, 3.3941],\n",
      "        [3.4056, 3.3629, 3.5737, 3.3899, 3.6251],\n",
      "        [3.4400, 3.3802, 3.4663, 3.5364, 3.4829],\n",
      "        [3.4070, 3.4163, 3.3634, 3.5059, 3.4666],\n",
      "        [3.4336, 3.3489, 3.4663, 3.5139, 3.4622],\n",
      "        [3.6841, 3.7326, 3.4934, 3.6459, 3.6068],\n",
      "        [3.3917, 3.4754, 3.6671, 3.5245, 3.6477],\n",
      "        [3.2912, 3.4618, 3.2760, 3.4862, 3.3291],\n",
      "        [3.4923, 3.5975, 3.5078, 3.6278, 3.6685],\n",
      "        [3.2980, 3.2293, 3.3433, 3.4226, 3.3538],\n",
      "        [3.7295, 3.6078, 3.6873, 3.7733, 3.8739],\n",
      "        [3.5482, 3.5120, 3.5346, 3.5673, 3.3513],\n",
      "        [3.5456, 3.4363, 3.4997, 3.4692, 3.3755],\n",
      "        [3.4307, 3.3426, 3.4718, 3.5147, 3.4529],\n",
      "        [3.2303, 3.2133, 3.2883, 3.3132, 3.2854],\n",
      "        [3.4249, 3.5003, 3.4919, 3.5506, 3.5042],\n",
      "        [3.5919, 3.6585, 3.4891, 3.6166, 3.6221],\n",
      "        [3.3682, 3.3457, 3.4328, 3.5013, 3.3791],\n",
      "        [3.5599, 3.5253, 3.4805, 3.6238, 3.7092],\n",
      "        [3.6391, 3.6362, 3.6655, 3.7385, 3.8228],\n",
      "        [3.4373, 3.4523, 3.3415, 3.5355, 3.4748],\n",
      "        [3.4093, 3.3095, 3.4624, 3.4943, 3.4282],\n",
      "        [3.3767, 3.3397, 3.4511, 3.5085, 3.4661],\n",
      "        [3.3196, 3.3475, 3.4047, 3.4379, 3.4033],\n",
      "        [3.8575, 3.5565, 3.7571, 4.2236, 4.0830],\n",
      "        [3.4311, 3.5150, 3.4437, 3.5542, 3.5538],\n",
      "        [3.8564, 3.5528, 3.7532, 4.2223, 4.0736],\n",
      "        [3.3840, 3.3325, 3.3873, 3.4451, 3.4929],\n",
      "        [3.3795, 3.3271, 3.4582, 3.5140, 3.5343],\n",
      "        [3.7014, 3.3270, 3.5229, 3.9222, 3.8409],\n",
      "        [3.5952, 3.6800, 3.5342, 3.5219, 3.5288],\n",
      "        [3.5176, 3.4818, 3.5057, 3.6242, 3.6130],\n",
      "        [3.5118, 3.3950, 3.5857, 3.7383, 3.7484],\n",
      "        [3.4379, 3.5465, 3.4991, 3.4949, 3.5722],\n",
      "        [3.4825, 3.5340, 3.4118, 3.5178, 3.5324],\n",
      "        [3.3230, 3.6124, 3.5394, 3.5154, 3.6592],\n",
      "        [3.4289, 3.4485, 3.3371, 3.5376, 3.4613],\n",
      "        [3.3667, 3.4012, 3.3253, 3.4593, 3.4251],\n",
      "        [3.6187, 3.4915, 3.5315, 3.5604, 3.4676],\n",
      "        [3.5876, 3.6358, 3.5065, 3.7915, 3.6517],\n",
      "        [3.3363, 3.4707, 3.3089, 3.5009, 3.3515]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5866, 3.5934, 3.5230, 3.6082, 3.5739],\n",
      "        [3.2956, 3.3080, 3.3834, 3.4205, 3.3564],\n",
      "        [3.4218, 3.3040, 3.4378, 3.5199, 3.5689],\n",
      "        [3.5644, 3.4717, 3.5553, 3.5678, 3.4303],\n",
      "        [3.4393, 3.5359, 3.4949, 3.7098, 3.5041],\n",
      "        [3.5210, 3.5726, 3.4884, 3.6569, 3.5584],\n",
      "        [3.5891, 3.6448, 3.4888, 3.6413, 3.6360],\n",
      "        [3.5502, 3.5131, 3.5375, 3.5714, 3.3534],\n",
      "        [3.4321, 3.5892, 3.4985, 3.5388, 3.4004],\n",
      "        [3.4410, 3.5469, 3.4392, 3.4970, 3.5422],\n",
      "        [3.3687, 3.4023, 3.3281, 3.4632, 3.4272],\n",
      "        [3.6128, 3.5919, 3.6308, 3.6869, 3.7872],\n",
      "        [3.5872, 3.6348, 3.5084, 3.7943, 3.6505],\n",
      "        [3.4325, 3.4442, 3.4229, 3.5053, 3.4859],\n",
      "        [3.2563, 3.4020, 3.2158, 3.4524, 3.2768],\n",
      "        [3.2931, 3.3925, 3.4215, 3.4376, 3.3957],\n",
      "        [3.4512, 3.4749, 3.3442, 3.5764, 3.4756],\n",
      "        [3.4381, 3.3016, 3.4407, 3.4456, 3.3985],\n",
      "        [3.4320, 3.3680, 3.4621, 3.5328, 3.4834],\n",
      "        [3.6297, 3.7983, 3.6010, 3.8406, 3.7800],\n",
      "        [3.3302, 3.3814, 3.3285, 3.4225, 3.4035],\n",
      "        [3.4556, 3.4622, 3.4785, 3.5232, 3.5151],\n",
      "        [3.4261, 3.4313, 3.4193, 3.4957, 3.4834],\n",
      "        [3.4541, 3.4330, 3.3832, 3.5969, 3.4869],\n",
      "        [3.3659, 3.3564, 3.4134, 3.4318, 3.4131],\n",
      "        [3.7816, 3.5095, 3.6659, 4.1608, 3.9916],\n",
      "        [3.3185, 3.3744, 3.3256, 3.4205, 3.3903],\n",
      "        [3.4259, 3.4413, 3.4538, 3.5168, 3.5049],\n",
      "        [3.4270, 3.4496, 3.3341, 3.5492, 3.4523],\n",
      "        [3.6392, 3.6387, 3.6084, 3.7105, 3.7099],\n",
      "        [3.3909, 3.5722, 3.4616, 3.4851, 3.3821],\n",
      "        [3.4041, 3.3610, 3.4297, 3.5409, 3.4109],\n",
      "        [3.8352, 3.8779, 3.5294, 3.7571, 3.5760],\n",
      "        [3.5034, 3.7141, 3.5428, 3.7356, 3.6749],\n",
      "        [3.4518, 3.3900, 3.5130, 3.5755, 3.5179],\n",
      "        [3.2922, 3.3411, 3.3960, 3.4212, 3.3692],\n",
      "        [3.3448, 3.3671, 3.3249, 3.4837, 3.3779],\n",
      "        [3.6183, 3.4098, 3.4847, 3.8975, 3.6782],\n",
      "        [3.4441, 3.3713, 3.4835, 3.5312, 3.5274],\n",
      "        [3.6615, 3.6572, 3.5579, 3.7189, 3.7590],\n",
      "        [3.3021, 3.3252, 3.3947, 3.4260, 3.3667],\n",
      "        [3.5742, 3.5033, 3.5630, 3.5877, 3.4163],\n",
      "        [3.3383, 3.4719, 3.3117, 3.5049, 3.3537],\n",
      "        [3.5324, 3.5041, 3.5620, 3.6003, 3.5725],\n",
      "        [3.6176, 3.7725, 3.7028, 3.7599, 3.7741],\n",
      "        [3.5325, 3.4047, 3.6251, 3.6887, 3.5072],\n",
      "        [3.3864, 3.2615, 3.3732, 3.4869, 3.3548],\n",
      "        [3.6668, 3.6735, 3.7322, 3.9147, 3.9728],\n",
      "        [3.4322, 3.3086, 3.4654, 3.5368, 3.5654],\n",
      "        [3.3915, 3.3702, 3.4176, 3.4505, 3.4408],\n",
      "        [3.4189, 3.5949, 3.4987, 3.5351, 3.4090],\n",
      "        [3.4818, 3.5846, 3.5250, 3.5805, 3.4220],\n",
      "        [3.4312, 3.4340, 3.3777, 3.5230, 3.4868],\n",
      "        [3.2863, 3.3789, 3.4140, 3.4255, 3.3733],\n",
      "        [3.4431, 3.6685, 3.5329, 3.6801, 3.6766],\n",
      "        [3.4899, 3.5215, 3.3702, 3.5246, 3.5134],\n",
      "        [3.5504, 3.6928, 3.6441, 3.6978, 3.7939],\n",
      "        [3.4528, 3.3995, 3.4826, 3.5596, 3.5131],\n",
      "        [3.4671, 3.6038, 3.5779, 3.6611, 3.7011],\n",
      "        [3.5698, 3.4668, 3.5533, 3.5603, 3.4542],\n",
      "        [3.6349, 3.5598, 3.6332, 3.7429, 3.8070],\n",
      "        [3.5679, 3.5956, 3.5965, 3.7746, 3.5820],\n",
      "        [3.9142, 3.9721, 3.7438, 3.8415, 3.7571],\n",
      "        [3.4454, 3.4582, 3.3323, 3.5596, 3.4587]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5890, 3.6360, 3.5110, 3.7986, 3.6534],\n",
      "        [3.3831, 3.3518, 3.4605, 3.5410, 3.4860],\n",
      "        [3.3684, 3.3394, 3.4256, 3.5252, 3.3774],\n",
      "        [3.4312, 3.3710, 3.4618, 3.5294, 3.4774],\n",
      "        [3.3380, 3.2463, 3.3546, 3.4614, 3.3382],\n",
      "        [3.4093, 3.3653, 3.5795, 3.3983, 3.6300],\n",
      "        [3.4529, 3.4674, 3.3371, 3.5730, 3.4659],\n",
      "        [3.6790, 3.7626, 3.6124, 3.8203, 3.7964],\n",
      "        [3.5411, 3.4908, 3.3946, 3.6690, 3.6265],\n",
      "        [3.6005, 3.6454, 3.5454, 3.6968, 3.6308],\n",
      "        [3.4238, 3.4458, 3.3486, 3.5365, 3.4660],\n",
      "        [3.4801, 3.5993, 3.4457, 3.6054, 3.5418],\n",
      "        [3.2915, 3.3605, 3.4056, 3.4266, 3.3759],\n",
      "        [3.5293, 3.2905, 3.6031, 3.6166, 3.5484],\n",
      "        [3.5616, 3.3081, 3.3846, 3.5204, 3.4967],\n",
      "        [3.3400, 3.4041, 3.3545, 3.5150, 3.3999],\n",
      "        [3.5457, 3.5156, 3.4687, 3.6029, 3.5235],\n",
      "        [3.4545, 3.5958, 3.5101, 3.5563, 3.4100],\n",
      "        [3.6007, 3.5453, 3.5738, 3.6567, 3.7146],\n",
      "        [3.6879, 3.7351, 3.4990, 3.6543, 3.6116],\n",
      "        [3.3371, 3.2903, 3.3813, 3.4518, 3.3681],\n",
      "        [3.4086, 3.2911, 3.4889, 3.3852, 3.5268],\n",
      "        [3.3202, 3.3755, 3.3281, 3.4246, 3.3931],\n",
      "        [3.4683, 3.4318, 3.5132, 3.5413, 3.7119],\n",
      "        [3.6406, 3.5836, 3.6039, 3.7057, 3.8115],\n",
      "        [3.5030, 3.7354, 3.5205, 3.7623, 3.6892],\n",
      "        [3.8172, 3.8044, 3.7755, 4.0610, 3.8707],\n",
      "        [3.3255, 3.2328, 3.3412, 3.4466, 3.3312],\n",
      "        [3.2955, 3.3464, 3.4020, 3.4243, 3.3724],\n",
      "        [3.5583, 3.5724, 3.6339, 3.6494, 3.6066],\n",
      "        [3.3982, 3.4174, 3.3265, 3.5094, 3.4208],\n",
      "        [3.4400, 3.5047, 3.5322, 3.5691, 3.4457],\n",
      "        [3.3802, 3.3810, 3.3643, 3.5514, 3.4435],\n",
      "        [3.6334, 3.5472, 3.6271, 3.7872, 3.6340],\n",
      "        [3.4506, 3.4475, 3.3834, 3.5489, 3.5054],\n",
      "        [3.5352, 3.4238, 3.5319, 3.5259, 3.4438],\n",
      "        [3.6110, 3.6288, 3.5323, 3.7468, 3.7173],\n",
      "        [3.8250, 3.6095, 3.7476, 3.9772, 3.8078],\n",
      "        [3.6611, 3.7046, 3.7333, 3.7611, 3.5667],\n",
      "        [3.4123, 3.4314, 3.3385, 3.5054, 3.4583],\n",
      "        [3.4640, 3.6989, 3.4948, 3.7296, 3.6610],\n",
      "        [3.3981, 3.6060, 3.5617, 3.6143, 3.6267],\n",
      "        [3.4500, 3.3766, 3.5237, 3.5734, 3.5229],\n",
      "        [3.2349, 3.3419, 3.5236, 3.3725, 3.4761],\n",
      "        [3.6693, 3.6798, 3.7418, 3.9153, 3.9834],\n",
      "        [3.4469, 3.3904, 3.4799, 3.5425, 3.4949],\n",
      "        [3.5519, 3.5142, 3.5400, 3.5756, 3.3561],\n",
      "        [3.5272, 3.2578, 3.6118, 3.6016, 3.5190],\n",
      "        [3.4799, 3.3740, 3.5551, 3.6268, 3.6110],\n",
      "        [3.4618, 3.3499, 3.5276, 3.5902, 3.5899],\n",
      "        [3.4809, 3.3987, 3.5491, 3.5828, 3.5398],\n",
      "        [3.5087, 3.7411, 3.5723, 3.7611, 3.7141],\n",
      "        [3.3947, 3.3768, 3.2423, 3.5676, 3.3105],\n",
      "        [3.8166, 3.7990, 3.7423, 4.0440, 3.8586],\n",
      "        [3.4350, 3.3604, 3.4655, 3.5210, 3.4741],\n",
      "        [3.6714, 3.7298, 3.7305, 3.7385, 3.5349],\n",
      "        [3.5982, 3.5656, 3.6225, 3.7194, 3.5299],\n",
      "        [3.6516, 3.6051, 3.6977, 3.8485, 3.6069],\n",
      "        [3.5806, 3.5336, 3.4264, 3.7047, 3.6632],\n",
      "        [3.4775, 3.6125, 3.4098, 3.5693, 3.5080],\n",
      "        [3.4226, 3.6589, 3.5389, 3.6520, 3.6823],\n",
      "        [3.5988, 3.5438, 3.5715, 3.6544, 3.7112],\n",
      "        [3.5127, 3.3958, 3.5776, 3.6496, 3.5602],\n",
      "        [3.4887, 3.3295, 3.4656, 3.5487, 3.4299]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4356, 3.3415, 3.4771, 3.5287, 3.4535],\n",
      "        [3.5704, 3.4385, 3.5621, 3.6548, 3.5343],\n",
      "        [3.9862, 4.1402, 3.7427, 3.9604, 3.7606],\n",
      "        [3.4451, 3.3584, 3.4823, 3.5534, 3.5486],\n",
      "        [3.3497, 3.3980, 3.3374, 3.4533, 3.4202],\n",
      "        [3.4198, 3.4136, 3.4585, 3.5497, 3.5982],\n",
      "        [3.4327, 3.6614, 3.5132, 3.6686, 3.6417],\n",
      "        [3.5909, 3.4590, 3.5176, 3.5257, 3.4254],\n",
      "        [3.4321, 3.3667, 3.4598, 3.5287, 3.4758],\n",
      "        [3.4411, 3.4180, 3.3923, 3.5701, 3.5941],\n",
      "        [3.5843, 3.5228, 3.5232, 3.7198, 3.7016],\n",
      "        [3.5265, 3.4379, 3.5981, 3.6382, 3.5762],\n",
      "        [3.4532, 3.4492, 3.3856, 3.5533, 3.5078],\n",
      "        [3.4051, 3.2990, 3.4583, 3.4954, 3.4278],\n",
      "        [3.3381, 3.2866, 3.3822, 3.4533, 3.3672],\n",
      "        [3.8080, 3.7120, 3.6864, 3.9038, 3.8209],\n",
      "        [3.3902, 3.6304, 3.5221, 3.6037, 3.6707],\n",
      "        [3.3061, 3.4176, 3.4380, 3.4539, 3.4127],\n",
      "        [3.5195, 3.4773, 3.5056, 3.5989, 3.5291],\n",
      "        [3.4382, 3.3612, 3.4689, 3.5288, 3.4775],\n",
      "        [3.3314, 3.3484, 3.4315, 3.4647, 3.3792],\n",
      "        [3.3049, 3.3558, 3.3272, 3.4030, 3.4008],\n",
      "        [3.4295, 3.4437, 3.3442, 3.5284, 3.4707],\n",
      "        [3.2490, 3.3119, 3.3073, 3.3349, 3.3405],\n",
      "        [3.5941, 3.6401, 3.5144, 3.8045, 3.6593],\n",
      "        [3.3076, 3.3644, 3.3258, 3.4083, 3.3872],\n",
      "        [3.3060, 3.3016, 3.3441, 3.4159, 3.3655],\n",
      "        [3.4476, 3.6714, 3.5378, 3.6890, 3.6821],\n",
      "        [3.5786, 3.5251, 3.5629, 3.6070, 3.3956],\n",
      "        [3.5827, 3.6053, 3.6233, 3.7144, 3.6177],\n",
      "        [3.3020, 3.3794, 3.4215, 3.4468, 3.4004],\n",
      "        [3.3814, 3.4283, 3.4445, 3.6150, 3.4150],\n",
      "        [3.6728, 3.5790, 3.6399, 3.8556, 3.8762],\n",
      "        [3.6123, 3.5341, 3.6477, 3.6521, 3.4953],\n",
      "        [3.5941, 3.6401, 3.5144, 3.8045, 3.6593],\n",
      "        [3.3238, 3.4402, 3.5500, 3.4823, 3.5105],\n",
      "        [3.3270, 3.4683, 3.4615, 3.4640, 3.4586],\n",
      "        [3.3609, 3.4296, 3.5381, 3.5602, 3.5750],\n",
      "        [3.7566, 3.6103, 3.6372, 3.8088, 3.7226],\n",
      "        [3.5934, 3.6436, 3.6570, 3.6645, 3.5170],\n",
      "        [3.6316, 3.5806, 3.6201, 3.7310, 3.7422],\n",
      "        [3.5030, 3.5386, 3.4404, 3.6276, 3.5524],\n",
      "        [3.8005, 3.8200, 3.7521, 4.0697, 3.8848],\n",
      "        [3.2407, 3.3053, 3.3057, 3.3209, 3.3354],\n",
      "        [3.5984, 3.6370, 3.5456, 3.7097, 3.6283],\n",
      "        [3.3849, 3.4140, 3.3398, 3.4761, 3.4456],\n",
      "        [3.5519, 3.4403, 3.5073, 3.4819, 3.3826],\n",
      "        [3.6069, 3.4648, 3.6014, 3.7006, 3.5707],\n",
      "        [3.4605, 3.4227, 3.5056, 3.4623, 3.3321],\n",
      "        [3.5519, 3.4403, 3.5073, 3.4819, 3.3826],\n",
      "        [3.6751, 3.5933, 3.6604, 3.8618, 3.8879],\n",
      "        [3.6488, 3.5826, 3.5838, 3.6896, 3.6832],\n",
      "        [3.6583, 3.6205, 3.6603, 3.7481, 3.8723],\n",
      "        [3.4528, 3.3501, 3.4946, 3.4891, 3.5274],\n",
      "        [3.4120, 3.3670, 3.5819, 3.4028, 3.6324],\n",
      "        [3.5276, 3.4155, 3.4970, 3.4890, 3.3535],\n",
      "        [3.6017, 3.6077, 3.6360, 3.8176, 3.5912],\n",
      "        [3.5788, 3.7200, 3.6846, 3.7158, 3.7232],\n",
      "        [3.3326, 3.3175, 3.2903, 3.4917, 3.2879],\n",
      "        [3.4301, 3.3741, 3.4651, 3.5375, 3.4798],\n",
      "        [3.2994, 3.4286, 3.4429, 3.4506, 3.4186],\n",
      "        [3.4587, 3.6115, 3.4599, 3.4056, 3.5753],\n",
      "        [3.7808, 3.8201, 3.5232, 3.7084, 3.6082],\n",
      "        [3.4600, 3.4649, 3.4833, 3.5320, 3.5203]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5611, 3.6722, 3.6980, 3.7217, 3.5872],\n",
      "        [3.6718, 3.6137, 3.7187, 3.8752, 3.6238],\n",
      "        [3.5685, 3.5804, 3.6400, 3.6115, 3.4865],\n",
      "        [3.4069, 3.2928, 3.4059, 3.4887, 3.5575],\n",
      "        [3.3282, 3.3529, 3.4142, 3.4544, 3.4137],\n",
      "        [3.4679, 3.4865, 3.3637, 3.6027, 3.4948],\n",
      "        [3.4386, 3.3725, 3.4690, 3.5452, 3.4914],\n",
      "        [3.3004, 3.3494, 3.4061, 3.4325, 3.3779],\n",
      "        [3.2697, 3.2398, 3.3507, 3.3827, 3.2868],\n",
      "        [3.3083, 3.3030, 3.3461, 3.4196, 3.3686],\n",
      "        [3.4012, 3.4257, 3.3355, 3.5026, 3.4425],\n",
      "        [3.5713, 3.4666, 3.5616, 3.5703, 3.4496],\n",
      "        [3.3453, 3.3759, 3.3066, 3.5061, 3.4011],\n",
      "        [3.5934, 3.5977, 3.5298, 3.6206, 3.5822],\n",
      "        [3.6566, 3.6688, 3.7304, 3.8974, 3.9716],\n",
      "        [3.4084, 3.4258, 3.3368, 3.5179, 3.4532],\n",
      "        [3.3064, 3.2349, 3.3526, 3.4388, 3.3639],\n",
      "        [3.3961, 3.2812, 3.3896, 3.4695, 3.5497],\n",
      "        [3.5543, 3.4418, 3.5093, 3.4857, 3.3856],\n",
      "        [3.3428, 3.2495, 3.3587, 3.4694, 3.3434],\n",
      "        [3.2997, 3.3967, 3.4282, 3.4501, 3.4041],\n",
      "        [3.4679, 3.4865, 3.3637, 3.6027, 3.4948],\n",
      "        [3.5974, 3.6122, 3.5288, 3.7024, 3.6165],\n",
      "        [3.6357, 3.5428, 3.7688, 3.6158, 3.5170],\n",
      "        [3.6147, 3.5272, 3.6206, 3.7424, 3.4652],\n",
      "        [3.5161, 3.6620, 3.6130, 3.6589, 3.5504],\n",
      "        [4.0762, 4.1462, 3.8188, 3.9702, 3.8051],\n",
      "        [3.5139, 3.7444, 3.5767, 3.7696, 3.7198],\n",
      "        [3.4558, 3.3818, 3.5024, 3.5517, 3.5332],\n",
      "        [3.6555, 3.5917, 3.5932, 3.7806, 3.7804],\n",
      "        [3.2389, 3.3004, 3.2987, 3.3263, 3.3348],\n",
      "        [3.3054, 3.3703, 3.3441, 3.4058, 3.4024],\n",
      "        [3.2883, 3.2020, 3.3279, 3.4702, 3.3305],\n",
      "        [3.4064, 3.4806, 3.3878, 3.6312, 3.4227],\n",
      "        [3.5533, 3.4491, 3.5533, 3.5571, 3.4527],\n",
      "        [3.4459, 3.3482, 3.3887, 3.6016, 3.4080],\n",
      "        [3.3342, 3.3989, 3.4697, 3.4931, 3.4150],\n",
      "        [3.4434, 3.4197, 3.3944, 3.5740, 3.5971],\n",
      "        [3.4381, 3.3214, 3.4789, 3.5481, 3.5767],\n",
      "        [3.5311, 3.5463, 3.5950, 3.7179, 3.6414],\n",
      "        [3.4849, 3.4063, 3.5527, 3.5802, 3.5506],\n",
      "        [3.7299, 3.6080, 3.6822, 3.8411, 3.5844],\n",
      "        [3.3855, 3.4144, 3.3374, 3.4890, 3.4400],\n",
      "        [3.5533, 3.4491, 3.5533, 3.5571, 3.4527],\n",
      "        [3.3618, 3.3528, 3.3363, 3.4967, 3.3862],\n",
      "        [3.3482, 3.3362, 3.3119, 3.5156, 3.3863],\n",
      "        [3.3098, 3.4558, 3.4612, 3.4544, 3.4288],\n",
      "        [3.5640, 3.7198, 3.5833, 3.7114, 3.6584],\n",
      "        [3.5141, 3.6610, 3.5641, 3.6732, 3.7105],\n",
      "        [3.6213, 3.6686, 3.6417, 3.7179, 3.6148],\n",
      "        [3.6190, 3.6485, 3.6089, 3.5959, 3.6462],\n",
      "        [3.4370, 3.4181, 3.4327, 3.5184, 3.4884],\n",
      "        [3.3417, 3.4106, 3.4118, 3.5937, 3.3722],\n",
      "        [3.2302, 3.3068, 3.3614, 3.3906, 3.3845],\n",
      "        [3.3847, 3.2552, 3.3528, 3.4724, 3.3487],\n",
      "        [3.4079, 3.4966, 3.4887, 3.4507, 3.4357],\n",
      "        [3.4557, 3.5147, 3.5272, 3.5838, 3.4859],\n",
      "        [3.5867, 3.5243, 3.5254, 3.7238, 3.7049],\n",
      "        [3.4647, 3.4856, 3.3502, 3.5991, 3.4928],\n",
      "        [3.6740, 3.6782, 3.7396, 3.9277, 3.9813],\n",
      "        [3.5851, 3.6069, 3.6254, 3.7184, 3.6208],\n",
      "        [3.5013, 3.6032, 3.5176, 3.6447, 3.6790],\n",
      "        [3.8669, 3.5626, 3.7677, 4.2402, 4.0934],\n",
      "        [3.4257, 3.3582, 3.3327, 3.5007, 3.5426]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4480, 3.5196, 3.5450, 3.5739, 3.6632],\n",
      "        [3.4031, 3.4270, 3.3372, 3.5065, 3.4451],\n",
      "        [3.5546, 3.4372, 3.5325, 3.6238, 3.5103],\n",
      "        [3.3960, 3.3484, 3.4244, 3.5475, 3.3990],\n",
      "        [3.6325, 3.5996, 3.6756, 3.8430, 3.6013],\n",
      "        [3.4340, 3.3547, 3.4663, 3.5297, 3.4738],\n",
      "        [3.6007, 3.6498, 3.5453, 3.7030, 3.6313],\n",
      "        [3.4305, 3.4533, 3.4902, 3.6499, 3.4848],\n",
      "        [3.6184, 3.6008, 3.6573, 3.8304, 3.5979],\n",
      "        [3.4362, 3.4999, 3.5093, 3.5677, 3.5355],\n",
      "        [3.3711, 3.5818, 3.6068, 3.5704, 3.6701],\n",
      "        [3.3336, 3.6196, 3.5511, 3.5368, 3.6732],\n",
      "        [3.7848, 3.5976, 3.7124, 3.9804, 3.8196],\n",
      "        [3.5142, 3.5906, 3.5500, 3.6185, 3.4494],\n",
      "        [3.6899, 3.5874, 3.6554, 3.8426, 3.6743],\n",
      "        [3.4497, 3.4247, 3.4906, 3.5451, 3.6715],\n",
      "        [3.4415, 3.3755, 3.4794, 3.5582, 3.4994],\n",
      "        [3.4844, 3.4043, 3.5644, 3.6176, 3.5622],\n",
      "        [3.5433, 3.4195, 3.5381, 3.5324, 3.4674],\n",
      "        [3.4407, 3.4433, 3.5063, 3.5936, 3.4637],\n",
      "        [3.5300, 3.5788, 3.4973, 3.6737, 3.5693],\n",
      "        [3.4596, 3.4805, 3.3527, 3.5925, 3.4865],\n",
      "        [3.4000, 3.5782, 3.4703, 3.5017, 3.3931],\n",
      "        [3.8565, 3.9459, 3.6115, 3.7654, 3.6389],\n",
      "        [3.3054, 3.4244, 3.4414, 3.4499, 3.4141],\n",
      "        [3.6752, 3.5754, 3.5124, 3.7276, 3.7234],\n",
      "        [3.2614, 3.2543, 3.3121, 3.3585, 3.3278],\n",
      "        [3.6037, 3.6451, 3.6155, 3.7484, 3.6273],\n",
      "        [3.7202, 3.5657, 3.5873, 3.7294, 3.7111],\n",
      "        [3.7320, 3.6094, 3.6841, 3.8453, 3.5871],\n",
      "        [3.4205, 3.3790, 3.5995, 3.4113, 3.6507],\n",
      "        [3.3813, 3.5958, 3.5373, 3.5929, 3.6520],\n",
      "        [3.4501, 3.3784, 3.4780, 3.5551, 3.4909],\n",
      "        [3.4445, 3.3599, 3.4697, 3.5365, 3.4835],\n",
      "        [3.3534, 3.3028, 3.4077, 3.4770, 3.3628],\n",
      "        [3.3806, 3.3981, 3.5243, 3.5104, 3.5115],\n",
      "        [3.3385, 3.3018, 3.4096, 3.4666, 3.3530],\n",
      "        [3.5059, 3.5752, 3.6248, 3.7023, 3.5973],\n",
      "        [3.3106, 3.3189, 3.3959, 3.4408, 3.3723],\n",
      "        [3.2793, 3.2358, 3.3497, 3.3830, 3.2970],\n",
      "        [3.4513, 3.3669, 3.4861, 3.5417, 3.4843],\n",
      "        [3.4953, 3.5379, 3.4099, 3.5403, 3.5384],\n",
      "        [3.4449, 3.3246, 3.4954, 3.5562, 3.5815],\n",
      "        [3.8389, 3.8727, 3.5313, 3.7572, 3.5916],\n",
      "        [3.3063, 3.3821, 3.4253, 3.4546, 3.4061],\n",
      "        [3.5010, 3.5332, 3.3942, 3.5439, 3.5319],\n",
      "        [3.3309, 3.3790, 3.3307, 3.4312, 3.3985],\n",
      "        [3.6589, 3.5741, 3.6357, 3.7761, 3.5742],\n",
      "        [3.6070, 3.6896, 3.5700, 3.7040, 3.6485],\n",
      "        [3.3647, 3.3977, 3.3380, 3.4719, 3.4342],\n",
      "        [3.4229, 3.3610, 3.4269, 3.4973, 3.5300],\n",
      "        [3.4562, 3.3038, 3.4479, 3.4561, 3.4030],\n",
      "        [3.4348, 3.4368, 3.4278, 3.5121, 3.4945],\n",
      "        [3.3063, 3.3461, 3.4097, 3.4412, 3.3803],\n",
      "        [3.6652, 3.6721, 3.7419, 3.9195, 3.9768],\n",
      "        [3.4524, 3.5177, 3.5193, 3.5832, 3.4890],\n",
      "        [3.3858, 3.4130, 3.3762, 3.5023, 3.4690],\n",
      "        [3.5478, 3.4352, 3.5196, 3.4727, 3.3776],\n",
      "        [3.7478, 3.6394, 3.7125, 3.9026, 3.7557],\n",
      "        [3.5539, 3.5096, 3.5921, 3.6412, 3.5855],\n",
      "        [3.3800, 3.4114, 3.3371, 3.4931, 3.4297],\n",
      "        [3.6121, 3.4075, 3.5036, 3.5969, 3.5575],\n",
      "        [3.4099, 3.4381, 3.3464, 3.5197, 3.4555],\n",
      "        [3.4467, 3.3073, 3.4494, 3.4617, 3.4091]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3771, 3.3456, 3.4330, 3.5410, 3.3878],\n",
      "        [3.3370, 3.3821, 3.3362, 3.4353, 3.4072],\n",
      "        [3.4490, 3.3267, 3.4936, 3.5597, 3.5852],\n",
      "        [3.6352, 3.6870, 3.4896, 3.6353, 3.6195],\n",
      "        [3.4661, 3.3843, 3.5245, 3.5638, 3.5376],\n",
      "        [3.4684, 3.4888, 3.3535, 3.6064, 3.4978],\n",
      "        [3.3784, 3.4485, 3.3887, 3.5450, 3.3928],\n",
      "        [3.4462, 3.3618, 3.4712, 3.5399, 3.4857],\n",
      "        [3.3487, 3.4790, 3.3215, 3.5253, 3.3671],\n",
      "        [3.5999, 3.6402, 3.5969, 3.7346, 3.6243],\n",
      "        [3.3671, 3.3424, 3.4378, 3.5208, 3.3799],\n",
      "        [3.5058, 3.4216, 3.5737, 3.6205, 3.5658],\n",
      "        [3.7360, 3.7400, 3.6939, 3.8216, 3.8380],\n",
      "        [3.4716, 3.4896, 3.3670, 3.6101, 3.4997],\n",
      "        [3.3620, 3.4012, 3.3434, 3.4590, 3.4219],\n",
      "        [3.7243, 3.6379, 3.6731, 3.8799, 3.6713],\n",
      "        [3.3109, 3.3602, 3.3324, 3.4142, 3.4087],\n",
      "        [3.7320, 3.6732, 3.6394, 3.9224, 3.7585],\n",
      "        [3.1477, 3.2334, 3.3387, 3.3187, 3.3298],\n",
      "        [3.3590, 3.3476, 3.4467, 3.5151, 3.3753],\n",
      "        [3.3353, 3.6216, 3.5526, 3.5404, 3.6756],\n",
      "        [3.6704, 3.4188, 3.5260, 3.9490, 3.7365],\n",
      "        [3.5572, 3.6871, 3.6426, 3.7139, 3.7920],\n",
      "        [3.5351, 3.5500, 3.5984, 3.7257, 3.6465],\n",
      "        [3.4381, 3.3715, 3.4651, 3.5399, 3.4836],\n",
      "        [3.6000, 3.6536, 3.4995, 3.6622, 3.6495],\n",
      "        [3.6917, 3.5894, 3.6569, 3.8462, 3.6766],\n",
      "        [3.8154, 3.8081, 3.7636, 4.0569, 3.8642],\n",
      "        [3.6991, 3.6401, 3.6371, 3.8680, 3.6689],\n",
      "        [3.4238, 3.4380, 3.4643, 3.6008, 3.5449],\n",
      "        [3.4542, 3.5196, 3.5209, 3.5867, 3.4913],\n",
      "        [3.4951, 3.5436, 3.4251, 3.5424, 3.5479],\n",
      "        [3.6046, 3.6420, 3.5510, 3.7211, 3.6364],\n",
      "        [3.6653, 3.5498, 3.6239, 3.7265, 3.8116],\n",
      "        [3.5446, 3.4213, 3.5051, 3.5148, 3.3749],\n",
      "        [3.4375, 3.5096, 3.5052, 3.5753, 3.5197],\n",
      "        [3.4335, 3.5842, 3.5645, 3.4968, 3.6053],\n",
      "        [3.7945, 3.8520, 3.6459, 3.7318, 3.6718],\n",
      "        [3.3495, 3.3002, 3.2646, 3.5071, 3.2955],\n",
      "        [3.5756, 3.5734, 3.4823, 3.6327, 3.7113],\n",
      "        [3.3004, 3.4454, 3.4516, 3.4505, 3.4227],\n",
      "        [3.3306, 3.3155, 3.4184, 3.4732, 3.3599],\n",
      "        [3.4874, 3.5513, 3.4540, 3.5339, 3.5658],\n",
      "        [3.4640, 3.5088, 3.5360, 3.5891, 3.4685],\n",
      "        [3.6671, 3.6742, 3.7435, 3.9231, 3.9792],\n",
      "        [3.4937, 3.5363, 3.4172, 3.5377, 3.5432],\n",
      "        [3.7132, 3.5036, 3.6582, 3.8379, 3.6649],\n",
      "        [3.5710, 3.6441, 3.6322, 3.7261, 3.6989],\n",
      "        [3.5638, 3.4609, 3.5624, 3.7372, 3.4847],\n",
      "        [3.3120, 3.3060, 3.3493, 3.4271, 3.3735],\n",
      "        [3.4466, 3.3265, 3.4970, 3.5596, 3.5837],\n",
      "        [3.6414, 3.4135, 3.5004, 3.9561, 3.7085],\n",
      "        [3.4399, 3.3775, 3.4694, 3.5450, 3.4876],\n",
      "        [3.5551, 3.5044, 3.5115, 3.7499, 3.5501],\n",
      "        [3.4517, 3.4647, 3.3483, 3.5797, 3.4772],\n",
      "        [3.4559, 3.3434, 3.5157, 3.5815, 3.5907],\n",
      "        [3.5320, 3.6395, 3.5680, 3.5993, 3.6305],\n",
      "        [3.3407, 3.5592, 3.4683, 3.3716, 3.5779],\n",
      "        [3.3901, 3.4222, 3.3392, 3.4999, 3.4391],\n",
      "        [3.6706, 3.5540, 3.6527, 3.7529, 3.8283],\n",
      "        [3.3388, 3.4233, 3.3176, 3.5133, 3.3996],\n",
      "        [3.5671, 3.7086, 3.6635, 3.7316, 3.8141],\n",
      "        [3.7289, 3.3468, 3.5464, 3.9507, 3.8704],\n",
      "        [3.3455, 3.4140, 3.4151, 3.6011, 3.3771]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4510, 3.4625, 3.3556, 3.5626, 3.4920],\n",
      "        [3.4700, 3.4904, 3.3548, 3.6100, 3.4997],\n",
      "        [3.5530, 3.5945, 3.5742, 3.6388, 3.4740],\n",
      "        [3.3714, 3.6426, 3.6013, 3.5956, 3.6926],\n",
      "        [3.4508, 3.3632, 3.4775, 3.5453, 3.4879],\n",
      "        [3.4699, 3.3762, 3.5118, 3.5234, 3.4912],\n",
      "        [3.8028, 3.7715, 3.6846, 4.0637, 3.8526],\n",
      "        [3.6475, 3.5367, 3.6861, 3.7133, 3.4959],\n",
      "        [3.6020, 3.6466, 3.5213, 3.8199, 3.6698],\n",
      "        [3.6287, 3.5149, 3.6719, 3.6690, 3.4511],\n",
      "        [3.4536, 3.4705, 3.3438, 3.5851, 3.4815],\n",
      "        [3.5161, 3.7236, 3.5548, 3.7596, 3.6904],\n",
      "        [3.5081, 3.5916, 3.5266, 3.5917, 3.6071],\n",
      "        [3.3139, 3.3223, 3.3987, 3.4480, 3.3765],\n",
      "        [3.5917, 3.7057, 3.5570, 3.7149, 3.6459],\n",
      "        [3.5781, 3.6192, 3.6039, 3.7982, 3.6102],\n",
      "        [3.3593, 3.2267, 3.4566, 3.3108, 3.5020],\n",
      "        [3.5454, 3.6606, 3.6273, 3.6949, 3.5806],\n",
      "        [3.7514, 3.6432, 3.7156, 3.9101, 3.7600],\n",
      "        [3.4722, 3.5520, 3.4692, 3.5318, 3.5733],\n",
      "        [3.4881, 3.4089, 3.5868, 3.7333, 3.7296],\n",
      "        [3.3070, 3.4346, 3.4495, 3.4659, 3.4287],\n",
      "        [3.4879, 3.7336, 3.5228, 3.7718, 3.6829],\n",
      "        [3.5002, 3.7421, 3.5765, 3.7728, 3.7116],\n",
      "        [3.4539, 3.3893, 3.4846, 3.5678, 3.4995],\n",
      "        [3.5074, 3.5120, 3.4462, 3.6237, 3.6180],\n",
      "        [3.5633, 3.5663, 3.5017, 3.6879, 3.6640],\n",
      "        [3.3040, 3.3500, 3.4072, 3.4448, 3.3843],\n",
      "        [3.7666, 3.6953, 3.6648, 3.9493, 3.7924],\n",
      "        [3.4441, 3.3834, 3.4754, 3.5552, 3.4924],\n",
      "        [3.4696, 3.7289, 3.6328, 3.5887, 3.5569],\n",
      "        [3.5862, 3.5124, 3.5747, 3.6116, 3.4313],\n",
      "        [3.3823, 3.3558, 3.4469, 3.5292, 3.3965],\n",
      "        [3.4574, 3.4126, 3.5515, 3.5163, 3.6493],\n",
      "        [3.4835, 3.3771, 3.5581, 3.6286, 3.6194],\n",
      "        [3.8653, 3.5167, 3.6716, 4.1475, 4.0282],\n",
      "        [3.5347, 3.4806, 3.5954, 3.6621, 3.5653],\n",
      "        [3.4424, 3.3527, 3.4875, 3.5349, 3.4677],\n",
      "        [3.8147, 3.5994, 3.7348, 3.9700, 3.7765],\n",
      "        [3.3677, 3.3793, 3.4765, 3.5210, 3.3945],\n",
      "        [3.6020, 3.6229, 3.5389, 3.7063, 3.6288],\n",
      "        [3.3165, 3.3707, 3.3316, 3.4182, 3.3949],\n",
      "        [3.3933, 3.3477, 3.4593, 3.5415, 3.4871],\n",
      "        [3.4520, 3.5572, 3.5139, 3.5232, 3.5899],\n",
      "        [3.5697, 3.5598, 3.4851, 3.6344, 3.7155],\n",
      "        [3.2936, 3.3567, 3.3305, 3.4020, 3.3864],\n",
      "        [3.6624, 3.5778, 3.6386, 3.7834, 3.5785],\n",
      "        [3.6772, 3.6191, 3.7237, 3.8868, 3.6310],\n",
      "        [3.4555, 3.3748, 3.5454, 3.5925, 3.5256],\n",
      "        [3.4329, 3.4310, 3.3781, 3.5647, 3.4528],\n",
      "        [3.5588, 3.5687, 3.4905, 3.6826, 3.6616],\n",
      "        [3.5996, 3.6443, 3.5202, 3.8186, 3.6663],\n",
      "        [3.3403, 3.4249, 3.3190, 3.5172, 3.4015],\n",
      "        [3.6907, 3.5061, 3.6342, 3.8063, 3.6589],\n",
      "        [3.3077, 3.3371, 3.4025, 3.4436, 3.3802],\n",
      "        [3.5808, 3.4964, 3.5695, 3.6056, 3.4436],\n",
      "        [3.3138, 3.3733, 3.4302, 3.4630, 3.4083],\n",
      "        [3.5203, 3.6651, 3.5704, 3.6877, 3.7177],\n",
      "        [3.4402, 3.3301, 3.4634, 3.4928, 3.4397],\n",
      "        [3.3629, 3.2739, 3.3759, 3.4870, 3.3709],\n",
      "        [3.4133, 3.5013, 3.4934, 3.4619, 3.4426],\n",
      "        [3.4773, 3.3157, 3.4609, 3.4600, 3.4132],\n",
      "        [3.4788, 3.4399, 3.5226, 3.5613, 3.7246],\n",
      "        [3.5496, 3.5927, 3.5714, 3.6371, 3.4718]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3853, 3.4291, 3.4430, 3.4159, 3.4506],\n",
      "        [3.2453, 3.3063, 3.3043, 3.3406, 3.3431],\n",
      "        [3.4391, 3.4517, 3.4663, 3.5437, 3.5220],\n",
      "        [3.1617, 3.2337, 3.3347, 3.3399, 3.3485],\n",
      "        [3.6260, 3.6468, 3.5182, 3.6762, 3.6879],\n",
      "        [3.5177, 3.4162, 3.4975, 3.4858, 3.3515],\n",
      "        [3.4971, 3.4494, 3.5573, 3.6264, 3.6476],\n",
      "        [3.3195, 3.4636, 3.4629, 3.4834, 3.4528],\n",
      "        [3.3594, 3.4830, 3.6394, 3.5369, 3.5777],\n",
      "        [3.4640, 3.3474, 3.3811, 3.6223, 3.4125],\n",
      "        [3.5085, 3.6751, 3.6731, 3.7328, 3.7224],\n",
      "        [3.3727, 3.5199, 3.4898, 3.5676, 3.6591],\n",
      "        [3.4549, 3.4227, 3.5515, 3.5169, 3.6481],\n",
      "        [3.4674, 3.4778, 3.4854, 3.5809, 3.5495],\n",
      "        [3.2758, 3.3349, 3.3165, 3.3768, 3.3650],\n",
      "        [3.6575, 3.6746, 3.6272, 3.7404, 3.7661],\n",
      "        [3.5563, 3.4458, 3.5327, 3.6273, 3.5212],\n",
      "        [3.5387, 3.5959, 3.5669, 3.6355, 3.4693],\n",
      "        [3.6034, 3.6481, 3.5225, 3.8231, 3.6715],\n",
      "        [3.4471, 3.3938, 3.4815, 3.5656, 3.4996],\n",
      "        [3.3492, 3.3987, 3.5095, 3.5167, 3.3992],\n",
      "        [3.7680, 3.4681, 3.5673, 4.0667, 3.8374],\n",
      "        [3.3672, 3.3223, 3.2894, 3.5383, 3.3888],\n",
      "        [3.4059, 3.3858, 3.2520, 3.5902, 3.3244],\n",
      "        [3.6756, 3.6624, 3.7152, 3.7211, 3.5589],\n",
      "        [3.5479, 3.4246, 3.5422, 3.5426, 3.4733],\n",
      "        [3.6733, 3.5771, 3.6416, 3.8633, 3.8854],\n",
      "        [3.4733, 3.4002, 3.5437, 3.6103, 3.5415],\n",
      "        [3.4492, 3.4761, 3.5076, 3.5557, 3.4286],\n",
      "        [3.3326, 3.3758, 3.4635, 3.4970, 3.4096],\n",
      "        [3.2763, 3.2457, 3.3563, 3.3970, 3.2953],\n",
      "        [3.5894, 3.5257, 3.5725, 3.6248, 3.4201],\n",
      "        [3.5935, 3.5964, 3.5367, 3.5914, 3.5840],\n",
      "        [3.4369, 3.6015, 3.4562, 3.4043, 3.5804],\n",
      "        [3.4624, 3.5214, 3.5332, 3.5984, 3.4946],\n",
      "        [3.6873, 3.7224, 3.7071, 3.8394, 3.7859],\n",
      "        [3.5887, 3.7281, 3.6929, 3.7349, 3.7352],\n",
      "        [3.3164, 3.4619, 3.4670, 3.4692, 3.4374],\n",
      "        [3.7992, 3.6875, 3.6533, 3.8662, 3.7822],\n",
      "        [3.3062, 3.4731, 3.2909, 3.5177, 3.3481],\n",
      "        [3.4074, 3.4875, 3.6829, 3.5559, 3.6668],\n",
      "        [3.4341, 3.3641, 3.4937, 3.5725, 3.5547],\n",
      "        [3.2368, 3.3130, 3.3671, 3.4051, 3.3930],\n",
      "        [3.4299, 3.6213, 3.5936, 3.6479, 3.6682],\n",
      "        [3.3737, 3.4040, 3.3824, 3.4972, 3.4488],\n",
      "        [3.5887, 3.6188, 3.5270, 3.7675, 3.7782],\n",
      "        [3.4317, 3.3174, 3.4440, 3.5357, 3.5857],\n",
      "        [3.4368, 3.3181, 3.5015, 3.4397, 3.5431],\n",
      "        [3.7001, 3.7816, 3.6391, 3.8535, 3.8264],\n",
      "        [3.4448, 3.4574, 3.5074, 3.5558, 3.4124],\n",
      "        [3.2982, 3.3580, 3.3282, 3.3999, 3.3855],\n",
      "        [3.7958, 3.5209, 3.6794, 4.1873, 4.0081],\n",
      "        [3.2881, 3.4663, 3.5815, 3.4573, 3.5257],\n",
      "        [3.5191, 3.4375, 3.5945, 3.6293, 3.5802],\n",
      "        [3.5278, 3.6453, 3.5320, 3.7666, 3.6220],\n",
      "        [3.5938, 3.6543, 3.6549, 3.7524, 3.6224],\n",
      "        [3.4494, 3.3297, 3.4996, 3.5664, 3.5873],\n",
      "        [3.3378, 3.3151, 3.4072, 3.4836, 3.3910],\n",
      "        [3.6080, 3.5441, 3.5404, 3.7470, 3.7237],\n",
      "        [3.6755, 3.7296, 3.6512, 3.6329, 3.7177],\n",
      "        [3.3958, 3.3934, 3.3783, 3.4631, 3.4176],\n",
      "        [3.4442, 3.3700, 3.4681, 3.5448, 3.4866],\n",
      "        [3.5208, 3.6262, 3.5346, 3.6731, 3.7029],\n",
      "        [3.3389, 3.3945, 3.3382, 3.4491, 3.4186]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4381, 3.6029, 3.4581, 3.4070, 3.5836],\n",
      "        [3.6902, 3.5894, 3.6683, 3.8259, 3.6936],\n",
      "        [3.2670, 3.2601, 3.3179, 3.3717, 3.3366],\n",
      "        [3.6349, 3.6479, 3.5562, 3.7828, 3.7266],\n",
      "        [3.4468, 3.3561, 3.4892, 3.5474, 3.4742],\n",
      "        [3.5490, 3.4261, 3.5442, 3.5453, 3.4764],\n",
      "        [3.4925, 3.4143, 3.5607, 3.5971, 3.5623],\n",
      "        [3.3558, 3.3434, 3.3195, 3.5327, 3.3979],\n",
      "        [3.5732, 3.3647, 3.3946, 3.5112, 3.5761],\n",
      "        [3.4154, 3.4442, 3.3522, 3.5326, 3.4646],\n",
      "        [3.4662, 3.4111, 3.4964, 3.4662, 3.3390],\n",
      "        [3.4481, 3.4567, 3.5026, 3.6035, 3.4868],\n",
      "        [3.4432, 3.6708, 3.5232, 3.6896, 3.6567],\n",
      "        [3.5814, 3.5421, 3.5594, 3.7886, 3.5867],\n",
      "        [3.4832, 3.4796, 3.5069, 3.5597, 3.5480],\n",
      "        [3.4100, 3.4315, 3.4836, 3.5807, 3.4442],\n",
      "        [3.4018, 3.2703, 3.3654, 3.4914, 3.3684],\n",
      "        [3.7101, 3.6180, 3.6948, 3.8272, 3.6937],\n",
      "        [3.5992, 3.7964, 3.6755, 3.7838, 3.8147],\n",
      "        [3.8548, 3.5538, 3.7128, 4.2308, 4.0206],\n",
      "        [3.5090, 3.3700, 3.5001, 3.6002, 3.5096],\n",
      "        [3.3402, 3.2415, 3.3534, 3.4690, 3.3470],\n",
      "        [3.3526, 3.2687, 3.3743, 3.4862, 3.3725],\n",
      "        [3.5657, 3.5693, 3.5048, 3.6938, 3.6688],\n",
      "        [3.5843, 3.4790, 3.5682, 3.5900, 3.4740],\n",
      "        [3.4503, 3.3379, 3.5093, 3.5785, 3.5878],\n",
      "        [3.6808, 3.5822, 3.5185, 3.7405, 3.7322],\n",
      "        [3.7198, 3.3522, 3.5492, 3.9494, 3.8593],\n",
      "        [3.5129, 3.4303, 3.4947, 3.6345, 3.5389],\n",
      "        [3.8489, 3.8900, 3.5445, 3.7867, 3.5957],\n",
      "        [3.5584, 3.4412, 3.5506, 3.5470, 3.4849],\n",
      "        [3.6065, 3.6565, 3.5514, 3.7162, 3.6405],\n",
      "        [3.6686, 3.6308, 3.6707, 3.7698, 3.8874],\n",
      "        [3.3302, 3.4751, 3.4727, 3.4907, 3.4676],\n",
      "        [3.4069, 3.3871, 3.2540, 3.5930, 3.3275],\n",
      "        [3.4894, 3.3836, 3.5547, 3.6462, 3.5343],\n",
      "        [3.4497, 3.6736, 3.4864, 3.7253, 3.6295],\n",
      "        [3.3356, 3.3856, 3.3375, 3.4492, 3.4100],\n",
      "        [3.6797, 3.7342, 3.7363, 3.7599, 3.5374],\n",
      "        [3.6708, 3.4359, 3.5289, 3.9397, 3.7385],\n",
      "        [3.3959, 3.3631, 3.4725, 3.5664, 3.5032],\n",
      "        [3.2464, 3.3075, 3.3063, 3.3433, 3.3463],\n",
      "        [3.3913, 3.5372, 3.4948, 3.5918, 3.6321],\n",
      "        [3.6525, 3.4475, 3.5126, 3.6450, 3.6213],\n",
      "        [3.5671, 3.5151, 3.6271, 3.6404, 3.4755],\n",
      "        [3.3988, 3.4437, 3.5175, 3.5858, 3.6385],\n",
      "        [3.6809, 3.3527, 3.5525, 3.8903, 3.8143],\n",
      "        [3.5906, 3.5270, 3.5745, 3.6275, 3.4233],\n",
      "        [3.5042, 3.5571, 3.4598, 3.6668, 3.5506],\n",
      "        [3.5992, 3.6210, 3.6341, 3.7367, 3.6377],\n",
      "        [3.4536, 3.6106, 3.4411, 3.6993, 3.5756],\n",
      "        [3.6278, 3.6057, 3.6461, 3.7180, 3.8078],\n",
      "        [3.4292, 3.5077, 3.5151, 3.5836, 3.5565],\n",
      "        [3.3050, 3.4677, 3.2886, 3.5322, 3.3518],\n",
      "        [3.6706, 3.7522, 3.6383, 3.8573, 3.7604],\n",
      "        [3.6885, 3.7238, 3.7092, 3.8423, 3.7892],\n",
      "        [3.4556, 3.4691, 3.3527, 3.5892, 3.4840],\n",
      "        [3.3377, 3.2434, 3.3527, 3.4711, 3.3475],\n",
      "        [3.5685, 3.7444, 3.6724, 3.7352, 3.7465],\n",
      "        [3.5222, 3.7524, 3.5849, 3.7871, 3.7318],\n",
      "        [3.6312, 3.5178, 3.6751, 3.6750, 3.4560],\n",
      "        [3.5299, 3.4969, 3.4587, 3.6725, 3.5765],\n",
      "        [3.3097, 3.3195, 3.3976, 3.4499, 3.3761],\n",
      "        [3.9370, 4.0437, 3.6863, 3.8682, 3.7290]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5552, 3.5137, 3.5431, 3.5956, 3.3671],\n",
      "        [3.6184, 3.4688, 3.5280, 3.9049, 3.7220],\n",
      "        [3.3707, 3.3831, 3.3446, 3.5210, 3.4092],\n",
      "        [3.4398, 3.3914, 3.4841, 3.5729, 3.5039],\n",
      "        [3.5499, 3.6472, 3.6686, 3.7096, 3.5774],\n",
      "        [3.3055, 3.4255, 3.4436, 3.4587, 3.4171],\n",
      "        [3.7268, 3.5086, 3.6649, 3.8138, 3.6929],\n",
      "        [3.3567, 3.3059, 3.4096, 3.4898, 3.3727],\n",
      "        [3.2726, 3.3335, 3.3241, 3.3730, 3.3806],\n",
      "        [3.5374, 3.4486, 3.6100, 3.6611, 3.5948],\n",
      "        [3.4410, 3.3844, 3.4765, 3.5602, 3.4980],\n",
      "        [3.3280, 3.3381, 3.4117, 3.4663, 3.4059],\n",
      "        [3.4251, 3.4513, 3.3582, 3.5483, 3.4721],\n",
      "        [3.5126, 3.4151, 3.5969, 3.7333, 3.7422],\n",
      "        [3.6726, 3.7385, 3.5732, 3.6239, 3.5854],\n",
      "        [3.5955, 3.5987, 3.5403, 3.5962, 3.5910],\n",
      "        [3.2751, 3.2389, 3.3550, 3.3908, 3.3023],\n",
      "        [3.3417, 3.4069, 3.3771, 3.5442, 3.4165],\n",
      "        [3.3386, 3.2444, 3.3543, 3.4732, 3.3511],\n",
      "        [3.6134, 3.6892, 3.6470, 3.7447, 3.6449],\n",
      "        [3.4796, 3.3765, 3.5122, 3.5847, 3.5698],\n",
      "        [3.6279, 3.6876, 3.5095, 3.6583, 3.6434],\n",
      "        [3.6979, 3.6071, 3.5406, 3.7783, 3.7388],\n",
      "        [3.3786, 3.3655, 3.4814, 3.5872, 3.5071],\n",
      "        [3.3169, 3.3618, 3.3311, 3.4224, 3.3940],\n",
      "        [3.3002, 3.3602, 3.3318, 3.4048, 3.3923],\n",
      "        [3.4297, 3.3718, 3.4900, 3.5768, 3.5778],\n",
      "        [3.4697, 3.4457, 3.3996, 3.6295, 3.5112],\n",
      "        [3.5784, 3.5275, 3.5626, 3.6188, 3.3916],\n",
      "        [3.3685, 3.3633, 3.4498, 3.4271, 3.5603],\n",
      "        [3.5479, 3.3709, 3.7105, 3.6615, 3.6520],\n",
      "        [3.4732, 3.7331, 3.6377, 3.5970, 3.5658],\n",
      "        [3.6233, 3.6913, 3.6502, 3.7464, 3.6388],\n",
      "        [3.8066, 3.7756, 3.6898, 4.0722, 3.8616],\n",
      "        [3.4477, 3.6338, 3.5618, 3.6805, 3.6960],\n",
      "        [3.8087, 3.8174, 3.7630, 4.0760, 3.8929],\n",
      "        [3.4302, 3.3239, 3.4830, 3.5299, 3.4533],\n",
      "        [3.5343, 3.7451, 3.5362, 3.7998, 3.7114],\n",
      "        [3.4430, 3.5075, 3.5171, 3.5831, 3.5485],\n",
      "        [3.3639, 3.3529, 3.4528, 3.5271, 3.3859],\n",
      "        [3.6029, 3.6052, 3.5415, 3.6220, 3.5985],\n",
      "        [3.8250, 3.5136, 3.6807, 4.2101, 4.0109],\n",
      "        [3.5815, 3.6232, 3.6088, 3.8064, 3.6189],\n",
      "        [3.5826, 3.6058, 3.5164, 3.6552, 3.6122],\n",
      "        [3.3172, 3.3377, 3.4107, 3.4578, 3.3902],\n",
      "        [3.4819, 3.5159, 3.3457, 3.5311, 3.5104],\n",
      "        [3.8629, 3.9542, 3.6195, 3.7809, 3.6519],\n",
      "        [3.3282, 3.3119, 3.3973, 3.4621, 3.3873],\n",
      "        [3.3458, 3.2422, 3.3603, 3.4799, 3.3503],\n",
      "        [3.4923, 3.5570, 3.4602, 3.5458, 3.5765],\n",
      "        [3.4790, 3.6364, 3.5900, 3.7088, 3.7282],\n",
      "        [3.5372, 3.6450, 3.5743, 3.6114, 3.6414],\n",
      "        [3.8460, 3.9001, 3.7040, 3.7847, 3.7436],\n",
      "        [3.4181, 3.4558, 3.3597, 3.5473, 3.4690],\n",
      "        [3.6533, 3.7360, 3.6233, 3.8465, 3.7442],\n",
      "        [3.6567, 3.6247, 3.6603, 3.7463, 3.8290],\n",
      "        [3.4445, 3.3886, 3.5112, 3.5780, 3.5274],\n",
      "        [3.6125, 3.6385, 3.6462, 3.6771, 3.5015],\n",
      "        [3.5490, 3.6647, 3.6322, 3.7032, 3.5894],\n",
      "        [3.5596, 3.4196, 3.5465, 3.5416, 3.5173],\n",
      "        [3.5103, 3.2672, 3.6004, 3.6417, 3.5992],\n",
      "        [3.5083, 3.6052, 3.4634, 3.6365, 3.5744],\n",
      "        [3.6245, 3.5443, 3.6593, 3.6758, 3.5138],\n",
      "        [3.4579, 3.5486, 3.4987, 3.5368, 3.5878]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2747, 3.3473, 3.3690, 3.4545, 3.4172],\n",
      "        [3.8017, 3.8448, 3.5518, 3.7525, 3.6403],\n",
      "        [3.2368, 3.2954, 3.3015, 3.3410, 3.3455],\n",
      "        [3.3472, 3.2605, 3.3676, 3.4836, 3.3641],\n",
      "        [3.6572, 3.7952, 3.6755, 3.8977, 3.8289],\n",
      "        [3.4645, 3.6090, 3.5250, 3.5802, 3.4328],\n",
      "        [3.4327, 3.6263, 3.6001, 3.6548, 3.6787],\n",
      "        [3.5740, 3.5867, 3.6503, 3.6796, 3.6309],\n",
      "        [3.6408, 3.5729, 3.6040, 3.7121, 3.7577],\n",
      "        [3.6296, 3.5261, 3.6010, 3.7052, 3.8014],\n",
      "        [3.5007, 3.5669, 3.4893, 3.6727, 3.5382],\n",
      "        [3.3890, 3.3861, 3.2660, 3.5795, 3.3468],\n",
      "        [3.4577, 3.4275, 3.5577, 3.5237, 3.6586],\n",
      "        [3.6763, 3.4268, 3.5349, 3.9623, 3.7502],\n",
      "        [3.3183, 3.4544, 3.4606, 3.4827, 3.4496],\n",
      "        [3.4028, 3.5590, 3.5143, 3.5963, 3.6775],\n",
      "        [3.3965, 3.6486, 3.5304, 3.6371, 3.6752],\n",
      "        [4.0210, 4.1257, 3.7579, 3.9381, 3.8081],\n",
      "        [3.7573, 3.6205, 3.6713, 3.9193, 3.7753],\n",
      "        [3.4645, 3.7070, 3.6550, 3.6567, 3.5668],\n",
      "        [3.7216, 3.3556, 3.5534, 3.9532, 3.8661],\n",
      "        [3.5677, 3.7089, 3.6640, 3.7331, 3.8218],\n",
      "        [3.4839, 3.5063, 3.3702, 3.6325, 3.5180],\n",
      "        [3.7045, 3.5148, 3.6638, 3.8567, 3.6709],\n",
      "        [3.6599, 3.6724, 3.7014, 3.7232, 3.5374],\n",
      "        [3.3818, 3.3709, 3.4316, 3.4651, 3.4401],\n",
      "        [3.8075, 3.7781, 3.6924, 4.0741, 3.8651],\n",
      "        [3.6732, 3.6829, 3.7527, 3.9370, 3.9936],\n",
      "        [3.7458, 3.5967, 3.6545, 3.8085, 3.7428],\n",
      "        [3.3352, 3.3820, 3.4594, 3.5064, 3.4098],\n",
      "        [3.6170, 3.6677, 3.5691, 3.7145, 3.6598],\n",
      "        [3.6029, 3.4611, 3.5025, 3.8653, 3.6916],\n",
      "        [4.0762, 4.1524, 3.8270, 3.9798, 3.8256],\n",
      "        [3.4181, 3.4459, 3.3509, 3.5488, 3.4625],\n",
      "        [3.6940, 3.7780, 3.6294, 3.8503, 3.8216],\n",
      "        [3.7500, 3.6895, 3.6360, 3.8464, 3.8456],\n",
      "        [3.5843, 3.6117, 3.6159, 3.8087, 3.6095],\n",
      "        [3.4142, 3.4222, 3.5944, 3.5751, 3.5929],\n",
      "        [3.4348, 3.4477, 3.6531, 3.5933, 3.6394],\n",
      "        [3.4516, 3.5727, 3.5402, 3.5256, 3.6099],\n",
      "        [3.5480, 3.5262, 3.4954, 3.6196, 3.5464],\n",
      "        [3.6541, 3.5642, 3.6351, 3.8280, 3.6520],\n",
      "        [3.5161, 3.3706, 3.5073, 3.5935, 3.5078],\n",
      "        [3.8251, 3.7956, 3.7638, 4.0552, 3.8400],\n",
      "        [3.3080, 3.4791, 3.2941, 3.5265, 3.3590],\n",
      "        [3.4918, 3.4143, 3.5746, 3.6345, 3.5783],\n",
      "        [3.6062, 3.6528, 3.5288, 3.8300, 3.6823],\n",
      "        [3.5832, 3.5454, 3.5637, 3.7927, 3.5939],\n",
      "        [3.6604, 3.5956, 3.5986, 3.7154, 3.7061],\n",
      "        [3.5506, 3.4288, 3.5134, 3.5284, 3.3885],\n",
      "        [3.6965, 3.6424, 3.6787, 3.7938, 3.9215],\n",
      "        [3.5874, 3.6272, 3.6342, 3.7355, 3.6654],\n",
      "        [3.4340, 3.3474, 3.4881, 3.5460, 3.4743],\n",
      "        [3.6980, 3.5236, 3.5512, 3.7043, 3.7011],\n",
      "        [3.3256, 3.4665, 3.5905, 3.4807, 3.5153],\n",
      "        [3.5923, 3.5303, 3.5786, 3.6315, 3.4304],\n",
      "        [3.4763, 3.5583, 3.4766, 3.5418, 3.5854],\n",
      "        [3.5628, 3.6145, 3.4930, 3.7849, 3.6284],\n",
      "        [3.5335, 3.6476, 3.5384, 3.7749, 3.6326],\n",
      "        [3.3844, 3.4169, 3.3464, 3.4963, 3.4541],\n",
      "        [3.4624, 3.3812, 3.4971, 3.5609, 3.5093],\n",
      "        [3.6252, 3.6522, 3.5164, 3.6829, 3.6871],\n",
      "        [3.3045, 3.4248, 3.4480, 3.4622, 3.4204],\n",
      "        [3.6584, 3.8294, 3.6229, 3.8938, 3.8244]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8919, 3.9622, 3.6706, 3.8226, 3.6689],\n",
      "        [3.3161, 3.2475, 3.3663, 3.4606, 3.3849],\n",
      "        [3.6116, 3.5511, 3.5490, 3.7554, 3.7375],\n",
      "        [3.4709, 3.4843, 3.4936, 3.5892, 3.5629],\n",
      "        [3.6612, 3.7477, 3.6245, 3.8430, 3.7615],\n",
      "        [3.9394, 4.0499, 3.6930, 3.8738, 3.7393],\n",
      "        [3.4775, 3.7150, 3.6646, 3.6601, 3.5807],\n",
      "        [3.4620, 3.3891, 3.5430, 3.6001, 3.5389],\n",
      "        [3.3230, 3.4699, 3.4713, 3.4920, 3.4659],\n",
      "        [3.3171, 3.3693, 3.3430, 3.4293, 3.4251],\n",
      "        [3.6095, 3.6170, 3.6448, 3.7487, 3.6213],\n",
      "        [3.4508, 3.3700, 3.5406, 3.5951, 3.5325],\n",
      "        [3.3682, 3.4104, 3.3540, 3.4740, 3.4384],\n",
      "        [3.4664, 3.5325, 3.4146, 3.7143, 3.4607],\n",
      "        [3.2060, 3.2757, 3.3743, 3.3703, 3.3933],\n",
      "        [3.6364, 3.4335, 3.5103, 3.6252, 3.6077],\n",
      "        [3.6513, 3.7105, 3.5144, 3.6715, 3.6502],\n",
      "        [3.4237, 3.3072, 3.5074, 3.4157, 3.5540],\n",
      "        [3.6186, 3.6624, 3.5248, 3.6838, 3.6887],\n",
      "        [3.5691, 3.3177, 3.4004, 3.5444, 3.5313],\n",
      "        [3.3369, 3.3248, 3.4291, 3.4885, 3.3763],\n",
      "        [3.6610, 3.6817, 3.6356, 3.7484, 3.7795],\n",
      "        [3.4937, 3.5615, 3.4650, 3.5490, 3.5827],\n",
      "        [3.4376, 3.3272, 3.5095, 3.4462, 3.5558],\n",
      "        [3.6134, 3.5826, 3.6414, 3.7507, 3.5575],\n",
      "        [3.6581, 3.6937, 3.7179, 3.7210, 3.4846],\n",
      "        [3.3083, 3.2845, 3.3772, 3.4339, 3.3432],\n",
      "        [3.6357, 3.4274, 3.5061, 3.9320, 3.7077],\n",
      "        [3.4594, 3.5530, 3.5035, 3.5401, 3.5940],\n",
      "        [3.5634, 3.4623, 3.5676, 3.5794, 3.4742],\n",
      "        [3.6152, 3.7018, 3.5827, 3.7229, 3.6678],\n",
      "        [3.4386, 3.4653, 3.5026, 3.6682, 3.5036],\n",
      "        [3.4645, 3.4248, 3.5120, 3.6010, 3.5397],\n",
      "        [3.6069, 3.6549, 3.5310, 3.8314, 3.6852],\n",
      "        [3.7425, 3.7507, 3.7052, 3.8368, 3.8553],\n",
      "        [3.6069, 3.6549, 3.5310, 3.8314, 3.6852],\n",
      "        [3.4606, 3.6865, 3.5548, 3.7158, 3.7074],\n",
      "        [3.3604, 3.2949, 3.3945, 3.4872, 3.3929],\n",
      "        [3.6602, 3.7082, 3.6450, 3.8089, 3.8981],\n",
      "        [3.6968, 3.6193, 3.7987, 3.7119, 3.5516],\n",
      "        [3.3641, 3.5090, 3.4971, 3.5632, 3.6558],\n",
      "        [3.3264, 3.3363, 3.4170, 3.4651, 3.3986],\n",
      "        [3.4536, 3.3922, 3.3731, 3.5372, 3.5787],\n",
      "        [3.7314, 3.3544, 3.5693, 3.9531, 3.8658],\n",
      "        [3.8226, 3.8187, 3.7753, 4.0727, 3.8818],\n",
      "        [3.7170, 3.3668, 3.5657, 3.9313, 3.8627],\n",
      "        [3.4871, 3.5759, 3.5078, 3.5993, 3.6073],\n",
      "        [3.4377, 3.4388, 3.3877, 3.5765, 3.4675],\n",
      "        [3.2785, 3.3487, 3.3343, 3.3907, 3.3862],\n",
      "        [3.4555, 3.3714, 3.4868, 3.5562, 3.5021],\n",
      "        [3.6815, 3.6236, 3.7339, 3.8963, 3.6421],\n",
      "        [3.2822, 3.3473, 3.3309, 3.3963, 3.3901],\n",
      "        [3.4381, 3.6758, 3.5582, 3.6836, 3.7102],\n",
      "        [3.5813, 3.4891, 3.5765, 3.6028, 3.4599],\n",
      "        [3.5610, 3.4240, 3.5511, 3.5447, 3.5234],\n",
      "        [3.7541, 3.5809, 3.7128, 3.9228, 3.7373],\n",
      "        [3.8024, 3.8470, 3.5540, 3.7539, 3.6432],\n",
      "        [3.4470, 3.5110, 3.4460, 3.6083, 3.5850],\n",
      "        [3.4470, 3.3609, 3.4967, 3.5458, 3.4819],\n",
      "        [3.5944, 3.6204, 3.5344, 3.6957, 3.6067],\n",
      "        [3.6019, 3.6527, 3.5018, 3.6687, 3.6633],\n",
      "        [3.7500, 3.5155, 3.6844, 3.8482, 3.7203],\n",
      "        [3.3879, 3.4224, 3.3491, 3.5113, 3.4484],\n",
      "        [3.4845, 3.5082, 3.3723, 3.6338, 3.5208]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8592, 3.5614, 3.7215, 4.2373, 4.0330],\n",
      "        [3.4940, 3.4183, 3.5786, 3.6370, 3.5836],\n",
      "        [3.4333, 3.5149, 3.5235, 3.5902, 3.5691],\n",
      "        [3.7493, 3.6626, 3.6804, 3.9341, 3.7362],\n",
      "        [3.5793, 3.4778, 3.4762, 3.7805, 3.6423],\n",
      "        [3.6729, 3.6385, 3.6793, 3.7764, 3.9003],\n",
      "        [3.6669, 3.6335, 3.6454, 3.7518, 3.8526],\n",
      "        [3.4225, 3.3796, 3.4523, 3.5774, 3.4431],\n",
      "        [3.3068, 3.4284, 3.4520, 3.4649, 3.4257],\n",
      "        [3.5244, 3.4572, 3.5034, 3.6703, 3.5540],\n",
      "        [3.3083, 3.4564, 3.4644, 3.4674, 3.4418],\n",
      "        [3.2808, 3.3426, 3.3264, 3.3862, 3.3801],\n",
      "        [3.4627, 3.5191, 3.5452, 3.6001, 3.4829],\n",
      "        [3.4590, 3.3932, 3.4952, 3.5589, 3.5663],\n",
      "        [3.4262, 3.3838, 3.6005, 3.4305, 3.6604],\n",
      "        [3.3855, 3.6283, 3.5934, 3.6264, 3.6912],\n",
      "        [3.6198, 3.6710, 3.6350, 3.7544, 3.6528],\n",
      "        [3.4432, 3.4594, 3.3619, 3.5553, 3.4977],\n",
      "        [3.6972, 3.7364, 3.7667, 3.7919, 3.5663],\n",
      "        [3.5261, 3.6348, 3.5450, 3.6826, 3.7184],\n",
      "        [3.8531, 3.8978, 3.5529, 3.7932, 3.6082],\n",
      "        [3.4567, 3.4209, 3.4132, 3.5821, 3.4757],\n",
      "        [3.5934, 3.3828, 3.4233, 3.5345, 3.6053],\n",
      "        [3.5872, 3.5064, 3.5809, 3.6180, 3.4608],\n",
      "        [3.2916, 3.2706, 3.3372, 3.4026, 3.3617],\n",
      "        [3.4993, 3.4236, 3.4986, 3.6056, 3.5502],\n",
      "        [3.4541, 3.3896, 3.4849, 3.5577, 3.5058],\n",
      "        [3.2813, 3.2534, 3.3662, 3.4064, 3.3104],\n",
      "        [3.2889, 3.3086, 3.2655, 3.4719, 3.3183],\n",
      "        [3.5140, 3.5221, 3.4576, 3.6359, 3.6351],\n",
      "        [3.6813, 3.6708, 3.7255, 3.7307, 3.5747],\n",
      "        [3.3403, 3.3916, 3.3446, 3.4507, 3.4196],\n",
      "        [3.5082, 3.5420, 3.3933, 3.5611, 3.5458],\n",
      "        [3.6085, 3.6331, 3.5506, 3.7188, 3.6462],\n",
      "        [3.6075, 3.5994, 3.6891, 3.6757, 3.5245],\n",
      "        [3.4946, 3.4191, 3.5983, 3.7456, 3.7464],\n",
      "        [3.6804, 3.6077, 3.6081, 3.7426, 3.7151],\n",
      "        [3.4712, 3.4297, 3.5106, 3.6050, 3.5488],\n",
      "        [3.4717, 3.4922, 3.3642, 3.6272, 3.5118],\n",
      "        [3.5650, 3.4641, 3.5695, 3.5805, 3.4767],\n",
      "        [3.5156, 3.5911, 3.5191, 3.6915, 3.5443],\n",
      "        [3.4670, 3.4267, 3.5141, 3.5936, 3.5471],\n",
      "        [3.3215, 3.2557, 3.3725, 3.4704, 3.3863],\n",
      "        [3.4502, 3.3875, 3.4849, 3.5683, 3.5150],\n",
      "        [3.7034, 3.6054, 3.6681, 3.8986, 3.9120],\n",
      "        [3.5388, 3.4746, 3.4654, 3.6964, 3.5814],\n",
      "        [3.4503, 3.4573, 3.5205, 3.6133, 3.4850],\n",
      "        [3.4819, 3.5677, 3.4879, 3.5986, 3.6073],\n",
      "        [3.2982, 3.3695, 3.3555, 3.4081, 3.4136],\n",
      "        [3.4739, 3.3961, 3.5372, 3.5797, 3.5566],\n",
      "        [3.5412, 3.4907, 3.6068, 3.6746, 3.5827],\n",
      "        [3.5619, 3.5432, 3.6311, 3.6251, 3.4983],\n",
      "        [3.5265, 3.6550, 3.4588, 3.6420, 3.5709],\n",
      "        [3.5446, 3.5119, 3.6029, 3.6644, 3.5702],\n",
      "        [3.5510, 3.5233, 3.5850, 3.6365, 3.6051],\n",
      "        [3.4122, 3.4289, 3.4865, 3.5832, 3.4460],\n",
      "        [3.8277, 3.7998, 3.7682, 4.0579, 3.8457],\n",
      "        [3.4596, 3.4384, 3.5053, 3.5648, 3.6933],\n",
      "        [3.5138, 3.6845, 3.6845, 3.7424, 3.7386],\n",
      "        [3.4859, 3.6242, 3.6022, 3.6986, 3.7349],\n",
      "        [3.5854, 3.5492, 3.5678, 3.7953, 3.5993],\n",
      "        [3.8128, 3.9384, 3.5562, 3.7335, 3.6429],\n",
      "        [3.6896, 3.3717, 3.5697, 3.8985, 3.8366],\n",
      "        [3.4188, 3.3661, 3.4775, 3.5397, 3.5067]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4599, 3.5690, 3.5272, 3.5366, 3.6094],\n",
      "        [3.4756, 3.5786, 3.4952, 3.7164, 3.5280],\n",
      "        [3.4486, 3.3734, 3.4917, 3.5605, 3.5048],\n",
      "        [3.5611, 3.6062, 3.5873, 3.6522, 3.4936],\n",
      "        [3.5634, 3.5447, 3.6327, 3.6260, 3.5003],\n",
      "        [3.5998, 3.5415, 3.5439, 3.7491, 3.7324],\n",
      "        [3.5142, 3.3710, 3.5038, 3.5963, 3.4868],\n",
      "        [3.5258, 3.4587, 3.5049, 3.6711, 3.5561],\n",
      "        [3.6876, 3.6434, 3.6693, 3.7788, 3.8850],\n",
      "        [3.4493, 3.5216, 3.4153, 3.6858, 3.4576],\n",
      "        [3.5902, 3.3360, 3.4154, 3.5406, 3.5681],\n",
      "        [3.4520, 3.3647, 3.4987, 3.5544, 3.4881],\n",
      "        [3.7692, 3.6563, 3.6445, 3.8499, 3.7960],\n",
      "        [3.2775, 3.3434, 3.3298, 3.3847, 3.3829],\n",
      "        [3.7155, 3.5335, 3.6889, 3.8813, 3.6979],\n",
      "        [3.4384, 3.4532, 3.6590, 3.5968, 3.6466],\n",
      "        [3.6438, 3.6158, 3.6920, 3.8636, 3.6256],\n",
      "        [3.4090, 3.2973, 3.4074, 3.4937, 3.5756],\n",
      "        [3.4077, 3.3052, 3.4650, 3.5086, 3.4386],\n",
      "        [3.3803, 3.4072, 3.3461, 3.4881, 3.4356],\n",
      "        [3.5861, 3.6313, 3.6172, 3.8115, 3.6298],\n",
      "        [3.6960, 3.5984, 3.6784, 3.8334, 3.7090],\n",
      "        [3.5944, 3.4711, 3.5318, 3.5417, 3.4460],\n",
      "        [3.6822, 3.7401, 3.6633, 3.6431, 3.7360],\n",
      "        [3.5644, 3.5176, 3.5258, 3.7671, 3.5715],\n",
      "        [3.5784, 3.4790, 3.4846, 3.7836, 3.6443],\n",
      "        [3.4246, 3.5433, 3.5753, 3.5866, 3.5703],\n",
      "        [3.6576, 3.4563, 3.5223, 3.6524, 3.6360],\n",
      "        [3.6016, 3.6988, 3.6656, 3.7642, 3.7817],\n",
      "        [3.5652, 3.4279, 3.5615, 3.5388, 3.5396],\n",
      "        [3.6820, 3.6795, 3.5832, 3.7565, 3.7940],\n",
      "        [3.5713, 3.6257, 3.5121, 3.6431, 3.6165],\n",
      "        [3.4651, 3.4245, 3.5646, 3.5297, 3.6690],\n",
      "        [3.3766, 3.4411, 3.5596, 3.5528, 3.5778],\n",
      "        [3.3183, 3.2891, 3.3874, 3.4417, 3.3734],\n",
      "        [3.5130, 3.3740, 3.5021, 3.5924, 3.5082],\n",
      "        [3.6228, 3.4227, 3.5193, 3.6173, 3.5811],\n",
      "        [3.4633, 3.3869, 3.4981, 3.5627, 3.5163],\n",
      "        [3.6891, 3.5985, 3.6605, 3.8843, 3.9060],\n",
      "        [3.4339, 3.3795, 3.4980, 3.5818, 3.5882],\n",
      "        [3.2995, 3.3558, 3.3404, 3.4081, 3.4139],\n",
      "        [3.4515, 3.3890, 3.4864, 3.5691, 3.5170],\n",
      "        [3.6683, 3.6578, 3.6864, 3.7779, 3.8547],\n",
      "        [3.6901, 3.4793, 3.5362, 3.6707, 3.6581],\n",
      "        [3.4302, 3.3200, 3.4402, 3.5315, 3.5933],\n",
      "        [3.5279, 3.6565, 3.4604, 3.6429, 3.5730],\n",
      "        [3.5516, 3.3894, 3.7440, 3.6730, 3.6721],\n",
      "        [3.4446, 3.4899, 3.4623, 3.6284, 3.5732],\n",
      "        [3.5172, 3.5916, 3.6410, 3.7236, 3.6215],\n",
      "        [3.7984, 3.6586, 3.6576, 3.8564, 3.7895],\n",
      "        [3.6180, 3.6695, 3.5208, 3.6827, 3.6789],\n",
      "        [3.4473, 3.5869, 3.5616, 3.5199, 3.6199],\n",
      "        [3.4553, 3.5782, 3.5461, 3.5290, 3.6173],\n",
      "        [3.2289, 3.2913, 3.3023, 3.3244, 3.3298],\n",
      "        [3.6919, 3.7497, 3.7528, 3.7732, 3.5672],\n",
      "        [3.3398, 3.3279, 3.4325, 3.4906, 3.3807],\n",
      "        [3.4033, 3.4751, 3.4387, 3.6180, 3.4694],\n",
      "        [3.4848, 3.3272, 3.4735, 3.4728, 3.4319],\n",
      "        [3.6846, 3.6272, 3.7375, 3.8982, 3.6468],\n",
      "        [3.3840, 3.4202, 3.3591, 3.4875, 3.4679],\n",
      "        [3.4625, 3.3969, 3.3742, 3.5486, 3.5957],\n",
      "        [3.6781, 3.6593, 3.7102, 3.7725, 3.9085],\n",
      "        [3.3348, 3.4008, 3.4761, 3.4979, 3.4373],\n",
      "        [3.3540, 3.2788, 3.3816, 3.4887, 3.3794]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6148, 3.6620, 3.6282, 3.7568, 3.6528],\n",
      "        [3.4606, 3.3430, 3.5217, 3.5821, 3.6068],\n",
      "        [3.4728, 3.4877, 3.3598, 3.6054, 3.4999],\n",
      "        [3.5808, 3.4804, 3.4860, 3.7841, 3.6468],\n",
      "        [3.5967, 3.4725, 3.5332, 3.5422, 3.4486],\n",
      "        [3.3621, 3.3114, 3.2841, 3.5231, 3.3303],\n",
      "        [3.7085, 3.7960, 3.6534, 3.8640, 3.8523],\n",
      "        [3.6511, 3.7881, 3.6662, 3.8949, 3.8245],\n",
      "        [3.4495, 3.3861, 3.4805, 3.5568, 3.5068],\n",
      "        [3.5919, 3.4892, 3.5794, 3.5977, 3.4910],\n",
      "        [3.6254, 3.4781, 3.5377, 3.9106, 3.7352],\n",
      "        [3.5900, 3.6360, 3.6426, 3.7444, 3.6749],\n",
      "        [3.4798, 3.3893, 3.5261, 3.5369, 3.5129],\n",
      "        [3.3416, 3.3319, 3.4156, 3.4747, 3.4164],\n",
      "        [3.4669, 3.4795, 3.3576, 3.5961, 3.4955],\n",
      "        [3.4823, 3.5653, 3.4839, 3.5458, 3.5955],\n",
      "        [3.6523, 3.8143, 3.6568, 3.7341, 3.9619],\n",
      "        [3.5707, 3.3322, 3.6529, 3.6608, 3.5953],\n",
      "        [3.4354, 3.4529, 3.4802, 3.6181, 3.5686],\n",
      "        [3.4776, 3.3991, 3.5401, 3.5811, 3.5612],\n",
      "        [3.5810, 3.3694, 3.4091, 3.5270, 3.5878],\n",
      "        [3.3552, 3.2786, 3.3829, 3.4908, 3.3812],\n",
      "        [3.7251, 3.6733, 3.6222, 3.8237, 3.8277],\n",
      "        [3.6017, 3.6045, 3.5085, 3.6740, 3.7255],\n",
      "        [3.5617, 3.4511, 3.5363, 3.4937, 3.4032],\n",
      "        [3.4556, 3.3806, 3.4896, 3.5569, 3.5084],\n",
      "        [3.3939, 3.4403, 3.4562, 3.4265, 3.4705],\n",
      "        [3.3195, 3.3977, 3.4423, 3.4761, 3.4318],\n",
      "        [3.6064, 3.6521, 3.6625, 3.6674, 3.5364],\n",
      "        [3.4884, 3.5252, 3.3554, 3.5367, 3.5236],\n",
      "        [3.4095, 3.4426, 3.3550, 3.5351, 3.4629],\n",
      "        [3.7471, 3.7053, 3.6432, 3.8245, 3.8426],\n",
      "        [3.9821, 4.1154, 3.7140, 3.9088, 3.7966],\n",
      "        [3.5284, 3.4431, 3.6004, 3.6505, 3.5947],\n",
      "        [3.6040, 3.7003, 3.6671, 3.7647, 3.7844],\n",
      "        [3.5751, 3.4762, 3.5781, 3.7544, 3.5088],\n",
      "        [3.2662, 3.3295, 3.3276, 3.3639, 3.3713],\n",
      "        [3.5801, 3.5938, 3.5318, 3.5632, 3.5880],\n",
      "        [3.5402, 3.4859, 3.5248, 3.6261, 3.5407],\n",
      "        [3.6971, 3.7342, 3.7209, 3.8507, 3.8069],\n",
      "        [3.3600, 3.3903, 3.4973, 3.5269, 3.4060],\n",
      "        [3.9196, 3.5759, 3.7835, 4.2967, 4.1196],\n",
      "        [3.5736, 3.5360, 3.5381, 3.7859, 3.5807],\n",
      "        [3.9108, 3.9696, 3.7514, 3.8496, 3.7800],\n",
      "        [3.6296, 3.4363, 3.5313, 3.6239, 3.5908],\n",
      "        [3.6122, 3.6360, 3.5536, 3.7203, 3.6508],\n",
      "        [3.4453, 3.5991, 3.5809, 3.5147, 3.6296],\n",
      "        [3.3237, 3.3462, 3.4200, 3.4636, 3.4030],\n",
      "        [3.4295, 3.4538, 3.3620, 3.5587, 3.4858],\n",
      "        [3.4633, 3.4765, 3.5227, 3.5708, 3.4324],\n",
      "        [3.4470, 3.3712, 3.4830, 3.5500, 3.4991],\n",
      "        [3.4596, 3.4778, 3.3703, 3.5968, 3.5073],\n",
      "        [3.7553, 3.6350, 3.7181, 3.8185, 3.9156],\n",
      "        [3.5308, 3.4745, 3.4907, 3.6770, 3.6736],\n",
      "        [3.4570, 3.3511, 3.4874, 3.5045, 3.4699],\n",
      "        [3.6116, 3.4887, 3.5416, 3.5619, 3.4681],\n",
      "        [3.2574, 3.4029, 3.2368, 3.4701, 3.3077],\n",
      "        [3.5747, 3.5497, 3.4695, 3.7075, 3.6467],\n",
      "        [3.4403, 3.6001, 3.5932, 3.5035, 3.6281],\n",
      "        [3.5337, 3.4516, 3.6161, 3.6537, 3.6018],\n",
      "        [3.3502, 3.4372, 3.3337, 3.5322, 3.4228],\n",
      "        [3.4100, 3.3066, 3.4663, 3.5091, 3.4410],\n",
      "        [3.5302, 3.5486, 3.5912, 3.7202, 3.6520],\n",
      "        [3.5563, 3.6741, 3.6420, 3.7089, 3.6034]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7468, 3.6899, 3.6571, 3.9407, 3.7858],\n",
      "        [3.4371, 3.5181, 3.5268, 3.5824, 3.5909],\n",
      "        [3.4781, 3.4900, 3.4997, 3.5922, 3.5722],\n",
      "        [4.0857, 4.1620, 3.8360, 3.9842, 3.8387],\n",
      "        [3.4918, 3.3952, 3.5131, 3.5998, 3.5778],\n",
      "        [3.3533, 3.3687, 3.4620, 3.5072, 3.4153],\n",
      "        [3.3684, 3.4348, 3.3923, 3.5797, 3.4320],\n",
      "        [3.4691, 3.4183, 3.5085, 3.5903, 3.5443],\n",
      "        [3.3970, 3.4325, 3.3541, 3.5118, 3.4592],\n",
      "        [3.3483, 3.3579, 3.4287, 3.4759, 3.4340],\n",
      "        [3.6444, 3.7968, 3.7314, 3.8002, 3.8150],\n",
      "        [3.5983, 3.3870, 3.4274, 3.5361, 3.6120],\n",
      "        [3.5221, 3.4416, 3.5998, 3.6532, 3.5999],\n",
      "        [3.3138, 3.2850, 3.3882, 3.4378, 3.3577],\n",
      "        [3.3198, 3.4077, 3.5967, 3.4587, 3.5840],\n",
      "        [3.3194, 3.3505, 3.4178, 3.4578, 3.4036],\n",
      "        [3.8277, 3.6143, 3.7511, 3.9847, 3.8021],\n",
      "        [3.3903, 3.4339, 3.3672, 3.5050, 3.4636],\n",
      "        [3.3135, 3.4199, 3.4462, 3.4632, 3.4239],\n",
      "        [3.2971, 3.2744, 3.3412, 3.4044, 3.3682],\n",
      "        [3.4145, 3.2915, 3.4598, 3.5344, 3.5135],\n",
      "        [3.7491, 3.7066, 3.6445, 3.8248, 3.8449],\n",
      "        [3.4773, 3.6294, 3.4658, 3.4322, 3.5697],\n",
      "        [3.5193, 3.6224, 3.5384, 3.6707, 3.7098],\n",
      "        [3.8558, 3.9119, 3.7155, 3.7909, 3.7597],\n",
      "        [3.3124, 3.4505, 3.4581, 3.4668, 3.4383],\n",
      "        [3.4206, 3.6296, 3.5880, 3.6487, 3.6641],\n",
      "        [3.5114, 3.5501, 3.4164, 3.5658, 3.5656],\n",
      "        [3.3320, 3.3410, 3.4178, 3.4648, 3.4057],\n",
      "        [3.5634, 3.4935, 3.6422, 3.7100, 3.5751],\n",
      "        [3.3907, 3.3172, 3.4187, 3.5143, 3.4004],\n",
      "        [3.6091, 3.6328, 3.6469, 3.7450, 3.6573],\n",
      "        [3.4394, 3.4773, 3.3685, 3.5702, 3.4969],\n",
      "        [3.2566, 3.3638, 3.5477, 3.4052, 3.5107],\n",
      "        [3.3146, 3.3846, 3.4324, 3.4590, 3.4115],\n",
      "        [3.4160, 3.5961, 3.4887, 3.5228, 3.4217],\n",
      "        [3.5088, 3.5487, 3.4204, 3.5564, 3.5613],\n",
      "        [3.6045, 3.7389, 3.5778, 3.7333, 3.6655],\n",
      "        [3.7459, 3.7884, 3.5373, 3.7053, 3.6488],\n",
      "        [3.4222, 3.4434, 3.3552, 3.5332, 3.4809],\n",
      "        [3.4543, 3.4722, 3.3664, 3.5785, 3.5022],\n",
      "        [3.7215, 3.5594, 3.5799, 3.7288, 3.7294],\n",
      "        [3.4842, 3.5666, 3.4852, 3.5460, 3.5976],\n",
      "        [3.6157, 3.6187, 3.5471, 3.6401, 3.6228],\n",
      "        [3.8093, 3.5399, 3.7024, 4.2020, 4.0386],\n",
      "        [3.6599, 3.5556, 3.7162, 3.7167, 3.4797],\n",
      "        [3.6866, 3.7272, 3.7583, 3.7967, 3.6040],\n",
      "        [3.4577, 3.4793, 3.3631, 3.5994, 3.5029],\n",
      "        [3.3967, 3.6147, 3.5575, 3.6146, 3.6807],\n",
      "        [3.5925, 3.5950, 3.5233, 3.7244, 3.6325],\n",
      "        [3.4601, 3.3869, 3.4865, 3.5681, 3.5135],\n",
      "        [3.4531, 3.3933, 3.4860, 3.5622, 3.5129],\n",
      "        [3.7171, 3.6053, 3.5849, 3.7574, 3.6985],\n",
      "        [3.4077, 3.3715, 3.4555, 3.5570, 3.4302],\n",
      "        [3.4928, 3.4910, 3.5196, 3.5680, 3.5671],\n",
      "        [3.6049, 3.4813, 3.5328, 3.5481, 3.4621],\n",
      "        [3.6742, 3.6291, 3.7232, 3.8828, 3.6447],\n",
      "        [3.6379, 3.6180, 3.6591, 3.7264, 3.8278],\n",
      "        [3.6493, 3.7037, 3.5068, 3.6527, 3.6453],\n",
      "        [3.2748, 3.3295, 3.2323, 3.4711, 3.3290],\n",
      "        [3.5352, 3.4186, 3.6022, 3.6828, 3.5962],\n",
      "        [3.3434, 3.3876, 3.4779, 3.5086, 3.4317],\n",
      "        [3.4182, 3.5006, 3.6978, 3.5670, 3.6888],\n",
      "        [3.5830, 3.6082, 3.6123, 3.6804, 3.5138]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5779, 3.7761, 3.6886, 3.7640, 3.8312],\n",
      "        [3.4974, 3.3872, 3.5480, 3.5965, 3.5219],\n",
      "        [3.5630, 3.6765, 3.6443, 3.7108, 3.6079],\n",
      "        [3.5605, 3.5354, 3.5049, 3.6255, 3.5601],\n",
      "        [3.6260, 3.7066, 3.5656, 3.5658, 3.5716],\n",
      "        [3.7139, 3.5163, 3.6663, 3.8610, 3.6813],\n",
      "        [3.5124, 3.4635, 3.5729, 3.6392, 3.6723],\n",
      "        [3.5276, 3.6567, 3.5255, 3.7673, 3.6404],\n",
      "        [3.6657, 3.7038, 3.7262, 3.7246, 3.5074],\n",
      "        [3.5291, 3.6477, 3.5573, 3.6872, 3.7312],\n",
      "        [3.3015, 3.2753, 3.3422, 3.4060, 3.3700],\n",
      "        [3.5746, 3.7267, 3.5903, 3.7263, 3.6773],\n",
      "        [3.3111, 3.4782, 3.5971, 3.4662, 3.5556],\n",
      "        [3.7186, 3.6271, 3.6049, 3.7670, 3.7321],\n",
      "        [3.4577, 3.4001, 3.5231, 3.5856, 3.5444],\n",
      "        [3.3661, 3.2805, 3.3873, 3.4956, 3.3926],\n",
      "        [3.6465, 3.5875, 3.6259, 3.7500, 3.7781],\n",
      "        [3.7124, 3.7669, 3.7922, 3.8105, 3.6092],\n",
      "        [3.3343, 3.6179, 3.5590, 3.5449, 3.6905],\n",
      "        [3.4289, 3.3714, 3.4827, 3.5428, 3.5152],\n",
      "        [3.4720, 3.3905, 3.5016, 3.5649, 3.5226],\n",
      "        [3.5007, 3.4014, 3.5533, 3.5758, 3.5331],\n",
      "        [3.2488, 3.3036, 3.3105, 3.3470, 3.3588],\n",
      "        [3.2600, 3.3186, 3.3193, 3.3534, 3.3663],\n",
      "        [3.6987, 3.6527, 3.6727, 3.7740, 3.8886],\n",
      "        [3.4518, 3.6110, 3.5979, 3.5135, 3.6408],\n",
      "        [3.4951, 3.4355, 3.5162, 3.4910, 3.3729],\n",
      "        [3.3637, 3.4524, 3.4068, 3.5052, 3.5093],\n",
      "        [3.4712, 3.4006, 3.3779, 3.5509, 3.6021],\n",
      "        [3.6492, 3.7979, 3.7325, 3.8019, 3.8169],\n",
      "        [3.4426, 3.3832, 3.5016, 3.5841, 3.5947],\n",
      "        [3.3727, 3.2706, 3.3818, 3.4953, 3.3831],\n",
      "        [3.6618, 3.6680, 3.5517, 3.7036, 3.7414],\n",
      "        [3.6039, 3.6107, 3.5523, 3.6006, 3.6066],\n",
      "        [3.4598, 3.3418, 3.5003, 3.5747, 3.6091],\n",
      "        [3.6185, 3.6576, 3.6155, 3.7546, 3.6525],\n",
      "        [3.2999, 3.3200, 3.2887, 3.4872, 3.3194],\n",
      "        [3.5342, 3.7420, 3.5554, 3.7999, 3.7297],\n",
      "        [3.4417, 3.5192, 3.5279, 3.5841, 3.5927],\n",
      "        [3.5440, 3.4992, 3.5293, 3.6299, 3.5650],\n",
      "        [3.4673, 3.3676, 3.4095, 3.6282, 3.4399],\n",
      "        [3.4425, 3.4458, 3.3929, 3.5483, 3.5105],\n",
      "        [3.5147, 3.4788, 3.5027, 3.6315, 3.6271],\n",
      "        [3.6602, 3.6608, 3.5427, 3.7119, 3.7449],\n",
      "        [3.4228, 3.5017, 3.6990, 3.5686, 3.6906],\n",
      "        [3.9443, 3.9995, 3.7741, 3.8829, 3.8002],\n",
      "        [3.4546, 3.3286, 3.4843, 3.5694, 3.6050],\n",
      "        [3.5751, 3.5882, 3.6439, 3.6931, 3.6414],\n",
      "        [3.3210, 3.4861, 3.3069, 3.5313, 3.3712],\n",
      "        [3.5928, 3.6748, 3.6510, 3.7471, 3.7450],\n",
      "        [3.4733, 3.4133, 3.5106, 3.5938, 3.5506],\n",
      "        [3.4543, 3.4961, 3.6508, 3.5423, 3.5506],\n",
      "        [3.5537, 3.5683, 3.6170, 3.7458, 3.6753],\n",
      "        [3.6190, 3.6619, 3.5383, 3.8359, 3.6966],\n",
      "        [3.5205, 3.3653, 3.4976, 3.5908, 3.4767],\n",
      "        [3.6723, 3.6101, 3.6973, 3.7239, 3.7476],\n",
      "        [3.4811, 3.4966, 3.3671, 3.6152, 3.5147],\n",
      "        [3.6736, 3.6893, 3.6429, 3.7526, 3.7913],\n",
      "        [3.4533, 3.4936, 3.4660, 3.6307, 3.5797],\n",
      "        [3.8500, 3.8934, 3.6790, 3.7903, 3.6877],\n",
      "        [3.3757, 3.2415, 3.4725, 3.3261, 3.5272],\n",
      "        [3.3993, 3.4290, 3.3560, 3.5157, 3.4591],\n",
      "        [3.4491, 3.3779, 3.5088, 3.5845, 3.5784],\n",
      "        [3.3863, 3.4212, 3.3512, 3.4926, 3.4542]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5787, 3.4540, 3.5620, 3.6511, 3.5482],\n",
      "        [3.4760, 3.4215, 3.5092, 3.5943, 3.5455],\n",
      "        [3.3209, 3.4348, 3.4591, 3.4704, 3.4355],\n",
      "        [3.5827, 3.5388, 3.5673, 3.6130, 3.3953],\n",
      "        [3.3675, 3.2704, 3.3809, 3.4972, 3.3760],\n",
      "        [3.8160, 3.5935, 3.7329, 3.9735, 3.8277],\n",
      "        [3.4630, 3.4589, 3.4069, 3.5637, 3.5289],\n",
      "        [3.4429, 3.3369, 3.4944, 3.5378, 3.4708],\n",
      "        [3.4871, 3.4582, 3.4137, 3.6396, 3.5299],\n",
      "        [3.3752, 3.4007, 3.3501, 3.4746, 3.4358],\n",
      "        [3.3306, 3.4562, 3.4665, 3.4793, 3.4535],\n",
      "        [3.5787, 3.7284, 3.5922, 3.7285, 3.6788],\n",
      "        [3.3520, 3.3158, 3.4072, 3.4735, 3.4029],\n",
      "        [3.3756, 3.3032, 3.4032, 3.4934, 3.4049],\n",
      "        [3.5957, 3.5405, 3.5762, 3.6285, 3.4101],\n",
      "        [3.7170, 3.5131, 3.6645, 3.8590, 3.6777],\n",
      "        [3.2639, 3.3202, 3.3212, 3.3554, 3.3677],\n",
      "        [3.3271, 3.4610, 3.4489, 3.5173, 3.6063],\n",
      "        [3.5088, 3.4261, 3.6055, 3.7508, 3.7563],\n",
      "        [3.4599, 3.3900, 3.4845, 3.5606, 3.5121],\n",
      "        [3.3202, 3.3617, 3.3475, 3.4173, 3.4045],\n",
      "        [3.4991, 3.5106, 3.5093, 3.6065, 3.5924],\n",
      "        [3.3936, 3.4309, 3.3621, 3.5028, 3.4640],\n",
      "        [3.5385, 3.4534, 3.6114, 3.6435, 3.6054],\n",
      "        [3.3875, 3.3953, 3.3579, 3.5305, 3.4273],\n",
      "        [3.4417, 3.3618, 3.3380, 3.5129, 3.5621],\n",
      "        [3.7596, 3.7602, 3.7145, 3.8432, 3.8690],\n",
      "        [3.8073, 3.7582, 3.8234, 4.0353, 4.0838],\n",
      "        [3.3215, 3.4078, 3.4452, 3.4685, 3.4216],\n",
      "        [3.4588, 3.4047, 3.4003, 3.6019, 3.4746],\n",
      "        [3.3219, 3.3841, 3.4326, 3.4642, 3.4148],\n",
      "        [3.3570, 3.3999, 3.3522, 3.4689, 3.4375],\n",
      "        [3.7048, 3.7360, 3.7208, 3.8479, 3.8094],\n",
      "        [3.4819, 3.4882, 3.3671, 3.6090, 3.5064],\n",
      "        [3.4556, 3.5145, 3.5393, 3.5804, 3.6655],\n",
      "        [3.4933, 3.5074, 3.3863, 3.6310, 3.5287],\n",
      "        [3.3534, 3.3011, 3.3978, 3.4806, 3.3944],\n",
      "        [3.6452, 3.7409, 3.6247, 3.8259, 3.7537],\n",
      "        [3.5822, 3.7779, 3.6905, 3.7662, 3.8327],\n",
      "        [3.4710, 3.3801, 3.4954, 3.5623, 3.5142],\n",
      "        [3.4613, 3.3788, 3.4969, 3.5647, 3.5124],\n",
      "        [3.4264, 3.4462, 3.3580, 3.5310, 3.4760],\n",
      "        [3.7039, 3.3789, 3.5767, 3.9035, 3.8463],\n",
      "        [3.4853, 3.4366, 3.5175, 3.6101, 3.5587],\n",
      "        [3.4795, 3.3241, 3.4687, 3.4800, 3.4337],\n",
      "        [3.6207, 3.6613, 3.5391, 3.8366, 3.6946],\n",
      "        [3.3415, 3.3859, 3.3574, 3.4325, 3.4486],\n",
      "        [3.6181, 3.7123, 3.6739, 3.7803, 3.7899],\n",
      "        [3.4872, 3.6352, 3.4854, 3.4390, 3.6120],\n",
      "        [3.3986, 3.4365, 3.3701, 3.5086, 3.4668],\n",
      "        [3.5599, 3.6465, 3.5638, 3.7899, 3.6454],\n",
      "        [3.4929, 3.4060, 3.5485, 3.5891, 3.5716],\n",
      "        [3.3274, 3.3328, 3.4126, 3.4617, 3.3977],\n",
      "        [3.6357, 3.4894, 3.6268, 3.7332, 3.6081],\n",
      "        [3.3309, 3.3902, 3.3639, 3.4818, 3.4095],\n",
      "        [3.5485, 3.3729, 3.7366, 3.6534, 3.6480],\n",
      "        [3.6242, 3.5737, 3.6688, 3.6664, 3.4727],\n",
      "        [3.4532, 3.4354, 3.4134, 3.5924, 3.4893],\n",
      "        [3.6808, 3.6707, 3.5665, 3.7285, 3.7828],\n",
      "        [3.4808, 3.4714, 3.4102, 3.5854, 3.5448],\n",
      "        [3.3008, 3.3553, 3.3432, 3.3937, 3.3986],\n",
      "        [3.3298, 3.3654, 3.4307, 3.4664, 3.4110],\n",
      "        [3.3761, 3.3228, 3.2900, 3.5338, 3.3472],\n",
      "        [3.4642, 3.3943, 3.4917, 3.5733, 3.5247]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4707, 3.4120, 3.4999, 3.5813, 3.5259],\n",
      "        [3.4872, 3.4514, 3.5237, 3.5696, 3.7261],\n",
      "        [3.7350, 3.5651, 3.5843, 3.7346, 3.7340],\n",
      "        [3.4634, 3.4075, 3.4019, 3.6035, 3.4757],\n",
      "        [3.4891, 3.3178, 3.4629, 3.4582, 3.4207],\n",
      "        [3.4823, 3.4239, 3.5128, 3.5956, 3.5486],\n",
      "        [3.7097, 3.6215, 3.6884, 3.8969, 3.9275],\n",
      "        [3.5524, 3.6640, 3.5516, 3.7829, 3.6489],\n",
      "        [3.3369, 3.4668, 3.4759, 3.4890, 3.4679],\n",
      "        [3.5837, 3.4788, 3.5132, 3.7592, 3.6346],\n",
      "        [3.6747, 3.7086, 3.7295, 3.7287, 3.5100],\n",
      "        [3.4036, 3.5407, 3.3954, 3.3421, 3.4961],\n",
      "        [3.9982, 4.1230, 3.7201, 3.9146, 3.8038],\n",
      "        [3.3908, 3.5310, 3.5069, 3.5756, 3.6727],\n",
      "        [3.3816, 3.3093, 3.4052, 3.4964, 3.4079],\n",
      "        [3.4099, 3.6207, 3.5625, 3.6201, 3.6851],\n",
      "        [3.4228, 3.3618, 3.4219, 3.4924, 3.5383],\n",
      "        [3.4440, 3.6007, 3.6225, 3.5586, 3.7734],\n",
      "        [3.4246, 3.3133, 3.4716, 3.5143, 3.4472],\n",
      "        [3.3766, 3.2847, 3.3888, 3.5002, 3.3931],\n",
      "        [3.4973, 3.4187, 3.5623, 3.6264, 3.5679],\n",
      "        [3.7072, 3.7051, 3.7657, 3.9594, 4.0186],\n",
      "        [3.4431, 3.5696, 3.4854, 3.5546, 3.4879],\n",
      "        [3.5016, 3.4037, 3.5207, 3.5586, 3.5718],\n",
      "        [3.5712, 3.5098, 3.5279, 3.7441, 3.5787],\n",
      "        [3.6168, 3.6854, 3.5372, 3.6775, 3.6740],\n",
      "        [3.6129, 3.5982, 3.6854, 3.6679, 3.5336],\n",
      "        [3.2995, 3.2625, 3.3747, 3.4135, 3.3211],\n",
      "        [3.4616, 3.4687, 3.3703, 3.5622, 3.5086],\n",
      "        [3.5182, 3.4333, 3.5070, 3.6124, 3.5613],\n",
      "        [3.6700, 3.5711, 3.8033, 3.6502, 3.5630],\n",
      "        [3.5780, 3.6863, 3.6499, 3.7171, 3.6217],\n",
      "        [3.8441, 3.8786, 3.5684, 3.7803, 3.6405],\n",
      "        [3.3721, 3.2977, 3.3984, 3.4902, 3.3951],\n",
      "        [3.3295, 3.4904, 3.3107, 3.5350, 3.3736],\n",
      "        [3.6138, 3.5638, 3.4542, 3.7436, 3.7038],\n",
      "        [3.5489, 3.5864, 3.4950, 3.6893, 3.5898],\n",
      "        [3.6279, 3.6665, 3.5418, 3.8397, 3.6992],\n",
      "        [3.5014, 3.6541, 3.6077, 3.7206, 3.7484],\n",
      "        [3.4383, 3.3719, 3.4387, 3.5883, 3.4381],\n",
      "        [3.4746, 3.3304, 3.4717, 3.4872, 3.4409],\n",
      "        [3.7792, 3.6346, 3.6845, 3.9289, 3.7936],\n",
      "        [3.3801, 3.3060, 3.4046, 3.4951, 3.4060],\n",
      "        [3.8652, 3.9106, 3.6947, 3.7964, 3.7208],\n",
      "        [3.4559, 3.6071, 3.5991, 3.5094, 3.6346],\n",
      "        [3.7217, 3.5203, 3.6743, 3.8583, 3.6857],\n",
      "        [3.6825, 3.6939, 3.6463, 3.7564, 3.7942],\n",
      "        [3.6995, 3.6179, 3.6168, 3.7501, 3.7266],\n",
      "        [3.3990, 3.4614, 3.3934, 3.6089, 3.4425],\n",
      "        [3.4239, 3.2866, 3.3818, 3.5046, 3.3912],\n",
      "        [3.3912, 3.4246, 3.5285, 3.5454, 3.4424],\n",
      "        [3.4946, 3.5093, 3.3743, 3.6289, 3.5278],\n",
      "        [3.7507, 3.6732, 3.7044, 3.8310, 3.9589],\n",
      "        [3.7140, 3.6068, 3.6857, 3.8396, 3.7197],\n",
      "        [3.3611, 3.3216, 3.4149, 3.4804, 3.4068],\n",
      "        [3.3916, 3.3759, 3.3606, 3.5272, 3.4207],\n",
      "        [3.6341, 3.7020, 3.6653, 3.7579, 3.6667],\n",
      "        [3.8021, 3.6565, 3.6627, 3.8534, 3.7722],\n",
      "        [3.5839, 3.4740, 3.5780, 3.5874, 3.4878],\n",
      "        [3.4048, 3.4104, 3.3792, 3.5436, 3.4776],\n",
      "        [3.6576, 3.5216, 3.5657, 3.6079, 3.5130],\n",
      "        [3.4718, 3.3778, 3.5244, 3.5599, 3.5043],\n",
      "        [3.5093, 3.4059, 3.5566, 3.5793, 3.5356],\n",
      "        [3.3698, 3.2852, 3.3883, 3.4962, 3.3874]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3550, 3.3351, 3.4191, 3.4746, 3.4093],\n",
      "        [3.5846, 3.6342, 3.5122, 3.6492, 3.6160],\n",
      "        [3.6457, 3.5057, 3.5370, 3.8904, 3.7271],\n",
      "        [3.5886, 3.4590, 3.5674, 3.6518, 3.5570],\n",
      "        [3.3161, 3.4881, 3.6033, 3.4762, 3.5546],\n",
      "        [3.6830, 3.8124, 3.6916, 3.9101, 3.8479],\n",
      "        [4.0009, 4.0867, 3.7700, 3.9312, 3.7624],\n",
      "        [3.2843, 3.3390, 3.3356, 3.3714, 3.3793],\n",
      "        [3.5072, 3.5694, 3.4432, 3.7474, 3.4896],\n",
      "        [3.4876, 3.3302, 3.4724, 3.4836, 3.4366],\n",
      "        [3.4516, 3.3467, 3.4791, 3.5136, 3.4697],\n",
      "        [3.5943, 3.8286, 3.6354, 3.8555, 3.7927],\n",
      "        [3.4666, 3.4805, 3.3670, 3.5932, 3.4971],\n",
      "        [3.5169, 3.5970, 3.5157, 3.6092, 3.6302],\n",
      "        [3.3850, 3.3282, 3.4325, 3.5059, 3.3965],\n",
      "        [3.2491, 3.3020, 3.3116, 3.3325, 3.3401],\n",
      "        [3.4949, 3.4989, 3.5065, 3.5996, 3.5783],\n",
      "        [3.6064, 3.4069, 3.4253, 3.5412, 3.6142],\n",
      "        [3.4750, 3.3462, 3.5145, 3.5813, 3.6105],\n",
      "        [3.4455, 3.4112, 3.4400, 3.4950, 3.4982],\n",
      "        [3.5027, 3.7304, 3.6776, 3.6705, 3.5976],\n",
      "        [3.4421, 3.5241, 3.5158, 3.4837, 3.4725],\n",
      "        [3.4930, 3.5042, 3.3726, 3.6209, 3.5190],\n",
      "        [3.4468, 3.4556, 3.5714, 3.6504, 3.6754],\n",
      "        [3.4549, 3.3875, 3.4523, 3.5263, 3.5643],\n",
      "        [3.3299, 3.3902, 3.4365, 3.4679, 3.4177],\n",
      "        [3.8535, 3.9002, 3.8910, 4.0406, 4.1216],\n",
      "        [3.8140, 3.8011, 3.7576, 3.8881, 3.9125],\n",
      "        [3.4688, 3.4616, 3.5746, 3.6180, 3.6113],\n",
      "        [3.5858, 3.5291, 3.5351, 3.7753, 3.5826],\n",
      "        [3.4916, 3.4347, 3.6046, 3.7084, 3.7284],\n",
      "        [3.4343, 3.4522, 3.3617, 3.5347, 3.4789],\n",
      "        [3.6269, 3.5235, 3.5843, 3.7172, 3.7937],\n",
      "        [3.4661, 3.3853, 3.5154, 3.5906, 3.5952],\n",
      "        [4.1136, 4.1784, 3.8484, 4.0051, 3.8454],\n",
      "        [3.4061, 3.3983, 3.5135, 3.6114, 3.5533],\n",
      "        [3.2476, 3.3078, 3.3933, 3.4000, 3.4231],\n",
      "        [3.4651, 3.4719, 3.3725, 3.5642, 3.5103],\n",
      "        [3.5514, 3.7102, 3.6112, 3.7167, 3.7542],\n",
      "        [3.4816, 3.4926, 3.3655, 3.6060, 3.5112],\n",
      "        [3.3887, 3.4690, 3.5805, 3.5397, 3.5757],\n",
      "        [3.3789, 3.4021, 3.3334, 3.5388, 3.4374],\n",
      "        [3.2974, 3.3514, 3.3413, 3.3865, 3.4014],\n",
      "        [3.3612, 3.4045, 3.3563, 3.4648, 3.4345],\n",
      "        [3.3430, 3.4707, 3.4759, 3.4947, 3.4676],\n",
      "        [3.4867, 3.3982, 3.5115, 3.5720, 3.5271],\n",
      "        [3.8192, 3.6254, 3.7388, 4.0100, 3.8570],\n",
      "        [3.4615, 3.4416, 3.4175, 3.5961, 3.4922],\n",
      "        [3.3523, 3.3972, 3.3603, 3.4435, 3.4333],\n",
      "        [3.3417, 3.3290, 3.3726, 3.4525, 3.4048],\n",
      "        [3.6887, 3.7159, 3.7277, 3.7336, 3.5096],\n",
      "        [3.4281, 3.3165, 3.4737, 3.5162, 3.4489],\n",
      "        [3.5828, 3.6179, 3.5966, 3.6608, 3.5049],\n",
      "        [3.4595, 3.6105, 3.6014, 3.5117, 3.6365],\n",
      "        [3.4077, 3.6132, 3.5660, 3.6186, 3.6645],\n",
      "        [3.6056, 3.4948, 3.5885, 3.6028, 3.4866],\n",
      "        [3.5072, 3.4433, 3.5214, 3.4971, 3.3771],\n",
      "        [3.3019, 3.3650, 3.3593, 3.3949, 3.4114],\n",
      "        [3.2688, 3.3254, 3.3264, 3.3570, 3.3711],\n",
      "        [3.6561, 3.6659, 3.6813, 3.7075, 3.5344],\n",
      "        [3.7044, 3.7366, 3.7650, 3.8048, 3.6103],\n",
      "        [3.4943, 3.3215, 3.4626, 3.4680, 3.4230],\n",
      "        [3.6663, 3.5611, 3.6202, 3.7608, 3.8277],\n",
      "        [3.5754, 3.4465, 3.5631, 3.5605, 3.5016]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6937, 3.7288, 3.6657, 3.6491, 3.7252],\n",
      "        [3.3453, 3.3990, 3.4543, 3.4871, 3.4393],\n",
      "        [3.3338, 3.4906, 3.3111, 3.5508, 3.3774],\n",
      "        [3.4692, 3.3890, 3.5173, 3.5930, 3.5967],\n",
      "        [3.5910, 3.5141, 3.6560, 3.7145, 3.5971],\n",
      "        [3.5099, 3.5390, 3.3652, 3.5467, 3.5338],\n",
      "        [3.4090, 3.3905, 3.4483, 3.4793, 3.4593],\n",
      "        [3.5270, 3.6570, 3.5094, 3.7645, 3.6349],\n",
      "        [3.4503, 3.4454, 3.4828, 3.5952, 3.6153],\n",
      "        [3.8011, 3.7234, 3.6903, 3.9739, 3.8273],\n",
      "        [3.5881, 3.4654, 3.5714, 3.5646, 3.5117],\n",
      "        [3.6081, 3.6497, 3.5199, 3.8092, 3.6613],\n",
      "        [3.5011, 3.5162, 3.3783, 3.6334, 3.5311],\n",
      "        [3.6079, 3.6175, 3.5194, 3.6789, 3.6366],\n",
      "        [3.2718, 3.3289, 3.3284, 3.3593, 3.3726],\n",
      "        [3.6123, 3.5983, 3.5103, 3.6588, 3.7402],\n",
      "        [3.6479, 3.4922, 3.5477, 3.9207, 3.7450],\n",
      "        [3.5850, 3.6935, 3.6541, 3.7218, 3.6258],\n",
      "        [3.4417, 3.4042, 3.4406, 3.4955, 3.4913],\n",
      "        [3.5040, 3.4596, 3.5263, 3.5099, 3.3734],\n",
      "        [3.6384, 3.6706, 3.5774, 3.7494, 3.6705],\n",
      "        [3.4264, 3.4457, 3.3623, 3.5261, 3.4797],\n",
      "        [3.8631, 3.8360, 3.7778, 4.0896, 3.9069],\n",
      "        [3.6470, 3.4378, 3.5302, 3.6285, 3.5936],\n",
      "        [3.4643, 3.3894, 3.5161, 3.5926, 3.5842],\n",
      "        [3.4808, 3.4043, 3.4996, 3.5668, 3.5198],\n",
      "        [3.4009, 3.4632, 3.5696, 3.5995, 3.6166],\n",
      "        [3.6126, 3.6506, 3.6526, 3.7547, 3.6853],\n",
      "        [3.4772, 3.4244, 3.5951, 3.5057, 3.6889],\n",
      "        [3.4524, 3.4008, 3.6131, 3.4420, 3.6749],\n",
      "        [3.5115, 3.4295, 3.5893, 3.6446, 3.5927],\n",
      "        [3.5081, 3.6619, 3.6123, 3.7254, 3.7519],\n",
      "        [3.6782, 3.6962, 3.7389, 3.7157, 3.4943],\n",
      "        [3.4845, 3.3951, 3.5055, 3.5679, 3.5199],\n",
      "        [3.2804, 3.3376, 3.3340, 3.3653, 3.3832],\n",
      "        [3.3401, 3.4779, 3.5877, 3.5074, 3.5400],\n",
      "        [3.3644, 3.3107, 3.4034, 3.4867, 3.3987],\n",
      "        [3.5688, 3.4854, 3.5149, 3.7242, 3.5930],\n",
      "        [3.4311, 3.3201, 3.4756, 3.5185, 3.4504],\n",
      "        [3.4964, 3.5068, 3.5205, 3.5787, 3.5634],\n",
      "        [3.4972, 3.6420, 3.4745, 3.4423, 3.5773],\n",
      "        [3.4748, 3.5315, 3.5572, 3.5977, 3.6712],\n",
      "        [3.4606, 3.6597, 3.6024, 3.6626, 3.7248],\n",
      "        [3.6437, 3.5814, 3.6079, 3.7021, 3.7608],\n",
      "        [3.7094, 3.5922, 3.6534, 3.7725, 3.8581],\n",
      "        [3.5961, 3.5935, 3.5262, 3.7116, 3.6968],\n",
      "        [3.5925, 3.7174, 3.6694, 3.7427, 3.8267],\n",
      "        [3.4615, 3.4767, 3.3701, 3.5743, 3.4985],\n",
      "        [3.4374, 3.4558, 3.3636, 3.5371, 3.4804],\n",
      "        [3.2841, 3.3524, 3.3889, 3.4466, 3.4295],\n",
      "        [3.4015, 3.6121, 3.6309, 3.5979, 3.7019],\n",
      "        [3.4880, 3.5360, 3.5581, 3.6118, 3.4976],\n",
      "        [3.9689, 4.0700, 3.7086, 3.8868, 3.7576],\n",
      "        [3.6110, 3.6469, 3.6287, 3.8224, 3.6427],\n",
      "        [3.4849, 3.4087, 3.5045, 3.5856, 3.5262],\n",
      "        [3.7716, 3.7703, 3.7204, 3.8496, 3.8743],\n",
      "        [3.4786, 3.3648, 3.4970, 3.5142, 3.4797],\n",
      "        [3.4711, 3.3998, 3.4900, 3.5667, 3.5164],\n",
      "        [3.4173, 3.3849, 3.4984, 3.5921, 3.5404],\n",
      "        [3.6025, 3.3830, 3.4185, 3.5375, 3.5976],\n",
      "        [3.7295, 3.5229, 3.6703, 3.8651, 3.6833],\n",
      "        [3.6631, 3.6644, 3.6541, 3.6579, 3.6855],\n",
      "        [3.4757, 3.3799, 3.5094, 3.5645, 3.5001],\n",
      "        [3.4127, 3.4523, 3.4658, 3.4362, 3.4739]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8018, 3.6424, 3.6659, 3.9445, 3.7675],\n",
      "        [3.3439, 3.4159, 3.4540, 3.4882, 3.4425],\n",
      "        [3.4674, 3.4501, 3.4212, 3.6007, 3.4949],\n",
      "        [3.5146, 3.6481, 3.6185, 3.7130, 3.7510],\n",
      "        [3.6049, 3.6243, 3.6778, 3.7206, 3.6408],\n",
      "        [3.4176, 3.6533, 3.5215, 3.6410, 3.6578],\n",
      "        [3.5367, 3.6596, 3.4541, 3.6429, 3.5633],\n",
      "        [3.4849, 3.3946, 3.5023, 3.5704, 3.5197],\n",
      "        [3.4676, 3.4198, 3.6404, 3.4505, 3.6947],\n",
      "        [3.4242, 3.3124, 3.4172, 3.5257, 3.4023],\n",
      "        [3.6876, 3.6258, 3.6397, 3.7526, 3.8589],\n",
      "        [3.5339, 3.5677, 3.4267, 3.5778, 3.5749],\n",
      "        [3.4222, 3.2875, 3.5036, 3.3698, 3.5578],\n",
      "        [3.3898, 3.3370, 3.2979, 3.5417, 3.3525],\n",
      "        [3.7133, 3.6524, 3.7500, 3.9135, 3.6657],\n",
      "        [3.7379, 3.6437, 3.6141, 3.7783, 3.7394],\n",
      "        [3.3542, 3.3579, 3.4280, 3.4766, 3.4142],\n",
      "        [3.6060, 3.6126, 3.6686, 3.6966, 3.6520],\n",
      "        [3.4787, 3.4836, 3.4598, 3.5552, 3.5340],\n",
      "        [3.6400, 3.6811, 3.6402, 3.7696, 3.6640],\n",
      "        [3.3845, 3.4085, 3.5091, 3.5393, 3.4168],\n",
      "        [3.4141, 3.4218, 3.3850, 3.5501, 3.4819],\n",
      "        [3.3356, 3.4550, 3.4641, 3.4767, 3.4409],\n",
      "        [3.4450, 3.4622, 3.3754, 3.5604, 3.4919],\n",
      "        [3.6560, 3.7204, 3.6723, 3.7652, 3.6635],\n",
      "        [3.4760, 3.4164, 3.5321, 3.5962, 3.5513],\n",
      "        [3.8260, 3.6341, 3.7425, 4.0146, 3.8605],\n",
      "        [3.7352, 3.7726, 3.5351, 3.7016, 3.6567],\n",
      "        [3.2869, 3.3571, 3.3906, 3.4487, 3.4306],\n",
      "        [3.5745, 3.3298, 3.6376, 3.6622, 3.5931],\n",
      "        [3.4848, 3.4929, 3.3807, 3.5881, 3.5243],\n",
      "        [3.6596, 3.7552, 3.6323, 3.8348, 3.7596],\n",
      "        [3.4949, 3.5137, 3.3854, 3.6209, 3.5305],\n",
      "        [3.5226, 3.4401, 3.5927, 3.6504, 3.5989],\n",
      "        [3.4961, 3.4466, 3.6105, 3.7167, 3.7317],\n",
      "        [3.3790, 3.2967, 3.3937, 3.5027, 3.3917],\n",
      "        [3.8441, 3.5735, 3.7153, 4.2141, 4.0467],\n",
      "        [3.9671, 4.0201, 3.7123, 3.8599, 3.7095],\n",
      "        [3.3258, 3.3749, 3.3534, 3.4207, 3.4269],\n",
      "        [3.6136, 3.7213, 3.5496, 3.5395, 3.6108],\n",
      "        [3.5001, 3.3297, 3.4660, 3.4723, 3.4256],\n",
      "        [3.6321, 3.6383, 3.5616, 3.6677, 3.6268],\n",
      "        [3.4533, 3.6136, 3.6287, 3.5654, 3.7781],\n",
      "        [3.4968, 3.5057, 3.3708, 3.6174, 3.5106],\n",
      "        [3.5039, 3.4593, 3.5366, 3.5040, 3.3735],\n",
      "        [3.3601, 3.3509, 3.4291, 3.4880, 3.4245],\n",
      "        [3.4877, 3.4135, 3.5060, 3.5877, 3.5273],\n",
      "        [3.4708, 3.4802, 3.3759, 3.5687, 3.5129],\n",
      "        [3.3359, 3.4368, 3.4569, 3.4750, 3.4325],\n",
      "        [3.7444, 3.6475, 3.7182, 3.8477, 3.7255],\n",
      "        [3.4461, 3.4560, 3.4807, 3.6237, 3.5642],\n",
      "        [3.4606, 3.6416, 3.6320, 3.5277, 3.6585],\n",
      "        [3.4722, 3.4707, 3.4561, 3.5456, 3.5315],\n",
      "        [3.6834, 3.5692, 3.7124, 3.7398, 3.5299],\n",
      "        [3.6118, 3.5624, 3.6756, 3.6642, 3.5534],\n",
      "        [3.2831, 3.3420, 3.3356, 3.3674, 3.3842],\n",
      "        [3.6376, 3.6786, 3.5476, 3.8465, 3.7037],\n",
      "        [3.4503, 3.6946, 3.6393, 3.6858, 3.7507],\n",
      "        [3.3888, 3.4148, 3.3575, 3.4827, 3.4411],\n",
      "        [3.7745, 3.7750, 3.7220, 3.8517, 3.8757],\n",
      "        [3.3417, 3.3674, 3.4281, 3.4696, 3.4121],\n",
      "        [3.3962, 3.3045, 3.4007, 3.5124, 3.4024],\n",
      "        [3.9018, 3.5498, 3.6979, 4.1729, 4.0608],\n",
      "        [3.8130, 3.5453, 3.7022, 4.1921, 4.0389]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4812, 3.4051, 3.5005, 3.5668, 3.5188],\n",
      "        [3.5146, 3.5225, 3.3863, 3.6391, 3.5247],\n",
      "        [3.6363, 3.4919, 3.5225, 3.8831, 3.7131],\n",
      "        [3.5437, 3.2994, 3.6224, 3.6614, 3.6236],\n",
      "        [3.3347, 3.4021, 3.4455, 3.4734, 3.4178],\n",
      "        [3.3812, 3.3282, 3.4150, 3.4952, 3.4093],\n",
      "        [3.2004, 3.2746, 3.3692, 3.3669, 3.3916],\n",
      "        [3.6211, 3.6590, 3.6544, 3.7538, 3.6881],\n",
      "        [3.6396, 3.6838, 3.5488, 3.8482, 3.7046],\n",
      "        [3.4802, 3.4581, 3.5117, 3.5840, 3.6860],\n",
      "        [3.4574, 3.3944, 3.4522, 3.5258, 3.5537],\n",
      "        [3.4161, 3.4267, 3.3863, 3.5517, 3.4828],\n",
      "        [3.5090, 3.5267, 3.3946, 3.6407, 3.5350],\n",
      "        [3.4890, 3.5016, 3.3760, 3.6104, 3.5122],\n",
      "        [3.3863, 3.5159, 3.3520, 3.5580, 3.4016],\n",
      "        [3.6069, 3.7621, 3.6162, 3.7516, 3.6997],\n",
      "        [3.6974, 3.6907, 3.5751, 3.7385, 3.7902],\n",
      "        [3.5900, 3.5739, 3.6095, 3.7006, 3.7254],\n",
      "        [3.6262, 3.6541, 3.5539, 3.7922, 3.8124],\n",
      "        [3.4702, 3.4280, 3.6062, 3.4912, 3.6738],\n",
      "        [3.4162, 3.4460, 3.3659, 3.5138, 3.4752],\n",
      "        [3.6132, 3.6822, 3.6362, 3.8422, 3.6630],\n",
      "        [3.4819, 3.4910, 3.5266, 3.6254, 3.5158],\n",
      "        [3.4987, 3.7384, 3.6750, 3.6750, 3.5908],\n",
      "        [3.4808, 3.4885, 3.4611, 3.5568, 3.5349],\n",
      "        [3.4925, 3.5585, 3.5495, 3.6187, 3.5274],\n",
      "        [3.2616, 3.3166, 3.3202, 3.3422, 3.3476],\n",
      "        [3.4928, 3.5024, 3.3698, 3.6096, 3.5069],\n",
      "        [3.4897, 3.4185, 3.5072, 3.5893, 3.5281],\n",
      "        [3.6396, 3.6838, 3.5488, 3.8482, 3.7046],\n",
      "        [3.5956, 3.6029, 3.5313, 3.5646, 3.5852],\n",
      "        [3.6436, 3.7075, 3.5315, 3.6722, 3.6733],\n",
      "        [3.3374, 3.4270, 3.4542, 3.4783, 3.4278],\n",
      "        [3.4768, 3.6123, 3.5761, 3.5351, 3.6346],\n",
      "        [3.4941, 3.4175, 3.5603, 3.6164, 3.5575],\n",
      "        [3.7076, 3.7500, 3.5290, 3.6865, 3.6572],\n",
      "        [3.4466, 3.3391, 3.4854, 3.5316, 3.4669],\n",
      "        [3.7129, 3.7506, 3.7697, 3.8119, 3.6139],\n",
      "        [3.6424, 3.5600, 3.6478, 3.7683, 3.5017],\n",
      "        [3.5318, 3.5755, 3.4462, 3.5694, 3.5794],\n",
      "        [3.3828, 3.3337, 3.4163, 3.4982, 3.4127],\n",
      "        [3.4467, 3.3848, 3.4335, 3.5103, 3.5473],\n",
      "        [3.7647, 3.8268, 3.6633, 3.6954, 3.7212],\n",
      "        [3.5157, 3.5358, 3.3893, 3.6498, 3.5393],\n",
      "        [3.7355, 3.8103, 3.6413, 3.6729, 3.6490],\n",
      "        [3.6043, 3.5687, 3.4631, 3.7183, 3.6832],\n",
      "        [3.3639, 3.4642, 3.4757, 3.4984, 3.4757],\n",
      "        [3.8214, 3.8914, 3.7082, 3.7608, 3.7534],\n",
      "        [3.3055, 3.2782, 3.3456, 3.3959, 3.3679],\n",
      "        [3.3165, 3.3741, 3.3521, 3.4034, 3.4047],\n",
      "        [3.4104, 3.6224, 3.5240, 3.4338, 3.6417],\n",
      "        [3.6408, 3.5936, 3.6770, 3.6773, 3.4792],\n",
      "        [3.4703, 3.4940, 3.5201, 3.6847, 3.5225],\n",
      "        [3.6291, 3.4865, 3.6008, 3.7056, 3.5756],\n",
      "        [3.3494, 3.3927, 3.3532, 3.4418, 3.4181],\n",
      "        [3.5643, 3.6811, 3.5588, 3.7914, 3.6544],\n",
      "        [3.8545, 3.7239, 3.7545, 3.9501, 3.8834],\n",
      "        [3.4627, 3.4047, 3.5115, 3.5959, 3.6024],\n",
      "        [3.4573, 3.4106, 3.6159, 3.4457, 3.6768],\n",
      "        [3.3652, 3.3560, 3.4478, 3.5021, 3.3964],\n",
      "        [3.7108, 3.6133, 3.6684, 3.8884, 3.9193],\n",
      "        [3.4380, 3.3220, 3.4214, 3.5088, 3.5897],\n",
      "        [3.5299, 3.4500, 3.5139, 3.6207, 3.5665],\n",
      "        [3.6252, 3.6143, 3.5317, 3.7356, 3.6406]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6987, 3.6952, 3.5763, 3.7413, 3.7910],\n",
      "        [3.6385, 3.6849, 3.5437, 3.8414, 3.6938],\n",
      "        [3.4543, 3.3928, 3.4465, 3.6056, 3.4519],\n",
      "        [3.4385, 3.6278, 3.4812, 3.5201, 3.4470],\n",
      "        [3.3482, 3.4424, 3.4610, 3.4883, 3.4467],\n",
      "        [3.7761, 3.6559, 3.7163, 3.8840, 3.6282],\n",
      "        [3.4746, 3.5196, 3.4775, 3.6456, 3.5884],\n",
      "        [3.7155, 3.6078, 3.6574, 3.7792, 3.8610],\n",
      "        [3.7299, 3.7242, 3.6820, 3.8102, 3.8166],\n",
      "        [3.4070, 3.6281, 3.6353, 3.6046, 3.7046],\n",
      "        [3.5618, 3.7096, 3.6465, 3.7014, 3.5950],\n",
      "        [3.5082, 3.4362, 3.5729, 3.6333, 3.5852],\n",
      "        [3.3778, 3.2832, 3.3798, 3.4958, 3.3778],\n",
      "        [3.4995, 3.4561, 3.6130, 3.7209, 3.7332],\n",
      "        [3.6034, 3.5043, 3.5914, 3.7711, 3.5219],\n",
      "        [3.3391, 3.3108, 3.4010, 3.4540, 3.3677],\n",
      "        [3.3789, 3.2781, 3.3823, 3.5014, 3.3747],\n",
      "        [3.8040, 3.6599, 3.6734, 3.8575, 3.7696],\n",
      "        [3.4262, 3.4555, 3.4066, 3.5395, 3.5069],\n",
      "        [3.6946, 3.6366, 3.7093, 3.7392, 3.7569],\n",
      "        [3.3206, 3.3447, 3.3014, 3.5012, 3.3274],\n",
      "        [3.7795, 3.5197, 3.5855, 4.0590, 3.8395],\n",
      "        [3.4634, 3.4813, 3.4939, 3.6350, 3.5812],\n",
      "        [3.8997, 3.9928, 3.6438, 3.8035, 3.6791],\n",
      "        [3.6488, 3.6569, 3.6718, 3.8638, 3.6370],\n",
      "        [3.6409, 3.6885, 3.5500, 3.8510, 3.7052],\n",
      "        [3.4813, 3.3937, 3.5087, 3.5667, 3.5037],\n",
      "        [3.3069, 3.3714, 3.3453, 3.4014, 3.3972],\n",
      "        [3.4611, 3.3583, 3.5014, 3.5476, 3.4815],\n",
      "        [3.5970, 3.4952, 3.5859, 3.5985, 3.4939],\n",
      "        [3.4860, 3.3694, 3.5262, 3.5933, 3.6195],\n",
      "        [3.8455, 3.8147, 3.7149, 4.0953, 3.8921],\n",
      "        [3.7835, 3.6948, 3.6979, 3.9525, 3.7562],\n",
      "        [3.5489, 3.3965, 3.6416, 3.6996, 3.5804],\n",
      "        [3.5688, 3.7283, 3.6167, 3.7345, 3.7654],\n",
      "        [3.2565, 3.3253, 3.3994, 3.4087, 3.4272],\n",
      "        [3.4787, 3.5481, 3.5375, 3.6129, 3.5503],\n",
      "        [3.4105, 3.4543, 3.3718, 3.5152, 3.4708],\n",
      "        [3.6259, 3.7120, 3.6693, 3.7618, 3.7804],\n",
      "        [3.6264, 3.6186, 3.5329, 3.7383, 3.6413],\n",
      "        [3.5749, 3.4998, 3.5189, 3.7308, 3.5956],\n",
      "        [3.2940, 3.3615, 3.3410, 3.3817, 3.3861],\n",
      "        [3.5158, 3.5269, 3.3874, 3.6417, 3.5253],\n",
      "        [3.8746, 3.5898, 3.7496, 4.2538, 4.0793],\n",
      "        [3.3884, 3.4084, 3.3383, 3.5505, 3.4396],\n",
      "        [3.4071, 3.4462, 3.3628, 3.5069, 3.4624],\n",
      "        [3.4159, 3.6243, 3.5279, 3.4318, 3.6342],\n",
      "        [3.4874, 3.4279, 3.5069, 3.5867, 3.5348],\n",
      "        [3.4156, 3.4599, 3.3798, 3.5209, 3.4736],\n",
      "        [3.4896, 3.5085, 3.3850, 3.6141, 3.5201],\n",
      "        [3.6472, 3.4630, 3.5126, 3.9106, 3.7035],\n",
      "        [3.3690, 3.3394, 3.4167, 3.4860, 3.4097],\n",
      "        [3.4794, 3.4257, 3.5345, 3.6007, 3.5528],\n",
      "        [3.5403, 3.4702, 3.5133, 3.6514, 3.5657],\n",
      "        [3.2860, 3.3473, 3.3373, 3.3722, 3.3814],\n",
      "        [3.6925, 3.8302, 3.6980, 3.9195, 3.8523],\n",
      "        [3.7354, 3.6402, 3.6939, 3.9105, 3.9313],\n",
      "        [3.6376, 3.8368, 3.7017, 3.8103, 3.8456],\n",
      "        [3.8240, 3.8193, 3.7637, 3.8973, 3.9177],\n",
      "        [3.5259, 3.6609, 3.4475, 3.6192, 3.5545],\n",
      "        [3.6384, 3.6861, 3.5489, 3.8496, 3.7018],\n",
      "        [3.5041, 3.5167, 3.5125, 3.6086, 3.5824],\n",
      "        [3.5974, 3.6147, 3.6552, 3.7089, 3.6501],\n",
      "        [3.5312, 3.4545, 3.5150, 3.6234, 3.5672]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4747, 3.5444, 3.5501, 3.5972, 3.6732],\n",
      "        [3.6644, 3.6939, 3.5468, 3.7067, 3.7230],\n",
      "        [3.4907, 3.6540, 3.4680, 3.7269, 3.6052],\n",
      "        [3.6068, 3.6224, 3.5831, 3.6847, 3.6999],\n",
      "        [3.5570, 3.7725, 3.5685, 3.8188, 3.7390],\n",
      "        [3.3422, 3.3947, 3.4363, 3.4782, 3.4180],\n",
      "        [3.5744, 3.6888, 3.5996, 3.6385, 3.6681],\n",
      "        [3.5144, 3.5377, 3.3993, 3.6456, 3.5410],\n",
      "        [3.5716, 3.5115, 3.4835, 3.7178, 3.5987],\n",
      "        [3.6516, 3.6017, 3.6127, 3.7121, 3.7640],\n",
      "        [3.3831, 3.3112, 3.3968, 3.5099, 3.3936],\n",
      "        [3.9694, 3.5983, 3.7608, 4.2633, 4.1297],\n",
      "        [3.3349, 3.4005, 3.3562, 3.4298, 3.4175],\n",
      "        [3.8588, 3.9047, 3.5778, 3.7942, 3.6479],\n",
      "        [3.4043, 3.5445, 3.3657, 3.5643, 3.4050],\n",
      "        [4.0153, 4.1509, 3.7233, 3.9102, 3.8041],\n",
      "        [3.4870, 3.3748, 3.5271, 3.5964, 3.6199],\n",
      "        [3.4826, 3.4299, 3.5036, 3.5880, 3.5264],\n",
      "        [3.7356, 3.6499, 3.6194, 3.7803, 3.7268],\n",
      "        [3.4073, 3.3532, 3.4353, 3.5187, 3.4144],\n",
      "        [3.8687, 3.8627, 3.8094, 4.1296, 3.9318],\n",
      "        [3.5977, 3.5059, 3.5224, 3.7737, 3.6409],\n",
      "        [3.5927, 3.4728, 3.5779, 3.5606, 3.5371],\n",
      "        [3.5218, 3.7396, 3.6461, 3.6621, 3.5502],\n",
      "        [3.4549, 3.4154, 3.4702, 3.5985, 3.4604],\n",
      "        [3.4529, 3.4969, 3.3836, 3.5722, 3.4945],\n",
      "        [3.4724, 3.5040, 3.5221, 3.6904, 3.5237],\n",
      "        [3.5628, 3.4856, 3.6305, 3.6729, 3.6145],\n",
      "        [3.5193, 3.4872, 3.5525, 3.5962, 3.7599],\n",
      "        [3.3957, 3.4729, 3.5709, 3.5684, 3.5886],\n",
      "        [3.6036, 3.5623, 3.4444, 3.7328, 3.6977],\n",
      "        [3.6418, 3.6940, 3.5509, 3.8541, 3.7057],\n",
      "        [3.3304, 3.2515, 3.3606, 3.5127, 3.3706],\n",
      "        [3.8844, 3.9450, 3.7299, 3.8112, 3.7717],\n",
      "        [3.6128, 3.6329, 3.6813, 3.7505, 3.6643],\n",
      "        [3.4761, 3.4270, 3.4999, 3.5851, 3.5235],\n",
      "        [3.6596, 3.5799, 3.6542, 3.7873, 3.5082],\n",
      "        [3.6159, 3.5272, 3.5958, 3.6252, 3.4801],\n",
      "        [3.4336, 3.4596, 3.3630, 3.5378, 3.4628],\n",
      "        [3.4925, 3.4507, 3.4408, 3.6444, 3.5147],\n",
      "        [3.3507, 3.4930, 3.4858, 3.5030, 3.4742],\n",
      "        [3.4512, 3.3920, 3.4953, 3.5472, 3.5020],\n",
      "        [3.6044, 3.7520, 3.6870, 3.7577, 3.8457],\n",
      "        [3.5233, 3.5526, 3.5278, 3.6385, 3.6103],\n",
      "        [3.3885, 3.5255, 3.3546, 3.5637, 3.4027],\n",
      "        [3.4650, 3.3690, 3.5050, 3.5557, 3.4795],\n",
      "        [3.4186, 3.4875, 3.4685, 3.6713, 3.4437],\n",
      "        [3.4416, 3.4235, 3.4575, 3.5074, 3.4900],\n",
      "        [3.4442, 3.4749, 3.3685, 3.5463, 3.4833],\n",
      "        [3.4860, 3.4213, 3.5031, 3.5807, 3.5268],\n",
      "        [3.6703, 3.6467, 3.6474, 3.7410, 3.8480],\n",
      "        [3.4847, 3.3801, 3.5257, 3.4999, 3.5721],\n",
      "        [3.7090, 3.6742, 3.7155, 3.8135, 3.6844],\n",
      "        [3.3431, 3.5163, 3.3215, 3.5486, 3.3798],\n",
      "        [3.3978, 3.3391, 3.4299, 3.5199, 3.3970],\n",
      "        [3.4484, 3.4746, 3.3685, 3.5520, 3.4913],\n",
      "        [3.3433, 3.3234, 3.3670, 3.4485, 3.3967],\n",
      "        [3.4378, 3.3969, 3.4562, 3.5883, 3.4374],\n",
      "        [3.8729, 3.8623, 3.8166, 4.1168, 3.9238],\n",
      "        [3.6186, 3.6519, 3.6720, 3.7365, 3.6308],\n",
      "        [3.3542, 3.5054, 3.4960, 3.5002, 3.4702],\n",
      "        [3.4854, 3.4287, 3.5440, 3.6107, 3.5522],\n",
      "        [3.4806, 3.3987, 3.5153, 3.5670, 3.5012],\n",
      "        [3.5178, 3.5456, 3.3913, 3.6554, 3.5404]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5647, 3.7673, 3.6475, 3.7427, 3.7626],\n",
      "        [3.6980, 3.6419, 3.6213, 3.7444, 3.7302],\n",
      "        [3.5016, 3.5250, 3.3748, 3.6284, 3.5126],\n",
      "        [3.5968, 3.6005, 3.6325, 3.7652, 3.6987],\n",
      "        [3.5163, 3.3662, 3.4898, 3.4958, 3.4476],\n",
      "        [3.3789, 3.6090, 3.4983, 3.4079, 3.6077],\n",
      "        [3.4452, 3.4730, 3.5087, 3.6191, 3.4752],\n",
      "        [3.5688, 3.5162, 3.5277, 3.7232, 3.5754],\n",
      "        [3.5606, 3.6779, 3.5642, 3.7083, 3.7367],\n",
      "        [3.4878, 3.4101, 3.5230, 3.5836, 3.5173],\n",
      "        [3.3482, 3.4773, 3.4750, 3.4952, 3.4529],\n",
      "        [3.4235, 3.4287, 3.2894, 3.6065, 3.3686],\n",
      "        [3.6258, 3.5065, 3.6002, 3.7112, 3.5863],\n",
      "        [3.6426, 3.6990, 3.5517, 3.8581, 3.7059],\n",
      "        [3.3527, 3.3908, 3.4421, 3.4875, 3.4195],\n",
      "        [3.8479, 3.8254, 3.7168, 4.1024, 3.8934],\n",
      "        [3.5472, 3.4753, 3.6045, 3.6610, 3.6023],\n",
      "        [3.6303, 3.6304, 3.5422, 3.7456, 3.6506],\n",
      "        [3.5004, 3.5218, 3.3781, 3.6282, 3.5138],\n",
      "        [3.7297, 3.6208, 3.7344, 3.8112, 3.5680],\n",
      "        [3.8885, 3.9388, 3.5719, 3.8178, 3.6278],\n",
      "        [3.4237, 3.4595, 3.3617, 3.5242, 3.4578],\n",
      "        [3.8340, 3.6478, 3.7400, 3.9742, 3.8202],\n",
      "        [3.4793, 3.3809, 3.4926, 3.5290, 3.4742],\n",
      "        [3.3753, 3.3523, 3.4246, 3.4981, 3.4132],\n",
      "        [3.4733, 3.7222, 3.5808, 3.7106, 3.7309],\n",
      "        [4.0377, 4.2020, 3.7823, 4.0149, 3.8095],\n",
      "        [3.4651, 3.4916, 3.4956, 3.6420, 3.5819],\n",
      "        [3.4780, 3.4386, 3.4126, 3.6212, 3.4824],\n",
      "        [3.4478, 3.6699, 3.6039, 3.6728, 3.6752],\n",
      "        [3.5040, 3.4506, 3.5545, 3.6368, 3.5677],\n",
      "        [3.5139, 3.7596, 3.6851, 3.6870, 3.6036],\n",
      "        [3.6039, 3.5750, 3.5535, 3.8098, 3.5940],\n",
      "        [3.6389, 3.6530, 3.5645, 3.6690, 3.6247],\n",
      "        [3.5544, 3.7950, 3.5610, 3.8208, 3.7378],\n",
      "        [3.4940, 3.3776, 3.3974, 3.6563, 3.4237],\n",
      "        [3.6390, 3.5155, 3.5530, 3.5791, 3.4700],\n",
      "        [3.6168, 3.6366, 3.6738, 3.6633, 3.5283],\n",
      "        [3.6039, 3.5750, 3.5535, 3.8098, 3.5940],\n",
      "        [3.7393, 3.6474, 3.6945, 3.8999, 3.7274],\n",
      "        [3.5062, 3.4062, 3.5581, 3.6346, 3.6349],\n",
      "        [3.5865, 3.4745, 3.5705, 3.5763, 3.5066],\n",
      "        [3.6277, 3.7227, 3.6711, 3.7691, 3.7812],\n",
      "        [3.3859, 3.3038, 3.3916, 3.5163, 3.3834],\n",
      "        [3.4798, 3.6271, 3.5790, 3.5451, 3.6359],\n",
      "        [3.7159, 3.6500, 3.6267, 3.7692, 3.7336],\n",
      "        [3.5934, 3.7187, 3.6598, 3.7355, 3.6303],\n",
      "        [3.6074, 3.5832, 3.4660, 3.7281, 3.6849],\n",
      "        [3.4274, 3.4705, 3.3757, 3.5209, 3.4818],\n",
      "        [3.5603, 3.6476, 3.5797, 3.6642, 3.4922],\n",
      "        [3.2617, 3.3390, 3.3270, 3.3531, 3.3552],\n",
      "        [3.3419, 3.4207, 3.4472, 3.4820, 3.4221],\n",
      "        [3.4308, 3.2968, 3.3721, 3.5146, 3.3752],\n",
      "        [3.3753, 3.3635, 3.4353, 3.5174, 3.4233],\n",
      "        [3.8585, 3.7395, 3.7574, 3.9604, 3.8849],\n",
      "        [3.6445, 3.5588, 3.6392, 3.8101, 3.5643],\n",
      "        [3.3528, 3.3835, 3.4358, 3.4869, 3.4157],\n",
      "        [3.6402, 3.6954, 3.5454, 3.8486, 3.6944],\n",
      "        [4.0143, 4.1550, 3.7307, 3.9333, 3.8116],\n",
      "        [3.6792, 3.7799, 3.6395, 3.8608, 3.7670],\n",
      "        [3.4378, 3.3925, 3.4318, 3.5110, 3.5449],\n",
      "        [3.5588, 3.5828, 3.5156, 3.6944, 3.6475],\n",
      "        [3.9695, 4.0366, 3.7884, 3.9057, 3.8108],\n",
      "        [3.4834, 3.4040, 3.5148, 3.5776, 3.5033]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8503, 3.5980, 3.7213, 4.2293, 4.0491],\n",
      "        [3.3865, 3.3079, 3.3931, 3.5196, 3.3835],\n",
      "        [3.6988, 3.6462, 3.6228, 3.7479, 3.7303],\n",
      "        [3.6483, 3.5223, 3.6261, 3.7509, 3.6022],\n",
      "        [3.8012, 3.7062, 3.7471, 3.9385, 3.8091],\n",
      "        [3.3219, 3.2911, 3.3838, 3.4311, 3.3352],\n",
      "        [3.3910, 3.5867, 3.4052, 3.3596, 3.5402],\n",
      "        [3.4415, 3.3323, 3.4792, 3.5669, 3.5368],\n",
      "        [3.2888, 3.3647, 3.3416, 3.3818, 3.3864],\n",
      "        [3.5929, 3.5531, 3.4355, 3.7286, 3.6755],\n",
      "        [3.5769, 3.7574, 3.6353, 3.7498, 3.7715],\n",
      "        [3.5465, 3.4148, 3.5216, 3.6231, 3.5023],\n",
      "        [3.4384, 3.3966, 3.4334, 3.5144, 3.5450],\n",
      "        [3.4860, 3.4170, 3.5618, 3.6239, 3.5523],\n",
      "        [3.3737, 3.2941, 3.3794, 3.5045, 3.3762],\n",
      "        [3.8859, 3.9544, 3.7326, 3.8189, 3.7722],\n",
      "        [3.6004, 3.4916, 3.5764, 3.6713, 3.5620],\n",
      "        [3.2623, 3.3429, 3.3286, 3.3564, 3.3553],\n",
      "        [3.4613, 3.4127, 3.4567, 3.5391, 3.5552],\n",
      "        [3.4535, 3.4826, 3.5133, 3.6133, 3.4715],\n",
      "        [3.4688, 3.5699, 3.5303, 3.6151, 3.5660],\n",
      "        [3.3447, 3.4158, 3.3654, 3.4455, 3.4337],\n",
      "        [3.4176, 3.6387, 3.5313, 3.4425, 3.6350],\n",
      "        [3.6431, 3.7034, 3.5533, 3.8616, 3.7060],\n",
      "        [3.5201, 3.4583, 3.5964, 3.6615, 3.5961],\n",
      "        [3.7155, 3.7247, 3.6022, 3.7842, 3.8120],\n",
      "        [3.3142, 3.2963, 3.3864, 3.4347, 3.3276],\n",
      "        [3.3891, 3.3197, 3.4013, 3.5201, 3.4015],\n",
      "        [3.4769, 3.4758, 3.5066, 3.6004, 3.6664],\n",
      "        [3.8553, 3.8857, 3.7939, 4.1283, 3.9366],\n",
      "        [3.4896, 3.4562, 3.5183, 3.6116, 3.5398],\n",
      "        [3.2937, 3.3767, 3.3896, 3.4756, 3.4259],\n",
      "        [3.6177, 3.6243, 3.7238, 3.7704, 3.7213],\n",
      "        [3.3520, 3.5018, 3.4883, 3.5104, 3.4745],\n",
      "        [3.6842, 3.7024, 3.5578, 3.7372, 3.7557],\n",
      "        [3.4518, 3.3597, 3.4949, 3.5486, 3.4709],\n",
      "        [3.4884, 3.4143, 3.5245, 3.5869, 3.5175],\n",
      "        [3.6060, 3.5189, 3.5947, 3.7813, 3.5229],\n",
      "        [3.3134, 3.2811, 3.3727, 3.4163, 3.3259],\n",
      "        [3.5008, 3.4357, 3.5439, 3.6058, 3.5705],\n",
      "        [3.3395, 3.3986, 3.3610, 3.4397, 3.4120],\n",
      "        [3.5426, 3.4847, 3.5165, 3.6618, 3.5664],\n",
      "        [3.9022, 3.9392, 3.5892, 3.8220, 3.6353],\n",
      "        [3.2837, 3.4044, 3.5637, 3.4314, 3.5213],\n",
      "        [3.5440, 3.4052, 3.5118, 3.6152, 3.4859],\n",
      "        [3.4120, 3.4556, 3.4123, 3.5344, 3.4816],\n",
      "        [3.8814, 3.6754, 3.7910, 4.0396, 3.8612],\n",
      "        [3.6725, 3.4749, 3.5283, 3.9616, 3.7279],\n",
      "        [3.6116, 3.7944, 3.7007, 3.7769, 3.7841],\n",
      "        [3.5830, 3.5881, 3.7089, 3.7144, 3.6728],\n",
      "        [3.4853, 3.4998, 3.4137, 3.5836, 3.5389],\n",
      "        [3.6546, 3.7125, 3.5475, 3.7137, 3.7109],\n",
      "        [3.7161, 3.6520, 3.6952, 3.8844, 3.9217],\n",
      "        [3.4777, 3.5121, 3.3759, 3.6119, 3.5018],\n",
      "        [3.8089, 3.5229, 3.5978, 4.1038, 3.8708],\n",
      "        [3.6190, 3.7452, 3.5556, 3.5547, 3.6132],\n",
      "        [3.7950, 3.7420, 3.6566, 3.8630, 3.8770],\n",
      "        [3.8008, 3.7067, 3.6669, 3.8609, 3.8069],\n",
      "        [3.7218, 3.6901, 3.6884, 3.8074, 3.9028],\n",
      "        [3.7381, 3.6550, 3.6975, 3.9213, 3.9325],\n",
      "        [3.6165, 3.6791, 3.5271, 3.8263, 3.6647],\n",
      "        [3.4466, 3.4688, 3.3974, 3.5622, 3.5027],\n",
      "        [3.3472, 3.3906, 3.4339, 3.4842, 3.4143],\n",
      "        [3.2833, 3.3567, 3.3348, 3.3778, 3.3752]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4486, 3.6786, 3.6080, 3.6793, 3.6754],\n",
      "        [3.5595, 3.6542, 3.5867, 3.6708, 3.4901],\n",
      "        [3.4179, 3.6425, 3.5337, 3.4455, 3.6349],\n",
      "        [3.6230, 3.6345, 3.5199, 3.6845, 3.7432],\n",
      "        [3.6263, 3.5192, 3.5981, 3.7169, 3.5769],\n",
      "        [3.6105, 3.6219, 3.5195, 3.6781, 3.7508],\n",
      "        [3.3646, 3.3920, 3.4404, 3.5016, 3.4315],\n",
      "        [3.1997, 3.2891, 3.3674, 3.3799, 3.3808],\n",
      "        [3.4985, 3.4341, 3.5225, 3.5938, 3.5319],\n",
      "        [3.4317, 3.3047, 3.3759, 3.5207, 3.3752],\n",
      "        [3.6441, 3.7105, 3.6982, 3.7258, 3.5636],\n",
      "        [3.4581, 3.6097, 3.4990, 3.5794, 3.4959],\n",
      "        [3.4383, 3.4559, 3.4053, 3.5039, 3.4587],\n",
      "        [3.7531, 3.7140, 3.7192, 3.8429, 3.9562],\n",
      "        [3.6085, 3.5913, 3.4701, 3.7344, 3.6852],\n",
      "        [3.5311, 3.4711, 3.5907, 3.6345, 3.5922],\n",
      "        [3.4357, 3.5274, 3.4233, 3.6593, 3.4582],\n",
      "        [3.4284, 3.3147, 3.5112, 3.3872, 3.5598],\n",
      "        [3.4954, 3.4814, 3.5839, 3.5581, 3.6817],\n",
      "        [3.4821, 3.5162, 3.3841, 3.6074, 3.5129],\n",
      "        [3.6347, 3.5255, 3.5501, 3.5788, 3.4732],\n",
      "        [3.4912, 3.7079, 3.6374, 3.7111, 3.7449],\n",
      "        [3.4020, 3.3315, 3.4083, 3.5295, 3.4046],\n",
      "        [3.4840, 3.4578, 3.6048, 3.5265, 3.6800],\n",
      "        [3.3095, 3.2997, 3.3525, 3.4116, 3.3692],\n",
      "        [3.3624, 3.5204, 3.6181, 3.5153, 3.5390],\n",
      "        [3.4920, 3.5065, 3.4589, 3.6471, 3.6322],\n",
      "        [3.4490, 3.4857, 3.4847, 3.6515, 3.5405],\n",
      "        [3.3476, 3.3944, 3.4362, 3.4870, 3.4142],\n",
      "        [3.5162, 3.6929, 3.5029, 3.7698, 3.6306],\n",
      "        [3.6125, 3.6406, 3.6766, 3.7154, 3.6544],\n",
      "        [3.4774, 3.5328, 3.5227, 3.5591, 3.4510],\n",
      "        [3.5359, 3.6539, 3.5705, 3.6495, 3.4737],\n",
      "        [3.3699, 3.4394, 3.3703, 3.4869, 3.4394],\n",
      "        [3.7755, 3.8336, 3.5560, 3.7346, 3.6611],\n",
      "        [3.2869, 3.4468, 3.2584, 3.4992, 3.3202],\n",
      "        [3.3417, 3.4254, 3.4484, 3.4898, 3.4224],\n",
      "        [3.5071, 3.6041, 3.4943, 3.6286, 3.6130],\n",
      "        [3.4895, 3.5332, 3.5402, 3.5972, 3.4619],\n",
      "        [3.3427, 3.4791, 3.4734, 3.4946, 3.4430],\n",
      "        [3.5932, 3.5681, 3.5715, 3.6320, 3.3936],\n",
      "        [3.6504, 3.6352, 3.6659, 3.7836, 3.5790],\n",
      "        [3.2692, 3.3576, 3.3957, 3.4386, 3.4085],\n",
      "        [3.5037, 3.4708, 3.6163, 3.7307, 3.7335],\n",
      "        [3.7650, 3.6625, 3.7038, 3.8689, 3.6281],\n",
      "        [3.4173, 3.4353, 3.5249, 3.6335, 3.5582],\n",
      "        [3.5057, 3.4630, 3.4113, 3.5884, 3.6178],\n",
      "        [3.6799, 3.6279, 3.6306, 3.7477, 3.7822],\n",
      "        [4.0560, 4.1716, 3.7824, 3.9648, 3.8255],\n",
      "        [3.5647, 3.7286, 3.6525, 3.7150, 3.5964],\n",
      "        [4.0620, 4.1825, 3.7868, 3.9737, 3.8342],\n",
      "        [3.8037, 3.5246, 3.6016, 4.1136, 3.8642],\n",
      "        [3.6411, 3.7050, 3.5545, 3.8632, 3.7025],\n",
      "        [3.4606, 3.4046, 3.3528, 3.5381, 3.5698],\n",
      "        [3.4939, 3.6169, 3.4856, 3.5657, 3.5937],\n",
      "        [3.4844, 3.4119, 3.5185, 3.5838, 3.5034],\n",
      "        [3.3890, 3.4053, 3.4620, 3.4695, 3.4423],\n",
      "        [3.5055, 3.6741, 3.4843, 3.4625, 3.5808],\n",
      "        [3.6471, 3.7024, 3.5874, 3.7701, 3.6742],\n",
      "        [3.3543, 3.4812, 3.4792, 3.5134, 3.4572],\n",
      "        [3.5194, 3.5538, 3.3898, 3.6602, 3.5330],\n",
      "        [3.8634, 3.8724, 3.8022, 4.1061, 3.9072],\n",
      "        [3.4390, 3.4003, 3.4357, 3.5174, 3.5450],\n",
      "        [3.5764, 3.7018, 3.6045, 3.6492, 3.6684]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3039, 3.3814, 3.3496, 3.4062, 3.3945],\n",
      "        [3.5355, 3.6344, 3.5239, 3.7259, 3.5489],\n",
      "        [3.4305, 3.4798, 3.3733, 3.5413, 3.4741],\n",
      "        [3.8495, 3.9913, 3.5816, 3.7672, 3.6622],\n",
      "        [3.5881, 3.4850, 3.5398, 3.5677, 3.4114],\n",
      "        [3.3871, 3.3148, 3.3972, 3.5247, 3.3833],\n",
      "        [3.6536, 3.7313, 3.6701, 3.7919, 3.6737],\n",
      "        [3.6078, 3.4909, 3.5918, 3.5724, 3.5681],\n",
      "        [3.3498, 3.4099, 3.4483, 3.4944, 3.4185],\n",
      "        [3.3429, 3.5076, 3.4899, 3.5013, 3.4591],\n",
      "        [3.4093, 3.3691, 3.4419, 3.5312, 3.4145],\n",
      "        [3.5057, 3.6775, 3.4864, 3.4650, 3.5806],\n",
      "        [3.3573, 3.5097, 3.4899, 3.5239, 3.4665],\n",
      "        [3.4428, 3.3357, 3.5224, 3.4169, 3.5671],\n",
      "        [3.5162, 3.5537, 3.4058, 3.6579, 3.5412],\n",
      "        [3.4008, 3.5089, 3.5945, 3.5647, 3.5806],\n",
      "        [3.6504, 3.5416, 3.5605, 3.6031, 3.4913],\n",
      "        [3.5648, 3.5021, 3.6369, 3.6855, 3.6146],\n",
      "        [3.6292, 3.6393, 3.5407, 3.7546, 3.6421],\n",
      "        [3.4843, 3.4400, 3.5082, 3.6012, 3.5323],\n",
      "        [3.5748, 3.6473, 3.5363, 3.7267, 3.6098],\n",
      "        [3.7654, 3.6659, 3.7060, 3.8713, 3.6281],\n",
      "        [4.0624, 4.1860, 3.7891, 3.9762, 3.8341],\n",
      "        [3.7521, 3.6791, 3.7294, 3.8678, 3.7297],\n",
      "        [3.4659, 3.4463, 3.6378, 3.4650, 3.6902],\n",
      "        [3.4854, 3.3802, 3.5126, 3.6064, 3.6149],\n",
      "        [3.4698, 3.5554, 3.4664, 3.6342, 3.5962],\n",
      "        [3.4608, 3.4864, 3.4124, 3.5781, 3.5181],\n",
      "        [3.6248, 3.8556, 3.7205, 3.8144, 3.8160],\n",
      "        [3.3390, 3.4273, 3.4544, 3.4916, 3.4190],\n",
      "        [3.4729, 3.4742, 3.6051, 3.6921, 3.6879],\n",
      "        [3.6915, 3.7521, 3.7451, 3.7578, 3.5168],\n",
      "        [3.4001, 3.2876, 3.4906, 3.3557, 3.5358],\n",
      "        [3.4744, 3.6634, 3.5427, 3.6002, 3.4497],\n",
      "        [3.3727, 3.3811, 3.3959, 3.5009, 3.4223],\n",
      "        [3.4413, 3.4489, 3.4089, 3.6145, 3.4929],\n",
      "        [3.4505, 3.4388, 3.4520, 3.5174, 3.4944],\n",
      "        [3.4547, 3.5627, 3.5294, 3.5090, 3.4772],\n",
      "        [3.9039, 3.5851, 3.7038, 4.1907, 4.0629],\n",
      "        [3.5098, 3.5330, 3.7004, 3.6692, 3.6893],\n",
      "        [3.8719, 3.8798, 3.8179, 4.1425, 3.9330],\n",
      "        [3.7524, 3.5844, 3.7137, 3.9134, 3.7183],\n",
      "        [3.3918, 3.3264, 3.4038, 3.5260, 3.3994],\n",
      "        [3.6182, 3.5433, 3.6025, 3.6379, 3.4804],\n",
      "        [3.7965, 3.7082, 3.7541, 3.9574, 3.8017],\n",
      "        [3.5322, 3.4702, 3.5933, 3.6476, 3.5866],\n",
      "        [3.3728, 3.5100, 3.5936, 3.5447, 3.5559],\n",
      "        [3.6694, 3.7059, 3.6949, 3.7335, 3.5396],\n",
      "        [3.8565, 3.8933, 3.7993, 4.1337, 3.9368],\n",
      "        [3.5426, 3.8075, 3.6147, 3.8204, 3.7474],\n",
      "        [3.5991, 3.5760, 3.6313, 3.6948, 3.6255],\n",
      "        [3.4466, 3.3986, 3.3423, 3.5282, 3.5592],\n",
      "        [3.5151, 3.7715, 3.6913, 3.6959, 3.6038],\n",
      "        [3.5755, 3.5085, 3.6401, 3.6985, 3.6209],\n",
      "        [3.6620, 3.5965, 3.6611, 3.7999, 3.5086],\n",
      "        [3.1888, 3.2950, 3.3758, 3.3680, 3.3656],\n",
      "        [3.3976, 3.4891, 3.5777, 3.5813, 3.5888],\n",
      "        [3.3937, 3.4104, 3.3509, 3.5664, 3.4310],\n",
      "        [3.4052, 3.5775, 3.5239, 3.6027, 3.6795],\n",
      "        [3.5448, 3.4124, 3.5159, 3.6204, 3.4857],\n",
      "        [3.4696, 3.5115, 3.5147, 3.7013, 3.5274],\n",
      "        [3.8468, 3.5869, 3.7198, 4.2344, 4.0480],\n",
      "        [3.3915, 3.5937, 3.4095, 3.3649, 3.5400],\n",
      "        [3.4571, 3.4689, 3.4147, 3.5304, 3.4706]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4813, 3.6430, 3.5867, 3.5566, 3.6356],\n",
      "        [3.5448, 3.6060, 3.4349, 3.5997, 3.5718],\n",
      "        [3.8420, 3.7957, 3.7387, 4.0396, 3.8596],\n",
      "        [3.4148, 3.5075, 3.4119, 3.6381, 3.4487],\n",
      "        [3.5264, 3.5392, 3.6996, 3.6905, 3.6932],\n",
      "        [3.6195, 3.6526, 3.5609, 3.6068, 3.6052],\n",
      "        [3.4488, 3.4761, 3.4187, 3.5180, 3.4685],\n",
      "        [3.6736, 3.5815, 3.7601, 3.6978, 3.5204],\n",
      "        [3.6015, 3.5033, 3.5823, 3.6793, 3.5615],\n",
      "        [3.6678, 3.5987, 3.6274, 3.7815, 3.8239],\n",
      "        [3.4100, 3.5036, 3.5832, 3.6246, 3.6197],\n",
      "        [3.8742, 3.9428, 3.6046, 3.8297, 3.6701],\n",
      "        [3.3229, 3.3021, 3.3897, 3.4390, 3.3348],\n",
      "        [3.3253, 3.3221, 3.4042, 3.4641, 3.3396],\n",
      "        [3.6269, 3.5271, 3.6017, 3.7219, 3.5764],\n",
      "        [3.7206, 3.6895, 3.7619, 3.9367, 3.6680],\n",
      "        [3.6245, 3.6755, 3.5659, 3.7310, 3.6257],\n",
      "        [3.6979, 3.6634, 3.7191, 3.7582, 3.7577],\n",
      "        [3.5849, 3.6171, 3.5165, 3.7072, 3.6910],\n",
      "        [3.3324, 3.4088, 3.3653, 3.4429, 3.4287],\n",
      "        [3.7405, 3.8503, 3.6781, 3.9013, 3.8663],\n",
      "        [3.6119, 3.6603, 3.6896, 3.7448, 3.6428],\n",
      "        [3.5164, 3.5581, 3.4073, 3.6604, 3.5409],\n",
      "        [3.4626, 3.4239, 3.4627, 3.5470, 3.5548],\n",
      "        [3.3110, 3.4066, 3.3999, 3.4933, 3.4395],\n",
      "        [3.4541, 3.3631, 3.4482, 3.5492, 3.5986],\n",
      "        [3.8503, 3.8419, 3.7265, 4.1140, 3.8940],\n",
      "        [3.4532, 3.5061, 3.3858, 3.5743, 3.4936],\n",
      "        [3.4736, 3.5289, 3.5223, 3.5549, 3.4489],\n",
      "        [3.3973, 3.3710, 3.4477, 3.5328, 3.4008],\n",
      "        [3.4289, 3.4858, 3.3830, 3.5319, 3.4815],\n",
      "        [3.3480, 3.4604, 3.6190, 3.4933, 3.5942],\n",
      "        [3.5724, 3.7551, 3.6267, 3.7537, 3.7659],\n",
      "        [3.6882, 3.7368, 3.7520, 3.7425, 3.4974],\n",
      "        [3.3041, 3.3856, 3.3512, 3.4087, 3.3943],\n",
      "        [3.6697, 3.7104, 3.6966, 3.7362, 3.5393],\n",
      "        [3.4827, 3.5259, 3.3882, 3.6214, 3.5091],\n",
      "        [3.5300, 3.7997, 3.5620, 3.8230, 3.7184],\n",
      "        [3.3400, 3.4512, 3.4638, 3.4969, 3.4259],\n",
      "        [3.7322, 3.7064, 3.7221, 3.8080, 3.8153],\n",
      "        [3.7820, 3.8111, 3.7345, 3.8749, 3.8789],\n",
      "        [3.5357, 3.6390, 3.5256, 3.7284, 3.5486],\n",
      "        [3.7685, 3.6637, 3.7181, 3.8378, 3.8988],\n",
      "        [3.5055, 3.5435, 3.4783, 3.6848, 3.5846],\n",
      "        [3.5284, 3.4736, 3.6024, 3.6772, 3.5969],\n",
      "        [3.7543, 3.4258, 3.5935, 3.9680, 3.8824],\n",
      "        [3.8229, 3.8351, 3.7481, 4.0538, 3.8341],\n",
      "        [3.3422, 3.4896, 3.4762, 3.4993, 3.4427],\n",
      "        [3.8440, 3.7390, 3.7189, 3.9269, 3.8307],\n",
      "        [3.8908, 3.9544, 3.5802, 3.8289, 3.6280],\n",
      "        [3.3512, 3.3421, 3.4119, 3.4771, 3.3883],\n",
      "        [3.6440, 3.7153, 3.5593, 3.8696, 3.7055],\n",
      "        [3.3916, 3.4334, 3.3478, 3.5684, 3.4401],\n",
      "        [3.4773, 3.5651, 3.5587, 3.6129, 3.6731],\n",
      "        [3.6440, 3.7153, 3.5593, 3.8696, 3.7055],\n",
      "        [3.8106, 3.6782, 3.6798, 3.9668, 3.7715],\n",
      "        [3.5028, 3.5492, 3.3917, 3.6469, 3.5248],\n",
      "        [3.5422, 3.6007, 3.4195, 3.5970, 3.5642],\n",
      "        [3.7185, 3.6369, 3.6670, 3.7979, 3.8616],\n",
      "        [3.3704, 3.4469, 3.3739, 3.4917, 3.4390],\n",
      "        [3.3339, 3.4202, 3.3679, 3.4501, 3.4199],\n",
      "        [3.3982, 3.4597, 3.3729, 3.5135, 3.4500],\n",
      "        [3.5985, 3.5739, 3.5502, 3.8028, 3.5871],\n",
      "        [3.4249, 3.4140, 3.4995, 3.5979, 3.5211]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3741, 3.4275, 3.4577, 3.5171, 3.4536],\n",
      "        [3.3915, 3.6024, 3.4126, 3.3704, 3.5389],\n",
      "        [3.7709, 3.7139, 3.7160, 3.9364, 3.7112],\n",
      "        [3.5294, 3.4804, 3.6053, 3.6761, 3.6000],\n",
      "        [3.4986, 3.4173, 3.5549, 3.6360, 3.6259],\n",
      "        [3.3651, 3.3777, 3.4308, 3.5048, 3.4116],\n",
      "        [3.4309, 3.4224, 3.5039, 3.5864, 3.5169],\n",
      "        [3.3703, 3.4287, 3.4574, 3.5102, 3.4457],\n",
      "        [3.6943, 3.6303, 3.6689, 3.8698, 3.6797],\n",
      "        [3.8400, 3.9280, 3.6885, 3.7884, 3.7098],\n",
      "        [3.2515, 3.3542, 3.4001, 3.4257, 3.3986],\n",
      "        [3.7133, 3.7339, 3.5959, 3.7631, 3.7950],\n",
      "        [3.5724, 3.8154, 3.5801, 3.8443, 3.7455],\n",
      "        [3.5716, 3.8065, 3.5623, 3.8372, 3.7241],\n",
      "        [3.5923, 3.5731, 3.4486, 3.7486, 3.6927],\n",
      "        [3.9253, 4.1117, 3.6870, 3.8970, 3.7092],\n",
      "        [3.7322, 3.7112, 3.7237, 3.8110, 3.8146],\n",
      "        [3.4785, 3.5280, 3.3829, 3.6223, 3.5005],\n",
      "        [3.3545, 3.4429, 3.4692, 3.5145, 3.4414],\n",
      "        [3.4829, 3.3973, 3.5083, 3.6029, 3.6270],\n",
      "        [3.4878, 3.4307, 3.5179, 3.5911, 3.5115],\n",
      "        [3.4700, 3.7439, 3.5692, 3.7347, 3.7027],\n",
      "        [3.7965, 3.6428, 3.7464, 3.9583, 3.7646],\n",
      "        [3.4190, 3.6652, 3.5837, 3.6492, 3.6683],\n",
      "        [3.3229, 3.3064, 3.3911, 3.4417, 3.3341],\n",
      "        [3.4173, 3.5157, 3.5884, 3.5911, 3.5988],\n",
      "        [3.5117, 3.4668, 3.5832, 3.6546, 3.5848],\n",
      "        [3.6965, 3.4309, 3.5914, 3.8933, 3.8255],\n",
      "        [3.4703, 3.5205, 3.3842, 3.6011, 3.5005],\n",
      "        [3.4688, 3.3837, 3.4764, 3.5820, 3.6124],\n",
      "        [3.3575, 3.5186, 3.4930, 3.5293, 3.4655],\n",
      "        [3.3598, 3.4026, 3.4440, 3.5150, 3.4214],\n",
      "        [3.3568, 3.4388, 3.3702, 3.4690, 3.4278],\n",
      "        [3.4946, 3.4612, 3.5224, 3.6187, 3.5327],\n",
      "        [3.4879, 3.3944, 3.5307, 3.6115, 3.6143],\n",
      "        [3.6899, 3.6713, 3.6379, 3.8298, 3.8245],\n",
      "        [3.5235, 3.4519, 3.5944, 3.6609, 3.6109],\n",
      "        [3.4745, 3.6726, 3.5457, 3.6057, 3.4487],\n",
      "        [4.0165, 4.1762, 3.7407, 3.9480, 3.8109],\n",
      "        [3.4892, 3.6390, 3.5725, 3.5685, 3.6322],\n",
      "        [3.5135, 3.6253, 3.5089, 3.5843, 3.6079],\n",
      "        [3.5292, 3.8001, 3.6123, 3.7910, 3.7533],\n",
      "        [3.6186, 3.6572, 3.6827, 3.6784, 3.5271],\n",
      "        [3.6196, 3.5515, 3.6018, 3.6499, 3.4779],\n",
      "        [3.6396, 3.5937, 3.6220, 3.6706, 3.4758],\n",
      "        [3.5989, 3.4885, 3.5868, 3.5765, 3.5544],\n",
      "        [3.7053, 3.6888, 3.7468, 3.9213, 3.6557],\n",
      "        [3.6318, 3.7342, 3.7012, 3.8074, 3.6581],\n",
      "        [3.5169, 3.7051, 3.5081, 3.7778, 3.6294],\n",
      "        [3.3651, 3.4041, 3.4454, 3.5092, 3.4304],\n",
      "        [3.6012, 3.6415, 3.5303, 3.7338, 3.6975],\n",
      "        [3.5750, 3.6567, 3.5395, 3.7321, 3.6088],\n",
      "        [3.3822, 3.4586, 3.3782, 3.4966, 3.4516],\n",
      "        [3.4252, 3.7054, 3.5558, 3.6747, 3.6913],\n",
      "        [3.7055, 3.6850, 3.7106, 3.8230, 3.6690],\n",
      "        [3.7188, 3.5370, 3.5594, 3.7072, 3.6799],\n",
      "        [3.8864, 3.9486, 3.5747, 3.8153, 3.6322],\n",
      "        [3.6080, 3.5000, 3.5948, 3.5781, 3.5670],\n",
      "        [3.4238, 3.4415, 3.5182, 3.6202, 3.5366],\n",
      "        [3.4932, 3.5360, 3.3873, 3.6336, 3.5123],\n",
      "        [3.5345, 3.4853, 3.5254, 3.6445, 3.5666],\n",
      "        [3.4011, 3.4740, 3.6201, 3.5665, 3.5942],\n",
      "        [3.4831, 3.4921, 3.4758, 3.5814, 3.5289],\n",
      "        [3.6745, 3.4965, 3.5388, 3.6666, 3.6275]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6267, 3.5367, 3.6042, 3.7288, 3.5748],\n",
      "        [3.4738, 3.5277, 3.3965, 3.6097, 3.5107],\n",
      "        [3.2897, 3.3845, 3.3501, 3.3959, 3.3845],\n",
      "        [3.4286, 3.6156, 3.5350, 3.6419, 3.6605],\n",
      "        [3.2781, 3.3718, 3.3429, 3.3837, 3.3637],\n",
      "        [3.6847, 3.8853, 3.6558, 3.9238, 3.8304],\n",
      "        [3.5417, 3.4937, 3.6107, 3.6686, 3.5931],\n",
      "        [3.4675, 3.5131, 3.5070, 3.6463, 3.6024],\n",
      "        [3.7134, 3.7279, 3.7386, 3.8160, 3.9245],\n",
      "        [3.4769, 3.5240, 3.3898, 3.5972, 3.5130],\n",
      "        [3.8871, 3.9759, 3.7420, 3.8341, 3.7703],\n",
      "        [3.4998, 3.5208, 3.4551, 3.6560, 3.6412],\n",
      "        [3.6472, 3.6878, 3.6763, 3.7936, 3.6408],\n",
      "        [3.6431, 3.6982, 3.5803, 3.7635, 3.6624],\n",
      "        [3.6696, 3.6390, 3.6378, 3.8061, 3.7979],\n",
      "        [3.4758, 3.6765, 3.4959, 3.4580, 3.6111],\n",
      "        [3.3789, 3.3458, 3.4094, 3.5225, 3.3922],\n",
      "        [3.6486, 3.4194, 3.4351, 3.5708, 3.6063],\n",
      "        [3.3951, 3.4580, 3.3716, 3.5111, 3.4413],\n",
      "        [3.7559, 3.7639, 3.6481, 3.8479, 3.8252],\n",
      "        [3.3732, 3.3590, 3.4187, 3.5173, 3.3999],\n",
      "        [3.4579, 3.5724, 3.5406, 3.6143, 3.5922],\n",
      "        [3.5283, 3.4831, 3.6048, 3.6840, 3.5952],\n",
      "        [3.5649, 3.5161, 3.6408, 3.6950, 3.6127],\n",
      "        [3.4687, 3.3883, 3.4776, 3.5859, 3.6115],\n",
      "        [3.5245, 3.6449, 3.5390, 3.6449, 3.6257],\n",
      "        [3.4035, 3.4759, 3.3843, 3.5170, 3.4561],\n",
      "        [3.3728, 3.3945, 3.4000, 3.5100, 3.4204],\n",
      "        [3.5116, 3.4716, 3.5843, 3.6585, 3.5839],\n",
      "        [3.5053, 3.5572, 3.3918, 3.6690, 3.5270],\n",
      "        [3.7683, 3.6744, 3.7208, 3.8447, 3.8969],\n",
      "        [3.6994, 3.7790, 3.6771, 3.8553, 3.9186],\n",
      "        [3.6003, 3.5303, 3.5976, 3.6237, 3.4927],\n",
      "        [3.3478, 3.4696, 3.6216, 3.4999, 3.5925],\n",
      "        [3.5884, 3.4972, 3.5447, 3.5754, 3.4090],\n",
      "        [3.4837, 3.5291, 3.3802, 3.6193, 3.4933],\n",
      "        [3.4508, 3.4928, 3.6280, 3.6208, 3.6138],\n",
      "        [3.4812, 3.6524, 3.5893, 3.5634, 3.6338],\n",
      "        [3.6590, 3.5595, 3.5552, 3.9254, 3.7301],\n",
      "        [3.3418, 3.4659, 3.4674, 3.5058, 3.4271],\n",
      "        [3.4074, 3.4531, 3.3790, 3.5671, 3.4328],\n",
      "        [3.6463, 3.5845, 3.6495, 3.8281, 3.5625],\n",
      "        [3.5285, 3.4721, 3.5308, 3.6230, 3.5723],\n",
      "        [3.4878, 3.3991, 3.5319, 3.6153, 3.6134],\n",
      "        [3.7253, 3.7636, 3.7870, 3.9977, 4.0250],\n",
      "        [3.5111, 3.6324, 3.5172, 3.6290, 3.6248],\n",
      "        [3.5046, 3.5566, 3.3896, 3.6539, 3.5215],\n",
      "        [3.8319, 3.9039, 3.5716, 3.7783, 3.6533],\n",
      "        [3.4596, 3.5155, 3.3871, 3.5992, 3.4965],\n",
      "        [3.5555, 3.8197, 3.5715, 3.8401, 3.7358],\n",
      "        [3.6366, 3.7679, 3.6947, 3.8079, 3.7967],\n",
      "        [3.4505, 3.4521, 3.4561, 3.5266, 3.4925],\n",
      "        [3.3049, 3.3294, 3.3549, 3.4205, 3.3638],\n",
      "        [3.4173, 3.4528, 3.5311, 3.6450, 3.5559],\n",
      "        [3.6554, 3.7391, 3.6649, 3.7993, 3.6689],\n",
      "        [3.4869, 3.4098, 3.5361, 3.5217, 3.5702],\n",
      "        [3.6754, 3.5772, 3.5849, 3.6449, 3.5181],\n",
      "        [3.5931, 3.5559, 3.6671, 3.7520, 3.5844],\n",
      "        [3.6399, 3.6688, 3.5566, 3.7699, 3.6428],\n",
      "        [3.6455, 3.6749, 3.5627, 3.7708, 3.6542],\n",
      "        [3.4855, 3.4447, 3.5128, 3.5941, 3.5181],\n",
      "        [3.8062, 3.9056, 3.6792, 3.7668, 3.6978],\n",
      "        [3.3626, 3.4133, 3.5607, 3.5219, 3.5319],\n",
      "        [3.5812, 3.7066, 3.5860, 3.8285, 3.6516]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5799, 3.7128, 3.5868, 3.8321, 3.6526],\n",
      "        [3.3510, 3.4810, 3.4740, 3.5161, 3.4445],\n",
      "        [3.4932, 3.6389, 3.5557, 3.5829, 3.6224],\n",
      "        [3.8069, 3.8822, 3.5713, 3.7662, 3.6566],\n",
      "        [3.4172, 3.4929, 3.3825, 3.5452, 3.4667],\n",
      "        [3.4900, 3.5504, 3.5254, 3.5929, 3.5539],\n",
      "        [3.3350, 3.5071, 3.4829, 3.5090, 3.4417],\n",
      "        [3.6221, 3.7066, 3.6705, 3.7901, 3.6862],\n",
      "        [3.2679, 3.3658, 3.3354, 3.3742, 3.3509],\n",
      "        [3.5219, 3.5212, 3.5648, 3.6222, 3.7571],\n",
      "        [3.3453, 3.3561, 3.3788, 3.4730, 3.3942],\n",
      "        [3.5309, 3.5765, 3.5437, 3.6635, 3.6134],\n",
      "        [3.4293, 3.3384, 3.3972, 3.5404, 3.3864],\n",
      "        [3.4426, 3.3534, 3.5272, 3.4293, 3.5642],\n",
      "        [3.5492, 3.6912, 3.5655, 3.7160, 3.7186],\n",
      "        [3.6516, 3.7591, 3.6849, 3.7900, 3.6537],\n",
      "        [3.4566, 3.6066, 3.5919, 3.6314, 3.5675],\n",
      "        [3.2963, 3.3934, 3.3546, 3.4073, 3.3812],\n",
      "        [3.3881, 3.5054, 3.3680, 3.5808, 3.4379],\n",
      "        [3.4276, 3.3628, 3.4366, 3.5519, 3.4026],\n",
      "        [3.4222, 3.5042, 3.4825, 3.4710, 3.4743],\n",
      "        [3.6388, 3.7206, 3.6894, 3.7143, 3.5474],\n",
      "        [3.4919, 3.6311, 3.5477, 3.7917, 3.5517],\n",
      "        [3.5101, 3.4573, 3.5522, 3.5809, 3.5232],\n",
      "        [3.5752, 3.5268, 3.6449, 3.7112, 3.6180],\n",
      "        [3.5009, 3.6040, 3.5683, 3.6503, 3.5120],\n",
      "        [3.5176, 3.6779, 3.5648, 3.6480, 3.4618],\n",
      "        [3.5646, 3.4854, 3.6269, 3.7275, 3.6042],\n",
      "        [3.5045, 3.3772, 3.4829, 3.4961, 3.4247],\n",
      "        [3.3208, 3.4160, 3.3661, 3.4334, 3.4033],\n",
      "        [3.7830, 3.5595, 3.5987, 4.0882, 3.8377],\n",
      "        [3.4853, 3.5404, 3.5306, 3.5773, 3.4544],\n",
      "        [3.4952, 3.5429, 3.5492, 3.6163, 3.4425],\n",
      "        [3.7362, 3.7201, 3.7142, 3.8441, 3.9446],\n",
      "        [3.5064, 3.5597, 3.5376, 3.6142, 3.5638],\n",
      "        [3.3539, 3.4121, 3.4467, 3.5076, 3.4128],\n",
      "        [3.2611, 3.3560, 3.3306, 3.3682, 3.3420],\n",
      "        [3.9715, 4.0670, 3.8008, 3.9278, 3.8084],\n",
      "        [3.6660, 3.7665, 3.5463, 3.7083, 3.6673],\n",
      "        [3.4815, 3.4597, 3.5103, 3.6061, 3.5206],\n",
      "        [3.5411, 3.5454, 3.5265, 3.6755, 3.6336],\n",
      "        [3.2589, 3.3638, 3.4123, 3.4365, 3.4250],\n",
      "        [3.4780, 3.5367, 3.3849, 3.6290, 3.4988],\n",
      "        [3.4590, 3.5583, 3.4584, 3.6472, 3.5885],\n",
      "        [3.6834, 3.6333, 3.7006, 3.7893, 3.5575],\n",
      "        [3.7139, 3.6448, 3.6966, 3.8171, 3.8645],\n",
      "        [3.6013, 3.7173, 3.6181, 3.8457, 3.6576],\n",
      "        [3.5112, 3.8139, 3.6746, 3.6489, 3.5920],\n",
      "        [3.3369, 3.4330, 3.3679, 3.4543, 3.4150],\n",
      "        [3.5306, 3.6090, 3.4039, 3.5923, 3.5493],\n",
      "        [3.6088, 3.6124, 3.4778, 3.7492, 3.6826],\n",
      "        [3.6392, 3.7020, 3.6734, 3.7904, 3.6664],\n",
      "        [3.3787, 3.4816, 3.4145, 3.5948, 3.4394],\n",
      "        [3.6336, 3.6738, 3.5765, 3.6461, 3.6154],\n",
      "        [3.5677, 3.4867, 3.6419, 3.8240, 3.7972],\n",
      "        [3.3128, 3.4013, 3.2582, 3.5025, 3.3398],\n",
      "        [3.8700, 3.7776, 3.7733, 3.9872, 3.8883],\n",
      "        [3.5069, 3.5559, 3.5252, 3.6369, 3.5802],\n",
      "        [3.3739, 3.4592, 3.3741, 3.4957, 3.4339],\n",
      "        [3.3759, 3.5533, 3.5108, 3.5391, 3.5008],\n",
      "        [3.4973, 3.4894, 3.6092, 3.5298, 3.6935],\n",
      "        [3.3889, 3.5161, 3.4312, 3.5488, 3.5153],\n",
      "        [3.4533, 3.3654, 3.4979, 3.5856, 3.5334],\n",
      "        [3.4243, 3.6859, 3.5850, 3.6600, 3.6890]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4568, 3.4704, 3.4590, 3.5341, 3.4991],\n",
      "        [3.4468, 3.4966, 3.4072, 3.5820, 3.4988],\n",
      "        [3.3814, 3.4707, 3.3810, 3.5059, 3.4489],\n",
      "        [3.6988, 3.7871, 3.6789, 3.8614, 3.9167],\n",
      "        [3.8763, 3.9624, 3.7058, 3.8365, 3.6949],\n",
      "        [3.6382, 3.6896, 3.5778, 3.7030, 3.6256],\n",
      "        [3.4716, 3.7416, 3.5837, 3.7254, 3.7203],\n",
      "        [3.7757, 3.8586, 3.5645, 3.7520, 3.6574],\n",
      "        [3.2891, 3.3919, 3.3518, 3.4015, 3.3828],\n",
      "        [3.7024, 3.7131, 3.6769, 3.8018, 3.8684],\n",
      "        [3.6505, 3.6676, 3.6491, 3.7366, 3.7439],\n",
      "        [3.5069, 3.4746, 3.5689, 3.6537, 3.5549],\n",
      "        [3.8789, 3.5788, 3.6860, 4.2055, 4.0375],\n",
      "        [3.3965, 3.3879, 3.4519, 3.5449, 3.3973],\n",
      "        [3.6179, 3.5645, 3.6083, 3.6533, 3.4766],\n",
      "        [3.6888, 3.6280, 3.7429, 3.7649, 3.4866],\n",
      "        [3.7392, 3.6884, 3.6320, 3.8091, 3.7236],\n",
      "        [3.3656, 3.4023, 3.4448, 3.5223, 3.4228],\n",
      "        [3.4287, 3.6280, 3.5459, 3.6427, 3.7030],\n",
      "        [3.6547, 3.7471, 3.6667, 3.8052, 3.6669],\n",
      "        [3.8640, 3.8984, 3.8123, 4.1246, 3.9038],\n",
      "        [3.7553, 3.7719, 3.6500, 3.8538, 3.8234],\n",
      "        [3.9313, 4.0399, 3.7050, 3.8736, 3.6876],\n",
      "        [3.5570, 3.7239, 3.5883, 3.7385, 3.7417],\n",
      "        [3.2403, 3.3494, 3.4068, 3.4196, 3.4093],\n",
      "        [3.4806, 3.5890, 3.5546, 3.6371, 3.5712],\n",
      "        [3.6039, 3.6045, 3.5902, 3.6575, 3.3996],\n",
      "        [3.3365, 3.4366, 3.3686, 3.4568, 3.4141],\n",
      "        [3.4776, 3.5403, 3.3856, 3.6316, 3.4978],\n",
      "        [3.6469, 3.7565, 3.5493, 3.6993, 3.6757],\n",
      "        [3.5917, 3.5178, 3.5902, 3.5999, 3.4984],\n",
      "        [3.7072, 3.7619, 3.7794, 3.9732, 4.0133],\n",
      "        [3.5949, 3.5259, 3.5621, 3.5586, 3.4098],\n",
      "        [3.3978, 3.3457, 3.4095, 3.5552, 3.4087],\n",
      "        [3.4738, 3.5429, 3.5347, 3.7178, 3.5199],\n",
      "        [3.4396, 3.3759, 3.4917, 3.5545, 3.4499],\n",
      "        [3.6430, 3.7332, 3.5635, 3.8823, 3.7017],\n",
      "        [3.4894, 3.3940, 3.4925, 3.5279, 3.4438],\n",
      "        [3.3218, 3.3793, 3.2975, 3.5195, 3.3316],\n",
      "        [3.6543, 3.7438, 3.5581, 3.7341, 3.7068],\n",
      "        [3.5276, 3.6404, 3.5184, 3.7261, 3.5533],\n",
      "        [3.4823, 3.5044, 3.4786, 3.5909, 3.5263],\n",
      "        [3.5020, 3.5575, 3.3860, 3.6515, 3.5087],\n",
      "        [3.8790, 3.9564, 3.5910, 3.8286, 3.6379],\n",
      "        [3.6927, 3.7437, 3.7267, 3.7719, 3.5533],\n",
      "        [3.3751, 3.7155, 3.6000, 3.6065, 3.7092],\n",
      "        [3.6405, 3.7308, 3.5624, 3.8810, 3.6983],\n",
      "        [3.3531, 3.4383, 3.3677, 3.4743, 3.4157],\n",
      "        [3.7936, 3.5834, 3.7266, 3.9305, 3.7444],\n",
      "        [3.3636, 3.4767, 3.3875, 3.4986, 3.4479],\n",
      "        [3.4997, 3.5017, 3.5435, 3.6506, 3.5556],\n",
      "        [3.5132, 3.5154, 3.5428, 3.5483, 3.3728],\n",
      "        [3.4139, 3.5244, 3.4162, 3.6504, 3.4453],\n",
      "        [3.3735, 3.4627, 3.3747, 3.4982, 3.4330],\n",
      "        [3.3660, 3.4928, 3.4817, 3.5291, 3.4643],\n",
      "        [3.4005, 3.3770, 3.4333, 3.5534, 3.4258],\n",
      "        [3.5096, 3.4610, 3.5529, 3.5836, 3.5222],\n",
      "        [3.4880, 3.4984, 3.4694, 3.6756, 3.5476],\n",
      "        [3.6830, 3.6371, 3.7014, 3.7920, 3.5564],\n",
      "        [3.3744, 3.4792, 3.5101, 3.5601, 3.4460],\n",
      "        [3.6318, 3.6790, 3.5363, 3.7212, 3.7349],\n",
      "        [3.3957, 3.3377, 3.4056, 3.5393, 3.3879],\n",
      "        [3.4671, 3.6902, 3.5435, 3.6076, 3.4542],\n",
      "        [3.6182, 3.6156, 3.6915, 3.7013, 3.5517]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5950, 3.7563, 3.6736, 3.7624, 3.6261],\n",
      "        [3.3841, 3.4056, 3.4530, 3.5413, 3.4307],\n",
      "        [3.4731, 3.4504, 3.5334, 3.6320, 3.5824],\n",
      "        [3.4569, 3.6135, 3.5932, 3.6369, 3.5654],\n",
      "        [3.7388, 3.7459, 3.7342, 3.8404, 3.9340],\n",
      "        [3.3818, 3.6480, 3.5123, 3.4404, 3.6088],\n",
      "        [3.8648, 3.9017, 3.8132, 4.1277, 3.9029],\n",
      "        [3.8417, 3.6651, 3.7611, 4.0208, 3.8352],\n",
      "        [3.5051, 3.5681, 3.3939, 3.6774, 3.5241],\n",
      "        [3.5026, 3.6104, 3.4493, 3.7675, 3.4757],\n",
      "        [3.4826, 3.5430, 3.3870, 3.6391, 3.5064],\n",
      "        [3.6065, 3.6024, 3.4586, 3.7633, 3.6940],\n",
      "        [3.6435, 3.7365, 3.5641, 3.8852, 3.7007],\n",
      "        [3.4580, 3.6388, 3.5075, 3.5993, 3.4909],\n",
      "        [3.4323, 3.5044, 3.3880, 3.5537, 3.4850],\n",
      "        [3.4942, 3.4772, 3.5257, 3.6309, 3.5287],\n",
      "        [3.5018, 3.6096, 3.5746, 3.6594, 3.5233],\n",
      "        [3.4698, 3.5807, 3.4729, 3.6517, 3.5911],\n",
      "        [3.3812, 3.3678, 3.4218, 3.5272, 3.4005],\n",
      "        [3.8057, 3.6901, 3.6795, 3.9783, 3.7682],\n",
      "        [3.3938, 3.4799, 3.3767, 3.5226, 3.4513],\n",
      "        [3.4486, 3.7082, 3.6171, 3.6999, 3.6703],\n",
      "        [3.3501, 3.4705, 3.4707, 3.5258, 3.4398],\n",
      "        [3.6408, 3.6016, 3.6138, 3.7580, 3.7713],\n",
      "        [3.6129, 3.5551, 3.5145, 3.8353, 3.6551],\n",
      "        [3.3595, 3.5477, 3.5056, 3.5451, 3.4811],\n",
      "        [3.5603, 3.5284, 3.6416, 3.7025, 3.6074],\n",
      "        [3.7756, 3.7601, 3.6578, 3.8845, 3.8461],\n",
      "        [3.5371, 3.6512, 3.5243, 3.7260, 3.5571],\n",
      "        [3.2811, 3.3862, 3.3468, 3.3982, 3.3713],\n",
      "        [3.7399, 3.6917, 3.6326, 3.8120, 3.7226],\n",
      "        [3.4251, 3.4551, 3.2731, 3.6328, 3.3401],\n",
      "        [3.8872, 4.0734, 3.6486, 3.8565, 3.6534],\n",
      "        [3.6072, 3.5512, 3.6055, 3.8043, 3.5180],\n",
      "        [3.5964, 3.6966, 3.5328, 3.6925, 3.6161],\n",
      "        [3.3681, 3.4754, 3.5067, 3.5487, 3.4479],\n",
      "        [3.3431, 3.5067, 3.4820, 3.5147, 3.4382],\n",
      "        [3.4547, 3.5369, 3.3963, 3.6020, 3.4899],\n",
      "        [3.4093, 3.3934, 3.4483, 3.5487, 3.4098],\n",
      "        [3.3896, 3.3508, 3.4117, 3.5425, 3.3965],\n",
      "        [3.8509, 3.8631, 3.7332, 4.1306, 3.8900],\n",
      "        [3.4789, 3.5384, 3.3887, 3.6204, 3.5071],\n",
      "        [3.6816, 3.5196, 3.5586, 3.9350, 3.7167],\n",
      "        [3.3806, 3.4026, 3.3402, 3.5705, 3.3392],\n",
      "        [3.2715, 3.3766, 3.4120, 3.4583, 3.4194],\n",
      "        [3.6963, 3.4467, 3.5948, 3.9060, 3.8219],\n",
      "        [3.6155, 3.4076, 3.4401, 3.5988, 3.5582],\n",
      "        [3.6101, 3.8326, 3.7136, 3.7970, 3.7729],\n",
      "        [3.6319, 3.7504, 3.7052, 3.8201, 3.6547],\n",
      "        [3.6379, 3.7379, 3.5355, 3.7216, 3.6801],\n",
      "        [3.6435, 3.7365, 3.5641, 3.8852, 3.7007],\n",
      "        [3.3910, 3.4644, 3.3541, 3.5802, 3.4376],\n",
      "        [3.5030, 3.4738, 3.5491, 3.6273, 3.5702],\n",
      "        [3.6090, 3.5320, 3.5943, 3.7121, 3.5596],\n",
      "        [3.7549, 3.7856, 3.7232, 3.8360, 3.7908],\n",
      "        [3.4718, 3.5266, 3.5011, 3.5612, 3.5348],\n",
      "        [3.3469, 3.5015, 3.4818, 3.5283, 3.4456],\n",
      "        [3.5046, 3.5413, 3.3617, 3.6568, 3.4116],\n",
      "        [3.5494, 3.5993, 3.4893, 3.6866, 3.6499],\n",
      "        [3.4610, 3.4627, 3.4188, 3.6347, 3.4672],\n",
      "        [3.3972, 3.4881, 3.3856, 3.5309, 3.4595],\n",
      "        [3.7969, 3.7400, 3.7553, 3.9711, 3.7916],\n",
      "        [3.3420, 3.4528, 3.4568, 3.5097, 3.4175],\n",
      "        [3.4392, 3.3529, 3.4035, 3.5479, 3.3928]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4883, 3.8055, 3.6826, 3.6900, 3.5735],\n",
      "        [3.3922, 3.4660, 3.5265, 3.5808, 3.4132],\n",
      "        [3.5229, 3.4491, 3.5828, 3.6822, 3.6340],\n",
      "        [3.4781, 3.5376, 3.3923, 3.6087, 3.5091],\n",
      "        [3.4986, 3.7727, 3.5907, 3.7733, 3.7219],\n",
      "        [3.7424, 3.8720, 3.6834, 3.9209, 3.8555],\n",
      "        [3.4946, 3.6970, 3.4819, 3.7608, 3.5997],\n",
      "        [3.5536, 3.5198, 3.6198, 3.6962, 3.6079],\n",
      "        [3.4955, 3.6487, 3.4946, 3.5889, 3.5874],\n",
      "        [3.6803, 3.7811, 3.5345, 3.7052, 3.6510],\n",
      "        [3.4844, 3.4155, 3.5122, 3.6185, 3.6222],\n",
      "        [3.7927, 3.7316, 3.7376, 3.9600, 3.6768],\n",
      "        [3.8439, 3.6679, 3.7618, 4.0241, 3.8343],\n",
      "        [3.9825, 4.1345, 3.7291, 3.9315, 3.7563],\n",
      "        [3.4397, 3.7336, 3.5757, 3.6879, 3.7106],\n",
      "        [3.4462, 3.5125, 3.5173, 3.6360, 3.4577],\n",
      "        [3.3910, 3.3536, 3.4122, 3.5455, 3.3954],\n",
      "        [3.5546, 3.7320, 3.5524, 3.8198, 3.6440],\n",
      "        [3.6861, 3.8998, 3.6587, 3.9360, 3.8263],\n",
      "        [3.4243, 3.4437, 3.4898, 3.5966, 3.4252],\n",
      "        [3.3154, 3.4253, 3.3713, 3.4397, 3.4037],\n",
      "        [3.7696, 3.6903, 3.7236, 3.8566, 3.8926],\n",
      "        [3.5192, 3.6878, 3.5666, 3.6565, 3.4586],\n",
      "        [3.6420, 3.6912, 3.5776, 3.6989, 3.6192],\n",
      "        [3.6267, 3.7108, 3.6066, 3.8074, 3.8038],\n",
      "        [3.4316, 3.3698, 3.4337, 3.5657, 3.3985],\n",
      "        [3.7361, 3.6658, 3.7396, 3.8602, 3.5830],\n",
      "        [3.3782, 3.4324, 3.4559, 3.5282, 3.4388],\n",
      "        [3.5373, 3.7872, 3.6990, 3.7859, 3.7755],\n",
      "        [3.3920, 3.5001, 3.4072, 3.6021, 3.4408],\n",
      "        [3.4217, 3.4980, 3.3812, 3.5522, 3.4707],\n",
      "        [3.4793, 3.4612, 3.5181, 3.6180, 3.5181],\n",
      "        [3.5011, 3.5352, 3.4578, 3.6673, 3.6371],\n",
      "        [3.8079, 3.6929, 3.6802, 3.9816, 3.7673],\n",
      "        [3.4804, 3.5296, 3.4238, 3.6140, 3.5241],\n",
      "        [3.3610, 3.5504, 3.5061, 3.5484, 3.4801],\n",
      "        [3.6092, 3.5188, 3.5984, 3.5938, 3.5620],\n",
      "        [3.7908, 3.7782, 3.6647, 3.8775, 3.8650],\n",
      "        [3.4731, 3.5453, 3.5322, 3.7206, 3.4978],\n",
      "        [3.7980, 3.7557, 3.7388, 3.9968, 3.7390],\n",
      "        [3.7245, 3.7276, 3.7005, 3.8343, 3.8968],\n",
      "        [3.4142, 3.4892, 3.4232, 3.5603, 3.4758],\n",
      "        [3.3772, 3.7219, 3.6012, 3.6124, 3.7071],\n",
      "        [3.4649, 3.5331, 3.3830, 3.6187, 3.4842],\n",
      "        [3.4975, 3.4652, 3.5264, 3.6155, 3.5256],\n",
      "        [3.5071, 3.4955, 3.5338, 3.5290, 3.3621],\n",
      "        [3.5082, 3.5692, 3.5394, 3.6228, 3.5607],\n",
      "        [3.4914, 3.3999, 3.4934, 3.5337, 3.4418],\n",
      "        [3.8047, 3.7421, 3.7608, 3.9658, 3.8043],\n",
      "        [3.3491, 3.4833, 3.6243, 3.5115, 3.5886],\n",
      "        [3.4484, 3.5782, 3.7263, 3.6212, 3.6936],\n",
      "        [3.5980, 3.6994, 3.5333, 3.6956, 3.6151],\n",
      "        [3.6502, 3.6330, 3.7085, 3.7339, 3.5281],\n",
      "        [3.7327, 3.6612, 3.7483, 3.8418, 3.5614],\n",
      "        [3.4447, 3.6792, 3.5151, 3.5726, 3.4378],\n",
      "        [3.5208, 3.5889, 3.4042, 3.6883, 3.5346],\n",
      "        [3.4830, 3.4694, 3.5120, 3.6145, 3.5174],\n",
      "        [3.5131, 3.5411, 3.4545, 3.6953, 3.5408],\n",
      "        [3.3510, 3.4697, 3.4668, 3.5208, 3.4337],\n",
      "        [3.4773, 3.4019, 3.4923, 3.6114, 3.6128],\n",
      "        [3.6020, 3.6549, 3.5470, 3.6034, 3.5814],\n",
      "        [3.7128, 3.6774, 3.7072, 3.7283, 3.4887],\n",
      "        [3.5463, 3.4397, 3.5223, 3.6412, 3.4801],\n",
      "        [3.7097, 3.7682, 3.7806, 3.9794, 4.0113]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6334, 3.7665, 3.6860, 3.8024, 3.7741],\n",
      "        [3.3546, 3.4639, 3.3893, 3.5333, 3.4102],\n",
      "        [3.4963, 3.5566, 3.3912, 3.6515, 3.5064],\n",
      "        [3.6511, 3.7357, 3.5970, 3.7967, 3.6669],\n",
      "        [3.4777, 3.5112, 3.4393, 3.6446, 3.4901],\n",
      "        [3.3906, 3.3439, 3.4041, 3.5473, 3.3763],\n",
      "        [3.3479, 3.4396, 3.4502, 3.5139, 3.4114],\n",
      "        [3.6473, 3.7419, 3.5649, 3.8912, 3.6984],\n",
      "        [3.5320, 3.4993, 3.6075, 3.6983, 3.5902],\n",
      "        [3.6449, 3.5559, 3.5658, 3.6119, 3.4634],\n",
      "        [3.3599, 3.4539, 3.4601, 3.5280, 3.4368],\n",
      "        [3.8178, 3.7914, 3.7126, 4.0214, 3.8258],\n",
      "        [3.4370, 3.4537, 3.5120, 3.6290, 3.5258],\n",
      "        [3.3408, 3.4445, 3.3700, 3.4654, 3.4111],\n",
      "        [3.6748, 3.7452, 3.5949, 3.8609, 3.8559],\n",
      "        [3.6596, 3.7241, 3.5858, 3.8332, 3.7433],\n",
      "        [3.4079, 3.4730, 3.3850, 3.5901, 3.4249],\n",
      "        [3.3543, 3.5428, 3.5009, 3.5309, 3.4582],\n",
      "        [3.5161, 3.5821, 3.4097, 3.6818, 3.5291],\n",
      "        [3.3515, 3.4268, 3.4453, 3.5125, 3.4072],\n",
      "        [3.4940, 3.5656, 3.5496, 3.6234, 3.4547],\n",
      "        [3.3885, 3.3560, 3.4102, 3.5448, 3.3867],\n",
      "        [3.4971, 3.4605, 3.5233, 3.6128, 3.5160],\n",
      "        [3.5935, 3.7564, 3.6723, 3.7657, 3.6131],\n",
      "        [3.5987, 3.5892, 3.4481, 3.7573, 3.6692],\n",
      "        [3.5627, 3.7429, 3.5987, 3.7506, 3.7400],\n",
      "        [3.6954, 3.8245, 3.6634, 3.9109, 3.7643],\n",
      "        [3.4819, 3.5408, 3.5078, 3.6108, 3.5483],\n",
      "        [3.5213, 3.4069, 3.5023, 3.5277, 3.4408],\n",
      "        [3.7811, 3.8669, 3.5661, 3.7605, 3.6544],\n",
      "        [3.6533, 3.6682, 3.6773, 3.8097, 3.5714],\n",
      "        [3.5791, 3.7561, 3.6833, 3.7280, 3.6878],\n",
      "        [3.4796, 3.4042, 3.4926, 3.6140, 3.6117],\n",
      "        [3.4108, 3.4464, 3.3837, 3.5763, 3.4203],\n",
      "        [3.6334, 3.6720, 3.7080, 3.7215, 3.5329],\n",
      "        [3.4916, 3.4151, 3.5348, 3.6296, 3.6084],\n",
      "        [3.5806, 3.5731, 3.6390, 3.7326, 3.5937],\n",
      "        [3.3961, 3.3883, 3.3139, 3.5774, 3.3361],\n",
      "        [3.7320, 3.8334, 3.7834, 3.8344, 3.5759],\n",
      "        [3.4959, 3.4207, 3.5374, 3.6329, 3.6148],\n",
      "        [3.7155, 3.7564, 3.7159, 3.8360, 3.8821],\n",
      "        [4.0209, 4.1581, 3.7932, 3.9818, 3.7616],\n",
      "        [3.4892, 3.4122, 3.4035, 3.6844, 3.4113],\n",
      "        [3.6334, 3.7665, 3.6860, 3.8024, 3.7741],\n",
      "        [3.5900, 3.4611, 3.7490, 3.7247, 3.6707],\n",
      "        [3.9816, 3.6520, 3.7847, 4.3086, 4.1307],\n",
      "        [3.4005, 3.4873, 3.3793, 3.5410, 3.4474],\n",
      "        [3.5161, 3.5821, 3.4097, 3.6818, 3.5291],\n",
      "        [3.5195, 3.5834, 3.4126, 3.6811, 3.5341],\n",
      "        [3.5515, 3.4423, 3.5112, 3.6515, 3.4716],\n",
      "        [3.4819, 3.5649, 3.5321, 3.5853, 3.4439],\n",
      "        [3.5154, 3.5833, 3.4051, 3.6854, 3.5314],\n",
      "        [3.3262, 3.3873, 3.2990, 3.5279, 3.3286],\n",
      "        [3.5048, 3.5625, 3.3905, 3.6597, 3.5067],\n",
      "        [3.5354, 3.6979, 3.4988, 3.6958, 3.5819],\n",
      "        [3.4430, 3.5197, 3.3829, 3.5895, 3.4686],\n",
      "        [3.4289, 3.5175, 3.4849, 3.4830, 3.4764],\n",
      "        [3.6517, 3.6170, 3.6640, 3.8102, 3.4963],\n",
      "        [3.4894, 3.4720, 3.4961, 3.5959, 3.5741],\n",
      "        [3.3655, 3.4185, 3.4503, 3.5227, 3.4113],\n",
      "        [3.3677, 3.4762, 3.5015, 3.5489, 3.4403],\n",
      "        [3.5130, 3.5811, 3.3962, 3.6781, 3.5271],\n",
      "        [3.4948, 3.4875, 3.5264, 3.6283, 3.5254],\n",
      "        [3.3454, 3.4816, 3.4704, 3.5200, 3.4222]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6497, 3.6847, 3.7403, 3.8309, 3.7682],\n",
      "        [3.5170, 3.5654, 3.5340, 3.6204, 3.5579],\n",
      "        [3.4044, 3.3545, 3.4097, 3.5412, 3.3972],\n",
      "        [3.4650, 3.6821, 3.6477, 3.6116, 3.7728],\n",
      "        [3.8498, 3.7853, 3.6963, 3.9400, 3.8112],\n",
      "        [3.3565, 3.4418, 3.4558, 3.5198, 3.4115],\n",
      "        [3.5529, 3.4577, 3.5309, 3.6499, 3.5166],\n",
      "        [3.5580, 3.5238, 3.6262, 3.7107, 3.6035],\n",
      "        [3.7540, 3.7399, 3.6853, 3.9455, 3.7025],\n",
      "        [3.8363, 3.8753, 3.7806, 3.9406, 3.9120],\n",
      "        [3.6003, 3.5748, 3.6704, 3.7688, 3.5790],\n",
      "        [3.6001, 3.5316, 3.5638, 3.5536, 3.4090],\n",
      "        [3.4797, 3.4583, 3.5343, 3.6398, 3.5800],\n",
      "        [3.5675, 3.6277, 3.5296, 3.7283, 3.6405],\n",
      "        [3.7282, 3.8262, 3.7788, 3.8278, 3.5696],\n",
      "        [3.4946, 3.4582, 3.5139, 3.6136, 3.5142],\n",
      "        [3.8773, 3.7931, 3.7756, 4.0018, 3.8840],\n",
      "        [3.3545, 3.4295, 3.4456, 3.5147, 3.4070],\n",
      "        [3.3662, 3.4257, 3.4484, 3.5350, 3.4154],\n",
      "        [3.7526, 3.5948, 3.6973, 3.9171, 3.6886],\n",
      "        [3.5269, 3.6031, 3.3837, 3.5949, 3.5265],\n",
      "        [3.3934, 3.3910, 3.4321, 3.5412, 3.4067],\n",
      "        [3.6075, 3.5828, 3.6755, 3.7633, 3.5932],\n",
      "        [3.6480, 3.7411, 3.5588, 3.8839, 3.6868],\n",
      "        [3.4770, 3.5567, 3.5275, 3.7262, 3.4987],\n",
      "        [3.6479, 3.5585, 3.5660, 3.6142, 3.4633],\n",
      "        [3.7091, 3.7894, 3.7490, 3.7874, 3.5070],\n",
      "        [3.7758, 3.4413, 3.6029, 4.0135, 3.8790],\n",
      "        [3.5066, 3.5664, 3.5513, 3.6248, 3.4466],\n",
      "        [3.4010, 3.3875, 3.3197, 3.5854, 3.3839],\n",
      "        [3.4641, 3.4461, 3.4616, 3.6468, 3.4455],\n",
      "        [3.4850, 3.5332, 3.4733, 3.5914, 3.5267],\n",
      "        [3.4129, 3.4134, 3.3324, 3.6063, 3.4140],\n",
      "        [3.3422, 3.5595, 3.6249, 3.5234, 3.5573],\n",
      "        [3.5551, 3.3571, 3.6384, 3.7057, 3.6176],\n",
      "        [3.3499, 3.5567, 3.3323, 3.5987, 3.3742],\n",
      "        [3.6460, 3.7355, 3.6918, 3.7279, 3.5428],\n",
      "        [3.5313, 3.4740, 3.5996, 3.6996, 3.6467],\n",
      "        [3.5235, 3.4686, 3.5491, 3.6475, 3.5884],\n",
      "        [3.3607, 3.4264, 3.4490, 3.5208, 3.4086],\n",
      "        [3.5709, 3.7637, 3.6162, 3.7621, 3.7462],\n",
      "        [3.5087, 3.5055, 3.5358, 3.6597, 3.5386],\n",
      "        [3.6777, 3.6127, 3.7159, 3.7417, 3.4784],\n",
      "        [3.4671, 3.3933, 3.5393, 3.4758, 3.5663],\n",
      "        [3.2959, 3.3985, 3.3525, 3.4128, 3.3754],\n",
      "        [3.6374, 3.6183, 3.6144, 3.6948, 3.4466],\n",
      "        [3.3208, 3.3187, 3.3843, 3.4470, 3.3192],\n",
      "        [3.4997, 3.5019, 3.5333, 3.6462, 3.5364],\n",
      "        [3.7037, 3.5232, 3.4706, 3.6676, 3.6432],\n",
      "        [3.4649, 3.6469, 3.5084, 3.6069, 3.4884],\n",
      "        [3.6562, 3.7463, 3.6636, 3.8305, 3.6599],\n",
      "        [3.3576, 3.4658, 3.3919, 3.4881, 3.4364],\n",
      "        [3.3959, 3.4906, 3.5528, 3.5874, 3.4255],\n",
      "        [3.5751, 3.5014, 3.6443, 3.8376, 3.7931],\n",
      "        [3.5058, 3.4758, 3.5758, 3.6607, 3.5517],\n",
      "        [3.5048, 3.4749, 3.5383, 3.6274, 3.5703],\n",
      "        [3.5589, 3.5249, 3.6202, 3.7010, 3.6066],\n",
      "        [3.4802, 3.5463, 3.3995, 3.6261, 3.5056],\n",
      "        [3.7240, 3.6950, 3.8166, 3.7438, 3.5348],\n",
      "        [3.8915, 3.9869, 3.7201, 3.8503, 3.7218],\n",
      "        [3.5085, 3.4422, 3.5603, 3.6602, 3.6239],\n",
      "        [3.4989, 3.6471, 3.5500, 3.8046, 3.5469],\n",
      "        [3.6736, 3.7818, 3.5488, 3.7214, 3.6627],\n",
      "        [3.7161, 3.7030, 3.6826, 3.8297, 3.8443]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3521, 3.5167, 3.4830, 3.5246, 3.4366],\n",
      "        [3.5534, 3.6384, 3.4407, 3.6238, 3.5651],\n",
      "        [3.6150, 3.5555, 3.6112, 3.8102, 3.5127],\n",
      "        [3.7346, 3.4595, 3.6015, 3.9598, 3.8480],\n",
      "        [3.3531, 3.4446, 3.4505, 3.5179, 3.4119],\n",
      "        [3.7994, 3.7532, 3.7161, 3.9975, 3.7513],\n",
      "        [3.8480, 3.6203, 3.7232, 4.2597, 4.0353],\n",
      "        [3.4979, 3.4560, 3.5353, 3.6192, 3.5108],\n",
      "        [3.3907, 3.4837, 3.3826, 3.5185, 3.4465],\n",
      "        [3.3061, 3.4151, 3.3562, 3.4241, 3.3807],\n",
      "        [3.6611, 3.7917, 3.6181, 3.7875, 3.6819],\n",
      "        [3.3654, 3.5558, 3.5106, 3.5408, 3.4641],\n",
      "        [3.5392, 3.5069, 3.6309, 3.8072, 3.7580],\n",
      "        [3.3938, 3.3878, 3.4307, 3.5399, 3.4040],\n",
      "        [3.5815, 3.8420, 3.5848, 3.8670, 3.7398],\n",
      "        [3.5523, 3.5273, 3.5280, 3.6947, 3.5596],\n",
      "        [3.5023, 3.4411, 3.4268, 3.6885, 3.4291],\n",
      "        [3.4181, 3.4590, 3.3869, 3.5801, 3.4225],\n",
      "        [3.3527, 3.4847, 3.4686, 3.5202, 3.4220],\n",
      "        [3.3981, 3.4929, 3.5528, 3.5892, 3.4262],\n",
      "        [3.4047, 3.3507, 3.4071, 3.5513, 3.3851],\n",
      "        [3.6068, 3.5178, 3.6894, 3.7836, 3.5967],\n",
      "        [3.5142, 3.5184, 3.5416, 3.6658, 3.5592],\n",
      "        [3.3812, 3.4712, 3.4962, 3.5707, 3.4261],\n",
      "        [3.3502, 3.5138, 3.4849, 3.5261, 3.4367],\n",
      "        [3.3567, 3.4318, 3.4456, 3.5165, 3.4077],\n",
      "        [3.7500, 3.6979, 3.7105, 3.9553, 3.9263],\n",
      "        [3.5004, 3.4485, 3.4357, 3.6852, 3.4425],\n",
      "        [3.4728, 3.4553, 3.4684, 3.5716, 3.5520],\n",
      "        [3.3512, 3.5014, 3.4748, 3.5224, 3.4283],\n",
      "        [3.5375, 3.4934, 3.5338, 3.6414, 3.5676],\n",
      "        [3.5890, 3.6933, 3.6093, 3.7077, 3.4972],\n",
      "        [3.4615, 3.5361, 3.3913, 3.5989, 3.4876],\n",
      "        [3.6079, 3.8781, 3.6427, 3.8965, 3.7693],\n",
      "        [3.6300, 3.6732, 3.5296, 3.7081, 3.7362],\n",
      "        [3.4315, 3.5088, 3.3820, 3.5722, 3.4616],\n",
      "        [3.5010, 3.4257, 3.5376, 3.6368, 3.6153],\n",
      "        [3.5011, 3.5000, 3.5283, 3.6523, 3.5402],\n",
      "        [3.5971, 3.5209, 3.5834, 3.6127, 3.5000],\n",
      "        [3.8389, 3.8777, 3.7806, 3.9424, 3.9126],\n",
      "        [3.5481, 3.7094, 3.5110, 3.5090, 3.5397],\n",
      "        [3.4967, 3.4670, 3.5200, 3.6185, 3.5156],\n",
      "        [3.4990, 3.4668, 3.5243, 3.6194, 3.5156],\n",
      "        [3.9189, 3.6177, 3.7160, 4.2228, 4.0569],\n",
      "        [3.6065, 3.4107, 3.6818, 3.7192, 3.5986],\n",
      "        [3.4430, 3.4856, 3.4191, 3.5327, 3.4442],\n",
      "        [3.4018, 3.3589, 3.4077, 3.5514, 3.3887],\n",
      "        [3.6301, 3.6393, 3.5998, 3.8575, 3.6105],\n",
      "        [3.6302, 3.5524, 3.5638, 3.5968, 3.4417],\n",
      "        [3.6095, 3.5514, 3.6007, 3.6420, 3.4880],\n",
      "        [3.3968, 3.5888, 3.6776, 3.6239, 3.5840],\n",
      "        [3.7517, 3.6944, 3.7023, 3.9620, 3.9259],\n",
      "        [3.5189, 3.5687, 3.7083, 3.6973, 3.6825],\n",
      "        [3.3230, 3.3210, 3.3844, 3.4488, 3.3199],\n",
      "        [3.6100, 3.6621, 3.5476, 3.6099, 3.5809],\n",
      "        [3.9433, 4.1203, 3.6732, 3.8854, 3.7284],\n",
      "        [3.5486, 3.6369, 3.4442, 3.6244, 3.5705],\n",
      "        [3.3735, 3.4711, 3.3809, 3.4989, 3.4384],\n",
      "        [3.4693, 3.5368, 3.5118, 3.7018, 3.5390],\n",
      "        [3.4651, 3.4751, 3.4457, 3.5386, 3.5040],\n",
      "        [3.4206, 3.5034, 3.3882, 3.5392, 3.4678],\n",
      "        [3.4994, 3.4775, 3.5124, 3.6102, 3.5782],\n",
      "        [3.4102, 3.4442, 3.4916, 3.5931, 3.4055],\n",
      "        [3.6430, 3.8238, 3.6069, 3.7950, 3.6700]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4020, 3.3624, 3.4108, 3.5538, 3.3932],\n",
      "        [3.4928, 3.5550, 3.3877, 3.6502, 3.5053],\n",
      "        [3.8168, 3.7517, 3.7617, 3.9741, 3.8043],\n",
      "        [3.4851, 3.5589, 3.5362, 3.7311, 3.5173],\n",
      "        [3.3830, 3.4731, 3.4961, 3.5721, 3.4266],\n",
      "        [3.6541, 3.6891, 3.7402, 3.8341, 3.7693],\n",
      "        [3.3527, 3.4648, 3.4578, 3.5208, 3.4164],\n",
      "        [3.4766, 3.5657, 3.4904, 3.6972, 3.5784],\n",
      "        [3.2700, 3.3823, 3.4146, 3.4527, 3.4217],\n",
      "        [3.4158, 3.6160, 3.5321, 3.6314, 3.6733],\n",
      "        [3.4986, 3.4790, 3.5151, 3.6190, 3.5167],\n",
      "        [3.3920, 3.4186, 3.3445, 3.5830, 3.3273],\n",
      "        [3.4632, 3.5381, 3.3912, 3.6003, 3.4881],\n",
      "        [3.6583, 3.7428, 3.5971, 3.8020, 3.6679],\n",
      "        [3.4918, 3.4608, 3.5201, 3.6208, 3.5138],\n",
      "        [3.7504, 3.7040, 3.6335, 3.8236, 3.7219],\n",
      "        [3.4992, 3.5266, 3.4421, 3.6581, 3.6319],\n",
      "        [3.3560, 3.5478, 3.4754, 3.5738, 3.6080],\n",
      "        [3.9707, 4.0583, 3.9873, 4.1704, 4.2104],\n",
      "        [3.6185, 3.8086, 3.7032, 3.8009, 3.8396],\n",
      "        [3.6189, 3.4797, 3.7537, 3.7585, 3.6871],\n",
      "        [3.4537, 3.3722, 3.5289, 3.4457, 3.5610],\n",
      "        [3.8633, 3.8730, 3.8019, 4.1039, 3.8299],\n",
      "        [3.7264, 3.5209, 3.5712, 4.0286, 3.7674],\n",
      "        [3.6444, 3.5508, 3.6159, 3.7533, 3.5708],\n",
      "        [3.7039, 3.5438, 3.5516, 3.7160, 3.6471],\n",
      "        [3.6778, 3.7508, 3.5615, 3.7480, 3.7171],\n",
      "        [3.4997, 3.6674, 3.5769, 3.5919, 3.6268],\n",
      "        [3.7516, 3.8842, 3.6842, 3.9287, 3.8601],\n",
      "        [3.6486, 3.6374, 3.6876, 3.7225, 3.4854],\n",
      "        [3.8450, 3.9266, 3.5755, 3.7980, 3.6496],\n",
      "        [3.8201, 3.7204, 3.6884, 3.9047, 3.7653],\n",
      "        [3.5073, 3.6121, 3.5769, 3.6619, 3.4946],\n",
      "        [3.6186, 3.5634, 3.6063, 3.8151, 3.5168],\n",
      "        [3.4778, 3.6040, 3.5548, 3.6445, 3.5955],\n",
      "        [3.5042, 3.7062, 3.4824, 3.7687, 3.5995],\n",
      "        [3.6174, 3.8190, 3.6258, 3.7755, 3.6878],\n",
      "        [3.5409, 3.6742, 3.5371, 3.6639, 3.6286],\n",
      "        [3.3834, 3.4170, 3.4031, 3.5295, 3.4167],\n",
      "        [3.3769, 3.4037, 3.4364, 3.5313, 3.4056],\n",
      "        [3.3734, 3.4109, 3.4383, 3.5246, 3.4062],\n",
      "        [3.6589, 3.4419, 3.4381, 3.5907, 3.6031],\n",
      "        [3.4489, 3.4948, 3.4142, 3.5349, 3.4531],\n",
      "        [3.3671, 3.4657, 3.3745, 3.4922, 3.4232],\n",
      "        [3.4177, 3.4533, 3.3838, 3.5817, 3.4214],\n",
      "        [3.5709, 3.6952, 3.5963, 3.7023, 3.4837],\n",
      "        [3.6564, 3.7529, 3.5930, 3.7874, 3.6651],\n",
      "        [3.5569, 3.4620, 3.5307, 3.6530, 3.5177],\n",
      "        [3.3705, 3.5597, 3.5066, 3.5566, 3.4801],\n",
      "        [3.7349, 3.7378, 3.7011, 3.8424, 3.8965],\n",
      "        [4.0512, 4.2425, 3.7934, 4.0236, 3.7916],\n",
      "        [3.8553, 3.7727, 3.7247, 3.9554, 3.8259],\n",
      "        [3.3585, 3.4337, 3.4455, 3.5178, 3.4082],\n",
      "        [3.7613, 3.7898, 3.6505, 3.8631, 3.8197],\n",
      "        [3.4311, 3.5815, 3.3889, 3.6408, 3.4127],\n",
      "        [3.4637, 3.5271, 3.3834, 3.6025, 3.4884],\n",
      "        [3.6503, 3.7222, 3.6691, 3.7375, 3.5107],\n",
      "        [3.7538, 3.6964, 3.7022, 3.9634, 3.9265],\n",
      "        [3.3662, 3.5460, 3.4978, 3.5487, 3.4665],\n",
      "        [3.7017, 3.4509, 3.5853, 3.9136, 3.8197],\n",
      "        [3.4838, 3.5551, 3.3956, 3.6311, 3.5034],\n",
      "        [3.4438, 3.4377, 3.5141, 3.6145, 3.5789],\n",
      "        [3.5606, 3.6885, 3.6716, 3.7852, 3.6310],\n",
      "        [3.4057, 3.3839, 3.4269, 3.5491, 3.4062]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3587, 3.5151, 3.4825, 3.5413, 3.4458],\n",
      "        [3.5128, 3.5022, 3.5588, 3.6717, 3.5619],\n",
      "        [3.6374, 3.7233, 3.6068, 3.8170, 3.8045],\n",
      "        [3.4587, 3.5132, 3.4083, 3.5976, 3.4982],\n",
      "        [3.5118, 3.5570, 3.4379, 3.6419, 3.5477],\n",
      "        [3.5026, 3.4639, 3.5183, 3.6201, 3.5167],\n",
      "        [3.3747, 3.5633, 3.6274, 3.5486, 3.5334],\n",
      "        [3.6270, 3.6451, 3.5394, 3.7285, 3.7557],\n",
      "        [3.3830, 3.4215, 3.4462, 3.5387, 3.4243],\n",
      "        [3.6364, 3.4230, 3.4441, 3.6044, 3.5806],\n",
      "        [3.4947, 3.5536, 3.3828, 3.6404, 3.4906],\n",
      "        [3.7216, 3.7796, 3.7811, 3.9895, 4.0124],\n",
      "        [3.4842, 3.7593, 3.5853, 3.7411, 3.7191],\n",
      "        [3.5754, 3.6033, 3.4752, 3.7109, 3.5753],\n",
      "        [3.4253, 3.6966, 3.6576, 3.6560, 3.7049],\n",
      "        [3.5294, 3.4155, 3.5020, 3.5346, 3.4429],\n",
      "        [3.6562, 3.8163, 3.6102, 3.6223, 3.6696],\n",
      "        [3.6152, 3.7964, 3.6906, 3.7975, 3.8252],\n",
      "        [3.4239, 3.4937, 3.3755, 3.5501, 3.4463],\n",
      "        [3.4875, 3.7014, 3.4991, 3.4792, 3.6077],\n",
      "        [3.6462, 3.6781, 3.6630, 3.7186, 3.6509],\n",
      "        [3.6256, 3.6966, 3.6400, 3.7453, 3.5204],\n",
      "        [3.6264, 3.4160, 3.4385, 3.6053, 3.5573],\n",
      "        [3.7959, 3.6632, 3.6150, 3.8170, 3.7061],\n",
      "        [3.5590, 3.4686, 3.5380, 3.6697, 3.5343],\n",
      "        [3.8601, 3.6268, 3.7275, 4.2672, 4.0435],\n",
      "        [3.4893, 3.5513, 3.3801, 3.6405, 3.4877],\n",
      "        [3.6323, 3.7909, 3.5679, 3.5910, 3.6080],\n",
      "        [3.8823, 3.7995, 3.7753, 4.0073, 3.8871],\n",
      "        [3.5162, 3.5819, 3.3944, 3.6902, 3.5243],\n",
      "        [3.3619, 3.4841, 3.4715, 3.5387, 3.4400],\n",
      "        [3.5137, 3.4858, 3.5748, 3.6696, 3.5650],\n",
      "        [3.5058, 3.6601, 3.4949, 3.5984, 3.5882],\n",
      "        [3.3249, 3.4212, 3.2606, 3.5206, 3.3383],\n",
      "        [3.3876, 3.7336, 3.6017, 3.6219, 3.7080],\n",
      "        [3.7901, 3.8756, 3.5662, 3.7674, 3.6565],\n",
      "        [3.7087, 3.4606, 3.5955, 3.9189, 3.8220],\n",
      "        [3.5040, 3.5653, 3.3910, 3.6585, 3.5087],\n",
      "        [3.3834, 3.3920, 3.4225, 3.5264, 3.3879],\n",
      "        [3.4872, 3.6122, 3.5681, 3.6555, 3.6178],\n",
      "        [3.7236, 3.5345, 3.5691, 4.0113, 3.7638],\n",
      "        [3.5654, 3.7431, 3.5527, 3.8296, 3.6450],\n",
      "        [3.5008, 3.5644, 3.3978, 3.6585, 3.5154],\n",
      "        [3.4787, 3.4196, 3.5185, 3.5962, 3.4739],\n",
      "        [3.6422, 3.6325, 3.5799, 3.8028, 3.7472],\n",
      "        [3.6356, 3.7090, 3.6523, 3.8766, 3.6286],\n",
      "        [3.6465, 3.7645, 3.7065, 3.8331, 3.6547],\n",
      "        [3.3266, 3.3399, 3.3978, 3.4705, 3.3234],\n",
      "        [3.6554, 3.7510, 3.5647, 3.8986, 3.7008],\n",
      "        [3.6093, 3.6246, 3.5216, 3.7005, 3.5658],\n",
      "        [3.3549, 3.5457, 3.4972, 3.5321, 3.4548],\n",
      "        [3.6185, 3.6694, 3.5461, 3.7642, 3.6960],\n",
      "        [3.4736, 3.4762, 3.6305, 3.4955, 3.6725],\n",
      "        [3.5961, 3.6347, 3.7211, 3.7511, 3.6675],\n",
      "        [3.6625, 3.7858, 3.6895, 3.8175, 3.6685],\n",
      "        [3.5325, 3.5457, 3.5641, 3.6403, 3.7541],\n",
      "        [3.6432, 3.7142, 3.5566, 3.7156, 3.6386],\n",
      "        [3.5980, 3.4701, 3.7488, 3.7319, 3.6728],\n",
      "        [3.7328, 3.4514, 3.5922, 3.9608, 3.8393],\n",
      "        [3.5051, 3.4447, 3.4265, 3.6915, 3.4309],\n",
      "        [3.7084, 3.7510, 3.6653, 3.8124, 3.7581],\n",
      "        [3.7411, 3.8424, 3.7833, 3.8417, 3.5780],\n",
      "        [3.4778, 3.4856, 3.6441, 3.4962, 3.6848],\n",
      "        [3.5201, 3.6733, 3.5251, 3.7786, 3.5386]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4209, 3.5066, 3.5521, 3.6062, 3.4465],\n",
      "        [3.7615, 3.6172, 3.7001, 3.8938, 3.6876],\n",
      "        [3.6157, 3.5466, 3.5546, 3.5774, 3.4241],\n",
      "        [3.4520, 3.6624, 3.5537, 3.6660, 3.6977],\n",
      "        [3.4824, 3.7411, 3.6228, 3.7187, 3.7249],\n",
      "        [3.4874, 3.4603, 3.4601, 3.6631, 3.4456],\n",
      "        [3.3926, 3.6602, 3.5112, 3.4493, 3.6037],\n",
      "        [3.4770, 3.5502, 3.3874, 3.6130, 3.4984],\n",
      "        [3.9006, 3.9136, 3.8247, 4.1525, 3.9049],\n",
      "        [3.4824, 3.6961, 3.6252, 3.5945, 3.6214],\n",
      "        [3.4894, 3.7028, 3.4987, 3.4812, 3.6095],\n",
      "        [3.6569, 3.6949, 3.6772, 3.8211, 3.6046],\n",
      "        [3.4698, 3.5958, 3.4400, 3.7212, 3.4635],\n",
      "        [3.6573, 3.7525, 3.5643, 3.9008, 3.7027],\n",
      "        [3.6313, 3.6914, 3.5385, 3.7348, 3.6371],\n",
      "        [3.3677, 3.4021, 3.4313, 3.5243, 3.4003],\n",
      "        [3.6425, 3.6324, 3.6121, 3.7023, 3.4380],\n",
      "        [3.4912, 3.4737, 3.5178, 3.6294, 3.5207],\n",
      "        [3.5210, 3.4580, 3.5696, 3.6759, 3.6319],\n",
      "        [3.7545, 3.8875, 3.6837, 3.9327, 3.8632],\n",
      "        [3.5862, 3.7451, 3.5750, 3.8451, 3.6531],\n",
      "        [3.4605, 3.5146, 3.4079, 3.5997, 3.5000],\n",
      "        [3.7965, 3.7953, 3.6735, 3.8900, 3.8562],\n",
      "        [3.5070, 3.4850, 3.5221, 3.6396, 3.5257],\n",
      "        [3.6130, 3.6362, 3.6615, 3.6947, 3.5127],\n",
      "        [3.5425, 3.7209, 3.4620, 3.6686, 3.5519],\n",
      "        [3.6311, 3.6243, 3.6002, 3.6907, 3.4154],\n",
      "        [3.7611, 3.6015, 3.7019, 3.9180, 3.6942],\n",
      "        [3.3107, 3.4200, 3.3556, 3.4292, 3.3844],\n",
      "        [3.4148, 3.5495, 3.6014, 3.5976, 3.5772],\n",
      "        [3.3373, 3.4039, 3.3166, 3.5486, 3.3257],\n",
      "        [3.4043, 3.3483, 3.3963, 3.5527, 3.3890],\n",
      "        [3.6138, 3.6160, 3.6383, 3.7280, 3.6224],\n",
      "        [3.7018, 3.6076, 3.6740, 3.8497, 3.6423],\n",
      "        [3.4011, 3.4612, 3.4966, 3.5695, 3.4357],\n",
      "        [3.4335, 3.5102, 3.3810, 3.5640, 3.4738],\n",
      "        [3.7157, 3.7761, 3.6702, 3.8161, 3.8000],\n",
      "        [3.3523, 3.4873, 3.4683, 3.5280, 3.4200],\n",
      "        [3.5339, 3.7246, 3.6373, 3.7671, 3.7501],\n",
      "        [3.3954, 3.4887, 3.3819, 3.5236, 3.4501],\n",
      "        [3.6469, 3.8338, 3.7368, 3.8152, 3.7667],\n",
      "        [3.9739, 4.0618, 3.9867, 4.1746, 4.2137],\n",
      "        [3.5107, 3.5018, 3.5356, 3.6564, 3.5560],\n",
      "        [3.4911, 3.5586, 3.3862, 3.6492, 3.4988],\n",
      "        [3.7022, 3.6584, 3.8254, 3.7076, 3.5617],\n",
      "        [3.5930, 3.8064, 3.6481, 3.7893, 3.7683],\n",
      "        [3.3850, 3.3996, 3.4308, 3.5332, 3.4072],\n",
      "        [3.6638, 3.6456, 3.7085, 3.7458, 3.5309],\n",
      "        [3.4912, 3.4654, 3.5346, 3.6471, 3.5965],\n",
      "        [3.4950, 3.6079, 3.5556, 3.6546, 3.5718],\n",
      "        [3.5069, 3.6614, 3.5574, 3.6029, 3.6219],\n",
      "        [3.2650, 3.3844, 3.4039, 3.4524, 3.3966],\n",
      "        [3.4094, 3.4020, 3.3189, 3.5891, 3.3625],\n",
      "        [3.3593, 3.5015, 3.4761, 3.5405, 3.4426],\n",
      "        [3.8306, 3.8019, 3.7127, 4.0311, 3.8298],\n",
      "        [3.3862, 3.4201, 3.4026, 3.5333, 3.4198],\n",
      "        [3.4025, 3.5273, 3.3702, 3.6014, 3.4382],\n",
      "        [3.8340, 3.7134, 3.6889, 3.9938, 3.7722],\n",
      "        [3.3729, 3.4330, 3.4477, 3.5419, 3.4196],\n",
      "        [3.6336, 3.4845, 3.4448, 3.5993, 3.6178],\n",
      "        [3.7921, 3.8770, 3.5659, 3.7695, 3.6582],\n",
      "        [3.6316, 3.7467, 3.6788, 3.8159, 3.7178],\n",
      "        [3.7804, 3.6742, 3.6333, 3.8197, 3.7507],\n",
      "        [3.5202, 3.3994, 3.4816, 3.5240, 3.4250]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6150, 3.5633, 3.5357, 3.8217, 3.6398],\n",
      "        [3.6542, 3.7168, 3.5741, 3.7482, 3.6301],\n",
      "        [3.5931, 3.4738, 3.7688, 3.7378, 3.6735],\n",
      "        [3.4216, 3.4799, 3.3810, 3.5917, 3.4335],\n",
      "        [3.3918, 3.4090, 3.4376, 3.5428, 3.4146],\n",
      "        [3.6075, 3.5374, 3.5904, 3.6191, 3.5005],\n",
      "        [3.4822, 3.5410, 3.5093, 3.6707, 3.6023],\n",
      "        [3.4515, 3.5664, 3.4697, 3.6857, 3.4836],\n",
      "        [3.3841, 3.3974, 3.4290, 3.5347, 3.4045],\n",
      "        [3.4559, 3.6922, 3.4950, 3.5687, 3.4455],\n",
      "        [3.5080, 3.4862, 3.5216, 3.6411, 3.5271],\n",
      "        [3.5158, 3.5048, 3.5580, 3.6753, 3.5652],\n",
      "        [3.6303, 3.5718, 3.5077, 3.8497, 3.6585],\n",
      "        [3.5352, 3.5217, 3.5400, 3.5571, 3.3801],\n",
      "        [3.7716, 3.7211, 3.7382, 3.9030, 3.7292],\n",
      "        [3.4310, 3.5097, 3.3882, 3.5535, 3.4820],\n",
      "        [3.6118, 3.7130, 3.5329, 3.7089, 3.6193],\n",
      "        [3.6336, 3.5749, 3.6079, 3.6623, 3.4901],\n",
      "        [3.4842, 3.5245, 3.5082, 3.6456, 3.6413],\n",
      "        [3.4424, 3.5219, 3.3787, 3.5827, 3.4717],\n",
      "        [3.4152, 3.3990, 3.4322, 3.5688, 3.4265],\n",
      "        [3.5582, 3.6608, 3.4992, 3.7394, 3.5797],\n",
      "        [3.5259, 3.5947, 3.4041, 3.6960, 3.5370],\n",
      "        [3.4868, 3.6093, 3.5427, 3.6555, 3.5605],\n",
      "        [3.5166, 3.4836, 3.5541, 3.6454, 3.5690],\n",
      "        [3.4980, 3.5560, 3.5511, 3.6793, 3.5006],\n",
      "        [3.3571, 3.5076, 3.4737, 3.5291, 3.4334],\n",
      "        [3.6644, 3.7551, 3.6626, 3.8391, 3.6656],\n",
      "        [3.5049, 3.6217, 3.5833, 3.6678, 3.4912],\n",
      "        [3.4978, 3.6086, 3.4790, 3.6769, 3.6032],\n",
      "        [3.3985, 3.4218, 3.4529, 3.5573, 3.4340],\n",
      "        [3.6319, 3.7019, 3.6386, 3.7525, 3.5284],\n",
      "        [3.6511, 3.5706, 3.5176, 3.8923, 3.6822],\n",
      "        [3.6480, 3.6999, 3.5370, 3.7398, 3.7363],\n",
      "        [3.7553, 3.7633, 3.7345, 3.8571, 3.9373],\n",
      "        [3.6196, 3.7158, 3.5424, 3.7113, 3.6307],\n",
      "        [3.7390, 3.7425, 3.7001, 3.8477, 3.9009],\n",
      "        [3.6268, 3.4160, 3.4339, 3.6200, 3.5440],\n",
      "        [3.8437, 3.8731, 3.7555, 4.0875, 3.8333],\n",
      "        [3.3111, 3.4157, 3.3560, 3.4290, 3.3831],\n",
      "        [3.5595, 3.5758, 3.5323, 3.6985, 3.6411],\n",
      "        [3.4681, 3.5343, 3.5237, 3.6508, 3.4688],\n",
      "        [3.5122, 3.5089, 3.5341, 3.6560, 3.5528],\n",
      "        [3.4128, 3.5306, 3.5842, 3.6157, 3.5869],\n",
      "        [3.3763, 3.4697, 3.3817, 3.4942, 3.4552],\n",
      "        [3.5847, 3.5878, 3.5549, 3.6959, 3.5727],\n",
      "        [3.6000, 3.5745, 3.5548, 3.7004, 3.5491],\n",
      "        [3.4494, 3.5207, 3.3798, 3.5813, 3.4816],\n",
      "        [3.5336, 3.5981, 3.3974, 3.6964, 3.5315],\n",
      "        [3.5793, 3.7733, 3.6139, 3.7678, 3.7517],\n",
      "        [3.4208, 3.4221, 3.3314, 3.6147, 3.4197],\n",
      "        [3.8677, 3.6481, 3.7328, 4.2719, 4.0478],\n",
      "        [3.5414, 3.5768, 3.7048, 3.7227, 3.6916],\n",
      "        [3.3640, 3.5561, 3.6062, 3.5643, 3.5412],\n",
      "        [3.4744, 3.5366, 3.5918, 3.7098, 3.6787],\n",
      "        [3.7564, 3.8780, 3.6579, 3.7266, 3.6490],\n",
      "        [3.6673, 3.7577, 3.5983, 3.7992, 3.6774],\n",
      "        [3.6340, 3.7510, 3.6519, 3.8961, 3.6628],\n",
      "        [3.5930, 3.3679, 3.6622, 3.7016, 3.5634],\n",
      "        [3.7277, 3.6912, 3.7067, 3.7417, 3.4928],\n",
      "        [4.1473, 4.2628, 3.8717, 4.0679, 3.8506],\n",
      "        [3.6638, 3.6807, 3.6647, 3.7841, 3.7723],\n",
      "        [3.7378, 3.7834, 3.6213, 3.8314, 3.8174],\n",
      "        [3.4294, 3.5437, 3.4169, 3.6696, 3.4478]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4885, 3.5227, 3.5147, 3.6387, 3.6625],\n",
      "        [3.5873, 3.8405, 3.5653, 3.8678, 3.7244],\n",
      "        [3.5053, 3.4921, 3.5196, 3.6369, 3.5343],\n",
      "        [3.6593, 3.7548, 3.5632, 3.9035, 3.7054],\n",
      "        [3.5529, 3.7347, 3.5275, 3.8229, 3.6378],\n",
      "        [3.4969, 3.6101, 3.5546, 3.6571, 3.5744],\n",
      "        [3.6590, 3.6944, 3.7387, 3.8407, 3.7748],\n",
      "        [3.6094, 3.5845, 3.6688, 3.7786, 3.5858],\n",
      "        [3.7139, 3.8446, 3.6584, 3.9164, 3.7819],\n",
      "        [3.4115, 3.3735, 3.4118, 3.5612, 3.4016],\n",
      "        [3.4839, 3.7116, 3.5433, 3.6270, 3.4568],\n",
      "        [3.2815, 3.3808, 3.3351, 3.3946, 3.3493],\n",
      "        [3.5770, 3.5525, 3.5335, 3.7399, 3.5713],\n",
      "        [3.3937, 3.3735, 3.4109, 3.5476, 3.3936],\n",
      "        [3.3800, 3.4781, 3.3793, 3.5066, 3.4447],\n",
      "        [3.7650, 3.7497, 3.6841, 3.9555, 3.7092],\n",
      "        [3.7126, 3.4642, 3.5942, 3.9241, 3.8264],\n",
      "        [3.6295, 3.8222, 3.7106, 3.8203, 3.8519],\n",
      "        [3.5039, 3.5321, 3.4407, 3.6641, 3.6370],\n",
      "        [3.6671, 3.7713, 3.5502, 3.7509, 3.6946],\n",
      "        [3.6958, 3.7125, 3.7209, 3.9334, 3.6421],\n",
      "        [3.7413, 3.5725, 3.5642, 3.7420, 3.6759],\n",
      "        [3.6108, 3.5316, 3.5897, 3.6090, 3.5366],\n",
      "        [3.5106, 3.4403, 3.5495, 3.6521, 3.6250],\n",
      "        [3.8599, 3.7782, 3.7232, 3.9630, 3.8329],\n",
      "        [3.6450, 3.5624, 3.5591, 3.6118, 3.4621],\n",
      "        [3.4524, 3.5674, 3.4692, 3.6868, 3.4848],\n",
      "        [3.5737, 3.7750, 3.6663, 3.7527, 3.5882],\n",
      "        [3.5856, 3.5887, 3.5544, 3.6971, 3.5739],\n",
      "        [3.3297, 3.3279, 3.3829, 3.4566, 3.3263],\n",
      "        [3.6568, 3.7524, 3.5621, 3.9021, 3.7020],\n",
      "        [3.5083, 3.4706, 3.5291, 3.6481, 3.5920],\n",
      "        [3.6223, 3.8244, 3.6243, 3.7820, 3.6935],\n",
      "        [3.4246, 3.4661, 3.3853, 3.5878, 3.4287],\n",
      "        [3.7253, 3.7833, 3.7798, 3.9945, 4.0169],\n",
      "        [3.4440, 3.6450, 3.5372, 3.6677, 3.6618],\n",
      "        [3.6646, 3.6817, 3.6642, 3.7852, 3.7735],\n",
      "        [3.5056, 3.4144, 3.4920, 3.5480, 3.4470],\n",
      "        [3.8965, 3.6001, 3.6862, 4.2272, 4.0411],\n",
      "        [3.4958, 3.4344, 3.5035, 3.5724, 3.4735],\n",
      "        [3.8359, 3.7254, 3.7409, 3.9383, 3.8161],\n",
      "        [3.4679, 3.5433, 3.3897, 3.6067, 3.4939],\n",
      "        [3.3440, 3.5713, 3.6234, 3.5369, 3.5584],\n",
      "        [3.4099, 3.6778, 3.5231, 3.4687, 3.6176],\n",
      "        [3.7208, 3.8078, 3.6838, 3.7075, 3.7287],\n",
      "        [3.5636, 3.6287, 3.5996, 3.7685, 3.6744],\n",
      "        [3.4165, 3.5073, 3.6231, 3.5963, 3.5946],\n",
      "        [3.4332, 3.5493, 3.5912, 3.6211, 3.5992],\n",
      "        [3.7398, 3.7435, 3.6996, 3.8489, 3.9021],\n",
      "        [3.5011, 3.4217, 3.5182, 3.6419, 3.6148],\n",
      "        [3.7616, 3.7018, 3.7097, 3.9448, 3.7288],\n",
      "        [3.5165, 3.5227, 3.5433, 3.6619, 3.5634],\n",
      "        [4.0359, 4.2097, 3.7447, 3.9791, 3.8122],\n",
      "        [3.7571, 3.8874, 3.6823, 3.9358, 3.8610],\n",
      "        [3.6552, 3.7452, 3.6902, 3.7376, 3.5498],\n",
      "        [3.4789, 3.5524, 3.3864, 3.6156, 3.5011],\n",
      "        [3.4913, 3.4895, 3.5232, 3.5204, 3.3366],\n",
      "        [3.6201, 3.6243, 3.5904, 3.6778, 3.4034],\n",
      "        [3.3881, 3.4189, 3.4614, 3.5581, 3.3958],\n",
      "        [3.4287, 3.4728, 3.4712, 3.5283, 3.4635],\n",
      "        [3.3378, 3.3994, 3.2979, 3.5396, 3.3354],\n",
      "        [3.4906, 3.5561, 3.3951, 3.6376, 3.5125],\n",
      "        [3.4814, 3.5712, 3.4890, 3.7033, 3.5836],\n",
      "        [3.6498, 3.5909, 3.6324, 3.8431, 3.5551]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5952, 3.5806, 3.4137, 3.7552, 3.6793],\n",
      "        [3.7766, 3.6271, 3.7229, 3.9516, 3.7205],\n",
      "        [3.4724, 3.5994, 3.4386, 3.7253, 3.4672],\n",
      "        [3.5833, 3.6149, 3.4964, 3.7319, 3.6043],\n",
      "        [3.8225, 3.7213, 3.7114, 3.9940, 3.8056],\n",
      "        [3.3950, 3.6638, 3.5098, 3.4533, 3.6070],\n",
      "        [3.8324, 3.8180, 3.7181, 4.0588, 3.8501],\n",
      "        [3.3888, 3.4235, 3.4012, 3.5374, 3.4235],\n",
      "        [3.6169, 3.5599, 3.5984, 3.6515, 3.4951],\n",
      "        [3.6254, 3.5510, 3.5928, 3.7313, 3.5651],\n",
      "        [3.3472, 3.3096, 3.3720, 3.5597, 3.3708],\n",
      "        [3.5700, 3.7481, 3.5509, 3.8359, 3.6503],\n",
      "        [3.7298, 3.6936, 3.7056, 3.7443, 3.4948],\n",
      "        [3.7820, 3.5673, 3.5868, 4.0758, 3.8125],\n",
      "        [3.8253, 3.7273, 3.6864, 3.9139, 3.7734],\n",
      "        [4.0833, 4.2307, 3.7961, 4.0149, 3.8353],\n",
      "        [3.6689, 3.6087, 3.7071, 3.7295, 3.4334],\n",
      "        [3.6313, 3.6885, 3.6848, 3.7554, 3.6546],\n",
      "        [3.7452, 3.7098, 3.7116, 3.9626, 3.9365],\n",
      "        [3.6354, 3.6857, 3.6788, 3.7546, 3.6468],\n",
      "        [3.5231, 3.7244, 3.5090, 3.5051, 3.6195],\n",
      "        [3.3620, 3.5742, 3.3351, 3.5982, 3.3816],\n",
      "        [3.5532, 3.6555, 3.4683, 3.6284, 3.5854],\n",
      "        [3.3650, 3.5358, 3.4885, 3.5511, 3.4609],\n",
      "        [3.5211, 3.4023, 3.4825, 3.5203, 3.4280],\n",
      "        [3.4408, 3.4808, 3.3010, 3.6514, 3.3700],\n",
      "        [3.5643, 3.3680, 3.6362, 3.7168, 3.6252],\n",
      "        [3.3202, 3.4231, 3.3551, 3.4425, 3.3959],\n",
      "        [3.5179, 3.5167, 3.5334, 3.6705, 3.5460],\n",
      "        [3.5560, 3.6869, 3.6644, 3.8035, 3.6368],\n",
      "        [3.9715, 3.6745, 3.8119, 4.3709, 4.1341],\n",
      "        [3.3671, 3.5565, 3.4991, 3.5444, 3.4662],\n",
      "        [3.6107, 3.6065, 3.4520, 3.7798, 3.6946],\n",
      "        [3.4014, 3.3709, 3.4083, 3.5558, 3.3945],\n",
      "        [3.4108, 3.4869, 3.3726, 3.5384, 3.4442],\n",
      "        [3.6434, 3.9016, 3.7271, 3.8532, 3.8166],\n",
      "        [3.5033, 3.4440, 3.5129, 3.5721, 3.4832],\n",
      "        [3.5856, 3.6004, 3.4977, 3.7510, 3.6068],\n",
      "        [3.6383, 3.7280, 3.6461, 3.8826, 3.6469],\n",
      "        [3.5484, 3.5140, 3.5976, 3.6846, 3.5872],\n",
      "        [3.4942, 3.5267, 3.5166, 3.6425, 3.6664],\n",
      "        [3.4362, 3.5536, 3.4324, 3.6324, 3.4299],\n",
      "        [3.8855, 3.7078, 3.7831, 4.0560, 3.8195],\n",
      "        [3.4393, 3.4597, 3.4883, 3.6126, 3.4321],\n",
      "        [3.4099, 3.4531, 3.3564, 3.6026, 3.4319],\n",
      "        [3.3280, 3.3357, 3.3912, 3.4654, 3.3292],\n",
      "        [3.6589, 3.7058, 3.5783, 3.6968, 3.6266],\n",
      "        [4.1280, 4.2445, 3.8712, 4.0811, 3.8361],\n",
      "        [3.5556, 3.7179, 3.5090, 3.5180, 3.5465],\n",
      "        [3.4672, 3.5226, 3.6294, 3.6482, 3.6159],\n",
      "        [3.4851, 3.7047, 3.6222, 3.5996, 3.6283],\n",
      "        [3.3763, 3.4309, 3.4433, 3.5324, 3.4169],\n",
      "        [3.5002, 3.4582, 3.5203, 3.6183, 3.5047],\n",
      "        [3.5132, 3.5054, 3.5340, 3.6604, 3.5594],\n",
      "        [3.5199, 3.5863, 3.3902, 3.6812, 3.5242],\n",
      "        [3.4893, 3.5572, 3.3973, 3.6371, 3.5135],\n",
      "        [3.3823, 3.4602, 3.4824, 3.5644, 3.4167],\n",
      "        [3.3806, 3.4115, 3.4330, 3.5354, 3.4132],\n",
      "        [3.4923, 3.5535, 3.3906, 3.6245, 3.5158],\n",
      "        [3.7441, 3.8000, 3.7956, 4.0231, 4.0355],\n",
      "        [3.7340, 3.6839, 3.6844, 3.9454, 3.9223],\n",
      "        [3.6831, 3.6473, 3.6955, 3.7541, 3.5408],\n",
      "        [3.4861, 3.6001, 3.4719, 3.6699, 3.5957],\n",
      "        [3.5030, 3.5710, 3.3904, 3.6566, 3.5150]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4512, 3.5249, 3.3792, 3.5848, 3.4845],\n",
      "        [3.5476, 3.6045, 3.5441, 3.6899, 3.6184],\n",
      "        [3.6040, 3.5208, 3.5786, 3.6097, 3.5261],\n",
      "        [3.4743, 3.6959, 3.6461, 3.6232, 3.7808],\n",
      "        [3.4112, 3.3924, 3.4253, 3.5575, 3.4133],\n",
      "        [3.5795, 3.8624, 3.6263, 3.8677, 3.7635],\n",
      "        [3.5014, 3.5051, 3.5237, 3.6520, 3.5388],\n",
      "        [3.5268, 3.4853, 3.5522, 3.6061, 3.5269],\n",
      "        [3.4584, 3.5295, 3.3730, 3.6046, 3.4704],\n",
      "        [3.7313, 3.6762, 3.6970, 3.8422, 3.8677],\n",
      "        [3.5016, 3.4763, 3.5138, 3.6220, 3.5209],\n",
      "        [3.7396, 3.7879, 3.6207, 3.8349, 3.8201],\n",
      "        [3.6969, 3.7159, 3.7208, 3.9359, 3.6438],\n",
      "        [3.6029, 3.6878, 3.6642, 3.8369, 3.6960],\n",
      "        [3.4286, 3.5005, 3.3741, 3.5571, 3.4525],\n",
      "        [3.6145, 3.5285, 3.6876, 3.7940, 3.6045],\n",
      "        [3.6757, 3.5743, 3.5656, 3.9831, 3.7500],\n",
      "        [3.4939, 3.5640, 3.3851, 3.6541, 3.5031],\n",
      "        [3.8161, 3.7942, 3.6687, 3.9065, 3.8791],\n",
      "        [3.4974, 3.6847, 3.5908, 3.5918, 3.6366],\n",
      "        [3.5781, 3.5559, 3.5333, 3.7423, 3.5730],\n",
      "        [3.7168, 3.7761, 3.7364, 3.8012, 3.5630],\n",
      "        [3.5696, 3.4726, 3.5395, 3.6665, 3.5318],\n",
      "        [3.8097, 3.7917, 3.6728, 3.9210, 3.8741],\n",
      "        [3.5761, 3.7487, 3.5892, 3.7615, 3.7468],\n",
      "        [3.6696, 3.7968, 3.6858, 3.8237, 3.6731],\n",
      "        [3.6030, 3.6585, 3.5215, 3.7419, 3.6924],\n",
      "        [3.4081, 3.4848, 3.3538, 3.6000, 3.4439],\n",
      "        [3.4827, 3.4769, 3.5251, 3.6512, 3.6044],\n",
      "        [3.4162, 3.3996, 3.4421, 3.5694, 3.3986],\n",
      "        [3.6474, 3.6309, 3.6127, 3.7070, 3.4554],\n",
      "        [3.8243, 3.7607, 3.7606, 3.9831, 3.8117],\n",
      "        [3.4554, 3.5351, 3.3813, 3.6035, 3.4772],\n",
      "        [3.6365, 3.5555, 3.6090, 3.7540, 3.5804],\n",
      "        [3.3767, 3.5684, 3.5051, 3.5655, 3.4878],\n",
      "        [3.5893, 3.5811, 3.5518, 3.6974, 3.5552],\n",
      "        [3.3641, 3.5013, 3.6233, 3.5282, 3.5955],\n",
      "        [3.7585, 3.8824, 3.6573, 3.7302, 3.6518],\n",
      "        [3.5092, 3.5150, 3.5313, 3.6578, 3.5445],\n",
      "        [3.5235, 3.5867, 3.5384, 3.6398, 3.5682],\n",
      "        [3.6577, 3.6248, 3.6130, 3.7772, 3.7765],\n",
      "        [3.5651, 3.7918, 3.7190, 3.8168, 3.7581],\n",
      "        [3.5488, 3.5159, 3.5980, 3.6856, 3.5880],\n",
      "        [3.6641, 3.6169, 3.6510, 3.8568, 3.5659],\n",
      "        [3.4692, 3.5914, 3.4361, 3.7274, 3.4657],\n",
      "        [3.5290, 3.4676, 3.5761, 3.6924, 3.6379],\n",
      "        [3.3767, 3.4328, 3.4437, 3.5333, 3.4176],\n",
      "        [3.5129, 3.5329, 3.5374, 3.6382, 3.7118],\n",
      "        [3.4764, 3.5410, 3.5912, 3.7134, 3.6815],\n",
      "        [3.5048, 3.5075, 3.5255, 3.6602, 3.5409],\n",
      "        [3.6400, 3.7149, 3.6852, 3.7885, 3.6320],\n",
      "        [3.3880, 3.4050, 3.4297, 3.5380, 3.4115],\n",
      "        [3.3828, 3.4621, 3.4829, 3.5653, 3.4174],\n",
      "        [3.7073, 3.7786, 3.7563, 3.7784, 3.4983],\n",
      "        [3.6870, 3.6724, 3.6392, 3.8367, 3.8022],\n",
      "        [3.5034, 3.6355, 3.5004, 3.6662, 3.6070],\n",
      "        [3.5046, 3.5116, 3.6007, 3.5810, 3.6780],\n",
      "        [3.4241, 3.5122, 3.5512, 3.6113, 3.4511],\n",
      "        [3.7406, 3.8396, 3.7770, 3.8400, 3.5779],\n",
      "        [4.0522, 4.2132, 3.8097, 4.0313, 3.7985],\n",
      "        [3.6620, 3.7072, 3.5645, 3.7994, 3.6573],\n",
      "        [3.7305, 3.6956, 3.7060, 3.7452, 3.4955],\n",
      "        [3.6723, 3.7264, 3.6155, 3.7735, 3.7478],\n",
      "        [3.3216, 3.3599, 3.3567, 3.4486, 3.3676]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.9347, 3.6804, 3.8132, 4.3397, 4.1290],\n",
      "        [3.5119, 3.5813, 3.3962, 3.6691, 3.5250],\n",
      "        [3.3057, 3.4125, 3.3514, 3.4252, 3.3848],\n",
      "        [3.6502, 3.5612, 3.6142, 3.7630, 3.5787],\n",
      "        [3.5986, 3.7403, 3.5879, 3.8579, 3.6553],\n",
      "        [3.5525, 3.5254, 3.5950, 3.6774, 3.6061],\n",
      "        [3.4344, 3.6282, 3.4174, 3.4062, 3.5036],\n",
      "        [3.6088, 3.7743, 3.6714, 3.7800, 3.6214],\n",
      "        [3.3692, 3.4669, 3.3758, 3.5016, 3.4473],\n",
      "        [3.3662, 3.4561, 3.4544, 3.5321, 3.4207],\n",
      "        [3.5205, 3.5477, 3.5990, 3.6869, 3.6619],\n",
      "        [3.4950, 3.5815, 3.5310, 3.6001, 3.4531],\n",
      "        [3.4766, 3.5494, 3.5103, 3.7121, 3.5469],\n",
      "        [3.3980, 3.3935, 3.4206, 3.5506, 3.4090],\n",
      "        [3.7586, 3.8657, 3.8180, 3.8848, 3.6199],\n",
      "        [3.3876, 3.4298, 3.4450, 3.5461, 3.4309],\n",
      "        [3.3722, 3.5561, 3.4966, 3.5580, 3.4748],\n",
      "        [3.4945, 3.5580, 3.5064, 3.6259, 3.5580],\n",
      "        [3.4322, 3.5320, 3.5812, 3.6405, 3.6126],\n",
      "        [3.4061, 3.5051, 3.5514, 3.6002, 3.4352],\n",
      "        [3.4864, 3.4496, 3.5200, 3.6185, 3.4982],\n",
      "        [3.4080, 3.4863, 3.3541, 3.6005, 3.4445],\n",
      "        [3.6833, 3.7924, 3.5453, 3.7319, 3.6689],\n",
      "        [3.7103, 3.6666, 3.6826, 3.8929, 3.6902],\n",
      "        [3.4792, 3.4650, 3.4674, 3.5829, 3.5575],\n",
      "        [3.4168, 3.3336, 3.4953, 3.3935, 3.5375],\n",
      "        [3.7511, 3.8372, 3.7509, 3.9265, 3.8231],\n",
      "        [3.7728, 3.7063, 3.7083, 3.9429, 3.7438],\n",
      "        [3.5483, 3.7155, 3.4976, 3.7105, 3.5905],\n",
      "        [3.5039, 3.4791, 3.5181, 3.6290, 3.5237],\n",
      "        [3.4082, 3.4938, 3.5340, 3.6062, 3.4270],\n",
      "        [3.4062, 3.5999, 3.6762, 3.6364, 3.5885],\n",
      "        [3.6475, 3.6886, 3.5545, 3.7933, 3.6524],\n",
      "        [3.8499, 3.5694, 3.6089, 4.1848, 3.8902],\n",
      "        [3.7728, 3.7063, 3.7083, 3.9429, 3.7438],\n",
      "        [3.4375, 3.4694, 3.4904, 3.6395, 3.4985],\n",
      "        [3.5866, 3.5937, 3.5544, 3.7002, 3.5763],\n",
      "        [3.5008, 3.4619, 3.5253, 3.6239, 3.5049],\n",
      "        [3.9922, 4.0966, 3.8027, 3.9547, 3.8136],\n",
      "        [3.8653, 3.6359, 3.7263, 4.2763, 4.0503],\n",
      "        [3.4719, 3.4009, 3.4531, 3.5840, 3.6012],\n",
      "        [3.4895, 3.5607, 3.3979, 3.6385, 3.5149],\n",
      "        [3.5250, 3.5983, 3.3946, 3.6927, 3.5362],\n",
      "        [3.4865, 3.5719, 3.5260, 3.7380, 3.5069],\n",
      "        [3.6887, 3.6021, 3.5736, 3.6585, 3.4987],\n",
      "        [3.4294, 3.6779, 3.5275, 3.4639, 3.6013],\n",
      "        [3.3811, 3.4415, 3.4484, 3.5414, 3.4334],\n",
      "        [3.5760, 3.7504, 3.5895, 3.7621, 3.7474],\n",
      "        [3.3062, 3.4164, 3.3523, 3.4246, 3.3891],\n",
      "        [3.4706, 3.4605, 3.4605, 3.6528, 3.4470],\n",
      "        [3.5279, 3.6661, 3.5192, 3.6577, 3.6282],\n",
      "        [3.5459, 3.5187, 3.6074, 3.7093, 3.6030],\n",
      "        [3.4397, 3.4632, 3.4890, 3.6140, 3.4335],\n",
      "        [3.4947, 3.5605, 3.3880, 3.6407, 3.5140],\n",
      "        [3.9360, 3.6843, 3.8173, 4.3414, 4.1386],\n",
      "        [3.5133, 3.5090, 3.5345, 3.6618, 3.5606],\n",
      "        [3.7597, 3.7027, 3.7047, 3.9355, 3.7224],\n",
      "        [3.6611, 3.5834, 3.5675, 3.6349, 3.4845],\n",
      "        [3.7286, 3.7755, 3.7145, 3.8504, 3.8905],\n",
      "        [3.6474, 3.7849, 3.6851, 3.8174, 3.7829],\n",
      "        [3.3898, 3.3466, 3.3890, 3.5459, 3.3774],\n",
      "        [3.7559, 3.7143, 3.6321, 3.8347, 3.7315],\n",
      "        [3.5076, 3.7615, 3.6466, 3.7526, 3.7464],\n",
      "        [3.5241, 3.4999, 3.5687, 3.6773, 3.5609]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5119, 3.5758, 3.3834, 3.6667, 3.5115],\n",
      "        [3.3654, 3.5635, 3.6059, 3.5697, 3.5458],\n",
      "        [3.9716, 3.6797, 3.8127, 4.3749, 4.1368],\n",
      "        [3.4046, 3.3935, 3.4190, 3.5572, 3.4078],\n",
      "        [3.7305, 3.6986, 3.7063, 3.7474, 3.4974],\n",
      "        [3.7254, 3.7209, 3.6809, 3.8436, 3.8542],\n",
      "        [3.7101, 3.6679, 3.6828, 3.8948, 3.6915],\n",
      "        [3.5890, 3.5840, 3.5520, 3.6997, 3.5572],\n",
      "        [3.3900, 3.4888, 3.3751, 3.5229, 3.4406],\n",
      "        [3.3486, 3.4664, 3.3868, 3.4808, 3.4348],\n",
      "        [3.7362, 3.6883, 3.6725, 3.8358, 3.8645],\n",
      "        [3.4498, 3.5308, 3.3749, 3.5999, 3.4722],\n",
      "        [3.2775, 3.3848, 3.3320, 3.3952, 3.3488],\n",
      "        [3.4013, 3.3756, 3.4089, 3.5587, 3.3971],\n",
      "        [3.6365, 3.7762, 3.6789, 3.8195, 3.7581],\n",
      "        [3.6289, 3.5549, 3.5370, 3.8560, 3.6466],\n",
      "        [3.5463, 3.6415, 3.4047, 3.6182, 3.5543],\n",
      "        [3.5020, 3.5124, 3.5276, 3.6594, 3.5480],\n",
      "        [3.3730, 3.5691, 3.5095, 3.5532, 3.4744],\n",
      "        [3.8598, 3.7147, 3.7648, 4.0772, 3.8695],\n",
      "        [3.4096, 3.5030, 3.3764, 3.5446, 3.4598],\n",
      "        [3.5909, 3.8011, 3.6325, 3.7921, 3.7695],\n",
      "        [3.5574, 3.6474, 3.4238, 3.6326, 3.5666],\n",
      "        [3.4967, 3.5331, 3.6207, 3.7482, 3.7014],\n",
      "        [3.7727, 3.7076, 3.7084, 3.9448, 3.7451],\n",
      "        [3.6542, 3.7639, 3.5349, 3.7428, 3.6870],\n",
      "        [3.4351, 3.3610, 3.4609, 3.5814, 3.5130],\n",
      "        [3.6125, 3.7070, 3.6163, 3.7270, 3.5131],\n",
      "        [3.5809, 3.5513, 3.6415, 3.7261, 3.6178],\n",
      "        [3.5181, 3.6343, 3.5742, 3.6807, 3.5307],\n",
      "        [3.4920, 3.5632, 3.3941, 3.6501, 3.5133],\n",
      "        [3.5067, 3.4906, 3.5110, 3.6229, 3.5883],\n",
      "        [3.5163, 3.4798, 3.5366, 3.6325, 3.5271],\n",
      "        [3.6728, 3.5862, 3.6486, 3.8027, 3.6190],\n",
      "        [3.3804, 3.4820, 3.3802, 3.5069, 3.4419],\n",
      "        [3.7822, 3.5723, 3.5876, 4.0795, 3.8152],\n",
      "        [3.5469, 3.5206, 3.6295, 3.8203, 3.7677],\n",
      "        [3.5071, 3.7629, 3.6467, 3.7543, 3.7477],\n",
      "        [3.6187, 3.7483, 3.6190, 3.8738, 3.6636],\n",
      "        [3.3701, 3.4419, 3.4477, 3.5346, 3.4191],\n",
      "        [3.6033, 3.5425, 3.5817, 3.6312, 3.4940],\n",
      "        [3.3807, 3.4841, 3.3797, 3.5111, 3.4485],\n",
      "        [3.5028, 3.5757, 3.3911, 3.6597, 3.5178],\n",
      "        [3.5241, 3.6839, 3.5238, 3.7872, 3.5456],\n",
      "        [3.4406, 3.7463, 3.5594, 3.7092, 3.6951],\n",
      "        [3.4804, 3.5758, 3.6583, 3.6079, 3.5434],\n",
      "        [3.4692, 3.5479, 3.3841, 3.6232, 3.4885],\n",
      "        [3.6573, 3.7588, 3.5622, 3.9068, 3.7058],\n",
      "        [3.5643, 3.3729, 3.6369, 3.7201, 3.6279],\n",
      "        [3.3497, 3.4490, 3.3643, 3.4775, 3.4125],\n",
      "        [3.4407, 3.4708, 3.5152, 3.6529, 3.5457],\n",
      "        [4.0002, 4.1554, 3.7291, 3.9511, 3.7658],\n",
      "        [3.5837, 3.4750, 3.7623, 3.7271, 3.6630],\n",
      "        [3.5890, 3.8527, 3.5750, 3.8812, 3.7413],\n",
      "        [3.4017, 3.5296, 3.4572, 3.6866, 3.4151],\n",
      "        [3.6679, 3.6542, 3.7076, 3.7531, 3.5369],\n",
      "        [3.6539, 3.6923, 3.6460, 3.7066, 3.6694],\n",
      "        [3.6087, 3.6159, 3.4507, 3.7020, 3.6737],\n",
      "        [3.3564, 3.4520, 3.3715, 3.4842, 3.4159],\n",
      "        [3.3621, 3.5789, 3.3365, 3.6013, 3.3844],\n",
      "        [3.4620, 3.5446, 3.5216, 3.6577, 3.4760],\n",
      "        [3.6913, 3.5306, 3.5391, 4.0090, 3.7314],\n",
      "        [3.3585, 3.5329, 3.4811, 3.5365, 3.4469],\n",
      "        [3.5182, 3.4955, 3.5735, 3.6793, 3.5732]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4981, 3.5317, 3.4796, 3.6177, 3.5355],\n",
      "        [3.4900, 3.5423, 3.4230, 3.6532, 3.4925],\n",
      "        [3.6537, 3.7442, 3.6746, 3.7536, 3.5342],\n",
      "        [3.6957, 3.7197, 3.7218, 3.9397, 3.6468],\n",
      "        [3.5660, 3.6237, 3.4902, 3.7094, 3.6583],\n",
      "        [3.4399, 3.5272, 3.3806, 3.5834, 3.4746],\n",
      "        [3.4189, 3.4823, 3.3821, 3.5955, 3.4436],\n",
      "        [3.5448, 3.5208, 3.6082, 3.7124, 3.6054],\n",
      "        [3.5417, 3.5851, 3.7054, 3.7300, 3.6973],\n",
      "        [3.5959, 3.7079, 3.6086, 3.7215, 3.5079],\n",
      "        [3.8860, 3.7135, 3.7852, 4.0611, 3.8233],\n",
      "        [3.6589, 3.7620, 3.5642, 3.9095, 3.7104],\n",
      "        [3.5083, 3.6708, 3.5575, 3.6112, 3.6290],\n",
      "        [3.6466, 3.6019, 3.6822, 3.7021, 3.4264],\n",
      "        [3.4822, 3.4331, 3.5169, 3.6089, 3.4840],\n",
      "        [3.5307, 3.8289, 3.5993, 3.8244, 3.7321],\n",
      "        [3.5868, 3.8485, 3.5665, 3.8738, 3.7290],\n",
      "        [3.3783, 3.5742, 3.6272, 3.5587, 3.5423],\n",
      "        [4.0352, 4.1776, 3.7937, 4.0004, 3.7735],\n",
      "        [3.9751, 4.0721, 3.9869, 4.1845, 4.2215],\n",
      "        [3.4230, 3.5159, 3.5526, 3.6148, 3.4544],\n",
      "        [3.5445, 3.8419, 3.6167, 3.8276, 3.7581],\n",
      "        [3.5747, 3.5432, 3.6267, 3.7243, 3.6120],\n",
      "        [3.4923, 3.4964, 3.5239, 3.5261, 3.3410],\n",
      "        [3.7084, 3.5559, 3.5510, 3.7303, 3.6590],\n",
      "        [3.5168, 3.4587, 3.5592, 3.6761, 3.6354],\n",
      "        [3.5018, 3.7126, 3.5525, 3.6497, 3.4552],\n",
      "        [3.5188, 3.5273, 3.6280, 3.7792, 3.7383],\n",
      "        [3.8217, 3.5782, 3.6112, 4.1606, 3.8689],\n",
      "        [3.5158, 3.5826, 3.5508, 3.6405, 3.4583],\n",
      "        [3.6502, 3.7285, 3.6751, 3.8189, 3.6685],\n",
      "        [3.8575, 3.6410, 3.7309, 4.2801, 4.0547],\n",
      "        [3.4978, 3.4633, 3.5274, 3.6202, 3.5055],\n",
      "        [3.4734, 3.5356, 3.4993, 3.6714, 3.6009],\n",
      "        [3.9995, 4.1562, 3.7300, 3.9525, 3.7669],\n",
      "        [3.4518, 3.6025, 3.5192, 3.5302, 3.4665],\n",
      "        [3.6589, 3.7620, 3.5642, 3.9095, 3.7104],\n",
      "        [3.7252, 3.8630, 3.6801, 3.9426, 3.7957],\n",
      "        [3.7394, 3.7510, 3.7007, 3.8549, 3.9066],\n",
      "        [3.3920, 3.4538, 3.4560, 3.5480, 3.4491],\n",
      "        [3.4946, 3.4848, 3.5071, 3.6289, 3.5230],\n",
      "        [3.5125, 3.7953, 3.5909, 3.7939, 3.7318],\n",
      "        [3.5283, 3.6669, 3.5128, 3.6194, 3.6124],\n",
      "        [3.5106, 3.6584, 3.5373, 3.6163, 3.6182],\n",
      "        [3.7159, 3.7407, 3.7156, 3.8336, 3.9045],\n",
      "        [3.6025, 3.5432, 3.5826, 3.6327, 3.4951],\n",
      "        [3.6590, 3.7044, 3.6774, 3.8299, 3.6120],\n",
      "        [3.6228, 3.4923, 3.7530, 3.7712, 3.6973],\n",
      "        [3.6706, 3.6692, 3.6260, 3.7692, 3.7704],\n",
      "        [3.8144, 3.7228, 3.6936, 3.9021, 3.7693],\n",
      "        [3.9707, 3.6806, 3.8136, 4.3766, 4.1379],\n",
      "        [3.3663, 3.4829, 3.3895, 3.5505, 3.4215],\n",
      "        [3.6171, 3.6486, 3.5202, 3.7185, 3.7587],\n",
      "        [3.6210, 3.6374, 3.5662, 3.8602, 3.5984],\n",
      "        [3.9064, 3.9869, 3.5804, 3.8517, 3.6386],\n",
      "        [3.3588, 3.5308, 3.4829, 3.5381, 3.4480],\n",
      "        [3.6905, 3.5314, 3.5400, 4.0105, 3.7325],\n",
      "        [3.6522, 3.5787, 3.5183, 3.8999, 3.6881],\n",
      "        [3.4169, 3.3828, 3.4167, 3.5714, 3.4083],\n",
      "        [3.4170, 3.4584, 3.4912, 3.6067, 3.4169],\n",
      "        [3.7052, 3.6167, 3.6746, 3.8586, 3.6495],\n",
      "        [3.5068, 3.5068, 3.5482, 3.6652, 3.5600],\n",
      "        [3.6641, 3.6364, 3.6634, 3.8280, 3.5077],\n",
      "        [3.8987, 3.9246, 3.8024, 4.1568, 3.9176]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4967, 3.6215, 3.4484, 3.7620, 3.4788],\n",
      "        [3.6384, 3.5887, 3.6078, 3.6741, 3.5094],\n",
      "        [3.6929, 3.7586, 3.5997, 3.8674, 3.7643],\n",
      "        [3.8145, 3.6721, 3.7429, 3.9947, 3.7568],\n",
      "        [3.5877, 3.5902, 3.5541, 3.7072, 3.5689],\n",
      "        [3.5040, 3.6315, 3.5844, 3.6760, 3.4974],\n",
      "        [3.8890, 3.6739, 3.7532, 4.3041, 4.0584],\n",
      "        [3.3957, 3.3967, 3.4222, 3.5550, 3.4122],\n",
      "        [3.4180, 3.3944, 3.4233, 3.5847, 3.4254],\n",
      "        [3.7466, 3.5514, 3.5761, 4.0604, 3.7949],\n",
      "        [3.7321, 3.6891, 3.6729, 3.8379, 3.8655],\n",
      "        [3.6458, 3.7266, 3.5572, 3.7280, 3.6484],\n",
      "        [3.6564, 3.7788, 3.5454, 3.7549, 3.6920],\n",
      "        [3.7407, 3.8020, 3.7911, 4.0338, 4.0322],\n",
      "        [3.3960, 3.4988, 3.3830, 3.5336, 3.4586],\n",
      "        [3.6315, 3.7114, 3.6397, 3.7615, 3.5350],\n",
      "        [3.4663, 3.5390, 3.4983, 3.6856, 3.5705],\n",
      "        [3.3678, 3.4662, 3.3699, 3.5019, 3.4254],\n",
      "        [3.8204, 3.5795, 3.6119, 4.1625, 3.8697],\n",
      "        [3.4597, 3.5468, 3.5232, 3.6604, 3.4777],\n",
      "        [3.5395, 3.6196, 3.5421, 3.6956, 3.6170],\n",
      "        [3.4244, 3.5502, 3.5894, 3.6651, 3.6247],\n",
      "        [3.5986, 3.4938, 3.7747, 3.7509, 3.6918],\n",
      "        [3.4323, 3.5300, 3.3948, 3.5785, 3.4800],\n",
      "        [3.6668, 3.7925, 3.6876, 3.8214, 3.6617],\n",
      "        [3.5156, 3.4600, 3.5599, 3.6778, 3.6363],\n",
      "        [3.7811, 3.6847, 3.6340, 3.8320, 3.7605],\n",
      "        [3.8629, 3.6395, 3.7281, 4.2820, 4.0535],\n",
      "        [3.6288, 3.7076, 3.6960, 3.7858, 3.6477],\n",
      "        [3.3071, 3.4370, 3.4091, 3.5108, 3.4377],\n",
      "        [3.6712, 3.4453, 3.4234, 3.6037, 3.6226],\n",
      "        [3.6381, 3.7407, 3.6737, 3.8211, 3.6940],\n",
      "        [3.4987, 3.5763, 3.3895, 3.6726, 3.5189],\n",
      "        [3.5486, 3.5908, 3.5511, 3.6726, 3.5810],\n",
      "        [3.4379, 3.5132, 3.5710, 3.6050, 3.5542],\n",
      "        [3.5118, 3.5842, 3.4010, 3.6780, 3.5287],\n",
      "        [3.4177, 3.4835, 3.3829, 3.5972, 3.4445],\n",
      "        [3.6599, 3.7221, 3.7067, 3.8325, 3.7321],\n",
      "        [3.7315, 3.6908, 3.6868, 3.9520, 3.9268],\n",
      "        [3.4311, 3.7405, 3.6295, 3.7033, 3.7136],\n",
      "        [3.2805, 3.3886, 3.3375, 3.4019, 3.3551],\n",
      "        [3.5219, 3.5178, 3.5340, 3.5505, 3.3727],\n",
      "        [3.3640, 3.4593, 3.4563, 3.5365, 3.4240],\n",
      "        [3.3995, 3.5318, 3.4587, 3.6894, 3.4167],\n",
      "        [3.5194, 3.5191, 3.4208, 3.6314, 3.6210],\n",
      "        [3.7803, 3.5745, 3.5892, 4.0829, 3.8171],\n",
      "        [3.4089, 3.4936, 3.3751, 3.5443, 3.4491],\n",
      "        [3.3801, 3.4307, 3.4466, 3.5495, 3.4317],\n",
      "        [3.5026, 3.6812, 3.5771, 3.6056, 3.6377],\n",
      "        [3.4263, 3.5052, 3.3761, 3.5621, 3.4565],\n",
      "        [3.6109, 3.5542, 3.5634, 3.5868, 3.4190],\n",
      "        [3.7109, 3.7628, 3.6660, 3.8250, 3.7678],\n",
      "        [3.7145, 3.7421, 3.7163, 3.8354, 3.9052],\n",
      "        [3.6471, 3.7832, 3.5610, 3.7460, 3.6838],\n",
      "        [3.5101, 3.5420, 3.5381, 3.6433, 3.7159],\n",
      "        [4.0341, 4.1789, 3.7945, 4.0022, 3.7743],\n",
      "        [3.6023, 3.5363, 3.5831, 3.6286, 3.5114],\n",
      "        [3.3195, 3.3646, 3.3591, 3.4536, 3.3717],\n",
      "        [3.5028, 3.4481, 3.5477, 3.6613, 3.6225],\n",
      "        [3.6355, 3.6976, 3.5672, 3.6471, 3.6110],\n",
      "        [3.6880, 3.7621, 3.5623, 3.7747, 3.7407],\n",
      "        [3.5711, 3.7496, 3.5871, 3.7622, 3.7460],\n",
      "        [3.4328, 3.4773, 3.4834, 3.6539, 3.5014],\n",
      "        [3.5997, 3.4822, 3.7490, 3.7444, 3.6826]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4945, 3.5699, 3.3883, 3.6659, 3.5183],\n",
      "        [3.4713, 3.4912, 3.6187, 3.5213, 3.6787],\n",
      "        [3.5129, 3.5289, 3.5944, 3.6095, 3.6916],\n",
      "        [3.6242, 3.8418, 3.6342, 3.8167, 3.7077],\n",
      "        [3.4083, 3.3674, 3.4075, 3.5676, 3.3977],\n",
      "        [3.6974, 3.9267, 3.6603, 3.9609, 3.8389],\n",
      "        [3.5004, 3.4775, 3.5140, 3.6325, 3.5276],\n",
      "        [3.5879, 3.7024, 3.5447, 3.7706, 3.6149],\n",
      "        [3.3972, 3.3776, 3.4109, 3.5650, 3.3998],\n",
      "        [3.6310, 3.6358, 3.6015, 3.7033, 3.4253],\n",
      "        [3.4873, 3.5337, 3.4411, 3.6661, 3.5043],\n",
      "        [3.4189, 3.4326, 3.3338, 3.6252, 3.4280],\n",
      "        [3.7697, 3.7113, 3.7108, 3.9502, 3.7484],\n",
      "        [3.3263, 3.4341, 3.2633, 3.5344, 3.3500],\n",
      "        [3.7399, 3.8088, 3.7984, 4.0322, 4.0417],\n",
      "        [3.7322, 3.8451, 3.6953, 3.7222, 3.7598],\n",
      "        [3.4822, 3.7883, 3.5748, 3.7744, 3.7097],\n",
      "        [3.8877, 3.6755, 3.7538, 4.3066, 4.0602],\n",
      "        [3.8337, 3.7355, 3.7431, 3.9499, 3.8247],\n",
      "        [3.3993, 3.3703, 3.4057, 3.5735, 3.4027],\n",
      "        [3.7216, 3.7251, 3.6830, 3.8485, 3.8575],\n",
      "        [3.5640, 3.5434, 3.6262, 3.7305, 3.6174],\n",
      "        [3.3105, 3.4315, 3.3577, 3.4410, 3.3945],\n",
      "        [3.4875, 3.7173, 3.5505, 3.6436, 3.4549],\n",
      "        [3.8450, 3.8613, 3.8519, 4.1146, 4.1003],\n",
      "        [3.8562, 3.9708, 3.6950, 3.8288, 3.7178],\n",
      "        [3.5829, 3.7598, 3.5764, 3.8561, 3.6623],\n",
      "        [3.5246, 3.5096, 3.5876, 3.6947, 3.5928],\n",
      "        [3.4043, 3.4903, 3.5282, 3.6049, 3.4268],\n",
      "        [3.5104, 3.5240, 3.6114, 3.5631, 3.7032],\n",
      "        [3.8745, 3.8395, 3.7393, 4.0204, 3.8800],\n",
      "        [3.7468, 3.7331, 3.8332, 3.7939, 3.5760],\n",
      "        [3.5799, 3.4785, 3.7645, 3.7321, 3.6665],\n",
      "        [3.5126, 3.5959, 3.4023, 3.6847, 3.5396],\n",
      "        [3.5896, 3.5892, 3.5464, 3.7858, 3.5907],\n",
      "        [3.4790, 3.4991, 3.6446, 3.5107, 3.6964],\n",
      "        [3.4978, 3.6358, 3.4927, 3.6806, 3.6135],\n",
      "        [3.6653, 3.6173, 3.7097, 3.7374, 3.4391],\n",
      "        [3.4959, 3.6200, 3.4807, 3.6870, 3.6108],\n",
      "        [3.5866, 3.7244, 3.5868, 3.6734, 3.6788],\n",
      "        [3.4424, 3.4659, 3.5083, 3.6248, 3.5236],\n",
      "        [3.2644, 3.3961, 3.4058, 3.4637, 3.4059],\n",
      "        [3.6296, 3.7361, 3.5359, 3.8735, 3.6668],\n",
      "        [3.7310, 3.7132, 3.7092, 3.9364, 3.9284],\n",
      "        [3.7799, 3.6862, 3.6345, 3.8342, 3.7622],\n",
      "        [3.5780, 3.5198, 3.6293, 3.7609, 3.6138],\n",
      "        [3.5951, 3.7454, 3.5901, 3.8648, 3.6600],\n",
      "        [3.4765, 3.5795, 3.6605, 3.6129, 3.5468],\n",
      "        [3.6423, 3.6440, 3.6134, 3.7150, 3.4478],\n",
      "        [3.5059, 3.4971, 3.5230, 3.6515, 3.5348],\n",
      "        [3.5382, 3.6212, 3.5427, 3.6976, 3.6186],\n",
      "        [3.5133, 3.5844, 3.3910, 3.6808, 3.5208],\n",
      "        [3.5033, 3.5217, 3.5304, 3.6631, 3.5469],\n",
      "        [3.8676, 3.7473, 3.8130, 4.0681, 3.8294],\n",
      "        [3.5849, 3.8609, 3.5856, 3.8848, 3.7529],\n",
      "        [3.6290, 3.6973, 3.6876, 3.7635, 3.6606],\n",
      "        [3.5003, 3.4479, 3.5393, 3.5574, 3.5789],\n",
      "        [3.4869, 3.4723, 3.4616, 3.6751, 3.4555],\n",
      "        [3.8151, 3.7683, 3.7586, 3.9996, 3.8033],\n",
      "        [3.3957, 3.4671, 3.4915, 3.5835, 3.4333],\n",
      "        [3.4001, 3.6063, 3.6784, 3.6415, 3.5968],\n",
      "        [3.6403, 3.5711, 3.6130, 3.7660, 3.5931],\n",
      "        [3.4363, 3.4680, 3.4915, 3.6205, 3.4385],\n",
      "        [3.5078, 3.4964, 3.5277, 3.6386, 3.5910]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7374, 3.8053, 3.7920, 4.0386, 4.0361],\n",
      "        [3.5137, 3.6583, 3.5092, 3.6688, 3.6273],\n",
      "        [3.3981, 3.6080, 3.6789, 3.6438, 3.5990],\n",
      "        [3.7449, 3.7348, 3.8336, 3.7963, 3.5781],\n",
      "        [3.7825, 3.8026, 3.6597, 3.8966, 3.8565],\n",
      "        [3.6663, 3.6595, 3.6702, 3.8344, 3.5351],\n",
      "        [3.4090, 3.5075, 3.3800, 3.5573, 3.4598],\n",
      "        [3.6105, 3.7269, 3.5296, 3.8693, 3.6609],\n",
      "        [3.2930, 3.4137, 3.3499, 3.4270, 3.3855],\n",
      "        [3.4852, 3.5766, 3.5373, 3.7486, 3.5310],\n",
      "        [3.4888, 3.4319, 3.5423, 3.5295, 3.5847],\n",
      "        [3.4838, 3.5545, 3.5035, 3.5903, 3.5483],\n",
      "        [3.4791, 3.7444, 3.6417, 3.7397, 3.7105],\n",
      "        [3.6352, 3.7441, 3.6747, 3.8255, 3.6976],\n",
      "        [3.3854, 3.7495, 3.6034, 3.6377, 3.7210],\n",
      "        [3.4841, 3.4299, 3.4875, 3.6268, 3.6276],\n",
      "        [3.3592, 3.4501, 3.4471, 3.5354, 3.4230],\n",
      "        [3.3557, 3.4629, 3.4521, 3.5369, 3.4273],\n",
      "        [3.5075, 3.6301, 3.5780, 3.6792, 3.5084],\n",
      "        [3.6864, 3.6928, 3.6537, 3.8328, 3.7983],\n",
      "        [3.3647, 3.5619, 3.5023, 3.5629, 3.4840],\n",
      "        [3.5713, 3.5577, 3.6427, 3.7327, 3.6213],\n",
      "        [3.7547, 3.8615, 3.5546, 3.7661, 3.6681],\n",
      "        [3.7112, 3.8205, 3.6820, 3.8954, 3.9294],\n",
      "        [3.4988, 3.4958, 3.5158, 3.6370, 3.5309],\n",
      "        [3.5148, 3.5962, 3.3932, 3.6914, 3.5327],\n",
      "        [3.5890, 3.3799, 3.6643, 3.7147, 3.5735],\n",
      "        [3.9206, 3.9974, 3.6049, 3.8754, 3.6454],\n",
      "        [3.7449, 3.7566, 3.7300, 3.8542, 3.8241],\n",
      "        [3.6556, 3.7329, 3.6921, 3.8110, 3.7128],\n",
      "        [3.9875, 4.1030, 3.8057, 3.9643, 3.8205],\n",
      "        [3.6472, 3.7091, 3.5802, 3.6810, 3.6272],\n",
      "        [3.4811, 3.5791, 3.5285, 3.7465, 3.5133],\n",
      "        [3.7362, 3.6927, 3.5618, 3.8278, 3.7748],\n",
      "        [3.4181, 3.7093, 3.6532, 3.6672, 3.7130],\n",
      "        [3.4209, 3.4219, 3.4507, 3.5773, 3.4234],\n",
      "        [3.8109, 3.7273, 3.6952, 3.9086, 3.7741],\n",
      "        [3.5143, 3.5032, 3.5434, 3.6529, 3.5938],\n",
      "        [3.6545, 3.7666, 3.5658, 3.9156, 3.7152],\n",
      "        [3.7563, 3.8580, 3.5552, 3.7682, 3.6675],\n",
      "        [3.4975, 3.7175, 3.5541, 3.6554, 3.4594],\n",
      "        [3.5993, 3.5394, 3.5840, 3.6331, 3.5152],\n",
      "        [3.3783, 3.5245, 3.4851, 3.5610, 3.4774],\n",
      "        [3.7879, 3.6208, 3.7104, 3.9005, 3.7343],\n",
      "        [3.5050, 3.7229, 3.4839, 3.7872, 3.6139],\n",
      "        [3.4390, 3.5340, 3.3810, 3.5954, 3.4822],\n",
      "        [3.3761, 3.4892, 3.3826, 3.5181, 3.4541],\n",
      "        [3.4389, 3.6569, 3.5402, 3.6793, 3.6705],\n",
      "        [3.3169, 3.3676, 3.3603, 3.4576, 3.3752],\n",
      "        [3.5004, 3.4936, 3.5182, 3.6350, 3.5309],\n",
      "        [3.3966, 3.5356, 3.4596, 3.6934, 3.4201],\n",
      "        [3.5632, 3.7092, 3.5724, 3.6874, 3.6508],\n",
      "        [3.6517, 3.7219, 3.5808, 3.7354, 3.6383],\n",
      "        [3.3519, 3.4570, 3.3744, 3.4912, 3.4215],\n",
      "        [3.4959, 3.5795, 3.3905, 3.6768, 3.5226],\n",
      "        [3.6254, 3.7119, 3.6412, 3.7622, 3.5340],\n",
      "        [3.6312, 3.5954, 3.6070, 3.6925, 3.4878],\n",
      "        [3.7363, 3.8482, 3.7797, 3.8496, 3.5854],\n",
      "        [3.5788, 3.6249, 3.4999, 3.7424, 3.6125],\n",
      "        [3.7108, 3.6903, 3.6719, 3.8437, 3.8720],\n",
      "        [3.4966, 3.5093, 3.5228, 3.6540, 3.5398],\n",
      "        [3.5596, 3.5410, 3.6174, 3.7178, 3.6113],\n",
      "        [3.3831, 3.4750, 3.4887, 3.5806, 3.4320],\n",
      "        [3.4859, 3.7191, 3.5509, 3.6458, 3.4568]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5262, 3.5030, 3.5851, 3.7067, 3.5990],\n",
      "        [3.6618, 3.7728, 3.6010, 3.8158, 3.6894],\n",
      "        [3.7408, 3.8934, 3.6694, 3.9415, 3.8565],\n",
      "        [3.4732, 3.4724, 3.4702, 3.5949, 3.5656],\n",
      "        [3.3572, 3.5705, 3.5959, 3.5728, 3.5876],\n",
      "        [3.2786, 3.4010, 3.3401, 3.4113, 3.3648],\n",
      "        [3.4037, 3.4641, 3.3604, 3.6158, 3.4418],\n",
      "        [3.3837, 3.7508, 3.6036, 3.6413, 3.7225],\n",
      "        [3.4779, 3.7254, 3.5459, 3.6418, 3.4667],\n",
      "        [3.4275, 3.6360, 3.4202, 3.4180, 3.5115],\n",
      "        [3.4041, 3.4094, 3.3222, 3.6095, 3.4014],\n",
      "        [3.4810, 3.5745, 3.5338, 3.7491, 3.5126],\n",
      "        [3.4066, 3.4705, 3.3891, 3.5875, 3.4354],\n",
      "        [3.5815, 3.8644, 3.5863, 3.8906, 3.7568],\n",
      "        [3.1988, 3.3482, 3.3851, 3.4164, 3.3752],\n",
      "        [3.4949, 3.4430, 3.5275, 3.6564, 3.6289],\n",
      "        [3.2691, 3.4001, 3.4166, 3.4732, 3.4377],\n",
      "        [3.3633, 3.5631, 3.5026, 3.5662, 3.4857],\n",
      "        [3.4231, 3.4755, 3.4840, 3.6504, 3.5045],\n",
      "        [3.3649, 3.5386, 3.4909, 3.5659, 3.4682],\n",
      "        [3.4482, 3.5124, 3.4157, 3.5563, 3.4703],\n",
      "        [3.3607, 3.4886, 3.3918, 3.5595, 3.4275],\n",
      "        [3.6437, 3.7347, 3.5738, 3.8627, 3.8248],\n",
      "        [3.5128, 3.5044, 3.5436, 3.6563, 3.5955],\n",
      "        [3.3624, 3.4350, 3.4450, 3.5431, 3.4204],\n",
      "        [3.5195, 3.5446, 3.5497, 3.6981, 3.5820],\n",
      "        [3.3826, 3.5660, 3.6028, 3.5951, 3.5655],\n",
      "        [3.5461, 3.6678, 3.4717, 3.6420, 3.5946],\n",
      "        [3.7549, 3.8593, 3.5554, 3.7718, 3.6692],\n",
      "        [3.4951, 3.4783, 3.5220, 3.6373, 3.5269],\n",
      "        [3.4488, 3.4801, 3.5146, 3.6422, 3.5235],\n",
      "        [3.3247, 3.4554, 3.3831, 3.4686, 3.4274],\n",
      "        [3.6757, 3.6488, 3.6387, 3.7924, 3.8348],\n",
      "        [3.3950, 3.5371, 3.4597, 3.6970, 3.4216],\n",
      "        [3.5224, 3.6731, 3.5146, 3.6286, 3.6180],\n",
      "        [3.3205, 3.3554, 3.3643, 3.4632, 3.3803],\n",
      "        [3.5894, 3.5912, 3.4173, 3.7692, 3.6888],\n",
      "        [3.5078, 3.4631, 3.5595, 3.6817, 3.6378],\n",
      "        [3.4943, 3.5808, 3.3906, 3.6802, 3.5243],\n",
      "        [3.4861, 3.7050, 3.6117, 3.5989, 3.6523],\n",
      "        [3.3042, 3.4374, 3.4036, 3.5303, 3.4360],\n",
      "        [3.3639, 3.4964, 3.4694, 3.5557, 3.4583],\n",
      "        [3.6073, 3.5376, 3.6907, 3.8072, 3.6136],\n",
      "        [3.7650, 3.4767, 3.6008, 4.0193, 3.8946],\n",
      "        [3.3800, 3.4739, 3.4636, 3.5544, 3.4572],\n",
      "        [3.7041, 3.6746, 3.6859, 3.9064, 3.6986],\n",
      "        [3.8303, 3.7286, 3.6914, 4.0181, 3.7834],\n",
      "        [3.8607, 3.6954, 3.7661, 4.0563, 3.8511],\n",
      "        [3.8335, 3.7282, 3.6923, 4.0132, 3.7857],\n",
      "        [3.5778, 3.7897, 3.6643, 3.7683, 3.6059],\n",
      "        [3.4098, 3.4089, 3.4454, 3.5817, 3.4076],\n",
      "        [3.4730, 3.5649, 3.3893, 3.6306, 3.5122],\n",
      "        [3.3599, 3.5425, 3.4907, 3.5541, 3.4640],\n",
      "        [3.6156, 3.6534, 3.5221, 3.7288, 3.7492],\n",
      "        [3.6594, 3.7693, 3.6652, 3.8559, 3.6778],\n",
      "        [3.4551, 3.4560, 3.3508, 3.5754, 3.5670],\n",
      "        [3.7318, 3.7427, 3.7686, 3.9868, 3.6789],\n",
      "        [3.3407, 3.3779, 3.3752, 3.4932, 3.3943],\n",
      "        [3.4095, 3.5202, 3.6263, 3.6117, 3.6052],\n",
      "        [3.5790, 3.5560, 3.6420, 3.7462, 3.6290],\n",
      "        [3.2863, 3.4094, 3.3409, 3.4256, 3.3747],\n",
      "        [3.4803, 3.5424, 3.4762, 3.6103, 3.5195],\n",
      "        [3.3918, 3.5031, 3.3844, 3.5410, 3.4638],\n",
      "        [3.3701, 3.5776, 3.5090, 3.5779, 3.4972]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6819, 3.7373, 3.6788, 3.7471, 3.6976],\n",
      "        [3.6333, 3.7466, 3.6759, 3.8320, 3.7006],\n",
      "        [3.5749, 3.7891, 3.6179, 3.7874, 3.7650],\n",
      "        [3.6497, 3.6396, 3.6286, 3.7194, 3.4889],\n",
      "        [3.5759, 3.4821, 3.7661, 3.7409, 3.6716],\n",
      "        [3.4807, 3.7774, 3.5882, 3.7642, 3.7355],\n",
      "        [3.5305, 3.5214, 3.6092, 3.7213, 3.6084],\n",
      "        [3.3487, 3.4821, 3.4650, 3.5439, 3.4311],\n",
      "        [3.6583, 3.5869, 3.6386, 3.8114, 3.6146],\n",
      "        [3.4065, 3.5185, 3.3894, 3.5660, 3.4767],\n",
      "        [3.3521, 3.5437, 3.4911, 3.5588, 3.4619],\n",
      "        [3.5620, 3.6671, 3.4933, 3.7406, 3.6090],\n",
      "        [3.4134, 3.3999, 3.4254, 3.5947, 3.4318],\n",
      "        [3.3963, 3.3941, 3.4229, 3.5675, 3.4125],\n",
      "        [3.5201, 3.6094, 3.4072, 3.7151, 3.5508],\n",
      "        [3.4992, 3.5786, 3.3997, 3.6603, 3.5387],\n",
      "        [3.6296, 3.6987, 3.5544, 3.8111, 3.6554],\n",
      "        [3.6583, 3.7319, 3.6824, 3.8387, 3.6544],\n",
      "        [3.5233, 3.6008, 3.6410, 3.7163, 3.6311],\n",
      "        [3.5956, 3.6384, 3.5349, 3.7102, 3.5811],\n",
      "        [3.4959, 3.5832, 3.3948, 3.6730, 3.5266],\n",
      "        [3.5179, 3.5605, 3.4440, 3.7220, 3.5503],\n",
      "        [3.4799, 3.5434, 3.4774, 3.6131, 3.5209],\n",
      "        [3.3599, 3.5013, 3.4748, 3.5607, 3.4567],\n",
      "        [3.5320, 3.5591, 3.5696, 3.6637, 3.7713],\n",
      "        [3.3521, 3.5220, 3.4781, 3.5476, 3.4469],\n",
      "        [3.4793, 3.4583, 3.5235, 3.6339, 3.5084],\n",
      "        [3.6366, 3.5750, 3.6145, 3.7749, 3.5987],\n",
      "        [3.6039, 3.4049, 3.6790, 3.7453, 3.6054],\n",
      "        [3.5043, 3.5918, 3.3974, 3.6934, 3.5329],\n",
      "        [3.4434, 3.4960, 3.4170, 3.6784, 3.4997],\n",
      "        [3.2094, 3.3464, 3.3798, 3.4333, 3.3916],\n",
      "        [3.7065, 3.8607, 3.6626, 3.9351, 3.7943],\n",
      "        [3.5056, 3.4044, 3.4738, 3.5234, 3.4281],\n",
      "        [3.4689, 3.5518, 3.5956, 3.7296, 3.6923],\n",
      "        [3.5395, 3.7060, 3.5594, 3.6837, 3.6475],\n",
      "        [3.5162, 3.5942, 3.5300, 3.6788, 3.5964],\n",
      "        [3.5414, 3.5262, 3.6017, 3.7019, 3.5989],\n",
      "        [3.6117, 3.6895, 3.5377, 3.7820, 3.7096],\n",
      "        [3.7497, 3.7192, 3.7134, 3.9830, 3.9449],\n",
      "        [3.5710, 3.5665, 3.5373, 3.7580, 3.5837],\n",
      "        [3.6416, 3.7297, 3.5716, 3.7850, 3.6396],\n",
      "        [3.8637, 4.0454, 3.5932, 3.8210, 3.6744],\n",
      "        [3.4325, 3.7256, 3.5904, 3.7009, 3.7029],\n",
      "        [3.5803, 3.6009, 3.5620, 3.7104, 3.5880],\n",
      "        [3.5619, 3.5467, 3.5360, 3.7282, 3.5809],\n",
      "        [3.4971, 3.4975, 3.5199, 3.6490, 3.5405],\n",
      "        [3.5219, 3.5701, 3.4588, 3.7281, 3.5591],\n",
      "        [3.5943, 3.5327, 3.5813, 3.6303, 3.5230],\n",
      "        [3.7090, 3.8229, 3.6832, 3.9021, 3.9326],\n",
      "        [3.8015, 3.8063, 3.6684, 3.9112, 3.8825],\n",
      "        [3.8459, 3.7687, 3.6903, 3.9505, 3.8221],\n",
      "        [3.3079, 3.4304, 3.2620, 3.5359, 3.3505],\n",
      "        [3.5793, 3.6126, 3.5024, 3.7677, 3.6182],\n",
      "        [3.4095, 3.4099, 3.4465, 3.5844, 3.4089],\n",
      "        [3.7353, 3.8076, 3.7932, 4.0455, 4.0394],\n",
      "        [3.5962, 3.5312, 3.5824, 3.6261, 3.5369],\n",
      "        [3.5378, 3.5253, 3.6093, 3.7290, 3.6095],\n",
      "        [3.5013, 3.4694, 3.4381, 3.7105, 3.4609],\n",
      "        [3.6505, 3.7418, 3.6787, 3.8323, 3.6808],\n",
      "        [3.4643, 3.4537, 3.5072, 3.5989, 3.5001],\n",
      "        [3.4514, 3.4787, 3.5223, 3.6413, 3.5240],\n",
      "        [3.4611, 3.4645, 3.5108, 3.6122, 3.5131],\n",
      "        [3.5127, 3.5343, 3.6312, 3.7919, 3.7463]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4369, 3.5590, 3.4975, 3.7288, 3.4700],\n",
      "        [3.3569, 3.4530, 3.4502, 3.5435, 3.4270],\n",
      "        [3.6608, 3.7036, 3.6544, 3.7801, 3.7626],\n",
      "        [3.3578, 3.5175, 3.4807, 3.5520, 3.4459],\n",
      "        [3.4963, 3.4821, 3.5171, 3.6433, 3.5339],\n",
      "        [3.6519, 3.7697, 3.5690, 3.9245, 3.7196],\n",
      "        [3.7603, 3.8097, 3.6550, 3.8910, 3.8382],\n",
      "        [3.7632, 3.6653, 3.6111, 3.8224, 3.7575],\n",
      "        [3.6535, 3.7359, 3.6950, 3.8197, 3.7170],\n",
      "        [3.4408, 3.5062, 3.4234, 3.6724, 3.5041],\n",
      "        [3.3880, 3.5197, 3.4223, 3.6373, 3.4553],\n",
      "        [3.4914, 3.6275, 3.4531, 3.7744, 3.4867],\n",
      "        [3.7113, 3.7919, 3.6750, 3.8399, 3.8156],\n",
      "        [3.8963, 3.9384, 3.8416, 4.1912, 3.9391],\n",
      "        [3.4308, 3.4902, 3.5260, 3.6695, 3.5493],\n",
      "        [3.4966, 3.4981, 3.5215, 3.6512, 3.5415],\n",
      "        [3.4186, 3.5221, 3.3820, 3.5767, 3.4765],\n",
      "        [3.6613, 3.7787, 3.5445, 3.7678, 3.7041],\n",
      "        [3.4932, 3.4711, 3.5304, 3.6414, 3.5162],\n",
      "        [3.3972, 3.4775, 3.5023, 3.5917, 3.4518],\n",
      "        [3.7132, 3.6845, 3.7003, 3.9250, 3.6948],\n",
      "        [3.6765, 3.8358, 3.7752, 3.8698, 3.6047],\n",
      "        [3.3626, 3.3624, 3.4072, 3.5556, 3.4156],\n",
      "        [3.5272, 3.6178, 3.4084, 3.7228, 3.5539],\n",
      "        [3.7938, 3.8631, 3.7455, 3.9303, 3.8923],\n",
      "        [3.5331, 3.5947, 3.5518, 3.6569, 3.5908],\n",
      "        [3.7107, 3.7112, 3.6384, 3.8129, 3.7457],\n",
      "        [3.4437, 3.5304, 3.3808, 3.6043, 3.4764],\n",
      "        [3.5053, 3.6449, 3.5697, 3.6919, 3.5400],\n",
      "        [3.4943, 3.6242, 3.5809, 3.6771, 3.6868],\n",
      "        [3.6648, 3.7368, 3.6212, 3.7921, 3.7592],\n",
      "        [3.8802, 3.8183, 3.7796, 4.0362, 3.9081],\n",
      "        [3.4849, 3.5662, 3.3969, 3.6429, 3.5284],\n",
      "        [3.5469, 3.6666, 3.4605, 3.6484, 3.5896],\n",
      "        [3.6750, 3.7281, 3.7079, 3.9422, 3.6520],\n",
      "        [3.4963, 3.4988, 3.5185, 3.6455, 3.5351],\n",
      "        [3.4182, 3.4963, 3.5254, 3.6236, 3.4431],\n",
      "        [3.8114, 3.6781, 3.7471, 4.0085, 3.7645],\n",
      "        [3.6200, 3.8468, 3.6377, 3.8276, 3.7139],\n",
      "        [3.5106, 3.6434, 3.5795, 3.6966, 3.5396],\n",
      "        [3.4412, 3.4576, 3.5174, 3.6409, 3.5972],\n",
      "        [3.7488, 3.9043, 3.6885, 3.9572, 3.8747],\n",
      "        [3.6501, 3.7425, 3.6803, 3.8347, 3.6819],\n",
      "        [3.5857, 3.5939, 3.5498, 3.7967, 3.5970],\n",
      "        [3.5038, 3.6662, 3.5419, 3.6306, 3.6261],\n",
      "        [3.7510, 3.7197, 3.5851, 3.8725, 3.7818],\n",
      "        [3.3535, 3.4979, 3.4740, 3.5564, 3.4495],\n",
      "        [3.4985, 3.6436, 3.4644, 3.7946, 3.4927],\n",
      "        [3.7085, 3.8234, 3.6850, 3.9045, 3.9337],\n",
      "        [3.4081, 3.5219, 3.6290, 3.6167, 3.6077],\n",
      "        [3.4169, 3.5163, 3.3883, 3.5791, 3.4861],\n",
      "        [3.5142, 3.6354, 3.5845, 3.6937, 3.5170],\n",
      "        [3.6607, 3.8148, 3.6226, 3.8161, 3.7014],\n",
      "        [3.5568, 3.4683, 3.5147, 3.6842, 3.4921],\n",
      "        [3.4783, 3.5403, 3.5130, 3.6668, 3.6549],\n",
      "        [3.4982, 3.5237, 3.6056, 3.5982, 3.7013],\n",
      "        [3.9143, 3.6440, 3.7157, 4.2524, 4.0785],\n",
      "        [3.3685, 3.4493, 3.4528, 3.5638, 3.4352],\n",
      "        [3.7641, 3.4784, 3.6035, 4.0246, 3.8977],\n",
      "        [3.6617, 3.6624, 3.7129, 3.7689, 3.5467],\n",
      "        [3.3418, 3.4591, 3.3764, 3.4948, 3.4427],\n",
      "        [3.3891, 3.4420, 3.4692, 3.5807, 3.4155],\n",
      "        [3.8093, 3.8047, 3.6746, 3.9256, 3.8907],\n",
      "        [3.3123, 3.4299, 3.2689, 3.5562, 3.3530]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3564, 3.4541, 3.4517, 3.5458, 3.4277],\n",
      "        [3.4138, 3.4252, 3.4448, 3.5864, 3.4595],\n",
      "        [3.6837, 3.5399, 3.5462, 4.0282, 3.7432],\n",
      "        [3.7284, 3.7203, 3.6454, 3.8407, 3.7503],\n",
      "        [3.6174, 3.5650, 3.6000, 3.7534, 3.5788],\n",
      "        [3.3817, 3.4936, 3.5030, 3.6004, 3.4467],\n",
      "        [3.4202, 3.5256, 3.3944, 3.5689, 3.4883],\n",
      "        [3.5123, 3.6008, 3.4001, 3.7173, 3.5432],\n",
      "        [3.4552, 3.5416, 3.3825, 3.6298, 3.4813],\n",
      "        [3.6434, 3.6970, 3.6689, 3.7466, 3.6693],\n",
      "        [3.5197, 3.6098, 3.4152, 3.7160, 3.5503],\n",
      "        [3.6625, 3.7905, 3.6839, 3.8516, 3.6874],\n",
      "        [3.4997, 3.5889, 3.5333, 3.6379, 3.5699],\n",
      "        [3.6741, 3.6522, 3.6429, 3.8012, 3.8377],\n",
      "        [3.3189, 3.4443, 3.3697, 3.4670, 3.4205],\n",
      "        [3.3948, 3.5766, 3.3540, 3.6167, 3.4075],\n",
      "        [3.6013, 3.7147, 3.6201, 3.7438, 3.5211],\n",
      "        [3.6290, 3.8100, 3.5739, 3.6184, 3.6258],\n",
      "        [3.6513, 3.7709, 3.5706, 3.9270, 3.7204],\n",
      "        [3.4572, 3.5490, 3.4993, 3.7107, 3.5520],\n",
      "        [3.3589, 3.5030, 3.4782, 3.5650, 3.4585],\n",
      "        [3.6747, 3.6590, 3.6383, 3.8379, 3.8359],\n",
      "        [3.3688, 3.4447, 3.4513, 3.5526, 3.4296],\n",
      "        [3.6523, 3.7133, 3.6832, 3.8473, 3.6211],\n",
      "        [3.4255, 3.5318, 3.3908, 3.5900, 3.4838],\n",
      "        [3.5028, 3.4902, 3.5348, 3.6513, 3.5360],\n",
      "        [3.4024, 3.4668, 3.3650, 3.6229, 3.4449],\n",
      "        [3.5557, 3.4791, 3.5372, 3.6869, 3.5166],\n",
      "        [3.6141, 3.6463, 3.5723, 3.8773, 3.6079],\n",
      "        [3.8530, 3.6856, 3.7004, 4.2899, 4.0415],\n",
      "        [3.6607, 3.6536, 3.6925, 3.7628, 3.5523],\n",
      "        [3.4237, 3.4982, 3.5391, 3.6929, 3.5701],\n",
      "        [3.7998, 3.5921, 3.6050, 4.1357, 3.8580],\n",
      "        [3.4333, 3.4747, 3.5056, 3.6472, 3.5149],\n",
      "        [3.5023, 3.4637, 3.4323, 3.7183, 3.4492],\n",
      "        [3.6222, 3.4733, 3.4418, 3.6199, 3.6180],\n",
      "        [3.3626, 3.4510, 3.4551, 3.5519, 3.4293],\n",
      "        [3.6040, 3.6195, 3.4598, 3.8015, 3.7073],\n",
      "        [3.4919, 3.5043, 3.5219, 3.6575, 3.5389],\n",
      "        [3.7801, 3.8065, 3.6640, 3.9083, 3.8614],\n",
      "        [3.3755, 3.5285, 3.4899, 3.5714, 3.4821],\n",
      "        [3.6608, 3.5979, 3.5725, 3.6634, 3.5071],\n",
      "        [3.4885, 3.4842, 3.5122, 3.6397, 3.5292],\n",
      "        [3.5799, 3.8677, 3.5907, 3.8982, 3.7601],\n",
      "        [4.0713, 4.2084, 3.8199, 4.0213, 3.8035],\n",
      "        [3.6688, 3.6038, 3.5645, 3.9766, 3.7470],\n",
      "        [3.3538, 3.5136, 3.6306, 3.5484, 3.6077],\n",
      "        [3.7162, 3.7233, 3.6484, 3.9040, 3.8411],\n",
      "        [3.3132, 3.4366, 3.3640, 3.4624, 3.4090],\n",
      "        [3.3687, 3.5803, 3.5138, 3.5850, 3.5004],\n",
      "        [3.6046, 3.6006, 3.5667, 3.7360, 3.5821],\n",
      "        [3.3617, 3.4771, 3.3838, 3.5204, 3.4591],\n",
      "        [3.4955, 3.4953, 3.5212, 3.6503, 3.5397],\n",
      "        [3.5390, 3.6026, 3.5572, 3.6886, 3.5857],\n",
      "        [3.6805, 3.7274, 3.6675, 3.8132, 3.8607],\n",
      "        [3.6489, 3.7685, 3.5695, 3.9256, 3.7169],\n",
      "        [3.4933, 3.5711, 3.4831, 3.6334, 3.5513],\n",
      "        [3.6464, 3.7013, 3.6529, 3.7251, 3.6797],\n",
      "        [3.6365, 3.6986, 3.5543, 3.8129, 3.6555],\n",
      "        [3.8728, 3.9391, 3.8156, 4.1791, 3.9403],\n",
      "        [3.6765, 3.7571, 3.5938, 3.8729, 3.7811],\n",
      "        [3.6481, 3.7608, 3.6969, 3.7609, 3.5636],\n",
      "        [3.7084, 3.7499, 3.7216, 3.8521, 3.9137],\n",
      "        [3.4329, 3.5355, 3.3871, 3.5997, 3.4840]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4847, 3.5710, 3.3872, 3.6692, 3.5070],\n",
      "        [3.6599, 3.7812, 3.5470, 3.7726, 3.7053],\n",
      "        [3.6607, 3.6647, 3.7156, 3.7731, 3.5481],\n",
      "        [3.5034, 3.4464, 3.4169, 3.7229, 3.4378],\n",
      "        [3.5594, 3.5509, 3.6260, 3.7364, 3.6289],\n",
      "        [3.4589, 3.4781, 3.5147, 3.6316, 3.5375],\n",
      "        [3.4424, 3.5377, 3.3881, 3.6063, 3.4976],\n",
      "        [3.4225, 3.5608, 3.4263, 3.6945, 3.4637],\n",
      "        [3.4837, 3.5683, 3.3997, 3.6471, 3.5297],\n",
      "        [3.6789, 3.6392, 3.7221, 3.7762, 3.4986],\n",
      "        [3.7146, 3.6381, 3.6895, 3.8810, 3.6750],\n",
      "        [3.4766, 3.7950, 3.5808, 3.7896, 3.7172],\n",
      "        [3.4819, 3.5855, 3.5557, 3.7025, 3.5289],\n",
      "        [3.5824, 3.5681, 3.6525, 3.7602, 3.6362],\n",
      "        [3.7657, 3.6280, 3.7129, 3.9552, 3.7145],\n",
      "        [3.6215, 3.8402, 3.7194, 3.8459, 3.8663],\n",
      "        [3.5051, 3.5923, 3.4078, 3.6948, 3.5380],\n",
      "        [3.4371, 3.3752, 3.5257, 3.4491, 3.5741],\n",
      "        [3.5122, 3.5426, 3.5472, 3.6977, 3.5790],\n",
      "        [3.7683, 3.4707, 3.5959, 4.0523, 3.9056],\n",
      "        [3.4209, 3.5324, 3.3939, 3.5891, 3.4863],\n",
      "        [3.5665, 3.7926, 3.6744, 3.7784, 3.6019],\n",
      "        [3.4049, 3.5211, 3.3941, 3.5721, 3.4792],\n",
      "        [3.5248, 3.6065, 3.4082, 3.7162, 3.5406],\n",
      "        [3.4428, 3.3720, 3.3933, 3.5861, 3.3952],\n",
      "        [3.6284, 3.4916, 3.4522, 3.6283, 3.6338],\n",
      "        [3.6443, 3.7142, 3.5858, 3.6938, 3.6326],\n",
      "        [3.4285, 3.4810, 3.4980, 3.6609, 3.5107],\n",
      "        [3.4260, 3.4818, 3.4747, 3.5608, 3.4782],\n",
      "        [3.4752, 3.5106, 3.5834, 3.6708, 3.5553],\n",
      "        [3.4221, 3.5712, 3.4997, 3.7470, 3.4717],\n",
      "        [3.9185, 4.0016, 3.6104, 3.8885, 3.6510],\n",
      "        [3.7309, 3.7859, 3.7646, 3.8298, 3.6072],\n",
      "        [3.8549, 3.7249, 3.7735, 4.0993, 3.8805],\n",
      "        [3.3262, 3.4552, 3.3731, 3.4887, 3.4245],\n",
      "        [3.6061, 3.6442, 3.5289, 3.7296, 3.5849],\n",
      "        [3.6467, 3.7158, 3.5671, 3.8207, 3.6587],\n",
      "        [3.7204, 3.5549, 3.5762, 4.0430, 3.7846],\n",
      "        [3.5043, 3.5822, 3.5578, 3.6635, 3.4593],\n",
      "        [3.6505, 3.7718, 3.5719, 3.9289, 3.7210],\n",
      "        [3.5038, 3.6359, 3.5834, 3.6929, 3.5132],\n",
      "        [3.6846, 3.6706, 3.6477, 3.8471, 3.8453],\n",
      "        [3.7259, 3.7932, 3.6218, 3.8508, 3.8256],\n",
      "        [3.6110, 3.7323, 3.5430, 3.7507, 3.6446],\n",
      "        [3.7572, 3.8115, 3.6496, 3.8800, 3.8503],\n",
      "        [3.8034, 3.7638, 3.7456, 4.0013, 3.6966],\n",
      "        [3.7594, 3.8117, 3.6575, 3.8956, 3.8395],\n",
      "        [3.4772, 3.5424, 3.5154, 3.6711, 3.6560],\n",
      "        [3.5134, 3.5703, 3.4528, 3.7403, 3.5634],\n",
      "        [3.5752, 3.8124, 3.6415, 3.8040, 3.7737],\n",
      "        [3.5095, 3.7273, 3.5670, 3.6766, 3.4698],\n",
      "        [3.5426, 3.5353, 3.5359, 3.6991, 3.5821],\n",
      "        [3.6595, 3.7300, 3.6656, 3.7226, 3.6856],\n",
      "        [3.6846, 3.6212, 3.5941, 3.6981, 3.5366],\n",
      "        [3.5595, 3.5333, 3.6431, 3.8332, 3.7840],\n",
      "        [3.6159, 3.8322, 3.7106, 3.8330, 3.8596],\n",
      "        [3.4406, 3.4863, 3.5121, 3.6527, 3.5238],\n",
      "        [3.6185, 3.6955, 3.6048, 3.7576, 3.7143],\n",
      "        [3.4055, 3.5124, 3.3861, 3.5694, 3.4652],\n",
      "        [3.5031, 3.5859, 3.3917, 3.6863, 3.5228],\n",
      "        [3.4980, 3.5165, 3.5323, 3.6640, 3.5457],\n",
      "        [3.4606, 3.5580, 3.3926, 3.6427, 3.4996],\n",
      "        [3.4005, 3.3820, 3.4137, 3.5822, 3.4082],\n",
      "        [3.9574, 4.0806, 3.7910, 3.9465, 3.8100]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5271, 3.5036, 3.5462, 3.6928, 3.6032],\n",
      "        [3.5115, 3.8291, 3.6991, 3.7560, 3.6055],\n",
      "        [3.3892, 3.5231, 3.5281, 3.6127, 3.4720],\n",
      "        [3.5010, 3.4653, 3.4343, 3.7215, 3.4500],\n",
      "        [3.6246, 3.7122, 3.5474, 3.7634, 3.6548],\n",
      "        [3.5459, 3.5477, 3.6247, 3.7257, 3.6186],\n",
      "        [3.3999, 3.6954, 3.5321, 3.4943, 3.6315],\n",
      "        [3.7424, 3.7256, 3.7277, 3.9903, 3.9480],\n",
      "        [3.3674, 3.5819, 3.5162, 3.5881, 3.5013],\n",
      "        [3.3498, 3.5469, 3.4970, 3.5663, 3.4645],\n",
      "        [3.5209, 3.5204, 3.5915, 3.7154, 3.5896],\n",
      "        [3.5208, 3.5102, 3.5794, 3.6796, 3.5943],\n",
      "        [3.3329, 3.3750, 3.4190, 3.5215, 3.3557],\n",
      "        [3.4468, 3.5474, 3.3904, 3.6200, 3.4938],\n",
      "        [3.4913, 3.4738, 3.5337, 3.6472, 3.5180],\n",
      "        [3.5131, 3.7404, 3.5187, 3.5293, 3.6326],\n",
      "        [3.4344, 3.6626, 3.5465, 3.6937, 3.6759],\n",
      "        [3.7156, 3.8750, 3.6886, 3.9634, 3.8062],\n",
      "        [3.2713, 3.4058, 3.3496, 3.4202, 3.3704],\n",
      "        [3.3256, 3.4558, 3.3742, 3.4900, 3.4248],\n",
      "        [3.4621, 3.4156, 3.4615, 3.6071, 3.6127],\n",
      "        [3.7482, 3.7264, 3.6410, 3.8596, 3.7449],\n",
      "        [3.4989, 3.5164, 3.5560, 3.6850, 3.5700],\n",
      "        [3.6591, 3.7821, 3.5479, 3.7743, 3.7055],\n",
      "        [3.4987, 3.5858, 3.3991, 3.6888, 3.5284],\n",
      "        [3.4962, 3.5094, 3.5280, 3.6628, 3.5487],\n",
      "        [3.5083, 3.5950, 3.3950, 3.6973, 3.5276],\n",
      "        [3.4957, 3.5028, 3.5649, 3.6852, 3.5672],\n",
      "        [3.4417, 3.5331, 3.3846, 3.6098, 3.4780],\n",
      "        [3.4921, 3.5150, 3.5288, 3.6682, 3.5453],\n",
      "        [3.3572, 3.4680, 3.4643, 3.5540, 3.4330],\n",
      "        [3.4585, 3.4679, 3.5159, 3.6202, 3.5157],\n",
      "        [3.2665, 3.4044, 3.4231, 3.4834, 3.4414],\n",
      "        [3.4452, 3.5661, 3.5153, 3.7403, 3.4830],\n",
      "        [3.8868, 3.6744, 3.7739, 4.3391, 4.0984],\n",
      "        [3.5763, 3.8412, 3.6706, 3.8151, 3.7775],\n",
      "        [3.6505, 3.7681, 3.5649, 3.9199, 3.7074],\n",
      "        [3.5798, 3.7647, 3.5834, 3.8744, 3.6706],\n",
      "        [3.4476, 3.7121, 3.5030, 3.5955, 3.4599],\n",
      "        [3.3511, 3.5827, 3.3433, 3.6330, 3.3962],\n",
      "        [3.5136, 3.5989, 3.4939, 3.7440, 3.6002],\n",
      "        [3.5531, 3.4840, 3.5376, 3.6863, 3.5389],\n",
      "        [3.6422, 3.6082, 3.6407, 3.8704, 3.5698],\n",
      "        [3.4293, 3.5326, 3.3902, 3.6051, 3.4830],\n",
      "        [3.5234, 3.5525, 3.5510, 3.5938, 3.3910],\n",
      "        [3.5183, 3.5913, 3.5414, 3.6555, 3.5793],\n",
      "        [3.4860, 3.4950, 3.5146, 3.6489, 3.5330],\n",
      "        [3.6970, 3.6668, 3.7517, 3.8119, 3.5032],\n",
      "        [3.7071, 3.7515, 3.7237, 3.8559, 3.9145],\n",
      "        [3.7999, 3.8093, 3.6735, 3.9197, 3.8853],\n",
      "        [3.6227, 3.5730, 3.6029, 3.7640, 3.5803],\n",
      "        [3.4229, 3.7060, 3.5508, 3.5091, 3.6474],\n",
      "        [3.4871, 3.6987, 3.5999, 3.6151, 3.6487],\n",
      "        [3.6930, 3.7142, 3.6790, 3.8614, 3.8066],\n",
      "        [3.6048, 3.5631, 3.5705, 3.6049, 3.4284],\n",
      "        [3.2828, 3.4305, 3.4184, 3.5076, 3.4394],\n",
      "        [3.8757, 4.0068, 3.9228, 4.1363, 4.1435],\n",
      "        [3.8753, 3.9779, 3.6021, 3.8694, 3.6640],\n",
      "        [3.9053, 4.0056, 3.5958, 3.8891, 3.6442],\n",
      "        [3.6382, 3.5793, 3.5677, 3.6386, 3.4776],\n",
      "        [3.3805, 3.4936, 3.5158, 3.6013, 3.4576],\n",
      "        [3.7091, 3.7139, 3.6419, 3.8192, 3.7474],\n",
      "        [3.6628, 3.7858, 3.6765, 3.8526, 3.6855],\n",
      "        [3.4679, 3.5443, 3.4278, 3.6387, 3.5336]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4968, 3.6480, 3.5837, 3.7029, 3.5307],\n",
      "        [3.5251, 3.6333, 3.3914, 3.6323, 3.5471],\n",
      "        [3.4377, 3.7711, 3.5783, 3.7378, 3.7132],\n",
      "        [3.4276, 3.6041, 3.4008, 3.6741, 3.4352],\n",
      "        [3.3660, 3.4524, 3.4572, 3.5709, 3.4378],\n",
      "        [3.8648, 3.7549, 3.8208, 4.0883, 3.8384],\n",
      "        [3.3797, 3.5002, 3.3868, 3.5501, 3.4554],\n",
      "        [3.4026, 3.4943, 3.3880, 3.6138, 3.4431],\n",
      "        [3.6854, 3.7668, 3.6080, 3.8885, 3.7747],\n",
      "        [3.3506, 3.5090, 3.4783, 3.5544, 3.4443],\n",
      "        [3.4814, 3.5819, 3.5363, 3.6145, 3.4639],\n",
      "        [3.4029, 3.4254, 3.3263, 3.6224, 3.3703],\n",
      "        [3.4299, 3.7579, 3.5692, 3.7326, 3.7070],\n",
      "        [3.3606, 3.4530, 3.4581, 3.5566, 3.4311],\n",
      "        [3.4804, 3.5007, 3.5271, 3.5390, 3.3486],\n",
      "        [3.5538, 3.4809, 3.5367, 3.6976, 3.5157],\n",
      "        [3.4291, 3.4703, 3.5128, 3.6574, 3.5355],\n",
      "        [3.6412, 3.8550, 3.7464, 3.8466, 3.7858],\n",
      "        [3.8397, 3.8920, 3.7660, 4.1194, 3.8507],\n",
      "        [3.6725, 3.7373, 3.6953, 3.8243, 3.8535],\n",
      "        [3.7560, 3.8126, 3.6512, 3.8835, 3.8517],\n",
      "        [3.8277, 3.6391, 3.7295, 4.2831, 4.0608],\n",
      "        [3.3306, 3.4229, 3.3281, 3.5774, 3.3442],\n",
      "        [4.0274, 4.1875, 3.8030, 4.0239, 3.7852],\n",
      "        [3.4300, 3.4824, 3.5247, 3.6761, 3.5575],\n",
      "        [3.6495, 3.5851, 3.5736, 3.6530, 3.4875],\n",
      "        [3.5247, 3.5063, 3.5509, 3.6486, 3.5941],\n",
      "        [3.3500, 3.5410, 3.4931, 3.5588, 3.4591],\n",
      "        [3.4362, 3.5380, 3.3895, 3.6029, 3.4903],\n",
      "        [3.6465, 3.7706, 3.5727, 3.9309, 3.7190],\n",
      "        [3.3798, 3.7558, 3.6105, 3.6542, 3.7271],\n",
      "        [3.6357, 3.6328, 3.6254, 3.7224, 3.4823],\n",
      "        [3.6627, 3.7807, 3.5552, 3.7796, 3.7160],\n",
      "        [3.2821, 3.4309, 3.4192, 3.5093, 3.4405],\n",
      "        [3.5246, 3.6817, 3.5285, 3.6962, 3.6393],\n",
      "        [3.5800, 3.5990, 3.5619, 3.7274, 3.5795],\n",
      "        [3.5440, 3.7062, 3.6745, 3.8318, 3.6506],\n",
      "        [3.5504, 3.7124, 3.5578, 3.6943, 3.6530],\n",
      "        [3.7138, 3.6392, 3.6911, 3.8844, 3.6764],\n",
      "        [3.4791, 3.6191, 3.4488, 3.7769, 3.4770],\n",
      "        [3.6406, 3.6309, 3.6067, 3.8008, 3.8100],\n",
      "        [3.4124, 3.4402, 3.3423, 3.6426, 3.4369],\n",
      "        [3.4491, 3.4705, 3.5324, 3.6484, 3.5219],\n",
      "        [3.4194, 3.4802, 3.4906, 3.6629, 3.5096],\n",
      "        [3.8105, 3.7702, 3.7731, 4.0253, 3.8183],\n",
      "        [3.5792, 3.7650, 3.5841, 3.8762, 3.6717],\n",
      "        [3.6740, 3.8108, 3.5569, 3.7591, 3.6839],\n",
      "        [3.5473, 3.5397, 3.6208, 3.7237, 3.6117],\n",
      "        [3.6745, 3.7588, 3.5966, 3.8781, 3.7830],\n",
      "        [3.4913, 3.6443, 3.5000, 3.6991, 3.6216],\n",
      "        [3.6204, 3.5898, 3.5244, 3.8817, 3.6763],\n",
      "        [3.4096, 3.5206, 3.3968, 3.5695, 3.4742],\n",
      "        [3.6204, 3.7180, 3.6481, 3.7786, 3.5406],\n",
      "        [3.8928, 3.9355, 3.8119, 4.1815, 3.9292],\n",
      "        [3.5869, 3.5952, 3.4242, 3.7817, 3.6938],\n",
      "        [3.4610, 3.4731, 3.4708, 3.6769, 3.4606],\n",
      "        [3.5533, 3.4894, 3.5457, 3.7031, 3.5554],\n",
      "        [3.6656, 3.5887, 3.5761, 4.0100, 3.7660],\n",
      "        [3.5182, 3.6792, 3.5286, 3.6823, 3.6408],\n",
      "        [3.7117, 3.6876, 3.7045, 3.9332, 3.6974],\n",
      "        [3.6096, 3.7335, 3.5448, 3.7539, 3.6460],\n",
      "        [3.9176, 4.0025, 3.6120, 3.8919, 3.6524],\n",
      "        [3.4614, 3.6205, 3.5449, 3.5712, 3.4919],\n",
      "        [3.3725, 3.4398, 3.4549, 3.5687, 3.4417]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5193, 3.5483, 3.5611, 3.5884, 3.3924],\n",
      "        [3.4058, 3.4136, 3.4533, 3.5947, 3.4142],\n",
      "        [3.3528, 3.5753, 3.6038, 3.5865, 3.5944],\n",
      "        [3.5439, 3.6645, 3.4527, 3.6617, 3.5924],\n",
      "        [3.6548, 3.7357, 3.6887, 3.8502, 3.6598],\n",
      "        [3.4251, 3.5686, 3.4906, 3.7467, 3.4585],\n",
      "        [3.4255, 3.5692, 3.4452, 3.6589, 3.4472],\n",
      "        [3.3727, 3.5305, 3.4937, 3.5773, 3.4857],\n",
      "        [3.4636, 3.6187, 3.5525, 3.6686, 3.6097],\n",
      "        [3.5866, 3.8275, 3.6584, 3.8217, 3.7890],\n",
      "        [3.5450, 3.4584, 3.5236, 3.6771, 3.4945],\n",
      "        [3.6887, 3.6800, 3.8350, 3.7434, 3.5833],\n",
      "        [3.5636, 3.6705, 3.6290, 3.8185, 3.6807],\n",
      "        [3.6249, 3.5694, 3.6191, 3.7820, 3.5977],\n",
      "        [3.3493, 3.5410, 3.4938, 3.5599, 3.4609],\n",
      "        [3.6222, 3.4406, 3.4495, 3.6480, 3.5831],\n",
      "        [3.3484, 3.5473, 3.4985, 3.5690, 3.4673],\n",
      "        [3.8608, 3.7516, 3.8203, 4.0881, 3.8382],\n",
      "        [3.8547, 3.7486, 3.8131, 4.0995, 3.8438],\n",
      "        [3.6264, 3.6379, 3.4635, 3.8211, 3.7351],\n",
      "        [3.4193, 3.4899, 3.4831, 3.5565, 3.4819],\n",
      "        [3.4498, 3.4765, 3.5281, 3.6557, 3.5288],\n",
      "        [3.4906, 3.6443, 3.5006, 3.7003, 3.6233],\n",
      "        [3.4664, 3.5446, 3.4293, 3.6416, 3.5364],\n",
      "        [3.4896, 3.5024, 3.5318, 3.6742, 3.5539],\n",
      "        [3.6575, 3.7310, 3.6680, 3.7271, 3.6887],\n",
      "        [3.6100, 3.5662, 3.5635, 3.6093, 3.4448],\n",
      "        [3.6481, 3.7730, 3.5745, 3.9336, 3.7242],\n",
      "        [3.7340, 3.7257, 3.7229, 3.9927, 3.9536],\n",
      "        [3.6088, 3.7336, 3.5455, 3.7550, 3.6477],\n",
      "        [3.5262, 3.4811, 3.5911, 3.7272, 3.6586],\n",
      "        [3.3820, 3.4219, 3.4466, 3.5686, 3.4297],\n",
      "        [3.8741, 4.0072, 3.9242, 4.1398, 4.1465],\n",
      "        [3.5272, 3.4939, 3.5811, 3.6915, 3.5492],\n",
      "        [3.7259, 3.5871, 3.5721, 3.7711, 3.7021],\n",
      "        [3.7386, 3.8426, 3.7603, 3.9505, 3.8448],\n",
      "        [4.1402, 4.2809, 3.8828, 4.1009, 3.8705],\n",
      "        [3.9429, 4.0767, 3.7169, 3.9246, 3.7092],\n",
      "        [3.4442, 3.4881, 3.5234, 3.6563, 3.5308],\n",
      "        [3.6460, 3.6430, 3.6347, 3.7304, 3.4943],\n",
      "        [3.6811, 3.6989, 3.6614, 3.8513, 3.8075],\n",
      "        [3.6428, 3.5891, 3.5281, 3.9236, 3.7021],\n",
      "        [3.3566, 3.4933, 3.4000, 3.5725, 3.4343],\n",
      "        [3.6886, 3.5547, 3.5689, 3.9840, 3.7407],\n",
      "        [3.4950, 3.5372, 3.4821, 3.7251, 3.5694],\n",
      "        [3.5965, 3.5428, 3.5560, 3.6301, 3.4280],\n",
      "        [3.5083, 3.6449, 3.4618, 3.8138, 3.4990],\n",
      "        [3.6021, 3.7331, 3.5435, 3.7387, 3.6382],\n",
      "        [3.7088, 3.7808, 3.6012, 3.8229, 3.8084],\n",
      "        [3.4074, 3.3932, 3.4256, 3.5934, 3.4204],\n",
      "        [3.4145, 3.6488, 3.5454, 3.6751, 3.7085],\n",
      "        [4.0502, 4.2640, 3.8038, 4.0616, 3.8160],\n",
      "        [3.4451, 3.5119, 3.5139, 3.6905, 3.5260],\n",
      "        [3.5048, 3.5407, 3.5527, 3.6994, 3.5755],\n",
      "        [3.4384, 3.4873, 3.5142, 3.6571, 3.5269],\n",
      "        [3.6720, 3.7313, 3.7125, 3.9516, 3.6565],\n",
      "        [3.9159, 3.6438, 3.7251, 4.2653, 4.0846],\n",
      "        [3.5283, 3.7392, 3.5899, 3.7161, 3.4848],\n",
      "        [3.8086, 3.7888, 3.7495, 4.0436, 3.7624],\n",
      "        [3.7479, 3.8962, 3.6682, 3.7573, 3.6675],\n",
      "        [3.6022, 3.4336, 3.6908, 3.7564, 3.6221],\n",
      "        [3.3719, 3.4261, 3.4457, 3.5651, 3.4284],\n",
      "        [3.6034, 3.5636, 3.5718, 3.6079, 3.4312],\n",
      "        [3.4835, 3.5729, 3.3989, 3.6662, 3.5297]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5580, 3.8121, 3.7343, 3.8494, 3.7785],\n",
      "        [3.4854, 3.5328, 3.6552, 3.7797, 3.6142],\n",
      "        [3.7060, 3.7518, 3.7254, 3.8604, 3.9187],\n",
      "        [3.5309, 3.6288, 3.5527, 3.7179, 3.6313],\n",
      "        [3.4806, 3.4400, 3.5503, 3.5458, 3.5947],\n",
      "        [3.4557, 3.5508, 3.4023, 3.6438, 3.5131],\n",
      "        [3.7392, 3.6942, 3.7582, 3.8876, 3.5850],\n",
      "        [3.3923, 3.3728, 3.4126, 3.5868, 3.4004],\n",
      "        [3.4857, 3.6989, 3.6016, 3.6189, 3.6527],\n",
      "        [3.5168, 3.6117, 3.4194, 3.7232, 3.5553],\n",
      "        [3.5062, 3.4763, 3.5497, 3.6114, 3.5921],\n",
      "        [3.3868, 3.3567, 3.4048, 3.5782, 3.3922],\n",
      "        [3.4328, 3.4559, 3.5431, 3.6385, 3.5123],\n",
      "        [3.8376, 3.8687, 3.8609, 4.1380, 4.1136],\n",
      "        [3.4507, 3.5014, 3.3076, 3.6968, 3.3761],\n",
      "        [4.1055, 4.2478, 3.8478, 4.0743, 3.8429],\n",
      "        [3.4378, 3.5385, 3.3993, 3.6000, 3.5090],\n",
      "        [3.4718, 3.5500, 3.4288, 3.6423, 3.5389],\n",
      "        [3.4664, 3.5666, 3.4053, 3.6492, 3.5170],\n",
      "        [3.5710, 3.4819, 3.7814, 3.7555, 3.6863],\n",
      "        [3.6793, 3.6420, 3.7825, 3.7649, 3.5434],\n",
      "        [3.5095, 3.8237, 3.5549, 3.8676, 3.7072],\n",
      "        [3.6579, 3.6820, 3.6845, 3.8600, 3.5704],\n",
      "        [3.7452, 3.8060, 3.6462, 3.8798, 3.8603],\n",
      "        [3.7261, 3.5869, 3.5725, 3.7722, 3.7035],\n",
      "        [3.4907, 3.5152, 3.5303, 3.6720, 3.5493],\n",
      "        [3.6965, 3.8281, 3.5584, 3.7716, 3.6883],\n",
      "        [3.6438, 3.5939, 3.5370, 3.9361, 3.7181],\n",
      "        [3.1950, 3.3527, 3.3932, 3.4300, 3.3830],\n",
      "        [3.3304, 3.5886, 3.4331, 3.3987, 3.4917],\n",
      "        [3.6224, 3.4404, 3.4499, 3.6490, 3.5845],\n",
      "        [3.4978, 3.6429, 3.5961, 3.6943, 3.7160],\n",
      "        [3.7655, 3.8102, 3.6615, 3.9060, 3.8456],\n",
      "        [3.6316, 3.7316, 3.5819, 3.7941, 3.6451],\n",
      "        [3.5107, 3.5299, 3.4295, 3.6542, 3.6334],\n",
      "        [3.4396, 3.3937, 3.4312, 3.6157, 3.4101],\n",
      "        [3.7393, 3.7619, 3.7381, 3.8734, 3.8343],\n",
      "        [3.8723, 3.9410, 3.8195, 4.1873, 3.9456],\n",
      "        [3.7623, 3.8202, 3.7340, 3.8858, 3.8145],\n",
      "        [3.7697, 3.7789, 3.6628, 3.9228, 3.8632],\n",
      "        [3.6066, 3.6086, 3.6851, 3.8036, 3.6191],\n",
      "        [3.5573, 3.5517, 3.6285, 3.7421, 3.6338],\n",
      "        [3.5081, 3.5113, 3.5301, 3.6544, 3.6135],\n",
      "        [3.4680, 3.4453, 3.5077, 3.6023, 3.4928],\n",
      "        [3.3867, 3.4365, 3.3531, 3.6162, 3.3630],\n",
      "        [3.5294, 3.5009, 3.6078, 3.7411, 3.6742],\n",
      "        [3.3775, 3.4388, 3.4538, 3.5695, 3.4471],\n",
      "        [3.8164, 3.6927, 3.7640, 4.0228, 3.7856],\n",
      "        [3.4869, 3.5783, 3.4029, 3.6739, 3.5320],\n",
      "        [3.5021, 3.8059, 3.6009, 3.8184, 3.7460],\n",
      "        [3.4003, 3.4213, 3.4579, 3.5908, 3.4168],\n",
      "        [3.5407, 3.5362, 3.5386, 3.7044, 3.5867],\n",
      "        [3.4902, 3.5128, 3.5296, 3.6707, 3.5476],\n",
      "        [3.4272, 3.4932, 3.5312, 3.6790, 3.5548],\n",
      "        [3.3244, 3.4561, 3.3762, 3.4935, 3.4290],\n",
      "        [3.7240, 3.7205, 3.7179, 3.9590, 3.9408],\n",
      "        [3.4778, 3.6286, 3.5527, 3.6864, 3.5792],\n",
      "        [3.4492, 3.3940, 3.5378, 3.4819, 3.5864],\n",
      "        [3.4112, 3.4270, 3.4485, 3.5933, 3.4643],\n",
      "        [3.4913, 3.5439, 3.5370, 3.6680, 3.7045],\n",
      "        [3.4859, 3.5584, 3.6051, 3.7072, 3.6340],\n",
      "        [3.3402, 3.4733, 3.3848, 3.5106, 3.4397],\n",
      "        [3.6248, 3.6015, 3.6184, 3.7042, 3.4993],\n",
      "        [3.4936, 3.6906, 3.5860, 3.6278, 3.6502]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3289, 3.4165, 3.3118, 3.5688, 3.3557],\n",
      "        [3.4256, 3.4236, 3.4562, 3.6103, 3.4303],\n",
      "        [3.4425, 3.6126, 3.5289, 3.5539, 3.4807],\n",
      "        [3.6592, 3.7583, 3.6940, 3.7855, 3.5485],\n",
      "        [3.6193, 3.4808, 3.4423, 3.6213, 3.6295],\n",
      "        [3.6454, 3.6419, 3.6239, 3.8090, 3.7938],\n",
      "        [3.4825, 3.4799, 3.5186, 3.6473, 3.5311],\n",
      "        [3.4152, 3.4997, 3.5318, 3.6339, 3.4501],\n",
      "        [3.4272, 3.4936, 3.5314, 3.6803, 3.5558],\n",
      "        [3.7628, 3.6211, 3.7086, 3.9609, 3.7154],\n",
      "        [3.7015, 3.7222, 3.6679, 3.8428, 3.8809],\n",
      "        [3.5837, 3.6021, 3.6491, 3.7762, 3.6204],\n",
      "        [3.7214, 3.8565, 3.6234, 3.7291, 3.6320],\n",
      "        [3.4040, 3.5252, 3.6343, 3.6277, 3.6146],\n",
      "        [3.4984, 3.5051, 3.5310, 3.6731, 3.5475],\n",
      "        [3.5995, 3.6010, 3.6804, 3.8104, 3.6061],\n",
      "        [3.5028, 3.5317, 3.6201, 3.5854, 3.7172],\n",
      "        [3.6576, 3.8185, 3.6285, 3.8270, 3.7083],\n",
      "        [3.3662, 3.4783, 3.4789, 3.5760, 3.4597],\n",
      "        [3.4836, 3.6046, 3.5017, 3.7266, 3.6064],\n",
      "        [3.5765, 3.5890, 3.5503, 3.7989, 3.5953],\n",
      "        [3.4930, 3.4919, 3.5282, 3.6575, 3.5417],\n",
      "        [3.4899, 3.5198, 3.5339, 3.6805, 3.5564],\n",
      "        [3.3876, 3.4061, 3.4313, 3.5774, 3.4259],\n",
      "        [3.6088, 3.6935, 3.5449, 3.7960, 3.7173],\n",
      "        [3.7312, 3.8552, 3.7884, 3.8692, 3.5967],\n",
      "        [4.0516, 4.2643, 3.8045, 4.0641, 3.8186],\n",
      "        [3.4826, 3.5782, 3.3970, 3.6823, 3.5218],\n",
      "        [3.5804, 3.7178, 3.6132, 3.7452, 3.5169],\n",
      "        [3.5708, 3.6937, 3.5276, 3.7828, 3.6151],\n",
      "        [3.5584, 3.5507, 3.5432, 3.7413, 3.5889],\n",
      "        [3.4928, 3.4772, 3.5413, 3.6511, 3.5289],\n",
      "        [3.3903, 3.3854, 3.4191, 3.5856, 3.4119],\n",
      "        [3.9441, 4.0771, 3.7175, 3.9270, 3.7117],\n",
      "        [3.9606, 3.6922, 3.8243, 4.4062, 4.1576],\n",
      "        [3.4967, 3.6430, 3.5065, 3.7102, 3.6328],\n",
      "        [3.4252, 3.5690, 3.4912, 3.7491, 3.4608],\n",
      "        [3.3971, 3.3850, 3.4194, 3.5895, 3.4174],\n",
      "        [3.6149, 3.6587, 3.5095, 3.8071, 3.6806],\n",
      "        [3.3880, 3.5080, 3.3937, 3.5559, 3.4731],\n",
      "        [3.3496, 3.5667, 3.5094, 3.5664, 3.4800],\n",
      "        [3.4928, 3.5806, 3.5421, 3.6303, 3.4763],\n",
      "        [3.6868, 3.8150, 3.5446, 3.7511, 3.6751],\n",
      "        [3.4621, 3.6154, 3.4527, 3.7541, 3.4870],\n",
      "        [3.4639, 3.5472, 3.5087, 3.6967, 3.6151],\n",
      "        [3.6232, 3.7749, 3.6895, 3.8460, 3.7570],\n",
      "        [3.3004, 3.4422, 3.4124, 3.5452, 3.4452],\n",
      "        [3.4980, 3.5341, 3.4582, 3.6824, 3.5140],\n",
      "        [3.4720, 3.5655, 3.5179, 3.7166, 3.5993],\n",
      "        [3.4945, 3.3953, 3.4667, 3.5332, 3.4241],\n",
      "        [3.6492, 3.5854, 3.5748, 3.6566, 3.4916],\n",
      "        [3.5658, 3.5709, 3.5440, 3.7707, 3.5917],\n",
      "        [3.5923, 3.6423, 3.5422, 3.7230, 3.5890],\n",
      "        [4.0292, 4.2268, 3.7567, 4.0126, 3.8329],\n",
      "        [3.4786, 3.6193, 3.4504, 3.7802, 3.4814],\n",
      "        [3.6001, 3.5492, 3.6000, 3.6417, 3.5578],\n",
      "        [3.6483, 3.7732, 3.5754, 3.9358, 3.7267],\n",
      "        [3.6088, 3.7601, 3.6299, 3.9014, 3.6803],\n",
      "        [3.5049, 3.4280, 3.5009, 3.5743, 3.4618],\n",
      "        [3.4493, 3.3944, 3.5380, 3.4831, 3.5875],\n",
      "        [3.7555, 3.7201, 3.7213, 3.9792, 3.7485],\n",
      "        [3.4805, 3.5533, 3.4346, 3.6780, 3.5083],\n",
      "        [3.3868, 3.4369, 3.3534, 3.6174, 3.3642],\n",
      "        [3.6219, 3.8654, 3.7246, 3.8517, 3.8042]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6005, 3.7691, 3.7187, 3.8186, 3.6245],\n",
      "        [3.2921, 3.4207, 3.3594, 3.4474, 3.3965],\n",
      "        [3.6493, 3.7733, 3.5766, 3.9367, 3.7276],\n",
      "        [3.8669, 3.7553, 3.8232, 4.0937, 3.8437],\n",
      "        [3.4040, 3.5411, 3.4342, 3.6776, 3.4640],\n",
      "        [3.4813, 3.7232, 3.5100, 3.5153, 3.6318],\n",
      "        [3.4210, 3.5734, 3.5035, 3.7551, 3.4777],\n",
      "        [3.4261, 3.5692, 3.4923, 3.7500, 3.4616],\n",
      "        [3.3621, 3.5437, 3.5014, 3.5817, 3.4785],\n",
      "        [3.4322, 3.4963, 3.3160, 3.6803, 3.3905],\n",
      "        [3.5017, 3.5941, 3.4091, 3.6978, 3.5440],\n",
      "        [3.4848, 3.6205, 3.5752, 3.6779, 3.6929],\n",
      "        [4.1078, 4.2488, 3.8493, 4.0768, 3.8451],\n",
      "        [3.4793, 3.7316, 3.5636, 3.6726, 3.4792],\n",
      "        [3.5306, 3.5960, 3.7167, 3.7570, 3.7140],\n",
      "        [3.7530, 3.6285, 3.6932, 3.9232, 3.7209],\n",
      "        [3.5608, 3.8078, 3.7379, 3.8571, 3.7766],\n",
      "        [3.5442, 3.7071, 3.6769, 3.8368, 3.6554],\n",
      "        [3.4764, 3.5440, 3.5191, 3.6787, 3.6621],\n",
      "        [3.9074, 4.0064, 3.5990, 3.8957, 3.6505],\n",
      "        [3.4879, 3.5788, 3.4044, 3.6760, 3.5339],\n",
      "        [3.4363, 3.3765, 3.5297, 3.4565, 3.5810],\n",
      "        [3.4300, 3.6996, 3.5069, 3.5952, 3.4444],\n",
      "        [3.5946, 3.6347, 3.6281, 3.7383, 3.6436],\n",
      "        [3.7509, 3.7226, 3.5916, 3.8850, 3.7895],\n",
      "        [3.2878, 3.4703, 3.5859, 3.5028, 3.5411],\n",
      "        [3.6078, 3.6091, 3.6866, 3.8058, 3.6211],\n",
      "        [3.3758, 3.5106, 3.5209, 3.5971, 3.4743],\n",
      "        [3.4222, 3.3712, 3.4719, 3.6045, 3.5373],\n",
      "        [3.7273, 3.8534, 3.7056, 3.7457, 3.7739],\n",
      "        [3.5817, 3.7118, 3.5544, 3.7951, 3.6283],\n",
      "        [3.3940, 3.3702, 3.4081, 3.5803, 3.4050],\n",
      "        [3.4084, 3.4831, 3.5005, 3.5292, 3.6047],\n",
      "        [3.6202, 3.8704, 3.7267, 3.8483, 3.7990],\n",
      "        [3.6377, 3.7990, 3.6976, 3.8481, 3.8018],\n",
      "        [3.4510, 3.4768, 3.5298, 3.6589, 3.5323],\n",
      "        [3.7880, 3.6271, 3.7198, 3.9229, 3.7460],\n",
      "        [3.5433, 3.7194, 3.5901, 3.7196, 3.4927],\n",
      "        [3.6004, 3.6270, 3.4630, 3.7304, 3.6907],\n",
      "        [3.4796, 3.5734, 3.4110, 3.6670, 3.5340],\n",
      "        [3.5529, 3.4847, 3.5405, 3.6928, 3.5454],\n",
      "        [3.6328, 3.7322, 3.5834, 3.7963, 3.6471],\n",
      "        [3.5076, 3.6044, 3.4082, 3.7109, 3.5463],\n",
      "        [3.7788, 3.9145, 3.6923, 3.7841, 3.7430],\n",
      "        [3.7135, 3.8260, 3.6963, 3.7406, 3.7497],\n",
      "        [3.5921, 3.6906, 3.5105, 3.7732, 3.6743],\n",
      "        [3.3621, 3.5437, 3.5014, 3.5817, 3.4785],\n",
      "        [3.7108, 3.7948, 3.6814, 3.8524, 3.8233],\n",
      "        [3.4955, 3.4999, 3.5270, 3.6554, 3.5429],\n",
      "        [3.4491, 3.4818, 3.5392, 3.6554, 3.5298],\n",
      "        [3.9049, 3.7437, 3.8196, 4.1190, 3.8840],\n",
      "        [3.4464, 3.5482, 3.3938, 3.6258, 3.4999],\n",
      "        [3.3918, 3.5437, 3.4684, 3.7151, 3.4309],\n",
      "        [3.4391, 3.5569, 3.6009, 3.7144, 3.6689],\n",
      "        [3.5354, 3.5369, 3.6109, 3.7410, 3.6191],\n",
      "        [3.5544, 3.4813, 3.5390, 3.7022, 3.5210],\n",
      "        [3.5885, 3.5952, 3.4267, 3.7861, 3.6987],\n",
      "        [3.6495, 3.7259, 3.5821, 3.7569, 3.6524],\n",
      "        [3.4835, 3.4856, 3.5449, 3.6822, 3.6201],\n",
      "        [3.4952, 3.5856, 3.4096, 3.6946, 3.5412],\n",
      "        [3.5054, 3.5015, 3.5484, 3.6692, 3.5982],\n",
      "        [3.6028, 3.5592, 3.5738, 3.5948, 3.4366],\n",
      "        [3.5022, 3.5039, 3.5372, 3.6607, 3.6046],\n",
      "        [3.6877, 3.6779, 3.8278, 3.7435, 3.5772]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3466, 3.5311, 3.4946, 3.5711, 3.4616],\n",
      "        [3.8120, 3.6300, 3.7360, 3.9555, 3.7682],\n",
      "        [3.6888, 3.9025, 3.7100, 4.0007, 3.8602],\n",
      "        [3.5352, 3.6829, 3.5308, 3.7798, 3.5758],\n",
      "        [3.7155, 3.7360, 3.6940, 3.8757, 3.8714],\n",
      "        [3.5954, 3.6353, 3.6291, 3.7390, 3.6441],\n",
      "        [3.8538, 3.9794, 3.7060, 3.8532, 3.7324],\n",
      "        [3.4997, 3.5177, 3.5599, 3.6917, 3.5768],\n",
      "        [3.6831, 3.7615, 3.6855, 3.7499, 3.7105],\n",
      "        [3.4000, 3.4884, 3.3675, 3.6320, 3.4620],\n",
      "        [3.3766, 3.5112, 3.5219, 3.5977, 3.4749],\n",
      "        [3.6500, 3.7739, 3.5776, 3.9374, 3.7282],\n",
      "        [3.4997, 3.4508, 3.5483, 3.6781, 3.6435],\n",
      "        [3.5089, 3.4699, 3.5707, 3.7040, 3.6536],\n",
      "        [3.6617, 3.7884, 3.5710, 3.7893, 3.7298],\n",
      "        [3.5371, 3.5319, 3.6198, 3.7403, 3.6236],\n",
      "        [3.3520, 3.5841, 3.3479, 3.6392, 3.4034],\n",
      "        [3.4951, 3.4563, 3.5500, 3.5805, 3.5941],\n",
      "        [3.3847, 3.5958, 3.5275, 3.5938, 3.5261],\n",
      "        [3.4875, 3.6385, 3.5614, 3.6935, 3.5760],\n",
      "        [3.5119, 3.5336, 3.5466, 3.6967, 3.5824],\n",
      "        [3.5680, 3.5355, 3.5484, 3.5973, 3.4046],\n",
      "        [3.4393, 3.4617, 3.5244, 3.6535, 3.6053],\n",
      "        [3.4896, 3.4914, 3.5185, 3.6539, 3.5392],\n",
      "        [3.4356, 3.4048, 3.4505, 3.6056, 3.4259],\n",
      "        [3.5862, 3.7660, 3.6259, 3.7201, 3.6884],\n",
      "        [3.4453, 3.5097, 3.5172, 3.7036, 3.5386],\n",
      "        [3.5953, 3.5463, 3.5939, 3.6548, 3.5286],\n",
      "        [3.3722, 3.4282, 3.4469, 3.5650, 3.4332],\n",
      "        [3.4299, 3.7476, 3.5516, 3.7294, 3.6799],\n",
      "        [3.4412, 3.3948, 3.4334, 3.6184, 3.4126],\n",
      "        [3.3005, 3.4470, 3.4213, 3.5346, 3.4535],\n",
      "        [3.6556, 3.7267, 3.5872, 3.7407, 3.6560],\n",
      "        [3.3809, 3.3598, 3.4008, 3.5741, 3.3953],\n",
      "        [3.3058, 3.4398, 3.3700, 3.4622, 3.4088],\n",
      "        [3.4970, 3.4325, 3.5044, 3.5814, 3.4692],\n",
      "        [3.6520, 3.7234, 3.5923, 3.7284, 3.6471],\n",
      "        [3.3353, 3.5903, 3.6376, 3.5688, 3.5795],\n",
      "        [3.3562, 3.5761, 3.6195, 3.5976, 3.5635],\n",
      "        [3.4569, 3.5497, 3.3946, 3.6308, 3.5132],\n",
      "        [3.4935, 3.4396, 3.5306, 3.6749, 3.6365],\n",
      "        [3.5472, 3.4595, 3.5262, 3.6811, 3.4987],\n",
      "        [3.5594, 3.5544, 3.6374, 3.7716, 3.5777],\n",
      "        [4.0551, 4.2658, 3.8066, 4.0660, 3.8201],\n",
      "        [3.7684, 3.4728, 3.6008, 4.0620, 3.9138],\n",
      "        [3.6273, 3.7122, 3.7088, 3.8334, 3.6860],\n",
      "        [3.3848, 3.5028, 3.3903, 3.5627, 3.4670],\n",
      "        [3.5101, 3.5073, 3.5859, 3.7078, 3.5918],\n",
      "        [3.6235, 3.7451, 3.5479, 3.8974, 3.6819],\n",
      "        [3.4999, 3.5058, 3.5330, 3.6747, 3.5489],\n",
      "        [3.6915, 3.7268, 3.6623, 3.8607, 3.8023],\n",
      "        [3.6572, 3.7754, 3.6759, 3.8736, 3.6887],\n",
      "        [3.6524, 3.8389, 3.6223, 3.6602, 3.6949],\n",
      "        [3.3580, 3.5387, 3.4978, 3.5663, 3.4625],\n",
      "        [3.6115, 3.6875, 3.5593, 3.6504, 3.6082],\n",
      "        [3.5801, 3.6271, 3.6458, 3.7593, 3.6471],\n",
      "        [3.3914, 3.4410, 3.4655, 3.5897, 3.4559],\n",
      "        [3.5933, 3.5936, 3.5670, 3.7350, 3.5724],\n",
      "        [3.6120, 3.7371, 3.5560, 3.7448, 3.6536],\n",
      "        [3.6233, 3.7492, 3.5512, 3.9014, 3.6867],\n",
      "        [3.3790, 3.4198, 3.4430, 3.5668, 3.4306],\n",
      "        [3.6075, 3.5609, 3.5969, 3.7494, 3.5781],\n",
      "        [3.3863, 3.4069, 3.4352, 3.5739, 3.4242],\n",
      "        [3.7300, 3.7444, 3.7788, 4.0043, 3.6857]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5149, 3.6991, 3.5366, 3.8179, 3.5624],\n",
      "        [3.4336, 3.4454, 3.5479, 3.6369, 3.5030],\n",
      "        [3.4481, 3.4139, 3.5039, 3.6081, 3.4765],\n",
      "        [3.4997, 3.5307, 3.5440, 3.6883, 3.5636],\n",
      "        [3.5784, 3.6057, 3.6343, 3.7532, 3.6250],\n",
      "        [3.5128, 3.5615, 3.6123, 3.7182, 3.6826],\n",
      "        [3.5009, 3.5137, 3.5373, 3.6808, 3.5534],\n",
      "        [3.4969, 3.4817, 3.5463, 3.6609, 3.5396],\n",
      "        [3.7288, 3.7237, 3.6521, 3.8525, 3.7589],\n",
      "        [3.4777, 3.5450, 3.5206, 3.6798, 3.6627],\n",
      "        [3.6782, 3.7600, 3.6008, 3.8838, 3.7887],\n",
      "        [3.6787, 3.8017, 3.7051, 3.8482, 3.6794],\n",
      "        [3.4961, 3.4569, 3.5551, 3.5849, 3.5932],\n",
      "        [3.5049, 3.5846, 3.5631, 3.6718, 3.4665],\n",
      "        [3.6401, 3.7382, 3.5699, 3.7536, 3.6650],\n",
      "        [3.5957, 3.6159, 3.5631, 3.8402, 3.6071],\n",
      "        [3.6631, 3.6838, 3.6869, 3.8575, 3.5725],\n",
      "        [3.8543, 3.7977, 3.7370, 4.0015, 3.8577],\n",
      "        [3.8602, 3.7209, 3.7722, 4.0581, 3.8441],\n",
      "        [3.4244, 3.7516, 3.6415, 3.7293, 3.7286],\n",
      "        [3.6890, 3.6789, 3.8293, 3.7445, 3.5778],\n",
      "        [3.3627, 3.4941, 3.4871, 3.5756, 3.4640],\n",
      "        [3.5389, 3.5664, 3.6764, 3.7533, 3.6405],\n",
      "        [3.4926, 3.4916, 3.5265, 3.6529, 3.5411],\n",
      "        [3.4691, 3.4828, 3.5444, 3.6776, 3.6248],\n",
      "        [3.5097, 3.7303, 3.5725, 3.6852, 3.4765],\n",
      "        [3.6526, 3.7250, 3.5791, 3.8301, 3.6773],\n",
      "        [3.4469, 3.5594, 3.5694, 3.6808, 3.6954],\n",
      "        [3.4733, 3.4926, 3.5379, 3.6823, 3.6243],\n",
      "        [3.5824, 3.7335, 3.5981, 3.6963, 3.6925],\n",
      "        [3.5113, 3.5032, 3.5611, 3.6764, 3.5959],\n",
      "        [3.2890, 3.4713, 3.5875, 3.5039, 3.5419],\n",
      "        [3.3877, 3.3632, 3.4049, 3.5758, 3.3978],\n",
      "        [3.6282, 3.6025, 3.6174, 3.7142, 3.5007],\n",
      "        [3.2823, 3.4062, 3.3523, 3.4417, 3.3898],\n",
      "        [3.6155, 3.5527, 3.6098, 3.6436, 3.5905],\n",
      "        [3.6601, 3.7797, 3.6125, 3.8338, 3.7003],\n",
      "        [3.7123, 3.7827, 3.6046, 3.8277, 3.8123],\n",
      "        [3.5661, 3.6722, 3.6324, 3.8233, 3.6845],\n",
      "        [3.5930, 3.5378, 3.5907, 3.6462, 3.5334],\n",
      "        [3.7690, 3.4733, 3.6014, 4.0626, 3.9141],\n",
      "        [3.6514, 3.5865, 3.5775, 3.6587, 3.4934],\n",
      "        [3.7617, 3.8146, 3.6631, 3.9052, 3.8466],\n",
      "        [3.6049, 3.4346, 3.6942, 3.7605, 3.6263],\n",
      "        [3.4694, 3.5595, 3.4025, 3.6366, 3.5269],\n",
      "        [3.3143, 3.3749, 3.3728, 3.4770, 3.3878],\n",
      "        [3.3064, 3.4402, 3.3707, 3.4625, 3.4091],\n",
      "        [3.4237, 3.5062, 3.5518, 3.7038, 3.5740],\n",
      "        [3.6322, 3.7496, 3.6191, 3.8578, 3.8293],\n",
      "        [3.4652, 3.5090, 3.4743, 3.5870, 3.5257],\n",
      "        [3.3550, 3.5913, 3.3531, 3.6281, 3.4031],\n",
      "        [3.8664, 4.0511, 3.6030, 3.8369, 3.6841],\n",
      "        [3.5727, 3.6253, 3.4883, 3.7482, 3.6016],\n",
      "        [3.9053, 3.9982, 3.5934, 3.8804, 3.6559],\n",
      "        [3.6238, 3.7495, 3.5519, 3.9018, 3.6869],\n",
      "        [3.6572, 3.6329, 3.6638, 3.8894, 3.5857],\n",
      "        [3.4686, 3.5681, 3.4085, 3.6523, 3.5197],\n",
      "        [3.6117, 3.6948, 3.5477, 3.7982, 3.7189],\n",
      "        [3.3741, 3.4410, 3.4588, 3.5737, 3.4474],\n",
      "        [3.8023, 3.7312, 3.6925, 3.9337, 3.7794],\n",
      "        [3.5815, 3.7666, 3.5881, 3.8818, 3.6776],\n",
      "        [3.8067, 3.8543, 3.7655, 3.9359, 3.8654],\n",
      "        [3.4848, 3.5792, 3.3998, 3.6842, 3.5235],\n",
      "        [3.6406, 3.7174, 3.5916, 3.6996, 3.6381]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4447, 3.3586, 3.3895, 3.5894, 3.3981],\n",
      "        [3.5033, 3.5952, 3.4130, 3.6995, 3.5449],\n",
      "        [3.5846, 3.7176, 3.5588, 3.8051, 3.6215],\n",
      "        [3.6991, 3.8371, 3.6757, 3.7254, 3.7424],\n",
      "        [3.6093, 3.5773, 3.6142, 3.6850, 3.5166],\n",
      "        [3.7814, 3.9164, 3.6964, 3.7861, 3.7438],\n",
      "        [3.3573, 3.5561, 3.5111, 3.5804, 3.4859],\n",
      "        [3.6607, 3.7850, 3.5550, 3.7833, 3.7121],\n",
      "        [3.5112, 3.4798, 3.5572, 3.6191, 3.5942],\n",
      "        [3.3237, 3.3465, 3.4010, 3.4883, 3.3486],\n",
      "        [3.8593, 3.7279, 3.7821, 4.1111, 3.8881],\n",
      "        [3.6099, 3.4403, 3.6965, 3.7635, 3.6290],\n",
      "        [3.7658, 3.6222, 3.7186, 3.9586, 3.7186],\n",
      "        [3.6159, 3.9341, 3.6731, 3.9537, 3.8191],\n",
      "        [3.3605, 3.5615, 3.5098, 3.5752, 3.4838],\n",
      "        [3.7040, 3.7571, 3.7146, 3.8583, 3.8769],\n",
      "        [3.4361, 3.6648, 3.5535, 3.7018, 3.6825],\n",
      "        [3.6685, 3.5297, 3.5467, 4.0305, 3.7401],\n",
      "        [3.7051, 3.7241, 3.6732, 3.8461, 3.8825],\n",
      "        [3.4626, 3.6188, 3.5512, 3.6712, 3.5976],\n",
      "        [3.3688, 3.4482, 3.4606, 3.5631, 3.4373],\n",
      "        [3.6985, 3.6687, 3.7588, 3.8200, 3.5100],\n",
      "        [3.5559, 3.8086, 3.7359, 3.8495, 3.7778],\n",
      "        [3.5545, 3.5508, 3.6384, 3.7385, 3.6230],\n",
      "        [3.3282, 3.3667, 3.4173, 3.5185, 3.3563],\n",
      "        [3.4098, 3.3946, 3.4309, 3.5981, 3.4243],\n",
      "        [3.4793, 3.5821, 3.5465, 3.7690, 3.5227],\n",
      "        [3.4361, 3.5647, 3.5075, 3.7434, 3.4778],\n",
      "        [3.4914, 3.6306, 3.4941, 3.7119, 3.6243],\n",
      "        [3.5153, 3.7316, 3.5764, 3.6920, 3.4783],\n",
      "        [3.4964, 3.6925, 3.5913, 3.6317, 3.6527],\n",
      "        [3.5112, 3.6667, 3.5223, 3.6909, 3.6389],\n",
      "        [3.6164, 3.4284, 3.4462, 3.6519, 3.5771],\n",
      "        [3.7408, 3.8506, 3.7641, 3.9522, 3.8406],\n",
      "        [3.5393, 3.5667, 3.6787, 3.7541, 3.6407],\n",
      "        [3.7664, 3.8225, 3.7394, 3.8903, 3.8173],\n",
      "        [3.3926, 3.3865, 3.4239, 3.5882, 3.4135],\n",
      "        [3.2842, 3.4324, 3.4256, 3.5149, 3.4465],\n",
      "        [3.3546, 3.5931, 3.3524, 3.6303, 3.4045],\n",
      "        [3.5605, 3.5361, 3.6511, 3.8435, 3.7921],\n",
      "        [3.6515, 3.7273, 3.5861, 3.7588, 3.6532],\n",
      "        [3.5012, 3.5139, 3.5397, 3.6815, 3.5534],\n",
      "        [3.6358, 3.5804, 3.6265, 3.7917, 3.6095],\n",
      "        [3.2601, 3.4052, 3.4202, 3.4866, 3.4203],\n",
      "        [3.4475, 3.3887, 3.4186, 3.5972, 3.4179],\n",
      "        [3.5964, 3.5470, 3.5968, 3.6561, 3.5289],\n",
      "        [3.5145, 3.7426, 3.5257, 3.5371, 3.6392],\n",
      "        [3.6509, 3.7745, 3.5807, 3.9385, 3.7285],\n",
      "        [3.7127, 3.7570, 3.6934, 3.8596, 3.8926],\n",
      "        [3.4237, 3.7081, 3.5577, 3.5169, 3.6540],\n",
      "        [3.3620, 3.3669, 3.4174, 3.5686, 3.4235],\n",
      "        [3.4169, 3.5169, 3.3880, 3.5849, 3.4733],\n",
      "        [3.9930, 4.1140, 3.7478, 3.9532, 3.7351],\n",
      "        [3.9449, 4.1634, 3.7086, 3.9639, 3.7330],\n",
      "        [3.4799, 3.7830, 3.6006, 3.7805, 3.7448],\n",
      "        [3.4571, 3.5532, 3.5079, 3.7224, 3.5591],\n",
      "        [3.8300, 3.8365, 3.7363, 4.0958, 3.8714],\n",
      "        [3.5011, 3.6844, 3.5093, 3.6371, 3.6127],\n",
      "        [3.3478, 3.5081, 3.4855, 3.5625, 3.4447],\n",
      "        [3.5467, 3.6666, 3.4583, 3.6670, 3.5962],\n",
      "        [4.0348, 4.2298, 3.7621, 4.0158, 3.8347],\n",
      "        [3.4842, 3.7207, 3.6395, 3.6142, 3.6696],\n",
      "        [3.4630, 3.4746, 3.4773, 3.6828, 3.4666],\n",
      "        [3.2679, 3.4063, 3.4302, 3.4907, 3.4483]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3017, 3.4475, 3.4264, 3.5361, 3.4537],\n",
      "        [3.6512, 3.7745, 3.5828, 3.9390, 3.7284],\n",
      "        [3.7175, 3.7272, 3.6596, 3.9173, 3.8501],\n",
      "        [3.3705, 3.4493, 3.4678, 3.5667, 3.4392],\n",
      "        [3.9246, 4.0058, 3.6206, 3.8994, 3.6585],\n",
      "        [3.7258, 3.7029, 3.6894, 3.8690, 3.8808],\n",
      "        [3.6304, 3.7254, 3.5735, 3.7638, 3.6606],\n",
      "        [3.6106, 3.5603, 3.6034, 3.7481, 3.5845],\n",
      "        [3.3725, 3.5890, 3.5346, 3.5980, 3.5102],\n",
      "        [3.4458, 3.5865, 3.4899, 3.7201, 3.5074],\n",
      "        [3.5009, 3.5063, 3.5378, 3.6763, 3.5489],\n",
      "        [3.4385, 3.3778, 3.5353, 3.4586, 3.5820],\n",
      "        [3.5694, 3.7657, 3.6087, 3.7942, 3.7670],\n",
      "        [3.4791, 3.5487, 3.4932, 3.6287, 3.5309],\n",
      "        [3.6449, 3.7677, 3.5764, 3.9299, 3.7187],\n",
      "        [3.4123, 3.4940, 3.4005, 3.6226, 3.4609],\n",
      "        [3.3748, 3.4276, 3.4533, 3.5701, 3.4324],\n",
      "        [3.7032, 3.7836, 3.7445, 3.8289, 3.5789],\n",
      "        [3.7406, 3.8545, 3.7641, 3.9504, 3.8350],\n",
      "        [3.6671, 3.4556, 3.4391, 3.6325, 3.6396],\n",
      "        [3.7581, 3.7378, 3.6479, 3.8753, 3.7674],\n",
      "        [3.5014, 3.5139, 3.5416, 3.6820, 3.5532],\n",
      "        [3.4285, 3.4248, 3.4632, 3.6133, 3.4319],\n",
      "        [3.6478, 3.7048, 3.6643, 3.7371, 3.6873],\n",
      "        [3.6933, 3.9173, 3.7869, 3.9165, 3.8482],\n",
      "        [3.6148, 3.5023, 3.7707, 3.8004, 3.7144],\n",
      "        [3.4996, 3.6445, 3.5134, 3.7135, 3.6341],\n",
      "        [3.5919, 3.5969, 3.4328, 3.7885, 3.6994],\n",
      "        [3.7288, 3.7968, 3.6319, 3.8618, 3.8325],\n",
      "        [3.4313, 3.5238, 3.5868, 3.6318, 3.5699],\n",
      "        [3.9003, 4.0163, 3.7380, 3.8966, 3.7508],\n",
      "        [3.3642, 3.5450, 3.5076, 3.5837, 3.4795],\n",
      "        [3.5268, 3.7234, 3.5831, 3.7051, 3.4841],\n",
      "        [3.6520, 3.7701, 3.5746, 3.9285, 3.7144],\n",
      "        [3.5731, 3.7351, 3.5998, 3.7107, 3.6722],\n",
      "        [3.6244, 3.7194, 3.7130, 3.8127, 3.6640],\n",
      "        [3.5409, 3.7218, 3.5814, 3.8518, 3.5752],\n",
      "        [3.4948, 3.5883, 3.4098, 3.6888, 3.5362],\n",
      "        [3.6740, 3.6591, 3.6840, 3.8717, 3.5296],\n",
      "        [3.5144, 3.7387, 3.5108, 3.5339, 3.6000],\n",
      "        [3.6269, 3.6943, 3.7533, 3.8479, 3.7420],\n",
      "        [3.4489, 3.4142, 3.5079, 3.6093, 3.4766],\n",
      "        [3.3800, 3.4437, 3.4633, 3.5759, 3.4498],\n",
      "        [3.6521, 3.7321, 3.6925, 3.8534, 3.6580],\n",
      "        [3.6162, 3.8921, 3.7361, 3.8698, 3.8633],\n",
      "        [3.8775, 3.9433, 3.8281, 4.1939, 3.9485],\n",
      "        [3.7380, 3.7002, 3.5774, 3.8516, 3.7874],\n",
      "        [3.6512, 3.7745, 3.5828, 3.9390, 3.7284],\n",
      "        [3.4759, 3.4417, 3.5340, 3.6362, 3.5014],\n",
      "        [3.7281, 3.7020, 3.7038, 3.9818, 3.9436],\n",
      "        [3.6222, 3.4823, 3.4489, 3.6254, 3.6315],\n",
      "        [3.5750, 3.7950, 3.6331, 3.8041, 3.7749],\n",
      "        [3.6082, 3.8378, 3.6357, 3.8287, 3.7079],\n",
      "        [3.4683, 3.6565, 3.6226, 3.6901, 3.6054],\n",
      "        [3.4964, 3.4570, 3.5548, 3.5820, 3.5944],\n",
      "        [3.3588, 3.5029, 3.4856, 3.5676, 3.4612],\n",
      "        [3.5823, 3.7670, 3.5925, 3.8831, 3.6776],\n",
      "        [3.6096, 3.5773, 3.6161, 3.6855, 3.5165],\n",
      "        [3.4463, 3.5102, 3.5220, 3.7052, 3.5386],\n",
      "        [3.4056, 3.6323, 3.5512, 3.6677, 3.6956],\n",
      "        [3.8753, 3.6383, 3.7377, 4.3271, 4.0636],\n",
      "        [3.7303, 3.4747, 3.6091, 4.0045, 3.8688],\n",
      "        [3.7923, 3.7956, 3.6766, 3.9390, 3.8724],\n",
      "        [3.6389, 3.4936, 3.4696, 3.6425, 3.6485]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3893, 3.4481, 3.4852, 3.5939, 3.4239],\n",
      "        [3.6186, 3.6949, 3.5478, 3.7508, 3.7686],\n",
      "        [3.6537, 3.9270, 3.7403, 3.9009, 3.8687],\n",
      "        [4.0511, 4.2320, 3.8323, 4.0666, 3.8193],\n",
      "        [3.9079, 3.6830, 3.7757, 4.3518, 4.0781],\n",
      "        [3.8221, 3.9555, 3.7033, 3.8296, 3.7210],\n",
      "        [3.4370, 3.6709, 3.5673, 3.6977, 3.7263],\n",
      "        [3.4923, 3.5052, 3.5417, 3.6798, 3.5575],\n",
      "        [3.5926, 3.7091, 3.6853, 3.8727, 3.7141],\n",
      "        [3.4421, 3.5918, 3.4538, 3.7326, 3.4831],\n",
      "        [3.4490, 3.4156, 3.5104, 3.6095, 3.4765],\n",
      "        [3.3683, 3.4552, 3.4683, 3.5772, 3.4434],\n",
      "        [3.3033, 3.4448, 3.4223, 3.5482, 3.4467],\n",
      "        [3.4926, 3.4655, 3.5505, 3.6428, 3.5293],\n",
      "        [3.5769, 3.8171, 3.6551, 3.8143, 3.7810],\n",
      "        [3.4615, 3.4277, 3.5230, 3.6237, 3.4938],\n",
      "        [3.3527, 3.5186, 3.6441, 3.5606, 3.6155],\n",
      "        [3.3525, 3.4931, 3.4816, 3.5580, 3.4437],\n",
      "        [3.3755, 3.4349, 3.4592, 3.5660, 3.4344],\n",
      "        [3.5396, 3.6217, 3.5675, 3.7220, 3.6399],\n",
      "        [3.6232, 3.4780, 3.4549, 3.6337, 3.6262],\n",
      "        [3.5949, 3.5957, 3.5745, 3.7368, 3.5724],\n",
      "        [3.5195, 3.6145, 3.4294, 3.7276, 3.5578],\n",
      "        [3.5152, 3.4215, 3.5003, 3.5624, 3.4503],\n",
      "        [3.9180, 3.9306, 3.8092, 4.2376, 3.9557],\n",
      "        [3.4847, 3.7129, 3.6294, 3.6177, 3.6619],\n",
      "        [3.6316, 3.9015, 3.7122, 3.8776, 3.8816],\n",
      "        [3.6621, 3.6721, 3.6015, 3.8665, 3.7828],\n",
      "        [3.3892, 3.3594, 3.4140, 3.5827, 3.3942],\n",
      "        [3.8537, 3.8164, 3.7154, 3.9915, 3.8446],\n",
      "        [3.5102, 3.5954, 3.5699, 3.6681, 3.4745],\n",
      "        [3.6223, 3.4836, 3.4514, 3.6258, 3.6314],\n",
      "        [3.4992, 3.7779, 3.6677, 3.7851, 3.7649],\n",
      "        [3.7597, 3.7066, 3.7268, 3.9487, 3.7476],\n",
      "        [3.4071, 3.4166, 3.5322, 3.6034, 3.4837],\n",
      "        [3.3151, 3.3764, 3.3800, 3.4782, 3.3878],\n",
      "        [3.4190, 3.5627, 3.6090, 3.6924, 3.6413],\n",
      "        [3.3909, 3.4436, 3.3668, 3.6218, 3.3555],\n",
      "        [3.4825, 3.4385, 3.5047, 3.6488, 3.6393],\n",
      "        [3.5338, 3.5111, 3.5963, 3.6765, 3.5648],\n",
      "        [3.5388, 3.6755, 3.4968, 3.6553, 3.6102],\n",
      "        [3.7623, 3.7708, 3.7063, 3.9935, 3.7308],\n",
      "        [3.3534, 3.5119, 3.4899, 3.5604, 3.4502],\n",
      "        [3.8427, 3.8730, 3.8718, 4.1440, 4.1162],\n",
      "        [3.4051, 3.4240, 3.3410, 3.6243, 3.3871],\n",
      "        [3.7222, 3.5594, 3.5891, 4.0545, 3.7929],\n",
      "        [3.7775, 3.6969, 3.6524, 3.8626, 3.7778],\n",
      "        [3.6422, 3.7245, 3.5569, 3.7768, 3.7575],\n",
      "        [3.5825, 3.7684, 3.5952, 3.8832, 3.6774],\n",
      "        [3.5742, 3.4846, 3.7916, 3.7601, 3.6886],\n",
      "        [3.3432, 3.3336, 3.4043, 3.5947, 3.4034],\n",
      "        [3.3748, 3.4426, 3.4658, 3.5750, 3.4471],\n",
      "        [3.6902, 3.9048, 3.7181, 4.0026, 3.8601],\n",
      "        [3.5397, 3.5353, 3.6507, 3.8523, 3.7877],\n",
      "        [3.4649, 3.5022, 3.4665, 3.5801, 3.5327],\n",
      "        [3.3577, 3.5575, 3.5160, 3.5809, 3.4856],\n",
      "        [3.4950, 3.4417, 3.5380, 3.6769, 3.6366],\n",
      "        [3.6485, 3.6652, 3.5009, 3.8413, 3.7337],\n",
      "        [3.6667, 3.7360, 3.7112, 3.9504, 3.6584],\n",
      "        [3.6579, 3.4665, 3.4565, 3.6358, 3.6328],\n",
      "        [3.3713, 3.4905, 3.4042, 3.5279, 3.4785],\n",
      "        [3.3819, 3.3615, 3.4080, 3.5758, 3.3950],\n",
      "        [3.3893, 3.4047, 3.4414, 3.5769, 3.4253],\n",
      "        [3.5260, 3.8392, 3.7183, 3.7670, 3.6226]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4219, 3.5380, 3.4096, 3.5983, 3.4940],\n",
      "        [3.7137, 3.7868, 3.6142, 3.8291, 3.8125],\n",
      "        [3.8877, 3.9438, 3.8403, 4.1868, 3.9304],\n",
      "        [3.4263, 3.4797, 3.5107, 3.6594, 3.5169],\n",
      "        [3.4539, 3.5535, 3.4045, 3.6263, 3.5057],\n",
      "        [3.5254, 3.7498, 3.5264, 3.8366, 3.6471],\n",
      "        [3.5460, 3.7121, 3.6880, 3.8393, 3.6560],\n",
      "        [3.3816, 3.5757, 3.6235, 3.6139, 3.5767],\n",
      "        [3.4368, 3.4084, 3.4603, 3.6070, 3.4264],\n",
      "        [3.6488, 3.7741, 3.5817, 3.9293, 3.7172],\n",
      "        [3.5283, 3.7503, 3.6601, 3.8051, 3.7740],\n",
      "        [3.3630, 3.5617, 3.5197, 3.5829, 3.4909],\n",
      "        [3.3434, 3.4780, 3.3975, 3.5146, 3.4431],\n",
      "        [3.6451, 3.6137, 3.6541, 3.8798, 3.5769],\n",
      "        [3.4977, 3.3999, 3.4780, 3.5367, 3.4265],\n",
      "        [3.4050, 3.4988, 3.4017, 3.6198, 3.4495],\n",
      "        [3.6034, 3.7935, 3.6948, 3.8143, 3.6402],\n",
      "        [3.4889, 3.5063, 3.5321, 3.6625, 3.5437],\n",
      "        [4.1279, 4.2678, 3.8970, 4.1176, 3.8586],\n",
      "        [3.6232, 3.4798, 3.4571, 3.6337, 3.6270],\n",
      "        [3.6148, 3.6456, 3.6123, 3.7123, 3.4249],\n",
      "        [3.6989, 3.6720, 3.7659, 3.8203, 3.5101],\n",
      "        [3.6394, 3.6172, 3.7039, 3.7306, 3.4429],\n",
      "        [3.3551, 3.4848, 3.4010, 3.5179, 3.4564],\n",
      "        [3.6226, 3.8753, 3.7386, 3.8506, 3.8002],\n",
      "        [3.6520, 3.5829, 3.5614, 3.9750, 3.7387],\n",
      "        [3.9196, 3.6491, 3.7382, 4.2727, 4.0904],\n",
      "        [3.5053, 3.5560, 3.5585, 3.6699, 3.7312],\n",
      "        [3.3748, 3.4971, 3.4034, 3.5371, 3.4682],\n",
      "        [3.5542, 3.4762, 3.5427, 3.6913, 3.5095],\n",
      "        [3.6602, 3.8127, 3.7124, 3.8574, 3.6956],\n",
      "        [3.5137, 3.6445, 3.6015, 3.7088, 3.5248],\n",
      "        [3.7760, 3.5892, 3.6111, 4.1130, 3.8374],\n",
      "        [3.7484, 3.8108, 3.7207, 3.8990, 3.8396],\n",
      "        [3.6267, 3.7178, 3.5619, 3.7717, 3.6620],\n",
      "        [3.5339, 3.6337, 3.5659, 3.7222, 3.6347],\n",
      "        [3.7052, 3.8190, 3.7750, 3.8283, 3.5378],\n",
      "        [3.5120, 3.6498, 3.4754, 3.8187, 3.5042],\n",
      "        [3.5379, 3.5416, 3.6213, 3.7434, 3.6205],\n",
      "        [3.8511, 3.6574, 3.7540, 4.3139, 4.0773],\n",
      "        [3.3613, 3.4442, 3.4655, 3.5610, 3.4314],\n",
      "        [3.3595, 3.5096, 3.4951, 3.5757, 3.4668],\n",
      "        [3.6517, 3.7460, 3.6007, 3.8316, 3.6806],\n",
      "        [3.5709, 3.7257, 3.6142, 3.7436, 3.5125],\n",
      "        [3.7504, 3.8122, 3.6589, 3.8851, 3.8631],\n",
      "        [3.5115, 3.6067, 3.4145, 3.7134, 3.5458],\n",
      "        [3.4753, 3.5879, 3.4180, 3.6698, 3.5300],\n",
      "        [3.7673, 3.6213, 3.7182, 3.9621, 3.7122],\n",
      "        [3.7324, 3.7531, 3.7885, 4.0086, 3.6905],\n",
      "        [3.3196, 3.4655, 3.4289, 3.5581, 3.4612],\n",
      "        [3.3643, 3.5481, 3.5128, 3.5836, 3.4798],\n",
      "        [3.4947, 3.5914, 3.4148, 3.6888, 3.5365],\n",
      "        [3.5691, 3.7241, 3.6173, 3.7436, 3.5103],\n",
      "        [3.7790, 3.4737, 3.6244, 4.0631, 3.9120],\n",
      "        [3.6346, 3.8308, 3.6171, 3.6384, 3.6854],\n",
      "        [3.3200, 3.3647, 3.3861, 3.4804, 3.3919],\n",
      "        [3.5680, 3.5586, 3.6479, 3.7543, 3.6316],\n",
      "        [3.5154, 3.7029, 3.5458, 3.8192, 3.5624],\n",
      "        [3.4656, 3.4173, 3.4749, 3.6142, 3.6196],\n",
      "        [3.6771, 3.8122, 3.5680, 3.7647, 3.6879],\n",
      "        [3.5465, 3.6759, 3.4775, 3.6635, 3.5974],\n",
      "        [3.4600, 3.4729, 3.5294, 3.6285, 3.5227],\n",
      "        [3.4257, 3.5383, 3.4077, 3.6009, 3.4921],\n",
      "        [3.6457, 3.7838, 3.5578, 3.7758, 3.7042]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4967, 3.5300, 3.5515, 3.6851, 3.5593],\n",
      "        [3.5259, 3.4425, 3.5244, 3.5746, 3.4708],\n",
      "        [3.2732, 3.4122, 3.3664, 3.4271, 3.3783],\n",
      "        [3.4954, 3.5080, 3.5368, 3.6593, 3.5440],\n",
      "        [3.5315, 3.5470, 3.5636, 3.5909, 3.4030],\n",
      "        [3.4198, 3.4957, 3.5357, 3.6366, 3.4492],\n",
      "        [3.8509, 3.6590, 3.7561, 4.3137, 4.0777],\n",
      "        [3.4097, 3.3991, 3.4394, 3.5982, 3.4247],\n",
      "        [3.6642, 3.7813, 3.5734, 3.7875, 3.7281],\n",
      "        [3.3931, 3.4180, 3.4535, 3.5797, 3.4313],\n",
      "        [3.6509, 3.7792, 3.5901, 3.9385, 3.7290],\n",
      "        [3.6655, 3.7886, 3.5705, 3.7868, 3.7218],\n",
      "        [3.4011, 3.5048, 3.3813, 3.6300, 3.4649],\n",
      "        [3.4180, 3.5057, 3.5465, 3.6364, 3.4526],\n",
      "        [3.4473, 3.5179, 3.5280, 3.6954, 3.5302],\n",
      "        [3.7132, 3.7626, 3.7026, 3.8600, 3.8929],\n",
      "        [3.5124, 3.5143, 3.5724, 3.6793, 3.5976],\n",
      "        [3.4606, 3.5664, 3.4159, 3.6395, 3.5167],\n",
      "        [3.4787, 3.5280, 3.4624, 3.5914, 3.5228],\n",
      "        [3.3516, 3.5502, 3.5086, 3.5639, 3.4661],\n",
      "        [3.7576, 3.8721, 3.5775, 3.7919, 3.6806],\n",
      "        [3.4343, 3.4504, 3.5586, 3.6378, 3.5039],\n",
      "        [3.5451, 3.7257, 3.6029, 3.7215, 3.4937],\n",
      "        [3.6616, 3.7374, 3.6828, 3.7324, 3.6932],\n",
      "        [3.9259, 4.0111, 3.6277, 3.8993, 3.6592],\n",
      "        [3.7798, 3.7344, 3.7392, 3.9445, 3.6490],\n",
      "        [3.7000, 3.6691, 3.7542, 3.8311, 3.5518],\n",
      "        [3.4924, 3.4530, 3.5352, 3.6670, 3.6500],\n",
      "        [3.6914, 3.6994, 3.6632, 3.8262, 3.8080],\n",
      "        [3.5052, 3.5576, 3.5604, 3.6696, 3.7315],\n",
      "        [3.4851, 3.5839, 3.4110, 3.6849, 3.5242],\n",
      "        [3.4901, 3.6394, 3.5757, 3.6977, 3.5703],\n",
      "        [3.8154, 3.7778, 3.7900, 4.0337, 3.8247],\n",
      "        [3.5489, 3.7407, 3.5344, 3.5502, 3.5666],\n",
      "        [3.5101, 3.5987, 3.5740, 3.6676, 3.4754],\n",
      "        [3.4473, 3.3934, 3.5477, 3.4836, 3.5838],\n",
      "        [3.3194, 3.4670, 3.4309, 3.5577, 3.4615],\n",
      "        [3.4182, 3.5311, 3.4025, 3.5895, 3.4859],\n",
      "        [3.4746, 3.5719, 3.5314, 3.7197, 3.6012],\n",
      "        [3.6680, 3.7467, 3.6405, 3.8068, 3.7680],\n",
      "        [3.4879, 3.4580, 3.5275, 3.6068, 3.4962],\n",
      "        [3.4865, 3.4439, 3.5642, 3.5512, 3.5989],\n",
      "        [3.7759, 3.7360, 3.7481, 3.9096, 3.9189],\n",
      "        [3.4086, 3.4204, 3.4573, 3.6055, 3.4502],\n",
      "        [3.8431, 3.5897, 3.6347, 4.2212, 3.9150],\n",
      "        [3.5121, 3.5082, 3.5719, 3.6774, 3.5967],\n",
      "        [3.3632, 3.4989, 3.4986, 3.5762, 3.4647],\n",
      "        [3.3566, 3.4621, 3.4701, 3.5561, 3.4360],\n",
      "        [3.3651, 3.5749, 3.5247, 3.5871, 3.4958],\n",
      "        [3.8086, 3.8601, 3.7773, 3.9370, 3.8659],\n",
      "        [3.7354, 3.7040, 3.7053, 3.8644, 3.8863],\n",
      "        [3.5146, 3.7474, 3.5345, 3.5373, 3.6396],\n",
      "        [3.7608, 3.8203, 3.6669, 3.8908, 3.8578],\n",
      "        [3.5211, 3.4882, 3.6000, 3.7258, 3.6608],\n",
      "        [3.5885, 3.5479, 3.5675, 3.6205, 3.4192],\n",
      "        [3.4208, 3.5202, 3.4008, 3.5871, 3.4735],\n",
      "        [3.5909, 3.7619, 3.6128, 3.8905, 3.6775],\n",
      "        [3.3841, 3.3628, 3.4126, 3.5732, 3.3953],\n",
      "        [3.4360, 3.5698, 3.5160, 3.7436, 3.4781],\n",
      "        [3.5134, 3.5369, 3.4432, 3.6584, 3.6361],\n",
      "        [3.4850, 3.4859, 3.5318, 3.6501, 3.5333],\n",
      "        [3.6714, 3.4909, 3.6154, 3.9144, 3.8293],\n",
      "        [3.4995, 3.6494, 3.5202, 3.7131, 3.6346],\n",
      "        [3.4223, 3.4959, 3.4986, 3.5611, 3.4870]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3810, 3.5785, 3.6272, 3.6128, 3.5769],\n",
      "        [3.5003, 3.6017, 3.5741, 3.6678, 3.4834],\n",
      "        [3.3196, 3.4555, 3.3893, 3.4805, 3.4215],\n",
      "        [3.4745, 3.5142, 3.6685, 3.5343, 3.7133],\n",
      "        [3.6133, 3.6558, 3.5924, 3.8883, 3.6162],\n",
      "        [3.4386, 3.4086, 3.4593, 3.6115, 3.4255],\n",
      "        [3.5302, 3.5016, 3.5966, 3.6962, 3.5546],\n",
      "        [3.7785, 3.4765, 3.6279, 4.0624, 3.9125],\n",
      "        [3.3559, 3.5587, 3.5200, 3.5694, 3.4747],\n",
      "        [3.6262, 3.7205, 3.5656, 3.7708, 3.6623],\n",
      "        [3.5604, 3.5599, 3.6437, 3.7459, 3.6379],\n",
      "        [3.7423, 3.7023, 3.7747, 3.8915, 3.5881],\n",
      "        [3.5834, 3.7197, 3.5689, 3.7968, 3.6292],\n",
      "        [3.6103, 3.5664, 3.6118, 3.7471, 3.5853],\n",
      "        [3.7518, 3.7317, 3.7370, 4.0009, 3.9554],\n",
      "        [3.5563, 3.4888, 3.5527, 3.7037, 3.5229],\n",
      "        [3.4704, 3.5719, 3.4093, 3.6653, 3.5127],\n",
      "        [3.5115, 3.6099, 3.4204, 3.7276, 3.5516],\n",
      "        [3.6795, 3.6479, 3.7407, 3.7851, 3.5060],\n",
      "        [3.3927, 3.4192, 3.4551, 3.5791, 3.4313],\n",
      "        [3.3590, 3.5123, 3.4988, 3.5747, 3.4671],\n",
      "        [3.4451, 3.4855, 3.5102, 3.6564, 3.4638],\n",
      "        [3.7035, 3.7951, 3.7511, 3.8893, 3.8978],\n",
      "        [3.3786, 3.4472, 3.4910, 3.5867, 3.4201],\n",
      "        [3.5392, 3.5399, 3.6566, 3.8514, 3.7887],\n",
      "        [3.3556, 3.5829, 3.6204, 3.5904, 3.5989],\n",
      "        [3.5639, 3.6142, 3.5880, 3.7106, 3.6048],\n",
      "        [3.4131, 3.5776, 3.4796, 3.6246, 3.5496],\n",
      "        [3.3992, 3.5392, 3.4353, 3.6481, 3.4692],\n",
      "        [3.5009, 3.5244, 3.5729, 3.6925, 3.5779],\n",
      "        [3.6505, 3.7804, 3.5918, 3.9379, 3.7291],\n",
      "        [3.8362, 3.7419, 3.7173, 4.0405, 3.7953],\n",
      "        [3.5113, 3.5140, 3.5989, 3.7086, 3.5930],\n",
      "        [3.5849, 3.6259, 3.5882, 3.7726, 3.6913],\n",
      "        [3.7022, 3.9240, 3.7415, 4.0089, 3.8758],\n",
      "        [3.5247, 3.6146, 3.4271, 3.7247, 3.5484],\n",
      "        [3.5788, 3.6239, 3.5254, 3.7828, 3.6287],\n",
      "        [3.3788, 3.5076, 3.4067, 3.5555, 3.4624],\n",
      "        [3.5336, 3.8773, 3.7019, 3.7175, 3.6216],\n",
      "        [3.4621, 3.5785, 3.4236, 3.6518, 3.5176],\n",
      "        [3.6413, 3.7237, 3.6045, 3.7000, 3.6386],\n",
      "        [3.3874, 3.3690, 3.4170, 3.5760, 3.3982],\n",
      "        [3.5828, 3.7398, 3.6109, 3.6966, 3.6931],\n",
      "        [3.5432, 3.8296, 3.7258, 3.8352, 3.8028],\n",
      "        [3.3067, 3.4460, 3.3840, 3.4625, 3.4100],\n",
      "        [3.2759, 3.4044, 3.3644, 3.4249, 3.3721],\n",
      "        [3.7285, 3.7085, 3.7126, 3.9811, 3.9443],\n",
      "        [3.5243, 3.5034, 3.5725, 3.6913, 3.6181],\n",
      "        [3.8214, 3.5996, 3.6362, 4.1858, 3.8978],\n",
      "        [3.5406, 3.5376, 3.6236, 3.7179, 3.6104],\n",
      "        [3.5945, 3.6004, 3.5802, 3.7357, 3.5735],\n",
      "        [3.4831, 3.5605, 3.4510, 3.6799, 3.5110],\n",
      "        [3.6512, 3.7487, 3.6044, 3.8307, 3.6809],\n",
      "        [3.4815, 3.6265, 3.4667, 3.7820, 3.4843],\n",
      "        [3.5258, 3.6280, 3.4302, 3.7356, 3.5631],\n",
      "        [3.5831, 3.6976, 3.6691, 3.8481, 3.7040],\n",
      "        [3.6324, 3.7569, 3.6323, 3.8582, 3.8295],\n",
      "        [3.3190, 3.4681, 3.4326, 3.5570, 3.4615],\n",
      "        [3.5780, 3.8038, 3.6885, 3.7883, 3.6165],\n",
      "        [3.3882, 3.5035, 3.4041, 3.5567, 3.4616],\n",
      "        [3.7320, 3.6326, 3.5711, 3.7990, 3.7174],\n",
      "        [3.6469, 3.6019, 3.5531, 3.9400, 3.7220],\n",
      "        [3.3789, 3.6004, 3.5434, 3.5992, 3.5212],\n",
      "        [3.4520, 3.7164, 3.5402, 3.6222, 3.4525]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4805, 3.4967, 3.4050, 3.6213, 3.6000],\n",
      "        [3.4973, 3.4399, 3.5187, 3.5813, 3.4702],\n",
      "        [3.4925, 3.5811, 3.5058, 3.6428, 3.5603],\n",
      "        [3.7851, 3.8110, 3.6782, 3.9121, 3.8708],\n",
      "        [3.4994, 3.4906, 3.4761, 3.7137, 3.4832],\n",
      "        [3.3515, 3.5238, 3.6512, 3.5588, 3.6165],\n",
      "        [3.5169, 3.5080, 3.5796, 3.6368, 3.5478],\n",
      "        [3.5127, 3.4263, 3.5095, 3.5526, 3.4508],\n",
      "        [3.4504, 3.4063, 3.5141, 3.6406, 3.5607],\n",
      "        [3.3413, 3.4700, 3.4005, 3.5057, 3.4523],\n",
      "        [3.5253, 3.6288, 3.4316, 3.7347, 3.5631],\n",
      "        [3.6869, 3.8634, 3.6813, 3.9402, 3.7890],\n",
      "        [3.5551, 3.4981, 3.5630, 3.7083, 3.5624],\n",
      "        [3.5269, 3.6243, 3.5634, 3.7039, 3.6246],\n",
      "        [3.4210, 3.5284, 3.4523, 3.6061, 3.5049],\n",
      "        [3.8206, 3.7049, 3.7826, 4.0331, 3.7866],\n",
      "        [3.3425, 3.4813, 3.4027, 3.5127, 3.4435],\n",
      "        [3.4170, 3.7850, 3.6765, 3.7113, 3.7482],\n",
      "        [3.4977, 3.4584, 3.5655, 3.6779, 3.6433],\n",
      "        [3.8459, 3.7813, 3.7143, 3.9689, 3.8348],\n",
      "        [3.6094, 3.4468, 3.7083, 3.7622, 3.6294],\n",
      "        [3.5423, 3.6754, 3.4882, 3.6556, 3.6000],\n",
      "        [3.5107, 3.6736, 3.5339, 3.6895, 3.6393],\n",
      "        [3.5369, 3.8617, 3.6442, 3.8550, 3.7756],\n",
      "        [3.5629, 3.7732, 3.5799, 3.8675, 3.6720],\n",
      "        [3.7053, 3.7321, 3.6854, 3.8450, 3.8828],\n",
      "        [3.4980, 3.6572, 3.6014, 3.7081, 3.5364],\n",
      "        [3.4444, 3.6204, 3.5453, 3.5551, 3.4828],\n",
      "        [3.7436, 3.7717, 3.7558, 3.8766, 3.8375],\n",
      "        [3.3855, 3.6032, 3.5436, 3.5932, 3.5272],\n",
      "        [3.3473, 3.5147, 3.4978, 3.5609, 3.4453],\n",
      "        [4.0344, 4.1652, 3.8551, 4.0341, 3.8546],\n",
      "        [3.7399, 3.7497, 3.8591, 3.8176, 3.5907],\n",
      "        [3.4856, 3.7831, 3.6659, 3.7735, 3.7578],\n",
      "        [3.6501, 3.7812, 3.5932, 3.9370, 3.7290],\n",
      "        [3.5168, 3.5725, 3.4705, 3.7359, 3.5611],\n",
      "        [3.3916, 3.3929, 3.4352, 3.5868, 3.4138],\n",
      "        [3.3615, 3.4870, 3.4062, 3.5291, 3.4679],\n",
      "        [3.6035, 3.6365, 3.6062, 3.7026, 3.4154],\n",
      "        [3.4904, 3.5144, 3.5417, 3.6673, 3.5466],\n",
      "        [3.5534, 3.4798, 3.5473, 3.6895, 3.5099],\n",
      "        [3.5480, 3.4672, 3.5403, 3.6811, 3.5001],\n",
      "        [3.5215, 3.5569, 3.5783, 3.5915, 3.3969],\n",
      "        [3.4983, 3.5967, 3.4265, 3.6960, 3.5433],\n",
      "        [3.4994, 3.4811, 3.4621, 3.7246, 3.4709],\n",
      "        [3.3685, 3.4323, 3.4224, 3.5513, 3.4401],\n",
      "        [3.4820, 3.5093, 3.5448, 3.5430, 3.3545],\n",
      "        [3.3862, 3.4139, 3.4496, 3.5736, 3.4248],\n",
      "        [3.5854, 3.3918, 3.6897, 3.7353, 3.5865],\n",
      "        [3.4259, 3.5470, 3.4225, 3.6021, 3.4971],\n",
      "        [3.8509, 3.9590, 3.6031, 3.8392, 3.6777],\n",
      "        [3.7186, 3.8110, 3.8091, 4.0322, 4.0401],\n",
      "        [3.4564, 3.5603, 3.5193, 3.7212, 3.5594],\n",
      "        [3.9516, 4.0882, 3.7351, 3.9290, 3.7142],\n",
      "        [3.4203, 3.4882, 3.5079, 3.6676, 3.5156],\n",
      "        [3.5045, 3.5596, 3.5633, 3.6681, 3.7315],\n",
      "        [3.4427, 3.4925, 3.4959, 3.5716, 3.5099],\n",
      "        [3.5422, 3.7260, 3.5754, 3.8497, 3.5820],\n",
      "        [3.3923, 3.5608, 3.4607, 3.5970, 3.5361],\n",
      "        [3.4096, 3.4770, 3.5202, 3.6319, 3.4349],\n",
      "        [3.6906, 3.8246, 3.5615, 3.7527, 3.6770],\n",
      "        [3.5150, 3.5294, 3.5926, 3.7145, 3.5909],\n",
      "        [3.3882, 3.4098, 3.4485, 3.5749, 3.4261],\n",
      "        [3.6088, 3.5902, 3.5638, 3.8564, 3.6648]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4024, 3.4147, 3.4534, 3.5850, 3.4324],\n",
      "        [3.6637, 3.7504, 3.7143, 3.9499, 3.6600],\n",
      "        [3.4653, 3.5161, 3.4901, 3.5852, 3.5263],\n",
      "        [3.4163, 3.5279, 3.4133, 3.5893, 3.4953],\n",
      "        [3.5829, 3.7270, 3.6312, 3.7455, 3.5186],\n",
      "        [3.6386, 3.6601, 3.6392, 3.7372, 3.4627],\n",
      "        [3.6606, 3.7877, 3.6282, 3.8322, 3.7007],\n",
      "        [3.5079, 3.5834, 3.4627, 3.6791, 3.5752],\n",
      "        [3.6083, 3.6307, 3.4826, 3.8106, 3.7151],\n",
      "        [3.6519, 3.7401, 3.7038, 3.8506, 3.6585],\n",
      "        [3.3957, 3.5872, 3.3781, 3.6247, 3.4171],\n",
      "        [3.7746, 3.7998, 3.8132, 3.8715, 3.6280],\n",
      "        [3.5148, 3.6066, 3.5577, 3.6917, 3.6072],\n",
      "        [3.4594, 3.4771, 3.5354, 3.6254, 3.5226],\n",
      "        [3.5434, 3.8311, 3.7284, 3.8332, 3.8026],\n",
      "        [3.5248, 3.5168, 3.6106, 3.7237, 3.6114],\n",
      "        [3.5828, 3.6082, 3.5808, 3.7312, 3.5860],\n",
      "        [3.5845, 3.4992, 3.7981, 3.7708, 3.6963],\n",
      "        [3.3590, 3.5560, 3.5194, 3.5685, 3.4758],\n",
      "        [3.3969, 3.4893, 3.5276, 3.6016, 3.4610],\n",
      "        [3.4923, 3.4715, 3.5583, 3.6397, 3.5302],\n",
      "        [3.5115, 3.5155, 3.6012, 3.7066, 3.5929],\n",
      "        [3.5611, 3.7245, 3.5986, 3.7064, 3.6628],\n",
      "        [3.5054, 3.5561, 3.5656, 3.6671, 3.7309],\n",
      "        [3.5286, 3.6765, 3.4974, 3.8388, 3.5186],\n",
      "        [4.0788, 4.2481, 3.8236, 4.0392, 3.8490],\n",
      "        [3.7130, 3.6919, 3.7051, 3.9364, 3.7031],\n",
      "        [3.3917, 3.4834, 3.5205, 3.6037, 3.4485],\n",
      "        [3.4981, 3.6884, 3.5764, 3.8475, 3.5729],\n",
      "        [3.7496, 3.7745, 3.7459, 3.9036, 3.9697],\n",
      "        [3.3694, 3.5912, 3.5383, 3.5924, 3.5092],\n",
      "        [3.7950, 3.7715, 3.7770, 3.9247, 3.9498],\n",
      "        [3.3194, 3.4574, 3.3908, 3.4804, 3.4209],\n",
      "        [3.7938, 3.8039, 3.6880, 3.9364, 3.8727],\n",
      "        [3.5147, 3.7076, 3.5517, 3.8163, 3.5621],\n",
      "        [3.6615, 3.5535, 3.5564, 3.9973, 3.7290],\n",
      "        [3.4054, 3.4304, 3.3501, 3.6215, 3.3884],\n",
      "        [3.3992, 3.5406, 3.4380, 3.6460, 3.4689],\n",
      "        [3.4907, 3.5150, 3.5428, 3.6662, 3.5463],\n",
      "        [3.3241, 3.4581, 3.3890, 3.4829, 3.4202],\n",
      "        [3.4167, 3.5238, 3.4013, 3.5823, 3.4737],\n",
      "        [3.6607, 3.8279, 3.6471, 3.8273, 3.7103],\n",
      "        [3.4206, 3.4888, 3.5090, 3.6664, 3.5154],\n",
      "        [3.4816, 3.5970, 3.5761, 3.7104, 3.5354],\n",
      "        [3.8081, 3.8158, 3.7030, 3.9532, 3.8944],\n",
      "        [3.5029, 3.6022, 3.4262, 3.6969, 3.5452],\n",
      "        [3.6309, 3.8056, 3.7282, 3.8418, 3.6654],\n",
      "        [3.4853, 3.4417, 3.5192, 3.6571, 3.6402],\n",
      "        [3.5109, 3.5318, 3.5856, 3.7084, 3.5893],\n",
      "        [3.8137, 3.7991, 3.7702, 4.0477, 3.7669],\n",
      "        [3.4470, 3.4936, 3.5396, 3.6585, 3.5353],\n",
      "        [3.4467, 3.4969, 3.5412, 3.6587, 3.5354],\n",
      "        [3.5212, 3.5828, 3.4867, 3.7408, 3.5697],\n",
      "        [3.3882, 3.3651, 3.4219, 3.5796, 3.3947],\n",
      "        [3.6537, 3.7871, 3.6220, 3.8258, 3.6928],\n",
      "        [3.7072, 3.6899, 3.7140, 3.9257, 3.7099],\n",
      "        [3.3809, 3.3672, 3.4158, 3.5728, 3.3955],\n",
      "        [3.6341, 3.7403, 3.6797, 3.9151, 3.6556],\n",
      "        [3.3585, 3.4770, 3.4851, 3.5585, 3.4405],\n",
      "        [3.7293, 3.8052, 3.6432, 3.8590, 3.8327],\n",
      "        [3.6612, 3.7160, 3.6779, 3.7933, 3.7733],\n",
      "        [3.6364, 3.7104, 3.5769, 3.8218, 3.6635],\n",
      "        [3.6481, 3.7723, 3.7188, 3.7700, 3.5714],\n",
      "        [3.7137, 3.7917, 3.6203, 3.8262, 3.8123]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5000, 3.4820, 3.4641, 3.7222, 3.4704],\n",
      "        [3.5542, 3.4808, 3.5492, 3.6871, 3.5095],\n",
      "        [3.4926, 3.4559, 3.5399, 3.6632, 3.6496],\n",
      "        [3.4255, 3.5425, 3.4148, 3.5966, 3.4919],\n",
      "        [3.6520, 3.7350, 3.6002, 3.7552, 3.6531],\n",
      "        [3.5768, 3.8240, 3.6649, 3.8099, 3.7813],\n",
      "        [3.4994, 3.7354, 3.5065, 3.8043, 3.6270],\n",
      "        [3.6828, 3.7503, 3.7057, 3.7597, 3.7069],\n",
      "        [3.4176, 3.6282, 3.4150, 3.6419, 3.4297],\n",
      "        [3.8239, 3.9627, 3.7128, 3.8252, 3.7214],\n",
      "        [3.6222, 3.5757, 3.5675, 3.8826, 3.6665],\n",
      "        [3.9296, 4.0559, 3.7679, 3.9256, 3.7682],\n",
      "        [3.6288, 3.7213, 3.7267, 3.8306, 3.6862],\n",
      "        [3.5666, 3.7696, 3.6169, 3.7854, 3.7624],\n",
      "        [3.3779, 3.5194, 3.5400, 3.5944, 3.4755],\n",
      "        [3.6670, 3.7428, 3.7204, 3.9462, 3.6589],\n",
      "        [3.6628, 3.7102, 3.7038, 3.8538, 3.6001],\n",
      "        [3.5430, 3.6764, 3.4901, 3.6532, 3.5994],\n",
      "        [3.4382, 3.5467, 3.4103, 3.6047, 3.4963],\n",
      "        [3.6427, 3.5836, 3.6430, 3.7920, 3.6006],\n",
      "        [3.4120, 3.5012, 3.4126, 3.6182, 3.4611],\n",
      "        [3.5038, 3.5308, 3.5629, 3.6890, 3.5792],\n",
      "        [3.4832, 3.5212, 3.6840, 3.5367, 3.7190],\n",
      "        [3.4911, 3.4829, 3.5545, 3.6450, 3.5241],\n",
      "        [3.4185, 3.5624, 3.6198, 3.6513, 3.6147],\n",
      "        [3.4767, 3.7604, 3.6692, 3.7586, 3.7225],\n",
      "        [3.6083, 3.8457, 3.6478, 3.8245, 3.7079],\n",
      "        [3.8162, 3.5994, 3.6411, 4.1896, 3.8909],\n",
      "        [3.6314, 3.8224, 3.5970, 3.6261, 3.6333],\n",
      "        [3.7224, 3.5660, 3.5984, 4.0506, 3.7936],\n",
      "        [3.5159, 3.6195, 3.4253, 3.7193, 3.5561],\n",
      "        [3.3362, 3.5987, 3.6550, 3.5653, 3.5791],\n",
      "        [3.6923, 3.7769, 3.6291, 3.8909, 3.7799],\n",
      "        [3.3626, 3.4693, 3.4851, 3.5589, 3.4408],\n",
      "        [3.4473, 3.4939, 3.5404, 3.6572, 3.5350],\n",
      "        [3.3930, 3.6239, 3.7061, 3.6631, 3.6125],\n",
      "        [3.7294, 3.5966, 3.5913, 3.7749, 3.7080],\n",
      "        [3.3916, 3.5537, 3.3995, 3.6293, 3.4597],\n",
      "        [3.3430, 3.4686, 3.3965, 3.5008, 3.4312],\n",
      "        [3.6268, 3.7168, 3.5557, 3.7483, 3.7667],\n",
      "        [3.6289, 3.5794, 3.6380, 3.7834, 3.6027],\n",
      "        [3.4786, 3.5308, 3.4677, 3.5876, 3.5224],\n",
      "        [3.5274, 3.7651, 3.5416, 3.8381, 3.6517],\n",
      "        [3.3866, 3.5195, 3.4107, 3.5547, 3.4736],\n",
      "        [3.5092, 3.6041, 3.4164, 3.7011, 3.5345],\n",
      "        [4.1161, 4.2615, 3.8684, 4.0754, 3.8462],\n",
      "        [3.6278, 3.7779, 3.7090, 3.8505, 3.7423],\n",
      "        [3.4460, 3.5769, 3.5353, 3.7451, 3.4890],\n",
      "        [3.2830, 3.4136, 3.3692, 3.4384, 3.3902],\n",
      "        [3.4182, 3.5771, 3.7300, 3.6371, 3.6914],\n",
      "        [3.6112, 3.6668, 3.6907, 3.7269, 3.5366],\n",
      "        [3.5358, 3.4804, 3.6635, 3.7680, 3.5763],\n",
      "        [3.5667, 3.8617, 3.6132, 3.8995, 3.7604],\n",
      "        [3.6304, 3.5123, 3.4726, 3.6371, 3.6459],\n",
      "        [3.5482, 3.5578, 3.6446, 3.7303, 3.6267],\n",
      "        [3.5803, 3.6139, 3.5875, 3.7224, 3.5980],\n",
      "        [3.5995, 3.5534, 3.5746, 3.6327, 3.4324],\n",
      "        [3.4929, 3.4835, 3.5532, 3.6516, 3.5256],\n",
      "        [3.6609, 3.7880, 3.6291, 3.8309, 3.7003],\n",
      "        [3.4285, 3.5382, 3.4119, 3.5952, 3.4987],\n",
      "        [3.8722, 3.8572, 3.7673, 4.0460, 3.8981],\n",
      "        [3.3709, 3.4420, 3.4670, 3.5590, 3.4330],\n",
      "        [3.3831, 3.7658, 3.6306, 3.6565, 3.7323],\n",
      "        [3.3808, 3.4213, 3.4538, 3.5596, 3.4153]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5780, 3.5393, 3.6740, 3.8803, 3.8238],\n",
      "        [3.4630, 3.6273, 3.5654, 3.6668, 3.5966],\n",
      "        [3.6164, 3.9013, 3.7497, 3.8646, 3.8627],\n",
      "        [3.5285, 3.7557, 3.6677, 3.8002, 3.7731],\n",
      "        [3.4682, 3.5739, 3.5394, 3.7395, 3.5639],\n",
      "        [3.6261, 3.4504, 3.4687, 3.6511, 3.5886],\n",
      "        [3.4037, 3.3999, 3.4407, 3.5891, 3.4212],\n",
      "        [3.4784, 3.5538, 3.5369, 3.6765, 3.6620],\n",
      "        [3.8220, 3.7879, 3.7944, 4.0159, 3.8311],\n",
      "        [3.6181, 3.7021, 3.5761, 3.8002, 3.7202],\n",
      "        [3.4889, 3.7094, 3.6210, 3.6181, 3.6543],\n",
      "        [3.4661, 3.6588, 3.6226, 3.6829, 3.5891],\n",
      "        [3.6622, 3.7684, 3.7134, 3.7843, 3.5496],\n",
      "        [3.4520, 3.6213, 3.7565, 3.6669, 3.7212],\n",
      "        [3.4199, 3.7005, 3.5576, 3.4898, 3.6187],\n",
      "        [3.4002, 3.3923, 3.4347, 3.5867, 3.4140],\n",
      "        [3.3628, 3.4625, 3.4794, 3.5576, 3.4364],\n",
      "        [3.6524, 3.7427, 3.7032, 3.9313, 3.6559],\n",
      "        [3.5216, 3.4920, 3.6051, 3.7213, 3.6599],\n",
      "        [3.6893, 3.6877, 3.8462, 3.7398, 3.5764],\n",
      "        [3.3594, 3.5474, 3.5163, 3.5625, 3.4624],\n",
      "        [3.6305, 3.5129, 3.4732, 3.6365, 3.6455],\n",
      "        [3.5132, 3.5242, 3.6337, 3.6965, 3.6062],\n",
      "        [3.5963, 3.5637, 3.6108, 3.6572, 3.5126],\n",
      "        [3.6496, 3.6531, 3.6542, 3.7315, 3.4981],\n",
      "        [3.3643, 3.4968, 3.4070, 3.5308, 3.4530],\n",
      "        [3.3987, 3.3940, 3.4379, 3.5878, 3.4181],\n",
      "        [3.5017, 3.4750, 3.4555, 3.7249, 3.4563],\n",
      "        [3.4829, 3.7328, 3.5283, 3.5128, 3.6317],\n",
      "        [3.5640, 3.7748, 3.5825, 3.8644, 3.6708],\n",
      "        [3.8997, 3.9475, 3.8361, 4.1863, 3.9347],\n",
      "        [3.6437, 3.8604, 3.6372, 3.8327, 3.6972],\n",
      "        [3.6168, 3.9430, 3.6880, 3.9490, 3.8183],\n",
      "        [3.6315, 3.7770, 3.6800, 3.9246, 3.6776],\n",
      "        [3.5877, 3.5909, 3.5638, 3.8131, 3.6185],\n",
      "        [3.6733, 3.7190, 3.6822, 3.8821, 3.8027],\n",
      "        [3.4743, 3.5594, 3.4492, 3.6416, 3.5414],\n",
      "        [3.3827, 3.4870, 3.4925, 3.5743, 3.4755],\n",
      "        [3.4182, 3.5344, 3.4083, 3.5850, 3.4848],\n",
      "        [3.5336, 3.6386, 3.5741, 3.7173, 3.6341],\n",
      "        [3.5787, 3.8069, 3.6926, 3.7843, 3.6150],\n",
      "        [3.4934, 3.4994, 3.5438, 3.6526, 3.5413],\n",
      "        [3.6484, 3.7804, 3.5949, 3.9323, 3.7243],\n",
      "        [3.6303, 3.7137, 3.7109, 3.7826, 3.6670],\n",
      "        [3.3238, 3.3541, 3.4162, 3.4838, 3.3484],\n",
      "        [3.5151, 3.6075, 3.5593, 3.6897, 3.6063],\n",
      "        [3.6044, 3.6381, 3.6086, 3.6997, 3.4144],\n",
      "        [3.5914, 3.6664, 3.7506, 3.7865, 3.6927],\n",
      "        [3.6585, 3.8097, 3.5768, 3.7556, 3.6927],\n",
      "        [3.4743, 3.6014, 3.5185, 3.7330, 3.6025],\n",
      "        [3.7480, 3.7379, 3.7501, 3.9957, 3.9544],\n",
      "        [3.5833, 3.6092, 3.5821, 3.7292, 3.5852],\n",
      "        [3.5886, 3.5515, 3.5729, 3.6161, 3.4181],\n",
      "        [3.5802, 3.7781, 3.6049, 3.8766, 3.6768],\n",
      "        [3.4770, 3.5012, 3.4076, 3.6190, 3.6001],\n",
      "        [3.6129, 3.7705, 3.6495, 3.9000, 3.6815],\n",
      "        [3.6330, 3.6272, 3.6401, 3.7186, 3.5001],\n",
      "        [3.4671, 3.6290, 3.5722, 3.6690, 3.6127],\n",
      "        [3.3989, 3.5565, 3.4050, 3.6323, 3.4640],\n",
      "        [3.3308, 3.4655, 3.4005, 3.4833, 3.4283],\n",
      "        [3.5115, 3.6752, 3.5364, 3.6865, 3.6380],\n",
      "        [3.6911, 3.7417, 3.7508, 3.9661, 3.6639],\n",
      "        [3.3747, 3.5019, 3.4114, 3.5322, 3.4675],\n",
      "        [3.4771, 3.5854, 3.5499, 3.7660, 3.5452]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6644, 3.6944, 3.7040, 3.8535, 3.5714],\n",
      "        [3.4999, 3.4837, 3.4652, 3.7208, 3.4691],\n",
      "        [3.6492, 3.6814, 3.6208, 3.8574, 3.7940],\n",
      "        [3.6299, 3.7820, 3.6824, 3.9277, 3.6849],\n",
      "        [3.2892, 3.4808, 3.6041, 3.5001, 3.5409],\n",
      "        [3.8885, 3.7370, 3.8191, 4.0898, 3.8396],\n",
      "        [3.4260, 3.4859, 3.5182, 3.6537, 3.5152],\n",
      "        [3.4897, 3.5897, 3.5806, 3.7107, 3.5194],\n",
      "        [3.8491, 3.6585, 3.7541, 4.3046, 4.0679],\n",
      "        [3.4407, 3.5492, 3.4202, 3.5984, 3.5108],\n",
      "        [3.3762, 3.5414, 3.5156, 3.5761, 3.4889],\n",
      "        [3.5172, 3.6803, 3.5328, 3.6945, 3.6306],\n",
      "        [3.6227, 3.8824, 3.7472, 3.8446, 3.7985],\n",
      "        [3.3819, 3.4496, 3.4352, 3.5627, 3.4437],\n",
      "        [3.4515, 3.7264, 3.5439, 3.6141, 3.4600],\n",
      "        [3.4743, 3.6026, 3.5188, 3.7322, 3.6017],\n",
      "        [3.4940, 3.5326, 3.6417, 3.5942, 3.7016],\n",
      "        [3.3623, 3.4896, 3.4095, 3.5252, 3.4662],\n",
      "        [3.5838, 3.7237, 3.5732, 3.7921, 3.6270],\n",
      "        [3.3530, 3.5519, 3.5160, 3.5586, 3.4642],\n",
      "        [3.4411, 3.4981, 3.5337, 3.6568, 3.5297],\n",
      "        [3.3796, 3.4528, 3.4762, 3.5701, 3.4484],\n",
      "        [3.4807, 3.6404, 3.5724, 3.6854, 3.5799],\n",
      "        [3.9945, 4.1238, 3.8356, 3.9833, 3.8326],\n",
      "        [3.6106, 3.6460, 3.6690, 3.7600, 3.6452],\n",
      "        [3.6778, 3.8194, 3.5758, 3.7589, 3.6859],\n",
      "        [3.4285, 3.5399, 3.4130, 3.5937, 3.4975],\n",
      "        [3.7305, 3.4845, 3.6219, 3.9997, 3.8683],\n",
      "        [3.4261, 3.5786, 3.6231, 3.6495, 3.6195],\n",
      "        [3.4346, 3.4552, 3.5641, 3.6324, 3.5023],\n",
      "        [3.5226, 3.6814, 3.5637, 3.6619, 3.6416],\n",
      "        [3.5621, 3.4980, 3.5690, 3.6940, 3.5525],\n",
      "        [3.3750, 3.4426, 3.4695, 3.5600, 3.4333],\n",
      "        [3.4602, 3.4336, 3.5269, 3.6135, 3.4907],\n",
      "        [3.3943, 3.4281, 3.4607, 3.5774, 3.4327],\n",
      "        [3.6620, 3.5558, 3.5583, 3.9947, 3.7275],\n",
      "        [3.6316, 3.7782, 3.6803, 3.9238, 3.6768],\n",
      "        [3.4822, 3.4399, 3.5185, 3.6483, 3.6360],\n",
      "        [3.4791, 3.4434, 3.5090, 3.6404, 3.6332],\n",
      "        [3.7949, 3.9104, 3.5966, 3.8026, 3.6809],\n",
      "        [3.5302, 3.8335, 3.6103, 3.8314, 3.7249],\n",
      "        [3.6646, 3.8250, 3.6232, 3.6609, 3.6004],\n",
      "        [3.7786, 3.7926, 3.6837, 3.9229, 3.8646],\n",
      "        [3.5612, 3.5637, 3.6477, 3.7409, 3.6361],\n",
      "        [3.7346, 3.7763, 3.7316, 3.8815, 3.9218],\n",
      "        [3.4952, 3.5127, 3.5424, 3.6538, 3.5420],\n",
      "        [3.4738, 3.6389, 3.5784, 3.6824, 3.5826],\n",
      "        [3.5376, 3.5292, 3.5627, 3.6776, 3.5950],\n",
      "        [3.3921, 3.3955, 3.4380, 3.5830, 3.4119],\n",
      "        [3.5013, 3.5011, 3.5504, 3.6533, 3.5432],\n",
      "        [3.5551, 3.6060, 3.5615, 3.7304, 3.6651],\n",
      "        [3.4843, 3.6166, 3.7071, 3.6389, 3.5797],\n",
      "        [3.4434, 3.4950, 3.4992, 3.5678, 3.5082],\n",
      "        [3.6944, 3.9440, 3.7183, 3.8372, 3.9952],\n",
      "        [3.8436, 3.5950, 3.6408, 4.2165, 3.9137],\n",
      "        [3.6611, 3.7109, 3.7064, 3.8522, 3.5984],\n",
      "        [3.4689, 3.5772, 3.4259, 3.6476, 3.5186],\n",
      "        [3.5635, 3.8192, 3.7572, 3.8537, 3.7759],\n",
      "        [3.7680, 3.7936, 3.7607, 3.9152, 3.9769],\n",
      "        [3.7022, 3.8416, 3.5786, 3.7707, 3.6892],\n",
      "        [3.5173, 3.6113, 3.5688, 3.6650, 3.5862],\n",
      "        [3.3193, 3.4715, 3.4371, 3.5521, 3.4595],\n",
      "        [3.5833, 3.7293, 3.6329, 3.7428, 3.5168],\n",
      "        [3.4672, 3.5710, 3.4209, 3.6525, 3.5194]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3738, 3.5179, 3.5376, 3.5859, 3.4678],\n",
      "        [3.6454, 3.7111, 3.6957, 3.7519, 3.6746],\n",
      "        [3.4266, 3.5504, 3.4280, 3.5972, 3.4945],\n",
      "        [3.4959, 3.4892, 3.5622, 3.6476, 3.5291],\n",
      "        [3.6482, 3.7812, 3.5925, 3.9221, 3.7146],\n",
      "        [3.4964, 3.8062, 3.5609, 3.8313, 3.6786],\n",
      "        [3.4821, 3.5528, 3.5466, 3.6666, 3.6804],\n",
      "        [3.6506, 3.7848, 3.5988, 3.9317, 3.7261],\n",
      "        [3.5315, 3.5527, 3.5715, 3.5845, 3.4002],\n",
      "        [3.3627, 3.4645, 3.4820, 3.5557, 3.4348],\n",
      "        [3.8222, 3.6045, 3.6431, 4.1806, 3.8954],\n",
      "        [3.6692, 3.5404, 3.5641, 4.0249, 3.7386],\n",
      "        [3.4924, 3.4547, 3.5448, 3.6689, 3.6403],\n",
      "        [3.5091, 3.6066, 3.4196, 3.6985, 3.5323],\n",
      "        [3.5465, 3.6781, 3.4749, 3.6609, 3.5934],\n",
      "        [3.5063, 3.5440, 3.6418, 3.5814, 3.7173],\n",
      "        [3.4997, 3.4941, 3.4814, 3.7088, 3.4805],\n",
      "        [3.4977, 3.4071, 3.4877, 3.5300, 3.4243],\n",
      "        [3.5506, 3.5522, 3.6432, 3.7237, 3.6165],\n",
      "        [3.4646, 3.4276, 3.4846, 3.6090, 3.6173],\n",
      "        [4.1321, 4.2775, 3.9080, 4.1106, 3.8562],\n",
      "        [3.4929, 3.4863, 3.5564, 3.6490, 3.5234],\n",
      "        [3.8912, 3.9314, 3.8425, 4.1640, 3.8886],\n",
      "        [3.4636, 3.6321, 3.5676, 3.5707, 3.4953],\n",
      "        [3.4463, 3.7796, 3.6084, 3.7304, 3.7346],\n",
      "        [3.6624, 3.6791, 3.7416, 3.7757, 3.5526],\n",
      "        [3.4091, 3.4044, 3.4473, 3.5918, 3.4218],\n",
      "        [3.3623, 3.4327, 3.4638, 3.5524, 3.4217],\n",
      "        [3.4905, 3.5712, 3.6269, 3.7053, 3.6340],\n",
      "        [3.3873, 3.6952, 3.5444, 3.4847, 3.6304],\n",
      "        [3.5171, 3.6812, 3.5350, 3.6934, 3.6297],\n",
      "        [3.5491, 3.5844, 3.6298, 3.7368, 3.7039],\n",
      "        [3.6797, 3.7782, 3.7338, 3.7993, 3.5590],\n",
      "        [3.7833, 3.7942, 3.7630, 3.9280, 3.9875],\n",
      "        [3.5399, 3.7335, 3.5962, 3.8452, 3.5722],\n",
      "        [3.7778, 3.7062, 3.6649, 3.8571, 3.7777],\n",
      "        [3.4031, 3.4295, 3.3552, 3.6162, 3.3407],\n",
      "        [3.4966, 3.5965, 3.4309, 3.6899, 3.5400],\n",
      "        [3.4967, 3.4674, 3.5743, 3.5789, 3.5913],\n",
      "        [3.4889, 3.5569, 3.6545, 3.7726, 3.7188],\n",
      "        [3.7999, 3.8149, 3.7241, 4.0430, 3.8201],\n",
      "        [3.7615, 3.7343, 3.7457, 3.9776, 3.7477],\n",
      "        [3.3316, 3.4823, 3.4215, 3.5421, 3.4339],\n",
      "        [3.2599, 3.4151, 3.4374, 3.4799, 3.4178],\n",
      "        [3.3149, 3.3849, 3.3930, 3.4712, 3.3862],\n",
      "        [3.5970, 3.5578, 3.6134, 3.6497, 3.5269],\n",
      "        [3.6496, 3.6552, 3.6569, 3.7296, 3.4965],\n",
      "        [3.4121, 3.5135, 3.4181, 3.6277, 3.4517],\n",
      "        [3.9000, 3.9500, 3.8391, 4.1845, 3.9330],\n",
      "        [3.6215, 3.6476, 3.6989, 3.7457, 3.5240],\n",
      "        [3.7237, 3.7359, 3.8475, 3.7809, 3.5586],\n",
      "        [3.4907, 3.5179, 3.5468, 3.6623, 3.5436],\n",
      "        [3.4039, 3.4209, 3.4580, 3.5826, 3.4318],\n",
      "        [3.8259, 3.7513, 3.7493, 4.0266, 3.8248],\n",
      "        [3.6237, 3.4450, 3.4652, 3.6538, 3.5687],\n",
      "        [3.7686, 3.6342, 3.7382, 3.9543, 3.7167],\n",
      "        [3.4467, 3.5234, 3.5360, 3.6889, 3.5270],\n",
      "        [3.6130, 3.7726, 3.6522, 3.8981, 3.6799],\n",
      "        [3.3932, 3.5642, 3.4658, 3.5921, 3.5334],\n",
      "        [3.1973, 3.3641, 3.4153, 3.4269, 3.3831],\n",
      "        [3.7662, 3.6509, 3.7356, 3.9290, 3.7093],\n",
      "        [3.5734, 3.7455, 3.6149, 3.7039, 3.6700],\n",
      "        [3.4809, 3.7443, 3.5844, 3.6677, 3.4767],\n",
      "        [3.6443, 3.8687, 3.7719, 3.8462, 3.7894]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4992, 3.7881, 3.6820, 3.7769, 3.7618],\n",
      "        [3.3572, 3.3710, 3.4314, 3.5521, 3.4208],\n",
      "        [3.4423, 3.5216, 3.4550, 3.5658, 3.4705],\n",
      "        [3.5607, 3.4876, 3.6905, 3.7779, 3.5984],\n",
      "        [3.5798, 3.6658, 3.7461, 3.7782, 3.7012],\n",
      "        [3.5521, 3.6948, 3.5331, 3.7686, 3.5970],\n",
      "        [3.8162, 3.8229, 3.7050, 3.9338, 3.8959],\n",
      "        [3.4930, 3.7743, 3.6389, 3.7828, 3.7401],\n",
      "        [3.5605, 3.5475, 3.6704, 3.8366, 3.7893],\n",
      "        [3.6916, 3.7062, 3.6737, 3.8190, 3.8051],\n",
      "        [3.4508, 3.4941, 3.5612, 3.6497, 3.5278],\n",
      "        [3.5009, 3.6951, 3.5909, 3.6315, 3.6410],\n",
      "        [3.4863, 3.5011, 3.5368, 3.6458, 3.5338],\n",
      "        [3.3600, 3.5873, 3.6406, 3.5837, 3.5533],\n",
      "        [3.6513, 3.7540, 3.6129, 3.8245, 3.6770],\n",
      "        [3.3063, 3.4453, 3.3936, 3.4539, 3.4037],\n",
      "        [3.4247, 3.3839, 3.4932, 3.5992, 3.5361],\n",
      "        [3.3729, 3.4660, 3.4842, 3.5631, 3.4492],\n",
      "        [3.4888, 3.4961, 3.5514, 3.6538, 3.5383],\n",
      "        [3.3746, 3.4441, 3.4736, 3.5578, 3.4315],\n",
      "        [3.4844, 3.4980, 3.5670, 3.6765, 3.6176],\n",
      "        [3.7454, 3.7768, 3.7631, 3.8704, 3.8335],\n",
      "        [3.5072, 3.5837, 3.4908, 3.7076, 3.6577],\n",
      "        [3.7504, 3.8200, 3.7331, 3.8910, 3.8358],\n",
      "        [3.6013, 3.7302, 3.6479, 3.7480, 3.5251],\n",
      "        [3.5184, 3.5206, 3.6001, 3.6759, 3.5937],\n",
      "        [3.4669, 3.6317, 3.5768, 3.6660, 3.6100],\n",
      "        [3.4927, 3.4870, 3.5583, 3.6479, 3.5225],\n",
      "        [3.3856, 3.4025, 3.4446, 3.5723, 3.4108],\n",
      "        [3.2858, 3.4259, 3.3753, 3.4347, 3.3833],\n",
      "        [3.4100, 3.4811, 3.5276, 3.6258, 3.4313],\n",
      "        [3.7939, 3.7543, 3.7684, 3.9659, 3.6461],\n",
      "        [3.5551, 3.5625, 3.6568, 3.7307, 3.6203],\n",
      "        [3.7162, 3.7042, 3.7039, 3.8438, 3.8659],\n",
      "        [3.3993, 3.5442, 3.4441, 3.6410, 3.4654],\n",
      "        [3.4532, 3.5609, 3.4168, 3.6184, 3.5024],\n",
      "        [3.3279, 3.3770, 3.4369, 3.5111, 3.3537],\n",
      "        [3.4945, 3.4726, 3.5473, 3.5975, 3.5011],\n",
      "        [3.4603, 3.5625, 3.5302, 3.7054, 3.5818],\n",
      "        [3.6238, 3.8173, 3.7824, 3.8454, 3.6474],\n",
      "        [3.6389, 3.6251, 3.7157, 3.7222, 3.4389],\n",
      "        [3.5187, 3.5219, 3.6313, 3.6868, 3.6009],\n",
      "        [3.5037, 3.5402, 3.5670, 3.6833, 3.5713],\n",
      "        [3.5320, 3.5710, 3.6883, 3.7462, 3.6299],\n",
      "        [3.4919, 3.5973, 3.4239, 3.6907, 3.5323],\n",
      "        [3.4394, 3.4835, 3.5342, 3.6468, 3.5378],\n",
      "        [3.6049, 3.6405, 3.4864, 3.7249, 3.6876],\n",
      "        [3.3685, 3.4710, 3.5966, 3.5741, 3.5514],\n",
      "        [3.9271, 3.7081, 3.8507, 4.3708, 4.1516],\n",
      "        [3.3608, 3.5723, 3.5301, 3.5672, 3.4808],\n",
      "        [3.7957, 3.8086, 3.6942, 3.9316, 3.8692],\n",
      "        [3.5245, 3.7778, 3.6676, 3.8119, 3.7725],\n",
      "        [3.6519, 3.5978, 3.5985, 3.6531, 3.4913],\n",
      "        [3.5258, 3.4489, 3.5342, 3.5670, 3.4672],\n",
      "        [3.3960, 3.5908, 3.3843, 3.6199, 3.4140],\n",
      "        [3.3626, 3.4870, 3.4054, 3.5188, 3.4389],\n",
      "        [3.3914, 3.5570, 3.4049, 3.6257, 3.4567],\n",
      "        [3.4462, 3.6959, 3.5878, 3.6955, 3.7175],\n",
      "        [3.3562, 3.4682, 3.4804, 3.5484, 3.4323],\n",
      "        [3.5022, 3.6074, 3.4296, 3.7012, 3.5395],\n",
      "        [3.5110, 3.4908, 3.5761, 3.6111, 3.5911],\n",
      "        [3.6585, 3.8123, 3.5843, 3.7462, 3.6949],\n",
      "        [3.6324, 3.7631, 3.6409, 3.8510, 3.8250],\n",
      "        [3.4057, 3.6436, 3.5677, 3.6601, 3.6924]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4279, 3.4954, 3.5263, 3.6614, 3.5132],\n",
      "        [3.2989, 3.4375, 3.3918, 3.4447, 3.4008],\n",
      "        [3.6060, 3.7467, 3.5668, 3.8826, 3.6695],\n",
      "        [3.5075, 3.4768, 3.5813, 3.6670, 3.6155],\n",
      "        [3.4522, 3.4903, 3.5543, 3.6519, 3.5290],\n",
      "        [3.5029, 3.5111, 3.5607, 3.6548, 3.5483],\n",
      "        [3.3552, 3.5892, 3.6317, 3.5816, 3.5934],\n",
      "        [3.6382, 3.6468, 3.6526, 3.7204, 3.4841],\n",
      "        [3.8797, 4.0237, 3.9543, 4.1372, 4.1460],\n",
      "        [3.3875, 3.3697, 3.4301, 3.5734, 3.3901],\n",
      "        [3.5073, 3.6050, 3.4274, 3.6957, 3.5315],\n",
      "        [3.4625, 3.6313, 3.5726, 3.6625, 3.5927],\n",
      "        [3.4779, 3.6324, 3.5090, 3.6938, 3.6099],\n",
      "        [3.7350, 3.7859, 3.7378, 3.8704, 3.9145],\n",
      "        [3.3603, 3.4528, 3.4802, 3.5516, 3.4268],\n",
      "        [3.5066, 3.5542, 3.5793, 3.6866, 3.5789],\n",
      "        [3.5392, 3.7355, 3.6007, 3.8428, 3.5699],\n",
      "        [3.3847, 3.5306, 3.5519, 3.6037, 3.4685],\n",
      "        [3.5168, 3.5415, 3.5688, 3.5665, 3.3840],\n",
      "        [3.6437, 3.7799, 3.5970, 3.9200, 3.7142],\n",
      "        [3.4516, 3.5102, 3.5100, 3.5798, 3.5097],\n",
      "        [3.5684, 3.5484, 3.5724, 3.5896, 3.4005],\n",
      "        [3.6500, 3.7867, 3.6035, 3.9291, 3.7239],\n",
      "        [3.6650, 3.8011, 3.7059, 3.8516, 3.6882],\n",
      "        [3.4725, 3.5051, 3.5612, 3.6741, 3.6198],\n",
      "        [3.4423, 3.5464, 3.4138, 3.6084, 3.4809],\n",
      "        [3.4173, 3.5129, 3.5598, 3.6274, 3.4479],\n",
      "        [3.5116, 3.5254, 3.5564, 3.6500, 3.6122],\n",
      "        [3.4982, 3.4986, 3.5525, 3.6502, 3.5390],\n",
      "        [3.4819, 3.5738, 3.5376, 3.6025, 3.5557],\n",
      "        [3.6605, 3.7928, 3.6369, 3.8266, 3.6959],\n",
      "        [3.4404, 3.5706, 3.6267, 3.7075, 3.6653],\n",
      "        [3.5991, 3.5568, 3.5829, 3.6261, 3.4277],\n",
      "        [3.4842, 3.7331, 3.6611, 3.6050, 3.6646],\n",
      "        [3.6077, 3.6595, 3.5587, 3.7298, 3.5880],\n",
      "        [3.4861, 3.4514, 3.5770, 3.5418, 3.5940],\n",
      "        [3.6101, 3.6488, 3.6758, 3.7565, 3.6421],\n",
      "        [3.5508, 3.6815, 3.4759, 3.6578, 3.5859],\n",
      "        [3.4803, 3.5025, 3.4144, 3.6141, 3.5948],\n",
      "        [3.6444, 3.7548, 3.7124, 3.8398, 3.6812],\n",
      "        [3.5984, 3.6878, 3.5599, 3.7663, 3.7068],\n",
      "        [3.4817, 3.6326, 3.4782, 3.7737, 3.4797],\n",
      "        [3.3913, 3.3981, 3.4446, 3.5795, 3.4089],\n",
      "        [3.8213, 3.6370, 3.7702, 3.9833, 3.7662],\n",
      "        [3.7537, 3.7392, 3.7485, 3.9929, 3.9503],\n",
      "        [3.3392, 3.3955, 3.4118, 3.5013, 3.4016],\n",
      "        [3.4417, 3.6023, 3.4713, 3.7231, 3.4793],\n",
      "        [3.3933, 3.3908, 3.4391, 3.5880, 3.4117],\n",
      "        [3.3861, 3.5239, 3.4185, 3.5497, 3.4695],\n",
      "        [3.6541, 3.7551, 3.7290, 3.8246, 3.7211],\n",
      "        [3.4179, 3.7912, 3.6864, 3.7037, 3.7430],\n",
      "        [3.6617, 3.7452, 3.6958, 3.7235, 3.6879],\n",
      "        [3.4970, 3.5397, 3.6381, 3.6041, 3.6956],\n",
      "        [3.6068, 3.5813, 3.6097, 3.7324, 3.5727],\n",
      "        [3.3651, 3.5008, 3.4133, 3.5216, 3.4474],\n",
      "        [3.6394, 3.8144, 3.7247, 3.8414, 3.7982],\n",
      "        [3.6709, 3.7942, 3.5897, 3.7820, 3.7262],\n",
      "        [3.4661, 3.5614, 3.5346, 3.6913, 3.6119],\n",
      "        [3.6802, 3.7019, 3.6779, 3.8627, 3.8209],\n",
      "        [3.6561, 3.7818, 3.6727, 3.7002, 3.6886],\n",
      "        [3.5048, 3.5591, 3.6282, 3.6229, 3.7008],\n",
      "        [3.7593, 3.8811, 3.5903, 3.7832, 3.6756],\n",
      "        [3.5025, 3.6068, 3.4348, 3.6906, 3.5407],\n",
      "        [3.5161, 3.5491, 3.6621, 3.7171, 3.6120]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5823, 3.7331, 3.6419, 3.7377, 3.5124],\n",
      "        [3.4940, 3.5163, 3.5512, 3.6487, 3.5377],\n",
      "        [3.5314, 3.5731, 3.6930, 3.7432, 3.6276],\n",
      "        [3.5053, 3.5978, 3.5888, 3.6624, 3.4612],\n",
      "        [3.5021, 3.6007, 3.4238, 3.6850, 3.5245],\n",
      "        [3.6513, 3.5999, 3.6032, 3.6504, 3.4891],\n",
      "        [4.1537, 4.3019, 3.9149, 4.0961, 3.8694],\n",
      "        [3.6151, 3.8589, 3.6657, 3.8063, 3.7095],\n",
      "        [3.5029, 3.5418, 3.4974, 3.7157, 3.5320],\n",
      "        [3.7112, 3.7698, 3.7554, 3.8552, 3.9152],\n",
      "        [3.7649, 3.8305, 3.6901, 3.8963, 3.8406],\n",
      "        [3.5003, 3.6973, 3.5958, 3.6287, 3.6385],\n",
      "        [3.4223, 3.7212, 3.5812, 3.5069, 3.6478],\n",
      "        [3.7473, 3.9240, 3.7247, 3.9622, 3.8775],\n",
      "        [3.4385, 3.4752, 3.5502, 3.6443, 3.5996],\n",
      "        [3.7140, 3.7984, 3.6312, 3.8185, 3.8060],\n",
      "        [3.3521, 3.5555, 3.5248, 3.5535, 3.4601],\n",
      "        [3.4643, 3.5410, 3.4624, 3.5882, 3.4888],\n",
      "        [3.7227, 3.7388, 3.8542, 3.7766, 3.5548],\n",
      "        [3.5114, 3.6594, 3.4928, 3.8079, 3.4989],\n",
      "        [3.4678, 3.4961, 3.5699, 3.6679, 3.6190],\n",
      "        [3.7800, 3.6597, 3.7673, 3.9802, 3.7361],\n",
      "        [3.4892, 3.5882, 3.4220, 3.6677, 3.5117],\n",
      "        [3.5270, 3.7708, 3.5514, 3.8317, 3.6462],\n",
      "        [3.4250, 3.5823, 3.6321, 3.6443, 3.6151],\n",
      "        [4.0647, 4.2848, 3.8356, 4.0572, 3.8149],\n",
      "        [3.4020, 3.4356, 3.4872, 3.5839, 3.4141],\n",
      "        [3.3599, 3.4537, 3.4823, 3.5501, 3.4256],\n",
      "        [3.4518, 3.4088, 3.5663, 3.4747, 3.5842],\n",
      "        [3.5386, 3.7251, 3.5952, 3.6889, 3.6505],\n",
      "        [3.6601, 3.7937, 3.6390, 3.8252, 3.6946],\n",
      "        [3.4625, 3.4815, 3.4874, 3.5872, 3.5638],\n",
      "        [3.6310, 3.6710, 3.7317, 3.7450, 3.5707],\n",
      "        [3.2484, 3.4007, 3.4475, 3.4602, 3.4274],\n",
      "        [3.3691, 3.4619, 3.4895, 3.5558, 3.4338],\n",
      "        [3.4885, 3.5480, 3.6837, 3.7736, 3.6125],\n",
      "        [3.3019, 3.4559, 3.4414, 3.5370, 3.4413],\n",
      "        [3.4806, 3.6032, 3.5867, 3.7029, 3.5291],\n",
      "        [3.4275, 3.4963, 3.5284, 3.6599, 3.5119],\n",
      "        [3.5490, 3.7497, 3.5490, 3.5401, 3.5603],\n",
      "        [3.5235, 3.8554, 3.6388, 3.8425, 3.7432],\n",
      "        [3.6271, 3.7842, 3.7194, 3.8440, 3.7366],\n",
      "        [3.4986, 3.4967, 3.4880, 3.7048, 3.4773],\n",
      "        [3.5562, 3.3965, 3.6768, 3.7396, 3.6407],\n",
      "        [3.7376, 3.8285, 3.8313, 4.0544, 4.0436],\n",
      "        [3.5707, 3.6716, 3.5679, 3.7628, 3.6610],\n",
      "        [3.3931, 3.4316, 3.4694, 3.5724, 3.4285],\n",
      "        [3.5373, 3.8686, 3.6564, 3.8460, 3.7692],\n",
      "        [3.5953, 3.6573, 3.5711, 3.7152, 3.5853],\n",
      "        [3.4813, 3.5557, 3.5534, 3.6627, 3.6770],\n",
      "        [3.3926, 3.3867, 3.4402, 3.5804, 3.3971],\n",
      "        [3.3229, 3.4715, 3.4095, 3.4811, 3.4232],\n",
      "        [3.6869, 3.8700, 3.6934, 3.9324, 3.7826],\n",
      "        [3.7347, 3.8205, 3.6614, 3.8591, 3.8334],\n",
      "        [3.4826, 3.5882, 3.4348, 3.6683, 3.5264],\n",
      "        [3.4985, 3.6041, 3.4241, 3.6875, 3.5322],\n",
      "        [3.6111, 3.6444, 3.4958, 3.7277, 3.6970],\n",
      "        [3.6448, 3.6512, 3.6434, 3.8036, 3.8111],\n",
      "        [3.5005, 3.4669, 3.5860, 3.6742, 3.6373],\n",
      "        [3.5112, 3.5532, 3.6675, 3.7989, 3.7518],\n",
      "        [3.3510, 3.5401, 3.5161, 3.5514, 3.4515],\n",
      "        [3.4512, 3.5111, 3.5121, 3.5783, 3.5085],\n",
      "        [3.5897, 3.6380, 3.6742, 3.7582, 3.6034],\n",
      "        [3.6176, 3.7073, 3.5854, 3.7943, 3.7150]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6305, 3.8132, 3.7411, 3.8323, 3.6578],\n",
      "        [3.7833, 3.9324, 3.7227, 3.7741, 3.7366],\n",
      "        [3.3950, 3.3995, 3.4507, 3.5795, 3.4141],\n",
      "        [3.5538, 3.6105, 3.5730, 3.7235, 3.6598],\n",
      "        [3.4008, 3.5285, 3.4197, 3.5603, 3.4720],\n",
      "        [3.6411, 3.7385, 3.5779, 3.7639, 3.7501],\n",
      "        [3.4347, 3.4715, 3.5725, 3.6305, 3.5093],\n",
      "        [3.3975, 3.5618, 3.4160, 3.6249, 3.4582],\n",
      "        [3.6182, 3.6026, 3.6447, 3.8461, 3.5375],\n",
      "        [3.5434, 3.7244, 3.7067, 3.8267, 3.6477],\n",
      "        [3.4781, 3.4988, 3.5128, 3.6085, 3.5835],\n",
      "        [3.6237, 3.7164, 3.6010, 3.6527, 3.6166],\n",
      "        [3.4659, 3.6346, 3.5836, 3.6615, 3.6062],\n",
      "        [3.4252, 3.4974, 3.5097, 3.5578, 3.4797],\n",
      "        [4.0397, 4.2088, 3.8370, 4.0187, 3.7846],\n",
      "        [3.4367, 3.5525, 3.4219, 3.5965, 3.4898],\n",
      "        [3.3779, 3.4570, 3.4867, 3.5633, 3.4430],\n",
      "        [3.6754, 3.8566, 3.8134, 3.8702, 3.6055],\n",
      "        [3.3407, 3.4767, 3.4142, 3.4951, 3.4454],\n",
      "        [3.7514, 3.8016, 3.7772, 3.8846, 3.9531],\n",
      "        [3.4296, 3.6193, 3.4346, 3.6683, 3.4364],\n",
      "        [3.4934, 3.5599, 3.5675, 3.6605, 3.7000],\n",
      "        [3.6125, 3.7150, 3.7123, 3.7831, 3.6646],\n",
      "        [3.5739, 3.8106, 3.6578, 3.7917, 3.7681],\n",
      "        [3.6135, 3.5161, 3.7946, 3.7877, 3.7069],\n",
      "        [3.4951, 3.5997, 3.4392, 3.6841, 3.5356],\n",
      "        [3.5232, 3.6220, 3.4422, 3.7131, 3.5412],\n",
      "        [3.3999, 3.5022, 3.3967, 3.6210, 3.4559],\n",
      "        [3.5693, 3.7919, 3.6420, 3.7853, 3.7617],\n",
      "        [3.6913, 3.8328, 3.5753, 3.7421, 3.6693],\n",
      "        [3.6574, 3.8153, 3.5909, 3.7416, 3.6911],\n",
      "        [3.3926, 3.5939, 3.6465, 3.6035, 3.5765],\n",
      "        [3.6401, 3.6705, 3.6208, 3.8330, 3.7702],\n",
      "        [3.4303, 3.4906, 3.5327, 3.6317, 3.4468],\n",
      "        [3.4504, 3.6272, 3.7676, 3.6597, 3.7150],\n",
      "        [3.5161, 3.5794, 3.4847, 3.7250, 3.5538],\n",
      "        [3.7109, 3.7305, 3.6751, 3.8173, 3.7502],\n",
      "        [3.4968, 3.5401, 3.5663, 3.6812, 3.5593],\n",
      "        [3.5023, 3.6542, 3.6162, 3.6914, 3.5123],\n",
      "        [3.6395, 3.7523, 3.5983, 3.7433, 3.6580],\n",
      "        [3.6466, 3.7858, 3.6064, 3.9243, 3.7179],\n",
      "        [3.3921, 3.3873, 3.4419, 3.5787, 3.3958],\n",
      "        [3.1958, 3.3673, 3.4234, 3.4212, 3.3785],\n",
      "        [3.4953, 3.4708, 3.5828, 3.5729, 3.5867],\n",
      "        [3.8094, 3.8236, 3.7159, 3.9437, 3.8872],\n",
      "        [3.6162, 3.4420, 3.4712, 3.6424, 3.5729],\n",
      "        [3.6462, 3.6954, 3.7044, 3.7658, 3.6703],\n",
      "        [3.3724, 3.5096, 3.4235, 3.5265, 3.4607],\n",
      "        [3.3747, 3.5456, 3.5262, 3.5693, 3.4835],\n",
      "        [3.5309, 3.5737, 3.6948, 3.7414, 3.6264],\n",
      "        [3.5158, 3.6848, 3.5436, 3.6878, 3.6249],\n",
      "        [3.5142, 3.6101, 3.7490, 3.7288, 3.7041],\n",
      "        [3.6085, 3.8641, 3.6667, 3.8075, 3.7014],\n",
      "        [3.5339, 3.8385, 3.7015, 3.7331, 3.5619],\n",
      "        [3.5160, 3.5203, 3.6409, 3.6857, 3.5992],\n",
      "        [3.4019, 3.4052, 3.4514, 3.5815, 3.4150],\n",
      "        [3.4848, 3.4483, 3.5318, 3.6479, 3.6333],\n",
      "        [3.4562, 3.5546, 3.6714, 3.6697, 3.6301],\n",
      "        [3.7600, 3.7215, 3.7492, 3.9369, 3.7408],\n",
      "        [3.3947, 3.4192, 3.4591, 3.5731, 3.4180],\n",
      "        [3.5010, 3.6591, 3.6274, 3.6862, 3.7114],\n",
      "        [3.4793, 3.7479, 3.5928, 3.6619, 3.4718],\n",
      "        [3.4987, 3.5038, 3.5689, 3.6704, 3.6072],\n",
      "        [3.3793, 3.4271, 3.4654, 3.5515, 3.4090]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4037, 3.4381, 3.3639, 3.6104, 3.3814],\n",
      "        [3.6055, 3.5849, 3.6152, 3.7273, 3.5699],\n",
      "        [3.3552, 3.3754, 3.4393, 3.5458, 3.4168],\n",
      "        [3.6612, 3.8074, 3.6015, 3.7767, 3.7215],\n",
      "        [3.4929, 3.5618, 3.5691, 3.6588, 3.6995],\n",
      "        [3.4467, 3.5757, 3.5992, 3.6677, 3.6877],\n",
      "        [3.6264, 3.6194, 3.6501, 3.6949, 3.4953],\n",
      "        [3.4930, 3.5010, 3.6129, 3.6852, 3.5675],\n",
      "        [3.3666, 3.4632, 3.4876, 3.5490, 3.4302],\n",
      "        [3.3503, 3.5069, 3.5043, 3.5433, 3.4370],\n",
      "        [3.3897, 3.4407, 3.4986, 3.5726, 3.4058],\n",
      "        [3.6312, 3.6347, 3.6528, 3.7092, 3.4936],\n",
      "        [3.3761, 3.5657, 3.5371, 3.5701, 3.4923],\n",
      "        [3.5103, 3.6619, 3.4961, 3.8044, 3.4975],\n",
      "        [3.6834, 3.6927, 3.6831, 3.8444, 3.8436],\n",
      "        [3.4806, 3.5273, 3.5606, 3.6642, 3.5412],\n",
      "        [3.6235, 3.8848, 3.7591, 3.8401, 3.7985],\n",
      "        [3.4938, 3.6450, 3.6187, 3.6767, 3.6871],\n",
      "        [3.7257, 3.8235, 3.8350, 4.0381, 4.0346],\n",
      "        [3.6487, 3.6795, 3.7298, 3.7483, 3.5048],\n",
      "        [3.6459, 3.7877, 3.6080, 3.9224, 3.7175],\n",
      "        [3.7292, 3.8715, 3.7376, 3.7334, 3.7666],\n",
      "        [3.6958, 3.5566, 3.5886, 4.0670, 3.7638],\n",
      "        [3.5224, 3.5627, 3.6842, 3.7320, 3.6174],\n",
      "        [3.5540, 3.5073, 3.5778, 3.6956, 3.5549],\n",
      "        [3.7922, 3.7594, 3.7767, 3.9594, 3.6419],\n",
      "        [3.3865, 3.5126, 3.4207, 3.5434, 3.4543],\n",
      "        [3.3492, 3.5038, 3.5015, 3.5449, 3.4372],\n",
      "        [3.8093, 3.8729, 3.7962, 3.9225, 3.8575],\n",
      "        [3.3515, 3.5177, 3.5128, 3.5548, 3.4513],\n",
      "        [3.7034, 3.6474, 3.7192, 3.8769, 3.6592],\n",
      "        [3.6953, 3.8024, 3.6213, 3.7920, 3.7636],\n",
      "        [3.6483, 3.7901, 3.6091, 3.9238, 3.7210],\n",
      "        [3.5114, 3.5317, 3.6463, 3.6869, 3.5998],\n",
      "        [3.4939, 3.4945, 3.5720, 3.6400, 3.5243],\n",
      "        [3.3528, 3.4897, 3.4972, 3.5424, 3.4333],\n",
      "        [3.4920, 3.7432, 3.5939, 3.6639, 3.4629],\n",
      "        [3.4280, 3.5267, 3.4456, 3.6237, 3.4998],\n",
      "        [3.6870, 3.9324, 3.8073, 3.8938, 3.8418],\n",
      "        [3.4514, 3.5652, 3.4246, 3.6121, 3.4986],\n",
      "        [3.5333, 3.8406, 3.7031, 3.7312, 3.5614],\n",
      "        [3.5403, 3.7358, 3.5905, 3.8374, 3.5734],\n",
      "        [3.4976, 3.7938, 3.6911, 3.7705, 3.7577],\n",
      "        [3.5931, 3.6317, 3.5930, 3.8267, 3.5997],\n",
      "        [3.3610, 3.5849, 3.5459, 3.5691, 3.4904],\n",
      "        [3.5303, 3.5757, 3.6963, 3.7395, 3.6260],\n",
      "        [3.7333, 3.5027, 3.6433, 3.9937, 3.8733],\n",
      "        [3.3179, 3.3763, 3.4063, 3.4662, 3.3852],\n",
      "        [3.5722, 3.7716, 3.6239, 3.7743, 3.7511],\n",
      "        [3.6941, 3.7330, 3.7145, 3.8567, 3.8087],\n",
      "        [3.4892, 3.4910, 3.5674, 3.6349, 3.5173],\n",
      "        [3.4023, 3.3972, 3.4486, 3.5688, 3.4164],\n",
      "        [3.3061, 3.4500, 3.3027, 3.5371, 3.3550],\n",
      "        [3.5813, 3.7833, 3.6178, 3.8688, 3.6705],\n",
      "        [3.5152, 3.6868, 3.5451, 3.6860, 3.6245],\n",
      "        [3.4818, 3.4572, 3.5823, 3.5351, 3.5908],\n",
      "        [3.4450, 3.4039, 3.4451, 3.5832, 3.4105],\n",
      "        [3.4484, 3.4994, 3.5600, 3.6434, 3.5272],\n",
      "        [3.7997, 3.6129, 3.6421, 4.1367, 3.8617],\n",
      "        [3.4678, 3.6053, 3.7008, 3.6249, 3.5552],\n",
      "        [3.5515, 3.7305, 3.5912, 3.6864, 3.6510],\n",
      "        [3.3224, 3.3765, 3.4422, 3.4934, 3.3442],\n",
      "        [3.8751, 3.9199, 3.7837, 4.1771, 3.9101],\n",
      "        [3.4231, 3.5442, 3.4328, 3.5732, 3.4987]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4516, 3.5612, 3.4214, 3.6246, 3.4828],\n",
      "        [3.8742, 3.9218, 3.7861, 4.1751, 3.9106],\n",
      "        [3.7688, 3.7418, 3.7566, 3.9635, 3.7560],\n",
      "        [3.3488, 3.5346, 3.6684, 3.5453, 3.6097],\n",
      "        [3.4884, 3.6039, 3.5856, 3.6974, 3.5280],\n",
      "        [3.6718, 3.6775, 3.7113, 3.8557, 3.5232],\n",
      "        [3.4938, 3.7104, 3.6206, 3.6157, 3.6452],\n",
      "        [3.7006, 3.8083, 3.7707, 3.8734, 3.8893],\n",
      "        [3.5090, 3.5574, 3.6731, 3.7934, 3.7509],\n",
      "        [3.5929, 3.6151, 3.4604, 3.7726, 3.6926],\n",
      "        [3.6780, 3.6617, 3.8173, 3.7510, 3.5374],\n",
      "        [3.4220, 3.5457, 3.4350, 3.5713, 3.4993],\n",
      "        [3.3536, 3.5544, 3.5297, 3.5617, 3.4662],\n",
      "        [3.7095, 3.7341, 3.6791, 3.8135, 3.7506],\n",
      "        [3.5006, 3.6578, 3.6200, 3.6877, 3.5124],\n",
      "        [3.6273, 3.7425, 3.6013, 3.7489, 3.6538],\n",
      "        [3.6766, 3.6597, 3.7595, 3.7691, 3.4980],\n",
      "        [3.5058, 3.6131, 3.4317, 3.6890, 3.5280],\n",
      "        [3.5069, 3.5157, 3.5776, 3.6490, 3.5465],\n",
      "        [3.7277, 3.7420, 3.6848, 3.8391, 3.7547],\n",
      "        [3.3462, 3.5237, 3.5161, 3.5451, 3.4420],\n",
      "        [3.4747, 3.6484, 3.5994, 3.6779, 3.5991],\n",
      "        [3.6032, 3.6222, 3.6047, 3.7314, 3.5840],\n",
      "        [3.5819, 3.5813, 3.6936, 3.7898, 3.5880],\n",
      "        [3.4660, 3.5624, 3.4649, 3.6305, 3.5346],\n",
      "        [3.7010, 3.9712, 3.7087, 3.9911, 3.8636],\n",
      "        [3.5302, 3.6474, 3.5892, 3.7058, 3.6283],\n",
      "        [3.6473, 3.7900, 3.6120, 3.9169, 3.7202],\n",
      "        [3.7398, 3.7145, 3.7939, 3.8755, 3.5801],\n",
      "        [3.6456, 3.7225, 3.6921, 3.7208, 3.6802],\n",
      "        [3.8193, 3.6119, 3.6556, 4.1716, 3.8914],\n",
      "        [3.5179, 3.6990, 3.5641, 3.6727, 3.6392],\n",
      "        [3.4666, 3.5761, 3.4343, 3.6214, 3.5207],\n",
      "        [3.3481, 3.5053, 3.5038, 3.5429, 3.4378],\n",
      "        [3.3596, 3.4712, 3.4940, 3.5462, 3.4306],\n",
      "        [3.3717, 3.5104, 3.4259, 3.5210, 3.4619],\n",
      "        [3.5126, 3.6181, 3.5326, 3.7355, 3.6014],\n",
      "        [3.3592, 3.4970, 3.4236, 3.5149, 3.4613],\n",
      "        [3.5104, 3.4369, 3.5265, 3.5381, 3.4440],\n",
      "        [3.8875, 3.6391, 3.7332, 4.2531, 4.0622],\n",
      "        [3.6113, 3.7140, 3.5799, 3.7834, 3.7114],\n",
      "        [3.4946, 3.4995, 3.5766, 3.6457, 3.5337],\n",
      "        [3.5353, 3.5483, 3.6499, 3.7293, 3.6143],\n",
      "        [3.3391, 3.4953, 3.4344, 3.4924, 3.4475],\n",
      "        [3.4920, 3.5137, 3.5545, 3.6520, 3.5372],\n",
      "        [3.4153, 3.5721, 3.6354, 3.6390, 3.6078],\n",
      "        [3.5849, 3.6003, 3.5789, 3.8017, 3.6127],\n",
      "        [3.3952, 3.4026, 3.4523, 3.5765, 3.4119],\n",
      "        [3.7248, 3.8253, 3.8374, 4.0361, 4.0351],\n",
      "        [3.4794, 3.5289, 3.5629, 3.6622, 3.5416],\n",
      "        [3.9166, 4.0299, 3.6332, 3.8831, 3.6456],\n",
      "        [3.4850, 3.4669, 3.5605, 3.6244, 3.5210],\n",
      "        [3.6076, 3.6278, 3.7204, 3.7919, 3.6149],\n",
      "        [3.5782, 3.6356, 3.5379, 3.7654, 3.6198],\n",
      "        [3.5213, 3.5643, 3.6865, 3.7300, 3.6180],\n",
      "        [3.3504, 3.5193, 3.5151, 3.5528, 3.4519],\n",
      "        [3.6307, 3.7714, 3.7186, 3.8332, 3.7036],\n",
      "        [3.4811, 3.6249, 3.7218, 3.6287, 3.5745],\n",
      "        [3.2566, 3.4217, 3.4492, 3.4704, 3.4134],\n",
      "        [3.4946, 3.4140, 3.4995, 3.5206, 3.4202],\n",
      "        [3.5081, 3.5400, 3.6553, 3.6929, 3.6030],\n",
      "        [3.6625, 3.6178, 3.6931, 3.8175, 3.6333],\n",
      "        [3.4956, 3.4926, 3.5908, 3.6518, 3.5355],\n",
      "        [3.6485, 3.7603, 3.6233, 3.8169, 3.6736]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7669, 3.6441, 3.7482, 3.9499, 3.7115],\n",
      "        [3.4872, 3.6501, 3.5250, 3.6945, 3.6172],\n",
      "        [3.5791, 3.7389, 3.6496, 3.7301, 3.5115],\n",
      "        [3.6007, 3.6485, 3.6252, 3.6867, 3.4088],\n",
      "        [3.4798, 3.5884, 3.4394, 3.6382, 3.5309],\n",
      "        [3.5023, 3.6033, 3.5964, 3.6549, 3.4605],\n",
      "        [3.3553, 3.5669, 3.5378, 3.5530, 3.4695],\n",
      "        [3.4279, 3.7679, 3.5863, 3.7130, 3.6734],\n",
      "        [3.5204, 3.8530, 3.5968, 3.8517, 3.7238],\n",
      "        [3.6222, 3.6111, 3.5556, 3.8683, 3.6768],\n",
      "        [3.5571, 3.5730, 3.6643, 3.7280, 3.6314],\n",
      "        [3.3489, 3.5607, 3.5322, 3.5460, 3.4596],\n",
      "        [3.4736, 3.7414, 3.6704, 3.6131, 3.6408],\n",
      "        [3.4827, 3.5278, 3.5687, 3.5346, 3.3509],\n",
      "        [3.3301, 3.3943, 3.4583, 3.5113, 3.3576],\n",
      "        [3.3879, 3.4942, 3.5388, 3.5881, 3.4422],\n",
      "        [3.4330, 3.5178, 3.5415, 3.6790, 3.5196],\n",
      "        [3.4384, 3.5286, 3.4669, 3.5557, 3.4677],\n",
      "        [3.3313, 3.3968, 3.4177, 3.4843, 3.3958],\n",
      "        [3.6705, 3.6853, 3.6791, 3.8333, 3.8355],\n",
      "        [3.4241, 3.5016, 3.5358, 3.6523, 3.5110],\n",
      "        [3.4136, 3.5191, 3.5695, 3.6184, 3.4462],\n",
      "        [3.5173, 3.5301, 3.6082, 3.6669, 3.5957],\n",
      "        [3.4269, 3.7211, 3.5415, 3.5786, 3.4371],\n",
      "        [3.5022, 3.5523, 3.6566, 3.5692, 3.7133],\n",
      "        [3.7284, 3.8096, 3.8058, 3.8202, 3.6072],\n",
      "        [3.5182, 3.5178, 3.5855, 3.6308, 3.5887],\n",
      "        [3.7387, 3.5824, 3.6227, 4.0731, 3.8095],\n",
      "        [3.6961, 3.4948, 3.6314, 3.9415, 3.8449],\n",
      "        [3.5210, 3.5281, 3.6286, 3.7083, 3.6050],\n",
      "        [3.5013, 3.5654, 3.6382, 3.6136, 3.6991],\n",
      "        [3.5145, 3.6307, 3.4560, 3.7090, 3.5519],\n",
      "        [3.6550, 3.7019, 3.7397, 3.7484, 3.4944],\n",
      "        [3.8137, 3.8313, 3.7175, 3.9234, 3.8926],\n",
      "        [3.5776, 3.6996, 3.5412, 3.7449, 3.6396],\n",
      "        [3.4486, 3.4140, 3.5738, 3.4669, 3.5836],\n",
      "        [3.4924, 3.5415, 3.6587, 3.5804, 3.7089],\n",
      "        [3.6124, 3.5723, 3.6431, 3.6259, 3.5845],\n",
      "        [3.4371, 3.7929, 3.6167, 3.7263, 3.7122],\n",
      "        [3.4224, 3.5581, 3.4418, 3.5858, 3.4907],\n",
      "        [3.8278, 3.7647, 3.7899, 3.9613, 3.8377],\n",
      "        [3.5342, 3.8745, 3.6645, 3.8384, 3.7683],\n",
      "        [3.3646, 3.4976, 3.5154, 3.5604, 3.4553],\n",
      "        [3.6200, 3.4950, 3.4813, 3.6176, 3.6228],\n",
      "        [3.6460, 3.8103, 3.7550, 3.8578, 3.6732],\n",
      "        [3.4669, 3.5885, 3.4349, 3.6307, 3.5173],\n",
      "        [3.3985, 3.3939, 3.4503, 3.5733, 3.4047],\n",
      "        [3.6460, 3.7930, 3.6134, 3.9196, 3.7218],\n",
      "        [3.6417, 3.6299, 3.6783, 3.8619, 3.5706],\n",
      "        [3.4061, 3.3649, 3.5413, 3.4051, 3.5523],\n",
      "        [3.9538, 4.1029, 3.7553, 3.9124, 3.7074],\n",
      "        [3.3697, 3.5257, 3.5515, 3.5742, 3.4641],\n",
      "        [3.3025, 3.4523, 3.4053, 3.4439, 3.4011],\n",
      "        [3.5329, 3.8794, 3.6159, 3.8745, 3.7334],\n",
      "        [3.4136, 3.5191, 3.5695, 3.6184, 3.4462],\n",
      "        [3.6241, 3.6631, 3.6452, 3.7104, 3.4336],\n",
      "        [3.8349, 3.7569, 3.7399, 4.0243, 3.7886],\n",
      "        [3.9930, 4.1349, 3.8530, 3.9703, 3.8275],\n",
      "        [3.5080, 3.8444, 3.5925, 3.8553, 3.7032],\n",
      "        [3.4427, 3.5080, 3.5590, 3.6433, 3.5288],\n",
      "        [3.5003, 3.6698, 3.6110, 3.6887, 3.5405],\n",
      "        [3.6263, 3.7250, 3.7281, 3.7690, 3.6610],\n",
      "        [3.5021, 3.5171, 3.5746, 3.6473, 3.5469],\n",
      "        [3.7187, 3.5775, 3.6161, 4.0373, 3.7878]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3552, 3.5261, 3.5213, 3.5552, 3.4606],\n",
      "        [3.7671, 3.6459, 3.7498, 3.9480, 3.7116],\n",
      "        [4.1524, 4.3102, 3.9247, 4.0859, 3.8688],\n",
      "        [3.4854, 3.5550, 3.6928, 3.7640, 3.6121],\n",
      "        [3.6220, 3.6633, 3.6451, 3.7060, 3.4327],\n",
      "        [3.4659, 3.5193, 3.4704, 3.6657, 3.4885],\n",
      "        [3.6459, 3.7946, 3.6150, 3.9175, 3.7219],\n",
      "        [3.7203, 3.7819, 3.7623, 3.8656, 3.9351],\n",
      "        [3.6818, 3.7832, 3.7222, 3.7310, 3.7037],\n",
      "        [3.6262, 3.7933, 3.7009, 3.9131, 3.6799],\n",
      "        [3.3874, 3.4611, 3.5008, 3.5709, 3.4498],\n",
      "        [3.4224, 3.5597, 3.4433, 3.5839, 3.4908],\n",
      "        [3.3991, 3.4386, 3.3703, 3.6031, 3.3374],\n",
      "        [3.7431, 3.9338, 3.7345, 3.9525, 3.8815],\n",
      "        [3.7358, 3.8415, 3.8478, 4.0410, 4.0506],\n",
      "        [3.8290, 3.7849, 3.7347, 3.9422, 3.8029],\n",
      "        [3.6711, 3.7627, 3.7353, 3.8112, 3.8510],\n",
      "        [3.7368, 3.7357, 3.7424, 3.9733, 3.9396],\n",
      "        [3.2758, 3.4317, 3.4613, 3.4869, 3.4384],\n",
      "        [3.4662, 3.5852, 3.4314, 3.6461, 3.5061],\n",
      "        [3.6311, 3.7538, 3.6207, 3.7797, 3.6415],\n",
      "        [3.6749, 3.8356, 3.5963, 3.7456, 3.6825],\n",
      "        [3.3659, 3.6038, 3.5585, 3.5747, 3.5032],\n",
      "        [3.5907, 3.6362, 3.5989, 3.8205, 3.6007],\n",
      "        [3.8502, 3.7115, 3.7443, 4.2852, 4.0466],\n",
      "        [3.6474, 3.7633, 3.6268, 3.8131, 3.6739],\n",
      "        [3.6215, 3.6765, 3.5292, 3.7874, 3.6994],\n",
      "        [3.4474, 3.4199, 3.5343, 3.6222, 3.5547],\n",
      "        [4.0386, 4.2160, 3.8448, 4.0106, 3.7853],\n",
      "        [3.3478, 3.5469, 3.5251, 3.5419, 3.4511],\n",
      "        [3.3826, 3.3825, 3.4383, 3.5571, 3.3912],\n",
      "        [3.6467, 3.7902, 3.6069, 3.9070, 3.7079],\n",
      "        [4.0548, 4.2556, 3.8625, 4.0454, 3.8134],\n",
      "        [3.3993, 3.5230, 3.4237, 3.5495, 3.4599],\n",
      "        [3.5985, 3.7924, 3.7570, 3.7996, 3.6181],\n",
      "        [3.6280, 3.8206, 3.7488, 3.8244, 3.6582],\n",
      "        [3.7900, 3.7643, 3.7827, 3.9532, 3.6427],\n",
      "        [3.4927, 3.7134, 3.6242, 3.6116, 3.6455],\n",
      "        [4.0637, 4.2930, 3.8453, 4.0472, 3.8144],\n",
      "        [3.6893, 3.9403, 3.8205, 3.8952, 3.8415],\n",
      "        [3.6213, 3.7229, 3.6082, 3.6451, 3.6171],\n",
      "        [3.5571, 3.5747, 3.6658, 3.7259, 3.6315],\n",
      "        [3.7837, 3.8339, 3.7071, 3.9014, 3.8624],\n",
      "        [3.6065, 3.4601, 3.7291, 3.7440, 3.6225],\n",
      "        [3.8525, 3.9748, 3.6246, 3.8210, 3.6711],\n",
      "        [3.3650, 3.4449, 3.4431, 3.5330, 3.4340],\n",
      "        [3.7272, 3.8763, 3.7435, 3.7272, 3.7674],\n",
      "        [3.3763, 3.3794, 3.4348, 3.5558, 3.3888],\n",
      "        [3.4468, 3.5742, 3.5675, 3.6772, 3.4860],\n",
      "        [3.4935, 3.5023, 3.5800, 3.6417, 3.5342],\n",
      "        [3.3546, 3.4894, 3.5047, 3.5412, 3.4342],\n",
      "        [3.6024, 3.5857, 3.6098, 3.5935, 3.4294],\n",
      "        [3.3530, 3.3798, 3.4448, 3.5398, 3.4176],\n",
      "        [3.3665, 3.4541, 3.4856, 3.5430, 3.4268],\n",
      "        [3.5777, 3.7013, 3.5428, 3.7429, 3.6397],\n",
      "        [3.3470, 3.5321, 3.5205, 3.5435, 3.4453],\n",
      "        [3.6742, 3.8310, 3.5941, 3.7442, 3.6805],\n",
      "        [3.3157, 3.3805, 3.4118, 3.4604, 3.3863],\n",
      "        [3.6084, 3.6701, 3.6152, 3.8683, 3.6091],\n",
      "        [3.3965, 3.5278, 3.5865, 3.6156, 3.4418],\n",
      "        [3.6616, 3.8095, 3.7175, 3.8404, 3.6863],\n",
      "        [3.7133, 3.8487, 3.7341, 3.7222, 3.7433],\n",
      "        [3.6710, 3.8439, 3.7617, 3.8359, 3.6850],\n",
      "        [3.5015, 3.5256, 3.5736, 3.6432, 3.5997]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4922, 3.4783, 3.5914, 3.5634, 3.5874],\n",
      "        [3.8535, 3.6743, 3.7790, 4.2935, 4.0698],\n",
      "        [3.7743, 3.7177, 3.6828, 3.8429, 3.7747],\n",
      "        [3.6345, 3.6359, 3.7307, 3.7080, 3.4352],\n",
      "        [3.8879, 3.9444, 3.8607, 4.1488, 3.8842],\n",
      "        [3.7308, 3.5086, 3.6504, 3.9865, 3.8743],\n",
      "        [3.5803, 3.8393, 3.6861, 3.8008, 3.7817],\n",
      "        [3.5066, 3.6155, 3.5993, 3.6465, 3.4688],\n",
      "        [3.7930, 3.9238, 3.6162, 3.7867, 3.6758],\n",
      "        [3.3599, 3.5659, 3.5406, 3.5615, 3.4737],\n",
      "        [3.6840, 3.7016, 3.8662, 3.7215, 3.5694],\n",
      "        [3.6614, 3.8109, 3.7189, 3.8389, 3.6862],\n",
      "        [3.5101, 3.5941, 3.4974, 3.7279, 3.5653],\n",
      "        [3.4615, 3.7025, 3.5563, 3.6283, 3.5063],\n",
      "        [3.5530, 3.4047, 3.6871, 3.7289, 3.6401],\n",
      "        [3.6394, 3.7891, 3.6100, 3.9070, 3.7121],\n",
      "        [3.5569, 3.7608, 3.6205, 3.7528, 3.7365],\n",
      "        [3.5333, 3.5261, 3.6407, 3.7357, 3.5813],\n",
      "        [3.4767, 3.6118, 3.5970, 3.6921, 3.5282],\n",
      "        [3.5239, 3.7795, 3.5621, 3.8210, 3.6454],\n",
      "        [3.6076, 3.6457, 3.5040, 3.7920, 3.7082],\n",
      "        [3.5107, 3.7608, 3.5426, 3.5128, 3.5934],\n",
      "        [3.5993, 3.7079, 3.6954, 3.8243, 3.7095],\n",
      "        [3.4404, 3.5314, 3.5537, 3.6831, 3.5314],\n",
      "        [3.3030, 3.4606, 3.4074, 3.4424, 3.4041],\n",
      "        [3.4578, 3.5931, 3.4470, 3.6312, 3.5111],\n",
      "        [3.3895, 3.6018, 3.6552, 3.5939, 3.5769],\n",
      "        [3.5326, 3.8827, 3.6189, 3.8712, 3.7333],\n",
      "        [3.4498, 3.5232, 3.3472, 3.6803, 3.3748],\n",
      "        [3.3523, 3.5585, 3.5345, 3.5563, 3.4667],\n",
      "        [3.5170, 3.5967, 3.5083, 3.7219, 3.5634],\n",
      "        [3.3962, 3.4414, 3.3615, 3.6021, 3.3481],\n",
      "        [3.3989, 3.4399, 3.3716, 3.6018, 3.3375],\n",
      "        [3.5123, 3.5025, 3.6172, 3.6958, 3.6555],\n",
      "        [3.8172, 3.7679, 3.7387, 3.9314, 3.7936],\n",
      "        [3.4472, 3.5830, 3.5702, 3.6683, 3.4850],\n",
      "        [3.4978, 3.6172, 3.4445, 3.6876, 3.5364],\n",
      "        [3.3023, 3.4551, 3.4082, 3.4406, 3.4013],\n",
      "        [3.4098, 3.5931, 3.5032, 3.6041, 3.5427],\n",
      "        [3.6935, 3.5626, 3.5959, 4.0598, 3.7648],\n",
      "        [3.4547, 3.4912, 3.5561, 3.6062, 3.5154],\n",
      "        [3.3521, 3.5738, 3.5440, 3.5484, 3.4683],\n",
      "        [3.4847, 3.6003, 3.4425, 3.6564, 3.5287],\n",
      "        [3.3839, 3.4240, 3.4702, 3.5552, 3.4191],\n",
      "        [3.3847, 3.4279, 3.4695, 3.5589, 3.4211],\n",
      "        [3.8380, 3.7599, 3.7438, 4.0159, 3.7908],\n",
      "        [3.4576, 3.6278, 3.4897, 3.7364, 3.4815],\n",
      "        [3.6809, 3.5661, 3.5905, 4.0204, 3.7471],\n",
      "        [3.8210, 3.7199, 3.8075, 4.0097, 3.7826],\n",
      "        [3.6000, 3.8149, 3.7230, 3.7924, 3.6326],\n",
      "        [3.5040, 3.5141, 3.5843, 3.6410, 3.5404],\n",
      "        [3.4236, 3.4456, 3.4951, 3.5915, 3.4258],\n",
      "        [3.2983, 3.4640, 3.4515, 3.5261, 3.4408],\n",
      "        [3.4735, 3.6527, 3.6043, 3.6725, 3.5993],\n",
      "        [3.3354, 3.4042, 3.4239, 3.4892, 3.4001],\n",
      "        [3.6651, 3.5519, 3.5814, 4.0105, 3.7350],\n",
      "        [3.5142, 3.6336, 3.4589, 3.7056, 3.5519],\n",
      "        [3.6085, 3.6532, 3.5064, 3.7167, 3.6960],\n",
      "        [3.4597, 3.4900, 3.4980, 3.5767, 3.5631],\n",
      "        [3.4564, 3.5713, 3.4332, 3.6205, 3.5103],\n",
      "        [3.5569, 3.7608, 3.6205, 3.7528, 3.7365],\n",
      "        [3.6089, 3.5896, 3.6027, 3.5939, 3.4432],\n",
      "        [3.3842, 3.3951, 3.4476, 3.5635, 3.3988],\n",
      "        [3.5515, 3.5132, 3.5847, 3.6880, 3.5559]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5484, 3.5141, 3.5975, 3.6594, 3.6085],\n",
      "        [3.7574, 3.7317, 3.7592, 3.9278, 3.7411],\n",
      "        [4.0645, 4.2956, 3.8479, 4.0457, 3.8142],\n",
      "        [3.5380, 3.5602, 3.5791, 3.6862, 3.5832],\n",
      "        [3.4739, 3.5702, 3.5271, 3.6070, 3.5253],\n",
      "        [3.4408, 3.6128, 3.4859, 3.7083, 3.4752],\n",
      "        [3.5019, 3.6073, 3.6003, 3.6513, 3.4604],\n",
      "        [3.4932, 3.4557, 3.5413, 3.5611, 3.4633],\n",
      "        [3.4701, 3.5008, 3.5177, 3.5922, 3.5695],\n",
      "        [3.7044, 3.7075, 3.7371, 3.9073, 3.7028],\n",
      "        [3.4129, 3.5057, 3.4380, 3.5989, 3.4451],\n",
      "        [3.4945, 3.5059, 3.4992, 3.6938, 3.4765],\n",
      "        [3.4613, 3.7379, 3.6991, 3.6335, 3.7917],\n",
      "        [3.3629, 3.4756, 3.4987, 3.5550, 3.4373],\n",
      "        [3.8275, 3.7688, 3.7941, 3.9578, 3.8379],\n",
      "        [3.5220, 3.5302, 3.5924, 3.6323, 3.5940],\n",
      "        [3.3876, 3.6396, 3.7277, 3.6462, 3.6060],\n",
      "        [3.4136, 3.5842, 3.6397, 3.6700, 3.6347],\n",
      "        [3.5031, 3.6005, 3.4889, 3.6588, 3.5686],\n",
      "        [3.6884, 3.5801, 3.6105, 3.9693, 3.7399],\n",
      "        [3.4377, 3.5192, 3.5521, 3.6467, 3.5242],\n",
      "        [3.4680, 3.5807, 3.4279, 3.6362, 3.4962],\n",
      "        [3.7001, 3.7831, 3.7509, 3.8363, 3.8687],\n",
      "        [3.7045, 3.7459, 3.7763, 3.8060, 3.7721],\n",
      "        [3.6468, 3.7717, 3.6347, 3.8044, 3.6789],\n",
      "        [3.5099, 3.7657, 3.5606, 3.5163, 3.6321],\n",
      "        [3.5789, 3.7376, 3.5937, 3.7760, 3.6210],\n",
      "        [3.6004, 3.6525, 3.6291, 3.6833, 3.4087],\n",
      "        [3.7776, 3.6704, 3.7791, 3.9700, 3.7354],\n",
      "        [3.5644, 3.5942, 3.5851, 3.7519, 3.5869],\n",
      "        [3.4988, 3.6950, 3.5873, 3.6228, 3.6265],\n",
      "        [3.8952, 4.1075, 3.6818, 3.8626, 3.6599],\n",
      "        [3.6575, 3.6239, 3.6162, 3.6560, 3.5107],\n",
      "        [3.7678, 3.7479, 3.7627, 3.9582, 3.7561],\n",
      "        [3.8432, 3.9204, 3.8119, 4.1072, 3.8499],\n",
      "        [3.4618, 3.6735, 3.6440, 3.6658, 3.5827],\n",
      "        [3.7269, 3.8788, 3.7459, 3.7256, 3.7671],\n",
      "        [3.5911, 3.6176, 3.6048, 3.7145, 3.5667],\n",
      "        [3.6432, 3.7044, 3.7142, 3.7564, 3.6704],\n",
      "        [3.4765, 3.8075, 3.6372, 3.7591, 3.7379],\n",
      "        [3.4461, 3.5766, 3.5698, 3.6756, 3.4856],\n",
      "        [3.8234, 3.9799, 3.7349, 3.8076, 3.7148],\n",
      "        [3.4276, 3.7722, 3.5905, 3.7095, 3.6732],\n",
      "        [3.5030, 3.4519, 3.5397, 3.5558, 3.4576],\n",
      "        [3.7569, 3.8923, 3.6042, 3.7706, 3.6733],\n",
      "        [3.6380, 3.7478, 3.5879, 3.7544, 3.7501],\n",
      "        [3.6468, 3.7659, 3.6292, 3.8117, 3.6736],\n",
      "        [3.4928, 3.6052, 3.4479, 3.6543, 3.5421],\n",
      "        [3.4173, 3.5129, 3.5251, 3.5402, 3.4808],\n",
      "        [4.1319, 4.2921, 3.9276, 4.0947, 3.8518],\n",
      "        [3.4787, 3.5915, 3.5214, 3.6126, 3.5427],\n",
      "        [3.4401, 3.5016, 3.5350, 3.6357, 3.4572],\n",
      "        [3.4940, 3.4817, 3.5956, 3.6670, 3.6345],\n",
      "        [3.3451, 3.4855, 3.4246, 3.4904, 3.4289],\n",
      "        [3.5990, 3.5740, 3.6395, 3.6228, 3.5535],\n",
      "        [3.5323, 3.6816, 3.4546, 3.6286, 3.5634],\n",
      "        [3.5566, 3.4990, 3.7066, 3.7642, 3.5950],\n",
      "        [3.4933, 3.5608, 3.5249, 3.7084, 3.5681],\n",
      "        [3.4988, 3.6632, 3.6258, 3.6821, 3.5124],\n",
      "        [3.4653, 3.5216, 3.4727, 3.6643, 3.4884],\n",
      "        [3.6257, 3.7480, 3.6071, 3.7436, 3.6538],\n",
      "        [3.4737, 3.6432, 3.5228, 3.6814, 3.6073],\n",
      "        [3.7741, 3.7188, 3.6839, 3.8428, 3.7746],\n",
      "        [3.3988, 3.5252, 3.4260, 3.5480, 3.4597]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6420, 3.8463, 3.7543, 3.8501, 3.8132],\n",
      "        [3.4875, 3.4882, 3.5813, 3.6217, 3.5238],\n",
      "        [3.3840, 3.4649, 3.3955, 3.5995, 3.3486],\n",
      "        [3.2025, 3.3744, 3.4278, 3.4272, 3.3937],\n",
      "        [3.3647, 3.6075, 3.5626, 3.5742, 3.5028],\n",
      "        [3.3766, 3.5243, 3.4306, 3.5356, 3.4555],\n",
      "        [3.4852, 3.4597, 3.5607, 3.6499, 3.6295],\n",
      "        [3.4843, 3.5190, 3.5585, 3.6375, 3.5339],\n",
      "        [3.3886, 3.4222, 3.4703, 3.5623, 3.4143],\n",
      "        [3.2732, 3.4294, 3.3916, 3.4082, 3.3706],\n",
      "        [3.5651, 3.7478, 3.6443, 3.7227, 3.5046],\n",
      "        [3.4641, 3.5824, 3.4417, 3.6170, 3.5205],\n",
      "        [3.4910, 3.5249, 3.5664, 3.6366, 3.5366],\n",
      "        [3.6796, 3.7866, 3.6418, 3.8637, 3.7805],\n",
      "        [3.6721, 3.7589, 3.7555, 3.9371, 3.6539],\n",
      "        [3.5022, 3.4534, 3.5413, 3.5568, 3.4573],\n",
      "        [3.6012, 3.6541, 3.5045, 3.7122, 3.6835],\n",
      "        [3.5685, 3.5074, 3.8243, 3.7386, 3.6809],\n",
      "        [3.3095, 3.3976, 3.4120, 3.4576, 3.3824],\n",
      "        [3.5197, 3.5791, 3.5941, 3.5811, 3.3909],\n",
      "        [3.3177, 3.4654, 3.3155, 3.5376, 3.3606],\n",
      "        [3.5035, 3.5017, 3.5917, 3.5940, 3.5886],\n",
      "        [3.6011, 3.6884, 3.6777, 3.7731, 3.7456],\n",
      "        [3.8135, 3.6592, 3.7792, 3.9403, 3.7620],\n",
      "        [3.5239, 3.6926, 3.5215, 3.8211, 3.5125],\n",
      "        [3.5079, 3.4435, 3.5336, 3.5337, 3.4439],\n",
      "        [3.3627, 3.4841, 3.6141, 3.5619, 3.5479],\n",
      "        [3.6451, 3.8167, 3.7608, 3.8557, 3.6726],\n",
      "        [3.5636, 3.5902, 3.6918, 3.7348, 3.6299],\n",
      "        [3.6171, 3.8709, 3.7678, 3.8354, 3.8667],\n",
      "        [3.5394, 3.7463, 3.6309, 3.7009, 3.4855],\n",
      "        [3.6916, 3.7380, 3.7433, 3.8691, 3.8711],\n",
      "        [3.8989, 3.9726, 3.8950, 4.1897, 3.9410],\n",
      "        [3.6443, 3.6965, 3.6447, 3.8420, 3.7894],\n",
      "        [3.7006, 3.5086, 3.6474, 3.9429, 3.8456],\n",
      "        [3.4513, 3.5541, 3.4778, 3.5635, 3.4860],\n",
      "        [3.9780, 3.7068, 3.8305, 4.3376, 4.1516],\n",
      "        [3.5502, 3.6209, 3.5848, 3.7150, 3.6604],\n",
      "        [3.4005, 3.5755, 3.6375, 3.6296, 3.6026],\n",
      "        [3.5073, 3.5571, 3.4709, 3.6382, 3.6278],\n",
      "        [3.8413, 3.8993, 3.9064, 4.1233, 4.1087],\n",
      "        [3.8171, 3.6191, 3.6634, 4.1677, 3.8914],\n",
      "        [3.6000, 3.7593, 3.5867, 3.7250, 3.6350],\n",
      "        [3.5030, 3.5166, 3.5870, 3.6418, 3.5399],\n",
      "        [3.8997, 4.0306, 3.7617, 3.8728, 3.7142],\n",
      "        [3.5060, 3.5581, 3.5857, 3.6769, 3.5748],\n",
      "        [3.7297, 3.5112, 3.6531, 3.9877, 3.8738],\n",
      "        [3.6629, 3.4793, 3.4736, 3.6146, 3.6358],\n",
      "        [3.4373, 3.5574, 3.4286, 3.5971, 3.4787],\n",
      "        [3.7586, 3.8423, 3.6955, 3.8706, 3.8497],\n",
      "        [3.8060, 3.7602, 3.7473, 3.9149, 3.7847],\n",
      "        [3.6709, 3.8058, 3.6134, 3.7704, 3.7347],\n",
      "        [3.4874, 3.4658, 3.4538, 3.7089, 3.4328],\n",
      "        [3.3998, 3.5512, 3.6758, 3.6114, 3.6099],\n",
      "        [3.3737, 3.4434, 3.4821, 3.5475, 3.4239],\n",
      "        [3.3351, 3.4903, 3.4225, 3.4866, 3.4326],\n",
      "        [3.6612, 3.8405, 3.6452, 3.6462, 3.5948],\n",
      "        [3.4209, 3.4579, 3.5791, 3.6053, 3.4885],\n",
      "        [3.4773, 3.5268, 3.5691, 3.5241, 3.3468],\n",
      "        [3.6422, 3.7415, 3.6307, 3.6840, 3.6327],\n",
      "        [3.6514, 3.8013, 3.7116, 3.8408, 3.6810],\n",
      "        [3.4867, 3.6554, 3.5024, 3.7670, 3.4905],\n",
      "        [3.4209, 3.6664, 3.4687, 3.4167, 3.5143],\n",
      "        [3.3952, 3.5316, 3.5907, 3.6151, 3.4414]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4916, 3.4583, 3.5464, 3.5630, 3.4624],\n",
      "        [3.6567, 3.8305, 3.7446, 3.8271, 3.6704],\n",
      "        [3.6326, 3.7309, 3.6116, 3.8072, 3.6641],\n",
      "        [3.4807, 3.5863, 3.4804, 3.6423, 3.5457],\n",
      "        [3.4828, 3.6037, 3.4486, 3.6581, 3.5277],\n",
      "        [3.3922, 3.5442, 3.6120, 3.6098, 3.4492],\n",
      "        [3.6797, 3.7271, 3.7097, 3.8373, 3.8068],\n",
      "        [3.4900, 3.4817, 3.5932, 3.5610, 3.5875],\n",
      "        [3.6560, 3.6851, 3.7433, 3.7537, 3.5516],\n",
      "        [3.4853, 3.5504, 3.5821, 3.6684, 3.5565],\n",
      "        [3.3878, 3.3952, 3.4502, 3.5627, 3.3978],\n",
      "        [3.6232, 3.7308, 3.5845, 3.7307, 3.7532],\n",
      "        [3.5245, 3.7683, 3.6360, 3.7010, 3.4798],\n",
      "        [3.4785, 3.5198, 3.5707, 3.6461, 3.5371],\n",
      "        [3.7665, 3.7513, 3.7679, 3.9608, 3.7552],\n",
      "        [3.5674, 3.5902, 3.6965, 3.7366, 3.6318],\n",
      "        [3.6813, 3.8828, 3.7104, 3.9240, 3.7804],\n",
      "        [3.4569, 3.8235, 3.7165, 3.7561, 3.7641],\n",
      "        [3.4255, 3.5707, 3.5383, 3.5069, 3.4896],\n",
      "        [3.4285, 3.4706, 3.5887, 3.6180, 3.4969],\n",
      "        [3.4253, 3.5017, 3.5475, 3.6242, 3.4466],\n",
      "        [3.4833, 3.5169, 3.5605, 3.6352, 3.5315],\n",
      "        [3.6564, 3.7860, 3.7398, 3.7692, 3.5425],\n",
      "        [3.3828, 3.4709, 3.5209, 3.5734, 3.4173],\n",
      "        [3.4326, 3.4872, 3.5666, 3.6348, 3.5975],\n",
      "        [3.6470, 3.7605, 3.7296, 3.9162, 3.6490],\n",
      "        [3.6185, 3.5014, 3.4903, 3.6161, 3.6223],\n",
      "        [3.3454, 3.5825, 3.5457, 3.5461, 3.4652],\n",
      "        [3.4837, 3.5996, 3.4383, 3.6585, 3.5100],\n",
      "        [3.5463, 3.6153, 3.5837, 3.7152, 3.6540],\n",
      "        [3.5181, 3.6328, 3.4568, 3.7056, 3.5405],\n",
      "        [3.7292, 3.8874, 3.8342, 3.8539, 3.5806],\n",
      "        [3.5309, 3.5446, 3.5885, 3.6627, 3.5890],\n",
      "        [3.8593, 3.8847, 3.8074, 4.0952, 3.8741],\n",
      "        [3.9772, 3.7081, 3.8341, 4.3386, 4.1510],\n",
      "        [3.4119, 3.5802, 3.6463, 3.6351, 3.6070],\n",
      "        [3.5094, 3.5760, 3.6021, 3.6967, 3.5836],\n",
      "        [3.5750, 3.6320, 3.6142, 3.7065, 3.5907],\n",
      "        [3.2675, 3.4312, 3.3974, 3.4082, 3.3717],\n",
      "        [3.4906, 3.6019, 3.6032, 3.6485, 3.4596],\n",
      "        [3.5589, 3.7009, 3.6756, 3.8044, 3.6751],\n",
      "        [3.5320, 3.7007, 3.5325, 3.6353, 3.6021],\n",
      "        [3.3464, 3.4192, 3.4682, 3.5171, 3.3796],\n",
      "        [3.3505, 3.5620, 3.5407, 3.5579, 3.4658],\n",
      "        [3.5315, 3.5298, 3.6468, 3.7373, 3.5803],\n",
      "        [3.3676, 3.4655, 3.5010, 3.5548, 3.4401],\n",
      "        [3.5463, 3.7097, 3.5544, 3.7568, 3.5920],\n",
      "        [3.3525, 3.4942, 3.5121, 3.5414, 3.4332],\n",
      "        [3.3785, 3.4386, 3.4839, 3.5644, 3.4233],\n",
      "        [3.4873, 3.6726, 3.5464, 3.6861, 3.6188],\n",
      "        [3.6453, 3.7745, 3.6399, 3.8062, 3.6779],\n",
      "        [3.5395, 3.6994, 3.5107, 3.6438, 3.5888],\n",
      "        [3.4130, 3.4535, 3.5770, 3.5982, 3.4886],\n",
      "        [3.7267, 3.8337, 3.8398, 4.0232, 4.0417],\n",
      "        [3.4727, 3.8247, 3.6302, 3.7797, 3.7163],\n",
      "        [3.4188, 3.5128, 3.5362, 3.6601, 3.5090],\n",
      "        [3.4841, 3.5459, 3.5783, 3.6630, 3.5490],\n",
      "        [3.4629, 3.6821, 3.6616, 3.6697, 3.5973],\n",
      "        [3.3684, 3.4577, 3.4944, 3.5457, 3.4274],\n",
      "        [3.5556, 3.8422, 3.7827, 3.8337, 3.7732],\n",
      "        [3.4776, 3.4664, 3.5957, 3.5290, 3.5909],\n",
      "        [4.0374, 4.1877, 3.8855, 4.0155, 3.8465],\n",
      "        [3.8692, 3.6652, 3.7775, 4.3094, 4.0577],\n",
      "        [3.6259, 3.6840, 3.7489, 3.7355, 3.5685]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4183, 3.5023, 3.5461, 3.6396, 3.5082],\n",
      "        [3.4291, 3.4304, 3.4960, 3.5873, 3.4181],\n",
      "        [3.6941, 3.8645, 3.7200, 3.7060, 3.7331],\n",
      "        [3.6697, 3.8703, 3.8321, 3.8627, 3.6036],\n",
      "        [3.3627, 3.5672, 3.5473, 3.5690, 3.4812],\n",
      "        [3.5454, 3.8989, 3.6824, 3.8722, 3.7592],\n",
      "        [3.6522, 3.7659, 3.7391, 3.8368, 3.6558],\n",
      "        [3.8268, 3.7908, 3.7458, 3.9431, 3.8016],\n",
      "        [4.0805, 4.2710, 3.8558, 4.0223, 3.8404],\n",
      "        [3.4742, 3.6128, 3.5927, 3.7535, 3.5336],\n",
      "        [3.3118, 3.4874, 3.4648, 3.5382, 3.4530],\n",
      "        [3.6428, 3.8004, 3.6260, 3.9183, 3.7199],\n",
      "        [3.4841, 3.5684, 3.5407, 3.6260, 3.5462],\n",
      "        [3.8742, 3.9748, 3.8740, 4.1773, 3.9401],\n",
      "        [3.5530, 3.5777, 3.5919, 3.7241, 3.5826],\n",
      "        [3.5948, 3.5839, 3.6477, 3.6364, 3.5165],\n",
      "        [3.3464, 3.5357, 3.5288, 3.5404, 3.4430],\n",
      "        [3.4738, 3.5991, 3.4582, 3.6496, 3.5272],\n",
      "        [3.5386, 3.7003, 3.5137, 3.6442, 3.5880],\n",
      "        [3.4899, 3.4745, 3.5592, 3.5794, 3.4781],\n",
      "        [3.9145, 3.9609, 3.8524, 4.2206, 3.9475],\n",
      "        [3.3517, 3.4950, 3.5150, 3.5419, 3.4325],\n",
      "        [3.3629, 3.4743, 3.5087, 3.5470, 3.4314],\n",
      "        [3.4434, 3.5354, 3.4776, 3.6640, 3.5078],\n",
      "        [3.2649, 3.4212, 3.3927, 3.4032, 3.3606],\n",
      "        [3.4966, 3.5543, 3.5169, 3.7073, 3.5300],\n",
      "        [3.3495, 3.6165, 3.3989, 3.6107, 3.3977],\n",
      "        [3.4768, 3.5955, 3.4513, 3.6370, 3.5292],\n",
      "        [3.3890, 3.4114, 3.4678, 3.5724, 3.4125],\n",
      "        [3.3555, 3.4796, 3.5077, 3.5429, 3.4293],\n",
      "        [3.3518, 3.5281, 3.5272, 3.5477, 3.4537],\n",
      "        [3.3936, 3.5335, 3.5972, 3.6163, 3.4402],\n",
      "        [3.6254, 3.8277, 3.7594, 3.8258, 3.6561],\n",
      "        [3.4850, 3.4965, 3.5796, 3.6379, 3.5121],\n",
      "        [3.4875, 3.5291, 3.5704, 3.6397, 3.5349],\n",
      "        [3.5895, 3.7205, 3.5582, 3.7568, 3.6655],\n",
      "        [3.4715, 3.5481, 3.4969, 3.5726, 3.5150],\n",
      "        [3.4245, 3.5026, 3.5504, 3.6247, 3.4459],\n",
      "        [3.4962, 3.6718, 3.6460, 3.6790, 3.7100],\n",
      "        [3.3446, 3.5834, 3.5486, 3.5465, 3.4646],\n",
      "        [3.3554, 3.5052, 3.4373, 3.5118, 3.4602],\n",
      "        [3.6785, 3.7889, 3.6482, 3.8652, 3.7790],\n",
      "        [3.6104, 3.9622, 3.7182, 3.9341, 3.8100],\n",
      "        [3.5269, 3.5360, 3.6339, 3.6563, 3.5579],\n",
      "        [3.4941, 3.7118, 3.5526, 3.6180, 3.6034],\n",
      "        [3.3976, 3.5203, 3.4378, 3.6003, 3.4418],\n",
      "        [3.4798, 3.8047, 3.6993, 3.7557, 3.7486],\n",
      "        [3.8498, 3.8254, 3.7851, 3.9859, 3.8534],\n",
      "        [3.7876, 3.7928, 3.8090, 3.9072, 3.9397],\n",
      "        [3.5134, 3.5254, 3.6498, 3.6741, 3.5950],\n",
      "        [3.7758, 3.6748, 3.7870, 3.9737, 3.7339],\n",
      "        [3.4586, 3.7076, 3.5653, 3.6304, 3.5041],\n",
      "        [3.4887, 3.4755, 3.5829, 3.6564, 3.6327],\n",
      "        [3.7266, 3.7311, 3.7462, 3.9637, 3.9351],\n",
      "        [3.5108, 3.6392, 3.4635, 3.7114, 3.5525],\n",
      "        [3.4484, 3.5596, 3.4676, 3.6163, 3.5177],\n",
      "        [3.5665, 3.5356, 3.5975, 3.6533, 3.6160],\n",
      "        [3.5245, 3.5302, 3.6547, 3.7066, 3.6264],\n",
      "        [3.5731, 3.6445, 3.5586, 3.7640, 3.6203],\n",
      "        [3.5239, 3.5096, 3.6389, 3.7128, 3.6564],\n",
      "        [3.3689, 3.5025, 3.5451, 3.5753, 3.4306],\n",
      "        [3.2601, 3.4314, 3.4727, 3.4709, 3.4399],\n",
      "        [3.7561, 3.7530, 3.7724, 3.9663, 3.7415],\n",
      "        [3.8004, 3.7961, 3.7994, 3.9935, 3.6948]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8206, 3.7720, 3.7798, 4.0181, 3.8184],\n",
      "        [3.4820, 3.5356, 3.5761, 3.6505, 3.5361],\n",
      "        [3.5027, 3.6302, 3.4541, 3.6953, 3.5367],\n",
      "        [3.4746, 3.6479, 3.5030, 3.7651, 3.4761],\n",
      "        [3.6275, 3.7622, 3.6346, 3.7822, 3.6386],\n",
      "        [3.4767, 3.6059, 3.4485, 3.6672, 3.5149],\n",
      "        [3.3751, 3.5277, 3.4393, 3.5332, 3.4511],\n",
      "        [3.5890, 3.6726, 3.5944, 3.7077, 3.5819],\n",
      "        [3.8998, 3.9698, 3.8940, 4.1802, 3.9206],\n",
      "        [3.4809, 3.5129, 3.5786, 3.6434, 3.5325],\n",
      "        [3.6619, 3.5587, 3.5942, 4.0146, 3.7325],\n",
      "        [3.5382, 3.5681, 3.6565, 3.6913, 3.6188],\n",
      "        [3.4973, 3.4377, 3.5304, 3.5225, 3.4305],\n",
      "        [3.4056, 3.6186, 3.5696, 3.5174, 3.4546],\n",
      "        [3.6511, 3.8310, 3.6097, 3.7422, 3.6833],\n",
      "        [3.4416, 3.5884, 3.6195, 3.6639, 3.6858],\n",
      "        [3.3713, 3.4709, 3.5075, 3.5576, 3.4409],\n",
      "        [3.9108, 4.0315, 3.6434, 3.8655, 3.6480],\n",
      "        [3.8118, 3.8013, 3.7386, 3.9472, 3.8341],\n",
      "        [3.4571, 3.5196, 3.5473, 3.6617, 3.4743],\n",
      "        [3.4984, 3.5336, 3.5876, 3.6454, 3.5971],\n",
      "        [3.5539, 3.8454, 3.7894, 3.8357, 3.7715],\n",
      "        [3.6243, 3.6872, 3.7554, 3.7373, 3.5668],\n",
      "        [3.6907, 3.8891, 3.7271, 3.9424, 3.7833],\n",
      "        [3.3789, 3.5389, 3.4431, 3.5412, 3.4655],\n",
      "        [3.4138, 3.5486, 3.4870, 3.5901, 3.4962],\n",
      "        [3.3944, 3.5420, 3.4405, 3.5550, 3.4702],\n",
      "        [3.4689, 3.6577, 3.6162, 3.6666, 3.6115],\n",
      "        [3.4740, 3.5397, 3.5802, 3.6602, 3.5388],\n",
      "        [3.4206, 3.5575, 3.4443, 3.5816, 3.4904],\n",
      "        [3.6346, 3.6646, 3.6601, 3.7903, 3.8046],\n",
      "        [3.5292, 3.5475, 3.5950, 3.6646, 3.5874],\n",
      "        [3.2924, 3.4564, 3.4170, 3.4359, 3.4015],\n",
      "        [3.5236, 3.6269, 3.7680, 3.7419, 3.7058],\n",
      "        [3.7244, 3.8285, 3.6775, 3.8443, 3.8224],\n",
      "        [3.9161, 4.0414, 3.6506, 3.8822, 3.6436],\n",
      "        [3.5323, 3.7406, 3.6187, 3.6816, 3.6468],\n",
      "        [3.6419, 3.8025, 3.6296, 3.9199, 3.7190],\n",
      "        [3.3757, 3.7889, 3.6654, 3.6423, 3.7225],\n",
      "        [3.3983, 3.5694, 3.4852, 3.6615, 3.4570],\n",
      "        [3.8241, 3.9578, 3.6368, 3.8081, 3.6720],\n",
      "        [3.5276, 3.7136, 3.5801, 3.7639, 3.5650],\n",
      "        [3.3770, 3.4928, 3.5182, 3.5566, 3.4569],\n",
      "        [3.6419, 3.8025, 3.6296, 3.9199, 3.7190],\n",
      "        [3.3935, 3.5273, 3.4190, 3.6129, 3.4563],\n",
      "        [3.4972, 3.7593, 3.5441, 3.7918, 3.6177],\n",
      "        [3.4582, 3.4455, 3.5144, 3.5983, 3.6107],\n",
      "        [3.5026, 3.5733, 3.6009, 3.6887, 3.5752],\n",
      "        [3.7941, 3.6261, 3.6623, 4.1340, 3.8602],\n",
      "        [3.4834, 3.5446, 3.5812, 3.6578, 3.5415],\n",
      "        [3.6855, 3.9492, 3.8355, 3.8977, 3.8387],\n",
      "        [3.4455, 3.5770, 3.4440, 3.6084, 3.4969],\n",
      "        [3.6396, 3.7990, 3.6232, 3.9103, 3.7074],\n",
      "        [3.4888, 3.5469, 3.5855, 3.6551, 3.5424],\n",
      "        [3.4922, 3.5434, 3.5816, 3.6597, 3.5441],\n",
      "        [3.6227, 3.7354, 3.7441, 3.7691, 3.6582],\n",
      "        [3.6724, 3.7967, 3.7641, 3.7881, 3.5520],\n",
      "        [3.4360, 3.3857, 3.4346, 3.5715, 3.3887],\n",
      "        [3.5134, 3.7103, 3.5817, 3.6709, 3.6366],\n",
      "        [3.6653, 3.7725, 3.6784, 3.7895, 3.7577],\n",
      "        [3.6118, 3.7233, 3.6086, 3.7873, 3.7109],\n",
      "        [3.2000, 3.3784, 3.4373, 3.4297, 3.3916],\n",
      "        [3.5068, 3.6267, 3.5922, 3.6765, 3.5985],\n",
      "        [3.4648, 3.5860, 3.4394, 3.6400, 3.4937]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4652, 3.5797, 3.4840, 3.6297, 3.5326],\n",
      "        [3.8140, 3.6252, 3.6766, 4.1720, 3.8884],\n",
      "        [3.4786, 3.5327, 3.5741, 3.6449, 3.5326],\n",
      "        [3.4368, 3.5428, 3.5683, 3.6782, 3.5184],\n",
      "        [3.8818, 3.6523, 3.7543, 4.2534, 4.0592],\n",
      "        [3.5339, 3.4960, 3.5629, 3.6185, 3.5773],\n",
      "        [3.2982, 3.4629, 3.4234, 3.4453, 3.3982],\n",
      "        [3.6284, 3.6114, 3.6760, 3.7741, 3.6003],\n",
      "        [3.4197, 3.5592, 3.4472, 3.5826, 3.4895],\n",
      "        [3.5688, 3.6199, 3.6057, 3.7843, 3.5869],\n",
      "        [3.7226, 3.6188, 3.6281, 3.7636, 3.6998],\n",
      "        [3.6250, 3.7390, 3.6311, 3.6582, 3.6167],\n",
      "        [3.5387, 3.5032, 3.5693, 3.6299, 3.5877],\n",
      "        [3.5795, 3.6129, 3.5996, 3.8009, 3.6095],\n",
      "        [3.4191, 3.5128, 3.5539, 3.6533, 3.5072],\n",
      "        [3.6016, 3.6077, 3.6634, 3.6685, 3.5069],\n",
      "        [3.8198, 3.7739, 3.7827, 4.0194, 3.8175],\n",
      "        [3.6507, 3.6644, 3.7159, 3.8744, 3.5759],\n",
      "        [3.3970, 3.5520, 3.4524, 3.5644, 3.4776],\n",
      "        [3.6690, 3.7649, 3.7686, 3.9411, 3.6506],\n",
      "        [3.4724, 3.8152, 3.6519, 3.7639, 3.7343],\n",
      "        [3.4274, 3.5050, 3.5708, 3.6317, 3.5264],\n",
      "        [3.6542, 3.7633, 3.7242, 3.7158, 3.6818],\n",
      "        [3.5018, 3.6319, 3.4570, 3.6964, 3.5357],\n",
      "        [3.5885, 3.5775, 3.6460, 3.6393, 3.5193],\n",
      "        [3.3192, 3.4859, 3.4315, 3.4808, 3.4237],\n",
      "        [3.4414, 3.5840, 3.5839, 3.6801, 3.4819],\n",
      "        [3.7749, 3.8151, 3.7186, 3.9128, 3.8559],\n",
      "        [3.4238, 3.5076, 3.5624, 3.6415, 3.5126],\n",
      "        [3.5090, 3.5596, 3.5964, 3.5584, 3.3781],\n",
      "        [3.5006, 3.7629, 3.6244, 3.6687, 3.4647],\n",
      "        [3.5339, 3.5673, 3.5939, 3.6909, 3.5797],\n",
      "        [3.2633, 3.4248, 3.3990, 3.4057, 3.3590],\n",
      "        [3.7385, 3.7973, 3.7946, 3.8614, 3.8261],\n",
      "        [3.6461, 3.7545, 3.6451, 3.7143, 3.6370],\n",
      "        [3.4673, 3.5932, 3.5734, 3.6900, 3.6127],\n",
      "        [3.6846, 3.5876, 3.6252, 3.9744, 3.7366],\n",
      "        [3.5730, 3.7240, 3.7091, 3.8314, 3.6915],\n",
      "        [3.5517, 3.5668, 3.7011, 3.8280, 3.7830],\n",
      "        [3.5173, 3.6674, 3.4460, 3.6230, 3.5413],\n",
      "        [3.4422, 3.5914, 3.5853, 3.6727, 3.4810],\n",
      "        [3.4795, 3.6106, 3.6150, 3.6994, 3.5100],\n",
      "        [3.7903, 3.9325, 3.6318, 3.7919, 3.6721],\n",
      "        [3.4797, 3.5402, 3.4936, 3.6821, 3.4957],\n",
      "        [3.5296, 3.7543, 3.6290, 3.8349, 3.5630],\n",
      "        [3.5802, 3.5733, 3.6075, 3.6039, 3.4088],\n",
      "        [3.5598, 3.5858, 3.6904, 3.7362, 3.6222],\n",
      "        [3.4926, 3.7145, 3.6222, 3.6222, 3.6336],\n",
      "        [3.3906, 3.4130, 3.4686, 3.5745, 3.4043],\n",
      "        [3.5135, 3.5137, 3.6404, 3.7084, 3.6513],\n",
      "        [3.5107, 3.5394, 3.6308, 3.6666, 3.5874],\n",
      "        [3.5228, 3.5339, 3.6611, 3.7091, 3.6245],\n",
      "        [3.6286, 3.7831, 3.7388, 3.8277, 3.7009],\n",
      "        [3.4649, 3.6239, 3.5536, 3.7210, 3.5923],\n",
      "        [3.3715, 3.3886, 3.4509, 3.5587, 3.3850],\n",
      "        [3.6933, 3.9494, 3.7821, 3.9948, 3.8644],\n",
      "        [3.5670, 3.8274, 3.6849, 3.7902, 3.7653],\n",
      "        [3.6663, 3.7730, 3.7526, 3.8144, 3.8466],\n",
      "        [3.5765, 3.6186, 3.5630, 3.7842, 3.6117],\n",
      "        [3.7074, 3.8166, 3.6575, 3.8125, 3.8010],\n",
      "        [3.4743, 3.5838, 3.4908, 3.6642, 3.5014],\n",
      "        [3.4719, 3.6614, 3.6076, 3.6742, 3.5706],\n",
      "        [3.4438, 3.4288, 3.5465, 3.6181, 3.5387],\n",
      "        [3.6614, 3.5633, 3.6122, 3.7106, 3.6143]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4854, 3.5175, 3.5776, 3.6407, 3.5315],\n",
      "        [3.4158, 3.5648, 3.4526, 3.5848, 3.4816],\n",
      "        [3.3386, 3.5174, 3.5304, 3.5422, 3.4306],\n",
      "        [3.5078, 3.7028, 3.5704, 3.6839, 3.6203],\n",
      "        [3.5431, 3.6212, 3.5963, 3.7190, 3.6506],\n",
      "        [3.4734, 3.8320, 3.6641, 3.7743, 3.7398],\n",
      "        [3.4606, 3.4518, 3.6055, 3.5019, 3.5856],\n",
      "        [3.3784, 3.4333, 3.4877, 3.5603, 3.4145],\n",
      "        [3.4872, 3.6610, 3.6447, 3.6746, 3.6832],\n",
      "        [3.3470, 3.5833, 3.5621, 3.5538, 3.4640],\n",
      "        [3.4880, 3.5239, 3.5880, 3.6450, 3.5328],\n",
      "        [3.8338, 3.7712, 3.7618, 4.0239, 3.7862],\n",
      "        [3.6564, 3.8208, 3.7373, 3.8441, 3.6814],\n",
      "        [3.7356, 3.8887, 3.8248, 3.9428, 3.8320],\n",
      "        [3.4900, 3.6204, 3.4581, 3.6770, 3.5205],\n",
      "        [3.6496, 3.7712, 3.7482, 3.8401, 3.6529],\n",
      "        [3.4978, 3.6230, 3.4575, 3.6887, 3.5249],\n",
      "        [3.7088, 3.7771, 3.8182, 3.9736, 3.6674],\n",
      "        [4.0367, 4.2279, 3.8651, 4.0152, 3.7806],\n",
      "        [3.3908, 3.5883, 3.4990, 3.5877, 3.5273],\n",
      "        [3.4888, 3.6198, 3.4665, 3.6816, 3.5320],\n",
      "        [3.4693, 3.6721, 3.6088, 3.6734, 3.5729],\n",
      "        [3.8563, 3.7577, 3.8314, 4.0482, 3.8336],\n",
      "        [3.5059, 3.6319, 3.5557, 3.7360, 3.5975],\n",
      "        [3.3529, 3.4846, 3.5165, 3.5460, 3.4265],\n",
      "        [3.5540, 3.6362, 3.6521, 3.6924, 3.6826],\n",
      "        [3.4974, 3.6159, 3.6173, 3.6568, 3.4560],\n",
      "        [3.4261, 3.5708, 3.4474, 3.6007, 3.4848],\n",
      "        [3.4797, 3.5228, 3.5722, 3.6387, 3.5278],\n",
      "        [3.4824, 3.5015, 3.5884, 3.6409, 3.5093],\n",
      "        [3.4526, 3.4901, 3.5702, 3.5984, 3.4978],\n",
      "        [3.5410, 3.7013, 3.5064, 3.6506, 3.5785],\n",
      "        [3.4815, 3.5735, 3.5497, 3.6293, 3.5435],\n",
      "        [3.4218, 3.5077, 3.5594, 3.6279, 3.4431],\n",
      "        [3.4108, 3.5586, 3.4564, 3.5636, 3.4862],\n",
      "        [3.4801, 3.6668, 3.6190, 3.6819, 3.5578],\n",
      "        [3.4102, 3.5123, 3.5473, 3.6527, 3.5034],\n",
      "        [3.6172, 3.8595, 3.7749, 3.8293, 3.8377],\n",
      "        [3.7634, 3.7582, 3.7798, 3.9654, 3.7515],\n",
      "        [3.4079, 3.5316, 3.5907, 3.6203, 3.4419],\n",
      "        [3.8393, 3.6816, 3.7930, 4.2958, 4.0590],\n",
      "        [3.3090, 3.5575, 3.3428, 3.5739, 3.3398],\n",
      "        [3.5079, 3.8982, 3.7440, 3.6881, 3.5986],\n",
      "        [3.6431, 3.6117, 3.6076, 3.9596, 3.7284],\n",
      "        [3.4786, 3.6716, 3.6165, 3.6791, 3.5640],\n",
      "        [3.6136, 3.7766, 3.6050, 3.8819, 3.6706],\n",
      "        [3.4917, 3.7159, 3.6247, 3.6229, 3.6326],\n",
      "        [3.5981, 3.6974, 3.5876, 3.7314, 3.7616],\n",
      "        [3.8106, 3.6609, 3.7889, 3.9382, 3.7580],\n",
      "        [3.4968, 3.5366, 3.5930, 3.6471, 3.5951],\n",
      "        [3.6616, 3.8148, 3.6207, 3.7747, 3.7184],\n",
      "        [3.6779, 3.7116, 3.8845, 3.7267, 3.5639],\n",
      "        [3.5051, 3.7651, 3.6283, 3.6755, 3.4656],\n",
      "        [3.7404, 3.6732, 3.6535, 3.8051, 3.7434],\n",
      "        [3.4727, 3.6043, 3.4641, 3.6548, 3.5241],\n",
      "        [3.4865, 3.6774, 3.6497, 3.6886, 3.4999],\n",
      "        [3.5532, 3.9043, 3.6440, 3.8874, 3.7471],\n",
      "        [3.3894, 3.5785, 3.4423, 3.6217, 3.4556],\n",
      "        [3.5718, 3.6380, 3.6262, 3.7101, 3.5872],\n",
      "        [3.3536, 3.4561, 3.4626, 3.5279, 3.4223],\n",
      "        [3.6355, 3.6703, 3.6722, 3.7977, 3.8047],\n",
      "        [3.5453, 3.5045, 3.5868, 3.6745, 3.4994],\n",
      "        [3.4208, 3.5639, 3.4495, 3.5967, 3.4798],\n",
      "        [3.5595, 3.5973, 3.7074, 3.7391, 3.6258]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5065, 3.5690, 3.6956, 3.7104, 3.6047],\n",
      "        [3.4855, 3.8794, 3.7532, 3.7229, 3.5836],\n",
      "        [3.3719, 3.5103, 3.5328, 3.5637, 3.4645],\n",
      "        [3.5423, 3.6221, 3.5993, 3.7200, 3.6496],\n",
      "        [3.5436, 3.7474, 3.6197, 3.6853, 3.6458],\n",
      "        [3.6397, 3.7047, 3.6645, 3.8479, 3.7845],\n",
      "        [3.4684, 3.8319, 3.6450, 3.7843, 3.7115],\n",
      "        [3.4013, 3.5525, 3.4584, 3.5606, 3.4693],\n",
      "        [3.4718, 3.7569, 3.5683, 3.5027, 3.6197],\n",
      "        [3.6315, 3.7683, 3.6399, 3.7877, 3.6370],\n",
      "        [3.5150, 3.5875, 3.6118, 3.5861, 3.3857],\n",
      "        [4.0783, 4.2774, 3.8684, 4.0269, 3.8364],\n",
      "        [3.4102, 3.5460, 3.4464, 3.5725, 3.4619],\n",
      "        [3.7889, 3.9349, 3.6373, 3.7936, 3.6700],\n",
      "        [3.7032, 3.7903, 3.7878, 3.8509, 3.9080],\n",
      "        [3.4258, 3.4895, 3.6013, 3.6274, 3.5045],\n",
      "        [3.4826, 3.4960, 3.5993, 3.6269, 3.5189],\n",
      "        [3.4222, 3.5693, 3.4515, 3.5956, 3.4807],\n",
      "        [3.5730, 3.6306, 3.6163, 3.7948, 3.5934],\n",
      "        [3.4805, 3.5485, 3.5894, 3.6604, 3.5382],\n",
      "        [3.4273, 3.5664, 3.4924, 3.6081, 3.5191],\n",
      "        [3.3461, 3.5842, 3.5651, 3.5548, 3.4631],\n",
      "        [3.4186, 3.6015, 3.5065, 3.6486, 3.4416],\n",
      "        [3.4770, 3.5193, 3.5742, 3.6356, 3.5246],\n",
      "        [3.6018, 3.8575, 3.7653, 3.8229, 3.8390],\n",
      "        [3.3535, 3.7700, 3.6596, 3.6291, 3.7059],\n",
      "        [3.5451, 3.5835, 3.6929, 3.7226, 3.6120],\n",
      "        [3.6165, 3.6752, 3.6671, 3.7112, 3.4271],\n",
      "        [3.4621, 3.5898, 3.4475, 3.6428, 3.4908],\n",
      "        [3.4725, 3.5861, 3.4963, 3.6660, 3.4994],\n",
      "        [3.4072, 3.4965, 3.5542, 3.6240, 3.4275],\n",
      "        [3.6126, 3.7535, 3.7100, 3.7702, 3.5335],\n",
      "        [3.3597, 3.6156, 3.5811, 3.5798, 3.4980],\n",
      "        [3.6165, 3.6715, 3.5309, 3.8014, 3.7071],\n",
      "        [3.4984, 3.5097, 3.6103, 3.5994, 3.5834],\n",
      "        [3.4212, 3.5564, 3.6384, 3.6173, 3.5574],\n",
      "        [3.4021, 3.4598, 3.5075, 3.5820, 3.4546],\n",
      "        [3.7693, 3.7283, 3.7046, 3.8502, 3.7697],\n",
      "        [3.3878, 3.4985, 3.5433, 3.5257, 3.4551],\n",
      "        [3.5636, 3.5619, 3.6978, 3.7713, 3.6186],\n",
      "        [3.6320, 3.7579, 3.6081, 3.7607, 3.7441],\n",
      "        [3.6489, 3.8098, 3.7353, 3.8596, 3.6766],\n",
      "        [3.4415, 3.4969, 3.4164, 3.5798, 3.5634],\n",
      "        [3.4837, 3.4937, 3.5828, 3.5898, 3.4920],\n",
      "        [3.4307, 3.6061, 3.5684, 3.7371, 3.4659],\n",
      "        [3.4634, 3.4711, 3.5813, 3.6172, 3.4949],\n",
      "        [3.6757, 3.7341, 3.7258, 3.8424, 3.8024],\n",
      "        [3.3811, 3.6493, 3.7476, 3.6527, 3.6005],\n",
      "        [3.3732, 3.4542, 3.5061, 3.5581, 3.4217],\n",
      "        [3.3237, 3.4075, 3.4819, 3.5145, 3.3526],\n",
      "        [3.5120, 3.7049, 3.6044, 3.6521, 3.6301],\n",
      "        [3.5423, 3.7531, 3.7417, 3.8124, 3.6416],\n",
      "        [3.6141, 3.5135, 3.5018, 3.6134, 3.6234],\n",
      "        [3.7230, 3.8412, 3.8552, 4.0286, 4.0368],\n",
      "        [3.5351, 3.7008, 3.5128, 3.6522, 3.5828],\n",
      "        [3.4987, 3.7654, 3.6297, 3.6703, 3.4625],\n",
      "        [3.7938, 3.9043, 3.8132, 3.9307, 3.8875],\n",
      "        [3.4608, 3.5308, 3.7013, 3.5175, 3.6884],\n",
      "        [3.4787, 3.7340, 3.6625, 3.6072, 3.6420],\n",
      "        [3.6525, 3.6333, 3.6362, 3.6629, 3.5056],\n",
      "        [3.3741, 3.4596, 3.5072, 3.5609, 3.4247],\n",
      "        [3.6325, 3.7503, 3.6490, 3.6868, 3.6257],\n",
      "        [3.4887, 3.6181, 3.4613, 3.6815, 3.5236],\n",
      "        [3.4473, 3.5911, 3.5922, 3.6725, 3.4759]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6808, 3.7147, 3.9004, 3.7279, 3.5684],\n",
      "        [3.4595, 3.6022, 3.4627, 3.6347, 3.5107],\n",
      "        [3.4718, 3.6069, 3.4701, 3.6647, 3.5190],\n",
      "        [3.2682, 3.4441, 3.4873, 3.4922, 3.4317],\n",
      "        [3.5315, 3.4989, 3.5727, 3.6210, 3.5741],\n",
      "        [3.8066, 3.8120, 3.8436, 4.0221, 3.8101],\n",
      "        [3.3646, 3.5093, 3.5614, 3.5804, 3.4259],\n",
      "        [3.7807, 3.7147, 3.7036, 3.8684, 3.7703],\n",
      "        [3.3904, 3.4498, 3.3897, 3.6076, 3.3539],\n",
      "        [3.5484, 3.5845, 3.6084, 3.7291, 3.5774],\n",
      "        [3.4854, 3.4813, 3.5754, 3.5843, 3.4729],\n",
      "        [3.5888, 3.5791, 3.6193, 3.6223, 3.4190],\n",
      "        [3.6149, 3.8126, 3.7576, 3.8353, 3.7454],\n",
      "        [3.6413, 3.7608, 3.6459, 3.7462, 3.6396],\n",
      "        [3.4899, 3.7176, 3.6321, 3.6245, 3.6303],\n",
      "        [3.4298, 3.8080, 3.6454, 3.7299, 3.7050],\n",
      "        [3.4909, 3.4866, 3.6218, 3.6700, 3.6302],\n",
      "        [3.5439, 3.7479, 3.6240, 3.7810, 3.5658],\n",
      "        [3.3494, 3.5557, 3.5528, 3.5566, 3.4570],\n",
      "        [3.4969, 3.6367, 3.4712, 3.6985, 3.5341],\n",
      "        [3.7051, 3.9123, 3.7574, 3.9598, 3.7990],\n",
      "        [3.7133, 3.7401, 3.7487, 3.8538, 3.8652],\n",
      "        [3.4344, 3.4234, 3.4993, 3.6078, 3.4108],\n",
      "        [3.3819, 3.6134, 3.6807, 3.6007, 3.5697],\n",
      "        [3.7533, 3.5170, 3.6739, 4.0290, 3.8971],\n",
      "        [3.6818, 3.9546, 3.8490, 3.9013, 3.8343],\n",
      "        [3.7462, 3.7615, 3.7874, 3.9888, 3.9409],\n",
      "        [3.9947, 4.1525, 3.8100, 3.9397, 3.7220],\n",
      "        [3.5626, 3.7902, 3.6579, 3.7743, 3.7454],\n",
      "        [3.4650, 3.4773, 3.5884, 3.6230, 3.4911],\n",
      "        [3.4608, 3.5256, 3.5989, 3.6683, 3.6104],\n",
      "        [3.6210, 3.5262, 3.5192, 3.6285, 3.6324],\n",
      "        [3.3798, 3.5791, 3.5293, 3.7036, 3.4170],\n",
      "        [3.6380, 3.8074, 3.6427, 3.9237, 3.7145],\n",
      "        [3.3369, 3.5399, 3.5453, 3.5480, 3.4325],\n",
      "        [3.3913, 3.4235, 3.4842, 3.5792, 3.4084],\n",
      "        [3.7193, 3.8787, 3.8638, 3.8877, 3.6214],\n",
      "        [3.6517, 3.7420, 3.7278, 3.7820, 3.7613],\n",
      "        [3.6047, 3.9291, 3.7976, 3.8547, 3.8495],\n",
      "        [3.5688, 3.6390, 3.6967, 3.7402, 3.6112],\n",
      "        [3.5060, 3.5124, 3.6427, 3.6994, 3.6461],\n",
      "        [3.4952, 3.5383, 3.6005, 3.6489, 3.5929],\n",
      "        [3.4693, 3.4669, 3.5539, 3.6320, 3.6216],\n",
      "        [3.4675, 3.6738, 3.6162, 3.6751, 3.5706],\n",
      "        [3.5796, 3.6925, 3.7960, 3.7770, 3.6792],\n",
      "        [3.4984, 3.5310, 3.6073, 3.6503, 3.5400],\n",
      "        [3.4840, 3.5438, 3.5930, 3.6558, 3.5411],\n",
      "        [3.5253, 3.5052, 3.7087, 3.7582, 3.5628],\n",
      "        [3.5068, 3.6445, 3.4840, 3.7129, 3.5450],\n",
      "        [3.3500, 3.5935, 3.5706, 3.5607, 3.4719],\n",
      "        [3.5700, 3.8035, 3.6505, 3.8673, 3.6640],\n",
      "        [3.3750, 3.3946, 3.4638, 3.5623, 3.3841],\n",
      "        [3.3731, 3.4603, 3.5115, 3.5617, 3.4235],\n",
      "        [3.4743, 3.6056, 3.4639, 3.6569, 3.5210],\n",
      "        [3.4646, 3.5962, 3.5832, 3.6924, 3.6094],\n",
      "        [3.4961, 3.4622, 3.5638, 3.5631, 3.4510],\n",
      "        [3.3453, 3.6231, 3.4150, 3.6157, 3.3933],\n",
      "        [3.5197, 3.5163, 3.6554, 3.7176, 3.6514],\n",
      "        [3.3894, 3.4521, 3.3861, 3.6095, 3.3422],\n",
      "        [3.4650, 3.6225, 3.5997, 3.7562, 3.5104],\n",
      "        [3.2964, 3.4714, 3.4322, 3.4496, 3.3981],\n",
      "        [3.6512, 3.7036, 3.7846, 3.7675, 3.5408],\n",
      "        [3.7271, 3.9361, 3.7453, 3.9488, 3.8536],\n",
      "        [3.8540, 3.7896, 3.8844, 4.0975, 3.8353]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5224, 3.8625, 3.7411, 3.7318, 3.5531],\n",
      "        [3.3464, 3.5873, 3.5730, 3.5684, 3.4691],\n",
      "        [3.4880, 3.5696, 3.5292, 3.6725, 3.5028],\n",
      "        [3.6389, 3.7655, 3.6591, 3.7462, 3.6361],\n",
      "        [3.3790, 3.4753, 3.5315, 3.5775, 3.4418],\n",
      "        [3.3797, 3.4470, 3.5074, 3.5664, 3.4164],\n",
      "        [3.7670, 3.5061, 3.6819, 4.0522, 3.8993],\n",
      "        [3.4087, 3.5368, 3.6122, 3.6893, 3.5602],\n",
      "        [3.4833, 3.5813, 3.6068, 3.6597, 3.6920],\n",
      "        [3.4226, 3.5225, 3.3546, 3.6708, 3.3564],\n",
      "        [3.6154, 3.8076, 3.7619, 3.8415, 3.7277],\n",
      "        [4.0769, 4.2545, 3.8981, 4.0212, 3.7974],\n",
      "        [3.7750, 3.6693, 3.7908, 3.9532, 3.7155],\n",
      "        [3.4300, 3.6241, 3.5135, 3.7191, 3.4705],\n",
      "        [3.4302, 3.5352, 3.4955, 3.6814, 3.4965],\n",
      "        [3.3079, 3.4808, 3.4436, 3.4646, 3.4163],\n",
      "        [3.3464, 3.5036, 3.5357, 3.5480, 3.4265],\n",
      "        [3.4808, 3.4986, 3.6083, 3.6287, 3.5166],\n",
      "        [3.4809, 3.7639, 3.6308, 3.6642, 3.4548],\n",
      "        [3.9021, 3.6860, 3.7933, 4.2591, 4.0771],\n",
      "        [3.3731, 3.5527, 3.5947, 3.5996, 3.4595],\n",
      "        [3.4902, 3.6284, 3.4767, 3.6867, 3.5308],\n",
      "        [3.4690, 3.7659, 3.6276, 3.6545, 3.4519],\n",
      "        [3.4268, 3.5768, 3.4620, 3.6035, 3.4838],\n",
      "        [3.5803, 3.7931, 3.6687, 3.8778, 3.6624],\n",
      "        [3.4846, 3.7284, 3.6559, 3.6182, 3.6370],\n",
      "        [3.4371, 3.5775, 3.4533, 3.6222, 3.4771],\n",
      "        [3.4928, 3.4443, 3.5477, 3.5271, 3.4253],\n",
      "        [3.5617, 3.5646, 3.7070, 3.7732, 3.6163],\n",
      "        [3.5141, 3.5423, 3.6221, 3.6406, 3.5861],\n",
      "        [3.5903, 3.8087, 3.7888, 3.8064, 3.6094],\n",
      "        [3.3080, 3.4833, 3.4409, 3.4706, 3.4080],\n",
      "        [3.6174, 3.6072, 3.6889, 3.7732, 3.5887],\n",
      "        [3.4762, 3.6149, 3.4722, 3.6740, 3.5174],\n",
      "        [3.3916, 3.4177, 3.4858, 3.5936, 3.4172],\n",
      "        [3.3791, 3.6521, 3.7569, 3.6546, 3.5982],\n",
      "        [3.6684, 3.8145, 3.7380, 3.7113, 3.6953],\n",
      "        [3.7111, 3.5943, 3.6495, 4.0430, 3.7802],\n",
      "        [3.4341, 3.7220, 3.6345, 3.6900, 3.7058],\n",
      "        [3.3797, 3.4213, 3.4857, 3.5734, 3.3993],\n",
      "        [3.6722, 3.7132, 3.7210, 3.8448, 3.8353],\n",
      "        [3.4043, 3.5541, 3.4638, 3.5793, 3.4816],\n",
      "        [3.6189, 3.7431, 3.6087, 3.7427, 3.7452],\n",
      "        [3.5563, 3.6064, 3.6146, 3.7603, 3.5789],\n",
      "        [3.4343, 3.4225, 3.4812, 3.5838, 3.4033],\n",
      "        [3.7350, 3.9471, 3.7666, 3.9603, 3.8679],\n",
      "        [3.4826, 3.5211, 3.5894, 3.6435, 3.5281],\n",
      "        [3.6471, 3.8126, 3.7446, 3.8615, 3.6742],\n",
      "        [3.7070, 3.7301, 3.7783, 3.9309, 3.6886],\n",
      "        [3.4226, 3.4800, 3.6123, 3.6243, 3.4902],\n",
      "        [3.6370, 3.8094, 3.6474, 3.9250, 3.7133],\n",
      "        [3.6692, 3.7252, 3.7245, 3.8588, 3.8118],\n",
      "        [3.6917, 3.8686, 3.6286, 3.7629, 3.6753],\n",
      "        [3.5016, 3.5508, 3.6835, 3.6874, 3.5930],\n",
      "        [3.3411, 3.5443, 3.5496, 3.5466, 3.4371],\n",
      "        [3.7195, 3.6237, 3.6432, 3.7678, 3.6957],\n",
      "        [3.4930, 3.7660, 3.5612, 3.7964, 3.6124],\n",
      "        [3.6489, 3.8565, 3.6989, 3.8177, 3.6950],\n",
      "        [3.3984, 3.3805, 3.5746, 3.4095, 3.5447],\n",
      "        [3.4974, 3.5378, 3.6163, 3.6583, 3.5855],\n",
      "        [3.3666, 3.4538, 3.5088, 3.5546, 3.4165],\n",
      "        [3.6526, 3.7155, 3.7062, 3.7858, 3.7734],\n",
      "        [3.3561, 3.4818, 3.5241, 3.5498, 3.4234],\n",
      "        [3.3485, 3.4006, 3.4796, 3.5553, 3.4084]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4656, 3.8363, 3.6581, 3.7870, 3.7077],\n",
      "        [3.5610, 3.5458, 3.6227, 3.6603, 3.6086],\n",
      "        [3.5509, 3.7131, 3.7036, 3.8113, 3.6660],\n",
      "        [3.4826, 3.6901, 3.5842, 3.6854, 3.6088],\n",
      "        [3.4306, 3.5463, 3.5874, 3.6918, 3.5215],\n",
      "        [3.8995, 4.0661, 3.8331, 3.8854, 3.7782],\n",
      "        [3.4858, 3.6223, 3.4741, 3.6843, 3.5200],\n",
      "        [3.9086, 3.9730, 3.8801, 4.2293, 3.9397],\n",
      "        [3.3454, 3.5052, 3.5397, 3.5488, 3.4253],\n",
      "        [3.6093, 3.9127, 3.8034, 3.8377, 3.7836],\n",
      "        [3.4861, 3.6836, 3.5456, 3.7955, 3.4885],\n",
      "        [3.5615, 3.5167, 3.8457, 3.7405, 3.6585],\n",
      "        [3.4452, 3.5061, 3.5899, 3.6151, 3.5055],\n",
      "        [3.3113, 3.4924, 3.4569, 3.4741, 3.4183],\n",
      "        [3.5810, 3.5753, 3.6611, 3.6346, 3.5181],\n",
      "        [3.4519, 3.5102, 3.5452, 3.6772, 3.4596],\n",
      "        [3.7554, 3.8557, 3.7353, 3.8952, 3.8299],\n",
      "        [3.6377, 3.7021, 3.7711, 3.7498, 3.4956],\n",
      "        [3.3777, 3.4269, 3.4964, 3.5692, 3.4023],\n",
      "        [3.3400, 3.5782, 3.5693, 3.5518, 3.4511],\n",
      "        [3.4762, 3.6590, 3.6492, 3.6677, 3.6772],\n",
      "        [3.4754, 3.6135, 3.4704, 3.6777, 3.5178],\n",
      "        [3.4983, 3.5769, 3.7123, 3.7973, 3.7420],\n",
      "        [3.4769, 3.5504, 3.6018, 3.6616, 3.5327],\n",
      "        [3.3380, 3.5479, 3.5558, 3.5513, 3.4365],\n",
      "        [3.7713, 3.8219, 3.7375, 3.9176, 3.8502],\n",
      "        [3.6253, 3.7422, 3.6392, 3.8144, 3.6557],\n",
      "        [3.3053, 3.4975, 3.4896, 3.5450, 3.4457],\n",
      "        [3.8684, 3.9868, 3.9014, 4.1859, 3.9323],\n",
      "        [3.4251, 3.4380, 3.5159, 3.5996, 3.4096],\n",
      "        [3.3400, 3.5782, 3.5693, 3.5518, 3.4511],\n",
      "        [3.4557, 3.5814, 3.5836, 3.6749, 3.6213],\n",
      "        [3.4858, 3.6223, 3.4741, 3.6843, 3.5200],\n",
      "        [3.4711, 3.6080, 3.4628, 3.6662, 3.4989],\n",
      "        [3.4656, 3.4995, 3.6012, 3.6373, 3.5043],\n",
      "        [3.4083, 3.5696, 3.4702, 3.5861, 3.4791],\n",
      "        [3.4278, 3.8117, 3.6541, 3.7318, 3.7024],\n",
      "        [3.6203, 3.7918, 3.7592, 3.8371, 3.6944],\n",
      "        [3.4271, 3.5247, 3.5862, 3.6493, 3.5151],\n",
      "        [3.4956, 3.5139, 3.6238, 3.6021, 3.5797],\n",
      "        [3.6662, 3.8527, 3.6321, 3.7531, 3.6724],\n",
      "        [3.7465, 3.7615, 3.7882, 3.9975, 3.9381],\n",
      "        [3.4815, 3.5293, 3.5997, 3.6474, 3.5275],\n",
      "        [3.8119, 3.6648, 3.8184, 3.9838, 3.7553],\n",
      "        [3.6144, 3.8093, 3.7661, 3.8423, 3.7264],\n",
      "        [3.4926, 3.5831, 3.6771, 3.6191, 3.6901],\n",
      "        [3.5807, 3.6526, 3.6350, 3.8282, 3.5909],\n",
      "        [3.5639, 3.6265, 3.6246, 3.7888, 3.5810],\n",
      "        [3.3389, 3.5627, 3.5605, 3.5497, 3.4424],\n",
      "        [3.5624, 3.8345, 3.7040, 3.7948, 3.7595],\n",
      "        [3.4309, 3.5030, 3.6126, 3.6341, 3.5053],\n",
      "        [3.7277, 3.8540, 3.8783, 4.0538, 4.0325],\n",
      "        [3.4796, 3.5118, 3.6066, 3.6425, 3.5104],\n",
      "        [3.4593, 3.5940, 3.4603, 3.6456, 3.4872],\n",
      "        [3.7087, 3.7632, 3.8997, 3.7738, 3.5427],\n",
      "        [3.4863, 3.6255, 3.4738, 3.6809, 3.5159],\n",
      "        [3.3210, 3.4116, 3.4948, 3.5174, 3.3492],\n",
      "        [3.5745, 3.8295, 3.7704, 3.7620, 3.7002],\n",
      "        [3.4295, 3.5693, 3.4592, 3.6054, 3.4701],\n",
      "        [3.5124, 3.4742, 3.5827, 3.5623, 3.4550],\n",
      "        [3.4724, 3.6090, 3.4724, 3.6590, 3.5186],\n",
      "        [3.6928, 3.6040, 3.6350, 3.7524, 3.6653],\n",
      "        [4.0823, 4.2928, 3.8871, 4.0387, 3.8412],\n",
      "        [3.5870, 3.5827, 3.6276, 3.6244, 3.4166]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6453, 3.8273, 3.6277, 3.7708, 3.6922],\n",
      "        [3.3790, 3.6536, 3.7646, 3.6573, 3.5917],\n",
      "        [3.4849, 3.8175, 3.7372, 3.7724, 3.7472],\n",
      "        [3.3829, 3.4048, 3.4786, 3.5753, 3.3941],\n",
      "        [3.4294, 3.3948, 3.4589, 3.5770, 3.3806],\n",
      "        [3.4786, 3.6109, 3.5661, 3.6330, 3.5438],\n",
      "        [3.6453, 3.6723, 3.7386, 3.8792, 3.5686],\n",
      "        [3.4826, 3.4780, 3.6049, 3.6646, 3.6207],\n",
      "        [3.4792, 3.6854, 3.5776, 3.6935, 3.6088],\n",
      "        [3.4941, 3.5299, 3.6216, 3.6499, 3.5298],\n",
      "        [3.4277, 3.5340, 3.5882, 3.6558, 3.5133],\n",
      "        [3.4321, 3.8092, 3.6648, 3.7248, 3.7191],\n",
      "        [3.8013, 3.8336, 3.8321, 4.0402, 3.7484],\n",
      "        [3.4603, 3.7744, 3.6300, 3.6479, 3.4571],\n",
      "        [3.4559, 3.6019, 3.4695, 3.6544, 3.4956],\n",
      "        [3.5910, 3.7246, 3.7127, 3.8230, 3.7225],\n",
      "        [3.6192, 3.6165, 3.6485, 3.6290, 3.4546],\n",
      "        [3.5281, 3.5751, 3.6164, 3.6958, 3.5725],\n",
      "        [3.5072, 3.6505, 3.4990, 3.7147, 3.5462],\n",
      "        [3.3833, 3.4222, 3.4931, 3.5800, 3.4013],\n",
      "        [3.4761, 3.6320, 3.6181, 3.6182, 3.4548],\n",
      "        [3.5338, 3.5107, 3.5914, 3.6347, 3.5807],\n",
      "        [3.5978, 3.8636, 3.7829, 3.8260, 3.8338],\n",
      "        [3.4966, 3.5168, 3.6297, 3.6062, 3.5774],\n",
      "        [4.0495, 4.2743, 3.9042, 4.0544, 3.8023],\n",
      "        [3.4976, 3.6314, 3.6372, 3.6558, 3.4582],\n",
      "        [3.5373, 3.8015, 3.6245, 3.8488, 3.6489],\n",
      "        [3.8095, 3.8227, 3.8547, 4.0110, 3.8139],\n",
      "        [3.7139, 3.8217, 3.8318, 3.8692, 3.9288],\n",
      "        [3.5562, 3.7622, 3.6793, 3.7311, 3.4939],\n",
      "        [3.5817, 3.5751, 3.6660, 3.6306, 3.5306],\n",
      "        [3.6413, 3.8085, 3.6851, 3.8326, 3.6778],\n",
      "        [3.9001, 3.6890, 3.8013, 4.2604, 4.0744],\n",
      "        [3.4538, 3.4512, 3.5394, 3.6030, 3.6029],\n",
      "        [3.6055, 3.6686, 3.7141, 3.7163, 3.7432],\n",
      "        [3.7727, 3.8240, 3.8202, 3.9236, 3.9719],\n",
      "        [3.7036, 3.8668, 3.7741, 3.7308, 3.7317],\n",
      "        [3.7332, 3.8055, 3.8175, 3.8663, 3.8186],\n",
      "        [3.3555, 3.5787, 3.5760, 3.5765, 3.4727],\n",
      "        [3.4716, 3.6204, 3.6139, 3.6089, 3.4530],\n",
      "        [3.4871, 3.7225, 3.6444, 3.6267, 3.6263],\n",
      "        [3.6220, 3.7412, 3.6351, 3.8146, 3.6458],\n",
      "        [3.2581, 3.4322, 3.4205, 3.4107, 3.3526],\n",
      "        [3.5197, 3.5475, 3.6625, 3.6632, 3.5491],\n",
      "        [3.4191, 3.7997, 3.6484, 3.7270, 3.6949],\n",
      "        [3.9244, 4.0893, 3.8284, 3.9181, 3.7511],\n",
      "        [3.3770, 3.4780, 3.5390, 3.5786, 3.4391],\n",
      "        [3.6368, 3.7882, 3.7653, 3.8378, 3.6731],\n",
      "        [3.8296, 3.7784, 3.7834, 4.0287, 3.7802],\n",
      "        [3.7049, 3.7667, 3.7357, 3.9057, 3.8352],\n",
      "        [3.6776, 3.7198, 3.9129, 3.7302, 3.5640],\n",
      "        [3.6917, 3.5222, 3.6828, 3.9518, 3.8357],\n",
      "        [3.5213, 3.7323, 3.6290, 3.6926, 3.6294],\n",
      "        [3.4475, 3.5112, 3.5490, 3.6711, 3.4503],\n",
      "        [3.4206, 3.4828, 3.6198, 3.6254, 3.4876],\n",
      "        [3.4696, 3.4786, 3.6280, 3.5366, 3.5813],\n",
      "        [3.4683, 3.6570, 3.5282, 3.7711, 3.4685],\n",
      "        [3.6009, 3.7260, 3.6333, 3.6412, 3.5910],\n",
      "        [3.5009, 3.6481, 3.4824, 3.7116, 3.5391],\n",
      "        [3.6622, 3.8835, 3.8609, 3.8704, 3.5940],\n",
      "        [3.6148, 3.8317, 3.7712, 3.8388, 3.7591],\n",
      "        [3.5250, 3.5763, 3.6865, 3.7304, 3.6041],\n",
      "        [3.3655, 3.6318, 3.6060, 3.5878, 3.5049],\n",
      "        [3.3461, 3.4337, 3.5061, 3.5312, 3.3964]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4247, 3.5980, 3.6802, 3.7042, 3.6510],\n",
      "        [3.5668, 3.6574, 3.5836, 3.7693, 3.6082],\n",
      "        [3.3585, 3.4792, 3.5348, 3.5624, 3.4293],\n",
      "        [3.5352, 3.6132, 3.6910, 3.7313, 3.6887],\n",
      "        [3.6263, 3.6209, 3.6487, 3.6369, 3.4677],\n",
      "        [3.4823, 3.4723, 3.5806, 3.5706, 3.4513],\n",
      "        [3.4739, 3.5307, 3.5945, 3.6425, 3.5202],\n",
      "        [3.5232, 3.8964, 3.7089, 3.8445, 3.7556],\n",
      "        [3.6482, 3.6403, 3.6560, 3.6664, 3.4995],\n",
      "        [3.8182, 3.9691, 3.6655, 3.8141, 3.6626],\n",
      "        [3.7848, 3.7584, 3.7846, 3.9153, 3.7793],\n",
      "        [3.4277, 3.5776, 3.4705, 3.6038, 3.4875],\n",
      "        [3.3778, 3.4168, 3.4902, 3.5846, 3.3974],\n",
      "        [3.5900, 3.7264, 3.7157, 3.8230, 3.7210],\n",
      "        [3.4836, 3.5222, 3.5385, 3.7034, 3.4648],\n",
      "        [3.3905, 3.4605, 3.4105, 3.6131, 3.3716],\n",
      "        [3.4837, 3.4852, 3.6229, 3.6642, 3.6200],\n",
      "        [3.5029, 3.6508, 3.4989, 3.7154, 3.5397],\n",
      "        [3.5055, 3.7212, 3.6026, 3.6357, 3.6079],\n",
      "        [3.5209, 3.6899, 3.4907, 3.6383, 3.5462],\n",
      "        [3.6382, 3.7654, 3.6683, 3.7373, 3.6276],\n",
      "        [3.6627, 3.7746, 3.7946, 3.9460, 3.6418],\n",
      "        [3.3805, 3.4241, 3.4982, 3.5793, 3.4022],\n",
      "        [3.6791, 3.7688, 3.7465, 3.8507, 3.7862],\n",
      "        [3.5452, 3.5377, 3.6291, 3.6622, 3.6006],\n",
      "        [3.6108, 3.7508, 3.6177, 3.7393, 3.7463],\n",
      "        [3.7476, 3.7510, 3.8002, 3.9396, 3.7289],\n",
      "        [3.5533, 3.5953, 3.7160, 3.7408, 3.6137],\n",
      "        [3.9585, 4.1294, 3.8786, 3.9455, 3.7988],\n",
      "        [3.2515, 3.4442, 3.5037, 3.4779, 3.4298],\n",
      "        [3.9730, 3.7285, 3.8798, 4.3539, 4.1474],\n",
      "        [3.5215, 3.5115, 3.7238, 3.7606, 3.5575],\n",
      "        [3.3369, 3.5655, 3.5670, 3.5502, 3.4397],\n",
      "        [3.4018, 3.5541, 3.4618, 3.5736, 3.4561],\n",
      "        [3.3414, 3.3984, 3.4854, 3.5475, 3.4052],\n",
      "        [3.5775, 3.7976, 3.6794, 3.8790, 3.6583],\n",
      "        [3.5252, 3.7519, 3.6470, 3.6874, 3.6371],\n",
      "        [3.4726, 3.4735, 3.5813, 3.6483, 3.6220],\n",
      "        [3.6154, 3.7477, 3.7721, 3.7752, 3.6486],\n",
      "        [3.5240, 3.5779, 3.6896, 3.7304, 3.6027],\n",
      "        [3.4257, 3.6138, 3.5874, 3.7399, 3.4593],\n",
      "        [3.4729, 3.6800, 3.6391, 3.6830, 3.5563],\n",
      "        [3.6118, 3.7399, 3.6873, 3.7566, 3.7020],\n",
      "        [3.4878, 3.4910, 3.6256, 3.6676, 3.6264],\n",
      "        [3.4100, 3.5669, 3.4798, 3.5758, 3.4882],\n",
      "        [3.4752, 3.6336, 3.6211, 3.6182, 3.4534],\n",
      "        [3.6952, 3.8325, 3.8290, 3.8229, 3.5644],\n",
      "        [3.4873, 3.6328, 3.4871, 3.6880, 3.5267],\n",
      "        [3.6344, 3.7877, 3.7588, 3.7678, 3.5188],\n",
      "        [3.6653, 3.8081, 3.7929, 3.7942, 3.5423],\n",
      "        [3.3735, 3.4450, 3.5090, 3.5679, 3.4090],\n",
      "        [3.5790, 3.5781, 3.6678, 3.6350, 3.5152],\n",
      "        [3.6441, 3.7247, 3.7830, 3.7546, 3.4816],\n",
      "        [3.6352, 3.7119, 3.6862, 3.8512, 3.7780],\n",
      "        [3.4275, 3.5720, 3.4656, 3.6059, 3.4675],\n",
      "        [3.4793, 3.4875, 3.6013, 3.6555, 3.6316],\n",
      "        [3.3617, 3.4547, 3.5177, 3.5558, 3.4084],\n",
      "        [3.4806, 3.7228, 3.6376, 3.8380, 3.5520],\n",
      "        [3.4962, 3.8661, 3.6366, 3.8618, 3.6906],\n",
      "        [3.5663, 3.8100, 3.6659, 3.8697, 3.6587],\n",
      "        [3.5001, 3.6401, 3.5788, 3.7405, 3.5903],\n",
      "        [3.6183, 3.7949, 3.7660, 3.8374, 3.6916],\n",
      "        [3.5359, 3.5812, 3.7014, 3.7174, 3.6008],\n",
      "        [3.7011, 3.8267, 3.6829, 3.8172, 3.7921]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4970, 3.4607, 3.5758, 3.5420, 3.4310],\n",
      "        [3.3425, 3.5099, 3.5506, 3.5491, 3.4212],\n",
      "        [3.4198, 3.5405, 3.5890, 3.6842, 3.5052],\n",
      "        [3.5300, 3.5812, 3.6896, 3.6967, 3.6079],\n",
      "        [3.6593, 3.8656, 3.8097, 3.8436, 3.6710],\n",
      "        [3.4733, 3.6773, 3.6461, 3.6855, 3.5486],\n",
      "        [3.3359, 3.5674, 3.5715, 3.5500, 3.4383],\n",
      "        [3.4463, 3.4668, 3.5954, 3.6106, 3.4762],\n",
      "        [3.7964, 3.8578, 3.7618, 3.9185, 3.8716],\n",
      "        [3.9477, 4.1263, 3.8052, 3.9189, 3.6939],\n",
      "        [3.6169, 3.5341, 3.5393, 3.6310, 3.6262],\n",
      "        [3.6870, 3.7694, 3.7435, 3.8884, 3.8326],\n",
      "        [3.5965, 3.7064, 3.6149, 3.7356, 3.7369],\n",
      "        [3.7498, 3.7579, 3.7101, 3.8579, 3.7201],\n",
      "        [3.7143, 3.8884, 3.8837, 3.8904, 3.6143],\n",
      "        [3.3711, 3.3974, 3.4852, 3.5697, 3.3743],\n",
      "        [3.6850, 3.8800, 3.7569, 3.7134, 3.7207],\n",
      "        [3.6478, 3.8219, 3.6444, 3.7749, 3.7054],\n",
      "        [3.4267, 3.5796, 3.4749, 3.6036, 3.4861],\n",
      "        [3.6580, 3.7858, 3.7113, 3.7953, 3.7466],\n",
      "        [3.5133, 3.7094, 3.5645, 3.8298, 3.5005],\n",
      "        [3.6108, 3.6339, 3.6041, 3.8745, 3.6637],\n",
      "        [3.4939, 3.5794, 3.6903, 3.6219, 3.6888],\n",
      "        [3.2844, 3.4690, 3.4489, 3.4419, 3.3916],\n",
      "        [3.4920, 3.5056, 3.6388, 3.6631, 3.6004],\n",
      "        [3.6617, 3.7767, 3.7993, 3.9457, 3.6403],\n",
      "        [3.4306, 3.5576, 3.5094, 3.5629, 3.4634],\n",
      "        [3.5804, 3.5771, 3.7758, 3.8186, 3.5585],\n",
      "        [3.3674, 3.4631, 3.5298, 3.5609, 3.4140],\n",
      "        [3.6431, 3.7269, 3.7874, 3.7545, 3.4801],\n",
      "        [3.4984, 3.5518, 3.6359, 3.6630, 3.5874],\n",
      "        [3.6979, 3.9178, 3.7431, 3.6927, 3.6758],\n",
      "        [3.4630, 3.8991, 3.7745, 3.7012, 3.5688],\n",
      "        [3.6994, 3.8653, 3.8443, 3.8180, 3.5136],\n",
      "        [3.4789, 3.6311, 3.4911, 3.6818, 3.5186],\n",
      "        [3.3026, 3.5669, 3.3695, 3.5778, 3.3320],\n",
      "        [3.4663, 3.5840, 3.5375, 3.6786, 3.5009],\n",
      "        [3.3617, 3.5523, 3.6060, 3.5862, 3.4569],\n",
      "        [3.8625, 3.9501, 3.8404, 4.1827, 3.8970],\n",
      "        [3.9228, 4.0929, 3.8363, 3.9179, 3.7483],\n",
      "        [3.4620, 3.7593, 3.7212, 3.6176, 3.6235],\n",
      "        [3.4897, 3.5879, 3.6890, 3.6192, 3.6859],\n",
      "        [3.6005, 3.7383, 3.6234, 3.7367, 3.7463],\n",
      "        [3.8417, 3.8407, 3.8242, 3.9944, 3.8422],\n",
      "        [3.4104, 3.5799, 3.4889, 3.5921, 3.4778],\n",
      "        [3.4982, 3.5510, 3.6432, 3.6671, 3.5779],\n",
      "        [3.3430, 3.5345, 3.4846, 3.5646, 3.4197],\n",
      "        [3.9862, 4.1589, 3.9040, 3.9769, 3.8136],\n",
      "        [3.4865, 3.6828, 3.6694, 3.6910, 3.4984],\n",
      "        [3.4358, 3.5382, 3.5668, 3.5775, 3.4953],\n",
      "        [3.8047, 3.6719, 3.8178, 3.9429, 3.7494],\n",
      "        [3.5398, 3.8537, 3.8185, 3.8370, 3.7567],\n",
      "        [3.3368, 3.5102, 3.5452, 3.5454, 3.4209],\n",
      "        [3.7562, 3.6689, 3.8026, 3.9531, 3.6999],\n",
      "        [3.4911, 3.6329, 3.4839, 3.6929, 3.5161],\n",
      "        [3.5947, 3.6519, 3.7709, 3.7962, 3.6011],\n",
      "        [3.6031, 3.6111, 3.6885, 3.7522, 3.5680],\n",
      "        [3.6044, 3.4678, 3.5247, 3.6442, 3.5620],\n",
      "        [4.1243, 4.3120, 3.9753, 4.1051, 3.8378],\n",
      "        [3.8448, 3.9964, 3.6718, 3.8297, 3.6577],\n",
      "        [3.6138, 3.7668, 3.6510, 3.7534, 3.6402],\n",
      "        [3.5842, 3.5878, 3.6382, 3.6248, 3.4124],\n",
      "        [3.4813, 3.4743, 3.5852, 3.5704, 3.4498],\n",
      "        [3.3321, 3.5481, 3.5650, 3.5503, 3.4261]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8619, 3.6845, 3.8222, 4.3191, 4.0438],\n",
      "        [3.4170, 3.5760, 3.4797, 3.6021, 3.4698],\n",
      "        [3.3799, 3.4611, 3.5273, 3.5715, 3.4127],\n",
      "        [3.5186, 3.5706, 3.7048, 3.7261, 3.5987],\n",
      "        [3.4763, 3.6175, 3.4801, 3.6675, 3.4962],\n",
      "        [3.6734, 3.7459, 3.7571, 3.8468, 3.7929],\n",
      "        [3.4188, 3.5212, 3.5954, 3.6469, 3.5010],\n",
      "        [3.6961, 3.7680, 3.8255, 3.8171, 3.7565],\n",
      "        [3.4822, 3.7276, 3.6458, 3.8388, 3.5489],\n",
      "        [3.5683, 3.6518, 3.6540, 3.7202, 3.5749],\n",
      "        [3.6861, 3.6667, 3.7515, 3.8625, 3.6341],\n",
      "        [3.4244, 3.5776, 3.5199, 3.6125, 3.5101],\n",
      "        [3.2531, 3.4485, 3.5119, 3.4787, 3.4269],\n",
      "        [3.6178, 3.9492, 3.7954, 3.8663, 3.8595],\n",
      "        [3.4632, 3.7991, 3.7402, 3.7513, 3.7003],\n",
      "        [3.3688, 3.5432, 3.4759, 3.5454, 3.4418],\n",
      "        [3.4745, 3.5907, 3.7210, 3.7681, 3.6997],\n",
      "        [3.4257, 3.4202, 3.6176, 3.4459, 3.5615],\n",
      "        [3.5271, 3.7661, 3.6463, 3.8397, 3.5573],\n",
      "        [3.7030, 3.8314, 3.6913, 3.8180, 3.7890],\n",
      "        [3.3400, 3.5530, 3.5685, 3.5489, 3.4304],\n",
      "        [3.8365, 3.6948, 3.8346, 4.2987, 4.0579],\n",
      "        [3.4328, 3.6565, 3.6162, 3.5460, 3.4610],\n",
      "        [3.5044, 3.5663, 3.6649, 3.7047, 3.5696],\n",
      "        [3.4987, 3.6372, 3.6488, 3.6569, 3.4539],\n",
      "        [3.6135, 3.7525, 3.7793, 3.7243, 3.5221],\n",
      "        [3.5013, 3.5541, 3.6399, 3.6642, 3.5859],\n",
      "        [3.3774, 3.5907, 3.5518, 3.7064, 3.4087],\n",
      "        [3.5775, 3.7035, 3.8200, 3.7803, 3.6707],\n",
      "        [3.3497, 3.5180, 3.4680, 3.5162, 3.4224],\n",
      "        [3.4471, 3.6021, 3.4829, 3.6411, 3.4863],\n",
      "        [3.2349, 3.4304, 3.5053, 3.4589, 3.4119],\n",
      "        [3.3459, 3.5491, 3.5714, 3.5643, 3.4462],\n",
      "        [3.3492, 3.5223, 3.4766, 3.5205, 3.4479],\n",
      "        [3.3069, 3.4917, 3.4595, 3.4730, 3.4015],\n",
      "        [3.6474, 3.6939, 3.7611, 3.8471, 3.5028],\n",
      "        [3.8480, 3.9988, 3.6758, 3.8308, 3.6562],\n",
      "        [3.5228, 3.9056, 3.6687, 3.8817, 3.7175],\n",
      "        [3.9510, 4.1286, 3.8093, 3.9200, 3.6924],\n",
      "        [3.4709, 3.6210, 3.4840, 3.6743, 3.5027],\n",
      "        [3.4484, 3.5026, 3.6011, 3.6031, 3.4871],\n",
      "        [3.5440, 3.5268, 3.6247, 3.6926, 3.5020],\n",
      "        [3.4834, 3.5699, 3.6236, 3.6816, 3.5435],\n",
      "        [3.7544, 3.7138, 3.7073, 3.8320, 3.7499],\n",
      "        [3.4330, 3.8153, 3.6760, 3.7256, 3.7147],\n",
      "        [3.3947, 3.4365, 3.5112, 3.5868, 3.4025],\n",
      "        [3.6630, 3.8905, 3.8723, 3.8717, 3.5895],\n",
      "        [3.4963, 3.5417, 3.6309, 3.6533, 3.5318],\n",
      "        [3.5696, 3.8278, 3.6570, 3.5805, 3.6454],\n",
      "        [3.5387, 3.5445, 3.6624, 3.6756, 3.5955],\n",
      "        [3.4891, 3.5371, 3.6248, 3.6511, 3.5231],\n",
      "        [3.3840, 3.4280, 3.5041, 3.5808, 3.3970],\n",
      "        [3.4796, 3.8096, 3.7051, 3.7792, 3.7211],\n",
      "        [3.3783, 3.5884, 3.4688, 3.6232, 3.4413],\n",
      "        [3.5027, 3.6196, 3.4648, 3.6981, 3.4227],\n",
      "        [3.5483, 3.5982, 3.7235, 3.7625, 3.5559],\n",
      "        [3.3480, 3.6042, 3.5945, 3.5642, 3.4641],\n",
      "        [3.6194, 3.8136, 3.7502, 3.9185, 3.6562],\n",
      "        [3.4040, 3.5988, 3.6895, 3.6433, 3.5927],\n",
      "        [3.6099, 3.7064, 3.5981, 3.8001, 3.6597],\n",
      "        [3.5287, 3.6500, 3.6497, 3.6890, 3.5724],\n",
      "        [3.6479, 3.8549, 3.7909, 3.8453, 3.6734],\n",
      "        [3.6163, 3.6879, 3.6970, 3.7178, 3.4188],\n",
      "        [3.6963, 3.7316, 3.7868, 3.9201, 3.6878]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6306, 3.7851, 3.6600, 3.7468, 3.6415],\n",
      "        [3.5064, 3.5481, 3.6553, 3.6279, 3.5233],\n",
      "        [3.6852, 3.7761, 3.7610, 3.8534, 3.7816],\n",
      "        [3.6400, 3.7849, 3.6783, 3.7759, 3.6298],\n",
      "        [3.6535, 3.8523, 3.7933, 3.8374, 3.6543],\n",
      "        [3.4196, 3.7515, 3.5962, 3.5861, 3.4192],\n",
      "        [3.5323, 3.5783, 3.7012, 3.7081, 3.5877],\n",
      "        [3.4786, 3.5308, 3.6191, 3.6512, 3.5185],\n",
      "        [3.4736, 3.6153, 3.4947, 3.6471, 3.5147],\n",
      "        [3.3777, 3.5691, 3.5210, 3.6403, 3.4427],\n",
      "        [3.5332, 3.7135, 3.5490, 3.6478, 3.5671],\n",
      "        [3.6827, 3.8261, 3.7023, 3.8993, 3.8594],\n",
      "        [3.5637, 3.5299, 3.8755, 3.7496, 3.6640],\n",
      "        [3.5015, 3.8730, 3.6495, 3.8641, 3.6860],\n",
      "        [3.3512, 3.6194, 3.6080, 3.5654, 3.4669],\n",
      "        [3.3722, 3.5242, 3.5649, 3.5693, 3.4538],\n",
      "        [3.6440, 3.6330, 3.6669, 3.6528, 3.4726],\n",
      "        [3.3749, 3.4364, 3.5109, 3.5700, 3.3911],\n",
      "        [3.6292, 3.4891, 3.5458, 3.6413, 3.5909],\n",
      "        [3.6501, 3.6737, 3.8065, 3.7480, 3.4466],\n",
      "        [3.4324, 3.6352, 3.5369, 3.7227, 3.4624],\n",
      "        [3.4326, 3.5789, 3.4779, 3.6083, 3.4631],\n",
      "        [3.6411, 3.6914, 3.7279, 3.7272, 3.4759],\n",
      "        [3.6392, 3.8213, 3.6713, 3.9288, 3.7043],\n",
      "        [3.4711, 3.8321, 3.6900, 3.7711, 3.7210],\n",
      "        [3.7734, 3.5197, 3.6934, 4.0680, 3.9119],\n",
      "        [3.6265, 3.7806, 3.7558, 3.9086, 3.6319],\n",
      "        [3.8622, 3.8072, 3.9223, 4.0916, 3.8200],\n",
      "        [3.3770, 3.4023, 3.4931, 3.5723, 3.3713],\n",
      "        [3.4840, 3.5491, 3.6143, 3.6489, 3.5197],\n",
      "        [3.6341, 3.8318, 3.6392, 3.7650, 3.6781],\n",
      "        [3.4825, 3.5214, 3.6213, 3.6411, 3.5043],\n",
      "        [3.4832, 3.5100, 3.6317, 3.6321, 3.5082],\n",
      "        [3.8047, 3.9058, 3.8593, 3.9277, 3.8406],\n",
      "        [3.5080, 3.6578, 3.5114, 3.7178, 3.5352],\n",
      "        [3.4733, 3.6147, 3.5737, 3.6253, 3.5269],\n",
      "        [3.7092, 3.7927, 3.8554, 3.9803, 3.6549],\n",
      "        [3.5560, 3.6826, 3.6855, 3.7167, 3.7041],\n",
      "        [3.4927, 3.6416, 3.6518, 3.6593, 3.4603],\n",
      "        [3.6118, 3.6868, 3.7688, 3.7432, 3.5024],\n",
      "        [3.5675, 3.5781, 3.7479, 3.8763, 3.8024],\n",
      "        [3.5881, 3.6823, 3.7202, 3.7314, 3.6204],\n",
      "        [3.5021, 3.7144, 3.6098, 3.6816, 3.6148],\n",
      "        [4.0686, 4.3297, 3.9088, 4.0898, 3.8103],\n",
      "        [3.5045, 3.7892, 3.6123, 3.5281, 3.6154],\n",
      "        [3.3777, 3.4479, 3.5221, 3.5666, 3.4027],\n",
      "        [3.4174, 3.5291, 3.5912, 3.6602, 3.4939],\n",
      "        [3.5587, 3.7698, 3.6983, 3.7337, 3.4856],\n",
      "        [3.5393, 3.8015, 3.6319, 3.8484, 3.6368],\n",
      "        [3.3222, 3.4010, 3.4992, 3.4952, 3.3377],\n",
      "        [3.2564, 3.4511, 3.5162, 3.4801, 3.4254],\n",
      "        [3.4966, 3.8567, 3.6957, 3.8132, 3.7248],\n",
      "        [3.5077, 3.5259, 3.6713, 3.7040, 3.6364],\n",
      "        [3.4805, 3.5627, 3.6216, 3.6656, 3.5269],\n",
      "        [3.5456, 3.5330, 3.6308, 3.6847, 3.5246],\n",
      "        [3.6999, 3.7345, 3.7913, 3.9216, 3.6863],\n",
      "        [3.4713, 3.5831, 3.7158, 3.7541, 3.6879],\n",
      "        [3.5746, 3.5385, 3.8736, 3.7637, 3.6714],\n",
      "        [3.5405, 3.7984, 3.5750, 3.7251, 3.5635],\n",
      "        [3.4164, 3.7684, 3.6921, 3.7036, 3.6659],\n",
      "        [3.6166, 3.8761, 3.8121, 3.8360, 3.8253],\n",
      "        [3.8109, 3.6839, 3.8319, 3.9538, 3.7463],\n",
      "        [3.6351, 3.7910, 3.7810, 3.8394, 3.6622],\n",
      "        [3.6497, 3.8243, 3.7685, 3.8652, 3.6655]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6361, 3.8169, 3.6685, 3.9210, 3.6930],\n",
      "        [3.4399, 3.7679, 3.5991, 3.5936, 3.4386],\n",
      "        [3.3445, 3.5872, 3.5941, 3.5575, 3.4426],\n",
      "        [3.3451, 3.5747, 3.5833, 3.5538, 3.4339],\n",
      "        [3.3982, 3.6002, 3.6922, 3.6412, 3.5846],\n",
      "        [3.3349, 3.6383, 3.7331, 3.5548, 3.5584],\n",
      "        [3.5366, 3.7432, 3.6295, 3.7700, 3.5536],\n",
      "        [3.3448, 3.6057, 3.5968, 3.5578, 3.4490],\n",
      "        [3.6419, 3.6456, 3.6353, 3.9334, 3.6978],\n",
      "        [3.4169, 3.6104, 3.5262, 3.6949, 3.4489],\n",
      "        [3.4436, 3.6084, 3.6658, 3.6735, 3.6698],\n",
      "        [3.6208, 3.7491, 3.7039, 3.7601, 3.6959],\n",
      "        [3.5971, 3.6511, 3.7780, 3.8056, 3.5823],\n",
      "        [3.6167, 3.7114, 3.6062, 3.8028, 3.6566],\n",
      "        [3.5073, 3.7838, 3.6670, 3.6830, 3.4515],\n",
      "        [3.6880, 3.7443, 3.7516, 3.8200, 3.7850],\n",
      "        [3.5162, 3.5674, 3.6929, 3.7110, 3.5853],\n",
      "        [3.5478, 3.5312, 3.6280, 3.6545, 3.5836],\n",
      "        [3.5040, 3.5524, 3.6810, 3.6965, 3.5578],\n",
      "        [3.7614, 3.7186, 3.7159, 3.8354, 3.7470],\n",
      "        [3.4710, 3.6700, 3.5783, 3.6941, 3.5887],\n",
      "        [3.3709, 3.6504, 3.7652, 3.6324, 3.5743],\n",
      "        [3.7892, 3.6555, 3.7100, 4.1462, 3.8433],\n",
      "        [3.4966, 3.5510, 3.6183, 3.6443, 3.5821],\n",
      "        [3.5076, 3.5614, 3.6273, 3.6511, 3.5924],\n",
      "        [3.3983, 3.5643, 3.4859, 3.5774, 3.4536],\n",
      "        [3.3812, 3.5483, 3.4831, 3.5502, 3.4415],\n",
      "        [3.6550, 3.7516, 3.7849, 3.8494, 3.5747],\n",
      "        [3.4721, 3.5400, 3.4823, 3.6136, 3.5736],\n",
      "        [3.3164, 3.3928, 3.4913, 3.4813, 3.3269],\n",
      "        [3.4388, 3.6340, 3.5801, 3.7112, 3.4843],\n",
      "        [3.6580, 3.7206, 3.6953, 3.8587, 3.7606],\n",
      "        [3.3667, 3.5556, 3.6119, 3.5843, 3.4470],\n",
      "        [3.3664, 3.4883, 3.5510, 3.5659, 3.4233],\n",
      "        [3.5275, 3.5745, 3.6930, 3.6880, 3.5853],\n",
      "        [3.6465, 3.7657, 3.8486, 3.8683, 3.7701],\n",
      "        [3.5004, 3.6019, 3.6448, 3.6619, 3.7056],\n",
      "        [3.4656, 3.4894, 3.6196, 3.6257, 3.4790],\n",
      "        [3.5717, 3.8973, 3.7738, 3.8156, 3.7596],\n",
      "        [3.6397, 3.6352, 3.6640, 3.6320, 3.4701],\n",
      "        [3.4670, 3.6787, 3.6558, 3.6794, 3.5584],\n",
      "        [3.4675, 3.6178, 3.7974, 3.6939, 3.6594],\n",
      "        [3.5761, 3.8326, 3.6652, 3.5833, 3.6422],\n",
      "        [3.5109, 3.6600, 3.5150, 3.7190, 3.5336],\n",
      "        [3.7474, 3.7691, 3.8239, 3.9362, 3.7272],\n",
      "        [3.3625, 3.4963, 3.5559, 3.5578, 3.4154],\n",
      "        [3.3785, 3.4541, 3.5269, 3.5665, 3.3999],\n",
      "        [3.3847, 3.5931, 3.4769, 3.6258, 3.4384],\n",
      "        [3.4786, 3.9170, 3.7849, 3.7162, 3.5717],\n",
      "        [3.9067, 4.0693, 3.8311, 3.8887, 3.7264],\n",
      "        [3.4802, 3.6305, 3.6557, 3.7071, 3.4950],\n",
      "        [3.4871, 3.5446, 3.6158, 3.6589, 3.5187],\n",
      "        [3.4890, 3.7025, 3.6073, 3.6894, 3.5998],\n",
      "        [3.4931, 3.5141, 3.5310, 3.7212, 3.4330],\n",
      "        [3.4793, 3.6310, 3.6337, 3.6128, 3.4456],\n",
      "        [3.4071, 3.6381, 3.6138, 3.5270, 3.4393],\n",
      "        [3.4181, 3.5760, 3.4958, 3.5794, 3.4824],\n",
      "        [3.5831, 3.8164, 3.7227, 3.7134, 3.6631],\n",
      "        [3.4892, 3.5048, 3.6456, 3.5722, 3.5702],\n",
      "        [3.4024, 3.5180, 3.5997, 3.6255, 3.4111],\n",
      "        [3.3633, 3.6320, 3.6176, 3.5869, 3.4860],\n",
      "        [3.4133, 3.5755, 3.4946, 3.5717, 3.4733],\n",
      "        [3.3613, 3.5270, 3.5747, 3.5700, 3.4377],\n",
      "        [3.7032, 3.8384, 3.8268, 3.8761, 3.8630]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6221, 3.6854, 3.7453, 3.7188, 3.7390],\n",
      "        [3.4973, 3.7352, 3.6676, 3.6321, 3.6179],\n",
      "        [3.4812, 3.9190, 3.7881, 3.7178, 3.5711],\n",
      "        [3.4929, 3.4834, 3.6003, 3.5756, 3.4445],\n",
      "        [3.5923, 3.6638, 3.7146, 3.7041, 3.7078],\n",
      "        [3.3546, 3.5433, 3.4995, 3.5698, 3.4145],\n",
      "        [3.5427, 3.7166, 3.5324, 3.6567, 3.5563],\n",
      "        [3.4128, 3.5507, 3.6330, 3.6302, 3.4282],\n",
      "        [3.6588, 3.7363, 3.7858, 3.8586, 3.5476],\n",
      "        [3.4642, 3.5504, 3.7309, 3.5373, 3.6696],\n",
      "        [3.3188, 3.3945, 3.4943, 3.4830, 3.3263],\n",
      "        [3.5313, 3.7014, 3.5101, 3.6432, 3.5395],\n",
      "        [3.6875, 3.7332, 3.9362, 3.7354, 3.5550],\n",
      "        [3.5105, 3.6607, 3.5045, 3.7169, 3.5309],\n",
      "        [3.5695, 3.5339, 3.8825, 3.7525, 3.6616],\n",
      "        [3.6845, 3.9717, 3.8787, 3.9025, 3.8229],\n",
      "        [3.5291, 3.7277, 3.6056, 3.6466, 3.5916],\n",
      "        [3.5129, 3.5875, 3.7357, 3.7186, 3.5915],\n",
      "        [3.5226, 3.6673, 3.6473, 3.6995, 3.5997],\n",
      "        [3.6907, 3.7309, 3.8138, 3.8417, 3.5528],\n",
      "        [3.6382, 3.6964, 3.7226, 3.7338, 3.4507],\n",
      "        [3.4845, 3.5417, 3.6141, 3.6476, 3.5133],\n",
      "        [3.9035, 4.0534, 3.7243, 3.8940, 3.6688],\n",
      "        [3.4783, 3.6580, 3.7879, 3.6380, 3.5560],\n",
      "        [3.5324, 3.7940, 3.5724, 3.6991, 3.5507],\n",
      "        [3.4864, 3.6831, 3.5878, 3.7053, 3.5976],\n",
      "        [3.3294, 3.3669, 3.4842, 3.5689, 3.3708],\n",
      "        [3.5108, 3.5606, 3.6515, 3.6688, 3.5821],\n",
      "        [3.5828, 3.4339, 3.7713, 3.7309, 3.5607],\n",
      "        [3.6493, 3.7674, 3.8519, 3.8700, 3.7695],\n",
      "        [3.4033, 3.4429, 3.5222, 3.5911, 3.3988],\n",
      "        [3.4595, 3.6696, 3.6465, 3.6647, 3.5711],\n",
      "        [3.3154, 3.4094, 3.4717, 3.4740, 3.3693],\n",
      "        [3.2792, 3.4540, 3.4475, 3.4366, 3.3679],\n",
      "        [3.5302, 3.5763, 3.6962, 3.6897, 3.5846],\n",
      "        [3.7623, 3.7877, 3.8326, 3.9742, 3.7308],\n",
      "        [3.4920, 3.5967, 3.6380, 3.6664, 3.6810],\n",
      "        [3.7069, 3.8439, 3.8495, 3.8290, 3.5575],\n",
      "        [3.6070, 3.6169, 3.6718, 3.6129, 3.4166],\n",
      "        [3.5186, 3.6965, 3.4900, 3.6302, 3.5295],\n",
      "        [3.5505, 3.5328, 3.6313, 3.6563, 3.5829],\n",
      "        [3.3833, 3.5730, 3.5277, 3.6430, 3.4405],\n",
      "        [3.3772, 3.4890, 3.5131, 3.5621, 3.4217],\n",
      "        [3.4885, 3.5733, 3.6340, 3.6838, 3.5327],\n",
      "        [3.4810, 3.6586, 3.6001, 3.7225, 3.5811],\n",
      "        [3.4797, 3.6276, 3.4949, 3.6786, 3.4989],\n",
      "        [3.5303, 3.5491, 3.6845, 3.6811, 3.5792],\n",
      "        [3.5870, 3.6753, 3.7453, 3.7624, 3.5831],\n",
      "        [3.3860, 3.4403, 3.5218, 3.5747, 3.3929],\n",
      "        [3.2843, 3.4645, 3.4559, 3.4348, 3.3660],\n",
      "        [3.5206, 3.5628, 3.6808, 3.6809, 3.5774],\n",
      "        [3.6426, 3.8231, 3.6771, 3.9304, 3.6985],\n",
      "        [3.6267, 3.7598, 3.6395, 3.7485, 3.7337],\n",
      "        [3.6372, 3.8505, 3.6707, 3.7657, 3.6718],\n",
      "        [3.3841, 3.5459, 3.4866, 3.5513, 3.4376],\n",
      "        [3.5566, 3.6040, 3.7345, 3.7484, 3.6097],\n",
      "        [3.3749, 3.4081, 3.4937, 3.5682, 3.3699],\n",
      "        [3.5901, 3.5893, 3.6881, 3.6401, 3.5084],\n",
      "        [3.4140, 3.6695, 3.4951, 3.6400, 3.4083],\n",
      "        [3.5105, 3.6607, 3.5045, 3.7169, 3.5309],\n",
      "        [3.4797, 3.5639, 3.7699, 3.5319, 3.6930],\n",
      "        [3.3675, 3.4773, 3.5427, 3.5592, 3.4088],\n",
      "        [3.4327, 3.7228, 3.6587, 3.6906, 3.7008],\n",
      "        [3.7708, 3.8004, 3.8539, 3.9397, 3.7263]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3510, 3.5933, 3.5979, 3.5589, 3.4412],\n",
      "        [3.5680, 3.9046, 3.7141, 3.8727, 3.7193],\n",
      "        [3.4960, 3.5248, 3.5462, 3.7209, 3.4451],\n",
      "        [3.9254, 3.7518, 3.9338, 4.3755, 4.1290],\n",
      "        [3.7847, 3.8373, 3.7666, 3.9248, 3.8404],\n",
      "        [3.5750, 3.6871, 3.7033, 3.7167, 3.7133],\n",
      "        [3.4832, 3.5412, 3.6138, 3.6472, 3.5103],\n",
      "        [3.3657, 3.4982, 3.5563, 3.5575, 3.4120],\n",
      "        [3.3899, 3.4236, 3.5106, 3.5849, 3.3765],\n",
      "        [3.5390, 3.7643, 3.6698, 3.6944, 3.6293],\n",
      "        [3.8167, 3.8333, 3.8833, 4.0316, 3.7975],\n",
      "        [3.6735, 3.7963, 3.7293, 3.8020, 3.7406],\n",
      "        [3.6935, 3.9906, 3.8053, 3.8378, 3.9675],\n",
      "        [3.5133, 3.7905, 3.6044, 3.5286, 3.5736],\n",
      "        [3.6995, 3.8907, 3.7752, 3.7202, 3.7144],\n",
      "        [3.4170, 3.6291, 3.6013, 3.7516, 3.4508],\n",
      "        [3.6611, 3.7853, 3.7725, 3.7274, 3.6652],\n",
      "        [3.5720, 3.7507, 3.6291, 3.7807, 3.5884],\n",
      "        [3.5834, 3.6156, 3.7616, 3.8009, 3.5682],\n",
      "        [3.6267, 3.7592, 3.6420, 3.7439, 3.7333],\n",
      "        [3.2959, 3.5568, 3.3818, 3.5631, 3.3217],\n",
      "        [3.5313, 3.7292, 3.6082, 3.6479, 3.5908],\n",
      "        [3.4929, 3.5824, 3.6394, 3.6811, 3.5325],\n",
      "        [3.9398, 4.0611, 3.7178, 3.8960, 3.6344],\n",
      "        [3.2980, 3.4791, 3.4660, 3.4486, 3.3859],\n",
      "        [3.5672, 3.8223, 3.7075, 3.7895, 3.7413],\n",
      "        [3.3527, 3.5730, 3.5907, 3.5697, 3.4429],\n",
      "        [3.4149, 3.5522, 3.6356, 3.6315, 3.4274],\n",
      "        [3.2925, 3.4709, 3.4589, 3.4445, 3.3747],\n",
      "        [4.0496, 4.2486, 3.9134, 4.0264, 3.7653],\n",
      "        [3.6609, 3.5989, 3.6419, 3.9963, 3.7040],\n",
      "        [3.7586, 3.9531, 3.7731, 3.7579, 3.6453],\n",
      "        [3.3562, 3.5201, 3.5680, 3.5557, 3.4153],\n",
      "        [3.4924, 3.5378, 3.6220, 3.6509, 3.5163],\n",
      "        [3.5116, 3.5760, 3.6711, 3.7059, 3.5636],\n",
      "        [3.5857, 3.8464, 3.7994, 3.7697, 3.6898],\n",
      "        [3.5803, 3.6584, 3.6719, 3.7212, 3.5721],\n",
      "        [3.4169, 3.5326, 3.5916, 3.6629, 3.4880],\n",
      "        [3.6404, 3.7789, 3.6507, 3.7696, 3.7294],\n",
      "        [3.4994, 3.7798, 3.5890, 3.8036, 3.6013],\n",
      "        [3.4335, 3.5509, 3.6066, 3.6909, 3.4989],\n",
      "        [3.4217, 3.5391, 3.5921, 3.6739, 3.4898],\n",
      "        [3.6560, 3.7796, 3.6875, 3.7383, 3.6297],\n",
      "        [3.3471, 3.5687, 3.7352, 3.5560, 3.5908],\n",
      "        [3.4576, 3.6116, 3.5025, 3.6347, 3.4911],\n",
      "        [3.6717, 3.7215, 3.7457, 3.8453, 3.8141],\n",
      "        [3.4129, 3.5353, 3.5913, 3.6711, 3.4902],\n",
      "        [3.5381, 3.7749, 3.6602, 3.8452, 3.5525],\n",
      "        [3.4006, 3.4318, 3.5158, 3.5767, 3.3973],\n",
      "        [3.6420, 3.8378, 3.6488, 3.7690, 3.6750],\n",
      "        [3.5345, 3.5712, 3.6464, 3.6770, 3.5701],\n",
      "        [3.4666, 3.5956, 3.5313, 3.6417, 3.5161],\n",
      "        [3.7051, 3.6878, 3.7908, 3.8881, 3.6410],\n",
      "        [3.5554, 3.5350, 3.6385, 3.6982, 3.4974],\n",
      "        [3.6459, 3.7691, 3.6907, 3.6995, 3.6134],\n",
      "        [3.6742, 3.9000, 3.8861, 3.8779, 3.5846],\n",
      "        [3.6768, 3.6980, 3.8864, 3.7607, 3.5154],\n",
      "        [3.8395, 3.7940, 3.8092, 4.0409, 3.7699],\n",
      "        [3.8707, 4.0188, 3.7048, 3.8561, 3.6623],\n",
      "        [3.7346, 3.7575, 3.8015, 3.9786, 3.9171],\n",
      "        [3.5059, 3.6466, 3.4979, 3.6999, 3.5086],\n",
      "        [3.3583, 3.5434, 3.5047, 3.5251, 3.4421],\n",
      "        [3.4943, 3.5981, 3.6407, 3.6679, 3.6801],\n",
      "        [3.7221, 3.8522, 3.7841, 3.8499, 3.7967]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5885, 3.6364, 3.6494, 3.8139, 3.5927],\n",
      "        [3.6778, 3.8114, 3.7030, 3.8758, 3.7418],\n",
      "        [3.5227, 3.5375, 3.6907, 3.7204, 3.6343],\n",
      "        [3.4954, 3.5720, 3.6375, 3.6680, 3.5237],\n",
      "        [3.9724, 4.1482, 4.1145, 4.2157, 4.2095],\n",
      "        [3.3816, 3.5529, 3.4912, 3.5519, 3.4365],\n",
      "        [3.5666, 3.6621, 3.6777, 3.7074, 3.5774],\n",
      "        [3.6710, 3.8392, 3.6680, 3.7857, 3.7018],\n",
      "        [3.5111, 3.5877, 3.5319, 3.6529, 3.6070],\n",
      "        [3.5739, 3.7526, 3.6311, 3.7816, 3.5875],\n",
      "        [3.7304, 3.9027, 3.9036, 3.8992, 3.6068],\n",
      "        [3.6833, 3.7444, 3.7636, 3.8687, 3.7990],\n",
      "        [3.7243, 3.8539, 3.7862, 3.8508, 3.7959],\n",
      "        [3.6225, 3.9319, 3.8349, 3.8466, 3.7721],\n",
      "        [3.6956, 3.9926, 3.8075, 3.8388, 3.9666],\n",
      "        [3.4434, 3.6245, 3.6185, 3.7442, 3.4611],\n",
      "        [3.6558, 3.7935, 3.8243, 3.8560, 3.7213],\n",
      "        [3.6067, 3.4871, 3.7954, 3.7578, 3.5989],\n",
      "        [3.7262, 3.7649, 3.7906, 3.8644, 3.8511],\n",
      "        [3.3489, 3.5590, 3.5852, 3.5567, 3.4228],\n",
      "        [3.3625, 3.5466, 3.5882, 3.5717, 3.4382],\n",
      "        [3.6982, 3.9145, 3.7802, 3.9556, 3.7647],\n",
      "        [3.3645, 3.5370, 3.5749, 3.5673, 3.4395],\n",
      "        [3.4625, 3.8528, 3.7770, 3.7709, 3.7435],\n",
      "        [3.5028, 3.5071, 3.6620, 3.6799, 3.6165],\n",
      "        [3.5467, 3.5934, 3.7099, 3.7045, 3.6008],\n",
      "        [3.4063, 3.4704, 3.5435, 3.5976, 3.4211],\n",
      "        [3.4167, 3.5540, 3.6376, 3.6324, 3.4265],\n",
      "        [3.3476, 3.5393, 3.5767, 3.5539, 3.4153],\n",
      "        [3.5251, 3.4913, 3.6136, 3.5699, 3.4438],\n",
      "        [3.6294, 3.6574, 3.7228, 3.7052, 3.4755],\n",
      "        [3.4681, 3.6743, 3.6586, 3.6693, 3.5852],\n",
      "        [3.3630, 3.6223, 3.6183, 3.5790, 3.4720],\n",
      "        [3.6719, 3.5866, 3.6626, 3.7252, 3.5982],\n",
      "        [3.4766, 3.8090, 3.7572, 3.7581, 3.6946],\n",
      "        [3.4994, 3.4992, 3.6478, 3.6719, 3.6115],\n",
      "        [3.6374, 3.9814, 3.8500, 3.8833, 3.8104],\n",
      "        [3.5466, 3.7199, 3.5370, 3.6588, 3.5546],\n",
      "        [3.5019, 3.6954, 3.6891, 3.6985, 3.4913],\n",
      "        [3.4929, 3.5170, 3.6431, 3.6370, 3.5042],\n",
      "        [3.6576, 3.8237, 3.7514, 3.7050, 3.6649],\n",
      "        [3.4138, 3.6428, 3.6217, 3.5311, 3.4369],\n",
      "        [3.6841, 3.7973, 3.7930, 3.7596, 3.6787],\n",
      "        [3.4391, 3.4299, 3.6339, 3.4523, 3.5558],\n",
      "        [3.4832, 3.5404, 3.6469, 3.6789, 3.5932],\n",
      "        [3.4910, 3.5281, 3.6386, 3.6436, 3.4980],\n",
      "        [3.4074, 3.4677, 3.6237, 3.5978, 3.4592],\n",
      "        [3.3891, 3.4926, 3.4563, 3.6152, 3.3306],\n",
      "        [3.4986, 3.5283, 3.6601, 3.6626, 3.5157],\n",
      "        [3.2943, 3.4726, 3.4609, 3.4454, 3.3738],\n",
      "        [3.8171, 3.8655, 3.7908, 3.9531, 3.8672],\n",
      "        [3.6019, 3.7748, 3.7290, 3.7518, 3.5004],\n",
      "        [3.5466, 3.6547, 3.6651, 3.6948, 3.5702],\n",
      "        [3.6761, 3.6978, 3.8803, 3.7578, 3.5060],\n",
      "        [3.5244, 3.6741, 3.5175, 3.7321, 3.5356],\n",
      "        [3.5165, 3.6192, 3.5589, 3.7337, 3.5348],\n",
      "        [3.7214, 3.7626, 3.8015, 3.8997, 3.6082],\n",
      "        [3.5998, 3.6007, 3.6572, 3.6335, 3.4054],\n",
      "        [3.2977, 3.5585, 3.3838, 3.5639, 3.3209],\n",
      "        [3.3196, 3.5012, 3.4747, 3.4794, 3.3963],\n",
      "        [3.4905, 3.6863, 3.5925, 3.7075, 3.5958],\n",
      "        [3.5506, 3.6072, 3.6426, 3.7315, 3.5608],\n",
      "        [3.4076, 3.4670, 3.5569, 3.5946, 3.3923],\n",
      "        [3.5419, 3.5911, 3.6442, 3.7033, 3.5625]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5618, 3.7969, 3.6887, 3.7717, 3.7150],\n",
      "        [3.5696, 3.7797, 3.7114, 3.7405, 3.4802],\n",
      "        [3.5106, 3.6574, 3.5067, 3.7103, 3.5174],\n",
      "        [3.4894, 3.5043, 3.6310, 3.6364, 3.5003],\n",
      "        [3.3558, 3.5350, 3.4934, 3.5151, 3.4303],\n",
      "        [3.5184, 3.6671, 3.5241, 3.7242, 3.5298],\n",
      "        [3.4965, 3.6403, 3.5129, 3.6936, 3.5144],\n",
      "        [3.7248, 3.6157, 3.6866, 4.0536, 3.7667],\n",
      "        [3.5737, 3.9376, 3.7469, 3.8974, 3.7539],\n",
      "        [3.4058, 3.5713, 3.4950, 3.5825, 3.4499],\n",
      "        [3.5051, 3.5977, 3.6583, 3.7003, 3.5487],\n",
      "        [3.3870, 3.4111, 3.5058, 3.5786, 3.3660],\n",
      "        [3.3528, 3.5817, 3.5926, 3.5588, 3.4302],\n",
      "        [3.5101, 3.6007, 3.6547, 3.7030, 3.5548],\n",
      "        [3.4919, 3.5902, 3.7619, 3.7809, 3.5903],\n",
      "        [3.6348, 3.7643, 3.6819, 3.6720, 3.5986],\n",
      "        [3.6540, 3.7910, 3.7946, 3.8506, 3.6294],\n",
      "        [3.6076, 3.7240, 3.6369, 3.7430, 3.7429],\n",
      "        [3.5457, 3.7310, 3.5708, 3.6595, 3.5672],\n",
      "        [3.4734, 3.4963, 3.6289, 3.6307, 3.4753],\n",
      "        [3.5526, 3.7915, 3.6248, 3.5475, 3.5375],\n",
      "        [3.3598, 3.5610, 3.5886, 3.5721, 3.4395],\n",
      "        [3.4177, 3.5561, 3.6393, 3.6337, 3.4252],\n",
      "        [3.5643, 3.7344, 3.7361, 3.8199, 3.6526],\n",
      "        [3.1960, 3.4078, 3.4960, 3.4289, 3.3576],\n",
      "        [3.4933, 3.7864, 3.6667, 3.6740, 3.4405],\n",
      "        [3.7175, 3.9350, 3.7994, 3.9707, 3.7833],\n",
      "        [3.4630, 3.6608, 3.5561, 3.7545, 3.4608],\n",
      "        [3.7611, 3.7228, 3.7140, 3.8327, 3.7441],\n",
      "        [3.7644, 3.9297, 3.6698, 3.7869, 3.6520],\n",
      "        [3.4969, 3.7097, 3.6168, 3.6947, 3.5959],\n",
      "        [3.4278, 3.5509, 3.6364, 3.6779, 3.5260],\n",
      "        [3.6501, 3.8311, 3.6847, 3.9355, 3.6986],\n",
      "        [3.7423, 3.9145, 3.8711, 3.9503, 3.8109],\n",
      "        [3.6359, 3.7892, 3.6887, 3.7969, 3.6193],\n",
      "        [3.8274, 3.7599, 3.8771, 4.0367, 3.7595],\n",
      "        [3.3805, 3.4678, 3.5393, 3.5616, 3.3892],\n",
      "        [3.2953, 3.4747, 3.4625, 3.4466, 3.3726],\n",
      "        [3.5162, 3.5651, 3.6653, 3.6765, 3.5695],\n",
      "        [3.4512, 3.5213, 3.4603, 3.5902, 3.5470],\n",
      "        [3.6387, 3.6707, 3.7963, 3.7263, 3.4118],\n",
      "        [3.4919, 3.6493, 3.6476, 3.6278, 3.4436],\n",
      "        [3.4184, 3.5799, 3.4925, 3.5870, 3.4586],\n",
      "        [3.5028, 3.6420, 3.4990, 3.6926, 3.5019],\n",
      "        [3.6434, 3.7830, 3.6545, 3.7717, 3.7270],\n",
      "        [3.4954, 3.6453, 3.5119, 3.6908, 3.5103],\n",
      "        [3.4134, 3.6994, 3.6490, 3.6688, 3.6703],\n",
      "        [3.7433, 3.7553, 3.8667, 3.8893, 3.5568],\n",
      "        [3.4000, 3.5548, 3.6462, 3.6253, 3.4152],\n",
      "        [3.6657, 3.8449, 3.6633, 3.7827, 3.6902],\n",
      "        [3.4051, 3.4755, 3.4352, 3.6210, 3.3618],\n",
      "        [3.6168, 3.6808, 3.5701, 3.8113, 3.6868],\n",
      "        [3.4308, 3.5877, 3.4966, 3.6099, 3.4631],\n",
      "        [3.5449, 3.8831, 3.8208, 3.8328, 3.7723],\n",
      "        [3.5208, 3.6571, 3.6556, 3.6684, 3.5594],\n",
      "        [3.8837, 4.0085, 3.9370, 4.1960, 3.9202],\n",
      "        [3.3991, 3.7528, 3.6385, 3.4995, 3.6083],\n",
      "        [3.5151, 3.7983, 3.6253, 3.5347, 3.6099],\n",
      "        [3.3608, 3.4949, 3.5577, 3.5572, 3.4037],\n",
      "        [3.5378, 3.5274, 3.7494, 3.7695, 3.5476],\n",
      "        [3.7463, 3.9171, 3.8755, 3.9575, 3.8140],\n",
      "        [3.6182, 3.6976, 3.7054, 3.7110, 3.3973],\n",
      "        [3.3082, 3.4933, 3.4722, 3.4608, 3.3841],\n",
      "        [3.5046, 3.6485, 3.5154, 3.7012, 3.5171]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3603, 3.6096, 3.6108, 3.5793, 3.4552],\n",
      "        [3.4110, 3.4600, 3.5359, 3.6073, 3.4116],\n",
      "        [3.3931, 3.6015, 3.4877, 3.6315, 3.4345],\n",
      "        [3.4585, 3.4612, 3.5537, 3.5953, 3.5833],\n",
      "        [3.4430, 3.8326, 3.6888, 3.7421, 3.6891],\n",
      "        [3.8467, 3.9541, 3.8856, 3.9691, 3.9087],\n",
      "        [3.5054, 3.7301, 3.6549, 3.6418, 3.6034],\n",
      "        [3.3992, 3.5231, 3.5891, 3.5393, 3.4393],\n",
      "        [3.3649, 3.6150, 3.6157, 3.5801, 3.4635],\n",
      "        [3.7770, 3.8079, 3.8619, 3.9443, 3.7236],\n",
      "        [3.5516, 3.5178, 3.6294, 3.6796, 3.4723],\n",
      "        [3.5273, 3.5798, 3.7011, 3.7212, 3.5694],\n",
      "        [3.4998, 3.5800, 3.7343, 3.5961, 3.6861],\n",
      "        [3.4440, 3.5953, 3.4970, 3.6134, 3.4774],\n",
      "        [3.6749, 3.9090, 3.7698, 3.9267, 3.7533],\n",
      "        [3.4195, 3.7105, 3.6551, 3.6784, 3.6829],\n",
      "        [3.4686, 3.6071, 3.6154, 3.6982, 3.5866],\n",
      "        [3.6606, 3.8617, 3.6657, 3.7565, 3.6625],\n",
      "        [3.5011, 3.8374, 3.7690, 3.7824, 3.7352],\n",
      "        [3.4993, 3.7508, 3.6948, 3.6292, 3.6220],\n",
      "        [3.4217, 3.5841, 3.5051, 3.5777, 3.4692],\n",
      "        [3.6242, 3.8076, 3.6587, 3.9005, 3.6568],\n",
      "        [3.3561, 3.4924, 3.5528, 3.5536, 3.3982],\n",
      "        [3.4998, 3.6348, 3.5832, 3.7143, 3.6198],\n",
      "        [3.5118, 3.5913, 3.6509, 3.6948, 3.5519],\n",
      "        [3.4336, 3.5847, 3.4903, 3.5980, 3.4525],\n",
      "        [3.4907, 3.6027, 3.6357, 3.6739, 3.6560],\n",
      "        [3.3481, 3.5295, 3.4876, 3.5073, 3.4142],\n",
      "        [3.7133, 3.8512, 3.8574, 3.8342, 3.5539],\n",
      "        [3.7391, 3.8284, 3.8223, 3.8852, 3.8924],\n",
      "        [3.5145, 3.7021, 3.5713, 3.8163, 3.4778],\n",
      "        [3.5159, 3.5652, 3.6916, 3.7069, 3.5645],\n",
      "        [3.5843, 3.6753, 3.6112, 3.7795, 3.5980],\n",
      "        [3.5459, 3.6704, 3.6747, 3.7195, 3.6714],\n",
      "        [3.7322, 3.9073, 3.9065, 3.9019, 3.6049],\n",
      "        [3.7651, 3.7708, 3.8285, 3.9495, 3.7198],\n",
      "        [3.4638, 3.6624, 3.5575, 3.7553, 3.4604],\n",
      "        [3.4935, 3.5273, 3.6380, 3.6542, 3.4917],\n",
      "        [3.6445, 3.7033, 3.7303, 3.7388, 3.4472],\n",
      "        [3.5027, 3.7435, 3.6120, 3.6346, 3.5820],\n",
      "        [3.4944, 3.5411, 3.6345, 3.6531, 3.5096],\n",
      "        [3.6910, 3.6047, 3.6608, 3.7388, 3.6287],\n",
      "        [3.6037, 3.7473, 3.7640, 3.8426, 3.6851],\n",
      "        [3.3732, 3.4841, 3.5501, 3.5636, 3.4053],\n",
      "        [3.3158, 3.4947, 3.4747, 3.4710, 3.3915],\n",
      "        [3.8191, 3.6517, 3.7318, 4.1942, 3.8637],\n",
      "        [3.5159, 3.6558, 3.6477, 3.6931, 3.5790],\n",
      "        [3.5622, 3.5582, 3.6722, 3.6820, 3.5917],\n",
      "        [3.5315, 3.8028, 3.6973, 3.7182, 3.4576],\n",
      "        [3.4972, 3.6419, 3.5143, 3.6945, 3.5140],\n",
      "        [3.5784, 3.8787, 3.7566, 3.8127, 3.7523],\n",
      "        [3.4262, 3.6269, 3.7109, 3.6514, 3.5914],\n",
      "        [3.6336, 3.7201, 3.8098, 3.7547, 3.5466],\n",
      "        [3.5114, 3.6590, 3.5081, 3.7112, 3.5169],\n",
      "        [3.8846, 4.0103, 3.9386, 4.1969, 3.9200],\n",
      "        [3.6955, 3.7924, 3.8416, 3.9692, 3.6348],\n",
      "        [3.4227, 3.5901, 3.5032, 3.5962, 3.4665],\n",
      "        [3.4555, 3.5997, 3.4921, 3.6386, 3.4613],\n",
      "        [3.4437, 3.5896, 3.4919, 3.6155, 3.4574],\n",
      "        [3.6588, 3.7799, 3.8372, 3.7818, 3.5329],\n",
      "        [3.4705, 3.5573, 3.7391, 3.5417, 3.6657],\n",
      "        [3.6354, 3.6368, 3.6784, 3.6406, 3.4433],\n",
      "        [3.4941, 3.4922, 3.6269, 3.6686, 3.6079],\n",
      "        [3.6113, 3.9662, 3.7633, 3.9379, 3.7668]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5017, 3.5863, 3.7246, 3.6119, 3.6706],\n",
      "        [3.3752, 3.4987, 3.5626, 3.5733, 3.4186],\n",
      "        [3.5157, 3.6567, 3.8279, 3.7405, 3.6812],\n",
      "        [3.6460, 3.8939, 3.7222, 3.8328, 3.6722],\n",
      "        [3.3891, 3.5592, 3.4983, 3.5509, 3.4382],\n",
      "        [3.4996, 3.6456, 3.6551, 3.6412, 3.4491],\n",
      "        [3.4617, 3.6189, 3.5085, 3.6391, 3.4878],\n",
      "        [3.2907, 3.4731, 3.4643, 3.4403, 3.3622],\n",
      "        [3.7242, 3.7888, 3.7715, 3.9184, 3.8229],\n",
      "        [3.7125, 3.8785, 3.8703, 3.8291, 3.4944],\n",
      "        [3.8197, 3.6537, 3.7329, 4.1956, 3.8632],\n",
      "        [3.3932, 3.4977, 3.4633, 3.6207, 3.3305],\n",
      "        [3.8302, 3.7614, 3.8808, 4.0343, 3.7615],\n",
      "        [3.5052, 3.5878, 3.5773, 3.7261, 3.5093],\n",
      "        [3.5337, 3.6043, 3.6542, 3.5918, 3.3731],\n",
      "        [3.3983, 3.7120, 3.5314, 3.4320, 3.5289],\n",
      "        [3.5023, 3.5180, 3.6644, 3.6872, 3.6119],\n",
      "        [3.5243, 3.6122, 3.6661, 3.5938, 3.3670],\n",
      "        [3.7386, 3.7836, 3.7647, 3.8578, 3.7339],\n",
      "        [3.3677, 3.5459, 3.4928, 3.5301, 3.4243],\n",
      "        [3.5615, 3.6111, 3.6528, 3.7426, 3.5609],\n",
      "        [3.4847, 3.6328, 3.5126, 3.6782, 3.5030],\n",
      "        [3.6865, 3.7400, 3.7604, 3.8568, 3.8194],\n",
      "        [3.2967, 3.4781, 3.4649, 3.4487, 3.3716],\n",
      "        [3.5374, 3.7199, 3.5213, 3.6478, 3.5399],\n",
      "        [3.6034, 3.6580, 3.5333, 3.7887, 3.6707],\n",
      "        [3.3690, 3.5114, 3.5656, 3.5754, 3.4151],\n",
      "        [3.5391, 3.7433, 3.6174, 3.6523, 3.5910],\n",
      "        [3.4663, 3.6783, 3.6555, 3.6706, 3.5667],\n",
      "        [3.4224, 3.5723, 3.4930, 3.5867, 3.4452],\n",
      "        [3.4572, 3.5919, 3.5260, 3.6351, 3.4972],\n",
      "        [3.2127, 3.4158, 3.5006, 3.4479, 3.3838],\n",
      "        [3.6135, 3.6698, 3.7951, 3.8075, 3.5914],\n",
      "        [3.5133, 3.5934, 3.5360, 3.6562, 3.6044],\n",
      "        [3.4405, 3.4247, 3.4989, 3.5876, 3.3656],\n",
      "        [3.2783, 3.4779, 3.5223, 3.5052, 3.4003],\n",
      "        [3.4755, 3.6085, 3.5361, 3.6460, 3.5137],\n",
      "        [3.4990, 3.6055, 3.6471, 3.6726, 3.6767],\n",
      "        [3.4828, 3.6301, 3.5098, 3.6491, 3.5010],\n",
      "        [3.7584, 3.8729, 3.7570, 3.8846, 3.8325],\n",
      "        [3.5001, 3.4991, 3.6371, 3.6761, 3.6086],\n",
      "        [3.5109, 3.5367, 3.6597, 3.6135, 3.5657],\n",
      "        [3.3863, 3.4487, 3.5260, 3.5785, 3.3848],\n",
      "        [3.4392, 3.7315, 3.6682, 3.6965, 3.6966],\n",
      "        [3.7376, 3.8074, 3.8892, 4.0061, 3.6555],\n",
      "        [3.2494, 3.4453, 3.5247, 3.4682, 3.4041],\n",
      "        [3.6132, 3.6371, 3.7180, 3.6847, 3.4874],\n",
      "        [3.5006, 3.6449, 3.5080, 3.6958, 3.5063],\n",
      "        [3.8256, 3.6560, 3.7315, 4.1889, 3.8697],\n",
      "        [3.6473, 3.7163, 3.7059, 3.8461, 3.7488],\n",
      "        [3.5197, 3.6705, 3.5265, 3.7264, 3.5287],\n",
      "        [3.6451, 3.7053, 3.7314, 3.7402, 3.4467],\n",
      "        [3.5002, 3.5449, 3.6330, 3.6573, 3.5138],\n",
      "        [3.7365, 3.7650, 3.8026, 3.8626, 3.8527],\n",
      "        [3.4980, 3.5822, 3.7357, 3.5980, 3.6734],\n",
      "        [3.6638, 3.8807, 3.7382, 3.8299, 3.6797],\n",
      "        [3.4716, 3.6041, 3.6191, 3.6866, 3.6074],\n",
      "        [3.9750, 4.1546, 4.1190, 4.2198, 4.2070],\n",
      "        [3.2601, 3.4624, 3.5213, 3.4842, 3.3912],\n",
      "        [3.3848, 3.5579, 3.4942, 3.5502, 3.4318],\n",
      "        [3.4636, 3.6299, 3.5146, 3.6521, 3.4886],\n",
      "        [3.6131, 3.7100, 3.6867, 3.8878, 3.5853],\n",
      "        [3.3095, 3.4967, 3.4746, 3.4629, 3.3831],\n",
      "        [3.6514, 3.8348, 3.6871, 3.9378, 3.6975]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3415, 3.4422, 3.4917, 3.5113, 3.3783],\n",
      "        [3.9815, 4.1508, 3.9098, 3.9588, 3.7874],\n",
      "        [3.2955, 3.3975, 3.4631, 3.4526, 3.3314],\n",
      "        [3.4699, 3.6269, 3.5128, 3.6541, 3.4906],\n",
      "        [3.5645, 3.6156, 3.7383, 3.7460, 3.6077],\n",
      "        [3.7175, 3.8050, 3.8045, 3.8775, 3.8376],\n",
      "        [3.9199, 4.0903, 3.8708, 3.8990, 3.7639],\n",
      "        [3.6916, 3.6840, 3.7067, 3.7146, 3.5180],\n",
      "        [3.3931, 3.4721, 3.5460, 3.5800, 3.4009],\n",
      "        [3.3513, 3.5662, 3.5899, 3.5617, 3.4198],\n",
      "        [3.6555, 3.7964, 3.7979, 3.8545, 3.6277],\n",
      "        [3.5432, 3.5939, 3.7275, 3.7415, 3.5950],\n",
      "        [3.4394, 3.5975, 3.5022, 3.6138, 3.4745],\n",
      "        [3.3341, 3.4743, 3.4189, 3.5725, 3.3327],\n",
      "        [3.8672, 4.0155, 3.6971, 3.8425, 3.6484],\n",
      "        [3.5560, 3.7781, 3.6676, 3.7954, 3.5481],\n",
      "        [3.6102, 3.6031, 3.8091, 3.8276, 3.5934],\n",
      "        [3.4584, 3.5897, 3.5435, 3.5852, 3.4638],\n",
      "        [3.4940, 3.5519, 3.6306, 3.6535, 3.5108],\n",
      "        [3.6660, 3.8229, 3.8048, 3.7915, 3.5195],\n",
      "        [3.3220, 3.5083, 3.4794, 3.4843, 3.3934],\n",
      "        [3.4982, 3.7148, 3.6199, 3.6986, 3.5941],\n",
      "        [3.4179, 3.7819, 3.7743, 3.6895, 3.6926],\n",
      "        [3.3022, 3.4879, 3.4726, 3.4543, 3.3822],\n",
      "        [3.5724, 3.9138, 3.7211, 3.8789, 3.7151],\n",
      "        [3.3875, 3.5789, 3.6343, 3.6136, 3.4443],\n",
      "        [3.8392, 3.9904, 3.6952, 3.8266, 3.6516],\n",
      "        [3.5045, 3.5591, 3.6420, 3.6635, 3.5222],\n",
      "        [3.9058, 4.0080, 3.9330, 4.1957, 3.9055],\n",
      "        [3.7074, 3.8956, 3.6688, 3.7760, 3.6593],\n",
      "        [3.5010, 3.5355, 3.6648, 3.6676, 3.5127],\n",
      "        [3.4953, 3.5588, 3.6317, 3.6615, 3.5163],\n",
      "        [3.6435, 3.8615, 3.6802, 3.7727, 3.6664],\n",
      "        [3.6567, 3.8098, 3.8133, 3.8359, 3.6949],\n",
      "        [3.9002, 4.0455, 3.7158, 3.8808, 3.6430],\n",
      "        [3.3701, 3.5390, 3.5870, 3.5789, 3.4324],\n",
      "        [3.4229, 3.7853, 3.7805, 3.6943, 3.6976],\n",
      "        [3.6580, 3.8055, 3.6946, 3.8837, 3.8046],\n",
      "        [3.5112, 3.6058, 3.6578, 3.7069, 3.5530],\n",
      "        [3.5098, 3.6555, 3.5044, 3.7059, 3.5046],\n",
      "        [3.5448, 3.6701, 3.6486, 3.7327, 3.6544],\n",
      "        [3.3453, 3.5331, 3.4928, 3.5154, 3.4154],\n",
      "        [3.4745, 3.5594, 3.7538, 3.5328, 3.6693],\n",
      "        [3.6371, 3.6607, 3.7259, 3.7029, 3.4963],\n",
      "        [3.6326, 3.7049, 3.7178, 3.7309, 3.4106],\n",
      "        [3.6264, 3.7241, 3.6186, 3.8119, 3.6515],\n",
      "        [3.3946, 3.4777, 3.5474, 3.5831, 3.4042],\n",
      "        [3.5116, 3.5305, 3.6761, 3.7013, 3.6212],\n",
      "        [3.3587, 3.6127, 3.6136, 3.5705, 3.4457],\n",
      "        [3.5813, 3.6933, 3.6184, 3.7652, 3.5958],\n",
      "        [3.7127, 3.7854, 3.8469, 3.8292, 3.7478],\n",
      "        [3.8788, 3.8263, 3.9413, 4.1042, 3.8166],\n",
      "        [3.5614, 3.6127, 3.6535, 3.7443, 3.5603],\n",
      "        [3.5772, 3.8617, 3.7391, 3.8059, 3.7450],\n",
      "        [3.3578, 3.5165, 3.5637, 3.5565, 3.4065],\n",
      "        [3.6513, 3.8364, 3.6878, 3.9395, 3.6967],\n",
      "        [3.8468, 3.6492, 3.7324, 4.2256, 3.8866],\n",
      "        [3.6621, 3.8018, 3.8020, 3.8573, 3.6336],\n",
      "        [3.6332, 3.8176, 3.7283, 3.8586, 3.7951],\n",
      "        [3.7407, 3.9641, 3.7908, 3.9633, 3.8360],\n",
      "        [3.5809, 3.8666, 3.7838, 3.7899, 3.5840],\n",
      "        [3.3977, 3.6133, 3.5522, 3.6001, 3.5058],\n",
      "        [3.4978, 3.5611, 3.6327, 3.6571, 3.5130],\n",
      "        [3.4331, 3.6646, 3.5127, 3.6813, 3.4168]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5346, 3.6228, 3.7746, 3.7544, 3.6034],\n",
      "        [3.6130, 3.6399, 3.7190, 3.6876, 3.4869],\n",
      "        [3.4944, 3.6921, 3.5698, 3.7890, 3.4689],\n",
      "        [3.4168, 3.6320, 3.8210, 3.6438, 3.6617],\n",
      "        [3.5785, 3.6526, 3.6610, 3.8032, 3.5666],\n",
      "        [3.5016, 3.5890, 3.7258, 3.6147, 3.6701],\n",
      "        [3.6513, 3.8295, 3.8118, 3.7760, 3.5401],\n",
      "        [3.4954, 3.6183, 3.5583, 3.6987, 3.6246],\n",
      "        [3.4202, 3.8436, 3.7729, 3.7134, 3.7159],\n",
      "        [3.5370, 3.5878, 3.7062, 3.6982, 3.5800],\n",
      "        [3.6401, 3.7666, 3.6746, 3.8280, 3.6417],\n",
      "        [3.6639, 3.8579, 3.6796, 3.7915, 3.6968],\n",
      "        [3.6249, 3.4868, 3.5502, 3.6606, 3.5542],\n",
      "        [3.6578, 3.8068, 3.6950, 3.8849, 3.8049],\n",
      "        [3.6505, 3.7441, 3.7847, 3.7805, 3.6463],\n",
      "        [3.5029, 3.5904, 3.7253, 3.6137, 3.6813],\n",
      "        [3.4644, 3.4870, 3.6200, 3.6240, 3.4666],\n",
      "        [3.6234, 3.8664, 3.8161, 3.8499, 3.6225],\n",
      "        [3.4911, 3.4954, 3.6116, 3.6630, 3.6109],\n",
      "        [3.5034, 3.7899, 3.5962, 3.8110, 3.5976],\n",
      "        [3.6036, 3.7523, 3.7659, 3.8466, 3.6838],\n",
      "        [3.5270, 3.4998, 3.6187, 3.5759, 3.4410],\n",
      "        [3.4889, 3.6438, 3.6471, 3.6238, 3.4404],\n",
      "        [3.7642, 3.7875, 3.8253, 4.0126, 3.9246],\n",
      "        [3.4920, 3.7636, 3.7129, 3.6243, 3.6233],\n",
      "        [3.6847, 3.8000, 3.7832, 3.8282, 3.8352],\n",
      "        [3.4049, 3.4784, 3.4402, 3.6246, 3.3161],\n",
      "        [3.3424, 3.5270, 3.4884, 3.5090, 3.4114],\n",
      "        [3.4702, 3.5285, 3.6285, 3.6198, 3.4857],\n",
      "        [3.5027, 3.5086, 3.5262, 3.7343, 3.4160],\n",
      "        [3.8200, 3.8743, 3.7961, 3.9597, 3.8649],\n",
      "        [4.0862, 4.3453, 3.9269, 4.1017, 3.8041],\n",
      "        [3.6430, 3.7045, 3.5742, 3.8298, 3.7096],\n",
      "        [3.6687, 3.7340, 3.7102, 3.8700, 3.7556],\n",
      "        [3.7898, 3.8476, 3.7740, 3.9323, 3.8375],\n",
      "        [3.6395, 3.7963, 3.7730, 3.9205, 3.6250],\n",
      "        [3.4069, 3.4858, 3.4355, 3.6299, 3.3501],\n",
      "        [3.5710, 3.8300, 3.6117, 3.7494, 3.5794],\n",
      "        [3.7371, 3.5491, 3.7214, 4.0105, 3.8519],\n",
      "        [3.4911, 3.6073, 3.6380, 3.6782, 3.6549],\n",
      "        [3.3814, 3.4741, 3.5428, 3.5665, 3.3879],\n",
      "        [3.5882, 3.7969, 3.7072, 3.7004, 3.6615],\n",
      "        [3.5778, 3.6874, 3.5952, 3.7513, 3.5724],\n",
      "        [3.4450, 3.6331, 3.6234, 3.7503, 3.4579],\n",
      "        [3.7493, 3.9744, 3.8077, 3.9748, 3.8517],\n",
      "        [3.7667, 3.5459, 3.7193, 4.0454, 3.8814],\n",
      "        [3.5103, 3.5665, 3.6464, 3.6657, 3.5766],\n",
      "        [3.7026, 3.8648, 3.8770, 3.8132, 3.4862],\n",
      "        [3.5176, 3.5713, 3.6690, 3.6816, 3.5681],\n",
      "        [3.4476, 3.6471, 3.5929, 3.7209, 3.4792],\n",
      "        [3.3879, 3.4171, 3.5090, 3.5835, 3.3646],\n",
      "        [3.5397, 3.6653, 3.6465, 3.7671, 3.6370],\n",
      "        [3.3963, 3.4656, 3.5353, 3.5866, 3.3951],\n",
      "        [4.0566, 4.2587, 3.9213, 4.0341, 3.7619],\n",
      "        [3.3601, 3.5302, 3.5751, 3.5627, 3.4116],\n",
      "        [3.4847, 3.6805, 3.5604, 3.7843, 3.4564],\n",
      "        [3.3913, 3.5006, 3.4614, 3.6209, 3.3280],\n",
      "        [3.5102, 3.6460, 3.6703, 3.6754, 3.4373],\n",
      "        [3.5262, 3.6825, 3.5224, 3.7383, 3.5327],\n",
      "        [3.4182, 3.5762, 3.4901, 3.5870, 3.4452],\n",
      "        [3.6590, 3.7854, 3.8391, 3.7868, 3.5317],\n",
      "        [3.4850, 3.6308, 3.5107, 3.6582, 3.5079],\n",
      "        [3.6040, 3.7837, 3.7341, 3.7586, 3.4975],\n",
      "        [3.8767, 4.0288, 3.7123, 3.8634, 3.6591]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6739, 3.5154, 3.5424, 3.6410, 3.6162],\n",
      "        [3.5964, 3.8193, 3.7098, 3.8936, 3.6451],\n",
      "        [3.6181, 3.9094, 3.7472, 3.8193, 3.6846],\n",
      "        [3.5008, 3.7093, 3.6156, 3.7157, 3.6028],\n",
      "        [3.6222, 3.6450, 3.7288, 3.8577, 3.5112],\n",
      "        [3.4950, 3.5653, 3.6307, 3.6608, 3.5127],\n",
      "        [3.4349, 3.6067, 3.6018, 3.5298, 3.4677],\n",
      "        [3.4086, 3.4549, 3.5316, 3.6002, 3.3944],\n",
      "        [3.7249, 3.7120, 3.8059, 3.8988, 3.6543],\n",
      "        [3.6685, 3.7348, 3.7104, 3.8707, 3.7558],\n",
      "        [3.7291, 3.6114, 3.6932, 4.0785, 3.7703],\n",
      "        [3.7981, 3.6705, 3.7233, 4.1574, 3.8386],\n",
      "        [3.5282, 3.6799, 3.6571, 3.7088, 3.5952],\n",
      "        [3.5547, 3.7870, 3.6228, 3.7483, 3.5914],\n",
      "        [3.6604, 3.8676, 3.6679, 3.7611, 3.6612],\n",
      "        [3.4424, 3.6036, 3.4939, 3.6308, 3.4620],\n",
      "        [3.4814, 3.7965, 3.6667, 3.6698, 3.4359],\n",
      "        [3.6398, 3.6454, 3.7321, 3.7931, 3.5801],\n",
      "        [3.4854, 3.5036, 3.6617, 3.5509, 3.5682],\n",
      "        [3.7637, 3.9639, 3.7806, 3.7660, 3.6417],\n",
      "        [3.4757, 3.6928, 3.6691, 3.6904, 3.5529],\n",
      "        [3.5012, 3.5923, 3.6494, 3.6928, 3.5405],\n",
      "        [3.6179, 3.6884, 3.5737, 3.8172, 3.6857],\n",
      "        [3.7509, 3.8315, 3.8512, 3.8813, 3.8059],\n",
      "        [3.4846, 3.6316, 3.5108, 3.6588, 3.5080],\n",
      "        [3.8436, 3.8062, 3.8174, 4.0496, 3.7677],\n",
      "        [3.4907, 3.5766, 3.6374, 3.6763, 3.5180],\n",
      "        [3.3991, 3.5824, 3.6768, 3.6327, 3.4279],\n",
      "        [3.2119, 3.4192, 3.5017, 3.4511, 3.3836],\n",
      "        [3.2850, 3.4661, 3.4571, 3.4453, 3.3640],\n",
      "        [3.3875, 3.4179, 3.5091, 3.5841, 3.3647],\n",
      "        [3.5267, 3.5723, 3.7013, 3.7287, 3.5817],\n",
      "        [3.5074, 3.5972, 3.6522, 3.7045, 3.5337],\n",
      "        [3.7270, 3.8720, 3.9060, 4.0395, 4.0086],\n",
      "        [3.7488, 3.7682, 3.8624, 3.9146, 3.5771],\n",
      "        [3.3027, 3.5039, 3.5204, 3.5489, 3.4183],\n",
      "        [3.5246, 3.6704, 3.7567, 3.7356, 3.6098],\n",
      "        [3.3365, 3.4397, 3.4888, 3.5048, 3.3748],\n",
      "        [3.3959, 3.4665, 3.5353, 3.5872, 3.3952],\n",
      "        [3.7063, 3.8864, 3.8725, 3.8323, 3.5055],\n",
      "        [3.5061, 3.6049, 3.6615, 3.6973, 3.5514],\n",
      "        [3.7179, 3.9390, 3.7687, 3.7080, 3.6659],\n",
      "        [3.6193, 3.7047, 3.7090, 3.7173, 3.3962],\n",
      "        [3.7224, 3.8624, 3.8384, 3.8877, 3.8758],\n",
      "        [3.6505, 3.8385, 3.6881, 3.9413, 3.6970],\n",
      "        [3.4445, 3.6340, 3.6235, 3.7509, 3.4579],\n",
      "        [3.4906, 3.5665, 3.6402, 3.6807, 3.5263],\n",
      "        [3.5348, 3.5659, 3.7052, 3.6937, 3.5742],\n",
      "        [3.5094, 3.6093, 3.7161, 3.6345, 3.6758],\n",
      "        [3.5099, 3.6468, 3.6705, 3.6761, 3.4374],\n",
      "        [3.4654, 3.7483, 3.6244, 3.6510, 3.4816],\n",
      "        [3.6227, 3.7061, 3.7848, 3.7571, 3.4955],\n",
      "        [3.4659, 3.5699, 3.5798, 3.5914, 3.4980],\n",
      "        [3.5071, 3.5608, 3.6469, 3.6668, 3.5233],\n",
      "        [3.4584, 3.5437, 3.6254, 3.6416, 3.5123],\n",
      "        [3.4625, 3.4856, 3.6147, 3.6202, 3.4641],\n",
      "        [3.4367, 3.4664, 3.5557, 3.6087, 3.3970],\n",
      "        [3.5062, 3.5647, 3.6320, 3.6558, 3.5771],\n",
      "        [3.7165, 3.7610, 3.7913, 3.8532, 3.8364],\n",
      "        [3.4686, 3.5457, 3.6501, 3.6800, 3.5940],\n",
      "        [3.3776, 3.5941, 3.6047, 3.5839, 3.4619],\n",
      "        [3.4842, 3.6170, 3.5459, 3.6838, 3.4823],\n",
      "        [3.6483, 3.7641, 3.7847, 3.7613, 3.6460],\n",
      "        [3.5080, 3.6542, 3.5080, 3.7074, 3.5062]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3657, 3.5468, 3.5798, 3.5744, 3.4369],\n",
      "        [3.3975, 3.6403, 3.4683, 3.6301, 3.3920],\n",
      "        [3.4148, 3.5024, 3.4522, 3.6515, 3.4158],\n",
      "        [3.5076, 3.7083, 3.7104, 3.7025, 3.6876],\n",
      "        [3.4920, 3.6944, 3.6756, 3.6940, 3.5630],\n",
      "        [3.5185, 3.6250, 3.7246, 3.7228, 3.6548],\n",
      "        [3.4586, 3.4669, 3.5559, 3.6008, 3.5826],\n",
      "        [3.6247, 3.7864, 3.7598, 3.7897, 3.5153],\n",
      "        [3.6191, 4.0012, 3.7810, 3.9571, 3.7871],\n",
      "        [3.5135, 3.9043, 3.8116, 3.7664, 3.5788],\n",
      "        [3.4028, 3.6617, 3.4937, 3.6480, 3.4025],\n",
      "        [3.3791, 3.4815, 3.5476, 3.5704, 3.4015],\n",
      "        [3.2748, 3.4678, 3.4592, 3.4304, 3.3517],\n",
      "        [3.4966, 3.5636, 3.6327, 3.6592, 3.5132],\n",
      "        [3.7270, 3.8119, 3.8402, 3.8980, 3.6624],\n",
      "        [3.4798, 3.5260, 3.6366, 3.6519, 3.4903],\n",
      "        [3.4958, 3.5484, 3.6891, 3.7015, 3.5450],\n",
      "        [3.6314, 3.7751, 3.8011, 3.7921, 3.6371],\n",
      "        [3.5395, 3.5981, 3.7511, 3.8555, 3.7597],\n",
      "        [3.5428, 3.7760, 3.6771, 3.7033, 3.6254],\n",
      "        [3.5021, 3.7496, 3.6139, 3.6396, 3.5809],\n",
      "        [3.6126, 3.7001, 3.7593, 3.7689, 3.6158],\n",
      "        [3.4811, 3.5435, 3.5793, 3.7019, 3.4416],\n",
      "        [3.5391, 3.5682, 3.7104, 3.7600, 3.5581],\n",
      "        [3.3593, 3.6402, 3.7262, 3.5921, 3.5253],\n",
      "        [3.6900, 3.8283, 3.7103, 3.8882, 3.7570],\n",
      "        [3.5332, 3.5470, 3.7009, 3.7341, 3.6348],\n",
      "        [3.4273, 3.5586, 3.6394, 3.6834, 3.5242],\n",
      "        [3.6536, 3.7907, 3.6905, 3.7632, 3.6232],\n",
      "        [3.5050, 3.6054, 3.6614, 3.7064, 3.5471],\n",
      "        [3.5105, 3.6649, 3.5097, 3.7161, 3.5159],\n",
      "        [3.7336, 3.8273, 3.8566, 3.9069, 3.6780],\n",
      "        [3.9683, 4.2318, 3.8178, 3.9685, 3.7047],\n",
      "        [3.5068, 3.5978, 3.6519, 3.7048, 3.5336],\n",
      "        [3.4302, 3.6312, 3.5553, 3.6658, 3.4249],\n",
      "        [3.5403, 3.7690, 3.6474, 3.7981, 3.5342],\n",
      "        [3.5231, 3.6170, 3.6667, 3.5984, 3.3665],\n",
      "        [3.4945, 3.5659, 3.6304, 3.6612, 3.5126],\n",
      "        [3.7252, 3.6237, 3.6900, 4.0598, 3.7655],\n",
      "        [3.9343, 4.0754, 3.7099, 3.9038, 3.6250],\n",
      "        [3.5791, 3.6986, 3.7109, 3.7257, 3.7096],\n",
      "        [3.5026, 3.5923, 3.6516, 3.6930, 3.5430],\n",
      "        [3.5183, 3.6746, 3.5272, 3.7300, 3.5282],\n",
      "        [3.6534, 3.7218, 3.7013, 3.8626, 3.7459],\n",
      "        [3.6499, 3.8391, 3.6878, 3.9416, 3.6969],\n",
      "        [3.5437, 3.7309, 3.5654, 3.6597, 3.5601],\n",
      "        [3.6367, 3.8788, 3.6875, 3.6336, 3.6030],\n",
      "        [3.5237, 3.7365, 3.6539, 3.6697, 3.6117],\n",
      "        [3.6560, 3.6504, 3.6833, 3.6675, 3.4667],\n",
      "        [3.4276, 3.5460, 3.6072, 3.6723, 3.4869],\n",
      "        [3.8743, 3.8263, 3.9406, 4.1056, 3.8155],\n",
      "        [3.4839, 3.6707, 3.7979, 3.6475, 3.5512],\n",
      "        [3.4212, 3.5764, 3.4938, 3.5902, 3.4449],\n",
      "        [3.5021, 3.7496, 3.6139, 3.6396, 3.5809],\n",
      "        [3.3838, 3.4845, 3.5539, 3.5757, 3.4044],\n",
      "        [3.4811, 3.6093, 3.6278, 3.6847, 3.6319],\n",
      "        [3.6419, 3.6981, 3.7357, 3.7339, 3.4591],\n",
      "        [3.4177, 3.5640, 3.6427, 3.6397, 3.4240],\n",
      "        [3.3008, 3.4863, 3.4720, 3.4569, 3.3786],\n",
      "        [3.4714, 3.4836, 3.6592, 3.5205, 3.5664],\n",
      "        [3.4478, 3.6754, 3.6375, 3.5607, 3.4527],\n",
      "        [3.5702, 3.8686, 3.7886, 3.7921, 3.5769],\n",
      "        [3.7111, 3.8837, 3.8709, 3.8339, 3.4938],\n",
      "        [3.7362, 3.5505, 3.7213, 4.0115, 3.8520]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4834, 3.6325, 3.5100, 3.6600, 3.5077],\n",
      "        [3.7429, 3.9185, 3.8768, 3.9620, 3.8178],\n",
      "        [3.6311, 3.6370, 3.7293, 3.7898, 3.5727],\n",
      "        [3.4022, 3.6621, 3.4933, 3.6490, 3.4024],\n",
      "        [3.9097, 4.0107, 3.9570, 4.2049, 3.9005],\n",
      "        [3.6119, 3.7005, 3.7588, 3.7697, 3.6156],\n",
      "        [3.5860, 3.9059, 3.7684, 3.8308, 3.7575],\n",
      "        [3.4976, 3.6024, 3.5942, 3.7344, 3.5457],\n",
      "        [3.3763, 3.5403, 3.6050, 3.5984, 3.4099],\n",
      "        [3.5011, 3.5103, 3.5256, 3.7361, 3.4159],\n",
      "        [3.7457, 3.9272, 3.8785, 3.9657, 3.8123],\n",
      "        [3.3992, 3.6099, 3.4943, 3.6409, 3.4388],\n",
      "        [3.5112, 3.8900, 3.6654, 3.8766, 3.6786],\n",
      "        [3.5526, 3.8277, 3.6567, 3.8650, 3.6360],\n",
      "        [3.7425, 3.7641, 3.8694, 3.8965, 3.5543],\n",
      "        [3.4368, 3.6094, 3.6015, 3.5320, 3.4738],\n",
      "        [3.6456, 3.5546, 3.5728, 3.6525, 3.6253],\n",
      "        [3.2951, 3.4826, 3.4655, 3.4531, 3.3714],\n",
      "        [3.3502, 3.5253, 3.4914, 3.5156, 3.4074],\n",
      "        [3.4269, 3.5464, 3.6067, 3.6731, 3.4867],\n",
      "        [3.4666, 3.6708, 3.5767, 3.7063, 3.5779],\n",
      "        [3.3923, 3.5391, 3.6106, 3.6099, 3.4199],\n",
      "        [3.4378, 3.5254, 3.6291, 3.6574, 3.5741],\n",
      "        [3.8553, 3.7578, 3.8185, 4.3111, 4.0235],\n",
      "        [3.6490, 3.8232, 3.7945, 3.7886, 3.5201],\n",
      "        [3.3178, 3.5241, 3.5243, 3.5601, 3.4319],\n",
      "        [3.7386, 3.9295, 3.9043, 3.8745, 3.5703],\n",
      "        [3.6657, 3.7674, 3.7855, 3.8254, 3.7644],\n",
      "        [3.4268, 3.4971, 3.6449, 3.6283, 3.4662],\n",
      "        [3.4785, 3.8027, 3.6694, 3.6768, 3.4467],\n",
      "        [3.6304, 3.6677, 3.7275, 3.7138, 3.4727],\n",
      "        [3.4823, 3.7759, 3.7433, 3.6094, 3.6285],\n",
      "        [3.6068, 3.6059, 3.7023, 3.6531, 3.5359],\n",
      "        [3.6492, 3.8395, 3.6873, 3.9424, 3.6967],\n",
      "        [3.5139, 3.6369, 3.5677, 3.7537, 3.5428],\n",
      "        [3.4635, 3.8629, 3.7824, 3.7790, 3.7403],\n",
      "        [3.4147, 3.5607, 3.4997, 3.6289, 3.4281],\n",
      "        [3.7106, 3.7939, 3.7798, 3.8512, 3.8506],\n",
      "        [3.4666, 3.6237, 3.5073, 3.6347, 3.4908],\n",
      "        [3.6208, 3.6341, 3.7134, 3.7682, 3.5577],\n",
      "        [3.5358, 3.5624, 3.6940, 3.6918, 3.5745],\n",
      "        [3.4288, 3.5962, 3.4972, 3.6073, 3.4599],\n",
      "        [3.3853, 3.4687, 3.5387, 3.5784, 3.3947],\n",
      "        [3.3492, 3.5805, 3.7418, 3.5649, 3.5868],\n",
      "        [3.6272, 3.7896, 3.7588, 3.7942, 3.5197],\n",
      "        [3.3961, 3.4297, 3.5089, 3.5907, 3.3814],\n",
      "        [3.6005, 3.6120, 3.6612, 3.6431, 3.4024],\n",
      "        [3.7374, 3.8421, 3.8226, 3.8837, 3.8869],\n",
      "        [3.3700, 3.4963, 3.5548, 3.5663, 3.4038],\n",
      "        [3.5076, 3.6672, 3.5138, 3.7164, 3.5173],\n",
      "        [3.4906, 3.7654, 3.7123, 3.6261, 3.6231],\n",
      "        [3.3571, 3.6003, 3.6038, 3.5812, 3.4443],\n",
      "        [3.8187, 3.8763, 3.7956, 3.9617, 3.8650],\n",
      "        [3.6047, 3.8633, 3.7938, 3.8188, 3.6086],\n",
      "        [3.5246, 3.6842, 3.5216, 3.7400, 3.5324],\n",
      "        [3.7169, 3.9399, 3.7680, 3.7093, 3.6656],\n",
      "        [3.4836, 3.9588, 3.8073, 3.7217, 3.5656],\n",
      "        [3.8773, 3.8301, 3.9414, 4.1082, 3.8174],\n",
      "        [3.7247, 3.7840, 3.8254, 3.7828, 3.4838],\n",
      "        [3.5317, 3.5679, 3.7147, 3.7296, 3.6043],\n",
      "        [3.4196, 3.4915, 3.6393, 3.6204, 3.4669],\n",
      "        [3.7759, 3.8159, 3.8636, 3.9510, 3.7233],\n",
      "        [3.5338, 3.5669, 3.7045, 3.6949, 3.5739],\n",
      "        [3.5185, 3.7358, 3.6221, 3.7040, 3.6007]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6483, 3.6751, 3.7511, 3.8855, 3.5466],\n",
      "        [3.6110, 3.6270, 3.7035, 3.7550, 3.5486],\n",
      "        [3.4649, 3.7807, 3.7682, 3.6588, 3.7663],\n",
      "        [3.4762, 3.5078, 3.6314, 3.6411, 3.4743],\n",
      "        [3.6547, 3.8435, 3.8268, 3.8062, 3.5527],\n",
      "        [3.3702, 3.6476, 3.6292, 3.5998, 3.4806],\n",
      "        [3.6252, 3.7771, 3.6462, 3.7548, 3.7331],\n",
      "        [3.2931, 3.4008, 3.4623, 3.4567, 3.3316],\n",
      "        [3.7006, 3.7824, 3.7990, 3.8784, 3.7869],\n",
      "        [3.5942, 3.6031, 3.6967, 3.6513, 3.5031],\n",
      "        [3.5868, 3.4469, 3.7794, 3.7424, 3.5552],\n",
      "        [3.4947, 3.5823, 3.6407, 3.6772, 3.5200],\n",
      "        [3.4721, 3.6594, 3.6061, 3.7413, 3.5711],\n",
      "        [3.6262, 3.8956, 3.8286, 3.8511, 3.8179],\n",
      "        [3.9230, 4.0050, 3.9190, 4.2490, 3.9269],\n",
      "        [3.4777, 3.8030, 3.6686, 3.6779, 3.4463],\n",
      "        [3.5554, 3.5508, 3.6460, 3.6986, 3.5173],\n",
      "        [3.6671, 3.7359, 3.7092, 3.8732, 3.7553],\n",
      "        [3.4018, 3.6196, 3.5497, 3.6095, 3.5083],\n",
      "        [3.3519, 3.6084, 3.6029, 3.5685, 3.4374],\n",
      "        [3.7253, 3.7762, 3.7938, 3.8736, 3.8470],\n",
      "        [3.6753, 3.9156, 3.8912, 3.8902, 3.5797],\n",
      "        [3.7017, 3.8597, 3.8462, 3.8938, 3.8627],\n",
      "        [3.4052, 3.4895, 3.5705, 3.6017, 3.3934],\n",
      "        [3.3856, 3.4189, 3.5075, 3.5864, 3.3641],\n",
      "        [3.4916, 3.5552, 3.5975, 3.6322, 3.5653],\n",
      "        [3.4476, 3.4512, 3.6438, 3.4868, 3.5531],\n",
      "        [3.4975, 3.5126, 3.6437, 3.6809, 3.6109],\n",
      "        [3.5579, 3.4456, 3.7552, 3.7554, 3.6162],\n",
      "        [3.6943, 3.7990, 3.8422, 3.9765, 3.6333],\n",
      "        [3.8518, 4.0495, 3.8494, 3.8586, 3.7457],\n",
      "        [3.8221, 3.6968, 3.8430, 3.9613, 3.7419],\n",
      "        [3.3608, 3.5047, 3.5578, 3.5647, 3.4021],\n",
      "        [3.4989, 3.6445, 3.6506, 3.6395, 3.4483],\n",
      "        [3.4924, 3.5389, 3.6408, 3.6590, 3.4958],\n",
      "        [3.3986, 3.5634, 3.6484, 3.6333, 3.4136],\n",
      "        [3.4857, 3.5174, 3.6203, 3.6102, 3.4645],\n",
      "        [3.6686, 3.7447, 3.7489, 3.8065, 3.7582],\n",
      "        [3.4425, 3.6353, 3.6218, 3.7530, 3.4572],\n",
      "        [3.6484, 3.8397, 3.6864, 3.9435, 3.6963],\n",
      "        [3.7468, 3.7966, 3.8350, 4.0065, 3.9272],\n",
      "        [3.6162, 3.9105, 3.7456, 3.8217, 3.6840],\n",
      "        [3.6219, 3.6948, 3.7473, 3.7349, 3.7295],\n",
      "        [3.8045, 3.8641, 3.7792, 3.9463, 3.8436],\n",
      "        [3.5353, 3.9254, 3.6883, 3.8968, 3.7082],\n",
      "        [3.4964, 3.4971, 3.6085, 3.5865, 3.4393],\n",
      "        [3.7273, 3.6126, 3.6917, 4.0808, 3.7698],\n",
      "        [3.5346, 3.6713, 3.6581, 3.7317, 3.6530],\n",
      "        [3.6374, 3.8190, 3.7944, 3.8500, 3.6805],\n",
      "        [3.3072, 3.5014, 3.4745, 3.4685, 3.3827],\n",
      "        [3.4782, 3.5402, 3.5866, 3.6200, 3.5467],\n",
      "        [3.7597, 3.7926, 3.7585, 3.8803, 3.7280],\n",
      "        [3.5009, 3.5922, 3.7241, 3.6165, 3.6807],\n",
      "        [3.4258, 3.8193, 3.7506, 3.7337, 3.6963],\n",
      "        [3.6340, 3.6439, 3.6790, 3.6488, 3.4422],\n",
      "        [3.5053, 3.5983, 3.6505, 3.7067, 3.5330],\n",
      "        [3.6498, 3.7344, 3.8041, 3.7703, 3.4805],\n",
      "        [3.5904, 3.7241, 3.8398, 3.7962, 3.6615],\n",
      "        [3.5091, 3.5618, 3.6502, 3.6687, 3.5227],\n",
      "        [3.5163, 3.6388, 3.4847, 3.7133, 3.4153],\n",
      "        [3.9712, 4.1603, 4.1184, 4.2266, 4.2062],\n",
      "        [3.4759, 3.5721, 3.7669, 3.5368, 3.6805],\n",
      "        [3.3702, 3.6476, 3.6292, 3.5998, 3.4806],\n",
      "        [3.6436, 3.7061, 3.7225, 3.8178, 3.7839]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5605, 3.5536, 3.6558, 3.7039, 3.5247],\n",
      "        [3.5151, 3.6759, 3.5249, 3.7325, 3.5281],\n",
      "        [3.4817, 3.5449, 3.6228, 3.6545, 3.5026],\n",
      "        [3.3713, 3.5565, 3.4986, 3.5404, 3.4334],\n",
      "        [3.6561, 3.8348, 3.7543, 3.7149, 3.6620],\n",
      "        [3.3890, 3.6817, 3.7953, 3.6728, 3.5825],\n",
      "        [3.5325, 3.7162, 3.5170, 3.6545, 3.5347],\n",
      "        [3.3709, 3.5040, 3.5612, 3.5797, 3.4184],\n",
      "        [3.5073, 3.6662, 3.5075, 3.7186, 3.5158],\n",
      "        [3.4891, 3.5052, 3.5172, 3.7347, 3.4107],\n",
      "        [3.5062, 3.5566, 3.6514, 3.6667, 3.5170],\n",
      "        [3.4259, 3.5491, 3.6315, 3.6850, 3.5296],\n",
      "        [3.6466, 3.8404, 3.6854, 3.9442, 3.6968],\n",
      "        [3.4846, 3.7856, 3.7440, 3.6194, 3.6374],\n",
      "        [3.8478, 3.9683, 3.8836, 4.1388, 3.8277],\n",
      "        [3.6414, 3.7823, 3.6959, 3.7074, 3.6084],\n",
      "        [3.4136, 3.5932, 3.6748, 3.6478, 3.4445],\n",
      "        [3.5605, 3.5624, 3.6572, 3.6812, 3.5897],\n",
      "        [3.3969, 3.5641, 3.6475, 3.6341, 3.4142],\n",
      "        [3.4503, 3.6237, 3.6775, 3.6881, 3.6644],\n",
      "        [3.4995, 3.6508, 3.4997, 3.7009, 3.5003],\n",
      "        [3.4779, 3.5429, 3.5855, 3.6205, 3.5505],\n",
      "        [3.4806, 3.6189, 3.5436, 3.6870, 3.4825],\n",
      "        [3.5322, 3.6752, 3.6560, 3.7292, 3.6622],\n",
      "        [3.8470, 3.7168, 3.8451, 4.3184, 4.0408],\n",
      "        [3.4743, 3.6282, 3.6258, 3.7122, 3.5923],\n",
      "        [3.6527, 3.8358, 3.7624, 3.8633, 3.6531],\n",
      "        [3.4782, 3.7871, 3.7436, 3.6371, 3.6161],\n",
      "        [3.6491, 3.7947, 3.6968, 3.7646, 3.6210],\n",
      "        [3.4895, 3.6258, 3.7099, 3.7172, 3.6059],\n",
      "        [3.5385, 3.5264, 3.6095, 3.6459, 3.5551],\n",
      "        [3.5654, 3.7009, 3.7008, 3.7330, 3.6972],\n",
      "        [3.4809, 3.9600, 3.8053, 3.7235, 3.5656],\n",
      "        [3.5668, 3.6274, 3.7507, 3.7467, 3.6073],\n",
      "        [3.6066, 3.6699, 3.6787, 3.7533, 3.5610],\n",
      "        [3.4809, 3.6720, 3.7957, 3.6502, 3.5511],\n",
      "        [3.5657, 3.6367, 3.6528, 3.7792, 3.5632],\n",
      "        [3.3180, 3.5122, 3.4777, 3.4892, 3.3941],\n",
      "        [3.6564, 3.8568, 3.6575, 3.7873, 3.6785],\n",
      "        [3.5311, 3.7526, 3.6334, 3.7860, 3.5428],\n",
      "        [3.7874, 3.8399, 3.8443, 4.0141, 3.7030],\n",
      "        [3.6798, 3.8346, 3.8208, 3.8141, 3.5310],\n",
      "        [3.7713, 3.8920, 3.8450, 3.8970, 3.7861],\n",
      "        [3.5192, 3.5779, 3.6874, 3.7147, 3.5525],\n",
      "        [3.3994, 3.4540, 3.5249, 3.5987, 3.3921],\n",
      "        [3.7399, 3.7651, 3.8675, 3.8984, 3.5544],\n",
      "        [3.5480, 3.8154, 3.5891, 3.7392, 3.5564],\n",
      "        [3.6414, 3.7108, 3.7301, 3.7472, 3.4466],\n",
      "        [3.5121, 3.8069, 3.6262, 3.5438, 3.6083],\n",
      "        [3.3591, 3.5054, 3.5569, 3.5655, 3.4027],\n",
      "        [3.6219, 3.7920, 3.8135, 3.8201, 3.6326],\n",
      "        [3.3796, 3.5008, 3.5802, 3.5955, 3.3896],\n",
      "        [3.5074, 3.5625, 3.6493, 3.6694, 3.5233],\n",
      "        [3.6127, 3.6344, 3.6688, 3.6240, 3.4207],\n",
      "        [3.4973, 3.7113, 3.6131, 3.7187, 3.6026],\n",
      "        [3.8879, 3.8901, 3.9037, 4.0658, 3.8934],\n",
      "        [3.7402, 3.8843, 3.9135, 4.0737, 4.0186],\n",
      "        [3.5054, 3.6593, 3.5022, 3.7105, 3.5047],\n",
      "        [3.6084, 3.7157, 3.6851, 3.8944, 3.5849],\n",
      "        [3.5765, 3.9160, 3.7846, 3.8311, 3.7544],\n",
      "        [3.8644, 3.8019, 3.8936, 4.1247, 3.8616],\n",
      "        [3.6564, 3.7550, 3.8084, 3.7755, 3.4697],\n",
      "        [3.6619, 3.8546, 3.6640, 3.7909, 3.6884],\n",
      "        [3.5347, 3.5361, 3.7504, 3.7782, 3.5459]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3881, 3.4414, 3.5149, 3.6023, 3.3866],\n",
      "        [3.3569, 3.5566, 3.5085, 3.5363, 3.4394],\n",
      "        [3.4596, 3.7512, 3.6203, 3.6542, 3.4816],\n",
      "        [3.4179, 3.5847, 3.5399, 3.6144, 3.4770],\n",
      "        [3.5657, 3.8373, 3.7119, 3.8019, 3.7384],\n",
      "        [3.6623, 3.6660, 3.6824, 3.6873, 3.4902],\n",
      "        [3.5193, 3.9000, 3.6668, 3.8753, 3.6997],\n",
      "        [3.7503, 3.7979, 3.8389, 4.0086, 3.9254],\n",
      "        [3.4480, 3.6308, 3.6775, 3.7034, 3.6580],\n",
      "        [3.4527, 3.5459, 3.6215, 3.6447, 3.5124],\n",
      "        [3.6047, 3.6968, 3.5674, 3.7391, 3.6610],\n",
      "        [3.9160, 3.7141, 3.8362, 4.2818, 4.0629],\n",
      "        [3.6391, 3.8522, 3.6519, 3.7796, 3.6710],\n",
      "        [3.4812, 3.5542, 3.6170, 3.6583, 3.5067],\n",
      "        [3.6680, 3.6747, 3.6775, 3.9971, 3.7280],\n",
      "        [3.4831, 3.5033, 3.6583, 3.5558, 3.5689],\n",
      "        [3.5485, 3.8291, 3.6538, 3.8674, 3.6366],\n",
      "        [3.6474, 3.8137, 3.6998, 3.8315, 3.6558],\n",
      "        [3.7386, 3.9205, 3.8738, 3.9647, 3.8184],\n",
      "        [3.9234, 3.7662, 3.9377, 4.3872, 4.1260],\n",
      "        [3.9247, 3.7703, 3.9423, 4.3891, 4.1358],\n",
      "        [3.4336, 3.6017, 3.4990, 3.6189, 3.4752],\n",
      "        [3.5702, 3.8251, 3.7008, 3.7959, 3.7297],\n",
      "        [3.5748, 3.7002, 3.7076, 3.7289, 3.7100],\n",
      "        [4.0547, 4.3009, 3.8696, 4.0234, 3.8060],\n",
      "        [3.3745, 3.4831, 3.5443, 3.5736, 3.4019],\n",
      "        [3.2827, 3.5354, 3.6876, 3.5119, 3.5138],\n",
      "        [3.5623, 3.6375, 3.6510, 3.7790, 3.5635],\n",
      "        [3.6751, 3.7769, 3.7781, 3.8952, 3.7758],\n",
      "        [3.6278, 3.4960, 3.5498, 3.6715, 3.5474],\n",
      "        [3.4653, 3.6855, 3.6604, 3.6799, 3.5826],\n",
      "        [3.4768, 3.6358, 3.5072, 3.6557, 3.5009],\n",
      "        [3.7198, 3.7150, 3.8025, 3.9028, 3.6552],\n",
      "        [3.3792, 3.4978, 3.5617, 3.5984, 3.4148],\n",
      "        [3.6828, 3.6108, 3.6587, 4.0495, 3.7251],\n",
      "        [3.5327, 3.5846, 3.6502, 3.6884, 3.5666],\n",
      "        [3.3475, 3.5763, 3.5880, 3.5695, 3.4236],\n",
      "        [3.3451, 3.5818, 3.7389, 3.5673, 3.5873],\n",
      "        [3.4244, 3.8353, 3.6939, 3.7295, 3.7045],\n",
      "        [3.5313, 3.7929, 3.6786, 3.8562, 3.5413],\n",
      "        [3.7628, 3.8857, 3.7603, 3.8977, 3.8272],\n",
      "        [3.6448, 3.8408, 3.6842, 3.9446, 3.6972],\n",
      "        [3.7162, 3.7642, 3.8165, 3.9512, 3.6758],\n",
      "        [3.4444, 3.4523, 3.6418, 3.4879, 3.5541],\n",
      "        [3.4827, 3.5810, 3.7415, 3.5848, 3.6678],\n",
      "        [3.4431, 3.5374, 3.5866, 3.6754, 3.4318],\n",
      "        [3.6465, 3.7361, 3.8018, 3.7716, 3.4813],\n",
      "        [3.4913, 3.5834, 3.6385, 3.6783, 3.5209],\n",
      "        [3.3443, 3.5508, 3.5784, 3.5642, 3.4132],\n",
      "        [3.6499, 3.8009, 3.7949, 3.8601, 3.6286],\n",
      "        [3.3423, 3.6138, 3.6044, 3.5699, 3.4403],\n",
      "        [3.6229, 3.7333, 3.7176, 3.9062, 3.6087],\n",
      "        [3.4881, 3.5995, 3.7620, 3.7900, 3.5893],\n",
      "        [3.5686, 3.7264, 3.6435, 3.7792, 3.6360],\n",
      "        [3.4467, 3.4777, 3.6037, 3.6135, 3.4499],\n",
      "        [3.4866, 3.6452, 3.5997, 3.7568, 3.6125],\n",
      "        [3.6449, 3.7472, 3.7812, 3.7846, 3.6467],\n",
      "        [3.7132, 3.8540, 3.7088, 3.8348, 3.7813],\n",
      "        [3.3388, 3.5264, 3.4881, 3.5139, 3.4255],\n",
      "        [3.4873, 3.6961, 3.6722, 3.6971, 3.5633],\n",
      "        [3.5405, 3.5564, 3.6765, 3.6911, 3.5835],\n",
      "        [3.5055, 3.5694, 3.6431, 3.6700, 3.5772],\n",
      "        [3.6310, 3.6452, 3.6769, 3.6501, 3.4432],\n",
      "        [3.4996, 3.7176, 3.6803, 3.7121, 3.5162]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5034, 3.5434, 3.6562, 3.6202, 3.5658],\n",
      "        [3.6967, 4.0217, 3.7808, 4.0134, 3.8396],\n",
      "        [3.4924, 3.5388, 3.5486, 3.7324, 3.4423],\n",
      "        [3.3645, 3.6072, 3.6038, 3.5946, 3.4612],\n",
      "        [3.3564, 3.6267, 3.6109, 3.5812, 3.4569],\n",
      "        [3.6766, 3.8360, 3.8183, 3.8146, 3.5315],\n",
      "        [3.5013, 3.4954, 3.6037, 3.5822, 3.4349],\n",
      "        [3.5016, 3.7196, 3.6833, 3.7129, 3.5023],\n",
      "        [3.4713, 3.8213, 3.7585, 3.7688, 3.6922],\n",
      "        [3.4817, 3.7012, 3.6847, 3.6999, 3.6116],\n",
      "        [3.5806, 3.6632, 3.6682, 3.7359, 3.5470],\n",
      "        [3.4308, 3.5231, 3.6454, 3.6475, 3.4876],\n",
      "        [3.7804, 3.7612, 3.7532, 3.8763, 3.7557],\n",
      "        [3.5677, 3.7660, 3.6309, 3.7917, 3.5847],\n",
      "        [3.6553, 3.8443, 3.7807, 3.8814, 3.6591],\n",
      "        [3.5474, 3.7901, 3.6179, 3.7517, 3.5918],\n",
      "        [3.6895, 3.8010, 3.8388, 3.9777, 3.6345],\n",
      "        [3.5090, 3.9389, 3.7899, 3.7088, 3.5777],\n",
      "        [3.6609, 3.6669, 3.6813, 3.6874, 3.4904],\n",
      "        [3.4583, 3.5417, 3.4717, 3.6105, 3.5557],\n",
      "        [3.7674, 3.7351, 3.7261, 3.8532, 3.7449],\n",
      "        [3.3539, 3.4308, 3.5134, 3.5732, 3.3936],\n",
      "        [3.7264, 3.8653, 3.8742, 3.8482, 3.5825],\n",
      "        [3.6019, 3.6090, 3.7053, 3.6470, 3.5481],\n",
      "        [3.5457, 3.7240, 3.7143, 3.8097, 3.6611],\n",
      "        [3.4940, 3.7126, 3.6107, 3.7191, 3.6031],\n",
      "        [3.3865, 3.4423, 3.5137, 3.6024, 3.3867],\n",
      "        [3.6574, 3.7158, 3.7779, 3.8648, 3.4953],\n",
      "        [3.7069, 3.8999, 3.7997, 3.9291, 3.9118],\n",
      "        [3.7323, 3.9693, 3.7859, 3.9683, 3.8367],\n",
      "        [3.9039, 4.0134, 3.9530, 4.2078, 3.9016],\n",
      "        [3.7314, 3.8379, 3.8194, 3.8938, 3.8919],\n",
      "        [3.3482, 3.5751, 3.5847, 3.5658, 3.4231],\n",
      "        [3.7613, 3.7940, 3.6959, 3.8956, 3.7622],\n",
      "        [3.4152, 3.7902, 3.7765, 3.6995, 3.6982],\n",
      "        [3.4168, 3.6130, 3.6975, 3.6767, 3.6027],\n",
      "        [3.7146, 3.7653, 3.8153, 3.9513, 3.6760],\n",
      "        [3.6062, 3.6291, 3.7002, 3.7562, 3.5497],\n",
      "        [3.4517, 3.6158, 3.5055, 3.6536, 3.4877],\n",
      "        [3.8221, 3.7719, 3.8772, 4.0477, 3.7605],\n",
      "        [3.4416, 3.6218, 3.6316, 3.7008, 3.4616],\n",
      "        [3.6803, 3.7569, 3.7657, 3.8800, 3.7976],\n",
      "        [3.6497, 3.8457, 3.8233, 3.8074, 3.5537],\n",
      "        [3.3846, 3.5042, 3.4574, 3.6255, 3.3292],\n",
      "        [3.3873, 3.4827, 3.5430, 3.5884, 3.4051],\n",
      "        [3.9143, 3.7150, 3.8350, 4.2818, 4.0630],\n",
      "        [3.5172, 3.7485, 3.6349, 3.6952, 3.6156],\n",
      "        [3.4712, 3.5795, 3.6894, 3.6853, 3.5351],\n",
      "        [3.4763, 3.5698, 3.6239, 3.6707, 3.5119],\n",
      "        [3.4091, 3.5629, 3.4958, 3.6312, 3.4288],\n",
      "        [3.6259, 3.7100, 3.7135, 3.7368, 3.4117],\n",
      "        [3.7388, 3.6317, 3.6924, 4.0989, 3.7877],\n",
      "        [3.6251, 3.7787, 3.7964, 3.7957, 3.6376],\n",
      "        [3.5162, 3.5792, 3.6851, 3.7151, 3.5531],\n",
      "        [3.7354, 3.9315, 3.8676, 3.9589, 3.8045],\n",
      "        [3.5771, 3.7887, 3.6572, 3.8107, 3.5890],\n",
      "        [3.3852, 3.5056, 3.5659, 3.5966, 3.4273],\n",
      "        [3.5291, 3.7270, 3.5173, 3.6540, 3.5397],\n",
      "        [3.5055, 3.7100, 3.6929, 3.7139, 3.4933],\n",
      "        [3.5116, 3.6407, 3.4817, 3.7151, 3.4166],\n",
      "        [3.6846, 4.0066, 3.7780, 3.9943, 3.8230],\n",
      "        [3.3730, 3.6157, 3.6098, 3.5905, 3.4718],\n",
      "        [3.6583, 3.6136, 3.6447, 4.0081, 3.7012],\n",
      "        [3.3530, 3.6213, 3.6122, 3.5864, 3.4588]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.9767, 3.7518, 3.8959, 4.3665, 4.1297],\n",
      "        [3.5431, 3.5399, 3.6223, 3.6598, 3.5694],\n",
      "        [3.8339, 3.8125, 3.8653, 3.9919, 3.8183],\n",
      "        [3.4836, 3.6998, 3.5915, 3.7179, 3.5929],\n",
      "        [3.6581, 3.7710, 3.7907, 3.8649, 3.5708],\n",
      "        [3.6257, 3.8406, 3.7680, 3.9407, 3.6564],\n",
      "        [3.3929, 3.5747, 3.6530, 3.6430, 3.4203],\n",
      "        [3.4899, 3.5139, 3.6260, 3.6748, 3.6213],\n",
      "        [3.4812, 3.6482, 3.6415, 3.6287, 3.4412],\n",
      "        [3.6143, 3.8724, 3.8100, 3.8548, 3.6234],\n",
      "        [3.5542, 3.8091, 3.6871, 3.7821, 3.7146],\n",
      "        [3.3929, 3.5747, 3.6530, 3.6430, 3.4203],\n",
      "        [3.4205, 3.4897, 3.5580, 3.6191, 3.4037],\n",
      "        [3.4702, 3.5071, 3.6281, 3.6407, 3.4743],\n",
      "        [3.6049, 3.8954, 3.8114, 3.8454, 3.8215],\n",
      "        [3.7490, 3.8382, 3.8348, 3.9147, 3.9401],\n",
      "        [3.4568, 3.5655, 3.5592, 3.5869, 3.5055],\n",
      "        [3.8937, 4.0512, 3.7108, 3.8868, 3.6444],\n",
      "        [3.5820, 3.7913, 3.7217, 3.7578, 3.4935],\n",
      "        [3.3952, 3.6646, 3.4886, 3.6527, 3.4036],\n",
      "        [3.5704, 3.9309, 3.6821, 3.9100, 3.7155],\n",
      "        [3.4725, 3.5426, 3.5823, 3.6218, 3.5479],\n",
      "        [3.7033, 3.7914, 3.8410, 3.8352, 3.7485],\n",
      "        [3.5177, 3.5850, 3.7005, 3.7257, 3.5807],\n",
      "        [3.4212, 3.5951, 3.4945, 3.6058, 3.4711],\n",
      "        [3.4935, 3.6953, 3.6939, 3.6982, 3.6645],\n",
      "        [3.6046, 3.7033, 3.7535, 3.7724, 3.6163],\n",
      "        [3.4497, 3.5364, 3.6191, 3.6323, 3.4910],\n",
      "        [3.7817, 3.8525, 3.7683, 3.9372, 3.8386],\n",
      "        [3.5425, 3.7913, 3.7841, 3.8321, 3.6219],\n",
      "        [3.6642, 3.8817, 3.7067, 3.6735, 3.5725],\n",
      "        [3.4864, 3.5688, 3.6244, 3.6644, 3.5130],\n",
      "        [3.4995, 3.8771, 3.7073, 3.8296, 3.7181],\n",
      "        [3.4196, 3.5342, 3.5921, 3.6660, 3.4187],\n",
      "        [3.4940, 3.6613, 3.5068, 3.7151, 3.5134],\n",
      "        [3.6044, 3.6445, 3.7131, 3.6920, 3.4875],\n",
      "        [3.4815, 3.5575, 3.6173, 3.6603, 3.5090],\n",
      "        [3.4046, 3.5677, 3.4978, 3.6406, 3.4259],\n",
      "        [3.6194, 3.6592, 3.6307, 3.8964, 3.6547],\n",
      "        [3.6443, 3.7966, 3.6933, 3.7654, 3.6215],\n",
      "        [3.6280, 3.7999, 3.6863, 3.8061, 3.6185],\n",
      "        [3.3500, 3.6186, 3.6084, 3.5765, 3.4469],\n",
      "        [3.3135, 3.5140, 3.4744, 3.4902, 3.3947],\n",
      "        [3.4195, 3.5491, 3.6012, 3.6756, 3.4873],\n",
      "        [3.6220, 3.7671, 3.7108, 3.7746, 3.6918],\n",
      "        [3.7676, 3.6917, 3.8155, 3.9759, 3.6874],\n",
      "        [3.6292, 3.8818, 3.6817, 3.6374, 3.6034],\n",
      "        [3.3990, 3.6065, 3.5364, 3.6853, 3.4380],\n",
      "        [3.5275, 3.6771, 3.6523, 3.7300, 3.6627],\n",
      "        [3.2935, 3.4895, 3.4668, 3.4609, 3.3794],\n",
      "        [3.7347, 3.8864, 3.9097, 4.0746, 4.0191],\n",
      "        [4.0798, 4.3499, 3.9213, 4.1067, 3.8053],\n",
      "        [3.3783, 3.4265, 3.5004, 3.5824, 3.3683],\n",
      "        [3.3476, 3.6475, 3.4500, 3.6478, 3.3808],\n",
      "        [3.4923, 3.6422, 3.6624, 3.6754, 3.4382],\n",
      "        [3.7671, 3.7985, 3.8286, 3.9895, 3.7355],\n",
      "        [3.7142, 3.7770, 3.8004, 3.9110, 3.6054],\n",
      "        [3.3922, 3.5977, 3.5224, 3.6545, 3.4410],\n",
      "        [3.7184, 3.8672, 3.7852, 3.8615, 3.7941],\n",
      "        [3.5586, 3.7059, 3.6025, 3.7457, 3.6444],\n",
      "        [3.6683, 3.8517, 3.6746, 3.7961, 3.7108],\n",
      "        [3.4616, 3.6556, 3.7731, 3.6453, 3.5330],\n",
      "        [3.3630, 3.4990, 3.5496, 3.5691, 3.4046],\n",
      "        [3.6229, 3.8240, 3.7219, 3.8638, 3.7953]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7276, 3.8395, 3.8167, 3.8949, 3.8917],\n",
      "        [3.6088, 3.6896, 3.5608, 3.8124, 3.6679],\n",
      "        [3.4089, 3.8490, 3.7659, 3.7187, 3.7161],\n",
      "        [3.4186, 3.5520, 3.6263, 3.6864, 3.5297],\n",
      "        [3.4830, 3.5903, 3.6356, 3.6976, 3.5280],\n",
      "        [3.8223, 3.8132, 3.8095, 3.9662, 3.7740],\n",
      "        [3.7189, 3.6165, 3.6860, 4.0832, 3.7708],\n",
      "        [3.3382, 3.5397, 3.4831, 3.5169, 3.4140],\n",
      "        [3.4746, 3.6445, 3.4970, 3.6920, 3.4945],\n",
      "        [3.4089, 3.5916, 3.4890, 3.5971, 3.4577],\n",
      "        [3.4715, 3.6135, 3.6208, 3.6890, 3.6322],\n",
      "        [3.6542, 3.8564, 3.7198, 3.8311, 3.6746],\n",
      "        [3.6611, 3.7482, 3.7434, 3.8092, 3.7598],\n",
      "        [3.8280, 3.8030, 3.8040, 4.0510, 3.7695],\n",
      "        [3.3339, 3.5441, 3.5013, 3.5163, 3.4273],\n",
      "        [3.8071, 3.8671, 3.8588, 4.0611, 3.7366],\n",
      "        [3.6235, 3.8753, 3.8146, 3.8535, 3.6354],\n",
      "        [3.4852, 3.7153, 3.6934, 3.7104, 3.4806],\n",
      "        [3.5046, 3.6407, 3.5613, 3.7578, 3.5435],\n",
      "        [3.5681, 3.6927, 3.5882, 3.7571, 3.5730],\n",
      "        [3.7820, 3.9869, 3.7966, 3.7948, 3.7135],\n",
      "        [3.8075, 3.9278, 3.8690, 3.9450, 3.8345],\n",
      "        [3.3830, 3.4385, 3.5101, 3.5974, 3.3732],\n",
      "        [3.5156, 3.5784, 3.6754, 3.6921, 3.5732],\n",
      "        [3.7294, 3.8787, 3.7358, 3.8770, 3.8089],\n",
      "        [3.7050, 3.7662, 3.7831, 3.8576, 3.8362],\n",
      "        [3.4574, 3.6271, 3.5013, 3.6652, 3.4923],\n",
      "        [3.9212, 4.0694, 3.6963, 3.8917, 3.6303],\n",
      "        [3.5764, 3.8361, 3.6888, 3.8911, 3.6480],\n",
      "        [3.4557, 3.6865, 3.6494, 3.6787, 3.5665],\n",
      "        [3.4198, 3.5999, 3.4909, 3.6109, 3.4605],\n",
      "        [3.9268, 4.0792, 3.7036, 3.9085, 3.6260],\n",
      "        [3.3587, 3.6489, 3.6275, 3.5882, 3.4664],\n",
      "        [3.4399, 3.6094, 3.4848, 3.6421, 3.4623],\n",
      "        [3.4715, 3.7900, 3.7386, 3.6388, 3.6164],\n",
      "        [4.0484, 4.2641, 3.9144, 4.0399, 3.7629],\n",
      "        [3.7078, 3.8566, 3.7050, 3.8358, 3.7812],\n",
      "        [3.6963, 3.7756, 3.7843, 3.8763, 3.8501],\n",
      "        [3.5158, 3.8373, 3.7503, 3.8275, 3.7453],\n",
      "        [3.8649, 4.0517, 3.8104, 3.8634, 3.7041],\n",
      "        [3.4893, 3.6530, 3.5017, 3.7035, 3.5061],\n",
      "        [3.3441, 3.6449, 3.7071, 3.5960, 3.5672],\n",
      "        [3.3932, 3.5804, 3.4896, 3.5802, 3.4511],\n",
      "        [3.3820, 3.5742, 3.4949, 3.5662, 3.4480],\n",
      "        [3.4714, 3.7849, 3.7401, 3.6378, 3.6133],\n",
      "        [3.3541, 3.5606, 3.5863, 3.5835, 3.4361],\n",
      "        [3.3505, 3.5729, 3.5852, 3.5827, 3.4387],\n",
      "        [3.5133, 3.5669, 3.7045, 3.7006, 3.5740],\n",
      "        [3.3939, 3.4489, 3.5170, 3.6136, 3.4023],\n",
      "        [3.8647, 3.8312, 3.9342, 4.1112, 3.8166],\n",
      "        [3.4601, 3.6250, 3.5003, 3.6447, 3.4985],\n",
      "        [3.4787, 3.6471, 3.5037, 3.6939, 3.5023],\n",
      "        [3.5236, 3.6978, 3.6580, 3.7305, 3.6063],\n",
      "        [3.5115, 3.6801, 3.5231, 3.7334, 3.5335],\n",
      "        [3.5073, 3.5944, 3.7274, 3.7172, 3.5846],\n",
      "        [3.3786, 3.6639, 3.6305, 3.6023, 3.4994],\n",
      "        [3.4883, 3.6061, 3.5879, 3.7385, 3.5465],\n",
      "        [3.6230, 3.7330, 3.8039, 3.7659, 3.5455],\n",
      "        [3.4854, 3.5599, 3.6279, 3.6662, 3.5134],\n",
      "        [3.4442, 3.4659, 3.5982, 3.6479, 3.5327],\n",
      "        [3.5919, 3.6165, 3.6544, 3.6469, 3.4029],\n",
      "        [3.3709, 3.4798, 3.5361, 3.5723, 3.3887],\n",
      "        [3.4916, 3.6963, 3.6926, 3.6991, 3.6643],\n",
      "        [3.9747, 3.7529, 3.8946, 4.3673, 4.1295]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4144, 3.5960, 3.5002, 3.5968, 3.4777],\n",
      "        [3.5995, 3.8041, 3.6468, 3.7701, 3.6214],\n",
      "        [3.3678, 3.5105, 3.5553, 3.5845, 3.4208],\n",
      "        [3.4431, 3.4667, 3.5924, 3.6426, 3.5199],\n",
      "        [3.3439, 3.6497, 3.4476, 3.6510, 3.3805],\n",
      "        [3.5275, 3.6675, 3.6589, 3.6813, 3.5701],\n",
      "        [3.5484, 3.6208, 3.6451, 3.7527, 3.5606],\n",
      "        [3.4268, 3.6054, 3.4941, 3.6220, 3.4749],\n",
      "        [3.5065, 3.5787, 3.6534, 3.6850, 3.5781],\n",
      "        [3.5556, 3.8367, 3.6645, 3.8793, 3.6416],\n",
      "        [3.6351, 3.8423, 3.6777, 3.9463, 3.6933],\n",
      "        [3.7063, 3.9451, 3.7599, 3.7151, 3.6659],\n",
      "        [3.6535, 3.8314, 3.7960, 3.8006, 3.5200],\n",
      "        [3.3407, 3.5800, 3.5831, 3.5729, 3.4234],\n",
      "        [3.7084, 3.7723, 3.8108, 3.8864, 3.8524],\n",
      "        [3.4583, 3.6263, 3.4989, 3.6466, 3.4983],\n",
      "        [3.5571, 3.7052, 3.6945, 3.7366, 3.6974],\n",
      "        [3.7257, 3.8409, 3.8152, 3.8972, 3.8914],\n",
      "        [3.4758, 3.6290, 3.5345, 3.6715, 3.5242],\n",
      "        [3.6112, 3.6506, 3.7200, 3.8645, 3.5115],\n",
      "        [3.7294, 3.9291, 3.7257, 3.7426, 3.6049],\n",
      "        [3.4776, 3.6505, 3.6389, 3.6315, 3.4408],\n",
      "        [3.2622, 3.4622, 3.4441, 3.4318, 3.3419],\n",
      "        [3.4823, 3.5436, 3.6337, 3.6630, 3.4965],\n",
      "        [3.3795, 3.4523, 3.5155, 3.5969, 3.3836],\n",
      "        [3.4094, 3.7934, 3.7725, 3.7028, 3.6977],\n",
      "        [3.6602, 3.8056, 3.8045, 3.9604, 3.6286],\n",
      "        [3.7487, 3.7986, 3.8247, 4.0136, 3.9252],\n",
      "        [3.5977, 3.6979, 3.6892, 3.7163, 3.3868],\n",
      "        [3.5176, 3.8198, 3.7531, 3.8149, 3.7429],\n",
      "        [3.4913, 3.5200, 3.6502, 3.6881, 3.6142],\n",
      "        [3.8706, 4.0873, 4.0348, 4.1592, 4.1184],\n",
      "        [3.4670, 3.6909, 3.5824, 3.7111, 3.5829],\n",
      "        [3.3539, 3.6130, 3.6024, 3.5925, 3.4519],\n",
      "        [3.6351, 3.8423, 3.6777, 3.9463, 3.6933],\n",
      "        [3.5715, 3.6680, 3.6575, 3.8194, 3.5753],\n",
      "        [3.6307, 3.7036, 3.7272, 3.7404, 3.4594],\n",
      "        [3.3682, 3.5072, 3.5530, 3.5822, 3.4208],\n",
      "        [3.4066, 3.5506, 3.4973, 3.6295, 3.4233],\n",
      "        [3.4988, 3.5665, 3.6430, 3.6727, 3.5234],\n",
      "        [3.3803, 3.5755, 3.4936, 3.5681, 3.4477],\n",
      "        [3.5952, 3.6329, 3.6703, 3.6093, 3.4080],\n",
      "        [3.5218, 3.7572, 3.6267, 3.7894, 3.5426],\n",
      "        [3.6052, 3.6236, 3.7095, 3.6515, 3.5601],\n",
      "        [3.3480, 3.5611, 3.5006, 3.5853, 3.4105],\n",
      "        [3.4057, 3.5875, 3.4945, 3.6016, 3.4672],\n",
      "        [3.7089, 3.8689, 3.8288, 3.8944, 3.8755],\n",
      "        [3.5669, 3.5773, 3.6514, 3.6837, 3.5953],\n",
      "        [3.3760, 3.5787, 3.4911, 3.5684, 3.4463],\n",
      "        [3.5440, 3.6422, 3.7154, 3.7540, 3.6785],\n",
      "        [3.5714, 3.7919, 3.6530, 3.8138, 3.5884],\n",
      "        [3.6627, 3.7829, 3.7597, 3.8433, 3.7529],\n",
      "        [3.3067, 3.5290, 3.5165, 3.5660, 3.4323],\n",
      "        [3.4719, 3.6230, 3.5376, 3.6910, 3.4828],\n",
      "        [3.5381, 3.7407, 3.5488, 3.6744, 3.5590],\n",
      "        [3.4707, 3.6414, 3.5061, 3.6797, 3.5055],\n",
      "        [3.3635, 3.5628, 3.4924, 3.5484, 3.4401],\n",
      "        [3.4713, 3.7811, 3.7351, 3.6147, 3.6287],\n",
      "        [3.3922, 3.4502, 3.5156, 3.6155, 3.4020],\n",
      "        [3.3209, 3.5237, 3.4803, 3.4978, 3.4025],\n",
      "        [3.5663, 3.6941, 3.5868, 3.7590, 3.5727],\n",
      "        [3.5258, 3.5883, 3.6451, 3.6914, 3.5664],\n",
      "        [3.3364, 3.5409, 3.4818, 3.5188, 3.4138],\n",
      "        [3.4833, 3.7167, 3.6919, 3.7127, 3.4803]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3796, 3.4458, 3.5083, 3.6070, 3.3859],\n",
      "        [3.5044, 3.5789, 3.6592, 3.6903, 3.5681],\n",
      "        [3.3780, 3.5034, 3.4521, 3.6315, 3.3410],\n",
      "        [3.6291, 3.7129, 3.5644, 3.8388, 3.7097],\n",
      "        [3.3494, 3.6303, 3.6058, 3.5861, 3.4562],\n",
      "        [3.4905, 3.5576, 3.6899, 3.7155, 3.5363],\n",
      "        [3.6031, 3.9720, 3.8334, 3.8829, 3.8321],\n",
      "        [3.4752, 3.7111, 3.6584, 3.7058, 3.5440],\n",
      "        [3.3498, 3.5297, 3.5643, 3.5735, 3.4120],\n",
      "        [3.5247, 3.7648, 3.6518, 3.7163, 3.6158],\n",
      "        [3.5098, 3.5690, 3.7017, 3.7040, 3.5734],\n",
      "        [3.5361, 3.6707, 3.6606, 3.7106, 3.5674],\n",
      "        [3.4999, 3.6676, 3.8186, 3.7525, 3.6804],\n",
      "        [3.4710, 3.6406, 3.4874, 3.6886, 3.4845],\n",
      "        [3.6229, 3.7729, 3.6565, 3.8366, 3.6328],\n",
      "        [3.7868, 3.7501, 3.7423, 3.8989, 3.7572],\n",
      "        [3.5935, 3.6118, 3.6928, 3.6594, 3.5358],\n",
      "        [4.0749, 4.3529, 3.9172, 4.1111, 3.8046],\n",
      "        [3.8088, 3.8051, 3.8123, 3.9525, 3.7650],\n",
      "        [3.5990, 3.7066, 3.7494, 3.7767, 3.6154],\n",
      "        [3.2872, 3.4945, 3.4659, 3.4590, 3.3754],\n",
      "        [3.5985, 3.6804, 3.7858, 3.8192, 3.5904],\n",
      "        [3.3757, 3.4742, 3.5275, 3.5904, 3.3978],\n",
      "        [3.4698, 3.6430, 3.5034, 3.6893, 3.5022],\n",
      "        [3.4094, 3.6168, 3.6920, 3.6814, 3.6019],\n",
      "        [3.5888, 3.8506, 3.8173, 3.8333, 3.5926],\n",
      "        [3.5010, 3.7140, 3.5639, 3.8297, 3.4772],\n",
      "        [3.3360, 3.5762, 3.5799, 3.5732, 3.4167],\n",
      "        [3.9694, 4.1596, 3.9003, 3.9696, 3.7879],\n",
      "        [3.5300, 3.7706, 3.6466, 3.7157, 3.6233],\n",
      "        [3.8060, 3.8544, 3.8808, 4.0491, 3.7954],\n",
      "        [3.5248, 3.7464, 3.5859, 3.6649, 3.5782],\n",
      "        [3.4857, 3.6551, 3.4988, 3.7068, 3.5055],\n",
      "        [3.4374, 3.5788, 3.5291, 3.6945, 3.4872],\n",
      "        [3.5976, 3.7207, 3.6771, 3.8997, 3.5846],\n",
      "        [3.4723, 3.6464, 3.5842, 3.7521, 3.6134],\n",
      "        [3.6088, 3.9214, 3.8291, 3.8683, 3.8430],\n",
      "        [3.4837, 3.5474, 3.6383, 3.6631, 3.5020],\n",
      "        [3.5109, 3.6134, 3.7440, 3.7419, 3.5904],\n",
      "        [3.8303, 3.8139, 3.8082, 4.0594, 3.7685],\n",
      "        [3.3462, 3.5378, 3.5654, 3.5719, 3.4117],\n",
      "        [3.2959, 3.5070, 3.4666, 3.4748, 3.3832],\n",
      "        [3.8293, 3.8156, 3.8612, 3.9968, 3.8178],\n",
      "        [3.5123, 3.5881, 3.6964, 3.7299, 3.5800],\n",
      "        [3.7119, 3.6305, 3.6802, 4.0673, 3.7654],\n",
      "        [3.4055, 3.5722, 3.6408, 3.7115, 3.5425],\n",
      "        [3.6606, 3.8165, 3.7969, 3.8419, 3.8244],\n",
      "        [3.2886, 3.4967, 3.4640, 3.4648, 3.3829],\n",
      "        [3.4672, 3.6580, 3.6424, 3.7826, 3.5106],\n",
      "        [3.6293, 3.8388, 3.6707, 3.9402, 3.6867],\n",
      "        [3.4386, 3.5411, 3.6305, 3.6641, 3.4986],\n",
      "        [3.8361, 3.7223, 3.8372, 4.3233, 4.0407],\n",
      "        [3.6539, 3.6719, 3.7598, 3.8429, 3.6093],\n",
      "        [3.6332, 3.8432, 3.6761, 3.9479, 3.6929],\n",
      "        [3.4586, 3.7262, 3.7177, 3.7007, 3.5734],\n",
      "        [3.3990, 3.4140, 3.6065, 3.4321, 3.5288],\n",
      "        [3.6313, 3.7875, 3.6884, 3.7124, 3.6082],\n",
      "        [3.3785, 3.5763, 3.4922, 3.5696, 3.4474],\n",
      "        [3.5861, 3.6832, 3.7148, 3.7226, 3.7030],\n",
      "        [3.5701, 3.8409, 3.6857, 3.8931, 3.6470],\n",
      "        [3.3937, 3.5819, 3.4877, 3.5892, 3.4448],\n",
      "        [3.4974, 3.5740, 3.6367, 3.6747, 3.5767],\n",
      "        [3.3774, 3.5442, 3.5927, 3.6049, 3.4175],\n",
      "        [3.3640, 3.5462, 3.5960, 3.6060, 3.4100]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5162, 3.7390, 3.5785, 3.8539, 3.4909],\n",
      "        [3.7216, 3.8505, 3.8109, 3.8924, 3.8860],\n",
      "        [3.5637, 3.9428, 3.6858, 3.9241, 3.7274],\n",
      "        [3.3259, 3.4529, 3.4814, 3.5226, 3.3784],\n",
      "        [3.4593, 3.6207, 3.5257, 3.6582, 3.5125],\n",
      "        [3.6649, 3.8851, 3.6545, 3.7744, 3.6544],\n",
      "        [3.3297, 3.5438, 3.4826, 3.5266, 3.4155],\n",
      "        [3.5542, 3.6804, 3.6716, 3.7240, 3.5740],\n",
      "        [3.3838, 3.5376, 3.5803, 3.5535, 3.4381],\n",
      "        [3.3884, 3.5992, 3.7311, 3.6437, 3.5862],\n",
      "        [3.5934, 3.6347, 3.6967, 3.6690, 3.5065],\n",
      "        [3.4497, 3.7890, 3.7577, 3.6660, 3.7656],\n",
      "        [3.3204, 3.4911, 3.4271, 3.5960, 3.3263],\n",
      "        [3.4876, 3.5998, 3.7142, 3.6232, 3.6808],\n",
      "        [3.4020, 3.6338, 3.6972, 3.7025, 3.6103],\n",
      "        [3.4688, 3.6403, 3.4992, 3.6677, 3.5070],\n",
      "        [3.4913, 3.6542, 3.6040, 3.8186, 3.5302],\n",
      "        [3.4280, 3.6036, 3.4826, 3.6288, 3.4557],\n",
      "        [3.4199, 3.5551, 3.4049, 3.6932, 3.3614],\n",
      "        [3.3162, 3.5415, 3.4956, 3.5595, 3.4070],\n",
      "        [3.4902, 3.4808, 3.5764, 3.5504, 3.4094],\n",
      "        [3.6336, 3.8477, 3.6757, 3.9503, 3.6958],\n",
      "        [3.3188, 3.4843, 3.4093, 3.5845, 3.3335],\n",
      "        [3.7451, 3.8015, 3.8217, 4.0163, 3.9242],\n",
      "        [3.4879, 3.5229, 3.6473, 3.6906, 3.6133],\n",
      "        [3.4255, 3.5816, 3.5290, 3.6983, 3.4847],\n",
      "        [3.4318, 3.5574, 3.6177, 3.6713, 3.5041],\n",
      "        [3.6012, 3.9156, 3.8187, 3.8564, 3.8358],\n",
      "        [3.3739, 3.6199, 3.5600, 3.7282, 3.3987],\n",
      "        [3.3647, 3.5100, 3.5501, 3.5847, 3.4199],\n",
      "        [3.4790, 3.9254, 3.7894, 3.7491, 3.5631],\n",
      "        [3.5473, 3.6254, 3.7329, 3.7658, 3.6042],\n",
      "        [3.7642, 3.8905, 3.7616, 3.9243, 3.8173],\n",
      "        [3.4692, 3.6426, 3.4860, 3.6895, 3.4839],\n",
      "        [3.4643, 3.5929, 3.5455, 3.6044, 3.4940],\n",
      "        [3.5238, 3.6066, 3.7398, 3.8644, 3.7591],\n",
      "        [3.6364, 3.8217, 3.7766, 3.7934, 3.5066],\n",
      "        [3.5816, 3.6094, 3.6878, 3.6530, 3.5167],\n",
      "        [3.4233, 3.6173, 3.5908, 3.5399, 3.4732],\n",
      "        [3.6439, 3.8502, 3.7684, 3.8739, 3.6568],\n",
      "        [3.6217, 3.8202, 3.7570, 3.9301, 3.6371],\n",
      "        [3.3577, 3.4981, 3.5408, 3.5776, 3.4037],\n",
      "        [3.3725, 3.5814, 3.4883, 3.5709, 3.4454],\n",
      "        [3.8600, 4.0558, 3.8061, 3.8680, 3.7029],\n",
      "        [3.5020, 3.6376, 3.5529, 3.7504, 3.5317],\n",
      "        [3.4831, 3.5772, 3.6262, 3.6864, 3.5161],\n",
      "        [3.5700, 3.8953, 3.7472, 3.8367, 3.7575],\n",
      "        [3.4107, 3.5670, 3.6271, 3.6917, 3.5228],\n",
      "        [3.5869, 3.8528, 3.8157, 3.8342, 3.5920],\n",
      "        [3.6624, 3.8163, 3.7248, 3.8188, 3.7365],\n",
      "        [3.5684, 3.6898, 3.6086, 3.7961, 3.5983],\n",
      "        [3.4496, 3.5706, 3.5538, 3.5922, 3.5042],\n",
      "        [3.4110, 3.8277, 3.7404, 3.7410, 3.6958],\n",
      "        [3.7719, 3.7241, 3.8415, 4.0088, 3.7156],\n",
      "        [3.4931, 3.6662, 3.4930, 3.7163, 3.5037],\n",
      "        [3.3888, 3.4536, 3.5130, 3.6091, 3.3958],\n",
      "        [3.3455, 3.4678, 3.5271, 3.5555, 3.3843],\n",
      "        [3.3049, 3.5950, 3.3839, 3.6014, 3.3238],\n",
      "        [3.3258, 3.6617, 3.7336, 3.5745, 3.5518],\n",
      "        [3.5896, 3.6744, 3.7793, 3.8257, 3.5758],\n",
      "        [3.5377, 3.9464, 3.7327, 3.9037, 3.7353],\n",
      "        [3.3541, 3.5499, 3.5761, 3.5902, 3.4321],\n",
      "        [3.4740, 3.5658, 3.6129, 3.6686, 3.5092],\n",
      "        [3.4860, 3.7178, 3.5707, 3.8199, 3.4749]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7494, 3.8007, 3.8166, 3.9924, 3.7241],\n",
      "        [3.6100, 3.7880, 3.7852, 3.7508, 3.5113],\n",
      "        [3.6212, 3.7791, 3.6610, 3.8382, 3.6403],\n",
      "        [3.3603, 3.6752, 3.7654, 3.6526, 3.5673],\n",
      "        [3.6079, 3.7375, 3.6056, 3.8235, 3.6504],\n",
      "        [3.7139, 3.5486, 3.6994, 4.0182, 3.8405],\n",
      "        [3.3983, 3.5700, 3.4877, 3.6372, 3.4270],\n",
      "        [3.6525, 3.7450, 3.6981, 3.8809, 3.7555],\n",
      "        [3.6890, 3.9086, 3.6560, 3.7872, 3.6578],\n",
      "        [3.4111, 3.8444, 3.6843, 3.7362, 3.7026],\n",
      "        [4.0416, 4.2697, 3.9085, 4.0451, 3.7612],\n",
      "        [3.5533, 3.6135, 3.6381, 3.6135, 3.3735],\n",
      "        [3.3690, 3.4779, 3.5264, 3.5869, 3.3936],\n",
      "        [3.3991, 3.6023, 3.6644, 3.6549, 3.4432],\n",
      "        [3.4910, 3.6678, 3.4915, 3.7167, 3.5032],\n",
      "        [3.4482, 3.6924, 3.6433, 3.6838, 3.5647],\n",
      "        [3.5779, 3.6123, 3.6850, 3.6580, 3.5023],\n",
      "        [3.9580, 4.2243, 3.7852, 3.9432, 3.7274],\n",
      "        [3.5802, 3.6090, 3.7876, 3.8432, 3.5467],\n",
      "        [3.5795, 3.6110, 3.6862, 3.6534, 3.5161],\n",
      "        [3.4758, 3.7597, 3.6520, 3.8617, 3.5376],\n",
      "        [3.4606, 3.8137, 3.6560, 3.6851, 3.4450],\n",
      "        [3.5058, 3.6746, 3.6465, 3.6844, 3.5569],\n",
      "        [3.5970, 3.6349, 3.6938, 3.7591, 3.5540],\n",
      "        [3.7636, 3.8088, 3.8236, 3.9587, 3.6149],\n",
      "        [3.9098, 3.7751, 3.9277, 4.3932, 4.1243],\n",
      "        [3.4632, 3.6617, 3.6393, 3.7843, 3.5095],\n",
      "        [3.7247, 3.7742, 3.8560, 3.9050, 3.5524],\n",
      "        [3.6102, 3.7998, 3.7456, 3.8028, 3.5184],\n",
      "        [3.6658, 3.8434, 3.8094, 3.8208, 3.5297],\n",
      "        [3.7724, 3.7173, 3.6960, 3.8748, 3.7227],\n",
      "        [3.5521, 3.6819, 3.6701, 3.7244, 3.5734],\n",
      "        [3.6156, 3.7394, 3.7978, 3.7709, 3.5436],\n",
      "        [3.3676, 3.4850, 3.5330, 3.5959, 3.4000],\n",
      "        [3.5602, 3.9391, 3.6745, 3.9158, 3.7135],\n",
      "        [3.5779, 3.6123, 3.6850, 3.6580, 3.5023],\n",
      "        [3.5054, 3.5721, 3.6471, 3.6605, 3.5637],\n",
      "        [3.5791, 3.6896, 3.7109, 3.7411, 3.6857],\n",
      "        [3.5688, 3.6372, 3.7555, 3.8184, 3.5626],\n",
      "        [3.3799, 3.4387, 3.4965, 3.5990, 3.3802],\n",
      "        [3.7856, 3.8858, 3.8025, 4.0659, 3.7917],\n",
      "        [3.4842, 3.7599, 3.6004, 3.6490, 3.5793],\n",
      "        [3.6354, 3.7997, 3.6715, 3.8448, 3.6456],\n",
      "        [3.3920, 3.4869, 3.6165, 3.6133, 3.4554],\n",
      "        [3.4436, 3.5322, 3.6082, 3.6248, 3.4766],\n",
      "        [3.5334, 3.8291, 3.6358, 3.8705, 3.6285],\n",
      "        [3.4087, 3.8295, 3.7389, 3.7416, 3.6952],\n",
      "        [3.3897, 3.4987, 3.5592, 3.6094, 3.3927],\n",
      "        [3.7523, 3.5352, 3.6871, 4.0832, 3.8901],\n",
      "        [3.3570, 3.5124, 3.5507, 3.5865, 3.4171],\n",
      "        [3.5200, 3.5719, 3.6818, 3.7002, 3.5736],\n",
      "        [3.5555, 3.7350, 3.6336, 3.7855, 3.6339],\n",
      "        [3.4042, 3.5860, 3.4814, 3.5994, 3.4437],\n",
      "        [3.6608, 3.7177, 3.8199, 3.7974, 3.4696],\n",
      "        [3.5262, 3.7743, 3.6435, 3.7171, 3.6222],\n",
      "        [3.4999, 3.6392, 3.5514, 3.7509, 3.5312],\n",
      "        [3.3409, 3.6502, 3.7125, 3.6017, 3.5237],\n",
      "        [3.7484, 3.5573, 3.7066, 4.0552, 3.8806],\n",
      "        [3.4259, 3.6452, 3.6098, 3.7608, 3.4560],\n",
      "        [3.4192, 3.5592, 3.6153, 3.6834, 3.5182],\n",
      "        [3.4013, 3.5758, 3.6376, 3.7129, 3.5413],\n",
      "        [3.4758, 3.6078, 3.7526, 3.7960, 3.5877],\n",
      "        [3.6275, 3.7911, 3.6855, 3.7138, 3.6071],\n",
      "        [3.7179, 3.9446, 3.8838, 3.8901, 3.5548]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7049, 3.8853, 3.8901, 4.0496, 4.0066],\n",
      "        [3.4716, 3.6209, 3.6230, 3.6885, 3.6530],\n",
      "        [3.5202, 3.6741, 3.6527, 3.6842, 3.5680],\n",
      "        [3.5468, 3.7938, 3.6767, 3.7225, 3.6294],\n",
      "        [3.5422, 3.8950, 3.8346, 3.8672, 3.7476],\n",
      "        [3.4651, 3.6520, 3.4895, 3.6967, 3.4922],\n",
      "        [3.4743, 3.6612, 3.4953, 3.7002, 3.5047],\n",
      "        [3.4640, 3.8776, 3.7026, 3.8035, 3.7183],\n",
      "        [3.4056, 3.5508, 3.5908, 3.6698, 3.4840],\n",
      "        [3.4268, 3.6292, 3.6170, 3.6970, 3.4475],\n",
      "        [3.6114, 3.6703, 3.7125, 3.7114, 3.4821],\n",
      "        [3.6438, 3.8583, 3.6534, 3.7994, 3.6926],\n",
      "        [3.4603, 3.6423, 3.5843, 3.8531, 3.4635],\n",
      "        [3.4057, 3.6361, 3.5248, 3.7155, 3.4425],\n",
      "        [3.4385, 3.6039, 3.5297, 3.5966, 3.4625],\n",
      "        [3.4763, 3.5934, 3.6267, 3.6844, 3.5184],\n",
      "        [3.7615, 3.8108, 3.8218, 3.9588, 3.6143],\n",
      "        [3.3847, 3.4563, 3.5094, 3.6186, 3.4000],\n",
      "        [3.5220, 3.6842, 3.6486, 3.7144, 3.6620],\n",
      "        [3.6448, 3.7785, 3.7833, 3.8711, 3.5680],\n",
      "        [3.6819, 3.7707, 3.7520, 3.8438, 3.7799],\n",
      "        [3.6414, 3.8724, 3.6633, 3.8025, 3.6942],\n",
      "        [3.4618, 3.5552, 3.5650, 3.7116, 3.4399],\n",
      "        [3.4724, 3.6595, 3.4922, 3.7101, 3.5040],\n",
      "        [3.3537, 3.5016, 3.5376, 3.5782, 3.4026],\n",
      "        [3.8309, 3.7283, 3.8414, 4.3221, 4.0484],\n",
      "        [3.4181, 3.4533, 3.5002, 3.6064, 3.3779],\n",
      "        [3.6280, 3.9022, 3.8108, 3.8849, 3.7881],\n",
      "        [3.4238, 3.6472, 3.6080, 3.7610, 3.4554],\n",
      "        [3.4707, 3.7119, 3.6561, 3.7104, 3.5361],\n",
      "        [3.4840, 3.5680, 3.6308, 3.6734, 3.5127],\n",
      "        [3.3332, 3.5863, 3.5772, 3.5760, 3.4214],\n",
      "        [3.7887, 3.8972, 3.7810, 3.9441, 3.8494],\n",
      "        [3.6766, 3.8103, 3.8282, 3.9843, 3.6320],\n",
      "        [3.7222, 3.9352, 3.7196, 3.7457, 3.6028],\n",
      "        [3.3582, 3.5517, 3.5914, 3.6076, 3.4084],\n",
      "        [3.5235, 3.6081, 3.7134, 3.7524, 3.5934],\n",
      "        [3.6674, 3.9344, 3.7592, 3.9553, 3.7550],\n",
      "        [3.3451, 3.5487, 3.4745, 3.5392, 3.4131],\n",
      "        [3.7751, 3.8239, 3.8407, 3.9879, 3.6152],\n",
      "        [3.8056, 3.8655, 3.8739, 4.0371, 3.8015],\n",
      "        [3.5139, 3.9092, 3.7652, 3.7573, 3.5345],\n",
      "        [3.3884, 3.4914, 3.5335, 3.6143, 3.4165],\n",
      "        [3.6773, 3.8966, 3.6398, 3.7654, 3.6431],\n",
      "        [3.4970, 3.5780, 3.6594, 3.6932, 3.5621],\n",
      "        [3.6265, 3.7262, 3.7176, 3.8252, 3.7593],\n",
      "        [3.5295, 3.6149, 3.7005, 3.7205, 3.5961],\n",
      "        [3.8166, 3.9219, 3.8335, 4.1139, 3.8403],\n",
      "        [3.7094, 3.6245, 3.6784, 4.0878, 3.7686],\n",
      "        [3.3302, 3.5817, 3.5754, 3.5748, 3.4150],\n",
      "        [3.4001, 3.5822, 3.6417, 3.7136, 3.5375],\n",
      "        [3.4431, 3.6456, 3.5010, 3.6648, 3.4864],\n",
      "        [3.4871, 3.6579, 3.6007, 3.8194, 3.5290],\n",
      "        [3.7037, 3.7912, 3.7466, 3.8464, 3.7289],\n",
      "        [3.3370, 3.5964, 3.5837, 3.5876, 3.4378],\n",
      "        [3.4749, 3.5773, 3.6154, 3.6701, 3.5105],\n",
      "        [3.3994, 3.6453, 3.5587, 3.6383, 3.5176],\n",
      "        [3.6313, 3.8142, 3.6803, 3.7971, 3.6213],\n",
      "        [3.4693, 3.6515, 3.4904, 3.7014, 3.5017],\n",
      "        [3.3971, 3.6043, 3.6628, 3.6550, 3.4427],\n",
      "        [3.2903, 3.5124, 3.4623, 3.4763, 3.3817],\n",
      "        [3.3725, 3.5147, 3.5559, 3.6029, 3.4248],\n",
      "        [3.7226, 3.7762, 3.8542, 3.9050, 3.5517],\n",
      "        [3.6986, 3.9516, 3.7535, 3.7184, 3.6637]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4628, 3.6453, 3.4943, 3.6678, 3.5053],\n",
      "        [3.2372, 3.4796, 3.5059, 3.4973, 3.3885],\n",
      "        [3.5515, 3.7385, 3.6300, 3.7853, 3.6326],\n",
      "        [3.5292, 3.7354, 3.7015, 3.8174, 3.6574],\n",
      "        [3.5588, 3.6402, 3.7434, 3.7756, 3.6100],\n",
      "        [3.8636, 3.9272, 3.8513, 4.0700, 3.8711],\n",
      "        [3.5862, 3.6411, 3.6622, 3.6121, 3.4053],\n",
      "        [3.4123, 3.8399, 3.6653, 3.7516, 3.6790],\n",
      "        [3.6587, 3.8902, 3.6494, 3.7747, 3.6525],\n",
      "        [3.7354, 3.8485, 3.8239, 3.9210, 3.9369],\n",
      "        [3.3524, 3.5301, 3.5517, 3.5826, 3.4210],\n",
      "        [3.6281, 3.8485, 3.6623, 3.9398, 3.6799],\n",
      "        [3.6085, 3.8029, 3.6590, 3.7764, 3.6277],\n",
      "        [3.6895, 3.8997, 3.8534, 3.8435, 3.4906],\n",
      "        [3.6517, 3.6867, 3.6645, 4.0028, 3.7251],\n",
      "        [3.4834, 3.6187, 3.6436, 3.7064, 3.5483],\n",
      "        [3.5580, 3.5854, 3.6435, 3.6862, 3.5926],\n",
      "        [3.3673, 3.5764, 3.4836, 3.5636, 3.4357],\n",
      "        [3.2447, 3.4806, 3.5159, 3.5012, 3.4163],\n",
      "        [3.5672, 3.8122, 3.6902, 3.7105, 3.6587],\n",
      "        [3.7455, 3.8042, 3.8131, 3.9922, 3.7228],\n",
      "        [3.6390, 3.6717, 3.7396, 3.8383, 3.5934],\n",
      "        [3.4966, 3.6877, 3.5106, 3.7383, 3.5253],\n",
      "        [3.4317, 3.5541, 3.6192, 3.6711, 3.5010],\n",
      "        [3.3039, 3.4365, 3.5025, 3.5205, 3.3221],\n",
      "        [3.6476, 3.8217, 3.7910, 3.9658, 3.6268],\n",
      "        [3.4346, 3.6183, 3.7329, 3.6940, 3.6043],\n",
      "        [3.4672, 3.5060, 3.5931, 3.6668, 3.6061],\n",
      "        [3.5000, 3.6998, 3.5135, 3.7447, 3.5379],\n",
      "        [3.6238, 3.9312, 3.7108, 3.8499, 3.6642],\n",
      "        [3.6514, 3.9303, 3.7542, 3.9404, 3.7493],\n",
      "        [3.4829, 3.6186, 3.6439, 3.7152, 3.5441],\n",
      "        [3.4267, 3.5922, 3.5177, 3.5867, 3.4517],\n",
      "        [3.5602, 3.7958, 3.6442, 3.8094, 3.5931],\n",
      "        [3.4989, 3.6379, 3.7089, 3.7319, 3.6529],\n",
      "        [3.7523, 3.9043, 3.8302, 3.9033, 3.7833],\n",
      "        [3.3295, 3.5821, 3.5744, 3.5733, 3.4180],\n",
      "        [3.2808, 3.5175, 3.5041, 3.5589, 3.4160],\n",
      "        [3.3820, 3.6044, 3.7261, 3.6441, 3.5844],\n",
      "        [3.3240, 3.5488, 3.4779, 3.5269, 3.4138],\n",
      "        [3.6381, 3.9184, 3.7138, 3.6749, 3.6615],\n",
      "        [3.4099, 3.6083, 3.4839, 3.6244, 3.4592],\n",
      "        [3.5476, 3.8839, 3.7713, 3.8014, 3.5740],\n",
      "        [3.5221, 3.7557, 3.5712, 3.6736, 3.5697],\n",
      "        [3.3275, 3.5940, 3.7260, 3.5734, 3.5842],\n",
      "        [3.5479, 3.8463, 3.5947, 3.7589, 3.5766],\n",
      "        [3.4786, 3.6060, 3.6317, 3.7020, 3.5374],\n",
      "        [3.4460, 3.6913, 3.5469, 3.7690, 3.4598],\n",
      "        [3.4410, 3.8772, 3.7662, 3.7879, 3.7374],\n",
      "        [3.4435, 3.5682, 3.5884, 3.6921, 3.4519],\n",
      "        [3.3988, 3.8024, 3.7643, 3.7061, 3.6948],\n",
      "        [3.8718, 4.1307, 3.6962, 3.8511, 3.6538],\n",
      "        [3.6301, 3.8211, 3.6806, 3.8447, 3.6473],\n",
      "        [3.6215, 3.7113, 3.7191, 3.7429, 3.4567],\n",
      "        [3.4969, 3.5859, 3.6528, 3.6913, 3.5658],\n",
      "        [3.5222, 3.5386, 3.5956, 3.6521, 3.5527],\n",
      "        [3.6309, 3.8764, 3.8135, 3.8907, 3.6483],\n",
      "        [3.4741, 3.5622, 3.6122, 3.6675, 3.5098],\n",
      "        [3.3230, 3.5531, 3.4925, 3.5210, 3.4246],\n",
      "        [3.6767, 3.8590, 3.6726, 3.8263, 3.7410],\n",
      "        [3.6238, 3.6543, 3.7182, 3.8059, 3.5681],\n",
      "        [3.4579, 3.8779, 3.6780, 3.8116, 3.6902],\n",
      "        [3.5455, 3.6490, 3.6378, 3.7849, 3.5605],\n",
      "        [3.6316, 3.7950, 3.8443, 3.8887, 3.7616]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3857, 3.4691, 3.5131, 3.6091, 3.3909],\n",
      "        [3.4925, 3.6682, 3.6023, 3.8075, 3.5512],\n",
      "        [3.4462, 3.7286, 3.6963, 3.6989, 3.5547],\n",
      "        [3.4693, 3.8757, 3.6671, 3.8121, 3.6725],\n",
      "        [3.7545, 3.7930, 3.7207, 3.8866, 3.7103],\n",
      "        [3.8926, 4.0797, 3.7173, 3.9126, 3.6625],\n",
      "        [3.7121, 3.9495, 3.8782, 3.8892, 3.5526],\n",
      "        [3.7148, 3.8304, 3.8704, 4.0214, 3.6562],\n",
      "        [3.8228, 3.9752, 3.8684, 3.9828, 3.9044],\n",
      "        [3.3169, 3.4070, 3.4813, 3.6035, 3.3692],\n",
      "        [3.4267, 3.5443, 3.4452, 3.6041, 3.5410],\n",
      "        [3.5370, 3.6150, 3.7381, 3.8559, 3.7607],\n",
      "        [3.3482, 3.5099, 3.5374, 3.5742, 3.4008],\n",
      "        [3.5111, 3.8067, 3.6623, 3.8627, 3.5368],\n",
      "        [3.4858, 3.7230, 3.6919, 3.7108, 3.6843],\n",
      "        [3.6958, 3.7817, 3.8000, 3.8905, 3.8484],\n",
      "        [3.6272, 3.8460, 3.7922, 3.7857, 3.5366],\n",
      "        [3.3399, 3.6510, 3.6072, 3.5868, 3.4575],\n",
      "        [3.6602, 3.8479, 3.8039, 3.8199, 3.5276],\n",
      "        [3.5259, 3.6172, 3.6970, 3.7196, 3.5947],\n",
      "        [3.2867, 3.5079, 3.3615, 3.5634, 3.3341],\n",
      "        [3.4444, 3.6983, 3.6369, 3.5893, 3.4646],\n",
      "        [3.5025, 3.5151, 3.6006, 3.5844, 3.4376],\n",
      "        [3.3658, 3.6261, 3.5530, 3.7286, 3.3961],\n",
      "        [3.3197, 3.5425, 3.4714, 3.5191, 3.4089],\n",
      "        [3.4975, 3.5841, 3.7022, 3.7086, 3.5734],\n",
      "        [3.6927, 3.9086, 3.8488, 3.8449, 3.4990],\n",
      "        [3.4351, 3.6253, 3.4819, 3.6432, 3.4815],\n",
      "        [3.3769, 3.5776, 3.6320, 3.6405, 3.4110],\n",
      "        [3.8527, 4.0616, 3.7993, 3.8678, 3.7004],\n",
      "        [3.6501, 3.8248, 3.7879, 3.8438, 3.8209],\n",
      "        [3.3142, 3.4541, 3.4717, 3.5145, 3.3721],\n",
      "        [3.4688, 3.6618, 3.4887, 3.7092, 3.5025],\n",
      "        [3.7510, 3.8660, 3.8351, 3.9349, 3.9449],\n",
      "        [3.7690, 3.8503, 3.8519, 3.9403, 3.9111],\n",
      "        [3.3406, 3.5301, 3.5498, 3.5737, 3.4053],\n",
      "        [3.3689, 3.5171, 3.5524, 3.6021, 3.4234],\n",
      "        [3.3642, 3.5961, 3.6169, 3.6253, 3.4419],\n",
      "        [3.7574, 3.7160, 3.8151, 3.9872, 3.6941],\n",
      "        [3.5457, 3.8850, 3.7694, 3.8010, 3.5732],\n",
      "        [3.7960, 3.8628, 3.8723, 4.0500, 3.7924],\n",
      "        [3.3319, 3.6554, 3.7085, 3.6077, 3.5282],\n",
      "        [3.8218, 4.0140, 3.6859, 3.8554, 3.6560],\n",
      "        [3.6499, 3.6877, 3.6626, 4.0022, 3.7244],\n",
      "        [3.5705, 3.6945, 3.6525, 3.8524, 3.5731],\n",
      "        [3.3836, 3.4974, 3.4222, 3.6364, 3.3583],\n",
      "        [3.1727, 3.4292, 3.4812, 3.4434, 3.3530],\n",
      "        [3.6253, 3.8538, 3.6686, 3.9498, 3.6931],\n",
      "        [3.6327, 3.8497, 3.6983, 3.8558, 3.6614],\n",
      "        [3.5740, 3.7751, 3.5997, 3.7876, 3.6397],\n",
      "        [3.4636, 3.5797, 3.6087, 3.6722, 3.5084],\n",
      "        [3.4853, 3.6720, 3.4862, 3.7158, 3.5012],\n",
      "        [3.7401, 3.5530, 3.7078, 4.0534, 3.8678],\n",
      "        [3.4232, 3.7662, 3.6576, 3.7155, 3.6867],\n",
      "        [3.4044, 3.5601, 3.5694, 3.5827, 3.4556],\n",
      "        [3.3519, 3.5906, 3.4917, 3.5634, 3.4439],\n",
      "        [3.6658, 4.0045, 3.8698, 3.9232, 3.8147],\n",
      "        [3.4472, 3.5771, 3.7236, 3.5541, 3.6610],\n",
      "        [3.6082, 3.7200, 3.6980, 3.7396, 3.4070],\n",
      "        [3.4084, 3.5543, 3.5933, 3.6561, 3.4221],\n",
      "        [3.5455, 3.6496, 3.6366, 3.7850, 3.5598],\n",
      "        [3.3113, 3.4900, 3.4031, 3.5848, 3.3312],\n",
      "        [3.5206, 3.5396, 3.5938, 3.6516, 3.5520],\n",
      "        [3.4571, 3.7091, 3.6570, 3.7055, 3.5714]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3826, 3.6302, 3.6842, 3.6599, 3.5749],\n",
      "        [3.3812, 3.4933, 3.4150, 3.6327, 3.3351],\n",
      "        [3.3787, 3.5870, 3.6391, 3.6476, 3.4157],\n",
      "        [3.6937, 3.9607, 3.7810, 3.9842, 3.7771],\n",
      "        [3.6325, 3.8605, 3.6925, 3.8406, 3.6578],\n",
      "        [3.6082, 3.5014, 3.5319, 3.6708, 3.5523],\n",
      "        [3.4672, 3.6388, 3.6008, 3.6236, 3.5268],\n",
      "        [3.5890, 3.7294, 3.6665, 3.8998, 3.5805],\n",
      "        [3.5234, 3.6904, 3.6253, 3.7680, 3.6426],\n",
      "        [3.3267, 3.5502, 3.4709, 3.5204, 3.4097],\n",
      "        [3.3376, 3.5990, 3.5771, 3.5754, 3.4227],\n",
      "        [3.6241, 3.8521, 3.6655, 3.9475, 3.6887],\n",
      "        [3.4730, 3.5409, 3.6286, 3.6510, 3.4974],\n",
      "        [3.4670, 3.5850, 3.6116, 3.6781, 3.5098],\n",
      "        [3.3949, 3.5661, 3.6148, 3.6997, 3.5140],\n",
      "        [3.5614, 3.7069, 3.7337, 3.7714, 3.6118],\n",
      "        [3.3845, 3.5520, 3.4873, 3.6159, 3.4150],\n",
      "        [3.5029, 3.6985, 3.5019, 3.7462, 3.5282],\n",
      "        [3.3876, 3.4916, 3.6098, 3.6117, 3.4526],\n",
      "        [3.5227, 3.6100, 3.6981, 3.7274, 3.5766],\n",
      "        [3.5617, 3.5712, 3.8685, 3.7839, 3.6585],\n",
      "        [3.4691, 3.6395, 3.5292, 3.6706, 3.5260],\n",
      "        [3.7516, 3.8156, 3.7386, 3.8933, 3.7404],\n",
      "        [3.4248, 3.5671, 3.6106, 3.6704, 3.5008],\n",
      "        [3.4584, 3.6551, 3.4934, 3.6810, 3.4978],\n",
      "        [3.4625, 3.6490, 3.4774, 3.6883, 3.4805],\n",
      "        [3.6264, 3.8545, 3.6666, 3.9489, 3.6922],\n",
      "        [3.3354, 3.6675, 3.4383, 3.6433, 3.3771],\n",
      "        [3.7723, 3.8271, 3.8349, 3.9862, 3.6128],\n",
      "        [3.4105, 3.5554, 3.5956, 3.6676, 3.4882],\n",
      "        [3.5115, 3.7088, 3.6450, 3.7339, 3.6018],\n",
      "        [3.4154, 3.5348, 3.6304, 3.6517, 3.4830],\n",
      "        [3.8996, 4.1077, 3.8510, 3.9097, 3.7602],\n",
      "        [3.5612, 3.6774, 3.6456, 3.8209, 3.5709],\n",
      "        [3.4056, 3.6164, 3.4935, 3.6145, 3.4643],\n",
      "        [3.6211, 3.7128, 3.7154, 3.7416, 3.4551],\n",
      "        [3.7198, 3.7795, 3.8485, 3.9033, 3.5492],\n",
      "        [3.3300, 3.5396, 3.4732, 3.5230, 3.4039],\n",
      "        [3.3606, 3.8408, 3.7041, 3.6706, 3.6962],\n",
      "        [3.7253, 3.8114, 3.8155, 4.0128, 3.9234],\n",
      "        [3.6669, 3.7626, 3.9225, 3.7516, 3.5417],\n",
      "        [3.3277, 3.5638, 3.5623, 3.5693, 3.4088],\n",
      "        [3.3318, 3.5683, 3.5611, 3.5683, 3.4118],\n",
      "        [3.3558, 3.5548, 3.5862, 3.6062, 3.4062],\n",
      "        [3.5556, 3.7359, 3.8114, 3.7969, 3.6684],\n",
      "        [3.4805, 3.6008, 3.6256, 3.6853, 3.5252],\n",
      "        [3.5292, 3.7660, 3.5957, 3.7867, 3.5638],\n",
      "        [3.4514, 3.5764, 3.7344, 3.5413, 3.6650],\n",
      "        [3.3307, 3.5894, 3.5719, 3.5746, 3.4191],\n",
      "        [3.3345, 3.5996, 3.5785, 3.5862, 3.4355],\n",
      "        [3.4677, 3.5918, 3.6159, 3.6842, 3.5132],\n",
      "        [3.5314, 3.6201, 3.7114, 3.7389, 3.5852],\n",
      "        [3.6437, 3.8411, 3.7838, 3.8019, 3.5155],\n",
      "        [3.4805, 3.6641, 3.4819, 3.7054, 3.4960],\n",
      "        [3.3868, 3.4698, 3.5112, 3.6084, 3.3901],\n",
      "        [3.3527, 3.6671, 3.6194, 3.6089, 3.4785],\n",
      "        [3.1737, 3.4299, 3.4794, 3.4427, 3.3521],\n",
      "        [3.4804, 3.5243, 3.5064, 3.7433, 3.4122],\n",
      "        [3.7116, 3.9361, 3.7968, 3.7582, 3.7381],\n",
      "        [3.2880, 3.5155, 3.4573, 3.4750, 3.3795],\n",
      "        [3.8584, 3.9919, 3.8479, 4.2088, 3.8856],\n",
      "        [3.3380, 3.5464, 3.5556, 3.5720, 3.4078],\n",
      "        [3.4874, 3.6117, 3.7144, 3.5968, 3.6851],\n",
      "        [3.4504, 3.7352, 3.7072, 3.7002, 3.5692]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3717, 3.4894, 3.5243, 3.5892, 3.3962],\n",
      "        [3.6168, 3.9082, 3.6924, 3.6493, 3.6487],\n",
      "        [3.3827, 3.4869, 3.5203, 3.5984, 3.3992],\n",
      "        [3.6857, 3.5633, 3.6937, 3.9728, 3.8187],\n",
      "        [3.6974, 3.6270, 3.5701, 3.7339, 3.6481],\n",
      "        [3.5730, 3.8473, 3.7134, 3.7324, 3.6522],\n",
      "        [3.7960, 3.9391, 3.8534, 3.9472, 3.8287],\n",
      "        [3.6891, 3.8041, 3.8241, 3.8385, 3.7425],\n",
      "        [3.4761, 3.5114, 3.5878, 3.5906, 3.4346],\n",
      "        [3.3354, 3.6000, 3.5766, 3.5853, 3.4346],\n",
      "        [3.8033, 3.6772, 3.7104, 4.1991, 3.8648],\n",
      "        [3.8203, 4.0079, 3.6743, 3.8358, 3.6473],\n",
      "        [3.5257, 3.5702, 3.6581, 3.6945, 3.5781],\n",
      "        [3.5053, 3.5970, 3.6845, 3.7287, 3.5751],\n",
      "        [3.4936, 3.8217, 3.6059, 3.5485, 3.6027],\n",
      "        [3.6358, 3.7993, 3.7770, 3.8710, 3.5940],\n",
      "        [3.4566, 3.5918, 3.6723, 3.6886, 3.5295],\n",
      "        [3.4593, 3.5406, 3.6151, 3.6581, 3.4853],\n",
      "        [3.4690, 3.6035, 3.6218, 3.6971, 3.5270],\n",
      "        [3.5647, 3.6968, 3.5914, 3.7919, 3.5920],\n",
      "        [3.7079, 3.6283, 3.6709, 4.0852, 3.7654],\n",
      "        [3.3341, 3.6461, 3.5993, 3.5790, 3.4496],\n",
      "        [3.4613, 3.6510, 3.4926, 3.6800, 3.5003],\n",
      "        [3.3663, 3.5972, 3.6132, 3.6237, 3.4401],\n",
      "        [3.5185, 3.5834, 3.6884, 3.7664, 3.5531],\n",
      "        [3.4598, 3.6158, 3.7101, 3.7730, 3.6762],\n",
      "        [3.5163, 3.5755, 3.6828, 3.7036, 3.5679],\n",
      "        [3.3855, 3.5524, 3.4855, 3.6150, 3.4141],\n",
      "        [3.6944, 3.6446, 3.6511, 3.7789, 3.6496],\n",
      "        [3.3426, 3.5312, 3.5461, 3.5721, 3.4035],\n",
      "        [3.8942, 3.7319, 3.8125, 4.2822, 4.0574],\n",
      "        [3.6450, 3.8951, 3.7874, 3.8662, 3.6579],\n",
      "        [3.4571, 3.6713, 3.6428, 3.7234, 3.4977],\n",
      "        [3.4804, 3.7658, 3.5909, 3.6467, 3.5752],\n",
      "        [3.3715, 3.4633, 3.5020, 3.5960, 3.3790],\n",
      "        [3.4806, 3.5691, 3.6164, 3.6669, 3.5094],\n",
      "        [3.5915, 3.6564, 3.6967, 3.6948, 3.4818],\n",
      "        [3.4648, 3.6886, 3.5873, 3.7388, 3.5706],\n",
      "        [3.2814, 3.5014, 3.4520, 3.4646, 3.3741],\n",
      "        [3.5396, 3.7596, 3.7149, 3.8346, 3.6442],\n",
      "        [3.5686, 3.7399, 3.8181, 3.8012, 3.6562],\n",
      "        [3.4935, 3.7230, 3.5522, 3.8291, 3.4725],\n",
      "        [3.5310, 3.7977, 3.6437, 3.8050, 3.5418],\n",
      "        [3.4716, 3.6014, 3.6199, 3.7000, 3.5221],\n",
      "        [3.5479, 3.8047, 3.6912, 3.7537, 3.4730],\n",
      "        [3.4716, 3.5555, 3.6140, 3.6675, 3.4940],\n",
      "        [3.5741, 3.6175, 3.6758, 3.6552, 3.4984],\n",
      "        [3.6246, 3.7945, 3.6733, 3.6901, 3.6026],\n",
      "        [3.6764, 3.9426, 3.7615, 3.9694, 3.7561],\n",
      "        [3.5219, 3.6161, 3.6271, 3.7173, 3.5543],\n",
      "        [3.3188, 3.4080, 3.4775, 3.6018, 3.3673],\n",
      "        [3.6792, 4.0019, 3.8134, 4.0212, 3.8379],\n",
      "        [3.3725, 3.6037, 3.6202, 3.6305, 3.4469],\n",
      "        [3.6355, 3.8036, 3.6780, 3.7408, 3.6123],\n",
      "        [3.5299, 3.8350, 3.6267, 3.8680, 3.6246],\n",
      "        [3.6377, 3.8842, 3.6477, 3.7618, 3.6602],\n",
      "        [4.1424, 4.3635, 3.9750, 4.1052, 3.8405],\n",
      "        [3.3325, 3.6360, 3.5886, 3.5764, 3.4394],\n",
      "        [3.4060, 3.5507, 3.5984, 3.6701, 3.5022],\n",
      "        [3.3724, 3.4493, 3.4952, 3.5999, 3.3677],\n",
      "        [3.7310, 3.7814, 3.6582, 3.8628, 3.7542],\n",
      "        [3.4967, 3.6896, 3.5049, 3.7360, 3.5228],\n",
      "        [3.4490, 3.5779, 3.5203, 3.6969, 3.4614],\n",
      "        [3.5692, 3.5824, 3.8715, 3.7874, 3.6692]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4618, 3.6255, 3.6035, 3.6910, 3.6255],\n",
      "        [3.6904, 3.9023, 3.8455, 3.8408, 3.4868],\n",
      "        [3.6601, 3.8972, 3.6439, 3.7737, 3.6507],\n",
      "        [3.3469, 3.6488, 3.5980, 3.5972, 3.4616],\n",
      "        [3.4430, 3.7970, 3.7446, 3.6638, 3.7598],\n",
      "        [3.4803, 3.6010, 3.7130, 3.6067, 3.6789],\n",
      "        [3.7065, 3.8085, 3.7496, 3.9296, 3.8177],\n",
      "        [3.5057, 3.6262, 3.7383, 3.7535, 3.5887],\n",
      "        [3.4433, 3.6835, 3.5365, 3.7676, 3.4540],\n",
      "        [3.4949, 3.6777, 3.6259, 3.7048, 3.5721],\n",
      "        [3.6687, 4.0234, 3.7570, 3.9976, 3.8158],\n",
      "        [3.4791, 3.5264, 3.6081, 3.6772, 3.6147],\n",
      "        [3.7048, 3.8018, 3.8007, 3.7887, 3.4772],\n",
      "        [3.4086, 3.5017, 3.5401, 3.6223, 3.3971],\n",
      "        [3.3723, 3.4634, 3.5001, 3.5955, 3.3780],\n",
      "        [3.4621, 3.5824, 3.6037, 3.6737, 3.5049],\n",
      "        [3.5916, 3.9095, 3.7929, 3.8491, 3.8146],\n",
      "        [3.4103, 3.6029, 3.6621, 3.6408, 3.5330],\n",
      "        [3.3730, 3.5161, 3.4425, 3.6323, 3.3255],\n",
      "        [3.4344, 3.4766, 3.5819, 3.6497, 3.5265],\n",
      "        [3.6523, 3.7244, 3.8578, 3.7703, 3.4925],\n",
      "        [3.5840, 3.7496, 3.6147, 3.7548, 3.7331],\n",
      "        [3.8866, 4.0354, 3.9448, 4.2254, 3.9136],\n",
      "        [3.4905, 3.6805, 3.4880, 3.7368, 3.5149],\n",
      "        [3.4641, 3.6472, 3.5665, 3.6443, 3.5145],\n",
      "        [3.6765, 3.8702, 3.6734, 3.8156, 3.7327],\n",
      "        [3.7967, 3.8962, 3.7633, 3.9405, 3.8569],\n",
      "        [3.6068, 3.8622, 3.7805, 3.8605, 3.7227],\n",
      "        [3.5828, 3.8018, 3.7085, 3.7662, 3.4910],\n",
      "        [3.4858, 3.6131, 3.6265, 3.7109, 3.5268],\n",
      "        [3.5600, 3.5877, 3.6360, 3.6834, 3.5891],\n",
      "        [3.5781, 3.6265, 3.6776, 3.6641, 3.4929],\n",
      "        [3.8835, 4.0358, 3.9382, 4.2386, 3.9224],\n",
      "        [3.6621, 3.7907, 3.7577, 3.8990, 3.7699],\n",
      "        [3.4525, 3.6355, 3.4711, 3.6664, 3.4670],\n",
      "        [3.5939, 3.6457, 3.6731, 3.7569, 3.5363],\n",
      "        [3.4687, 3.5855, 3.6076, 3.6767, 3.5078],\n",
      "        [3.4358, 3.8299, 3.7166, 3.7620, 3.6583],\n",
      "        [3.7416, 3.7186, 3.6860, 3.8366, 3.7232],\n",
      "        [3.7078, 3.8435, 3.8113, 3.8976, 3.9050],\n",
      "        [3.3379, 3.6667, 3.4380, 3.6407, 3.3741],\n",
      "        [3.4208, 3.4542, 3.6163, 3.4647, 3.5466],\n",
      "        [3.6224, 3.7218, 3.6980, 3.8246, 3.7773],\n",
      "        [3.3665, 3.4382, 3.4824, 3.5853, 3.3616],\n",
      "        [3.6686, 4.0061, 3.8638, 3.9210, 3.8117],\n",
      "        [3.7272, 3.9472, 3.8948, 3.9124, 3.5655],\n",
      "        [3.3649, 3.5051, 3.5312, 3.5853, 3.4012],\n",
      "        [3.4962, 3.8175, 3.5870, 3.5442, 3.5631],\n",
      "        [3.4402, 3.5376, 3.5969, 3.6217, 3.4716],\n",
      "        [3.3885, 3.4702, 3.5074, 3.6071, 3.3881],\n",
      "        [3.4132, 3.5541, 3.5992, 3.6555, 3.4984],\n",
      "        [3.4335, 3.6265, 3.4761, 3.6351, 3.4706],\n",
      "        [3.6422, 3.8623, 3.6435, 3.7969, 3.6881],\n",
      "        [3.4773, 3.7341, 3.5956, 3.7073, 3.5876],\n",
      "        [3.6357, 3.6444, 3.6992, 3.9729, 3.5761],\n",
      "        [3.4724, 3.5556, 3.6121, 3.6670, 3.4929],\n",
      "        [3.5132, 3.6394, 3.7505, 3.7609, 3.5972],\n",
      "        [3.5906, 3.7075, 3.6737, 3.7162, 3.3806],\n",
      "        [3.5495, 3.7159, 3.6785, 3.7363, 3.6909],\n",
      "        [3.7513, 3.5531, 3.6852, 4.0757, 3.8826],\n",
      "        [3.4465, 3.6872, 3.5527, 3.7123, 3.5713],\n",
      "        [3.3829, 3.4677, 3.5032, 3.6025, 3.3859],\n",
      "        [3.6676, 3.8430, 3.7709, 3.7605, 3.6727],\n",
      "        [3.3280, 3.5964, 3.7185, 3.5710, 3.5807]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6311, 3.8244, 3.6708, 3.8415, 3.6422],\n",
      "        [3.4891, 3.7848, 3.6130, 3.8272, 3.5197],\n",
      "        [3.7050, 3.8017, 3.7987, 3.7880, 3.4758],\n",
      "        [3.2663, 3.4819, 3.4333, 3.4524, 3.3574],\n",
      "        [3.3252, 3.5371, 3.4604, 3.5143, 3.3973],\n",
      "        [3.7907, 3.7634, 3.7143, 3.8794, 3.7071],\n",
      "        [3.8043, 3.7188, 3.8251, 3.9745, 3.7358],\n",
      "        [3.3286, 3.5507, 3.4653, 3.5185, 3.4065],\n",
      "        [3.6197, 3.7189, 3.6892, 3.8181, 3.7735],\n",
      "        [3.4603, 3.5406, 3.6112, 3.6568, 3.4829],\n",
      "        [3.6397, 3.6659, 3.6576, 3.6739, 3.4600],\n",
      "        [3.3596, 3.6287, 3.5892, 3.5936, 3.4639],\n",
      "        [3.4528, 3.5748, 3.4687, 3.6305, 3.5607],\n",
      "        [3.4790, 3.5612, 3.5419, 3.7244, 3.4466],\n",
      "        [3.8307, 3.6987, 3.7179, 4.2330, 3.9001],\n",
      "        [3.3843, 3.4603, 3.4985, 3.6060, 3.3891],\n",
      "        [3.3244, 3.5552, 3.4835, 3.5180, 3.4198],\n",
      "        [3.4313, 3.5609, 3.6193, 3.6641, 3.4939],\n",
      "        [3.3742, 3.4461, 3.4853, 3.5901, 3.3680],\n",
      "        [3.4133, 3.6149, 3.4737, 3.6188, 3.4562],\n",
      "        [3.6080, 3.6717, 3.6107, 3.8983, 3.6467],\n",
      "        [3.4550, 3.6710, 3.6165, 3.7793, 3.4848],\n",
      "        [3.4760, 3.5702, 3.5734, 3.6356, 3.5586],\n",
      "        [3.8748, 4.0091, 3.9102, 4.1844, 3.8542],\n",
      "        [3.7136, 3.8816, 3.7087, 3.8712, 3.7935],\n",
      "        [3.4659, 3.8602, 3.7358, 3.7847, 3.7183],\n",
      "        [3.9017, 4.1082, 3.8450, 3.9075, 3.7568],\n",
      "        [3.4816, 3.7219, 3.6670, 3.7128, 3.4799],\n",
      "        [3.4518, 3.4982, 3.6340, 3.5251, 3.5588],\n",
      "        [3.6652, 3.8230, 3.7718, 3.7722, 3.6678],\n",
      "        [3.4675, 3.7915, 3.7042, 3.6246, 3.6220],\n",
      "        [3.3798, 3.6098, 3.5027, 3.6573, 3.4331],\n",
      "        [3.3613, 3.6737, 3.6136, 3.6094, 3.4856],\n",
      "        [3.7533, 3.9064, 3.8202, 3.8996, 3.7780],\n",
      "        [3.4533, 3.5767, 3.7284, 3.5389, 3.6614],\n",
      "        [3.4429, 3.5004, 3.5897, 3.6253, 3.4569],\n",
      "        [3.6724, 4.0205, 3.7841, 3.8521, 3.9544],\n",
      "        [3.3495, 3.6487, 3.5957, 3.6009, 3.4545],\n",
      "        [3.7144, 3.8911, 3.8789, 4.0544, 4.0110],\n",
      "        [3.6802, 3.6219, 3.6418, 4.0910, 3.7352],\n",
      "        [3.4049, 3.6397, 3.5138, 3.7122, 3.4370],\n",
      "        [3.4952, 3.6776, 3.6239, 3.7041, 3.5707],\n",
      "        [3.5044, 3.5762, 3.6393, 3.6989, 3.5796],\n",
      "        [3.6104, 3.6720, 3.6037, 3.8958, 3.6466],\n",
      "        [3.6819, 3.8090, 3.7547, 3.8736, 3.7684],\n",
      "        [3.4813, 3.7660, 3.5869, 3.6455, 3.5727],\n",
      "        [3.3836, 3.4869, 3.5164, 3.5972, 3.3968],\n",
      "        [3.6411, 3.8620, 3.6927, 3.8449, 3.6620],\n",
      "        [3.7465, 3.8066, 3.8035, 3.9889, 3.7179],\n",
      "        [3.4870, 3.6697, 3.4818, 3.7125, 3.4983],\n",
      "        [3.5301, 3.9047, 3.7623, 3.7855, 3.5558],\n",
      "        [3.5460, 3.7185, 3.5821, 3.7478, 3.6360],\n",
      "        [3.4907, 3.9225, 3.7835, 3.7722, 3.5701],\n",
      "        [3.6282, 3.8549, 3.6605, 3.9466, 3.6886],\n",
      "        [3.4618, 3.7970, 3.7204, 3.6383, 3.6048],\n",
      "        [3.5164, 3.8241, 3.5555, 3.7132, 3.5381],\n",
      "        [3.2743, 3.4968, 3.4436, 3.4570, 3.3657],\n",
      "        [3.4730, 3.5122, 3.5862, 3.6694, 3.6038],\n",
      "        [3.8214, 4.0079, 3.6705, 3.8346, 3.6448],\n",
      "        [3.6259, 3.8525, 3.6593, 3.9452, 3.6852],\n",
      "        [3.4643, 3.6471, 3.5646, 3.6436, 3.5131],\n",
      "        [3.5034, 3.7188, 3.4719, 3.6481, 3.5130],\n",
      "        [3.7216, 3.8993, 3.8881, 4.0767, 4.0105],\n",
      "        [3.6286, 3.5187, 3.5388, 3.6627, 3.5805]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6815, 3.7045, 3.7459, 3.8827, 3.6207],\n",
      "        [3.5475, 3.8472, 3.6449, 3.8778, 3.6331],\n",
      "        [3.6720, 3.6939, 3.6661, 3.7054, 3.4865],\n",
      "        [3.4898, 3.6230, 3.5666, 3.8174, 3.5556],\n",
      "        [3.4589, 3.6461, 3.5706, 3.8493, 3.4570],\n",
      "        [3.5140, 3.5614, 3.6731, 3.7382, 3.6269],\n",
      "        [3.5014, 3.7615, 3.6034, 3.6555, 3.5871],\n",
      "        [3.6211, 3.8669, 3.6251, 3.7831, 3.6615],\n",
      "        [3.3254, 3.5368, 3.4585, 3.5136, 3.3969],\n",
      "        [3.9641, 4.1682, 3.8819, 3.9664, 3.7798],\n",
      "        [3.4072, 3.5608, 3.5787, 3.6765, 3.4784],\n",
      "        [3.9315, 4.0860, 3.6993, 3.9095, 3.6248],\n",
      "        [3.3895, 3.4916, 3.6022, 3.6087, 3.4489],\n",
      "        [3.7050, 3.8015, 3.7966, 3.7871, 3.4752],\n",
      "        [3.4789, 3.6637, 3.4809, 3.7035, 3.4977],\n",
      "        [3.4451, 3.5774, 3.5377, 3.5884, 3.4972],\n",
      "        [3.3644, 3.5768, 3.4686, 3.5590, 3.4241],\n",
      "        [3.3520, 3.6624, 3.6036, 3.6038, 3.4734],\n",
      "        [3.7989, 3.8639, 3.8622, 4.0463, 3.7876],\n",
      "        [3.6365, 3.8720, 3.6295, 3.7912, 3.6693],\n",
      "        [3.3374, 3.5339, 3.5368, 3.5641, 3.3991],\n",
      "        [3.5650, 3.6648, 3.6170, 3.7925, 3.6768],\n",
      "        [3.4236, 3.6663, 3.5262, 3.7404, 3.4484],\n",
      "        [3.5829, 3.6281, 3.6333, 3.6474, 3.3944],\n",
      "        [3.8177, 3.8238, 3.7889, 3.9676, 3.7666],\n",
      "        [3.6187, 3.5078, 3.5268, 3.6744, 3.5410],\n",
      "        [3.8715, 3.7030, 3.7825, 4.2784, 4.0326],\n",
      "        [3.4272, 3.7974, 3.6014, 3.6288, 3.4099],\n",
      "        [3.3858, 3.4973, 3.4125, 3.6328, 3.3532],\n",
      "        [3.6070, 3.7958, 3.7787, 3.7984, 3.6363],\n",
      "        [3.4406, 3.6377, 3.4819, 3.6473, 3.4795],\n",
      "        [4.1187, 4.3367, 3.9377, 4.0884, 3.8081],\n",
      "        [3.6046, 3.8082, 3.7869, 3.8225, 3.6240],\n",
      "        [3.3781, 3.5992, 3.6494, 3.6389, 3.4202],\n",
      "        [3.7592, 3.7470, 3.7035, 3.8566, 3.7380],\n",
      "        [3.5046, 3.6800, 3.6316, 3.6795, 3.5502],\n",
      "        [3.3957, 3.5751, 3.4732, 3.6327, 3.4205],\n",
      "        [3.3918, 3.7239, 3.6253, 3.6807, 3.6605],\n",
      "        [3.5177, 3.4852, 3.5799, 3.8387, 3.4445],\n",
      "        [3.6012, 3.9341, 3.7253, 3.8501, 3.6830],\n",
      "        [3.4781, 3.6661, 3.4890, 3.7046, 3.5050],\n",
      "        [3.3338, 3.5685, 3.5535, 3.5656, 3.4081],\n",
      "        [3.4198, 3.4428, 3.4718, 3.5962, 3.3571],\n",
      "        [3.8506, 3.8775, 3.8247, 4.0208, 3.8280],\n",
      "        [3.3843, 3.4593, 3.4962, 3.6141, 3.3939],\n",
      "        [3.4667, 3.6219, 3.6070, 3.6814, 3.6437],\n",
      "        [3.6654, 3.7638, 3.9144, 3.7518, 3.5393],\n",
      "        [3.5837, 3.8155, 3.6248, 3.7521, 3.6035],\n",
      "        [3.3832, 3.4903, 3.4122, 3.6358, 3.3780],\n",
      "        [3.3361, 3.5511, 3.5461, 3.5646, 3.4042],\n",
      "        [3.6198, 3.8131, 3.7440, 3.9267, 3.6169],\n",
      "        [3.7484, 3.9491, 3.6464, 3.7997, 3.6419],\n",
      "        [3.2895, 3.5101, 3.4506, 3.4707, 3.3731],\n",
      "        [3.5405, 3.5608, 3.6140, 3.6715, 3.5710],\n",
      "        [3.5174, 3.6039, 3.6783, 3.7033, 3.5721],\n",
      "        [3.6272, 3.9062, 3.7973, 3.8806, 3.7817],\n",
      "        [3.2814, 3.5033, 3.4493, 3.4567, 3.3682],\n",
      "        [3.3796, 3.6309, 3.5249, 3.6068, 3.4982],\n",
      "        [3.6143, 3.8210, 3.7780, 3.8305, 3.6120],\n",
      "        [3.3636, 3.5773, 3.4695, 3.5641, 3.4264],\n",
      "        [3.3842, 3.5371, 3.4537, 3.6479, 3.4142],\n",
      "        [3.3706, 3.5239, 3.5566, 3.6017, 3.3881],\n",
      "        [3.3990, 3.6023, 3.4688, 3.5976, 3.4495],\n",
      "        [3.6198, 3.8131, 3.7440, 3.9267, 3.6169]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7568, 3.7038, 3.7930, 3.9782, 3.6794],\n",
      "        [3.5078, 3.6961, 3.6271, 3.7147, 3.5867],\n",
      "        [3.6063, 3.9126, 3.7996, 3.8554, 3.8095],\n",
      "        [3.4338, 3.6262, 3.4703, 3.6339, 3.4682],\n",
      "        [3.3605, 3.4347, 3.4730, 3.5828, 3.3569],\n",
      "        [3.6282, 3.8548, 3.6563, 3.9460, 3.6875],\n",
      "        [3.3735, 3.4543, 3.4885, 3.6045, 3.3776],\n",
      "        [3.3818, 3.6884, 3.7727, 3.6599, 3.5930],\n",
      "        [3.5900, 3.8164, 3.6249, 3.7688, 3.6124],\n",
      "        [3.3309, 3.5841, 3.5614, 3.5698, 3.4120],\n",
      "        [3.6434, 3.8699, 3.6962, 3.8322, 3.6652],\n",
      "        [3.5115, 3.7459, 3.5606, 3.8509, 3.4833],\n",
      "        [3.4678, 3.6386, 3.5135, 3.6702, 3.5156],\n",
      "        [3.5047, 3.6988, 3.4920, 3.7434, 3.5238],\n",
      "        [3.4949, 3.5818, 3.6649, 3.7126, 3.5443],\n",
      "        [3.6846, 3.7739, 3.7367, 3.8401, 3.7736],\n",
      "        [3.8336, 3.9892, 3.8737, 3.9957, 3.9004],\n",
      "        [3.4204, 3.5664, 3.5913, 3.6685, 3.4919],\n",
      "        [3.4836, 3.6077, 3.5490, 3.7361, 3.5008],\n",
      "        [3.6312, 3.7353, 3.6785, 3.8560, 3.7414],\n",
      "        [3.5909, 3.6474, 3.6490, 3.6249, 3.3980],\n",
      "        [3.5032, 3.7187, 3.4679, 3.6477, 3.5118],\n",
      "        [3.4682, 3.5162, 3.6323, 3.5570, 3.5598],\n",
      "        [3.2745, 3.4968, 3.4399, 3.4567, 3.3647],\n",
      "        [3.8842, 4.0626, 3.6877, 3.8885, 3.6357],\n",
      "        [3.3985, 3.5602, 3.4767, 3.6284, 3.4148],\n",
      "        [3.6356, 3.6443, 3.6929, 3.9718, 3.5733],\n",
      "        [3.6638, 3.8846, 3.7841, 3.8571, 3.6392],\n",
      "        [3.5719, 3.6259, 3.6293, 3.6321, 3.3808],\n",
      "        [3.6176, 3.8275, 3.7379, 3.9266, 3.6290],\n",
      "        [3.6259, 3.8524, 3.6552, 3.9446, 3.6840],\n",
      "        [3.7492, 3.8066, 3.7309, 3.8854, 3.7220],\n",
      "        [3.4657, 3.8603, 3.7318, 3.7842, 3.7172],\n",
      "        [3.6826, 3.8088, 3.7507, 3.8732, 3.7675],\n",
      "        [3.5174, 3.6870, 3.6288, 3.7348, 3.6447],\n",
      "        [3.4410, 3.6363, 3.4736, 3.6594, 3.4695],\n",
      "        [3.6170, 3.6783, 3.6958, 3.7096, 3.4880],\n",
      "        [3.5487, 3.6503, 3.6247, 3.7816, 3.5543],\n",
      "        [3.4587, 3.8146, 3.7405, 3.6242, 3.6383],\n",
      "        [3.4783, 3.5839, 3.6071, 3.6825, 3.5079],\n",
      "        [3.4774, 3.6603, 3.4855, 3.6833, 3.5104],\n",
      "        [3.6619, 3.7608, 3.7286, 3.8683, 3.8085],\n",
      "        [3.6020, 3.7200, 3.6789, 3.7231, 3.3881],\n",
      "        [3.6624, 3.8143, 3.7938, 3.9672, 3.6215],\n",
      "        [3.5175, 3.6042, 3.6763, 3.7037, 3.5715],\n",
      "        [3.6441, 3.8911, 3.7815, 3.8655, 3.6557],\n",
      "        [3.5572, 3.6690, 3.6303, 3.8094, 3.5578],\n",
      "        [3.5555, 3.6437, 3.7316, 3.7625, 3.6003],\n",
      "        [3.4706, 3.5263, 3.6055, 3.6463, 3.4906],\n",
      "        [3.3496, 3.5568, 3.5580, 3.5869, 3.4243],\n",
      "        [3.3478, 3.6668, 3.7169, 3.5917, 3.5172],\n",
      "        [3.4904, 3.9226, 3.7792, 3.7716, 3.5687],\n",
      "        [3.5960, 3.6331, 3.6873, 3.6495, 3.5509],\n",
      "        [3.3957, 3.5753, 3.4713, 3.6330, 3.4199],\n",
      "        [3.3743, 3.4459, 3.4814, 3.5897, 3.3670],\n",
      "        [3.5986, 3.6491, 3.6411, 3.6269, 3.4125],\n",
      "        [3.8563, 4.0628, 3.7876, 3.8643, 3.6950],\n",
      "        [3.7158, 3.8070, 3.7997, 3.9752, 3.9041],\n",
      "        [3.4473, 3.6379, 3.4789, 3.6658, 3.4834],\n",
      "        [3.4704, 3.5788, 3.5998, 3.6764, 3.5125],\n",
      "        [3.5013, 3.7618, 3.6014, 3.6559, 3.5865],\n",
      "        [3.4622, 3.6867, 3.7677, 3.6532, 3.5422],\n",
      "        [3.4585, 3.7018, 3.5604, 3.7105, 3.5736],\n",
      "        [3.5000, 3.5910, 3.6113, 3.6680, 3.5792]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6257, 3.8523, 3.6530, 3.9446, 3.6833],\n",
      "        [3.8474, 3.9446, 3.8430, 4.1268, 3.8430],\n",
      "        [3.4450, 3.5776, 3.5338, 3.5888, 3.4960],\n",
      "        [3.4918, 3.5477, 3.6447, 3.7078, 3.6124],\n",
      "        [3.4480, 3.6467, 3.5956, 3.7526, 3.5234],\n",
      "        [3.6517, 3.6721, 3.6576, 4.0269, 3.7354],\n",
      "        [3.5036, 3.5875, 3.6546, 3.6908, 3.5587],\n",
      "        [3.4624, 3.6254, 3.5954, 3.6898, 3.6223],\n",
      "        [4.1440, 4.3639, 3.9646, 4.1033, 3.8361],\n",
      "        [3.4828, 3.8081, 3.5647, 3.8173, 3.5880],\n",
      "        [3.3643, 3.5738, 3.5977, 3.6176, 3.4282],\n",
      "        [3.7254, 3.6454, 3.6649, 4.1003, 3.7783],\n",
      "        [3.6070, 3.8622, 3.7724, 3.8593, 3.7194],\n",
      "        [3.6108, 3.7201, 3.5481, 3.8247, 3.6811],\n",
      "        [3.6157, 3.8496, 3.7389, 3.9386, 3.6382],\n",
      "        [3.5244, 3.6144, 3.6857, 3.7142, 3.5767],\n",
      "        [3.5177, 3.6479, 3.6538, 3.6884, 3.7393],\n",
      "        [3.3744, 3.4745, 3.5035, 3.5904, 3.3825],\n",
      "        [3.4944, 3.7230, 3.5426, 3.8277, 3.4685],\n",
      "        [3.4899, 3.5554, 3.6290, 3.6217, 3.5558],\n",
      "        [3.4585, 3.5183, 3.6027, 3.6419, 3.4648],\n",
      "        [3.5372, 3.5714, 3.6296, 3.7056, 3.5329],\n",
      "        [3.6083, 3.6717, 3.6047, 3.8979, 3.6450],\n",
      "        [3.3850, 3.4943, 3.4107, 3.6325, 3.3081],\n",
      "        [3.4269, 3.6425, 3.6048, 3.6982, 3.4500],\n",
      "        [3.5566, 3.7365, 3.7989, 3.7942, 3.6628],\n",
      "        [3.4816, 3.5688, 3.6064, 3.6651, 3.5052],\n",
      "        [3.4687, 3.5934, 3.6051, 3.5630, 3.3177],\n",
      "        [3.3556, 3.5725, 3.4701, 3.5477, 3.4310],\n",
      "        [3.4734, 3.5477, 3.6084, 3.6636, 3.4815],\n",
      "        [3.5044, 3.5759, 3.6332, 3.6985, 3.5779],\n",
      "        [3.4741, 3.5527, 3.6104, 3.6617, 3.4871],\n",
      "        [3.2619, 3.5088, 3.4965, 3.5221, 3.4078],\n",
      "        [3.4957, 3.6159, 3.6858, 3.6423, 3.6697],\n",
      "        [3.5920, 3.6484, 3.6616, 3.7493, 3.5381],\n",
      "        [3.4722, 3.7105, 3.6428, 3.6995, 3.5530],\n",
      "        [3.4782, 3.5583, 3.6304, 3.6621, 3.4961],\n",
      "        [3.5166, 3.8044, 3.6320, 3.8593, 3.5368],\n",
      "        [3.4221, 3.6189, 3.4625, 3.6360, 3.4529],\n",
      "        [3.6884, 3.8649, 3.8159, 3.8398, 3.5395],\n",
      "        [3.4694, 3.5621, 3.6032, 3.6678, 3.5021],\n",
      "        [3.4830, 3.6254, 3.6993, 3.6984, 3.6389],\n",
      "        [3.5522, 3.7796, 3.6023, 3.7944, 3.5739],\n",
      "        [3.7607, 3.5499, 3.6910, 4.0730, 3.8766],\n",
      "        [3.5623, 3.7114, 3.5869, 3.7730, 3.5869],\n",
      "        [3.5155, 3.6051, 3.6947, 3.7447, 3.5812],\n",
      "        [3.5907, 3.9315, 3.7129, 3.8282, 3.6678],\n",
      "        [3.6953, 3.9102, 3.8344, 3.8413, 3.4926],\n",
      "        [3.4868, 3.5074, 3.5764, 3.5835, 3.4250],\n",
      "        [3.6219, 3.8164, 3.6568, 3.8103, 3.6100],\n",
      "        [3.4418, 3.7673, 3.5900, 3.6565, 3.4706],\n",
      "        [3.3821, 3.4832, 3.5098, 3.5954, 3.3932],\n",
      "        [3.3831, 3.4672, 3.4953, 3.6013, 3.3828],\n",
      "        [3.6415, 3.8582, 3.7523, 3.8837, 3.6488],\n",
      "        [3.6209, 3.5109, 3.5272, 3.6643, 3.5570],\n",
      "        [3.3646, 3.5752, 3.5871, 3.6198, 3.4183],\n",
      "        [3.6994, 3.9087, 3.7749, 3.7503, 3.7087],\n",
      "        [3.7968, 3.8963, 3.7553, 3.9392, 3.8536],\n",
      "        [3.4934, 3.6257, 3.5674, 3.7984, 3.5725],\n",
      "        [3.4726, 3.5552, 3.6041, 3.6657, 3.4898],\n",
      "        [3.4486, 3.6294, 3.5849, 3.7087, 3.5757],\n",
      "        [3.6379, 3.8058, 3.8048, 3.7939, 3.5214],\n",
      "        [3.4714, 3.7812, 3.6797, 3.6299, 3.6132],\n",
      "        [3.2901, 3.5160, 3.4462, 3.4728, 3.3747]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8157, 3.9127, 3.8059, 4.0849, 3.8144],\n",
      "        [3.4739, 3.5525, 3.6084, 3.6613, 3.4863],\n",
      "        [3.7160, 3.8512, 3.7881, 3.8972, 3.8803],\n",
      "        [3.8585, 3.8459, 3.9090, 4.1140, 3.8088],\n",
      "        [3.3505, 3.5255, 3.5351, 3.5743, 3.4006],\n",
      "        [3.7240, 3.9976, 3.7711, 3.9801, 3.8453],\n",
      "        [3.6277, 3.8545, 3.6520, 3.9457, 3.6859],\n",
      "        [3.3910, 3.7241, 3.6193, 3.6809, 3.6585],\n",
      "        [3.7457, 3.5626, 3.6856, 4.0509, 3.8724],\n",
      "        [3.4047, 3.8025, 3.6759, 3.7220, 3.6484],\n",
      "        [3.4709, 3.5954, 3.4877, 3.6450, 3.5731],\n",
      "        [3.3742, 3.4742, 3.5015, 3.5902, 3.3817],\n",
      "        [3.4915, 3.6323, 3.6239, 3.6785, 3.6900],\n",
      "        [3.4157, 3.5616, 3.3841, 3.6903, 3.3529],\n",
      "        [3.4903, 3.7234, 3.6625, 3.7177, 3.4819],\n",
      "        [3.4265, 3.6423, 3.6027, 3.6979, 3.4492],\n",
      "        [3.6942, 3.9585, 3.7666, 3.9849, 3.7681],\n",
      "        [3.5678, 3.4618, 3.7467, 3.7455, 3.5450],\n",
      "        [3.8267, 3.8229, 3.7858, 4.0519, 3.7612],\n",
      "        [3.3445, 3.5520, 3.4562, 3.5352, 3.4053],\n",
      "        [3.3641, 3.5736, 3.5957, 3.6173, 3.4274],\n",
      "        [3.6067, 3.8620, 3.7704, 3.8591, 3.7186],\n",
      "        [3.4397, 3.5371, 3.5865, 3.6200, 3.4674],\n",
      "        [3.8065, 3.8937, 3.7581, 3.9511, 3.8604],\n",
      "        [3.4379, 3.6072, 3.5110, 3.5924, 3.4546],\n",
      "        [3.3721, 3.5850, 3.4692, 3.5670, 3.4379],\n",
      "        [3.5403, 3.5511, 3.5941, 3.7048, 3.4642],\n",
      "        [3.6751, 3.7808, 3.7475, 3.8685, 3.7761],\n",
      "        [3.5423, 3.6317, 3.7101, 3.7615, 3.5947],\n",
      "        [3.8962, 4.0810, 3.7020, 3.9090, 3.6559],\n",
      "        [3.7705, 3.7167, 3.8001, 3.9768, 3.6939],\n",
      "        [3.5195, 3.5830, 3.6763, 3.7644, 3.5482],\n",
      "        [3.3602, 3.5183, 3.5506, 3.5959, 3.3816],\n",
      "        [3.6324, 3.8287, 3.7530, 3.7893, 3.4971],\n",
      "        [3.6512, 3.5653, 3.6774, 3.9226, 3.7907],\n",
      "        [3.3368, 3.6678, 3.4255, 3.6413, 3.3716],\n",
      "        [3.3548, 3.5915, 3.4767, 3.5602, 3.4375],\n",
      "        [3.5400, 3.6274, 3.7010, 3.7465, 3.5865],\n",
      "        [3.6585, 3.7552, 3.7809, 3.7972, 3.5194],\n",
      "        [3.2969, 3.4507, 3.4458, 3.4873, 3.3527],\n",
      "        [3.3294, 3.6091, 3.5696, 3.5805, 3.4244],\n",
      "        [3.6299, 3.5182, 3.5311, 3.6629, 3.5790],\n",
      "        [3.5810, 3.8610, 3.7922, 3.8300, 3.5820],\n",
      "        [3.6413, 3.8621, 3.6328, 3.7955, 3.6836],\n",
      "        [3.6376, 3.8846, 3.6325, 3.7659, 3.6496],\n",
      "        [3.4795, 3.6074, 3.6134, 3.6977, 3.5294],\n",
      "        [3.4454, 3.5857, 3.5466, 3.5971, 3.4884],\n",
      "        [3.4317, 3.5494, 3.6067, 3.6608, 3.4888],\n",
      "        [3.4071, 3.6165, 3.4799, 3.6118, 3.4586],\n",
      "        [3.6413, 3.8204, 3.7678, 3.8655, 3.6238],\n",
      "        [3.6682, 3.6865, 3.6972, 3.9538, 3.5305],\n",
      "        [3.4469, 3.5447, 3.5931, 3.6244, 3.4746],\n",
      "        [3.6196, 3.8133, 3.7378, 3.9269, 3.6148],\n",
      "        [3.3642, 3.4990, 3.5204, 3.5811, 3.3944],\n",
      "        [3.3110, 3.6666, 3.5037, 3.4116, 3.4534],\n",
      "        [3.6110, 3.7932, 3.7665, 3.7976, 3.6266],\n",
      "        [3.5496, 3.6407, 3.7187, 3.7482, 3.5971],\n",
      "        [3.4402, 3.6377, 3.4760, 3.6474, 3.4775],\n",
      "        [3.3835, 3.6303, 3.6699, 3.6569, 3.5686],\n",
      "        [3.6300, 3.8187, 3.6609, 3.7927, 3.6130],\n",
      "        [3.6501, 3.7434, 3.7206, 3.8243, 3.7995],\n",
      "        [3.5918, 3.6482, 3.6596, 3.7490, 3.5373],\n",
      "        [3.9064, 3.7811, 3.9055, 4.3886, 4.1156],\n",
      "        [3.6643, 3.8486, 3.7874, 3.8162, 3.5208]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3668, 3.5965, 3.5995, 3.6216, 3.4344],\n",
      "        [3.5938, 3.7881, 3.7544, 3.8053, 3.6294],\n",
      "        [3.4528, 3.5448, 3.5340, 3.6069, 3.5305],\n",
      "        [3.6274, 3.6605, 3.6419, 3.6600, 3.4477],\n",
      "        [3.5053, 3.9615, 3.7554, 3.7219, 3.5721],\n",
      "        [3.5855, 3.6197, 3.6660, 3.6549, 3.5247],\n",
      "        [3.7508, 3.8183, 3.8070, 3.9189, 3.8711],\n",
      "        [3.7704, 3.8509, 3.8321, 3.9368, 3.9023],\n",
      "        [3.6334, 3.8614, 3.6761, 3.8372, 3.6508],\n",
      "        [3.4689, 3.6510, 3.4643, 3.6847, 3.4768],\n",
      "        [3.5397, 3.5691, 3.6321, 3.6894, 3.5754],\n",
      "        [3.4074, 3.5103, 3.6107, 3.6309, 3.4559],\n",
      "        [3.8559, 4.0626, 3.7814, 3.8635, 3.6928],\n",
      "        [3.4113, 3.5883, 3.4865, 3.6458, 3.4682],\n",
      "        [3.4734, 3.7078, 3.5350, 3.7956, 3.4590],\n",
      "        [3.4856, 3.6807, 3.4832, 3.7153, 3.5139],\n",
      "        [3.6273, 3.8540, 3.6499, 3.9451, 3.6851],\n",
      "        [3.4229, 3.6156, 3.4638, 3.6225, 3.4659],\n",
      "        [3.3772, 3.6546, 3.4355, 3.6378, 3.3829],\n",
      "        [3.4732, 3.5793, 3.5963, 3.6706, 3.5071],\n",
      "        [3.3548, 3.5089, 3.5214, 3.5729, 3.3950],\n",
      "        [3.7428, 3.5535, 3.6900, 4.0493, 3.8607],\n",
      "        [3.5951, 3.7787, 3.6173, 3.8072, 3.6760],\n",
      "        [3.7559, 3.7079, 3.7955, 3.9753, 3.6839],\n",
      "        [3.5296, 3.7660, 3.5792, 3.7832, 3.5565],\n",
      "        [3.4900, 3.7230, 3.6604, 3.7171, 3.4810],\n",
      "        [3.7980, 3.6745, 3.6975, 4.2033, 3.8527],\n",
      "        [3.7644, 3.5514, 3.6747, 4.0843, 3.8962],\n",
      "        [3.4885, 3.6698, 3.6112, 3.6579, 3.5375],\n",
      "        [3.3770, 3.4428, 3.4736, 3.5943, 3.3708],\n",
      "        [3.6105, 3.9901, 3.7799, 3.8870, 3.8395],\n",
      "        [3.6273, 3.8540, 3.6499, 3.9451, 3.6851],\n",
      "        [3.5625, 3.6766, 3.6292, 3.8175, 3.5640],\n",
      "        [3.7395, 3.8086, 3.7963, 4.0119, 3.9140],\n",
      "        [3.3436, 3.5710, 3.5580, 3.5840, 3.4251],\n",
      "        [3.5827, 3.6264, 3.6260, 3.6455, 3.3912],\n",
      "        [3.4144, 3.5768, 3.5757, 3.7028, 3.4832],\n",
      "        [3.3343, 3.6197, 3.5703, 3.5723, 3.4273],\n",
      "        [3.7217, 3.9042, 3.8843, 4.0718, 4.0151],\n",
      "        [3.5583, 3.9320, 3.7504, 3.8331, 3.7430],\n",
      "        [3.3973, 3.5918, 3.4553, 3.5924, 3.4349],\n",
      "        [3.5193, 3.6435, 3.6526, 3.6881, 3.7385],\n",
      "        [3.4127, 3.6048, 3.4572, 3.6071, 3.4410],\n",
      "        [3.4700, 3.6399, 3.6757, 3.7183, 3.5942],\n",
      "        [3.6314, 3.6760, 3.6126, 3.9495, 3.6821],\n",
      "        [3.4043, 3.6389, 3.5040, 3.7110, 3.4337],\n",
      "        [3.8151, 3.9251, 3.8115, 4.1087, 3.8310],\n",
      "        [3.6386, 3.8070, 3.6588, 3.7505, 3.6154],\n",
      "        [3.3394, 3.5460, 3.5401, 3.5689, 3.4013],\n",
      "        [3.6956, 3.8678, 3.6749, 3.8368, 3.7691],\n",
      "        [3.5518, 3.5652, 3.8457, 3.7638, 3.6358],\n",
      "        [3.5744, 3.6167, 3.6614, 3.6524, 3.4925],\n",
      "        [3.3331, 3.6041, 3.5613, 3.5700, 3.4185],\n",
      "        [3.7882, 3.9517, 3.8267, 3.9524, 3.8585],\n",
      "        [3.4578, 3.5208, 3.5977, 3.6427, 3.4644],\n",
      "        [3.3720, 3.4623, 3.4882, 3.5936, 3.3734],\n",
      "        [3.5906, 3.6833, 3.6447, 3.7546, 3.5501],\n",
      "        [3.4683, 3.5928, 3.6011, 3.5622, 3.3162],\n",
      "        [3.4636, 3.6545, 3.4682, 3.6915, 3.4833],\n",
      "        [3.3628, 3.5556, 3.5459, 3.5867, 3.4366],\n",
      "        [3.5557, 3.7775, 3.7240, 3.8569, 3.6566],\n",
      "        [3.3984, 3.6018, 3.4610, 3.5972, 3.4468],\n",
      "        [3.3700, 3.5233, 3.5487, 3.6013, 3.3853],\n",
      "        [3.7747, 3.7216, 3.6736, 3.8719, 3.7151]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4186, 3.6079, 3.4517, 3.6197, 3.4422],\n",
      "        [3.3438, 3.5507, 3.4524, 3.5339, 3.4038],\n",
      "        [3.9679, 3.7690, 3.8713, 4.3727, 4.1250],\n",
      "        [3.3725, 3.4472, 3.4795, 3.5968, 3.3613],\n",
      "        [3.4031, 3.5721, 3.5990, 3.6857, 3.5108],\n",
      "        [3.4359, 3.6092, 3.4900, 3.6420, 3.4857],\n",
      "        [3.6004, 3.8277, 3.6208, 3.9081, 3.6430],\n",
      "        [3.5880, 3.9185, 3.6995, 3.8356, 3.6649],\n",
      "        [3.4890, 3.6101, 3.6962, 3.5921, 3.6773],\n",
      "        [3.7129, 3.9220, 3.6280, 3.7805, 3.6360],\n",
      "        [3.4894, 3.5403, 3.6261, 3.6806, 3.5792],\n",
      "        [3.4038, 3.6380, 3.5022, 3.7102, 3.4329],\n",
      "        [3.3207, 3.4581, 3.4563, 3.5181, 3.3680],\n",
      "        [3.5305, 3.6301, 3.6092, 3.7422, 3.5460],\n",
      "        [3.6306, 3.6699, 3.6021, 3.9372, 3.6669],\n",
      "        [3.5822, 3.6347, 3.6712, 3.6608, 3.4827],\n",
      "        [3.3708, 3.5104, 3.4261, 3.6286, 3.3303],\n",
      "        [3.4718, 3.5672, 3.5923, 3.6584, 3.4990],\n",
      "        [3.8998, 4.0831, 3.7947, 3.9007, 3.6811],\n",
      "        [3.4885, 3.5681, 3.6158, 3.6669, 3.5054],\n",
      "        [3.4678, 3.7132, 3.6505, 3.7000, 3.5987],\n",
      "        [3.3879, 3.4681, 3.4935, 3.6044, 3.3827],\n",
      "        [3.5810, 3.7566, 3.6033, 3.7821, 3.6687],\n",
      "        [3.3945, 3.5645, 3.5959, 3.6949, 3.5057],\n",
      "        [3.4731, 3.5721, 3.5891, 3.6730, 3.5009],\n",
      "        [3.3287, 3.6077, 3.5658, 3.5791, 3.4228],\n",
      "        [3.5905, 3.6884, 3.7573, 3.8145, 3.5784],\n",
      "        [3.5231, 3.8037, 3.6577, 3.7279, 3.4489],\n",
      "        [3.5099, 3.8370, 3.5942, 3.8495, 3.6100],\n",
      "        [3.4683, 3.5673, 3.5845, 3.6600, 3.4964],\n",
      "        [3.5167, 3.6025, 3.6682, 3.7019, 3.5685],\n",
      "        [3.4610, 3.6492, 3.4768, 3.6766, 3.4938],\n",
      "        [3.2963, 3.4493, 3.4421, 3.4860, 3.3512],\n",
      "        [3.6487, 3.8222, 3.7686, 3.9604, 3.6174],\n",
      "        [3.5034, 3.5742, 3.6271, 3.6967, 3.5755],\n",
      "        [3.3453, 3.5604, 3.5429, 3.5788, 3.4255],\n",
      "        [3.4756, 3.7304, 3.6540, 3.7172, 3.4917],\n",
      "        [3.4592, 3.8653, 3.6691, 3.7881, 3.7015],\n",
      "        [3.5103, 3.7633, 3.6008, 3.7096, 3.6013],\n",
      "        [3.6527, 3.8633, 3.6404, 3.7974, 3.6973],\n",
      "        [3.6519, 3.8929, 3.6747, 3.6737, 3.5601],\n",
      "        [3.6378, 3.8749, 3.6381, 3.7971, 3.6832],\n",
      "        [3.7567, 3.7076, 3.7892, 3.9809, 3.6819],\n",
      "        [3.7122, 3.8804, 3.6963, 3.8690, 3.7891],\n",
      "        [3.4908, 3.6227, 3.6784, 3.6380, 3.6645],\n",
      "        [3.3339, 3.5862, 3.5525, 3.5668, 3.4112],\n",
      "        [3.6259, 3.8235, 3.7599, 3.8568, 3.6438],\n",
      "        [3.4958, 3.6892, 3.4845, 3.7362, 3.5188],\n",
      "        [3.5823, 3.8000, 3.6940, 3.7632, 3.4852],\n",
      "        [3.5936, 3.6438, 3.6589, 3.7539, 3.5308],\n",
      "        [3.6206, 3.7200, 3.6832, 3.8221, 3.7710],\n",
      "        [3.3963, 3.5785, 3.6056, 3.6442, 3.4127],\n",
      "        [3.5159, 3.6887, 3.6194, 3.7301, 3.6502],\n",
      "        [3.4216, 3.5867, 3.5830, 3.7095, 3.4942],\n",
      "        [3.7511, 3.7427, 3.6817, 3.8472, 3.7362],\n",
      "        [3.4244, 3.6338, 3.5972, 3.7041, 3.4482],\n",
      "        [3.7145, 3.8564, 3.7825, 3.8882, 3.8741],\n",
      "        [3.5819, 3.6776, 3.4974, 3.7955, 3.6592],\n",
      "        [3.5685, 3.5809, 3.8548, 3.7839, 3.6618],\n",
      "        [3.3637, 3.5736, 3.5812, 3.6182, 3.4159],\n",
      "        [3.7601, 3.7456, 3.6937, 3.8570, 3.7356],\n",
      "        [3.5820, 3.7480, 3.6000, 3.7514, 3.7266],\n",
      "        [3.6248, 3.7294, 3.6923, 3.7489, 3.4224],\n",
      "        [4.0557, 4.3146, 3.9009, 4.0739, 3.7783]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4460, 3.5580, 3.6087, 3.6829, 3.5819],\n",
      "        [3.4056, 3.5580, 3.5665, 3.6747, 3.4748],\n",
      "        [3.8240, 4.0132, 3.6646, 3.8499, 3.6478],\n",
      "        [3.5649, 3.6622, 3.6053, 3.7915, 3.6738],\n",
      "        [3.4790, 3.6230, 3.6077, 3.6797, 3.6645],\n",
      "        [3.4749, 3.5566, 3.5969, 3.6590, 3.4934],\n",
      "        [3.5894, 3.8165, 3.6224, 3.7527, 3.6112],\n",
      "        [3.4620, 3.6302, 3.5068, 3.6889, 3.4711],\n",
      "        [3.9007, 4.1063, 3.8307, 3.9049, 3.7526],\n",
      "        [3.6925, 3.8407, 3.7580, 3.8682, 3.8472],\n",
      "        [3.5121, 3.7064, 3.6251, 3.7295, 3.5945],\n",
      "        [3.4836, 3.4844, 3.5481, 3.5442, 3.3987],\n",
      "        [3.4116, 3.4469, 3.5388, 3.6160, 3.4952],\n",
      "        [3.6186, 3.6332, 3.6570, 3.9364, 3.5612],\n",
      "        [3.5612, 3.7087, 3.5790, 3.7711, 3.5846],\n",
      "        [3.3121, 3.5309, 3.4508, 3.4955, 3.3914],\n",
      "        [3.7148, 3.5632, 3.6815, 4.0141, 3.8412],\n",
      "        [3.2959, 3.4482, 3.4403, 3.4857, 3.3513],\n",
      "        [3.4700, 3.6574, 3.5620, 3.7573, 3.5997],\n",
      "        [3.4830, 3.6173, 3.6190, 3.7003, 3.5387],\n",
      "        [3.5491, 3.6317, 3.7057, 3.7571, 3.5904],\n",
      "        [3.4459, 3.6355, 3.4686, 3.6367, 3.4795],\n",
      "        [3.4880, 3.5670, 3.6138, 3.6665, 3.5054],\n",
      "        [3.5587, 3.6390, 3.7194, 3.7691, 3.6008],\n",
      "        [3.4741, 3.5935, 3.6005, 3.6779, 3.5083],\n",
      "        [3.8319, 3.9869, 3.8631, 3.9934, 3.8971],\n",
      "        [3.5702, 3.7014, 3.7145, 3.7746, 3.5659],\n",
      "        [3.5124, 3.9426, 3.6475, 3.8975, 3.6961],\n",
      "        [3.4962, 3.5787, 3.6342, 3.6868, 3.5526],\n",
      "        [3.3694, 3.6569, 3.6839, 3.6200, 3.5399],\n",
      "        [3.8733, 3.8121, 3.8765, 4.1090, 3.8036],\n",
      "        [3.7070, 3.7915, 3.7216, 3.8418, 3.7207],\n",
      "        [3.4487, 3.6393, 3.4612, 3.6715, 3.4714],\n",
      "        [3.4879, 3.6678, 3.6074, 3.6568, 3.5369],\n",
      "        [3.3679, 3.6944, 3.7573, 3.6738, 3.5703],\n",
      "        [3.3462, 3.5625, 3.4560, 3.5376, 3.4133],\n",
      "        [3.4882, 3.6207, 3.5544, 3.8157, 3.5517],\n",
      "        [3.4700, 3.9312, 3.7585, 3.7428, 3.5505],\n",
      "        [3.4791, 3.5236, 3.5923, 3.6743, 3.6097],\n",
      "        [3.5294, 3.7950, 3.6247, 3.8011, 3.5343],\n",
      "        [3.4623, 3.5620, 3.6109, 3.6887, 3.5783],\n",
      "        [3.7947, 3.8762, 3.8247, 4.0598, 3.7237],\n",
      "        [3.5423, 3.5641, 3.6184, 3.7037, 3.5133],\n",
      "        [3.4257, 3.6235, 3.4615, 3.6398, 3.4576],\n",
      "        [3.4710, 3.6222, 3.5974, 3.6824, 3.6432],\n",
      "        [3.3882, 3.4888, 3.5226, 3.6058, 3.3783],\n",
      "        [3.4665, 3.5089, 3.5606, 3.6537, 3.5948],\n",
      "        [3.4782, 3.5196, 3.5939, 3.6821, 3.6026],\n",
      "        [3.5880, 3.8144, 3.6148, 3.7667, 3.6093],\n",
      "        [3.3428, 3.5689, 3.5542, 3.5829, 3.4243],\n",
      "        [3.4980, 3.5789, 3.6290, 3.6835, 3.5562],\n",
      "        [3.4724, 3.5497, 3.5980, 3.6555, 3.4859],\n",
      "        [3.5644, 3.6403, 3.7282, 3.8121, 3.5518],\n",
      "        [3.6163, 3.8249, 3.7276, 3.9247, 3.6260],\n",
      "        [3.6263, 3.8518, 3.6458, 3.9438, 3.6843],\n",
      "        [3.5915, 3.7061, 3.7003, 3.7555, 3.6824],\n",
      "        [3.9051, 3.7785, 3.8992, 4.3867, 4.1141],\n",
      "        [3.3335, 3.6177, 3.5666, 3.5711, 3.4265],\n",
      "        [3.6021, 3.6364, 3.6428, 3.9225, 3.5519],\n",
      "        [3.3955, 3.6551, 3.5669, 3.7639, 3.4337],\n",
      "        [3.7387, 3.8067, 3.7922, 4.0107, 3.9133],\n",
      "        [3.3937, 3.7875, 3.6164, 3.5289, 3.6174],\n",
      "        [3.7524, 3.8804, 3.8630, 3.8831, 3.5825],\n",
      "        [3.3217, 3.5411, 3.4510, 3.5144, 3.4010]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6742, 3.8576, 3.6460, 3.8198, 3.7311],\n",
      "        [3.5586, 3.7986, 3.6179, 3.8105, 3.5752],\n",
      "        [3.6005, 3.7160, 3.6671, 3.7209, 3.3856],\n",
      "        [3.7398, 3.8016, 3.7821, 4.0167, 3.9132],\n",
      "        [3.3065, 3.4398, 3.4810, 3.5263, 3.3194],\n",
      "        [3.4466, 3.6956, 3.6136, 3.5834, 3.4564],\n",
      "        [3.4575, 3.6216, 3.5546, 3.6352, 3.4920],\n",
      "        [3.6231, 3.8481, 3.6426, 3.9416, 3.6808],\n",
      "        [3.3678, 3.5699, 3.4560, 3.5636, 3.4223],\n",
      "        [3.5785, 3.6698, 3.6330, 3.7414, 3.5319],\n",
      "        [3.7437, 3.5589, 3.6778, 4.0486, 3.8711],\n",
      "        [3.7113, 3.9441, 3.8550, 3.8793, 3.5524],\n",
      "        [3.3843, 3.6145, 3.5014, 3.6851, 3.4260],\n",
      "        [3.5327, 3.5487, 3.5871, 3.6591, 3.5581],\n",
      "        [3.3393, 3.5133, 3.5201, 3.5663, 3.3910],\n",
      "        [3.6253, 3.8505, 3.6437, 3.9430, 3.6842],\n",
      "        [3.4653, 3.5604, 3.5800, 3.6548, 3.4945],\n",
      "        [3.4636, 3.6524, 3.5514, 3.7471, 3.6015],\n",
      "        [3.5675, 3.8003, 3.6839, 3.7565, 3.4806],\n",
      "        [3.4683, 3.5042, 3.5682, 3.6606, 3.5976],\n",
      "        [3.6957, 3.9519, 3.7258, 3.7115, 3.6535],\n",
      "        [3.5669, 3.6762, 3.6313, 3.7392, 3.5447],\n",
      "        [3.9126, 4.0770, 3.6633, 3.8898, 3.6193],\n",
      "        [3.6262, 3.8461, 3.6355, 3.9325, 3.6702],\n",
      "        [3.4674, 3.5988, 3.6011, 3.6925, 3.5202],\n",
      "        [3.3042, 3.5311, 3.4489, 3.4983, 3.3910],\n",
      "        [3.4439, 3.6835, 3.5346, 3.7083, 3.5652],\n",
      "        [3.4852, 3.6776, 3.4724, 3.7171, 3.5057],\n",
      "        [3.7682, 3.8474, 3.8257, 3.9348, 3.9013],\n",
      "        [3.8170, 4.0326, 3.7643, 3.8358, 3.6802],\n",
      "        [3.4393, 3.5346, 3.5236, 3.5961, 3.5264],\n",
      "        [3.3004, 3.5201, 3.4437, 3.4843, 3.3916],\n",
      "        [3.6999, 3.6227, 3.5509, 3.7320, 3.6440],\n",
      "        [3.3796, 3.6029, 3.7004, 3.6380, 3.5751],\n",
      "        [3.5398, 3.6637, 3.6124, 3.7425, 3.6222],\n",
      "        [3.4735, 3.5591, 3.6469, 3.7035, 3.5334],\n",
      "        [3.4687, 3.6357, 3.5077, 3.6653, 3.5187],\n",
      "        [3.3376, 3.5428, 3.5344, 3.5671, 3.4005],\n",
      "        [3.3622, 3.5731, 3.4552, 3.5568, 3.4206],\n",
      "        [3.4782, 3.5484, 3.6237, 3.6711, 3.5015],\n",
      "        [3.7518, 3.8637, 3.8105, 3.9291, 3.9365],\n",
      "        [3.7440, 3.8961, 3.7208, 3.8973, 3.8144],\n",
      "        [3.2547, 3.4792, 3.4209, 3.4344, 3.3413],\n",
      "        [3.5942, 3.9235, 3.7038, 3.8225, 3.6722],\n",
      "        [3.5139, 3.7911, 3.7395, 3.8446, 3.6070],\n",
      "        [3.6513, 3.6850, 3.6388, 3.9961, 3.7162],\n",
      "        [3.4285, 3.6872, 3.5962, 3.5631, 3.4412],\n",
      "        [3.6880, 3.8983, 3.8268, 3.8363, 3.4807],\n",
      "        [3.4326, 3.4680, 3.6081, 3.4880, 3.5482],\n",
      "        [3.3523, 3.5136, 3.5222, 3.5802, 3.4069],\n",
      "        [3.4024, 3.6357, 3.4984, 3.7091, 3.4328],\n",
      "        [3.6603, 3.8103, 3.7813, 3.9647, 3.6185],\n",
      "        [3.4155, 3.6190, 3.5606, 3.5329, 3.4564],\n",
      "        [3.7200, 3.9328, 3.8337, 3.9642, 3.8055],\n",
      "        [3.5045, 3.8281, 3.7189, 3.8119, 3.7306],\n",
      "        [3.3798, 3.4791, 3.5000, 3.5929, 3.3909],\n",
      "        [3.8320, 4.0614, 3.8078, 3.8594, 3.7341],\n",
      "        [3.4578, 3.5960, 3.5161, 3.5985, 3.4836],\n",
      "        [3.4543, 3.5819, 3.7258, 3.5350, 3.6685],\n",
      "        [3.4322, 3.6413, 3.6382, 3.7026, 3.6457],\n",
      "        [3.4719, 3.5762, 3.5875, 3.6630, 3.5005],\n",
      "        [3.7514, 3.8791, 3.8609, 3.8823, 3.5824],\n",
      "        [3.7432, 3.7143, 3.6687, 3.8354, 3.7202],\n",
      "        [3.6383, 3.8589, 3.6764, 3.8417, 3.6577]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3768, 3.6193, 3.4551, 3.6453, 3.4284],\n",
      "        [3.4772, 3.5469, 3.6227, 3.6703, 3.5013],\n",
      "        [3.3655, 3.5731, 3.4584, 3.5568, 3.4267],\n",
      "        [3.6700, 3.7552, 3.7781, 3.8524, 3.5327],\n",
      "        [3.3895, 3.5646, 3.4602, 3.6269, 3.4214],\n",
      "        [3.4910, 3.5748, 3.6272, 3.6400, 3.5032],\n",
      "        [3.4759, 3.5553, 3.5253, 3.7209, 3.4426],\n",
      "        [3.5966, 3.7719, 3.6214, 3.8096, 3.6769],\n",
      "        [3.5368, 3.6243, 3.6102, 3.7479, 3.5484],\n",
      "        [3.6554, 3.8875, 3.6223, 3.7668, 3.6422],\n",
      "        [3.5109, 3.5560, 3.6581, 3.7348, 3.6231],\n",
      "        [3.5010, 3.6162, 3.7109, 3.7349, 3.5786],\n",
      "        [3.5010, 3.6931, 3.4791, 3.7399, 3.5206],\n",
      "        [3.4967, 3.6085, 3.6043, 3.5828, 3.3462],\n",
      "        [3.4248, 3.6197, 3.4579, 3.6320, 3.4605],\n",
      "        [3.5481, 3.6821, 3.6401, 3.7168, 3.5631],\n",
      "        [3.3566, 3.5145, 3.5215, 3.5804, 3.4090],\n",
      "        [3.6722, 3.8650, 3.6535, 3.8107, 3.7262],\n",
      "        [3.4867, 3.5496, 3.6181, 3.6180, 3.5531],\n",
      "        [3.3039, 3.5288, 3.4522, 3.4922, 3.3947],\n",
      "        [3.4605, 3.6417, 3.4683, 3.6604, 3.4961],\n",
      "        [3.3613, 3.5054, 3.5227, 3.5976, 3.4027],\n",
      "        [3.4772, 3.6084, 3.5277, 3.6917, 3.4763],\n",
      "        [3.4191, 3.4657, 3.4957, 3.6243, 3.3719],\n",
      "        [3.7428, 3.5574, 3.6768, 4.0479, 3.8709],\n",
      "        [3.4868, 3.6060, 3.6912, 3.5902, 3.6771],\n",
      "        [3.7008, 3.8841, 3.8601, 4.0417, 3.9963],\n",
      "        [3.5141, 3.5452, 3.7098, 3.7772, 3.5332],\n",
      "        [3.5166, 3.5776, 3.6673, 3.7611, 3.5465],\n",
      "        [3.5608, 3.7972, 3.6778, 3.7536, 3.4745],\n",
      "        [3.3711, 3.4402, 3.4686, 3.5865, 3.3640],\n",
      "        [3.6923, 3.8508, 3.7425, 3.8580, 3.7412],\n",
      "        [3.4709, 3.5747, 3.5865, 3.6622, 3.5003],\n",
      "        [3.4747, 3.5780, 3.5936, 3.6790, 3.5045],\n",
      "        [3.5995, 3.9569, 3.7963, 3.8576, 3.7568],\n",
      "        [3.6919, 3.9047, 3.8231, 3.8373, 3.4896],\n",
      "        [3.4000, 3.5600, 3.5545, 3.6829, 3.4732],\n",
      "        [3.6340, 3.8708, 3.6785, 3.8286, 3.6530],\n",
      "        [3.8390, 3.7485, 3.8141, 4.3215, 4.0367],\n",
      "        [4.0858, 4.3309, 3.8825, 4.0565, 3.8158],\n",
      "        [3.3359, 3.5654, 3.4670, 3.5811, 3.3984],\n",
      "        [3.4799, 3.5704, 3.5986, 3.6666, 3.5102],\n",
      "        [3.3341, 3.5525, 3.4565, 3.5235, 3.4181],\n",
      "        [3.4861, 3.9174, 3.7654, 3.7673, 3.5646],\n",
      "        [3.5683, 3.6986, 3.7116, 3.7732, 3.5656],\n",
      "        [3.4773, 3.6203, 3.6048, 3.6783, 3.6644],\n",
      "        [3.3224, 3.5456, 3.4531, 3.5202, 3.4049],\n",
      "        [3.4568, 3.6102, 3.6889, 3.7676, 3.6693],\n",
      "        [3.6553, 3.8989, 3.7911, 3.8615, 3.6484],\n",
      "        [3.3841, 3.4984, 3.5299, 3.6024, 3.3823],\n",
      "        [3.5010, 3.8031, 3.6392, 3.7087, 3.4389],\n",
      "        [3.3556, 3.5849, 3.5890, 3.6039, 3.4358],\n",
      "        [3.4608, 3.6497, 3.4616, 3.6888, 3.4824],\n",
      "        [3.1713, 3.4248, 3.4571, 3.4366, 3.3441],\n",
      "        [3.5812, 3.6763, 3.7474, 3.8183, 3.5641],\n",
      "        [3.5358, 3.5558, 3.6064, 3.7016, 3.4854],\n",
      "        [3.4756, 3.5951, 3.6942, 3.6022, 3.6609],\n",
      "        [3.1868, 3.4291, 3.4594, 3.4538, 3.3715],\n",
      "        [3.6275, 3.7464, 3.7609, 3.7697, 3.4681],\n",
      "        [3.8270, 3.9780, 3.8426, 4.1383, 3.8159],\n",
      "        [3.4524, 3.6533, 3.5947, 3.7756, 3.5015],\n",
      "        [3.4280, 3.5550, 3.6024, 3.6598, 3.4895],\n",
      "        [3.4678, 3.6341, 3.5786, 3.6181, 3.5197],\n",
      "        [3.6550, 3.7870, 3.7251, 3.8396, 3.7419]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8063, 3.7176, 3.7996, 4.2982, 4.0291],\n",
      "        [3.4328, 3.6278, 3.5658, 3.7270, 3.5147],\n",
      "        [3.6221, 3.7950, 3.6338, 3.8356, 3.6230],\n",
      "        [3.4079, 3.5465, 3.5784, 3.6492, 3.4915],\n",
      "        [3.3692, 3.4418, 3.4736, 3.5942, 3.3609],\n",
      "        [3.7239, 3.7482, 3.7530, 4.0274, 3.5921],\n",
      "        [3.6320, 3.6994, 3.7795, 3.7633, 3.4030],\n",
      "        [3.7087, 3.8751, 3.6903, 3.8660, 3.7884],\n",
      "        [3.8809, 4.0570, 3.6742, 3.8840, 3.6324],\n",
      "        [3.1813, 3.4203, 3.4497, 3.4499, 3.3590],\n",
      "        [3.7406, 3.9737, 3.7362, 3.7676, 3.6291],\n",
      "        [3.6824, 3.8637, 3.7917, 3.8902, 3.8425],\n",
      "        [3.5473, 3.7341, 3.6019, 3.7766, 3.6221],\n",
      "        [3.3752, 3.5382, 3.5495, 3.5461, 3.4274],\n",
      "        [3.4752, 3.6002, 3.6030, 3.6934, 3.5272],\n",
      "        [3.4488, 3.7288, 3.6830, 3.6929, 3.5608],\n",
      "        [3.4458, 3.6350, 3.4576, 3.6690, 3.4708],\n",
      "        [3.5000, 3.6915, 3.4782, 3.7388, 3.5202],\n",
      "        [3.4783, 3.6475, 3.6250, 3.6722, 3.4258],\n",
      "        [3.5544, 3.9257, 3.7426, 3.8293, 3.7416],\n",
      "        [3.4068, 3.6407, 3.5632, 3.7475, 3.4324],\n",
      "        [3.3505, 3.5792, 3.5821, 3.5972, 3.4300],\n",
      "        [3.3784, 3.4440, 3.4765, 3.5944, 3.3693],\n",
      "        [3.5845, 3.7402, 3.5940, 3.7491, 3.7109],\n",
      "        [3.5239, 3.6858, 3.6323, 3.7258, 3.6582],\n",
      "        [3.6763, 3.6151, 3.6240, 4.0861, 3.7308],\n",
      "        [3.4918, 3.5739, 3.6142, 3.6756, 3.5590],\n",
      "        [3.4787, 3.7574, 3.6324, 3.6420, 3.5999],\n",
      "        [3.4047, 3.4943, 3.5207, 3.6170, 3.3911],\n",
      "        [3.6573, 3.7536, 3.8878, 3.7434, 3.5234],\n",
      "        [3.7420, 3.8002, 3.7854, 3.9838, 3.7132],\n",
      "        [3.6454, 3.7364, 3.7100, 3.8199, 3.7968],\n",
      "        [3.5979, 3.6415, 3.6695, 3.7671, 3.5456],\n",
      "        [3.4737, 3.6646, 3.5855, 3.8265, 3.5018],\n",
      "        [3.4815, 3.6551, 3.5708, 3.8112, 3.5178],\n",
      "        [3.4854, 3.5894, 3.6253, 3.6978, 3.5371],\n",
      "        [3.5565, 3.7955, 3.6158, 3.8086, 3.5745],\n",
      "        [3.5270, 3.6215, 3.6920, 3.7351, 3.5849],\n",
      "        [3.5156, 3.5761, 3.6663, 3.7601, 3.5462],\n",
      "        [3.4069, 3.5485, 3.5684, 3.6488, 3.4134],\n",
      "        [3.5912, 3.7727, 3.6093, 3.8032, 3.6744],\n",
      "        [3.7831, 3.7516, 3.7093, 3.8960, 3.7491],\n",
      "        [3.3675, 3.4544, 3.4805, 3.5918, 3.3716],\n",
      "        [3.6383, 3.7502, 3.7825, 3.7885, 3.5105],\n",
      "        [3.9266, 4.1236, 3.8192, 3.9344, 3.7273],\n",
      "        [3.4207, 3.7971, 3.5844, 3.6204, 3.4144],\n",
      "        [3.6288, 3.8242, 3.7547, 3.8550, 3.6482],\n",
      "        [3.7049, 3.6216, 3.6491, 4.0789, 3.7586],\n",
      "        [3.4023, 3.7129, 3.4898, 3.4412, 3.4786],\n",
      "        [3.4721, 3.5522, 3.5930, 3.6565, 3.4927],\n",
      "        [3.6039, 3.7838, 3.6034, 3.7571, 3.7138],\n",
      "        [3.2960, 3.5954, 3.3547, 3.5953, 3.3133],\n",
      "        [3.4787, 3.7574, 3.6324, 3.6420, 3.5999],\n",
      "        [3.4977, 3.6281, 3.6243, 3.6726, 3.7101],\n",
      "        [3.4970, 3.9217, 3.7717, 3.7682, 3.5750],\n",
      "        [3.4193, 3.6093, 3.4564, 3.6189, 3.4646],\n",
      "        [3.6320, 3.8644, 3.7785, 3.8760, 3.6398],\n",
      "        [3.5002, 3.5706, 3.6680, 3.6965, 3.5615],\n",
      "        [3.2405, 3.4755, 3.4888, 3.4930, 3.4062],\n",
      "        [3.4764, 3.6187, 3.6038, 3.6773, 3.6641],\n",
      "        [3.5525, 3.9509, 3.6604, 3.9145, 3.7234],\n",
      "        [3.5865, 3.7218, 3.6420, 3.8927, 3.5723],\n",
      "        [3.4963, 3.6837, 3.4863, 3.7290, 3.5209],\n",
      "        [3.4895, 3.6215, 3.6191, 3.7192, 3.5466]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5863, 3.6751, 3.6359, 3.7496, 3.5484],\n",
      "        [3.4322, 3.5685, 3.3744, 3.7065, 3.3433],\n",
      "        [3.4780, 3.5671, 3.5965, 3.6643, 3.5094],\n",
      "        [3.3135, 3.3991, 3.4546, 3.5943, 3.3595],\n",
      "        [3.5261, 3.6198, 3.6910, 3.7338, 3.5845],\n",
      "        [3.5039, 3.6631, 3.6090, 3.6676, 3.5449],\n",
      "        [3.3782, 3.7071, 3.6112, 3.6716, 3.6527],\n",
      "        [3.3680, 3.4940, 3.5308, 3.5898, 3.3720],\n",
      "        [3.3399, 3.4943, 3.4710, 3.5476, 3.3931],\n",
      "        [3.3348, 3.5382, 3.5317, 3.5641, 3.3995],\n",
      "        [3.6311, 3.7959, 3.6555, 3.7333, 3.6048],\n",
      "        [3.4612, 3.5713, 3.5812, 3.6629, 3.4987],\n",
      "        [3.6599, 3.8397, 3.7763, 3.8110, 3.5186],\n",
      "        [3.6458, 3.7385, 3.7426, 3.8625, 3.5054],\n",
      "        [3.3607, 3.4584, 3.4824, 3.5822, 3.3721],\n",
      "        [3.3265, 3.4596, 3.4940, 3.5420, 3.3531],\n",
      "        [3.5184, 3.6024, 3.6831, 3.7420, 3.5827],\n",
      "        [3.7101, 3.9781, 3.7430, 3.9642, 3.8222],\n",
      "        [3.4600, 3.6804, 3.5644, 3.7312, 3.5624],\n",
      "        [3.3329, 3.6224, 3.5710, 3.5731, 3.4338],\n",
      "        [3.5882, 3.6326, 3.6596, 3.7517, 3.5365],\n",
      "        [3.2601, 3.5415, 3.6471, 3.5092, 3.5009],\n",
      "        [3.5195, 3.6054, 3.6728, 3.7082, 3.5734],\n",
      "        [3.4856, 3.6688, 3.7827, 3.7445, 3.6674],\n",
      "        [3.4588, 3.6405, 3.4531, 3.6798, 3.4722],\n",
      "        [3.6571, 3.8524, 3.6342, 3.8063, 3.7101],\n",
      "        [3.6536, 3.7515, 3.7081, 3.8090, 3.7522],\n",
      "        [3.5616, 3.6783, 3.6308, 3.7343, 3.5542],\n",
      "        [3.4843, 3.6061, 3.4915, 3.6591, 3.5894],\n",
      "        [3.7189, 3.9873, 3.7594, 3.9746, 3.8376],\n",
      "        [3.5588, 3.7940, 3.6758, 3.7512, 3.4737],\n",
      "        [3.2713, 3.4068, 3.4223, 3.4560, 3.3204],\n",
      "        [3.3348, 3.5382, 3.5317, 3.5641, 3.3995],\n",
      "        [3.3791, 3.4505, 3.4794, 3.6092, 3.3896],\n",
      "        [3.4150, 3.5803, 3.4968, 3.6899, 3.4729],\n",
      "        [3.7929, 3.7875, 3.7739, 3.9381, 3.7616],\n",
      "        [3.4762, 3.5980, 3.6047, 3.6919, 3.5296],\n",
      "        [3.4002, 3.5414, 3.5744, 3.6619, 3.4937],\n",
      "        [3.6449, 3.7413, 3.7041, 3.8554, 3.7949],\n",
      "        [3.6285, 3.7417, 3.5547, 3.8444, 3.6908],\n",
      "        [3.7996, 3.7110, 3.8070, 3.9687, 3.7313],\n",
      "        [3.7106, 3.8427, 3.7766, 3.8916, 3.8774],\n",
      "        [3.5342, 3.8912, 3.8034, 3.8574, 3.7364],\n",
      "        [3.6850, 3.8936, 3.8239, 3.8329, 3.4795],\n",
      "        [3.7409, 3.5542, 3.6749, 4.0457, 3.8702],\n",
      "        [3.4949, 3.6054, 3.6025, 3.5805, 3.3454],\n",
      "        [3.5453, 3.6255, 3.7008, 3.7531, 3.5893],\n",
      "        [3.4177, 3.4410, 3.4571, 3.5968, 3.3595],\n",
      "        [3.4739, 3.5545, 3.5887, 3.6595, 3.5006],\n",
      "        [3.6354, 3.7419, 3.6758, 3.8686, 3.7565],\n",
      "        [3.4790, 3.6110, 3.6137, 3.6965, 3.5376],\n",
      "        [3.4594, 3.8521, 3.7167, 3.7788, 3.7132],\n",
      "        [3.3331, 3.6068, 3.5612, 3.5809, 3.4320],\n",
      "        [3.4870, 3.6564, 3.5738, 3.8296, 3.5169],\n",
      "        [3.6398, 3.7732, 3.7525, 3.8616, 3.5572],\n",
      "        [3.5181, 3.6080, 3.6753, 3.7440, 3.5790],\n",
      "        [3.3022, 3.5187, 3.4366, 3.4896, 3.3815],\n",
      "        [3.3749, 3.5793, 3.6152, 3.6397, 3.4074],\n",
      "        [3.5899, 3.6311, 3.6615, 3.7487, 3.5426],\n",
      "        [3.5663, 3.6954, 3.7098, 3.7708, 3.5647],\n",
      "        [3.7658, 3.7088, 3.7897, 3.9715, 3.6916],\n",
      "        [3.4010, 3.8429, 3.6521, 3.7270, 3.6911],\n",
      "        [3.6970, 3.7831, 3.7461, 3.8736, 3.8324],\n",
      "        [3.6296, 3.8227, 3.7679, 3.8384, 3.6818]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3402, 3.5549, 3.4534, 3.5375, 3.4138],\n",
      "        [3.4819, 3.6636, 3.6260, 3.6705, 3.4409],\n",
      "        [3.5398, 3.6639, 3.6157, 3.7389, 3.6269],\n",
      "        [3.5095, 3.8153, 3.5375, 3.7052, 3.5322],\n",
      "        [3.6140, 3.8032, 3.7276, 3.9200, 3.6118],\n",
      "        [3.4875, 3.5729, 3.6034, 3.6649, 3.5645],\n",
      "        [3.4818, 3.6451, 3.5134, 3.6810, 3.5327],\n",
      "        [3.6436, 3.7127, 3.8358, 3.7600, 3.4819],\n",
      "        [3.4878, 3.5698, 3.6261, 3.6360, 3.5017],\n",
      "        [3.4482, 3.6608, 3.5982, 3.7714, 3.4785],\n",
      "        [3.6178, 3.5007, 3.5162, 3.6598, 3.5557],\n",
      "        [3.5759, 3.7393, 3.5936, 3.7450, 3.7243],\n",
      "        [3.8193, 3.6590, 3.6885, 4.2251, 3.8746],\n",
      "        [3.4951, 3.5809, 3.5978, 3.6614, 3.5753],\n",
      "        [3.8269, 3.9794, 3.8589, 3.9877, 3.8954],\n",
      "        [3.7480, 3.8019, 3.7901, 3.9842, 3.7219],\n",
      "        [3.4331, 3.5267, 3.5763, 3.6126, 3.4640],\n",
      "        [3.6558, 3.8489, 3.7344, 3.7242, 3.6655],\n",
      "        [3.5295, 3.5425, 3.5853, 3.6550, 3.5569],\n",
      "        [3.5720, 3.6157, 3.6573, 3.6551, 3.4856],\n",
      "        [3.6088, 3.8262, 3.7525, 3.8518, 3.6671],\n",
      "        [3.6206, 3.8146, 3.7540, 3.8512, 3.6423],\n",
      "        [3.8185, 3.8134, 3.7756, 4.0505, 3.7566],\n",
      "        [3.6561, 3.8508, 3.6351, 3.8048, 3.7095],\n",
      "        [3.5773, 3.6198, 3.6654, 3.6427, 3.5157],\n",
      "        [3.5332, 3.8896, 3.8043, 3.8559, 3.7359],\n",
      "        [3.3287, 3.5697, 3.5469, 3.5705, 3.4172],\n",
      "        [3.9586, 4.1597, 3.8657, 3.9592, 3.7747],\n",
      "        [3.3728, 3.5496, 3.5760, 3.6062, 3.4196],\n",
      "        [3.6189, 3.8414, 3.6408, 3.9368, 3.6792],\n",
      "        [3.3309, 3.6583, 3.4166, 3.6348, 3.3687],\n",
      "        [3.4709, 3.6499, 3.4720, 3.6761, 3.5059],\n",
      "        [3.4670, 3.5078, 3.4765, 3.7309, 3.3984],\n",
      "        [3.6832, 3.7995, 3.7343, 3.8493, 3.8366],\n",
      "        [3.4863, 3.6222, 3.6141, 3.6718, 3.6872],\n",
      "        [3.7651, 3.8552, 3.7312, 3.9311, 3.8254],\n",
      "        [3.4264, 3.4799, 3.5650, 3.6075, 3.4370],\n",
      "        [3.3727, 3.4441, 3.4703, 3.5987, 3.3820],\n",
      "        [3.5012, 3.5790, 3.6390, 3.6854, 3.5600],\n",
      "        [3.8651, 3.6929, 3.7663, 4.2716, 4.0279],\n",
      "        [3.2202, 3.4540, 3.4821, 3.4703, 3.3903],\n",
      "        [3.3447, 3.5155, 3.5256, 3.5676, 3.3976],\n",
      "        [3.4837, 3.5269, 3.6258, 3.6871, 3.6065],\n",
      "        [3.4206, 3.5533, 3.5851, 3.6599, 3.4915],\n",
      "        [3.6117, 3.8173, 3.7236, 3.9194, 3.6245],\n",
      "        [3.5860, 3.7368, 3.7339, 3.7341, 3.4913],\n",
      "        [3.4496, 3.5621, 3.4507, 3.6216, 3.5528],\n",
      "        [3.3696, 3.7663, 3.5962, 3.5039, 3.5918],\n",
      "        [3.4308, 3.6245, 3.5658, 3.7242, 3.5137],\n",
      "        [3.4407, 3.5943, 3.4995, 3.6006, 3.4538],\n",
      "        [3.2883, 3.4981, 3.3436, 3.5730, 3.3266],\n",
      "        [3.3485, 3.6576, 3.5966, 3.5993, 3.4694],\n",
      "        [4.0385, 4.3065, 3.8222, 3.9987, 3.7852],\n",
      "        [3.5868, 3.6457, 3.6745, 3.6856, 3.4738],\n",
      "        [3.6786, 3.8954, 3.8260, 3.8303, 3.4904],\n",
      "        [3.4841, 3.6697, 3.4685, 3.7281, 3.5080],\n",
      "        [3.6824, 3.7080, 3.7551, 3.8956, 3.6266],\n",
      "        [3.3929, 3.5923, 3.4538, 3.5909, 3.4446],\n",
      "        [3.7401, 3.7970, 3.7854, 3.9810, 3.7123],\n",
      "        [3.5071, 3.9356, 3.6435, 3.8920, 3.6943],\n",
      "        [3.5871, 3.6530, 3.6140, 3.8601, 3.6225],\n",
      "        [3.4677, 3.5509, 3.5922, 3.6552, 3.4952],\n",
      "        [3.4163, 3.5689, 3.4934, 3.6969, 3.4692],\n",
      "        [3.7381, 3.8457, 3.7650, 3.9967, 3.6865]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8123, 4.0251, 3.7631, 3.8295, 3.6778],\n",
      "        [3.5327, 3.6175, 3.6102, 3.7424, 3.5461],\n",
      "        [3.7062, 3.9359, 3.8538, 3.8725, 3.5496],\n",
      "        [3.4894, 3.6787, 3.4798, 3.7289, 3.5164],\n",
      "        [3.4516, 3.5527, 3.6062, 3.6812, 3.5633],\n",
      "        [3.4149, 3.5759, 3.5775, 3.7021, 3.4916],\n",
      "        [3.4170, 3.5752, 3.4974, 3.5739, 3.4325],\n",
      "        [3.5342, 3.7454, 3.5636, 3.7569, 3.5703],\n",
      "        [3.4530, 3.5882, 3.5155, 3.5926, 3.4814],\n",
      "        [3.6020, 3.7678, 3.6731, 3.7665, 3.6767],\n",
      "        [3.3937, 3.6139, 3.6580, 3.6693, 3.5873],\n",
      "        [3.4049, 3.6711, 3.4736, 3.6835, 3.4055],\n",
      "        [3.3254, 3.5539, 3.5363, 3.5589, 3.4023],\n",
      "        [3.3372, 3.5684, 3.5462, 3.5730, 3.4272],\n",
      "        [3.8640, 3.6913, 3.7672, 4.2700, 4.0270],\n",
      "        [3.5328, 3.4485, 3.7142, 3.7503, 3.6022],\n",
      "        [3.9499, 4.1523, 3.7891, 3.9306, 3.6713],\n",
      "        [3.4851, 3.6119, 3.6737, 3.6308, 3.6623],\n",
      "        [3.4579, 3.5614, 3.5786, 3.6544, 3.4939],\n",
      "        [3.5274, 3.5054, 3.5848, 3.8381, 3.4457],\n",
      "        [3.4833, 3.5634, 3.6083, 3.6622, 3.5090],\n",
      "        [3.6883, 3.8605, 3.8143, 3.8368, 3.5393],\n",
      "        [3.7580, 3.5401, 3.6680, 4.0767, 3.8935],\n",
      "        [3.6385, 3.6150, 3.6067, 4.0009, 3.6870],\n",
      "        [3.4959, 3.7410, 3.6096, 3.6660, 3.5965],\n",
      "        [3.5643, 3.6921, 3.7115, 3.7676, 3.5632],\n",
      "        [3.6201, 3.8420, 3.6428, 3.9365, 3.6817],\n",
      "        [3.3856, 3.5582, 3.4603, 3.6216, 3.4192],\n",
      "        [3.6679, 3.8585, 3.6530, 3.8049, 3.7236],\n",
      "        [3.3504, 3.5984, 3.5630, 3.5817, 3.4481],\n",
      "        [3.3778, 3.5680, 3.4523, 3.5692, 3.4243],\n",
      "        [3.5117, 3.6360, 3.6427, 3.6798, 3.7348],\n",
      "        [3.4654, 3.5429, 3.5930, 3.6566, 3.4850],\n",
      "        [3.8400, 3.9327, 3.8315, 4.1174, 3.8379],\n",
      "        [3.3855, 3.5677, 3.4620, 3.6334, 3.4116],\n",
      "        [3.3735, 3.6768, 3.7594, 3.6513, 3.5873],\n",
      "        [3.4333, 3.7559, 3.5781, 3.6465, 3.4646],\n",
      "        [3.3771, 3.4472, 3.4810, 3.6062, 3.3882],\n",
      "        [3.5853, 3.6362, 3.6506, 3.7402, 3.5334],\n",
      "        [3.6296, 3.6559, 3.6342, 3.6596, 3.4584],\n",
      "        [3.5108, 3.6019, 3.7080, 3.8519, 3.7460],\n",
      "        [3.7636, 3.7959, 3.7967, 4.0757, 3.6519],\n",
      "        [3.3258, 3.6441, 3.6824, 3.5945, 3.5161],\n",
      "        [3.8483, 3.8312, 3.8990, 4.1040, 3.8032],\n",
      "        [3.8202, 3.8116, 3.7770, 4.0436, 3.7576],\n",
      "        [3.5059, 3.9340, 3.6443, 3.8903, 3.6933],\n",
      "        [3.3392, 3.5533, 3.4542, 3.5359, 3.4129],\n",
      "        [3.3178, 3.5438, 3.4679, 3.5093, 3.4136],\n",
      "        [3.3382, 3.5270, 3.6369, 3.5815, 3.5110],\n",
      "        [3.4689, 3.5470, 3.5974, 3.6553, 3.4891],\n",
      "        [3.6397, 3.8290, 3.7600, 3.7905, 3.5058],\n",
      "        [3.6734, 3.6129, 3.6211, 3.7452, 3.6191],\n",
      "        [3.7362, 3.5423, 3.6832, 4.0415, 3.8579],\n",
      "        [3.3760, 3.4551, 3.4842, 3.5929, 3.3783],\n",
      "        [3.6603, 3.6746, 3.6874, 3.9445, 3.5256],\n",
      "        [3.4280, 3.5359, 3.5803, 3.6239, 3.4751],\n",
      "        [3.5813, 3.9085, 3.6944, 3.8282, 3.6622],\n",
      "        [3.6175, 3.7009, 3.6924, 3.7304, 3.4458],\n",
      "        [3.2694, 3.4036, 3.4240, 3.4531, 3.3190],\n",
      "        [3.8519, 3.8344, 3.9001, 4.1056, 3.8052],\n",
      "        [3.6250, 3.6648, 3.6059, 3.9414, 3.6789],\n",
      "        [3.2191, 3.4524, 3.4828, 3.4687, 3.3893],\n",
      "        [3.3474, 3.5057, 3.5211, 3.5742, 3.4046],\n",
      "        [3.4720, 3.5469, 3.6081, 3.6587, 3.4969]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5443, 3.5514, 3.8389, 3.7535, 3.6317],\n",
      "        [3.6331, 3.8497, 3.6758, 3.8337, 3.6551],\n",
      "        [3.6112, 3.6837, 3.6877, 3.7219, 3.4576],\n",
      "        [3.6266, 3.7370, 3.5569, 3.8394, 3.6892],\n",
      "        [3.4399, 3.5467, 3.6059, 3.6742, 3.5792],\n",
      "        [3.6040, 3.7799, 3.7579, 3.7868, 3.6221],\n",
      "        [3.8249, 3.8098, 3.8294, 3.9875, 3.8079],\n",
      "        [3.4539, 3.5448, 3.5377, 3.6976, 3.4281],\n",
      "        [3.5430, 3.7927, 3.6667, 3.7408, 3.4654],\n",
      "        [3.3574, 3.5638, 3.4551, 3.5491, 3.4183],\n",
      "        [3.5117, 3.6850, 3.6271, 3.7203, 3.5977],\n",
      "        [3.6513, 3.7418, 3.7720, 3.7862, 3.5148],\n",
      "        [3.4671, 3.7150, 3.5665, 3.7029, 3.5801],\n",
      "        [3.6292, 3.8101, 3.7861, 3.8595, 3.7037],\n",
      "        [3.8033, 3.6976, 3.8165, 3.9973, 3.7324],\n",
      "        [3.8767, 4.0146, 3.8903, 4.1938, 3.8925],\n",
      "        [3.3979, 3.5489, 3.5884, 3.6752, 3.5133],\n",
      "        [3.5901, 3.8297, 3.6975, 3.9031, 3.6373],\n",
      "        [3.4603, 3.6087, 3.5925, 3.6714, 3.6377],\n",
      "        [3.4802, 3.6679, 3.4721, 3.7092, 3.5032],\n",
      "        [3.6579, 3.8346, 3.7787, 3.8060, 3.5170],\n",
      "        [3.4866, 3.5664, 3.6274, 3.6325, 3.5006],\n",
      "        [3.5961, 3.7063, 3.6666, 3.7134, 3.3835],\n",
      "        [3.4665, 3.5596, 3.5842, 3.6638, 3.4984],\n",
      "        [3.4830, 3.6664, 3.4698, 3.7248, 3.5069],\n",
      "        [3.5953, 3.9487, 3.7967, 3.8501, 3.7543],\n",
      "        [3.4036, 3.6341, 3.5643, 3.7413, 3.4301],\n",
      "        [3.5856, 3.6936, 3.6555, 3.7053, 3.3737],\n",
      "        [3.6352, 3.6520, 3.6415, 3.6647, 3.4554],\n",
      "        [3.5042, 3.7325, 3.5487, 3.8404, 3.4778],\n",
      "        [3.6092, 3.4881, 3.5114, 3.6620, 3.5469],\n",
      "        [3.5488, 3.8687, 3.6992, 3.8069, 3.7314],\n",
      "        [3.4609, 3.5020, 3.6202, 3.5458, 3.5538],\n",
      "        [3.4680, 3.5496, 3.5857, 3.6527, 3.4980],\n",
      "        [3.3971, 3.7755, 3.5664, 3.5906, 3.3947],\n",
      "        [3.5482, 3.9352, 3.6435, 3.9005, 3.6996],\n",
      "        [3.7886, 3.7492, 3.6990, 3.8725, 3.7046],\n",
      "        [3.7769, 3.6663, 3.6786, 4.1500, 3.8272],\n",
      "        [3.4422, 3.8077, 3.6157, 3.6552, 3.4265],\n",
      "        [3.4755, 3.5046, 3.5966, 3.6743, 3.5950],\n",
      "        [3.4149, 3.6055, 3.4526, 3.6255, 3.4482],\n",
      "        [3.7614, 3.7184, 3.8120, 3.9955, 3.7037],\n",
      "        [3.4689, 3.5452, 3.5979, 3.6535, 3.4890],\n",
      "        [3.4565, 3.6336, 3.4689, 3.6533, 3.4939],\n",
      "        [3.5367, 3.6188, 3.6959, 3.7410, 3.5935],\n",
      "        [3.6352, 3.7435, 3.7837, 3.7820, 3.5083],\n",
      "        [3.5814, 3.6275, 3.6651, 3.6538, 3.4928],\n",
      "        [3.3992, 3.5924, 3.4677, 3.5855, 3.4639],\n",
      "        [3.4176, 3.5305, 3.6063, 3.6421, 3.4771],\n",
      "        [3.3279, 3.6329, 3.5800, 3.5671, 3.4406],\n",
      "        [3.3606, 3.4188, 3.4664, 3.5796, 3.3508],\n",
      "        [3.4704, 3.6580, 3.5866, 3.8202, 3.4995],\n",
      "        [3.5079, 3.7905, 3.6203, 3.8476, 3.5305],\n",
      "        [3.6751, 3.9048, 3.7392, 3.7216, 3.6954],\n",
      "        [3.7144, 3.8860, 3.8705, 4.0652, 4.0038],\n",
      "        [3.3416, 3.6470, 3.5938, 3.5791, 3.4520],\n",
      "        [3.3460, 3.4913, 3.5103, 3.5640, 3.3907],\n",
      "        [3.3045, 3.3804, 3.4502, 3.5716, 3.3512],\n",
      "        [3.5784, 3.6064, 3.6594, 3.6444, 3.5210],\n",
      "        [3.2693, 3.4020, 3.4246, 3.4514, 3.3191],\n",
      "        [3.4866, 3.5871, 3.6887, 3.7042, 3.5657],\n",
      "        [3.6814, 3.7048, 3.7564, 3.8921, 3.6256],\n",
      "        [3.6257, 3.8148, 3.7442, 3.7789, 3.4931],\n",
      "        [3.5982, 3.8989, 3.7868, 3.8444, 3.8034]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5029, 3.8989, 3.7353, 3.7387, 3.5206],\n",
      "        [3.7428, 3.8032, 3.7998, 3.9063, 3.8675],\n",
      "        [3.5813, 3.6261, 3.6655, 3.6519, 3.4935],\n",
      "        [3.7885, 3.8637, 3.8222, 4.0487, 3.7215],\n",
      "        [3.3745, 3.5517, 3.4340, 3.6302, 3.4222],\n",
      "        [3.5540, 3.7490, 3.5698, 3.7581, 3.6004],\n",
      "        [3.3836, 3.5058, 3.4040, 3.6268, 3.3851],\n",
      "        [3.6298, 3.7333, 3.5588, 3.8370, 3.6906],\n",
      "        [3.5960, 3.7050, 3.6670, 3.7116, 3.3843],\n",
      "        [3.4635, 3.6987, 3.5542, 3.7074, 3.5776],\n",
      "        [3.3002, 3.5127, 3.4393, 3.4832, 3.3810],\n",
      "        [3.4023, 3.4337, 3.5368, 3.6006, 3.4991],\n",
      "        [3.4253, 3.6252, 3.5957, 3.6840, 3.4418],\n",
      "        [3.4399, 3.5100, 3.5720, 3.5989, 3.4502],\n",
      "        [3.8069, 3.8124, 3.8019, 4.0367, 3.7896],\n",
      "        [3.4826, 3.7087, 3.6539, 3.7054, 3.4778],\n",
      "        [3.2598, 3.4679, 3.4190, 3.4404, 3.3522],\n",
      "        [3.7469, 3.7974, 3.7917, 3.9787, 3.7216],\n",
      "        [4.0771, 4.3109, 3.8789, 4.0378, 3.8057],\n",
      "        [3.3745, 3.5633, 3.4356, 3.6272, 3.4241],\n",
      "        [3.5178, 3.8963, 3.7862, 3.8343, 3.7572],\n",
      "        [3.7101, 3.7714, 3.7654, 3.9803, 3.9007],\n",
      "        [3.6905, 3.6812, 3.6629, 3.8215, 3.6932],\n",
      "        [3.6038, 3.7858, 3.7596, 3.7402, 3.5023],\n",
      "        [3.3803, 3.4766, 3.5078, 3.6014, 3.4068],\n",
      "        [3.3333, 3.5693, 3.5514, 3.5717, 3.4252],\n",
      "        [3.4858, 3.6110, 3.5568, 3.7856, 3.5678],\n",
      "        [3.7910, 3.8498, 3.8474, 4.0334, 3.7820],\n",
      "        [3.7072, 3.8765, 3.8617, 4.0410, 4.0051],\n",
      "        [3.5738, 3.6586, 3.6330, 3.7314, 3.5302],\n",
      "        [3.4609, 3.5694, 3.5883, 3.6627, 3.5001],\n",
      "        [3.6576, 3.8081, 3.7553, 3.7585, 3.6614],\n",
      "        [3.4779, 3.5968, 3.6071, 3.6968, 3.5191],\n",
      "        [3.4879, 3.6657, 3.5673, 3.7490, 3.5662],\n",
      "        [3.4334, 3.6214, 3.4619, 3.6470, 3.4648],\n",
      "        [3.7447, 3.7128, 3.7844, 3.9364, 3.6719],\n",
      "        [3.5341, 3.7425, 3.5644, 3.7531, 3.5708],\n",
      "        [3.5335, 3.5361, 3.5863, 3.6922, 3.4610],\n",
      "        [3.4746, 3.6565, 3.4737, 3.6944, 3.5018],\n",
      "        [3.8476, 3.7065, 3.8004, 4.3256, 4.0230],\n",
      "        [3.5804, 3.4971, 3.7581, 3.7580, 3.5813],\n",
      "        [3.4639, 3.6477, 3.4653, 3.6932, 3.4925],\n",
      "        [3.6231, 3.8171, 3.6599, 3.8214, 3.6413],\n",
      "        [3.3276, 3.5732, 3.5488, 3.5562, 3.4095],\n",
      "        [3.3415, 3.6457, 3.5942, 3.5773, 3.4528],\n",
      "        [3.7430, 3.5260, 3.6587, 4.0673, 3.8794],\n",
      "        [3.3284, 3.6403, 3.6817, 3.5838, 3.5100],\n",
      "        [3.2762, 3.4916, 3.4347, 3.4511, 3.3708],\n",
      "        [3.3307, 3.6525, 3.4215, 3.6283, 3.3675],\n",
      "        [3.5409, 3.5620, 3.6183, 3.6719, 3.5774],\n",
      "        [3.7514, 3.7850, 3.7819, 4.0593, 3.6410],\n",
      "        [3.6121, 3.8056, 3.6339, 3.7507, 3.6208],\n",
      "        [3.5682, 3.8237, 3.6665, 3.8871, 3.6329],\n",
      "        [3.5975, 3.7296, 3.5759, 3.8062, 3.6378],\n",
      "        [4.1482, 4.3574, 3.9594, 4.1028, 3.8316],\n",
      "        [3.3472, 3.5027, 3.5220, 3.5706, 3.4053],\n",
      "        [3.3278, 3.6317, 3.5804, 3.5653, 3.4414],\n",
      "        [3.3602, 3.5650, 3.4564, 3.5605, 3.4272],\n",
      "        [4.1384, 4.3503, 3.9542, 4.0897, 3.8321],\n",
      "        [3.7901, 3.8825, 3.7449, 3.9263, 3.8495],\n",
      "        [3.3651, 3.4479, 3.4819, 3.5824, 3.3711],\n",
      "        [3.4766, 3.6448, 3.6109, 3.6303, 3.4362],\n",
      "        [3.7610, 3.7985, 3.7997, 4.0696, 3.6489],\n",
      "        [3.4164, 3.4184, 3.4478, 3.5844, 3.3547]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4131, 3.6036, 3.4603, 3.6101, 3.4574],\n",
      "        [3.3769, 3.5754, 3.4566, 3.5671, 3.4395],\n",
      "        [3.5009, 3.5801, 3.6651, 3.7122, 3.5687],\n",
      "        [3.4581, 3.5412, 3.5825, 3.6418, 3.4905],\n",
      "        [3.3340, 3.5679, 3.5516, 3.5697, 3.4268],\n",
      "        [3.4835, 3.5207, 3.6279, 3.6798, 3.6078],\n",
      "        [3.3296, 3.4970, 3.5138, 3.5503, 3.3860],\n",
      "        [3.4709, 3.5390, 3.6068, 3.6453, 3.4903],\n",
      "        [3.9517, 4.1483, 3.7903, 3.9247, 3.6737],\n",
      "        [3.5939, 3.9157, 3.7965, 3.8511, 3.8305],\n",
      "        [3.3230, 3.5482, 3.5414, 3.5527, 3.4014],\n",
      "        [3.4608, 3.5477, 3.5796, 3.6429, 3.4942],\n",
      "        [3.4872, 3.5635, 3.6279, 3.6284, 3.5028],\n",
      "        [3.5890, 3.7635, 3.6109, 3.7927, 3.6744],\n",
      "        [3.3310, 3.5421, 3.4578, 3.5129, 3.4183],\n",
      "        [3.5416, 3.7813, 3.6490, 3.7035, 3.6194],\n",
      "        [4.0780, 4.2837, 3.8990, 4.0279, 3.7711],\n",
      "        [3.4107, 3.4399, 3.4729, 3.5883, 3.3682],\n",
      "        [3.8488, 3.8605, 3.8118, 4.0108, 3.8286],\n",
      "        [3.4136, 3.5728, 3.4997, 3.6813, 3.4738],\n",
      "        [3.5348, 3.7411, 3.5645, 3.7510, 3.5724],\n",
      "        [3.3685, 3.7604, 3.5978, 3.4966, 3.5929],\n",
      "        [3.4902, 3.5777, 3.6827, 3.6928, 3.5656],\n",
      "        [3.5062, 3.5653, 3.6725, 3.7189, 3.5927],\n",
      "        [3.5417, 3.6329, 3.6125, 3.7668, 3.5510],\n",
      "        [3.5134, 3.5665, 3.6683, 3.7500, 3.5465],\n",
      "        [3.5156, 3.7420, 3.5445, 3.6554, 3.5594],\n",
      "        [3.5600, 3.6806, 3.5720, 3.7759, 3.5856],\n",
      "        [3.3284, 3.6045, 3.5651, 3.5587, 3.4264],\n",
      "        [3.6301, 3.8419, 3.7838, 3.7942, 3.5409],\n",
      "        [3.4575, 3.6808, 3.5203, 3.7774, 3.4456],\n",
      "        [3.3799, 3.5364, 3.4668, 3.5994, 3.4076],\n",
      "        [3.5494, 3.8660, 3.6997, 3.8030, 3.7338],\n",
      "        [3.4743, 3.6095, 3.6058, 3.6672, 3.6646],\n",
      "        [3.3323, 3.5547, 3.4679, 3.5700, 3.3984],\n",
      "        [3.4440, 3.6057, 3.4978, 3.6406, 3.5013],\n",
      "        [3.5233, 3.7811, 3.6219, 3.7877, 3.5331],\n",
      "        [3.4638, 3.9175, 3.7557, 3.7288, 3.5490],\n",
      "        [3.4367, 3.6673, 3.5193, 3.7522, 3.4485],\n",
      "        [3.2488, 3.4807, 3.4816, 3.5000, 3.3880],\n",
      "        [3.8482, 3.8770, 3.7832, 3.9982, 3.8154],\n",
      "        [3.4176, 3.5709, 3.4986, 3.5685, 3.4348],\n",
      "        [3.6464, 3.8487, 3.6356, 3.7837, 3.6964],\n",
      "        [3.7693, 3.8724, 3.7297, 3.9083, 3.8286],\n",
      "        [3.4158, 3.5630, 3.4953, 3.6898, 3.4707],\n",
      "        [3.6386, 3.7654, 3.7553, 3.8526, 3.5580],\n",
      "        [3.4676, 3.5359, 3.6005, 3.6468, 3.4844],\n",
      "        [3.8686, 3.7987, 3.8745, 4.0964, 3.8039],\n",
      "        [3.6373, 3.7965, 3.7372, 3.7252, 3.6486],\n",
      "        [3.3734, 3.5718, 3.6183, 3.6310, 3.4085],\n",
      "        [3.4573, 3.6388, 3.4627, 3.6779, 3.4824],\n",
      "        [3.3677, 3.4580, 3.4933, 3.5764, 3.3802],\n",
      "        [3.4975, 3.6821, 3.4802, 3.7288, 3.5206],\n",
      "        [3.4686, 3.5468, 3.5862, 3.6488, 3.5003],\n",
      "        [3.5772, 3.6643, 3.4935, 3.7822, 3.6590],\n",
      "        [3.5817, 3.6050, 3.7668, 3.8202, 3.5806],\n",
      "        [3.3613, 3.5845, 3.4965, 3.6438, 3.4247],\n",
      "        [3.4659, 3.6297, 3.5674, 3.8357, 3.4852],\n",
      "        [3.5621, 3.6661, 3.7174, 3.7727, 3.5785],\n",
      "        [3.6789, 3.8989, 3.6263, 3.7673, 3.6458],\n",
      "        [3.4521, 3.5482, 3.6072, 3.6754, 3.5655],\n",
      "        [3.6694, 3.9291, 3.7403, 3.9527, 3.7486],\n",
      "        [3.4724, 3.6506, 3.4669, 3.6859, 3.4898],\n",
      "        [3.3600, 3.4665, 3.4975, 3.5691, 3.3834]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3495, 3.4998, 3.5219, 3.5674, 3.4092],\n",
      "        [3.5547, 3.6865, 3.5538, 3.7423, 3.5635],\n",
      "        [3.3600, 3.4721, 3.5040, 3.5767, 3.3921],\n",
      "        [3.3200, 3.5381, 3.4689, 3.5026, 3.4183],\n",
      "        [3.5200, 3.5959, 3.6759, 3.6979, 3.5764],\n",
      "        [3.7640, 3.7143, 3.8124, 3.9904, 3.7085],\n",
      "        [3.5343, 3.5430, 3.6075, 3.6890, 3.4875],\n",
      "        [3.4740, 3.5888, 3.6042, 3.6818, 3.5298],\n",
      "        [3.4779, 3.7144, 3.6402, 3.6995, 3.5049],\n",
      "        [3.6322, 3.6499, 3.6353, 3.6532, 3.4635],\n",
      "        [3.6223, 3.8358, 3.6438, 3.9292, 3.6863],\n",
      "        [3.3366, 3.4996, 3.5199, 3.5535, 3.3932],\n",
      "        [3.4290, 3.6032, 3.7067, 3.6746, 3.5969],\n",
      "        [3.4961, 3.5707, 3.6206, 3.6681, 3.5693],\n",
      "        [3.6448, 3.7318, 3.7064, 3.8449, 3.7975],\n",
      "        [3.5328, 3.6112, 3.7009, 3.7274, 3.5839],\n",
      "        [3.4277, 3.4722, 3.5670, 3.5990, 3.4404],\n",
      "        [3.6764, 3.8255, 3.7754, 3.8514, 3.8313],\n",
      "        [3.4182, 3.5927, 3.4531, 3.6096, 3.4472],\n",
      "        [3.4787, 3.6014, 3.6159, 3.6862, 3.5406],\n",
      "        [3.5288, 3.8270, 3.6151, 3.8535, 3.6261],\n",
      "        [3.4876, 3.5293, 3.6350, 3.6917, 3.6122],\n",
      "        [3.3989, 3.5805, 3.5033, 3.6014, 3.4678],\n",
      "        [3.6034, 3.7900, 3.6331, 3.7564, 3.6203],\n",
      "        [3.2785, 3.4889, 3.4349, 3.4480, 3.3746],\n",
      "        [3.3545, 3.5394, 3.5396, 3.5649, 3.4300],\n",
      "        [3.4900, 3.6521, 3.5776, 3.7883, 3.5440],\n",
      "        [3.4412, 3.6808, 3.6138, 3.6638, 3.5560],\n",
      "        [3.9912, 4.1799, 3.8885, 3.9816, 3.7952],\n",
      "        [3.5165, 3.8912, 3.7809, 3.8292, 3.7615],\n",
      "        [3.6223, 3.8358, 3.6438, 3.9292, 3.6863],\n",
      "        [3.9548, 4.2142, 3.7564, 3.9225, 3.7197],\n",
      "        [3.7361, 3.7921, 3.7899, 3.9966, 3.9156],\n",
      "        [3.3003, 3.4220, 3.4791, 3.5025, 3.3162],\n",
      "        [3.6931, 3.9384, 3.7253, 3.6980, 3.6557],\n",
      "        [3.4072, 3.6655, 3.4746, 3.6769, 3.4105],\n",
      "        [3.4061, 3.5925, 3.4594, 3.6052, 3.4525],\n",
      "        [3.6353, 3.6543, 3.7134, 3.8172, 3.5858],\n",
      "        [3.7142, 3.8082, 3.8450, 3.9998, 3.6458],\n",
      "        [3.4797, 3.7347, 3.6136, 3.6358, 3.5918],\n",
      "        [3.3681, 3.4309, 3.4749, 3.5832, 3.3637],\n",
      "        [3.3503, 3.5744, 3.4695, 3.5452, 3.4382],\n",
      "        [3.3463, 3.4929, 3.5139, 3.5558, 3.3948],\n",
      "        [3.3653, 3.5564, 3.4564, 3.5509, 3.4245],\n",
      "        [3.4185, 3.5986, 3.4583, 3.6078, 3.4673],\n",
      "        [3.4650, 3.7477, 3.6201, 3.8414, 3.5268],\n",
      "        [3.2524, 3.4662, 3.4214, 3.4221, 3.3436],\n",
      "        [3.7155, 3.9400, 3.8595, 3.8741, 3.5600],\n",
      "        [3.6353, 3.7178, 3.6618, 3.8536, 3.7393],\n",
      "        [3.5371, 3.6153, 3.7022, 3.7654, 3.5368],\n",
      "        [3.8110, 3.8950, 3.7973, 4.0685, 3.8146],\n",
      "        [3.4176, 3.4317, 3.4594, 3.5869, 3.3626],\n",
      "        [3.4994, 3.6032, 3.7121, 3.7222, 3.5805],\n",
      "        [3.4743, 3.5820, 3.6960, 3.5894, 3.6631],\n",
      "        [3.5459, 3.6259, 3.7182, 3.7446, 3.5964],\n",
      "        [3.5062, 3.7898, 3.6358, 3.8424, 3.5279],\n",
      "        [3.3356, 3.5664, 3.5514, 3.5685, 3.4290],\n",
      "        [3.4720, 3.8438, 3.7281, 3.7780, 3.7249],\n",
      "        [3.6017, 3.8441, 3.7621, 3.8433, 3.7192],\n",
      "        [3.4678, 3.5842, 3.6006, 3.6756, 3.5158],\n",
      "        [3.7388, 3.7783, 3.7881, 3.9448, 3.7108],\n",
      "        [3.4627, 3.6046, 3.5929, 3.6663, 3.6426],\n",
      "        [3.5444, 3.9164, 3.6773, 3.8693, 3.7037],\n",
      "        [3.6409, 3.7099, 3.7394, 3.8518, 3.4856]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3933, 3.7526, 3.6016, 3.4867, 3.5809],\n",
      "        [3.5052, 3.6771, 3.6154, 3.6976, 3.5890],\n",
      "        [4.0835, 4.2815, 3.8986, 4.0250, 3.7766],\n",
      "        [3.8668, 3.7423, 3.8468, 4.3434, 4.0731],\n",
      "        [3.7287, 3.7826, 3.7266, 3.8551, 3.7333],\n",
      "        [3.3325, 3.5694, 3.5485, 3.5514, 3.4162],\n",
      "        [3.6579, 3.7416, 3.7145, 3.8503, 3.8092],\n",
      "        [3.4018, 3.7847, 3.6670, 3.7050, 3.6529],\n",
      "        [3.6888, 3.7587, 3.7440, 3.8433, 3.8267],\n",
      "        [3.5248, 3.5228, 3.5709, 3.6327, 3.5505],\n",
      "        [3.4096, 3.6647, 3.4743, 3.6754, 3.4136],\n",
      "        [3.3813, 3.4404, 3.4813, 3.5979, 3.3956],\n",
      "        [3.6689, 4.0011, 3.7659, 3.8326, 3.9542],\n",
      "        [3.3417, 3.5531, 3.5520, 3.5678, 3.4294],\n",
      "        [3.3846, 3.5815, 3.4652, 3.5728, 3.4527],\n",
      "        [3.8475, 3.8219, 3.8925, 4.1068, 3.8168],\n",
      "        [3.4839, 3.4884, 3.5659, 3.5657, 3.4271],\n",
      "        [4.0681, 4.3358, 3.8799, 4.0587, 3.7859],\n",
      "        [3.5146, 3.7378, 3.5520, 3.6454, 3.5707],\n",
      "        [3.7233, 3.7657, 3.8169, 3.9013, 3.5666],\n",
      "        [3.7820, 3.6613, 3.6788, 4.1435, 3.8346],\n",
      "        [3.7021, 3.8058, 3.8276, 3.9817, 3.6417],\n",
      "        [3.9055, 3.7659, 3.9014, 4.3730, 4.1292],\n",
      "        [3.6212, 3.7056, 3.5322, 3.8175, 3.7031],\n",
      "        [3.4897, 3.5374, 3.6214, 3.6075, 3.5570],\n",
      "        [3.5273, 3.7787, 3.6213, 3.7847, 3.5382],\n",
      "        [3.4884, 3.5621, 3.5907, 3.6448, 3.5721],\n",
      "        [3.5201, 3.7316, 3.5166, 3.6579, 3.5563],\n",
      "        [3.3998, 3.8181, 3.7081, 3.7199, 3.6902],\n",
      "        [3.7442, 3.7891, 3.7866, 3.9705, 3.7188],\n",
      "        [3.3364, 3.5523, 3.4674, 3.5672, 3.4034],\n",
      "        [3.3402, 3.5005, 3.5176, 3.5518, 3.3963],\n",
      "        [3.1870, 3.4161, 3.4593, 3.4399, 3.3764],\n",
      "        [3.9158, 4.0638, 3.6631, 3.8753, 3.6249],\n",
      "        [3.4117, 3.5581, 3.5683, 3.6859, 3.4870],\n",
      "        [3.5478, 3.7876, 3.6666, 3.7339, 3.4729],\n",
      "        [3.6393, 3.8016, 3.7591, 3.8482, 3.6275],\n",
      "        [3.4303, 3.4713, 3.5667, 3.5976, 3.4430],\n",
      "        [3.4589, 3.6681, 3.7550, 3.6363, 3.5440],\n",
      "        [3.4782, 3.5332, 3.6234, 3.6563, 3.5061],\n",
      "        [3.5579, 3.7838, 3.6166, 3.7950, 3.5793],\n",
      "        [3.4871, 3.6608, 3.4677, 3.7030, 3.5089],\n",
      "        [3.3080, 3.5159, 3.4458, 3.4902, 3.4000],\n",
      "        [3.2977, 3.5844, 3.3561, 3.5833, 3.3194],\n",
      "        [3.9615, 3.7456, 3.8580, 4.3503, 4.1230],\n",
      "        [3.2882, 3.4982, 3.4371, 3.4565, 3.3777],\n",
      "        [3.6755, 3.7946, 3.7988, 3.9628, 3.6275],\n",
      "        [3.4654, 3.7022, 3.6250, 3.6864, 3.5365],\n",
      "        [4.0399, 4.2248, 3.9117, 4.0267, 3.8186],\n",
      "        [3.4522, 3.8295, 3.7030, 3.7482, 3.7117],\n",
      "        [3.4797, 3.5052, 3.4844, 3.7245, 3.4104],\n",
      "        [3.4085, 3.5370, 3.5700, 3.6362, 3.4192],\n",
      "        [3.5249, 3.7187, 3.6729, 3.7964, 3.6510],\n",
      "        [3.4688, 3.8288, 3.6846, 3.7824, 3.7067],\n",
      "        [3.6149, 3.7708, 3.6307, 3.8173, 3.6346],\n",
      "        [3.4800, 3.5660, 3.6277, 3.6783, 3.5414],\n",
      "        [3.4873, 3.7051, 3.6535, 3.7005, 3.4846],\n",
      "        [3.3804, 3.4722, 3.3987, 3.6195, 3.3793],\n",
      "        [3.3641, 3.6093, 3.5278, 3.7081, 3.3911],\n",
      "        [3.3323, 3.4176, 3.4706, 3.5489, 3.3870],\n",
      "        [3.6637, 3.7704, 3.7406, 3.8817, 3.7716],\n",
      "        [3.4806, 3.6357, 3.6268, 3.6596, 3.4317],\n",
      "        [3.6635, 3.9715, 3.7737, 3.9937, 3.8209],\n",
      "        [3.7455, 3.9358, 3.6313, 3.7796, 3.6433]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4696, 3.7458, 3.6202, 3.8390, 3.5330],\n",
      "        [3.4520, 3.6154, 3.4539, 3.6472, 3.4698],\n",
      "        [3.3254, 3.5318, 3.4546, 3.5062, 3.4137],\n",
      "        [3.6538, 3.6690, 3.6394, 3.9809, 3.7249],\n",
      "        [3.3862, 3.4825, 3.3967, 3.6205, 3.3481],\n",
      "        [3.4782, 3.5378, 3.6208, 3.6437, 3.5017],\n",
      "        [3.3532, 3.5122, 3.5267, 3.5614, 3.4206],\n",
      "        [3.6089, 3.8565, 3.7633, 3.8421, 3.7433],\n",
      "        [3.6602, 3.7978, 3.7378, 3.8174, 3.8300],\n",
      "        [3.9002, 3.7083, 3.7969, 4.2656, 4.0601],\n",
      "        [3.5222, 3.7306, 3.5172, 3.6570, 3.5597],\n",
      "        [3.3835, 3.5182, 3.4409, 3.6305, 3.4189],\n",
      "        [3.4816, 3.6515, 3.4740, 3.6889, 3.5118],\n",
      "        [3.7576, 3.6857, 3.7819, 3.9609, 3.6858],\n",
      "        [4.0086, 4.2356, 3.8144, 3.9735, 3.7534],\n",
      "        [3.4941, 3.4779, 3.5570, 3.5500, 3.4181],\n",
      "        [3.3369, 3.5145, 3.5234, 3.5468, 3.4041],\n",
      "        [3.6326, 3.6691, 3.7095, 3.8718, 3.5449],\n",
      "        [3.5919, 3.6960, 3.7173, 3.7552, 3.6118],\n",
      "        [3.4510, 3.5567, 3.7009, 3.5309, 3.6600],\n",
      "        [3.4785, 3.5309, 3.5119, 3.7176, 3.4393],\n",
      "        [3.3880, 3.4498, 3.4891, 3.5885, 3.3913],\n",
      "        [3.5686, 3.6626, 3.7175, 3.7691, 3.5872],\n",
      "        [3.5103, 3.8942, 3.7354, 3.7325, 3.5305],\n",
      "        [3.3738, 3.7127, 3.4896, 3.4242, 3.5242],\n",
      "        [3.5113, 3.7965, 3.6473, 3.6991, 3.4499],\n",
      "        [3.4964, 3.5611, 3.6168, 3.6622, 3.5685],\n",
      "        [3.4352, 3.4561, 3.5648, 3.6305, 3.5294],\n",
      "        [3.8627, 4.0275, 3.6721, 3.8514, 3.6571],\n",
      "        [3.3573, 3.5906, 3.5642, 3.5725, 3.4592],\n",
      "        [3.6246, 3.6928, 3.6937, 3.7214, 3.4569],\n",
      "        [3.5314, 3.6080, 3.6944, 3.7212, 3.5935],\n",
      "        [3.4670, 3.5441, 3.5796, 3.6393, 3.5026],\n",
      "        [3.2365, 3.4619, 3.4804, 3.4753, 3.3873],\n",
      "        [3.4918, 3.5363, 3.6220, 3.6067, 3.5604],\n",
      "        [3.7377, 3.8316, 3.7975, 3.8991, 3.9365],\n",
      "        [3.6681, 3.6030, 3.6384, 3.7321, 3.6060],\n",
      "        [3.8238, 3.9903, 3.6550, 3.8155, 3.6494],\n",
      "        [3.4643, 3.8411, 3.7195, 3.7662, 3.7243],\n",
      "        [3.6000, 3.7580, 3.6220, 3.7942, 3.6851],\n",
      "        [3.4550, 3.4753, 3.5326, 3.6088, 3.5896],\n",
      "        [3.4194, 3.8370, 3.6486, 3.7350, 3.6853],\n",
      "        [3.6065, 3.8422, 3.7624, 3.8409, 3.7258],\n",
      "        [3.4480, 3.6246, 3.4720, 3.6429, 3.4876],\n",
      "        [3.4210, 3.6318, 3.5797, 3.7389, 3.4525],\n",
      "        [3.6211, 3.8269, 3.6376, 3.9178, 3.6832],\n",
      "        [3.3789, 3.5902, 3.4872, 3.6387, 3.4373],\n",
      "        [3.5090, 3.5705, 3.6498, 3.6770, 3.5701],\n",
      "        [3.5408, 3.5310, 3.5867, 3.6867, 3.4707],\n",
      "        [4.0708, 4.3349, 3.8805, 4.0579, 3.7896],\n",
      "        [3.5497, 3.8336, 3.6746, 3.7869, 3.7352],\n",
      "        [3.3773, 3.5801, 3.6364, 3.6214, 3.4254],\n",
      "        [3.4238, 3.5380, 3.5631, 3.6487, 3.4324],\n",
      "        [3.6168, 3.8891, 3.6718, 3.6293, 3.6503],\n",
      "        [3.4681, 3.5696, 3.5079, 3.6905, 3.4741],\n",
      "        [3.3969, 3.5237, 3.5626, 3.6305, 3.4082],\n",
      "        [3.7549, 3.7242, 3.6793, 3.8349, 3.7491],\n",
      "        [3.3423, 3.4994, 3.5182, 3.5510, 3.3998],\n",
      "        [3.4551, 3.6900, 3.6262, 3.6780, 3.5488],\n",
      "        [3.6345, 3.7314, 3.5574, 3.8317, 3.7002],\n",
      "        [3.5155, 3.5671, 3.6536, 3.6635, 3.5329],\n",
      "        [3.6205, 3.7937, 3.7296, 3.9091, 3.6220],\n",
      "        [3.3173, 3.4360, 3.4500, 3.4945, 3.3727],\n",
      "        [3.7443, 3.8362, 3.7667, 3.9853, 3.6961]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4912, 3.5217, 3.4973, 3.7224, 3.4388],\n",
      "        [3.3497, 3.5096, 3.5258, 3.5662, 3.4159],\n",
      "        [3.4911, 3.6585, 3.4686, 3.7012, 3.5161],\n",
      "        [3.5016, 3.6340, 3.5386, 3.7339, 3.5419],\n",
      "        [3.5970, 3.6114, 3.6754, 3.6289, 3.5591],\n",
      "        [3.3368, 3.6257, 3.5811, 3.5585, 3.4557],\n",
      "        [3.6985, 3.7848, 3.8886, 3.7709, 3.5189],\n",
      "        [3.4947, 3.6077, 3.6181, 3.6600, 3.7015],\n",
      "        [3.6022, 3.9110, 3.7972, 3.8462, 3.8436],\n",
      "        [3.6056, 3.7771, 3.6170, 3.7610, 3.6316],\n",
      "        [3.3441, 3.4982, 3.5186, 3.5498, 3.4037],\n",
      "        [3.6365, 3.7303, 3.5579, 3.8305, 3.7041],\n",
      "        [3.6361, 3.6451, 3.6359, 3.6344, 3.4692],\n",
      "        [3.4063, 3.5413, 3.5890, 3.6661, 3.5278],\n",
      "        [3.6319, 3.8064, 3.6548, 3.8219, 3.6505],\n",
      "        [3.4058, 3.7826, 3.6686, 3.7031, 3.6609],\n",
      "        [3.7717, 3.8293, 3.8253, 3.9168, 3.9135],\n",
      "        [3.4758, 3.5311, 3.6009, 3.6423, 3.4965],\n",
      "        [3.8066, 3.6568, 3.6910, 4.1789, 3.8709],\n",
      "        [3.4916, 3.6589, 3.4709, 3.7162, 3.5215],\n",
      "        [3.6929, 3.6023, 3.6199, 3.7388, 3.6447],\n",
      "        [3.3324, 3.5635, 3.5506, 3.5509, 3.4215],\n",
      "        [3.5229, 3.6242, 3.7421, 3.7392, 3.6109],\n",
      "        [3.4608, 3.7936, 3.7291, 3.6044, 3.6481],\n",
      "        [3.5706, 3.5598, 3.8510, 3.7656, 3.6736],\n",
      "        [3.3196, 3.6471, 3.7012, 3.5498, 3.5515],\n",
      "        [3.5173, 3.7647, 3.6023, 3.7832, 3.5315],\n",
      "        [3.3661, 3.5530, 3.5889, 3.5985, 3.4384],\n",
      "        [3.5456, 3.5452, 3.6170, 3.6863, 3.5251],\n",
      "        [3.4623, 3.5374, 3.5387, 3.6892, 3.4431],\n",
      "        [3.4751, 3.5261, 3.5990, 3.6441, 3.4908],\n",
      "        [3.5432, 3.8027, 3.6528, 3.7658, 3.7153],\n",
      "        [3.5192, 3.9181, 3.6964, 3.8454, 3.7439],\n",
      "        [3.4728, 3.6165, 3.5158, 3.6851, 3.6229],\n",
      "        [3.5249, 3.5873, 3.6854, 3.7324, 3.5920],\n",
      "        [3.6300, 3.8281, 3.6362, 3.9151, 3.6828],\n",
      "        [3.4645, 3.7762, 3.7051, 3.6183, 3.6137],\n",
      "        [3.5056, 3.5541, 3.6234, 3.6789, 3.5875],\n",
      "        [3.4187, 3.5180, 3.5865, 3.6418, 3.5742],\n",
      "        [3.7862, 3.6591, 3.6798, 4.1420, 3.8419],\n",
      "        [3.6176, 3.7011, 3.6769, 3.7208, 3.4136],\n",
      "        [3.3697, 3.4579, 3.4967, 3.5657, 3.3971],\n",
      "        [3.5064, 3.5563, 3.6709, 3.6818, 3.5743],\n",
      "        [3.6290, 3.8324, 3.6444, 3.9256, 3.6968],\n",
      "        [3.3909, 3.5281, 3.5726, 3.6239, 3.4078],\n",
      "        [3.4629, 3.6659, 3.7561, 3.6345, 3.5515],\n",
      "        [3.6156, 3.6602, 3.6826, 3.7052, 3.4729],\n",
      "        [3.8648, 4.0265, 3.6725, 3.8503, 3.6611],\n",
      "        [3.8038, 3.8721, 3.7549, 3.9462, 3.8662],\n",
      "        [3.4485, 3.6170, 3.4680, 3.6469, 3.4927],\n",
      "        [3.4984, 3.6680, 3.4857, 3.7148, 3.5283],\n",
      "        [3.5190, 3.5755, 3.6123, 3.6703, 3.5664],\n",
      "        [3.4602, 3.5001, 3.5927, 3.6243, 3.4753],\n",
      "        [3.4528, 3.5491, 3.6001, 3.6703, 3.5933],\n",
      "        [3.4867, 3.5084, 3.6180, 3.6678, 3.6152],\n",
      "        [3.4838, 3.5062, 3.6046, 3.6650, 3.6133],\n",
      "        [3.3398, 3.6103, 3.5744, 3.5597, 3.4474],\n",
      "        [3.6268, 3.8300, 3.6433, 3.9243, 3.6933],\n",
      "        [3.7165, 3.9036, 3.6244, 3.7620, 3.6477],\n",
      "        [3.7079, 3.6196, 3.6490, 4.0457, 3.7667],\n",
      "        [3.7398, 3.8499, 3.8157, 3.8880, 3.9305],\n",
      "        [3.6132, 3.7725, 3.7589, 3.7780, 3.6368],\n",
      "        [3.6490, 3.6580, 3.7275, 3.8193, 3.6094],\n",
      "        [3.3042, 3.5060, 3.4419, 3.4743, 3.3958]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4822, 3.7511, 3.6545, 3.6179, 3.6245],\n",
      "        [3.5513, 3.8303, 3.5693, 3.7343, 3.5830],\n",
      "        [3.6582, 3.9110, 3.8479, 3.8707, 3.5819],\n",
      "        [3.9100, 3.7582, 3.8979, 4.3685, 4.1303],\n",
      "        [3.5034, 3.7302, 3.5806, 3.6877, 3.6046],\n",
      "        [3.6404, 3.6455, 3.6362, 3.6491, 3.4775],\n",
      "        [3.6420, 3.7924, 3.7522, 3.9247, 3.6308],\n",
      "        [3.5136, 3.4718, 3.5664, 3.8053, 3.4396],\n",
      "        [3.5110, 3.5669, 3.6420, 3.6722, 3.5776],\n",
      "        [3.8193, 3.9040, 3.8059, 4.0880, 3.8463],\n",
      "        [3.6638, 3.7953, 3.7383, 3.8148, 3.8375],\n",
      "        [3.6123, 3.8541, 3.7640, 3.8396, 3.7509],\n",
      "        [3.8666, 4.0253, 3.6727, 3.8490, 3.6646],\n",
      "        [3.5148, 3.7429, 3.5977, 3.6906, 3.6176],\n",
      "        [3.5865, 3.7789, 3.6903, 3.7439, 3.5012],\n",
      "        [3.5865, 3.6136, 3.6679, 3.6417, 3.4981],\n",
      "        [3.5738, 3.8963, 3.7322, 3.8166, 3.7672],\n",
      "        [3.5656, 3.6538, 3.6237, 3.7973, 3.5792],\n",
      "        [3.6102, 3.8140, 3.6825, 3.8460, 3.7963],\n",
      "        [3.4976, 3.7263, 3.5846, 3.6789, 3.6113],\n",
      "        [3.2602, 3.4620, 3.4222, 3.4175, 3.3572],\n",
      "        [3.4710, 3.6323, 3.4642, 3.6766, 3.5074],\n",
      "        [3.7922, 3.7360, 3.7133, 3.8830, 3.7695],\n",
      "        [4.0968, 4.3151, 3.8845, 4.0382, 3.8331],\n",
      "        [3.4094, 3.5380, 3.5644, 3.6559, 3.4899],\n",
      "        [3.4923, 3.9009, 3.7661, 3.7484, 3.5793],\n",
      "        [3.5996, 3.9060, 3.7043, 3.8043, 3.6884],\n",
      "        [3.5824, 3.6734, 3.6825, 3.7166, 3.6921],\n",
      "        [3.3732, 3.6369, 3.6817, 3.6003, 3.5553],\n",
      "        [3.7764, 3.8444, 3.7337, 3.9178, 3.8425],\n",
      "        [3.4992, 3.5591, 3.6542, 3.6923, 3.5574],\n",
      "        [3.4919, 3.5930, 3.4947, 3.6438, 3.6055],\n",
      "        [3.6264, 3.7074, 3.6882, 3.8007, 3.7634],\n",
      "        [3.4093, 3.8297, 3.6560, 3.7120, 3.7101],\n",
      "        [3.6207, 3.6555, 3.6844, 3.6892, 3.5010],\n",
      "        [3.4788, 3.7100, 3.6503, 3.6980, 3.5071],\n",
      "        [3.4781, 3.5407, 3.5866, 3.6428, 3.5158],\n",
      "        [3.5258, 3.5923, 3.6078, 3.6946, 3.5632],\n",
      "        [3.7726, 3.8324, 3.8035, 3.9950, 3.7057],\n",
      "        [3.9398, 4.0674, 3.6871, 3.8896, 3.6383],\n",
      "        [3.5108, 3.6735, 3.6165, 3.6944, 3.6000],\n",
      "        [3.3357, 3.5680, 3.5517, 3.5519, 3.4277],\n",
      "        [3.4861, 3.7424, 3.6352, 3.6255, 3.6166],\n",
      "        [3.6058, 3.6256, 3.6724, 3.7508, 3.5618],\n",
      "        [3.6345, 3.7294, 3.7619, 3.7520, 3.4833],\n",
      "        [3.4667, 3.6249, 3.4701, 3.6435, 3.5119],\n",
      "        [3.7170, 3.8605, 3.6924, 3.8492, 3.8045],\n",
      "        [3.6569, 3.8733, 3.6714, 3.6548, 3.5761],\n",
      "        [3.4128, 3.4263, 3.5377, 3.5931, 3.5159],\n",
      "        [3.7276, 3.9186, 3.6934, 3.7210, 3.6093],\n",
      "        [3.5589, 3.6200, 3.7202, 3.7410, 3.6122],\n",
      "        [3.4609, 3.6803, 3.5487, 3.6895, 3.5856],\n",
      "        [3.6045, 3.8017, 3.6143, 3.8843, 3.6541],\n",
      "        [3.6667, 3.7917, 3.7816, 3.9466, 3.6351],\n",
      "        [3.6719, 3.6031, 3.6214, 4.0312, 3.7294],\n",
      "        [3.5637, 3.6892, 3.5752, 3.7550, 3.6058],\n",
      "        [4.0468, 4.2215, 3.9131, 4.0233, 3.8301],\n",
      "        [3.7042, 3.6217, 3.6331, 3.7619, 3.6645],\n",
      "        [3.5220, 3.6646, 3.5943, 3.7791, 3.6041],\n",
      "        [3.6306, 3.8310, 3.6446, 3.9242, 3.7003],\n",
      "        [3.4631, 3.8451, 3.6660, 3.7691, 3.7190],\n",
      "        [3.4474, 3.4610, 3.5169, 3.5871, 3.5893],\n",
      "        [3.7154, 3.8696, 3.8717, 4.0424, 4.0155],\n",
      "        [3.3857, 3.4687, 3.3997, 3.6164, 3.3901]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4232, 3.4198, 3.4581, 3.5750, 3.3722],\n",
      "        [3.4755, 3.6146, 3.5160, 3.6822, 3.6291],\n",
      "        [3.6260, 3.5276, 3.5186, 3.6334, 3.6189],\n",
      "        [3.8033, 3.8752, 3.7458, 3.9166, 3.8701],\n",
      "        [3.3779, 3.4514, 3.4938, 3.5692, 3.3990],\n",
      "        [3.4670, 3.6393, 3.6245, 3.7027, 3.4940],\n",
      "        [3.5217, 3.6676, 3.6164, 3.7099, 3.6699],\n",
      "        [3.5440, 3.8769, 3.8076, 3.8405, 3.7591],\n",
      "        [3.3873, 3.5245, 3.4387, 3.6203, 3.4322],\n",
      "        [3.4624, 3.8587, 3.6529, 3.7855, 3.7003],\n",
      "        [3.5543, 3.8305, 3.6753, 3.7830, 3.7458],\n",
      "        [3.4207, 3.4585, 3.5146, 3.5934, 3.4044],\n",
      "        [3.3923, 3.4466, 3.4896, 3.5847, 3.4015],\n",
      "        [3.6626, 3.7347, 3.7109, 3.7915, 3.7709],\n",
      "        [3.4689, 3.5500, 3.5799, 3.6413, 3.5146],\n",
      "        [3.4730, 3.5452, 3.5805, 3.6395, 3.5146],\n",
      "        [3.7778, 3.8438, 3.7338, 3.9163, 3.8455],\n",
      "        [3.3592, 3.4867, 3.5161, 3.5522, 3.4131],\n",
      "        [3.6800, 3.8479, 3.6543, 3.7910, 3.7446],\n",
      "        [3.4587, 3.6381, 3.4733, 3.6558, 3.5080],\n",
      "        [3.5590, 3.7546, 3.7171, 3.8342, 3.6736],\n",
      "        [3.5903, 3.5968, 3.6606, 3.6328, 3.5417],\n",
      "        [3.7428, 3.8286, 3.7980, 3.8952, 3.9473],\n",
      "        [3.4823, 3.6444, 3.4613, 3.6833, 3.5144],\n",
      "        [3.4943, 3.6569, 3.4710, 3.7135, 3.5278],\n",
      "        [3.4317, 3.5281, 3.5498, 3.6566, 3.4394],\n",
      "        [3.7028, 3.6730, 3.6646, 3.8141, 3.7164],\n",
      "        [3.4773, 3.5285, 3.6027, 3.6329, 3.5016],\n",
      "        [3.3693, 3.4441, 3.4854, 3.5664, 3.3917],\n",
      "        [3.4226, 3.6008, 3.5619, 3.5145, 3.4761],\n",
      "        [3.5139, 3.6490, 3.6132, 3.6517, 3.5658],\n",
      "        [3.6809, 3.8787, 3.6127, 3.7377, 3.6504],\n",
      "        [3.4656, 3.5579, 3.5850, 3.6501, 3.5175],\n",
      "        [3.5974, 3.6248, 3.6527, 3.7271, 3.5550],\n",
      "        [3.3483, 3.5490, 3.5531, 3.5631, 3.4432],\n",
      "        [3.7595, 3.7209, 3.6802, 3.8318, 3.7608],\n",
      "        [3.4648, 3.5168, 3.5960, 3.6343, 3.4968],\n",
      "        [3.9374, 4.1381, 3.7440, 3.8778, 3.6825],\n",
      "        [3.4104, 3.5887, 3.4636, 3.5875, 3.4710],\n",
      "        [3.6716, 3.6637, 3.6885, 3.9306, 3.5461],\n",
      "        [3.3633, 3.5674, 3.5908, 3.5852, 3.4550],\n",
      "        [3.6640, 3.8181, 3.6657, 3.8633, 3.7447],\n",
      "        [3.3720, 3.5744, 3.5949, 3.6004, 3.4527],\n",
      "        [3.6359, 3.7876, 3.6423, 3.8192, 3.6540],\n",
      "        [3.3692, 3.5524, 3.5784, 3.5980, 3.4350],\n",
      "        [3.4495, 3.4793, 3.5806, 3.6074, 3.4733],\n",
      "        [3.2410, 3.4588, 3.4809, 3.4713, 3.3976],\n",
      "        [3.4830, 3.5835, 3.6047, 3.6755, 3.5463],\n",
      "        [3.3224, 3.6450, 3.7013, 3.5468, 3.5581],\n",
      "        [3.5339, 3.7442, 3.5730, 3.7609, 3.5729],\n",
      "        [3.4970, 3.7994, 3.5861, 3.5251, 3.6148],\n",
      "        [3.7610, 3.8114, 3.8226, 3.9338, 3.7316],\n",
      "        [3.5930, 3.5980, 3.7675, 3.8127, 3.5997],\n",
      "        [3.5023, 3.5811, 3.6936, 3.6951, 3.5906],\n",
      "        [3.7098, 3.7788, 3.7823, 3.7643, 3.4890],\n",
      "        [3.8159, 3.7614, 3.8431, 4.0244, 3.7720],\n",
      "        [3.4915, 3.6584, 3.4733, 3.6979, 3.5240],\n",
      "        [3.4276, 3.5935, 3.4592, 3.6018, 3.4837],\n",
      "        [3.8721, 3.8910, 3.8018, 4.1248, 3.6792],\n",
      "        [3.6182, 3.6976, 3.6754, 3.7157, 3.4192],\n",
      "        [3.6990, 3.7827, 3.7335, 3.8905, 3.8345],\n",
      "        [3.6526, 3.6599, 3.6645, 3.9061, 3.5391],\n",
      "        [3.4844, 3.7043, 3.5732, 3.6991, 3.6087],\n",
      "        [3.4141, 3.4256, 3.5377, 3.5917, 3.5187]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6186, 3.7776, 3.7599, 3.7296, 3.5257],\n",
      "        [3.5008, 3.7256, 3.5845, 3.6766, 3.6178],\n",
      "        [3.5992, 3.6841, 3.6568, 3.6940, 3.3992],\n",
      "        [3.7751, 3.7103, 3.8133, 3.9839, 3.7290],\n",
      "        [3.4455, 3.8575, 3.7413, 3.7604, 3.7530],\n",
      "        [3.6616, 3.9104, 3.8477, 3.8683, 3.5883],\n",
      "        [3.4663, 3.6980, 3.6195, 3.6748, 3.5633],\n",
      "        [3.4944, 3.7078, 3.6508, 3.6969, 3.5249],\n",
      "        [3.6437, 3.7759, 3.7571, 3.8465, 3.6104],\n",
      "        [3.8313, 3.8019, 3.7781, 4.0352, 3.7814],\n",
      "        [3.5109, 3.5640, 3.6457, 3.6681, 3.5788],\n",
      "        [3.5077, 3.6966, 3.4552, 3.6245, 3.5299],\n",
      "        [3.3201, 3.3792, 3.4451, 3.5734, 3.3684],\n",
      "        [3.5198, 3.6857, 3.6245, 3.7089, 3.6173],\n",
      "        [3.4483, 3.6259, 3.4751, 3.6382, 3.4989],\n",
      "        [3.4295, 3.5934, 3.4590, 3.6009, 3.4871],\n",
      "        [3.6316, 3.8277, 3.6433, 3.9205, 3.7035],\n",
      "        [3.7625, 3.7619, 3.7870, 4.0437, 3.6558],\n",
      "        [3.3895, 3.5687, 3.4572, 3.5590, 3.4616],\n",
      "        [3.3603, 3.4946, 3.5225, 3.5604, 3.4292],\n",
      "        [3.7779, 3.6961, 3.7929, 3.9547, 3.7152],\n",
      "        [3.4235, 3.5113, 3.6094, 3.6260, 3.4965],\n",
      "        [3.3965, 3.7023, 3.6129, 3.6588, 3.6820],\n",
      "        [3.5092, 3.5527, 3.6190, 3.6326, 3.5748],\n",
      "        [3.6296, 3.4853, 3.5156, 3.6587, 3.5659],\n",
      "        [3.5289, 3.6549, 3.6270, 3.6579, 3.5823],\n",
      "        [3.6135, 3.8132, 3.6823, 3.8435, 3.8028],\n",
      "        [3.3873, 3.5841, 3.7007, 3.6186, 3.5976],\n",
      "        [3.7343, 3.7752, 3.7731, 3.9811, 3.9277],\n",
      "        [3.6252, 3.6127, 3.6543, 3.9143, 3.5820],\n",
      "        [3.4223, 3.5399, 3.3780, 3.6695, 3.3743],\n",
      "        [3.7175, 3.7701, 3.7221, 3.8234, 3.7470],\n",
      "        [3.3613, 3.5692, 3.4702, 3.5384, 3.4583],\n",
      "        [3.3748, 3.6744, 3.7559, 3.6534, 3.5926],\n",
      "        [3.6339, 3.8301, 3.6444, 3.9218, 3.7069],\n",
      "        [3.5495, 3.6076, 3.7027, 3.7382, 3.6145],\n",
      "        [3.4343, 3.5716, 3.4945, 3.5612, 3.4652],\n",
      "        [3.3890, 3.4338, 3.4803, 3.5680, 3.4040],\n",
      "        [3.4720, 3.6452, 3.6155, 3.6988, 3.5118],\n",
      "        [3.6390, 3.6537, 3.6079, 3.9280, 3.7039],\n",
      "        [3.5065, 3.6672, 3.4888, 3.7107, 3.5431],\n",
      "        [3.3033, 3.4287, 3.4394, 3.4658, 3.3735],\n",
      "        [3.6301, 3.8933, 3.6800, 3.8188, 3.6823],\n",
      "        [3.5628, 3.6443, 3.6183, 3.7862, 3.5770],\n",
      "        [3.4921, 3.7104, 3.6449, 3.6935, 3.5110],\n",
      "        [3.6182, 3.7706, 3.7589, 3.7744, 3.6465],\n",
      "        [3.6979, 3.8005, 3.7582, 3.8634, 3.8461],\n",
      "        [3.4988, 3.4741, 3.5595, 3.5375, 3.4307],\n",
      "        [3.5157, 3.5671, 3.6502, 3.6725, 3.5839],\n",
      "        [3.3982, 3.6271, 3.7791, 3.6289, 3.6726],\n",
      "        [3.8967, 4.0045, 3.9152, 4.1866, 3.9128],\n",
      "        [3.2663, 3.4523, 3.4185, 3.4139, 3.3574],\n",
      "        [3.4834, 3.5595, 3.5942, 3.6594, 3.5265],\n",
      "        [3.4615, 3.4722, 3.5335, 3.6044, 3.6040],\n",
      "        [3.6154, 3.6488, 3.5959, 3.8757, 3.6654],\n",
      "        [3.4278, 3.7810, 3.5660, 3.5837, 3.4390],\n",
      "        [3.5715, 3.6740, 3.5795, 3.7701, 3.6106],\n",
      "        [3.7190, 3.8567, 3.8346, 3.8256, 3.5907],\n",
      "        [3.3767, 3.5011, 3.5436, 3.5796, 3.4068],\n",
      "        [3.6239, 3.6547, 3.6843, 3.6871, 3.5075],\n",
      "        [3.6455, 3.8986, 3.6882, 3.6481, 3.6749],\n",
      "        [3.6130, 3.8389, 3.7630, 3.8362, 3.7401],\n",
      "        [3.6717, 3.8000, 3.7562, 3.7478, 3.6858],\n",
      "        [3.5436, 3.5410, 3.6062, 3.6782, 3.5279]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6522, 3.7903, 3.7376, 3.7156, 3.6741],\n",
      "        [3.4261, 3.6011, 3.5617, 3.5127, 3.4827],\n",
      "        [3.2894, 3.4821, 3.4374, 3.4345, 3.3900],\n",
      "        [3.8416, 3.7999, 3.8317, 3.9763, 3.8405],\n",
      "        [3.4290, 3.5941, 3.4676, 3.5889, 3.4974],\n",
      "        [3.2862, 3.5012, 3.4856, 3.5189, 3.4379],\n",
      "        [3.3461, 3.5930, 3.5644, 3.5628, 3.4584],\n",
      "        [3.8726, 3.7476, 3.8349, 4.3240, 4.0668],\n",
      "        [3.7775, 3.8322, 3.8030, 3.9919, 3.7153],\n",
      "        [3.6394, 3.7880, 3.6418, 3.8174, 3.6605],\n",
      "        [3.4277, 3.5665, 3.5001, 3.6720, 3.4994],\n",
      "        [3.4031, 3.6180, 3.6655, 3.6742, 3.6238],\n",
      "        [3.5225, 3.7815, 3.6202, 3.8335, 3.5575],\n",
      "        [3.3184, 3.3714, 3.4506, 3.5583, 3.3781],\n",
      "        [3.6017, 3.7041, 3.6011, 3.7241, 3.5775],\n",
      "        [3.6492, 3.8817, 3.6959, 3.8149, 3.6929],\n",
      "        [3.4792, 3.5167, 3.5885, 3.5863, 3.4855],\n",
      "        [3.4248, 3.5160, 3.5861, 3.6372, 3.5868],\n",
      "        [3.5021, 3.4750, 3.5570, 3.5445, 3.4342],\n",
      "        [3.6228, 3.7655, 3.6238, 3.8109, 3.6465],\n",
      "        [3.5332, 3.5908, 3.6763, 3.6901, 3.5992],\n",
      "        [3.9432, 4.1095, 3.8219, 3.9146, 3.7545],\n",
      "        [3.3475, 3.5243, 3.5348, 3.5463, 3.4257],\n",
      "        [3.5916, 3.6071, 3.6675, 3.6258, 3.5416],\n",
      "        [3.7086, 3.7582, 3.7777, 3.9293, 3.6895],\n",
      "        [3.4544, 3.5821, 3.5020, 3.5846, 3.4803],\n",
      "        [3.5562, 3.8258, 3.6314, 3.8543, 3.6549],\n",
      "        [3.6004, 3.4941, 3.7585, 3.7490, 3.6109],\n",
      "        [3.6400, 3.8579, 3.7874, 3.8623, 3.6640],\n",
      "        [3.6016, 3.6406, 3.6167, 3.8440, 3.6499],\n",
      "        [3.4881, 3.5770, 3.6080, 3.6753, 3.5599],\n",
      "        [3.7399, 3.9500, 3.8963, 3.9010, 3.6183],\n",
      "        [3.4914, 3.7869, 3.5555, 3.7937, 3.6106],\n",
      "        [3.3734, 3.8180, 3.6976, 3.6555, 3.7168],\n",
      "        [3.4565, 3.6073, 3.5752, 3.6850, 3.5987],\n",
      "        [3.8134, 3.6988, 3.8101, 3.9514, 3.7582],\n",
      "        [3.3570, 3.5342, 3.5465, 3.5635, 3.4467],\n",
      "        [3.3324, 3.5182, 3.4530, 3.4939, 3.4394],\n",
      "        [3.3511, 3.5085, 3.5270, 3.5472, 3.4224],\n",
      "        [3.6287, 3.5333, 3.5150, 3.6241, 3.6313],\n",
      "        [3.4762, 3.5485, 3.5811, 3.6407, 3.5225],\n",
      "        [3.2630, 3.4507, 3.4146, 3.4092, 3.3561],\n",
      "        [3.7587, 3.7950, 3.7997, 3.8939, 3.8956],\n",
      "        [3.6613, 3.8427, 3.6354, 3.7738, 3.7218],\n",
      "        [3.6652, 3.6583, 3.6757, 3.9192, 3.5426],\n",
      "        [3.5316, 3.7828, 3.6533, 3.7047, 3.4735],\n",
      "        [3.8560, 3.9227, 3.8326, 4.1021, 3.8664],\n",
      "        [3.4688, 3.6263, 3.4697, 3.6338, 3.5137],\n",
      "        [3.6845, 3.8792, 3.6122, 3.7358, 3.6566],\n",
      "        [3.3627, 3.6453, 3.5990, 3.5826, 3.4967],\n",
      "        [4.0808, 4.3329, 3.8810, 4.0521, 3.8073],\n",
      "        [3.5149, 3.5642, 3.6585, 3.7102, 3.5949],\n",
      "        [3.4198, 3.8209, 3.6406, 3.7240, 3.6970],\n",
      "        [3.6454, 3.8624, 3.6270, 3.7339, 3.6764],\n",
      "        [3.8682, 4.0426, 3.7762, 3.8401, 3.7185],\n",
      "        [3.4735, 3.6455, 3.6152, 3.6977, 3.5147],\n",
      "        [3.4973, 3.6566, 3.4683, 3.6965, 3.5287],\n",
      "        [3.4832, 3.5178, 3.6074, 3.6244, 3.5141],\n",
      "        [3.4710, 3.5411, 3.6085, 3.6666, 3.6030],\n",
      "        [3.6087, 3.9132, 3.7111, 3.8260, 3.7051],\n",
      "        [3.4491, 3.5291, 3.5404, 3.6687, 3.4526],\n",
      "        [3.5593, 3.7575, 3.5913, 3.7691, 3.5950],\n",
      "        [3.4182, 3.6232, 3.5155, 3.6489, 3.4399],\n",
      "        [3.5771, 3.5578, 3.8507, 3.7608, 3.6865]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.9109, 4.1436, 3.7127, 3.8679, 3.6565],\n",
      "        [3.3195, 3.3715, 3.4501, 3.5572, 3.3814],\n",
      "        [3.3502, 3.4948, 3.5197, 3.5444, 3.4196],\n",
      "        [3.8522, 3.7313, 3.8148, 4.3012, 4.0662],\n",
      "        [3.4689, 3.6032, 3.5552, 3.6135, 3.5208],\n",
      "        [3.5382, 3.5477, 3.6392, 3.6690, 3.6017],\n",
      "        [3.3795, 3.5016, 3.5429, 3.5774, 3.4131],\n",
      "        [3.4317, 3.5677, 3.5765, 3.6763, 3.5131],\n",
      "        [3.4829, 3.5292, 3.5955, 3.6326, 3.5135],\n",
      "        [3.4348, 3.4448, 3.5008, 3.6058, 3.4116],\n",
      "        [3.5168, 3.8052, 3.6535, 3.7016, 3.4705],\n",
      "        [3.4767, 3.6159, 3.5021, 3.6457, 3.5409],\n",
      "        [3.3459, 3.4519, 3.4613, 3.5132, 3.4107],\n",
      "        [3.3640, 3.6455, 3.5985, 3.5815, 3.5001],\n",
      "        [3.4114, 3.5423, 3.5542, 3.6612, 3.5014],\n",
      "        [3.5106, 3.5341, 3.6465, 3.6954, 3.6464],\n",
      "        [3.6583, 3.8475, 3.7472, 3.8437, 3.6801],\n",
      "        [3.4239, 3.7263, 3.6185, 3.6864, 3.6713],\n",
      "        [3.4727, 3.6264, 3.4558, 3.6607, 3.5011],\n",
      "        [3.3437, 3.5576, 3.5486, 3.5529, 3.4474],\n",
      "        [3.5016, 3.4747, 3.5587, 3.5355, 3.4370],\n",
      "        [3.4415, 3.5324, 3.5929, 3.6419, 3.5193],\n",
      "        [3.4995, 3.5523, 3.6087, 3.6462, 3.5393],\n",
      "        [3.5480, 3.5569, 3.6434, 3.6716, 3.6062],\n",
      "        [3.3451, 3.6326, 3.6810, 3.5705, 3.5406],\n",
      "        [3.5062, 3.5712, 3.6824, 3.6826, 3.5940],\n",
      "        [3.3473, 3.5931, 3.5640, 3.5617, 3.4618],\n",
      "        [3.4608, 3.5537, 3.7006, 3.5237, 3.6801],\n",
      "        [3.4641, 3.8258, 3.7050, 3.7404, 3.7377],\n",
      "        [3.4226, 3.5409, 3.5835, 3.6523, 3.5346],\n",
      "        [3.5020, 3.6049, 3.6198, 3.6982, 3.5757],\n",
      "        [3.6592, 3.7270, 3.7058, 3.8351, 3.8242],\n",
      "        [3.4826, 3.5244, 3.5981, 3.6385, 3.5067],\n",
      "        [3.5716, 3.6532, 3.6227, 3.7928, 3.5921],\n",
      "        [3.3623, 3.5094, 3.5264, 3.5545, 3.4407],\n",
      "        [3.3683, 3.4117, 3.4602, 3.5590, 3.3822],\n",
      "        [3.6438, 3.9944, 3.8023, 3.8855, 3.8554],\n",
      "        [3.6059, 3.9059, 3.7034, 3.7998, 3.7016],\n",
      "        [3.3613, 3.6406, 3.5905, 3.5791, 3.4987],\n",
      "        [3.4841, 3.5803, 3.5987, 3.6748, 3.5504],\n",
      "        [3.9995, 4.0242, 3.8501, 4.2658, 3.8194],\n",
      "        [3.7247, 3.9661, 3.7452, 3.9443, 3.8527],\n",
      "        [3.5395, 3.5948, 3.6732, 3.6908, 3.6148],\n",
      "        [3.3804, 3.4943, 3.4232, 3.6060, 3.3473],\n",
      "        [3.3729, 3.4881, 3.5231, 3.5764, 3.4316],\n",
      "        [3.7693, 3.7496, 3.7620, 4.0262, 3.6709],\n",
      "        [3.5212, 3.7189, 3.4775, 3.6324, 3.5545],\n",
      "        [3.5467, 3.7366, 3.6918, 3.8066, 3.6642],\n",
      "        [3.6732, 3.7915, 3.7806, 3.9423, 3.6486],\n",
      "        [3.4830, 3.5649, 3.5923, 3.6520, 3.5397],\n",
      "        [3.6351, 3.6322, 3.6917, 3.7757, 3.5868],\n",
      "        [3.5842, 3.5943, 3.6551, 3.6277, 3.5196],\n",
      "        [3.4263, 3.5118, 3.6086, 3.6239, 3.5028],\n",
      "        [3.9675, 4.2276, 3.7772, 3.9481, 3.7236],\n",
      "        [3.8737, 4.0135, 3.8986, 4.1846, 3.9394],\n",
      "        [3.4724, 3.7747, 3.7048, 3.6124, 3.6306],\n",
      "        [3.2907, 3.4823, 3.4370, 3.4334, 3.3933],\n",
      "        [3.4938, 3.7303, 3.6139, 3.6264, 3.6189],\n",
      "        [4.0978, 4.2788, 3.8992, 4.0172, 3.8019],\n",
      "        [3.4042, 3.7489, 3.6021, 3.4792, 3.6049],\n",
      "        [3.6460, 3.8503, 3.7798, 3.8550, 3.6689],\n",
      "        [3.6413, 3.8582, 3.7869, 3.8613, 3.6675],\n",
      "        [3.4014, 3.4821, 3.5130, 3.5809, 3.4543],\n",
      "        [3.2642, 3.4508, 3.4141, 3.4081, 3.3594]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3326, 3.4377, 3.4533, 3.4944, 3.3994],\n",
      "        [3.3757, 3.4819, 3.5133, 3.5585, 3.4274],\n",
      "        [3.5736, 3.8412, 3.6347, 3.5747, 3.6564],\n",
      "        [3.6288, 3.8734, 3.6452, 3.6131, 3.6230],\n",
      "        [3.6381, 3.8837, 3.7835, 3.8541, 3.8110],\n",
      "        [3.3213, 3.5121, 3.4466, 3.4815, 3.4263],\n",
      "        [3.4974, 3.8696, 3.6711, 3.8049, 3.7386],\n",
      "        [3.7887, 3.7501, 3.7189, 3.8610, 3.7861],\n",
      "        [3.4677, 3.4929, 3.5896, 3.6124, 3.4968],\n",
      "        [3.4807, 3.5699, 3.7042, 3.5582, 3.6869],\n",
      "        [3.3452, 3.4136, 3.4710, 3.5398, 3.4130],\n",
      "        [3.5762, 3.8291, 3.6537, 3.8641, 3.6675],\n",
      "        [3.4929, 3.6413, 3.4605, 3.6764, 3.5195],\n",
      "        [3.9131, 4.1438, 3.7131, 3.8666, 3.6596],\n",
      "        [3.6304, 3.8649, 3.7703, 3.8334, 3.7932],\n",
      "        [3.6618, 3.7270, 3.7061, 3.8337, 3.8273],\n",
      "        [3.7431, 3.7784, 3.7280, 3.8474, 3.7631],\n",
      "        [3.6373, 3.7739, 3.6542, 3.6623, 3.6278],\n",
      "        [3.5790, 3.8266, 3.6538, 3.8656, 3.6678],\n",
      "        [3.7257, 3.8607, 3.6917, 3.8434, 3.8205],\n",
      "        [3.6329, 3.7965, 3.6471, 3.7840, 3.6392],\n",
      "        [3.7560, 3.6985, 3.7656, 3.9150, 3.7164],\n",
      "        [3.5099, 3.5586, 3.6331, 3.6630, 3.5848],\n",
      "        [3.3775, 3.6057, 3.5279, 3.6990, 3.4167],\n",
      "        [3.6402, 3.8262, 3.6358, 3.9076, 3.7026],\n",
      "        [3.4690, 3.5618, 3.7271, 3.5094, 3.6989],\n",
      "        [3.4209, 3.5884, 3.4578, 3.5860, 3.4801],\n",
      "        [3.3533, 3.5790, 3.5570, 3.5535, 3.4615],\n",
      "        [3.6436, 3.8583, 3.7872, 3.8600, 3.6705],\n",
      "        [3.3161, 3.4177, 3.4798, 3.4926, 3.3456],\n",
      "        [3.5013, 3.6571, 3.4705, 3.7091, 3.5405],\n",
      "        [3.4962, 3.5885, 3.6067, 3.6827, 3.5525],\n",
      "        [3.5036, 3.7020, 3.6694, 3.6810, 3.7102],\n",
      "        [3.5065, 3.6580, 3.5678, 3.7352, 3.6002],\n",
      "        [3.5931, 3.6508, 3.6336, 3.7178, 3.5642],\n",
      "        [3.6360, 3.7032, 3.5332, 3.8086, 3.7295],\n",
      "        [3.5631, 3.6935, 3.6611, 3.7093, 3.7190],\n",
      "        [3.3703, 3.4733, 3.5061, 3.5504, 3.4216],\n",
      "        [3.3756, 3.4672, 3.5041, 3.5664, 3.4214],\n",
      "        [3.8991, 4.0138, 3.9265, 4.1976, 3.9417],\n",
      "        [3.4905, 3.7508, 3.6542, 3.6120, 3.6407],\n",
      "        [3.4895, 3.5104, 3.6225, 3.5646, 3.5824],\n",
      "        [3.6606, 3.8475, 3.7476, 3.8423, 3.6832],\n",
      "        [3.4943, 3.6320, 3.6279, 3.6509, 3.4587],\n",
      "        [3.4220, 3.5331, 3.5708, 3.6273, 3.4460],\n",
      "        [3.5353, 3.7247, 3.4975, 3.6452, 3.5699],\n",
      "        [3.8676, 3.8220, 3.9004, 4.0874, 3.8391],\n",
      "        [3.4966, 3.6400, 3.5723, 3.7890, 3.5493],\n",
      "        [3.5250, 3.6151, 3.7323, 3.7320, 3.6219],\n",
      "        [3.3081, 3.4291, 3.4391, 3.4625, 3.3826],\n",
      "        [3.5845, 3.6041, 3.6173, 3.6068, 3.4093],\n",
      "        [3.7226, 3.8430, 3.8210, 3.8640, 3.9365],\n",
      "        [3.7280, 3.8354, 3.7777, 3.8622, 3.9064],\n",
      "        [3.4135, 3.5887, 3.4651, 3.5807, 3.4857],\n",
      "        [3.3682, 3.4699, 3.5047, 3.5505, 3.4175],\n",
      "        [3.5340, 3.6554, 3.6269, 3.6546, 3.5920],\n",
      "        [3.3128, 3.4086, 3.4749, 3.4813, 3.3457],\n",
      "        [3.6611, 3.7419, 3.7524, 3.8422, 3.5640],\n",
      "        [3.6263, 3.7943, 3.6504, 3.7814, 3.6379],\n",
      "        [3.5277, 3.4637, 3.5649, 3.8121, 3.4705],\n",
      "        [3.4173, 3.5890, 3.4632, 3.5832, 3.4837],\n",
      "        [3.5044, 3.6298, 3.5276, 3.7332, 3.5638],\n",
      "        [3.6007, 3.8653, 3.7522, 3.7980, 3.6379],\n",
      "        [3.9953, 4.0079, 3.8621, 4.2126, 3.7959]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7050, 3.8801, 3.8262, 3.8098, 3.5137],\n",
      "        [3.3943, 3.5558, 3.4362, 3.6123, 3.4594],\n",
      "        [3.4823, 3.5383, 3.5927, 3.6400, 3.5331],\n",
      "        [3.6966, 3.9318, 3.7370, 3.9333, 3.7951],\n",
      "        [3.4976, 3.4644, 3.5462, 3.5190, 3.4315],\n",
      "        [3.3762, 3.4943, 3.4833, 3.5506, 3.4408],\n",
      "        [3.2773, 3.5280, 3.6502, 3.4888, 3.5358],\n",
      "        [3.5031, 3.9011, 3.7652, 3.7407, 3.5973],\n",
      "        [3.6541, 3.8421, 3.6764, 3.8167, 3.6928],\n",
      "        [3.3764, 3.5553, 3.4571, 3.5376, 3.4568],\n",
      "        [3.6554, 3.8357, 3.7424, 3.8554, 3.6821],\n",
      "        [3.6568, 3.7252, 3.7617, 3.7561, 3.5490],\n",
      "        [3.4790, 3.6341, 3.5512, 3.7219, 3.6358],\n",
      "        [3.6021, 3.6182, 3.6657, 3.6369, 3.5294],\n",
      "        [3.5363, 3.7332, 3.5300, 3.6430, 3.5867],\n",
      "        [3.3466, 3.5824, 3.5564, 3.5433, 3.4519],\n",
      "        [3.6596, 3.7050, 3.7394, 3.8401, 3.5187],\n",
      "        [3.5746, 3.7928, 3.6626, 3.6919, 3.6656],\n",
      "        [3.4815, 3.5576, 3.5952, 3.6576, 3.5476],\n",
      "        [3.4903, 3.5597, 3.5935, 3.6544, 3.5385],\n",
      "        [3.8980, 4.0143, 3.9200, 4.2098, 3.9534],\n",
      "        [3.4093, 3.5302, 3.4639, 3.6019, 3.4445],\n",
      "        [3.5188, 3.5687, 3.6492, 3.6896, 3.5765],\n",
      "        [3.4715, 3.8590, 3.6528, 3.7798, 3.7163],\n",
      "        [3.7342, 3.8077, 3.8446, 3.9900, 3.6841],\n",
      "        [3.4906, 3.6787, 3.6465, 3.6611, 3.6877],\n",
      "        [3.5258, 3.7187, 3.4777, 3.6296, 3.5600],\n",
      "        [3.6168, 3.6167, 3.6395, 3.8956, 3.5845],\n",
      "        [3.4803, 3.5408, 3.5792, 3.6298, 3.5280],\n",
      "        [3.5477, 3.4951, 3.5853, 3.8189, 3.4812],\n",
      "        [3.4311, 3.5491, 3.3841, 3.6669, 3.3913],\n",
      "        [3.3498, 3.4516, 3.4618, 3.5106, 3.4161],\n",
      "        [3.5992, 3.5971, 3.6598, 3.6271, 3.5573],\n",
      "        [3.5011, 3.5989, 3.6122, 3.6856, 3.5746],\n",
      "        [3.5147, 3.5339, 3.6468, 3.6927, 3.6521],\n",
      "        [3.6307, 3.7678, 3.6313, 3.8072, 3.6642],\n",
      "        [3.5258, 3.5501, 3.6480, 3.6749, 3.5469],\n",
      "        [3.5966, 3.6132, 3.6673, 3.6347, 3.5167],\n",
      "        [3.3573, 3.5350, 3.4585, 3.5133, 3.4634],\n",
      "        [3.3528, 3.5576, 3.5473, 3.5483, 3.4558],\n",
      "        [3.5131, 3.6322, 3.5385, 3.7254, 3.5641],\n",
      "        [3.3681, 3.5482, 3.4620, 3.5167, 3.4563],\n",
      "        [3.4221, 3.5845, 3.4604, 3.5804, 3.4930],\n",
      "        [3.3359, 3.5219, 3.4503, 3.4897, 3.4351],\n",
      "        [3.7643, 3.7868, 3.6589, 3.8693, 3.7844],\n",
      "        [3.5557, 3.5389, 3.6018, 3.6464, 3.6041],\n",
      "        [3.4254, 3.8209, 3.6408, 3.7201, 3.7065],\n",
      "        [3.3737, 3.4694, 3.5042, 3.5471, 3.4118],\n",
      "        [3.5051, 3.6428, 3.5760, 3.8071, 3.5513],\n",
      "        [3.4968, 3.7871, 3.5556, 3.7900, 3.6197],\n",
      "        [3.6814, 3.6641, 3.6875, 3.9247, 3.5613],\n",
      "        [3.2794, 3.4605, 3.4198, 3.4260, 3.3874],\n",
      "        [3.4873, 3.5292, 3.6003, 3.6340, 3.5180],\n",
      "        [3.6481, 3.6435, 3.6356, 3.6268, 3.4919],\n",
      "        [3.3992, 3.6280, 3.6780, 3.6110, 3.5918],\n",
      "        [3.4795, 3.6030, 3.6991, 3.7591, 3.7140],\n",
      "        [3.6342, 3.6367, 3.6389, 3.6275, 3.4680],\n",
      "        [3.3976, 3.5573, 3.4539, 3.5508, 3.4605],\n",
      "        [3.5444, 3.7872, 3.5800, 3.7254, 3.6130],\n",
      "        [3.5299, 3.4636, 3.5648, 3.8107, 3.4730],\n",
      "        [3.3774, 3.4817, 3.5133, 3.5571, 3.4299],\n",
      "        [3.8358, 4.0157, 3.7648, 3.8105, 3.7160],\n",
      "        [4.0007, 4.0223, 3.8378, 4.2619, 3.8140],\n",
      "        [3.5832, 3.6448, 3.5773, 3.7831, 3.6163]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5745, 3.6813, 3.5546, 3.7291, 3.5986],\n",
      "        [3.5358, 3.6212, 3.6478, 3.6602, 3.7767],\n",
      "        [3.2934, 3.5603, 3.3520, 3.5514, 3.3463],\n",
      "        [3.4594, 3.5546, 3.5249, 3.5605, 3.5299],\n",
      "        [3.8490, 3.8182, 3.7734, 3.9560, 3.8199],\n",
      "        [3.3683, 3.4944, 3.5219, 3.5541, 3.4432],\n",
      "        [3.3823, 3.5657, 3.4600, 3.5392, 3.4711],\n",
      "        [3.3481, 3.5821, 3.5563, 3.5417, 3.4540],\n",
      "        [3.5992, 3.6049, 3.6199, 3.6179, 3.4265],\n",
      "        [3.6427, 3.8299, 3.6440, 3.9151, 3.7216],\n",
      "        [3.5115, 3.6656, 3.4853, 3.7047, 3.5520],\n",
      "        [3.4918, 3.5593, 3.5932, 3.6529, 3.5406],\n",
      "        [4.1548, 4.3300, 3.9602, 4.0957, 3.8564],\n",
      "        [3.8706, 3.7699, 3.8530, 4.0681, 3.8638],\n",
      "        [3.7048, 3.8406, 3.8056, 3.8111, 3.5761],\n",
      "        [3.3636, 3.5337, 3.5463, 3.5581, 3.4577],\n",
      "        [3.8202, 3.6989, 3.8098, 3.9468, 3.7696],\n",
      "        [3.3740, 3.4935, 3.5198, 3.5528, 3.4454],\n",
      "        [3.4962, 3.6407, 3.4605, 3.6735, 3.5241],\n",
      "        [3.6503, 3.7295, 3.5575, 3.8206, 3.7281],\n",
      "        [3.5691, 3.8184, 3.6639, 3.7702, 3.7550],\n",
      "        [3.8518, 4.0437, 3.8079, 3.8321, 3.7725],\n",
      "        [3.4888, 3.5288, 3.6000, 3.6324, 3.5201],\n",
      "        [3.6669, 3.8022, 3.7611, 3.8097, 3.8475],\n",
      "        [3.8135, 3.9175, 3.8319, 3.9143, 3.8589],\n",
      "        [3.5867, 3.6389, 3.6138, 3.7984, 3.6165],\n",
      "        [3.4492, 3.5244, 3.5806, 3.6029, 3.5130],\n",
      "        [3.5217, 3.5639, 3.6581, 3.7050, 3.6063],\n",
      "        [3.6251, 3.7800, 3.7753, 3.8153, 3.6795],\n",
      "        [3.4191, 3.7805, 3.6694, 3.6930, 3.6865],\n",
      "        [3.7717, 3.8456, 3.8102, 3.9022, 3.9748],\n",
      "        [3.4977, 3.7093, 3.6402, 3.6857, 3.5392],\n",
      "        [3.4904, 3.4878, 3.5672, 3.5592, 3.4630],\n",
      "        [3.4756, 3.6878, 3.6334, 3.6725, 3.5997],\n",
      "        [3.3782, 3.4875, 3.5232, 3.5722, 3.4392],\n",
      "        [3.8579, 3.8831, 3.7475, 4.1041, 3.7256],\n",
      "        [3.6569, 3.7265, 3.6809, 3.8457, 3.7973],\n",
      "        [3.6270, 3.7713, 3.7582, 3.7679, 3.6605],\n",
      "        [3.5978, 3.6701, 3.6832, 3.6909, 3.7301],\n",
      "        [3.6695, 3.5159, 3.5193, 3.6291, 3.6443],\n",
      "        [3.7697, 3.7913, 3.7915, 3.9622, 3.7602],\n",
      "        [3.6206, 3.7550, 3.8126, 3.8254, 3.7341],\n",
      "        [3.4743, 3.6027, 3.5557, 3.6093, 3.5285],\n",
      "        [3.5466, 3.8137, 3.6072, 3.8373, 3.6546],\n",
      "        [3.5303, 3.6047, 3.6123, 3.5733, 3.3962],\n",
      "        [3.6748, 3.7333, 3.7720, 3.7672, 3.5529],\n",
      "        [3.7590, 3.7750, 3.7879, 3.9318, 3.7453],\n",
      "        [3.4316, 3.5155, 3.5855, 3.6318, 3.5980],\n",
      "        [3.9849, 3.7468, 3.8673, 4.3465, 4.1635],\n",
      "        [3.6883, 3.7741, 3.7650, 3.8693, 3.8687],\n",
      "        [3.6783, 3.8389, 3.6360, 3.7816, 3.7471],\n",
      "        [3.5742, 3.9102, 3.7447, 3.8040, 3.7791],\n",
      "        [3.5468, 3.6046, 3.6940, 3.7101, 3.6215],\n",
      "        [3.5306, 3.5636, 3.6531, 3.6525, 3.5606],\n",
      "        [3.3709, 3.5476, 3.4603, 3.5176, 3.4657],\n",
      "        [3.4783, 3.6318, 3.4628, 3.6632, 3.5182],\n",
      "        [3.4248, 3.6228, 3.5154, 3.6436, 3.4512],\n",
      "        [3.3167, 3.5039, 3.4418, 3.4647, 3.4193],\n",
      "        [3.4958, 3.7018, 3.5419, 3.7881, 3.5016],\n",
      "        [3.6504, 3.8089, 3.7706, 3.8142, 3.7191],\n",
      "        [3.4664, 3.5531, 3.7008, 3.5192, 3.6880],\n",
      "        [3.4964, 3.6480, 3.4740, 3.6777, 3.5393],\n",
      "        [3.4500, 3.4527, 3.5644, 3.6199, 3.5569],\n",
      "        [3.4731, 3.5409, 3.6066, 3.6608, 3.6017]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.2534, 3.4588, 3.4825, 3.4639, 3.4164],\n",
      "        [3.3875, 3.6364, 3.6831, 3.5910, 3.5776],\n",
      "        [3.4501, 3.6034, 3.4617, 3.6049, 3.5026],\n",
      "        [3.9792, 4.1440, 3.7932, 3.9101, 3.7135],\n",
      "        [3.4744, 3.5680, 3.6547, 3.6570, 3.5599],\n",
      "        [3.5135, 3.5582, 3.6197, 3.6513, 3.5988],\n",
      "        [3.4071, 3.4977, 3.4068, 3.6104, 3.4246],\n",
      "        [3.4258, 3.5844, 3.4628, 3.5787, 3.4968],\n",
      "        [3.5049, 3.5988, 3.6143, 3.6839, 3.5784],\n",
      "        [3.4873, 3.6195, 3.6717, 3.6899, 3.6304],\n",
      "        [3.5652, 3.8658, 3.7460, 3.7660, 3.6005],\n",
      "        [3.4831, 3.6342, 3.5534, 3.7203, 3.6395],\n",
      "        [3.3987, 3.4439, 3.4869, 3.5729, 3.4182],\n",
      "        [3.6420, 3.4930, 3.5243, 3.6486, 3.6015],\n",
      "        [3.6683, 3.7268, 3.7083, 3.8306, 3.8336],\n",
      "        [3.4901, 3.7047, 3.6589, 3.6840, 3.5046],\n",
      "        [3.6430, 3.7739, 3.6566, 3.6594, 3.6341],\n",
      "        [3.7284, 3.7836, 3.7367, 3.9005, 3.8556],\n",
      "        [3.3895, 3.4799, 3.5360, 3.5664, 3.4107],\n",
      "        [3.9028, 4.0071, 3.8932, 4.1759, 3.9350],\n",
      "        [3.7680, 3.9295, 3.6349, 3.7698, 3.6756],\n",
      "        [3.3901, 3.7098, 3.4919, 3.4134, 3.5536],\n",
      "        [3.6900, 3.7448, 3.7332, 3.8544, 3.8290],\n",
      "        [3.5427, 3.5864, 3.6789, 3.6949, 3.6070],\n",
      "        [3.5131, 3.5586, 3.6563, 3.6836, 3.5800],\n",
      "        [3.4867, 3.5723, 3.5973, 3.5340, 3.3515],\n",
      "        [3.4951, 3.5275, 3.5142, 3.7066, 3.4688],\n",
      "        [3.3645, 3.5075, 3.5277, 3.5561, 3.4414],\n",
      "        [3.7909, 3.9777, 3.7634, 3.7660, 3.7406],\n",
      "        [3.6129, 3.7353, 3.6163, 3.7407, 3.7676],\n",
      "        [3.4619, 3.4794, 3.5823, 3.6002, 3.4922],\n",
      "        [3.4904, 3.6198, 3.5053, 3.6364, 3.5585],\n",
      "        [4.0643, 4.2565, 3.8822, 4.0103, 3.7919],\n",
      "        [3.7308, 3.8701, 3.8736, 4.0340, 4.0391],\n",
      "        [3.7724, 3.7919, 3.7940, 3.9624, 3.7619],\n",
      "        [3.8320, 3.8066, 3.8048, 4.0220, 3.8308],\n",
      "        [3.3939, 3.6335, 3.4331, 3.6110, 3.4221],\n",
      "        [3.5853, 3.7179, 3.7993, 3.7694, 3.6876],\n",
      "        [3.5942, 3.7553, 3.5771, 3.7538, 3.6677],\n",
      "        [3.2714, 3.4506, 3.4171, 3.4039, 3.3684],\n",
      "        [3.4060, 3.5262, 3.5749, 3.6138, 3.4335],\n",
      "        [3.3452, 3.5287, 3.4538, 3.4899, 3.4403],\n",
      "        [3.4399, 3.5936, 3.4613, 3.5944, 3.5026],\n",
      "        [3.3892, 3.6001, 3.4542, 3.6168, 3.4637],\n",
      "        [3.4847, 3.6000, 3.5961, 3.6530, 3.6794],\n",
      "        [3.5093, 3.7996, 3.5878, 3.5180, 3.6342],\n",
      "        [3.4804, 3.6242, 3.4723, 3.6348, 3.5338],\n",
      "        [3.5251, 3.6565, 3.7853, 3.7392, 3.7112],\n",
      "        [3.3816, 3.5526, 3.5805, 3.5905, 3.4540],\n",
      "        [3.8542, 4.0441, 3.8105, 3.8320, 3.7743],\n",
      "        [3.4383, 3.4481, 3.4986, 3.5989, 3.4098],\n",
      "        [3.7792, 3.7495, 3.7644, 4.0218, 3.6805],\n",
      "        [3.3271, 3.3712, 3.4526, 3.5528, 3.3904],\n",
      "        [3.3489, 3.5431, 3.5400, 3.5385, 3.4425],\n",
      "        [3.5544, 3.5413, 3.6079, 3.6718, 3.5438],\n",
      "        [3.4664, 3.6131, 3.4692, 3.6163, 3.5242],\n",
      "        [3.4329, 3.4585, 3.5163, 3.5861, 3.4233],\n",
      "        [3.7012, 3.7639, 3.7474, 3.8491, 3.8742],\n",
      "        [3.4852, 3.6331, 3.4722, 3.6561, 3.5313],\n",
      "        [3.3673, 3.4877, 3.5163, 3.5424, 3.4304],\n",
      "        [3.4982, 3.5037, 3.5940, 3.6480, 3.6494],\n",
      "        [3.4892, 3.8559, 3.6459, 3.7790, 3.7023],\n",
      "        [3.4943, 3.6787, 3.6489, 3.6595, 3.6916],\n",
      "        [3.4105, 3.5381, 3.5558, 3.6541, 3.5111]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3838, 3.4943, 3.4878, 3.5501, 3.4459],\n",
      "        [3.6745, 3.7008, 3.8491, 3.7406, 3.5289],\n",
      "        [3.6461, 3.7726, 3.7860, 3.7489, 3.5551],\n",
      "        [3.6693, 3.6562, 3.7313, 3.8102, 3.6368],\n",
      "        [3.5053, 3.4644, 3.5505, 3.5186, 3.4367],\n",
      "        [3.4955, 3.5035, 3.5813, 3.5760, 3.4821],\n",
      "        [3.5054, 3.5009, 3.6171, 3.6566, 3.6380],\n",
      "        [3.7692, 3.6949, 3.6757, 3.8154, 3.7676],\n",
      "        [3.8098, 3.8309, 3.8227, 3.9941, 3.6984],\n",
      "        [3.4917, 3.7912, 3.6286, 3.6549, 3.4626],\n",
      "        [3.6333, 3.9686, 3.7788, 3.8585, 3.8790],\n",
      "        [3.6471, 3.8278, 3.6478, 3.9148, 3.7212],\n",
      "        [3.5413, 3.5599, 3.6725, 3.7369, 3.5861],\n",
      "        [3.3938, 3.4717, 3.5097, 3.5633, 3.4321],\n",
      "        [3.6484, 3.8836, 3.7879, 3.8524, 3.8190],\n",
      "        [3.4676, 3.6150, 3.4723, 3.6380, 3.5193],\n",
      "        [3.5181, 3.5710, 3.6873, 3.6794, 3.6048],\n",
      "        [3.5076, 3.8696, 3.6756, 3.8031, 3.7467],\n",
      "        [3.3855, 3.5526, 3.5826, 3.5917, 3.4553],\n",
      "        [3.2575, 3.4588, 3.4844, 3.4651, 3.4177],\n",
      "        [3.3105, 3.4943, 3.4425, 3.4459, 3.4114],\n",
      "        [3.6300, 3.7725, 3.7585, 3.7171, 3.5384],\n",
      "        [3.5747, 3.5351, 3.8416, 3.7318, 3.6685],\n",
      "        [3.7463, 3.9192, 3.6974, 3.7139, 3.6333],\n",
      "        [3.5002, 3.5441, 3.6082, 3.6608, 3.6106],\n",
      "        [3.4573, 3.5880, 3.4917, 3.6161, 3.5243],\n",
      "        [3.4471, 3.5436, 3.5923, 3.6393, 3.5314],\n",
      "        [3.4727, 3.5532, 3.4564, 3.6010, 3.5929],\n",
      "        [3.2097, 3.4121, 3.4637, 3.4289, 3.4099],\n",
      "        [3.6063, 3.6586, 3.7533, 3.7934, 3.6039],\n",
      "        [3.3731, 3.4819, 3.5150, 3.5467, 3.4321],\n",
      "        [3.3679, 3.5430, 3.4596, 3.5122, 3.4522],\n",
      "        [3.3616, 3.4945, 3.5244, 3.5412, 3.4301],\n",
      "        [3.4824, 3.6892, 3.6242, 3.6712, 3.5768],\n",
      "        [3.4946, 3.5842, 3.6047, 3.6655, 3.5548],\n",
      "        [3.8867, 3.7478, 3.8393, 4.3203, 4.0827],\n",
      "        [3.8684, 3.8586, 3.7410, 4.0395, 3.6567],\n",
      "        [3.4798, 3.8592, 3.6572, 3.7794, 3.7216],\n",
      "        [3.4930, 3.4925, 3.5700, 3.6317, 3.6415],\n",
      "        [3.6522, 3.8052, 3.6587, 3.8133, 3.6780],\n",
      "        [3.6132, 3.6667, 3.7583, 3.7877, 3.6179],\n",
      "        [3.5033, 3.6428, 3.6208, 3.6229, 3.4783],\n",
      "        [3.3651, 3.5302, 3.4542, 3.5081, 3.4426],\n",
      "        [3.5634, 3.8722, 3.8146, 3.8397, 3.7778],\n",
      "        [3.7336, 3.7625, 3.7603, 3.8448, 3.8775],\n",
      "        [3.3745, 3.4947, 3.5264, 3.5551, 3.4461],\n",
      "        [3.4074, 3.6280, 3.6822, 3.6106, 3.5969],\n",
      "        [3.4900, 3.5699, 3.5967, 3.6542, 3.5460],\n",
      "        [3.4074, 3.5773, 3.4706, 3.5620, 3.4866],\n",
      "        [3.9837, 4.1443, 3.7953, 3.9115, 3.7149],\n",
      "        [3.5713, 3.8310, 3.6793, 3.7772, 3.7667],\n",
      "        [3.6600, 3.8632, 3.6281, 3.7361, 3.6853],\n",
      "        [3.4927, 3.7588, 3.6748, 3.6008, 3.6509],\n",
      "        [3.5585, 3.5414, 3.6100, 3.6730, 3.5452],\n",
      "        [3.8981, 3.9880, 3.8981, 4.1562, 3.8910],\n",
      "        [3.3093, 3.4872, 3.3448, 3.5349, 3.3663],\n",
      "        [3.4026, 3.4439, 3.4888, 3.5741, 3.4194],\n",
      "        [3.5256, 3.5644, 3.6499, 3.6628, 3.5962],\n",
      "        [3.4179, 3.5578, 3.6074, 3.6178, 3.4526],\n",
      "        [3.8365, 3.8069, 3.8068, 4.0235, 3.8322],\n",
      "        [3.3546, 3.6330, 3.6870, 3.5740, 3.5578],\n",
      "        [3.9023, 3.9168, 3.7546, 4.1352, 3.7341],\n",
      "        [3.4666, 3.6143, 3.6740, 3.7256, 3.7006],\n",
      "        [3.5135, 3.6401, 3.6346, 3.6536, 3.4663]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4723, 3.6704, 3.5288, 3.7386, 3.4929],\n",
      "        [3.3648, 3.6115, 3.5832, 3.5617, 3.4882],\n",
      "        [3.4484, 3.5933, 3.4650, 3.5964, 3.5058],\n",
      "        [3.2813, 3.4612, 3.4281, 3.4108, 3.3818],\n",
      "        [3.4554, 3.5654, 3.5048, 3.6659, 3.5175],\n",
      "        [3.4522, 3.6197, 3.5991, 3.6718, 3.4867],\n",
      "        [3.6275, 3.9131, 3.7170, 3.8227, 3.7217],\n",
      "        [3.4604, 3.5245, 3.5867, 3.6049, 3.5178],\n",
      "        [3.6541, 3.8299, 3.6507, 3.9172, 3.7267],\n",
      "        [3.5436, 3.5271, 3.7172, 3.7537, 3.5742],\n",
      "        [3.8440, 3.8917, 3.8032, 4.0584, 3.8550],\n",
      "        [3.7279, 3.7592, 3.7833, 3.9272, 3.7057],\n",
      "        [3.4775, 3.5530, 3.7077, 3.5210, 3.6929],\n",
      "        [3.4075, 3.4676, 3.4052, 3.6099, 3.4152],\n",
      "        [3.3142, 3.4885, 3.4449, 3.4449, 3.4105],\n",
      "        [3.5284, 3.6614, 3.4834, 3.7050, 3.5466],\n",
      "        [3.5187, 3.6042, 3.6255, 3.6960, 3.5884],\n",
      "        [3.4427, 3.5113, 3.6148, 3.6216, 3.5155],\n",
      "        [3.7569, 3.7778, 3.7349, 3.8468, 3.7740],\n",
      "        [3.3763, 3.5973, 3.5744, 3.5699, 3.4904],\n",
      "        [3.4372, 3.5317, 3.5786, 3.6375, 3.5208],\n",
      "        [3.5172, 3.9014, 3.7709, 3.7418, 3.6041],\n",
      "        [3.7159, 3.6982, 3.7625, 3.8770, 3.6694],\n",
      "        [3.3913, 3.4089, 3.4719, 3.5636, 3.3936],\n",
      "        [3.6683, 3.8355, 3.7484, 3.8559, 3.6895],\n",
      "        [3.9128, 4.0073, 3.8968, 4.1787, 3.9385],\n",
      "        [3.3944, 3.6745, 3.7615, 3.6493, 3.6121],\n",
      "        [3.5119, 3.5595, 3.6430, 3.6751, 3.5774],\n",
      "        [3.4871, 3.6890, 3.6258, 3.6723, 3.5786],\n",
      "        [3.8833, 3.7708, 3.8589, 4.0712, 3.8690],\n",
      "        [3.6641, 3.8509, 3.7858, 3.8538, 3.6815],\n",
      "        [3.5239, 3.6309, 3.4536, 3.6939, 3.4494],\n",
      "        [3.6541, 3.8299, 3.6507, 3.9172, 3.7267],\n",
      "        [3.3021, 3.4757, 3.4346, 3.4327, 3.4018],\n",
      "        [3.7041, 3.8796, 3.6178, 3.7330, 3.6725],\n",
      "        [3.6602, 3.7108, 3.6758, 3.8305, 3.7843],\n",
      "        [3.8026, 3.7495, 3.7256, 3.8607, 3.7975],\n",
      "        [3.4445, 3.5967, 3.4668, 3.5975, 3.4982],\n",
      "        [3.8380, 3.7016, 3.8080, 4.2775, 4.0732],\n",
      "        [3.4519, 3.6712, 3.8109, 3.6552, 3.7227],\n",
      "        [3.5103, 3.6857, 3.6650, 3.6721, 3.6960],\n",
      "        [3.5179, 3.7994, 3.5912, 3.5202, 3.6375],\n",
      "        [3.5484, 3.5911, 3.6133, 3.6878, 3.5887],\n",
      "        [3.7839, 3.8130, 3.8277, 3.9303, 3.7545],\n",
      "        [3.5445, 3.4635, 3.5704, 3.8125, 3.4797],\n",
      "        [3.3271, 3.5039, 3.4480, 3.4663, 3.4241],\n",
      "        [3.5435, 3.6678, 3.6220, 3.7050, 3.6929],\n",
      "        [3.7912, 3.5292, 3.6755, 4.0608, 3.9382],\n",
      "        [3.5794, 3.7195, 3.6088, 3.7539, 3.6626],\n",
      "        [3.3587, 3.5821, 3.5625, 3.5435, 3.4588],\n",
      "        [3.5217, 3.5583, 3.6601, 3.6856, 3.5834],\n",
      "        [3.5440, 3.7628, 3.6069, 3.7760, 3.5597],\n",
      "        [3.3701, 3.6141, 3.5843, 3.5639, 3.4928],\n",
      "        [3.5082, 3.4952, 3.6041, 3.6583, 3.6398],\n",
      "        [3.4861, 3.6982, 3.6251, 3.6706, 3.5822],\n",
      "        [3.4360, 3.5326, 3.5770, 3.6262, 3.4556],\n",
      "        [3.5773, 3.6646, 3.6481, 3.6932, 3.6062],\n",
      "        [3.7123, 3.8838, 3.8333, 3.8093, 3.5322],\n",
      "        [3.4983, 3.6409, 3.4750, 3.6686, 3.5357],\n",
      "        [3.4176, 3.6270, 3.7847, 3.6248, 3.6922],\n",
      "        [3.6340, 3.6429, 3.6870, 3.8420, 3.5467],\n",
      "        [3.4972, 3.6384, 3.6136, 3.6036, 3.4720],\n",
      "        [3.5980, 3.6810, 3.7191, 3.7492, 3.6070],\n",
      "        [3.4797, 3.6041, 3.5031, 3.6276, 3.5426]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5248, 3.6429, 3.5828, 3.8095, 3.5597],\n",
      "        [4.0800, 4.2570, 3.8873, 4.0134, 3.7971],\n",
      "        [3.5255, 3.7056, 3.6837, 3.6815, 3.7271],\n",
      "        [3.8088, 3.8758, 3.7444, 3.9048, 3.8709],\n",
      "        [3.4481, 3.5921, 3.4698, 3.5944, 3.5057],\n",
      "        [3.6725, 3.6491, 3.7208, 3.8062, 3.6272],\n",
      "        [3.2872, 3.4659, 3.4959, 3.4870, 3.4457],\n",
      "        [3.4827, 3.5532, 3.7091, 3.5214, 3.6946],\n",
      "        [3.4330, 3.5419, 3.5612, 3.6595, 3.5155],\n",
      "        [3.5085, 3.5463, 3.6037, 3.6410, 3.5442],\n",
      "        [3.3708, 3.4945, 3.5272, 3.5425, 3.4335],\n",
      "        [3.4910, 3.5167, 3.6025, 3.6297, 3.5209],\n",
      "        [3.2853, 3.4742, 3.4884, 3.4875, 3.4304],\n",
      "        [3.7221, 3.7823, 3.8103, 3.8095, 3.7797],\n",
      "        [3.3867, 3.4696, 3.5116, 3.5499, 3.4284],\n",
      "        [3.4799, 3.6189, 3.4674, 3.6470, 3.5135],\n",
      "        [3.6789, 3.8540, 3.7647, 3.8442, 3.6977],\n",
      "        [3.4882, 3.5679, 3.6596, 3.6596, 3.5649],\n",
      "        [3.6533, 3.7911, 3.7368, 3.9011, 3.6580],\n",
      "        [3.4361, 3.5832, 3.4763, 3.5695, 3.5087],\n",
      "        [3.4110, 3.4277, 3.4843, 3.5729, 3.4120],\n",
      "        [3.5933, 3.6528, 3.6304, 3.7911, 3.6065],\n",
      "        [3.5024, 3.5979, 3.5691, 3.6285, 3.5578],\n",
      "        [3.7543, 3.7451, 3.7377, 4.0304, 3.7027],\n",
      "        [3.6227, 3.6845, 3.6636, 3.6904, 3.4204],\n",
      "        [3.7855, 3.7208, 3.6881, 3.8286, 3.7888],\n",
      "        [3.5088, 3.5100, 3.6303, 3.5639, 3.5936],\n",
      "        [3.6408, 3.6318, 3.6803, 3.7518, 3.5900],\n",
      "        [3.8102, 3.8683, 3.7369, 3.8971, 3.8722],\n",
      "        [3.4957, 3.5431, 3.5838, 3.6332, 3.5365],\n",
      "        [3.5950, 3.7426, 3.5767, 3.7445, 3.6443],\n",
      "        [3.5066, 3.5355, 3.6053, 3.6377, 3.5337],\n",
      "        [3.4360, 3.5887, 3.4708, 3.5826, 3.4947],\n",
      "        [3.4733, 3.4607, 3.5242, 3.5812, 3.6169],\n",
      "        [3.4199, 3.4686, 3.5962, 3.5825, 3.4866],\n",
      "        [3.3196, 3.4944, 3.4454, 3.4470, 3.4148],\n",
      "        [3.5305, 3.5588, 3.6356, 3.6592, 3.6003],\n",
      "        [3.8074, 3.7497, 3.7270, 3.8613, 3.7993],\n",
      "        [3.4526, 3.5566, 3.5032, 3.6777, 3.5140],\n",
      "        [3.7705, 3.8732, 3.7215, 3.8675, 3.8629],\n",
      "        [3.6691, 3.8500, 3.6199, 3.7643, 3.7072],\n",
      "        [3.6445, 3.7015, 3.5456, 3.7977, 3.7211],\n",
      "        [3.6264, 3.7673, 3.7555, 3.7786, 3.6706],\n",
      "        [3.3893, 3.4575, 3.5020, 3.5567, 3.4235],\n",
      "        [3.7973, 3.7699, 3.7085, 3.8635, 3.7553],\n",
      "        [4.0783, 4.2232, 3.9204, 4.0177, 3.8592],\n",
      "        [3.5493, 3.7816, 3.6266, 3.8321, 3.5749],\n",
      "        [3.4997, 3.5404, 3.5610, 3.6051, 3.5959],\n",
      "        [3.4002, 3.4439, 3.4956, 3.5637, 3.4193],\n",
      "        [3.5452, 3.7095, 3.4818, 3.6329, 3.5638],\n",
      "        [3.6795, 3.7603, 3.7608, 3.8413, 3.6030],\n",
      "        [3.7092, 3.7230, 3.8118, 3.8108, 3.5442],\n",
      "        [3.6473, 3.8313, 3.7382, 3.9160, 3.6885],\n",
      "        [3.5554, 3.5875, 3.6941, 3.7208, 3.6269],\n",
      "        [3.3318, 3.5042, 3.4493, 3.4667, 3.4256],\n",
      "        [3.8221, 3.9624, 3.6536, 3.7899, 3.6841],\n",
      "        [3.6990, 3.7373, 3.9041, 3.7180, 3.5711],\n",
      "        [3.5116, 3.7020, 3.5495, 3.7903, 3.5082],\n",
      "        [3.6571, 3.8277, 3.6509, 3.9164, 3.7249],\n",
      "        [3.4667, 3.6161, 3.6463, 3.6631, 3.6974],\n",
      "        [3.6105, 3.6924, 3.7027, 3.7217, 3.6439],\n",
      "        [3.4409, 3.5329, 3.5783, 3.6267, 3.4571],\n",
      "        [3.4976, 3.5406, 3.5862, 3.6309, 3.5367],\n",
      "        [3.5015, 3.5029, 3.6013, 3.6198, 3.5297]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8129, 3.8275, 3.8326, 3.9118, 3.9474],\n",
      "        [3.6463, 3.7727, 3.7622, 3.7196, 3.5442],\n",
      "        [3.5179, 3.5911, 3.5376, 3.6696, 3.5223],\n",
      "        [3.8516, 3.6921, 3.8250, 3.9856, 3.7811],\n",
      "        [3.5414, 3.6708, 3.4828, 3.7123, 3.5574],\n",
      "        [3.5286, 3.7622, 3.6020, 3.8012, 3.5573],\n",
      "        [3.4478, 3.5330, 3.5792, 3.6277, 3.4593],\n",
      "        [3.4193, 3.4680, 3.4073, 3.6113, 3.4189],\n",
      "        [3.9490, 3.7621, 3.9106, 4.3665, 4.1731],\n",
      "        [3.7426, 3.8439, 3.7936, 3.8663, 3.9019],\n",
      "        [3.6401, 3.9134, 3.7191, 3.8243, 3.7255],\n",
      "        [3.5775, 3.5379, 3.6123, 3.6849, 3.5272],\n",
      "        [3.4737, 3.6162, 3.6472, 3.6641, 3.6996],\n",
      "        [3.8028, 3.7776, 3.7890, 4.0469, 3.6884],\n",
      "        [3.4047, 3.5747, 3.6030, 3.5963, 3.4786],\n",
      "        [3.4838, 3.6150, 3.4762, 3.6403, 3.5250],\n",
      "        [3.4416, 3.8142, 3.7190, 3.7114, 3.7332],\n",
      "        [3.6665, 3.8302, 3.6530, 3.9188, 3.7306],\n",
      "        [3.5924, 3.7200, 3.6107, 3.7559, 3.6663],\n",
      "        [3.5052, 3.5741, 3.6034, 3.6638, 3.5574],\n",
      "        [3.5099, 3.5443, 3.5964, 3.6378, 3.5438],\n",
      "        [3.6862, 3.8540, 3.7655, 3.8453, 3.6999],\n",
      "        [3.5309, 3.5607, 3.6148, 3.6468, 3.6127],\n",
      "        [3.5629, 3.5192, 3.5804, 3.6246, 3.5916],\n",
      "        [3.5567, 3.5544, 3.6623, 3.6706, 3.6096],\n",
      "        [3.6387, 3.6873, 3.5406, 3.7964, 3.7188],\n",
      "        [3.7471, 3.8685, 3.8694, 4.0201, 4.0440],\n",
      "        [3.5753, 3.5281, 3.6058, 3.6716, 3.5145],\n",
      "        [3.5228, 3.5534, 3.6689, 3.6896, 3.5861],\n",
      "        [3.6281, 3.8988, 3.7037, 3.8113, 3.7110],\n",
      "        [3.8509, 3.7894, 3.7928, 3.9311, 3.8107],\n",
      "        [3.5798, 3.8014, 3.6607, 3.7599, 3.7484],\n",
      "        [3.5653, 3.8887, 3.7966, 3.8210, 3.8096],\n",
      "        [3.5820, 3.5434, 3.6246, 3.6800, 3.5581],\n",
      "        [3.5374, 3.5588, 3.6365, 3.6602, 3.6025],\n",
      "        [3.5270, 3.5461, 3.6195, 3.6429, 3.5498],\n",
      "        [3.4343, 3.5579, 3.6113, 3.6200, 3.4582],\n",
      "        [3.6663, 3.8023, 3.7640, 3.8332, 3.6905],\n",
      "        [3.3893, 3.6405, 3.5996, 3.5779, 3.5148],\n",
      "        [3.7065, 3.7373, 3.9049, 3.7192, 3.5733],\n",
      "        [3.7497, 3.9118, 3.8708, 3.8860, 3.6347],\n",
      "        [3.6807, 3.8358, 3.7506, 3.8575, 3.6934],\n",
      "        [3.7298, 3.8807, 3.8342, 3.8119, 3.5245],\n",
      "        [3.5385, 3.7300, 3.5882, 3.6828, 3.6339],\n",
      "        [3.3798, 3.5084, 3.5349, 3.5451, 3.4417],\n",
      "        [4.1042, 4.2972, 3.9062, 4.0492, 3.8272],\n",
      "        [3.6450, 3.8900, 3.7958, 3.8294, 3.8526],\n",
      "        [3.6488, 3.7687, 3.6128, 3.7353, 3.7581],\n",
      "        [3.4236, 3.4712, 3.5135, 3.5853, 3.4516],\n",
      "        [3.4600, 3.5405, 3.5560, 3.5578, 3.5158],\n",
      "        [3.5254, 3.6400, 3.5798, 3.7911, 3.5624],\n",
      "        [3.4381, 3.5827, 3.4759, 3.5626, 3.5016],\n",
      "        [3.4837, 3.6143, 3.6776, 3.7280, 3.7066],\n",
      "        [3.6492, 3.6496, 3.5970, 3.8703, 3.6890],\n",
      "        [3.7884, 3.8796, 3.7282, 3.8748, 3.8597],\n",
      "        [3.4274, 3.4978, 3.4125, 3.6139, 3.4315],\n",
      "        [3.5168, 3.7508, 3.6625, 3.6125, 3.6539],\n",
      "        [3.5203, 3.5762, 3.7054, 3.5784, 3.7190],\n",
      "        [3.6460, 3.7748, 3.7725, 3.7723, 3.6768],\n",
      "        [3.4188, 3.6663, 3.7688, 3.6352, 3.6355],\n",
      "        [3.8412, 3.8245, 3.7074, 4.0830, 3.8089],\n",
      "        [3.6738, 3.9948, 3.8112, 3.8849, 3.8726],\n",
      "        [3.5876, 3.7827, 3.6780, 3.7257, 3.5109],\n",
      "        [3.7595, 3.7659, 3.7739, 3.9683, 3.9495]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6396, 3.6219, 3.6716, 3.7310, 3.5797],\n",
      "        [4.0348, 4.0079, 3.8805, 4.2171, 3.8131],\n",
      "        [3.8455, 3.9185, 3.8481, 3.9199, 3.8709],\n",
      "        [3.3973, 3.4864, 3.5308, 3.5497, 3.4415],\n",
      "        [3.7212, 3.7744, 3.7826, 3.8772, 3.8802],\n",
      "        [3.5271, 3.5470, 3.6188, 3.6447, 3.5500],\n",
      "        [3.4477, 3.5300, 3.5781, 3.6410, 3.5209],\n",
      "        [3.6829, 3.6827, 3.7930, 3.7394, 3.4678],\n",
      "        [3.6730, 3.8299, 3.6614, 3.9204, 3.7335],\n",
      "        [3.7909, 3.5399, 3.6942, 4.0294, 3.9211],\n",
      "        [3.3566, 3.3791, 3.4597, 3.5718, 3.3929],\n",
      "        [3.5212, 3.6441, 3.4774, 3.6809, 3.5431],\n",
      "        [3.5226, 3.5394, 3.6069, 3.6411, 3.5487],\n",
      "        [3.5514, 3.5661, 3.6576, 3.6684, 3.6103],\n",
      "        [3.4272, 3.5571, 3.4697, 3.5539, 3.4736],\n",
      "        [3.5199, 3.5354, 3.6103, 3.6368, 3.5404],\n",
      "        [3.5110, 3.6341, 3.5676, 3.7263, 3.6492],\n",
      "        [3.7059, 3.8204, 3.6810, 3.8612, 3.7738],\n",
      "        [3.7344, 3.7722, 3.7783, 3.8599, 3.8308],\n",
      "        [3.4253, 3.4678, 3.4148, 3.6127, 3.4215],\n",
      "        [3.5189, 3.6393, 3.4914, 3.6797, 3.5484],\n",
      "        [3.4395, 3.5861, 3.6532, 3.6264, 3.4815],\n",
      "        [3.6766, 3.6489, 3.6151, 3.9152, 3.7162],\n",
      "        [3.7101, 3.8250, 3.7957, 3.7928, 3.5697],\n",
      "        [3.3769, 3.6009, 3.5803, 3.5481, 3.4739],\n",
      "        [3.7181, 3.7446, 3.7481, 3.8598, 3.8397],\n",
      "        [3.4579, 3.5398, 3.3930, 3.6679, 3.3995],\n",
      "        [3.4928, 3.6187, 3.4762, 3.6494, 3.5183],\n",
      "        [3.5355, 3.6012, 3.5685, 3.7943, 3.5986],\n",
      "        [3.4280, 3.4748, 3.4151, 3.6098, 3.3969],\n",
      "        [3.5069, 3.6318, 3.4794, 3.6681, 3.5295],\n",
      "        [3.7863, 3.8704, 3.7926, 3.8818, 3.8449],\n",
      "        [3.5305, 3.6581, 3.4894, 3.6955, 3.5528],\n",
      "        [3.2874, 3.4596, 3.5052, 3.4727, 3.4535],\n",
      "        [3.5604, 3.8049, 3.5558, 3.6881, 3.5817],\n",
      "        [3.3929, 3.5027, 3.5428, 3.5505, 3.4463],\n",
      "        [3.5083, 3.5495, 3.5947, 3.6391, 3.5436],\n",
      "        [3.4862, 3.4605, 3.5322, 3.5833, 3.6219],\n",
      "        [3.2874, 3.4596, 3.5052, 3.4727, 3.4535],\n",
      "        [3.3934, 3.4795, 3.4897, 3.5387, 3.4490],\n",
      "        [3.5062, 3.7743, 3.7211, 3.6124, 3.6499],\n",
      "        [3.6900, 3.7905, 3.7539, 3.7156, 3.6969],\n",
      "        [3.4907, 3.5365, 3.6219, 3.6606, 3.6294],\n",
      "        [3.5103, 3.8381, 3.7373, 3.7602, 3.7673],\n",
      "        [3.6254, 3.6504, 3.6497, 3.7196, 3.5809],\n",
      "        [3.7753, 3.7778, 3.7453, 3.8499, 3.7813],\n",
      "        [3.5788, 3.5289, 3.6004, 3.6338, 3.6079],\n",
      "        [3.5395, 3.6578, 3.5839, 3.7371, 3.6163],\n",
      "        [3.4874, 3.5470, 3.5795, 3.6647, 3.4911],\n",
      "        [3.5173, 3.5560, 3.6023, 3.6414, 3.5477],\n",
      "        [3.4596, 3.4991, 3.6270, 3.6194, 3.5102],\n",
      "        [3.5484, 3.5543, 3.6864, 3.6767, 3.6102],\n",
      "        [3.6730, 3.8299, 3.6614, 3.9204, 3.7335],\n",
      "        [3.6315, 3.5979, 3.6829, 3.6221, 3.5826],\n",
      "        [3.5169, 3.8558, 3.6595, 3.7842, 3.7125],\n",
      "        [3.6480, 3.8754, 3.8397, 3.8373, 3.6525],\n",
      "        [3.6739, 3.8256, 3.6532, 3.9099, 3.7194],\n",
      "        [3.4555, 3.5300, 3.5952, 3.6284, 3.5385],\n",
      "        [3.4276, 3.4719, 3.4173, 3.6094, 3.3533],\n",
      "        [3.9355, 3.7441, 3.8542, 4.3397, 4.0905],\n",
      "        [3.5924, 3.7750, 3.6657, 3.6936, 3.6691],\n",
      "        [3.3635, 3.6449, 3.7161, 3.5441, 3.5868],\n",
      "        [3.5567, 3.5497, 3.6642, 3.6783, 3.5609],\n",
      "        [3.6973, 3.6495, 3.6647, 4.0033, 3.7827]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5412, 3.7013, 3.6922, 3.6834, 3.7301],\n",
      "        [3.7598, 3.8099, 3.8206, 3.8824, 3.7023],\n",
      "        [3.4683, 3.6143, 3.6886, 3.7000, 3.6788],\n",
      "        [3.4342, 3.4753, 3.4222, 3.6112, 3.4005],\n",
      "        [3.6849, 3.8078, 3.7797, 3.8367, 3.7016],\n",
      "        [3.4188, 3.6050, 3.5530, 3.7045, 3.4352],\n",
      "        [3.4752, 3.6441, 3.5367, 3.7152, 3.4934],\n",
      "        [3.5615, 3.8169, 3.6136, 3.8280, 3.6616],\n",
      "        [3.5305, 3.6477, 3.4975, 3.6837, 3.5538],\n",
      "        [3.6880, 3.8015, 3.8097, 3.8469, 3.7576],\n",
      "        [3.5770, 3.6684, 3.6271, 3.7431, 3.6866],\n",
      "        [3.5422, 3.5234, 3.6584, 3.6845, 3.6617],\n",
      "        [3.6785, 3.8831, 3.8064, 3.8578, 3.8311],\n",
      "        [4.1313, 4.3440, 3.9089, 4.0843, 3.8476],\n",
      "        [3.7026, 3.5154, 3.5422, 3.6351, 3.6606],\n",
      "        [3.3936, 3.6253, 3.6062, 3.5687, 3.5089],\n",
      "        [3.6581, 3.6165, 3.6657, 3.9027, 3.6012],\n",
      "        [3.5732, 3.7527, 3.6213, 3.7640, 3.5834],\n",
      "        [3.9455, 3.9201, 3.7792, 4.1494, 3.7512],\n",
      "        [3.5235, 3.6461, 3.5931, 3.7121, 3.6741],\n",
      "        [3.7775, 3.8780, 3.8954, 4.0538, 4.0606],\n",
      "        [3.5460, 3.6219, 3.5464, 3.7241, 3.5723],\n",
      "        [3.5170, 3.5721, 3.6176, 3.5400, 3.3640],\n",
      "        [3.6691, 3.6363, 3.6619, 3.6321, 3.4855],\n",
      "        [3.9477, 3.7081, 3.8162, 4.2593, 4.1060],\n",
      "        [3.7121, 3.5058, 3.5274, 3.6323, 3.6672],\n",
      "        [3.5365, 3.6507, 3.6509, 3.6543, 3.4946],\n",
      "        [3.3273, 3.5004, 3.5073, 3.5192, 3.4631],\n",
      "        [3.6814, 3.7300, 3.7844, 3.7496, 3.5177],\n",
      "        [3.3911, 3.5153, 3.5553, 3.5481, 3.4512],\n",
      "        [3.5238, 3.8592, 3.6280, 3.8225, 3.6886],\n",
      "        [3.7906, 3.8729, 3.7382, 3.8715, 3.8712],\n",
      "        [3.6744, 3.6979, 3.7027, 3.8023, 3.8209],\n",
      "        [3.3938, 3.5422, 3.4779, 3.5216, 3.4653],\n",
      "        [3.7665, 3.8701, 3.8953, 4.0411, 4.0533],\n",
      "        [3.5895, 3.5467, 3.6495, 3.6678, 3.6278],\n",
      "        [3.3839, 3.6324, 3.7053, 3.5790, 3.5693],\n",
      "        [3.5507, 3.5609, 3.7017, 3.6815, 3.6162],\n",
      "        [3.7065, 3.7923, 3.7932, 3.9374, 3.6704],\n",
      "        [3.5375, 3.5187, 3.5191, 3.7187, 3.4770],\n",
      "        [3.5381, 3.6558, 3.4919, 3.6971, 3.5543],\n",
      "        [3.5743, 3.5185, 3.5938, 3.6268, 3.5976],\n",
      "        [3.5303, 3.5820, 3.6295, 3.6741, 3.5815],\n",
      "        [3.4938, 3.4787, 3.6026, 3.6060, 3.5055],\n",
      "        [3.3884, 3.4530, 3.5214, 3.5298, 3.4247],\n",
      "        [3.6583, 3.8388, 3.7855, 3.8365, 3.7698],\n",
      "        [3.8026, 3.7876, 3.6807, 3.8743, 3.8015],\n",
      "        [3.3443, 3.4938, 3.4607, 3.4596, 3.4302],\n",
      "        [3.7516, 3.7586, 3.7985, 3.8658, 3.8899],\n",
      "        [3.7076, 3.8428, 3.6602, 3.7766, 3.7476],\n",
      "        [3.9539, 4.0626, 3.7177, 3.8870, 3.7073],\n",
      "        [3.4459, 3.7115, 3.6403, 3.6676, 3.7263],\n",
      "        [3.7665, 3.8253, 3.8369, 3.8913, 3.7180],\n",
      "        [3.6696, 3.9896, 3.8357, 3.8740, 3.8479],\n",
      "        [3.3873, 3.5476, 3.4900, 3.5610, 3.4488],\n",
      "        [3.9167, 3.9724, 3.8489, 4.1856, 3.9323],\n",
      "        [3.6264, 3.5923, 3.6793, 3.6244, 3.5562],\n",
      "        [3.4458, 3.5573, 3.6251, 3.6224, 3.4639],\n",
      "        [3.4847, 3.5874, 3.5099, 3.6209, 3.5357],\n",
      "        [3.6603, 3.8313, 3.7847, 3.8415, 3.7533],\n",
      "        [3.4301, 3.4730, 3.4135, 3.6107, 3.3669],\n",
      "        [3.7519, 3.8866, 3.7888, 3.7261, 3.7577],\n",
      "        [3.7810, 3.7774, 3.7522, 3.8509, 3.7849],\n",
      "        [3.7781, 3.9229, 3.8593, 3.9467, 3.8526]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5128, 3.5609, 3.7571, 3.5123, 3.7213],\n",
      "        [3.7348, 3.8488, 3.6855, 3.7926, 3.7798],\n",
      "        [3.5698, 3.9254, 3.6759, 3.8763, 3.7506],\n",
      "        [3.8161, 3.6856, 3.8097, 3.9601, 3.7316],\n",
      "        [3.7830, 3.9233, 3.8656, 3.9475, 3.8554],\n",
      "        [3.7030, 3.8536, 3.7868, 3.8484, 3.7089],\n",
      "        [3.6835, 3.8019, 3.7852, 3.8365, 3.6995],\n",
      "        [3.5477, 3.6295, 3.5565, 3.7368, 3.5858],\n",
      "        [3.7340, 3.7559, 3.7726, 3.8476, 3.8346],\n",
      "        [3.6661, 3.6501, 3.7136, 3.6845, 3.5272],\n",
      "        [3.4903, 3.8077, 3.7290, 3.7383, 3.7117],\n",
      "        [3.5268, 3.6285, 3.5871, 3.6313, 3.5743],\n",
      "        [3.5518, 3.6473, 3.6093, 3.7832, 3.5953],\n",
      "        [3.5965, 3.8011, 3.6808, 3.7631, 3.7572],\n",
      "        [3.4849, 3.5366, 3.6317, 3.6406, 3.5424],\n",
      "        [3.7493, 3.7881, 3.7667, 3.8354, 3.8930],\n",
      "        [3.6836, 3.8281, 3.6759, 3.9174, 3.7384],\n",
      "        [3.5341, 3.6492, 3.5009, 3.6936, 3.5541],\n",
      "        [3.7418, 3.5399, 3.7030, 3.9500, 3.8681],\n",
      "        [3.6942, 3.7759, 3.7860, 3.8477, 3.6431],\n",
      "        [3.9000, 3.7310, 3.8456, 4.3041, 4.0948],\n",
      "        [3.6754, 3.4849, 3.5438, 3.6599, 3.6006],\n",
      "        [3.8709, 3.7637, 3.8708, 4.0273, 3.8080],\n",
      "        [3.6400, 3.4611, 3.7823, 3.7482, 3.6256],\n",
      "        [3.5506, 3.6490, 3.6579, 3.6539, 3.4894],\n",
      "        [3.9060, 3.8583, 3.7714, 4.0474, 3.6717],\n",
      "        [3.7451, 3.7720, 3.7916, 3.8616, 3.8374],\n",
      "        [3.6142, 3.6883, 3.6033, 3.7525, 3.6446],\n",
      "        [3.4335, 3.5654, 3.6469, 3.6223, 3.4624],\n",
      "        [3.6592, 3.9404, 3.8268, 3.8380, 3.8121],\n",
      "        [3.7214, 3.7911, 3.8114, 3.9458, 3.6753],\n",
      "        [3.5214, 3.6027, 3.7277, 3.7642, 3.7342],\n",
      "        [3.8079, 3.9299, 3.6626, 3.7777, 3.6914],\n",
      "        [3.5306, 3.6426, 3.5052, 3.6823, 3.5544],\n",
      "        [3.3825, 3.5867, 3.5903, 3.5577, 3.4757],\n",
      "        [3.5641, 3.8053, 3.6845, 3.7049, 3.4951],\n",
      "        [3.8602, 3.8726, 3.7830, 3.9442, 3.9085],\n",
      "        [3.4783, 3.6286, 3.6114, 3.7365, 3.4967],\n",
      "        [3.4349, 3.5841, 3.7278, 3.6190, 3.6296],\n",
      "        [3.7535, 3.8208, 3.7867, 3.8489, 3.9020],\n",
      "        [3.4655, 3.5825, 3.4808, 3.5855, 3.4929],\n",
      "        [3.4756, 3.4295, 3.6288, 3.4390, 3.5928],\n",
      "        [3.7211, 3.7379, 3.9281, 3.7262, 3.5848],\n",
      "        [3.8483, 3.8473, 3.8284, 4.0343, 3.7919],\n",
      "        [3.4231, 3.6744, 3.7833, 3.6539, 3.6248],\n",
      "        [3.4369, 3.5570, 3.4820, 3.5555, 3.4793],\n",
      "        [3.3860, 3.5950, 3.5950, 3.5515, 3.4795],\n",
      "        [3.5996, 3.5570, 3.6619, 3.6707, 3.6359],\n",
      "        [3.9579, 3.8152, 3.9264, 4.1201, 3.9042],\n",
      "        [3.6170, 3.6523, 3.6527, 3.7953, 3.6174],\n",
      "        [3.6622, 3.9356, 3.8262, 3.8424, 3.8182],\n",
      "        [3.7287, 3.6705, 3.6823, 3.6877, 3.5428],\n",
      "        [3.6116, 3.8602, 3.7288, 3.7953, 3.7888],\n",
      "        [3.5506, 3.6221, 3.5524, 3.7247, 3.5750],\n",
      "        [3.3922, 3.5767, 3.5841, 3.5502, 3.4683],\n",
      "        [3.8160, 3.5269, 3.7106, 4.0529, 3.9308],\n",
      "        [3.4501, 3.5567, 3.6346, 3.6836, 3.5821],\n",
      "        [3.6975, 3.8354, 3.7719, 3.8606, 3.7023],\n",
      "        [3.8888, 3.7148, 3.8430, 4.3039, 4.0959],\n",
      "        [3.7189, 3.7354, 3.9191, 3.7231, 3.5753],\n",
      "        [3.5274, 3.5558, 3.6155, 3.6430, 3.5537],\n",
      "        [3.6811, 3.6315, 3.7219, 3.7781, 3.6130],\n",
      "        [3.5298, 3.5393, 3.6753, 3.6838, 3.5872],\n",
      "        [3.7077, 3.6493, 3.6777, 4.0049, 3.7889]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4798, 3.5641, 3.5335, 3.5614, 3.4907],\n",
      "        [3.5794, 3.4636, 3.6056, 3.8199, 3.4950],\n",
      "        [3.4027, 3.6005, 3.6042, 3.5700, 3.4965],\n",
      "        [3.7447, 3.8843, 3.8635, 3.8155, 3.5477],\n",
      "        [3.6432, 3.7892, 3.6442, 3.8767, 3.6883],\n",
      "        [3.5827, 3.7359, 3.5827, 3.6497, 3.6166],\n",
      "        [3.7510, 3.8473, 3.8325, 3.8747, 3.9012],\n",
      "        [3.3996, 3.5082, 3.5604, 3.5491, 3.4532],\n",
      "        [3.5282, 3.5690, 3.7402, 3.5623, 3.7130],\n",
      "        [3.5957, 3.5410, 3.6412, 3.6795, 3.5633],\n",
      "        [3.6104, 3.7842, 3.7040, 3.7302, 3.5251],\n",
      "        [3.6375, 3.6729, 3.7170, 3.7154, 3.7348],\n",
      "        [3.7554, 3.7546, 3.7838, 3.8419, 3.8795],\n",
      "        [3.6851, 3.5553, 3.5619, 3.6416, 3.6795],\n",
      "        [3.7579, 3.8210, 3.7936, 3.8502, 3.9053],\n",
      "        [3.5956, 3.5277, 3.6330, 3.6756, 3.5265],\n",
      "        [3.6656, 3.7214, 3.7136, 3.8868, 3.6544],\n",
      "        [3.5970, 3.6054, 3.7366, 3.7215, 3.6394],\n",
      "        [3.4489, 3.5566, 3.4982, 3.6205, 3.4697],\n",
      "        [3.4006, 3.5489, 3.5863, 3.5632, 3.4805],\n",
      "        [3.5238, 3.4941, 3.6565, 3.5324, 3.6121],\n",
      "        [3.5830, 3.8863, 3.8191, 3.8235, 3.8227],\n",
      "        [3.3952, 3.6086, 3.6078, 3.5568, 3.4910],\n",
      "        [3.5389, 3.6480, 3.5099, 3.6854, 3.5597],\n",
      "        [3.8926, 3.6770, 3.7387, 4.2130, 3.9562],\n",
      "        [3.4546, 3.6177, 3.6999, 3.6765, 3.6559],\n",
      "        [3.6942, 3.7853, 3.6923, 3.7360, 3.6621],\n",
      "        [3.3583, 3.5021, 3.4777, 3.4657, 3.4472],\n",
      "        [3.5348, 3.5481, 3.5926, 3.6148, 3.6149],\n",
      "        [3.4779, 3.4478, 3.5301, 3.6065, 3.4281],\n",
      "        [3.5822, 3.5849, 3.7205, 3.7299, 3.6377],\n",
      "        [3.4465, 3.4682, 3.6230, 3.5873, 3.5005],\n",
      "        [3.4169, 3.6286, 3.7116, 3.5962, 3.5886],\n",
      "        [3.5435, 3.6458, 3.5023, 3.6903, 3.5503],\n",
      "        [3.6056, 3.6501, 3.6556, 3.7251, 3.6895],\n",
      "        [3.4574, 3.6262, 3.5658, 3.6123, 3.5667],\n",
      "        [3.5605, 3.6124, 3.6618, 3.6552, 3.7703],\n",
      "        [3.7708, 3.8545, 3.7144, 3.8180, 3.8288],\n",
      "        [3.7694, 3.8685, 3.8983, 4.0248, 4.0567],\n",
      "        [3.7920, 3.9512, 3.9331, 3.9037, 3.6506],\n",
      "        [3.7233, 3.8372, 3.7728, 3.7098, 3.7245],\n",
      "        [3.7257, 3.7912, 3.8180, 3.9470, 3.6788],\n",
      "        [3.5539, 3.5580, 3.6514, 3.6585, 3.6183],\n",
      "        [3.5254, 3.6328, 3.5053, 3.6638, 3.5499],\n",
      "        [3.5615, 3.5774, 3.6809, 3.7025, 3.6089],\n",
      "        [3.4199, 3.5376, 3.6015, 3.5884, 3.4615],\n",
      "        [3.3381, 3.4800, 3.4671, 3.4424, 3.4234],\n",
      "        [3.4509, 3.3982, 3.6116, 3.4056, 3.5720],\n",
      "        [3.4222, 3.4088, 3.4999, 3.5690, 3.4088],\n",
      "        [3.5105, 3.8002, 3.6536, 3.6444, 3.4834],\n",
      "        [3.7128, 3.7202, 3.7504, 3.8051, 3.8542],\n",
      "        [3.5114, 3.6378, 3.5082, 3.6561, 3.5457],\n",
      "        [3.4088, 3.4816, 3.5444, 3.5530, 3.4492],\n",
      "        [4.1532, 4.3062, 3.9160, 4.0293, 3.8688],\n",
      "        [3.5285, 3.5025, 3.6288, 3.6246, 3.5439],\n",
      "        [3.5835, 3.5904, 3.7114, 3.6921, 3.6320],\n",
      "        [3.4212, 3.4140, 3.4975, 3.5635, 3.4120],\n",
      "        [3.5441, 3.5594, 3.6711, 3.6804, 3.5935],\n",
      "        [3.4110, 3.4864, 3.5491, 3.5523, 3.4504],\n",
      "        [3.7813, 3.7659, 3.8018, 3.9729, 3.9620],\n",
      "        [3.6293, 3.5570, 3.8868, 3.7633, 3.7188],\n",
      "        [3.4588, 3.5882, 3.4998, 3.5851, 3.5103],\n",
      "        [3.5241, 3.6390, 3.6625, 3.7059, 3.5312],\n",
      "        [3.6230, 3.6845, 3.7477, 3.7468, 3.6613]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5448, 3.5952, 3.6570, 3.6900, 3.5944],\n",
      "        [3.7625, 3.9342, 3.7657, 3.6935, 3.7150],\n",
      "        [3.6743, 3.7722, 3.7994, 3.7769, 3.6837],\n",
      "        [3.5931, 3.6571, 3.6687, 3.6868, 3.6184],\n",
      "        [3.4334, 3.6360, 3.7210, 3.5998, 3.5991],\n",
      "        [3.5093, 3.6654, 3.5778, 3.6912, 3.6234],\n",
      "        [3.4035, 3.6174, 3.6143, 3.5626, 3.5038],\n",
      "        [3.5453, 3.4642, 3.5852, 3.5255, 3.4573],\n",
      "        [3.5310, 3.6172, 3.6185, 3.6008, 3.5816],\n",
      "        [3.4128, 3.6405, 3.6296, 3.5826, 3.5288],\n",
      "        [3.4881, 3.6711, 3.8439, 3.6614, 3.7418],\n",
      "        [3.7711, 3.7113, 3.8048, 3.8875, 3.7032],\n",
      "        [3.7597, 3.9391, 3.8017, 3.9645, 3.8279],\n",
      "        [3.7528, 3.5998, 3.6608, 3.7390, 3.6974],\n",
      "        [3.3945, 3.5572, 3.5875, 3.5566, 3.4774],\n",
      "        [3.5546, 3.5604, 3.6453, 3.6513, 3.6278],\n",
      "        [3.8846, 3.9056, 3.8469, 4.0910, 3.8919],\n",
      "        [3.5050, 3.7472, 3.6227, 3.6348, 3.5238],\n",
      "        [3.4424, 3.4359, 3.5208, 3.5856, 3.4439],\n",
      "        [3.9852, 4.0630, 3.7032, 3.8734, 3.6810],\n",
      "        [3.5535, 3.7016, 3.7089, 3.6856, 3.7394],\n",
      "        [3.7211, 3.7343, 3.7525, 3.7935, 3.8162],\n",
      "        [3.4671, 3.7807, 3.7097, 3.7018, 3.7118],\n",
      "        [3.3956, 3.6240, 3.6195, 3.5562, 3.5020],\n",
      "        [3.7523, 3.8938, 3.6697, 3.7622, 3.7052],\n",
      "        [3.6314, 3.7179, 3.8364, 3.7780, 3.7100],\n",
      "        [3.7028, 3.8072, 3.6924, 3.8681, 3.8527],\n",
      "        [3.6009, 3.4951, 3.6325, 3.8288, 3.5061],\n",
      "        [3.4038, 3.5301, 3.4881, 3.5149, 3.4620],\n",
      "        [3.7380, 3.7376, 3.8198, 3.8351, 3.5912],\n",
      "        [3.7107, 3.8537, 3.7985, 3.8502, 3.7150],\n",
      "        [3.6986, 3.9950, 3.8445, 3.8903, 3.8879],\n",
      "        [3.5866, 3.5870, 3.7273, 3.7265, 3.6443],\n",
      "        [3.6573, 3.6217, 3.6959, 3.7342, 3.5920],\n",
      "        [3.4004, 3.5614, 3.5904, 3.5629, 3.4857],\n",
      "        [3.4669, 3.5390, 3.6289, 3.6641, 3.5746],\n",
      "        [3.4100, 3.6428, 3.7434, 3.5686, 3.5728],\n",
      "        [3.3911, 3.5180, 3.4918, 3.5003, 3.4550],\n",
      "        [3.4312, 3.4250, 3.5135, 3.5783, 3.4199],\n",
      "        [3.7364, 3.6642, 3.7357, 3.9349, 3.5867],\n",
      "        [3.3951, 3.4901, 3.5524, 3.5437, 3.4447],\n",
      "        [3.7835, 3.8703, 3.9049, 4.0344, 4.0703],\n",
      "        [3.5247, 3.5332, 3.5865, 3.6034, 3.5991],\n",
      "        [3.9863, 4.1741, 3.7733, 3.8993, 3.7030],\n",
      "        [3.4104, 3.4796, 3.5125, 3.5419, 3.4603],\n",
      "        [3.5754, 3.7944, 3.6901, 3.6971, 3.5005],\n",
      "        [3.4232, 3.5376, 3.6064, 3.5890, 3.4641],\n",
      "        [3.6327, 3.7918, 3.7048, 3.6851, 3.7120],\n",
      "        [3.6643, 3.7040, 3.7820, 3.7422, 3.5408],\n",
      "        [3.3490, 3.4943, 3.4755, 3.4525, 3.4305],\n",
      "        [3.6121, 3.7825, 3.7127, 3.7309, 3.5256],\n",
      "        [3.6972, 3.5443, 3.5752, 3.6448, 3.6863],\n",
      "        [3.4569, 3.5862, 3.6761, 3.6298, 3.4931],\n",
      "        [3.5464, 3.5801, 3.7267, 3.5983, 3.7204],\n",
      "        [3.6245, 3.6524, 3.6645, 3.7972, 3.6234],\n",
      "        [3.3393, 3.5007, 3.5240, 3.5215, 3.4714],\n",
      "        [3.4019, 3.4959, 3.5567, 3.5479, 3.4499],\n",
      "        [3.5619, 3.5656, 3.6606, 3.6629, 3.6285],\n",
      "        [3.5387, 3.5372, 3.5659, 3.7040, 3.5024],\n",
      "        [3.4275, 3.5659, 3.4990, 3.5470, 3.4935],\n",
      "        [3.6794, 3.6549, 3.7237, 3.6890, 3.5461],\n",
      "        [3.8178, 3.8613, 3.9027, 3.8635, 3.6418],\n",
      "        [3.5239, 3.7793, 3.7425, 3.6165, 3.6654],\n",
      "        [3.5341, 3.6286, 3.5982, 3.6330, 3.5802]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5747, 3.8062, 3.6268, 3.8249, 3.6680],\n",
      "        [3.6111, 3.6254, 3.6575, 3.7602, 3.6134],\n",
      "        [3.6661, 3.6875, 3.5764, 3.8019, 3.7357],\n",
      "        [3.5332, 3.5691, 3.6378, 3.6620, 3.5688],\n",
      "        [3.7937, 3.9750, 3.8111, 3.9598, 3.9031],\n",
      "        [3.8427, 3.8270, 3.8767, 3.9191, 3.9653],\n",
      "        [3.3440, 3.4962, 3.5216, 3.5342, 3.4675],\n",
      "        [3.8464, 3.8685, 3.7753, 3.9043, 3.8917],\n",
      "        [3.6976, 3.8233, 3.8137, 3.7617, 3.5920],\n",
      "        [3.6744, 3.7604, 3.6836, 3.6537, 3.6444],\n",
      "        [3.5379, 3.5834, 3.6460, 3.6733, 3.5777],\n",
      "        [3.4801, 3.5943, 3.5111, 3.5848, 3.5251],\n",
      "        [3.7705, 3.7604, 3.8230, 3.9357, 3.7264],\n",
      "        [3.4436, 3.5655, 3.6618, 3.6243, 3.4704],\n",
      "        [3.7109, 3.8677, 3.8152, 3.8441, 3.7173],\n",
      "        [3.5638, 3.6667, 3.5347, 3.7129, 3.5827],\n",
      "        [3.7194, 3.7237, 3.7916, 3.8491, 3.5708],\n",
      "        [3.5514, 3.6508, 3.6712, 3.6567, 3.5059],\n",
      "        [3.5670, 3.7391, 3.6359, 3.6356, 3.6456],\n",
      "        [3.4303, 3.5657, 3.5031, 3.5473, 3.4957],\n",
      "        [3.7876, 3.8292, 3.8281, 3.8787, 3.9426],\n",
      "        [3.5068, 3.8574, 3.7870, 3.7632, 3.7965],\n",
      "        [3.5846, 3.5592, 3.7132, 3.7442, 3.6096],\n",
      "        [3.8118, 3.5395, 3.7232, 4.0329, 3.9361],\n",
      "        [4.0030, 4.1406, 3.7882, 3.8804, 3.7273],\n",
      "        [3.7150, 3.7410, 3.7990, 3.8555, 3.5963],\n",
      "        [3.5893, 3.7528, 3.6477, 3.7675, 3.5944],\n",
      "        [3.5939, 3.5559, 3.6938, 3.6770, 3.6341],\n",
      "        [3.5587, 3.7957, 3.6824, 3.6782, 3.4928],\n",
      "        [3.8306, 3.5289, 3.7143, 4.0672, 3.9605],\n",
      "        [3.5549, 3.7078, 3.6979, 3.7010, 3.5642],\n",
      "        [3.6357, 3.7916, 3.7091, 3.6854, 3.7144],\n",
      "        [3.7422, 3.9977, 3.8148, 3.8303, 4.0141],\n",
      "        [3.5452, 3.5757, 3.7421, 3.5838, 3.7248],\n",
      "        [3.5115, 3.6451, 3.7796, 3.6281, 3.5836],\n",
      "        [3.5242, 3.6797, 3.5960, 3.6908, 3.6312],\n",
      "        [3.6097, 3.6083, 3.7420, 3.7307, 3.6590],\n",
      "        [4.1208, 4.2975, 3.8705, 3.9859, 3.8527],\n",
      "        [3.6339, 3.6443, 3.6211, 3.7897, 3.6449],\n",
      "        [3.8822, 3.8307, 3.8138, 3.9479, 3.8766],\n",
      "        [3.4224, 3.7374, 3.6289, 3.4741, 3.6435],\n",
      "        [3.4577, 3.5374, 3.5988, 3.6629, 3.5351],\n",
      "        [3.4820, 3.5966, 3.5048, 3.6040, 3.5183],\n",
      "        [3.7767, 3.7696, 3.7683, 3.8264, 3.7914],\n",
      "        [3.4761, 3.5296, 3.6242, 3.6321, 3.5527],\n",
      "        [3.8777, 3.7520, 3.8744, 4.0270, 3.8014],\n",
      "        [3.5744, 3.9407, 3.7977, 3.7002, 3.6293],\n",
      "        [3.5342, 3.6920, 3.6919, 3.6805, 3.6621],\n",
      "        [3.4022, 3.5767, 3.5990, 3.5522, 3.4762],\n",
      "        [3.4740, 3.5326, 3.6141, 3.6327, 3.4757],\n",
      "        [3.6569, 3.6914, 3.5739, 3.7204, 3.7095],\n",
      "        [3.4373, 3.4375, 3.5272, 3.5794, 3.4406],\n",
      "        [3.8187, 3.7746, 3.8138, 4.0448, 3.7222],\n",
      "        [3.4499, 3.4457, 3.5321, 3.5861, 3.4438],\n",
      "        [3.5481, 3.5127, 3.6692, 3.6748, 3.6633],\n",
      "        [3.5603, 3.6653, 3.5316, 3.7134, 3.5775],\n",
      "        [3.7199, 3.6659, 3.6847, 3.9788, 3.7807],\n",
      "        [3.4638, 3.5683, 3.4979, 3.5751, 3.4943],\n",
      "        [3.5442, 3.6491, 3.5170, 3.6956, 3.5623],\n",
      "        [3.8904, 3.7958, 3.8145, 4.0373, 3.8228],\n",
      "        [3.8291, 3.7230, 3.7373, 3.8447, 3.8102],\n",
      "        [3.3445, 3.4841, 3.4768, 3.4428, 3.4324],\n",
      "        [3.6234, 3.6811, 3.5982, 3.7371, 3.6246],\n",
      "        [3.7396, 3.6641, 3.7413, 3.9354, 3.5890]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6529, 3.6625, 3.5407, 3.7777, 3.7220],\n",
      "        [3.4415, 3.4315, 3.5184, 3.5866, 3.4461],\n",
      "        [3.4505, 3.6080, 3.7089, 3.6364, 3.6304],\n",
      "        [3.8249, 3.7959, 3.8559, 3.9021, 3.9357],\n",
      "        [3.7964, 3.8796, 3.9230, 4.0580, 4.0744],\n",
      "        [3.5970, 3.8140, 3.5986, 3.7211, 3.6086],\n",
      "        [3.4938, 3.6135, 3.6469, 3.6894, 3.5092],\n",
      "        [3.7913, 3.7573, 3.8750, 3.8803, 3.6030],\n",
      "        [3.5852, 3.5549, 3.7007, 3.6762, 3.6289],\n",
      "        [3.4367, 3.4227, 3.5154, 3.5708, 3.4267],\n",
      "        [3.4065, 3.4968, 3.5645, 3.5489, 3.4540],\n",
      "        [3.5023, 3.6041, 3.5077, 3.6202, 3.5359],\n",
      "        [3.8436, 3.8477, 3.7799, 3.9204, 3.8913],\n",
      "        [3.5630, 3.6233, 3.5717, 3.7276, 3.5850],\n",
      "        [3.6290, 3.6893, 3.6254, 3.7530, 3.6503],\n",
      "        [3.4581, 3.6278, 3.8253, 3.6320, 3.7155],\n",
      "        [3.8105, 3.8717, 3.8245, 3.8868, 3.8615],\n",
      "        [3.6847, 3.8148, 3.8039, 3.8402, 3.7349],\n",
      "        [3.4893, 3.5677, 3.6262, 3.6817, 3.5485],\n",
      "        [3.6383, 3.7827, 3.7347, 3.7396, 3.5451],\n",
      "        [3.6933, 3.5454, 3.5751, 3.6433, 3.6842],\n",
      "        [3.4820, 3.5954, 3.5148, 3.5856, 3.5269],\n",
      "        [3.3199, 3.4624, 3.4663, 3.4176, 3.4027],\n",
      "        [3.6849, 3.8321, 3.7812, 3.9235, 3.7106],\n",
      "        [3.4877, 3.5649, 3.5463, 3.5631, 3.4974],\n",
      "        [3.3987, 3.6019, 3.6106, 3.5524, 3.4892],\n",
      "        [3.6342, 3.9031, 3.7764, 3.8157, 3.8102],\n",
      "        [3.4906, 3.4418, 3.5245, 3.5852, 3.4392],\n",
      "        [3.5263, 3.6218, 3.6370, 3.6965, 3.6446],\n",
      "        [3.6959, 3.8307, 3.6963, 3.9251, 3.7501],\n",
      "        [3.5286, 3.6325, 3.5122, 3.6725, 3.5453],\n",
      "        [3.3530, 3.4897, 3.4836, 3.4517, 3.4316],\n",
      "        [3.5696, 3.6141, 3.6733, 3.5849, 3.4169],\n",
      "        [3.5381, 3.7594, 3.7183, 3.6089, 3.6759],\n",
      "        [3.6959, 3.8307, 3.6963, 3.9251, 3.7501],\n",
      "        [3.5295, 3.6111, 3.5538, 3.6713, 3.5353],\n",
      "        [3.5524, 3.5602, 3.6839, 3.6820, 3.6008],\n",
      "        [3.5172, 3.7080, 3.7210, 3.6747, 3.6113],\n",
      "        [3.5286, 3.6325, 3.5122, 3.6725, 3.5453],\n",
      "        [3.6435, 3.5935, 3.7046, 3.6278, 3.5697],\n",
      "        [3.5412, 3.5180, 3.6554, 3.6281, 3.5534],\n",
      "        [3.6242, 3.8616, 3.7487, 3.7985, 3.7992],\n",
      "        [3.5915, 3.5879, 3.7355, 3.7275, 3.6487],\n",
      "        [3.4619, 3.5755, 3.5103, 3.5810, 3.5184],\n",
      "        [3.6240, 3.7150, 3.8357, 3.7740, 3.7257],\n",
      "        [3.5566, 3.5145, 3.6764, 3.6746, 3.6731],\n",
      "        [3.4150, 3.4883, 3.5605, 3.5516, 3.4554],\n",
      "        [3.6997, 3.8245, 3.8177, 3.7625, 3.5939],\n",
      "        [3.5886, 3.6620, 3.6554, 3.7551, 3.6898],\n",
      "        [3.6804, 3.6591, 3.7300, 3.7047, 3.5258],\n",
      "        [3.6926, 3.8459, 3.6664, 3.7654, 3.7206],\n",
      "        [3.4855, 3.6155, 3.7141, 3.7035, 3.6918],\n",
      "        [3.7836, 3.8445, 3.8734, 3.8734, 3.9704],\n",
      "        [3.7348, 3.7921, 3.8324, 3.9491, 3.6862],\n",
      "        [3.6769, 3.6181, 3.6980, 3.9073, 3.6141],\n",
      "        [3.6778, 3.7821, 3.8250, 3.8256, 3.7071],\n",
      "        [3.6653, 3.9621, 3.8510, 3.8600, 3.8860],\n",
      "        [3.6908, 3.7740, 3.8326, 3.7581, 3.5796],\n",
      "        [3.9247, 3.8222, 3.9416, 4.1096, 3.8784],\n",
      "        [3.7789, 3.7707, 3.7721, 3.8273, 3.7936],\n",
      "        [3.6929, 3.8946, 3.7301, 3.8222, 3.7247],\n",
      "        [3.6450, 3.6747, 3.7003, 3.7643, 3.7218],\n",
      "        [3.6613, 3.6265, 3.6881, 3.6123, 3.4658],\n",
      "        [3.4464, 3.5569, 3.4828, 3.6199, 3.4878]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6296, 3.7575, 3.7772, 3.8411, 3.7200],\n",
      "        [3.3927, 3.5763, 3.7495, 3.5520, 3.6410],\n",
      "        [3.7546, 3.6896, 3.7836, 3.8674, 3.6820],\n",
      "        [3.5860, 3.5545, 3.7138, 3.6824, 3.6281],\n",
      "        [3.6001, 3.5173, 3.6427, 3.6694, 3.5253],\n",
      "        [3.4060, 3.5599, 3.5964, 3.5561, 3.4857],\n",
      "        [3.5744, 3.9110, 3.8293, 3.7536, 3.6386],\n",
      "        [3.4391, 3.4958, 3.4753, 3.6134, 3.3850],\n",
      "        [3.7309, 3.7703, 3.7826, 3.8244, 3.8149],\n",
      "        [3.6793, 3.7839, 3.8283, 3.8260, 3.7085],\n",
      "        [3.4686, 3.5487, 3.6031, 3.5525, 3.5132],\n",
      "        [3.5257, 3.5796, 3.5676, 3.5823, 3.5482],\n",
      "        [4.0111, 3.8530, 3.8824, 4.1076, 3.9440],\n",
      "        [3.4198, 3.4828, 3.5617, 3.5588, 3.4562],\n",
      "        [3.4560, 3.4706, 3.6390, 3.5894, 3.5088],\n",
      "        [3.5499, 3.6521, 3.6466, 3.8142, 3.5663],\n",
      "        [3.6945, 3.8963, 3.7335, 3.8227, 3.7262],\n",
      "        [3.5610, 3.5628, 3.6559, 3.6527, 3.6337],\n",
      "        [3.6353, 3.6281, 3.7758, 3.7550, 3.6696],\n",
      "        [3.6551, 3.7495, 3.7580, 3.8283, 3.7598],\n",
      "        [3.5182, 3.6141, 3.5060, 3.6457, 3.5255],\n",
      "        [3.5862, 3.5296, 3.7631, 3.7616, 3.5982],\n",
      "        [3.2554, 3.4140, 3.5081, 3.4374, 3.4343],\n",
      "        [4.2160, 4.3346, 4.0143, 4.1071, 3.8881],\n",
      "        [3.4467, 3.4295, 3.5275, 3.5801, 3.4338],\n",
      "        [3.6756, 3.6900, 3.7570, 3.7181, 3.7879],\n",
      "        [3.4601, 3.7694, 3.6656, 3.5119, 3.6824],\n",
      "        [3.6699, 3.6904, 3.5832, 3.8032, 3.7390],\n",
      "        [3.5448, 3.6426, 3.5201, 3.6843, 3.5584],\n",
      "        [3.6676, 3.7211, 3.7637, 3.7887, 3.7856],\n",
      "        [3.7405, 3.9873, 3.8995, 3.8999, 3.8737],\n",
      "        [3.5271, 3.5667, 3.6439, 3.6656, 3.5695],\n",
      "        [3.6423, 3.5477, 3.8785, 3.7599, 3.7184],\n",
      "        [3.8946, 4.0193, 3.8161, 3.8200, 3.7484],\n",
      "        [3.7642, 3.7549, 3.8187, 3.9239, 3.7361],\n",
      "        [3.5863, 3.7963, 3.6289, 3.7294, 3.6324],\n",
      "        [3.3451, 3.5629, 3.3991, 3.5603, 3.3737],\n",
      "        [3.5658, 3.5834, 3.7441, 3.6974, 3.6380],\n",
      "        [3.3546, 3.4894, 3.3880, 3.5429, 3.3907],\n",
      "        [3.7704, 3.8207, 3.8502, 3.8588, 3.9453],\n",
      "        [3.7697, 3.7846, 3.9432, 3.7709, 3.5722],\n",
      "        [3.5320, 3.6056, 3.6390, 3.6714, 3.6867],\n",
      "        [3.4300, 3.4688, 3.5538, 3.5731, 3.4542],\n",
      "        [3.6024, 3.5312, 3.6329, 3.6384, 3.6259],\n",
      "        [3.4830, 3.5014, 3.6619, 3.6240, 3.5277],\n",
      "        [3.4026, 3.5381, 3.5071, 3.5077, 3.4819],\n",
      "        [3.7982, 3.8814, 3.9264, 4.0586, 4.0760],\n",
      "        [4.1641, 4.2834, 3.9528, 4.0242, 3.8416],\n",
      "        [3.7070, 3.8379, 3.8377, 3.7899, 3.6087],\n",
      "        [3.4358, 3.4400, 3.5315, 3.5774, 3.4361],\n",
      "        [3.3463, 3.4844, 3.4849, 3.4382, 3.4279],\n",
      "        [3.6347, 3.7456, 3.6266, 3.7534, 3.6666],\n",
      "        [3.5955, 3.5497, 3.6887, 3.6740, 3.6394],\n",
      "        [3.5977, 3.6727, 3.6877, 3.7113, 3.7266],\n",
      "        [3.6702, 3.6993, 3.7177, 3.7056, 3.4532],\n",
      "        [3.5672, 3.5818, 3.6888, 3.7002, 3.6166],\n",
      "        [3.4550, 3.4709, 3.5703, 3.5885, 3.4423],\n",
      "        [3.5353, 3.5688, 3.7922, 3.5212, 3.7401],\n",
      "        [3.4251, 3.4595, 3.5448, 3.5638, 3.4453],\n",
      "        [3.6527, 3.6094, 3.7186, 3.6301, 3.5832],\n",
      "        [3.6976, 3.8307, 3.7003, 3.9208, 3.7503],\n",
      "        [3.7912, 3.7895, 3.8414, 3.9578, 3.9694],\n",
      "        [3.9986, 4.0759, 3.7214, 3.8922, 3.6828],\n",
      "        [3.6198, 3.6124, 3.7566, 3.7389, 3.6565]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7652, 3.7563, 3.8214, 3.9243, 3.7371],\n",
      "        [3.7969, 3.6276, 3.7110, 4.0828, 3.8451],\n",
      "        [3.7086, 3.7544, 3.8229, 3.7584, 3.5212],\n",
      "        [3.5268, 3.8033, 3.6843, 3.6609, 3.4963],\n",
      "        [3.6137, 3.8759, 3.8659, 3.8494, 3.8082],\n",
      "        [3.5483, 3.6528, 3.5268, 3.6969, 3.5665],\n",
      "        [3.5120, 3.5667, 3.5929, 3.5787, 3.5526],\n",
      "        [3.4838, 3.5027, 3.6644, 3.6242, 3.5288],\n",
      "        [3.3553, 3.4906, 3.3904, 3.5430, 3.3917],\n",
      "        [3.5264, 3.5808, 3.5701, 3.5824, 3.5493],\n",
      "        [3.6619, 3.7078, 3.6538, 3.7282, 3.6192],\n",
      "        [3.8045, 3.6476, 3.7030, 3.7851, 3.7448],\n",
      "        [3.5128, 3.5852, 3.5549, 3.5888, 3.5205],\n",
      "        [3.5818, 3.8886, 3.7132, 3.8254, 3.7500],\n",
      "        [3.7311, 3.8077, 3.7460, 3.7958, 3.7916],\n",
      "        [3.6538, 3.7928, 3.6646, 3.8791, 3.6978],\n",
      "        [3.8726, 3.9229, 3.8861, 3.9257, 3.8904],\n",
      "        [3.4228, 3.5514, 3.5120, 3.5269, 3.4944],\n",
      "        [3.5418, 3.5321, 3.6500, 3.6382, 3.5517],\n",
      "        [3.6004, 3.4124, 3.7552, 3.7021, 3.5899],\n",
      "        [3.6402, 3.6426, 3.6672, 3.8078, 3.6476],\n",
      "        [3.7837, 3.7872, 3.7914, 3.9114, 3.8877],\n",
      "        [3.4006, 3.5861, 3.6077, 3.5511, 3.4827],\n",
      "        [3.5746, 3.7438, 3.6527, 3.6783, 3.6704],\n",
      "        [3.5410, 3.5317, 3.6562, 3.6355, 3.5496],\n",
      "        [3.4721, 3.5335, 3.6169, 3.6460, 3.5394],\n",
      "        [3.7676, 3.7863, 3.7907, 3.8943, 3.8877],\n",
      "        [3.7446, 3.6688, 3.7539, 3.9372, 3.5933],\n",
      "        [3.9938, 4.0675, 3.7167, 3.8756, 3.6879],\n",
      "        [3.5810, 3.8212, 3.6447, 3.8321, 3.6773],\n",
      "        [3.4648, 3.5604, 3.6606, 3.6871, 3.5947],\n",
      "        [3.7171, 3.8666, 3.8222, 3.8350, 3.7036],\n",
      "        [3.5352, 3.5438, 3.6337, 3.6383, 3.5604],\n",
      "        [3.3887, 3.6485, 3.7543, 3.5493, 3.6050],\n",
      "        [3.3804, 3.4360, 3.5423, 3.5204, 3.3911],\n",
      "        [3.4740, 3.6356, 3.6164, 3.7445, 3.4811],\n",
      "        [3.3906, 3.5217, 3.5039, 3.4979, 3.4788],\n",
      "        [3.5316, 3.6493, 3.6700, 3.7635, 3.5640],\n",
      "        [3.5471, 3.7133, 3.7087, 3.7019, 3.5570],\n",
      "        [3.7555, 3.9005, 3.7965, 3.7134, 3.7653],\n",
      "        [3.5542, 3.4878, 3.6191, 3.5639, 3.4880],\n",
      "        [3.5757, 3.5675, 3.7129, 3.7149, 3.6373],\n",
      "        [3.7329, 3.8759, 3.6828, 3.7517, 3.7074],\n",
      "        [3.5306, 3.6275, 3.5243, 3.6447, 3.5615],\n",
      "        [3.8770, 3.6598, 3.7473, 4.1806, 3.9285],\n",
      "        [3.5491, 3.5798, 3.6631, 3.6802, 3.6015],\n",
      "        [3.5030, 3.5392, 3.6346, 3.6256, 3.5641],\n",
      "        [3.8250, 3.8656, 3.9178, 3.8654, 3.6484],\n",
      "        [3.4660, 3.8441, 3.7866, 3.7010, 3.7763],\n",
      "        [3.5931, 3.7292, 3.5826, 3.6488, 3.6130],\n",
      "        [3.7891, 3.9303, 3.9168, 3.8586, 3.6229],\n",
      "        [3.5524, 3.5463, 3.7119, 3.6933, 3.5918],\n",
      "        [3.4396, 3.4835, 3.5855, 3.5762, 3.4378],\n",
      "        [3.5588, 3.5551, 3.6636, 3.6519, 3.5775],\n",
      "        [3.7060, 3.6417, 3.6741, 3.9660, 3.7675],\n",
      "        [3.9043, 3.7190, 3.8701, 4.3075, 4.1098],\n",
      "        [3.5500, 3.5797, 3.6571, 3.6631, 3.5837],\n",
      "        [3.5488, 3.6441, 3.5161, 3.6834, 3.5537],\n",
      "        [3.4130, 3.6043, 3.6222, 3.5723, 3.5055],\n",
      "        [3.5945, 3.5897, 3.7309, 3.7047, 3.6364],\n",
      "        [3.7243, 3.6700, 3.6943, 3.9802, 3.7853],\n",
      "        [3.6790, 3.7644, 3.6933, 3.6553, 3.6488],\n",
      "        [3.5385, 3.6959, 3.7013, 3.6819, 3.6666],\n",
      "        [3.6809, 3.6539, 3.7385, 3.6880, 3.5404]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4472, 3.5913, 3.5413, 3.6371, 3.4949],\n",
      "        [3.5335, 3.6078, 3.6439, 3.6715, 3.6886],\n",
      "        [3.4032, 3.6421, 3.4697, 3.6336, 3.4375],\n",
      "        [3.6926, 3.8277, 3.6983, 3.9166, 3.7438],\n",
      "        [3.5311, 3.6301, 3.5134, 3.6662, 3.5389],\n",
      "        [3.5682, 3.5671, 3.7087, 3.6973, 3.6212],\n",
      "        [3.5397, 3.6427, 3.6593, 3.6107, 3.4983],\n",
      "        [3.5969, 3.5518, 3.6931, 3.6741, 3.6413],\n",
      "        [3.6021, 3.8190, 3.6636, 3.8473, 3.6862],\n",
      "        [3.4204, 3.5133, 3.5807, 3.5599, 3.4781],\n",
      "        [3.7259, 3.7051, 3.9053, 3.7502, 3.5572],\n",
      "        [3.6463, 3.5972, 3.7122, 3.6283, 3.5731],\n",
      "        [3.4485, 3.6067, 3.5100, 3.6301, 3.4968],\n",
      "        [3.6168, 3.6678, 3.7148, 3.6972, 3.7187],\n",
      "        [3.3206, 3.4551, 3.4657, 3.4128, 3.3954],\n",
      "        [3.7419, 3.9898, 3.9045, 3.9001, 3.8756],\n",
      "        [3.8243, 3.7933, 3.7125, 3.8791, 3.8177],\n",
      "        [3.5579, 3.6607, 3.5284, 3.7160, 3.5757],\n",
      "        [3.7059, 3.7900, 3.7141, 3.7386, 3.6724],\n",
      "        [3.6571, 3.6024, 3.7228, 3.6269, 3.6029],\n",
      "        [3.7874, 3.9198, 3.8335, 3.7355, 3.7986],\n",
      "        [3.8112, 3.7903, 3.8530, 3.9384, 3.7807],\n",
      "        [3.6963, 3.7812, 3.7144, 3.6914, 3.6642],\n",
      "        [3.3847, 3.3889, 3.5114, 3.5803, 3.4251],\n",
      "        [3.5431, 3.6199, 3.5786, 3.6870, 3.6761],\n",
      "        [3.5151, 3.5258, 3.6401, 3.6044, 3.5387],\n",
      "        [3.9025, 3.7141, 3.8640, 4.3032, 4.1022],\n",
      "        [3.8840, 3.7573, 3.8858, 4.0296, 3.8068],\n",
      "        [3.3464, 3.5649, 3.4033, 3.5603, 3.3754],\n",
      "        [3.7041, 3.7807, 3.8727, 3.8646, 3.8206],\n",
      "        [3.7134, 3.8865, 3.7549, 3.8199, 3.7356],\n",
      "        [3.6623, 3.6968, 3.5863, 3.7219, 3.7145],\n",
      "        [3.5537, 3.6619, 3.5357, 3.6967, 3.5794],\n",
      "        [3.4499, 3.4722, 3.4533, 3.6173, 3.4400],\n",
      "        [3.7531, 3.7953, 3.8595, 3.9630, 3.6935],\n",
      "        [3.6217, 3.6247, 3.7758, 3.7407, 3.6626],\n",
      "        [4.0375, 4.1504, 3.8472, 3.9215, 3.7441],\n",
      "        [3.5758, 3.9135, 3.8348, 3.7538, 3.6403],\n",
      "        [3.4159, 3.5059, 3.5761, 3.5521, 3.4630],\n",
      "        [3.5681, 3.6525, 3.6414, 3.7873, 3.6088],\n",
      "        [3.4569, 3.5306, 3.6265, 3.6234, 3.4616],\n",
      "        [3.4646, 3.6494, 3.6377, 3.5242, 3.4906],\n",
      "        [3.5758, 3.5422, 3.7116, 3.7119, 3.6884],\n",
      "        [3.6800, 3.6362, 3.7299, 3.7591, 3.6153],\n",
      "        [3.7081, 3.7362, 3.6147, 3.8319, 3.7591],\n",
      "        [3.5292, 3.8639, 3.7098, 3.7886, 3.7511],\n",
      "        [3.5888, 3.7387, 3.6141, 3.6449, 3.6330],\n",
      "        [3.3777, 3.3752, 3.5049, 3.5626, 3.4182],\n",
      "        [3.4318, 3.4182, 3.5182, 3.5659, 3.4219],\n",
      "        [3.9295, 4.0205, 3.7144, 3.8327, 3.7067],\n",
      "        [3.6964, 3.8310, 3.6984, 3.9160, 3.7419],\n",
      "        [3.6486, 3.5956, 3.8156, 3.8198, 3.6038],\n",
      "        [3.6222, 3.6979, 3.7181, 3.7164, 3.7560],\n",
      "        [3.4068, 3.5285, 3.5882, 3.5503, 3.4662],\n",
      "        [3.3999, 3.5719, 3.6047, 3.5526, 3.4774],\n",
      "        [3.5742, 3.6622, 3.6719, 3.6610, 3.6169],\n",
      "        [3.5699, 3.5729, 3.6545, 3.6493, 3.6467],\n",
      "        [3.5547, 3.4887, 3.6211, 3.5638, 3.4888],\n",
      "        [3.3978, 3.4505, 3.5505, 3.5285, 3.4201],\n",
      "        [3.6775, 3.7604, 3.8681, 3.8358, 3.7660],\n",
      "        [3.8175, 3.7951, 3.8459, 3.9685, 3.7697],\n",
      "        [3.7230, 3.5200, 3.5743, 3.6398, 3.6784],\n",
      "        [3.5530, 3.5471, 3.7140, 3.6932, 3.5926],\n",
      "        [3.3984, 3.5225, 3.5066, 3.5017, 3.4620]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6664, 3.7736, 3.8078, 3.7865, 3.6962],\n",
      "        [3.3502, 3.4893, 3.4885, 3.4437, 3.4385],\n",
      "        [3.7000, 3.7129, 3.7540, 3.8062, 3.8160],\n",
      "        [3.7505, 3.7805, 3.8331, 3.8842, 3.9016],\n",
      "        [3.7317, 3.8865, 3.8514, 3.8445, 3.7205],\n",
      "        [3.4412, 3.7143, 3.5451, 3.4234, 3.5833],\n",
      "        [3.4503, 3.5612, 3.4918, 3.6200, 3.4922],\n",
      "        [3.6857, 3.7042, 3.7330, 3.7209, 3.4714],\n",
      "        [3.4182, 3.6434, 3.6496, 3.5692, 3.5220],\n",
      "        [3.6765, 3.7628, 3.6852, 3.7950, 3.7451],\n",
      "        [3.5482, 3.5146, 3.6762, 3.5666, 3.6207],\n",
      "        [4.0392, 4.0126, 3.8942, 4.2468, 3.8427],\n",
      "        [3.7875, 3.9355, 3.9138, 3.8648, 3.6111],\n",
      "        [3.5285, 3.6368, 3.5310, 3.6586, 3.5580],\n",
      "        [3.4242, 3.6507, 3.6540, 3.5861, 3.5388],\n",
      "        [3.5732, 3.6798, 3.5403, 3.7236, 3.5886],\n",
      "        [4.1681, 4.2868, 3.9591, 4.0241, 3.8453],\n",
      "        [3.4274, 3.5017, 3.5779, 3.5643, 3.4767],\n",
      "        [3.5560, 3.7353, 3.6740, 3.6322, 3.6589],\n",
      "        [3.5832, 3.5549, 3.7065, 3.6827, 3.5822],\n",
      "        [3.4870, 3.5204, 3.6442, 3.6416, 3.6305],\n",
      "        [3.7039, 3.8290, 3.8276, 3.7628, 3.5988],\n",
      "        [3.4498, 3.4483, 3.5408, 3.5825, 3.4479],\n",
      "        [3.7292, 3.7680, 3.7979, 3.7909, 3.8121],\n",
      "        [3.5770, 3.5429, 3.7131, 3.7116, 3.6898],\n",
      "        [3.3720, 3.4225, 3.5332, 3.4982, 3.3808],\n",
      "        [3.4221, 3.4995, 3.5777, 3.5634, 3.4744],\n",
      "        [3.7376, 3.8303, 3.8389, 3.7978, 3.5916],\n",
      "        [3.4490, 3.4644, 3.5554, 3.5765, 3.4584],\n",
      "        [3.7395, 3.8061, 3.8157, 3.7519, 3.7332],\n",
      "        [3.5592, 3.7162, 3.7078, 3.6994, 3.5567],\n",
      "        [3.5754, 3.6628, 3.6733, 3.6606, 3.6184],\n",
      "        [3.6559, 3.7842, 3.7507, 3.7456, 3.5550],\n",
      "        [3.8342, 3.8205, 3.8815, 3.9411, 3.7824],\n",
      "        [3.4868, 3.4605, 3.5653, 3.6011, 3.4517],\n",
      "        [3.5642, 3.6111, 3.6753, 3.6596, 3.7599],\n",
      "        [3.6060, 3.8284, 3.6737, 3.8500, 3.6940],\n",
      "        [3.8748, 3.9246, 3.8896, 3.9254, 3.8929],\n",
      "        [3.8245, 3.8858, 3.7821, 3.8825, 3.8838],\n",
      "        [3.8788, 3.8309, 3.7753, 4.0914, 3.8336],\n",
      "        [3.5481, 3.6001, 3.6119, 3.7211, 3.6035],\n",
      "        [3.4497, 3.6074, 3.5115, 3.6298, 3.4982],\n",
      "        [3.5427, 3.5831, 3.6593, 3.6720, 3.5823],\n",
      "        [3.5834, 3.5633, 3.7307, 3.7142, 3.6623],\n",
      "        [3.9838, 4.0863, 3.8615, 3.8873, 3.7829],\n",
      "        [3.5294, 3.5401, 3.5952, 3.6889, 3.4986],\n",
      "        [3.4019, 3.5512, 3.5952, 3.5461, 3.4715],\n",
      "        [3.5497, 3.7174, 3.6386, 3.6872, 3.6505],\n",
      "        [3.6891, 3.6793, 3.7453, 3.7135, 3.5307],\n",
      "        [3.5888, 3.7990, 3.6355, 3.7291, 3.6356],\n",
      "        [3.4365, 3.5611, 3.5156, 3.5406, 3.4937],\n",
      "        [3.4769, 3.4832, 3.5781, 3.6020, 3.4592],\n",
      "        [3.5285, 3.6315, 3.6466, 3.7106, 3.6258],\n",
      "        [3.5522, 3.6084, 3.6646, 3.6624, 3.7357],\n",
      "        [3.7393, 3.6046, 3.6974, 3.7332, 3.6719],\n",
      "        [3.4314, 3.4993, 3.5387, 3.5581, 3.4738],\n",
      "        [3.6781, 3.7266, 3.7378, 3.8890, 3.6662],\n",
      "        [3.4037, 3.6033, 3.6201, 3.5528, 3.4936],\n",
      "        [3.4228, 3.4914, 3.5710, 3.5542, 3.4617],\n",
      "        [3.5670, 3.6542, 3.6846, 3.6567, 3.5048],\n",
      "        [3.5101, 3.5336, 3.5967, 3.6728, 3.4951],\n",
      "        [3.5522, 3.6084, 3.6646, 3.6624, 3.7357],\n",
      "        [3.6619, 3.9041, 3.7561, 3.8176, 3.7348],\n",
      "        [3.4920, 3.6391, 3.6400, 3.7434, 3.5007]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7051, 3.8986, 3.8528, 3.8732, 3.8508],\n",
      "        [3.6284, 3.7200, 3.8519, 3.7737, 3.7316],\n",
      "        [3.4087, 3.5534, 3.5308, 3.5637, 3.4665],\n",
      "        [3.4969, 3.6075, 3.5242, 3.6153, 3.5287],\n",
      "        [3.7080, 3.8476, 3.7391, 3.8183, 3.7209],\n",
      "        [3.5399, 3.5837, 3.6666, 3.6749, 3.5897],\n",
      "        [3.5570, 3.6633, 3.5399, 3.6995, 3.5743],\n",
      "        [3.7981, 3.8092, 3.9162, 3.9979, 3.7183],\n",
      "        [3.5468, 3.5592, 3.6552, 3.6434, 3.5704],\n",
      "        [3.4258, 3.4746, 3.5673, 3.5562, 3.4543],\n",
      "        [3.6532, 3.6560, 3.6980, 3.7235, 3.6036],\n",
      "        [3.3067, 3.4639, 3.5425, 3.4726, 3.4466],\n",
      "        [3.6855, 3.6639, 3.7464, 3.7044, 3.5319],\n",
      "        [3.6375, 3.7827, 3.6934, 3.7875, 3.6512],\n",
      "        [3.3832, 3.4742, 3.4429, 3.5640, 3.3926],\n",
      "        [3.3729, 3.4230, 3.5398, 3.4976, 3.3818],\n",
      "        [3.4631, 3.7083, 3.6779, 3.6624, 3.7332],\n",
      "        [3.4254, 3.5533, 3.5223, 3.5258, 3.4975],\n",
      "        [3.6976, 3.7133, 3.7527, 3.7317, 3.4951],\n",
      "        [4.1443, 4.3046, 3.9651, 4.0558, 3.8542],\n",
      "        [3.4215, 3.4870, 3.5733, 3.5543, 3.4614],\n",
      "        [3.4384, 3.5609, 3.5190, 3.5465, 3.4935],\n",
      "        [3.8983, 3.8048, 3.8453, 3.9550, 3.8482],\n",
      "        [3.5365, 3.5613, 3.6495, 3.6484, 3.5690],\n",
      "        [3.6546, 3.6758, 3.7467, 3.6994, 3.7649],\n",
      "        [3.7967, 3.9318, 3.8977, 3.9410, 3.8634],\n",
      "        [3.7008, 3.8355, 3.7145, 3.9246, 3.7561],\n",
      "        [3.7103, 3.7906, 3.8633, 3.7733, 3.5875],\n",
      "        [3.7556, 3.7965, 3.8693, 3.9622, 3.6963],\n",
      "        [3.5302, 3.7971, 3.7913, 3.6015, 3.7070],\n",
      "        [3.5399, 3.5749, 3.6593, 3.6624, 3.5765],\n",
      "        [3.5249, 3.6081, 3.6464, 3.6768, 3.6655],\n",
      "        [3.6584, 3.6643, 3.8150, 3.8017, 3.6349],\n",
      "        [3.7710, 3.6779, 3.7300, 3.8183, 3.7746],\n",
      "        [3.4640, 3.4038, 3.6405, 3.4064, 3.5849],\n",
      "        [3.5508, 3.6547, 3.5381, 3.6958, 3.5697],\n",
      "        [3.5009, 3.5432, 3.6589, 3.6431, 3.5615],\n",
      "        [3.4543, 3.4775, 3.4639, 3.6130, 3.3741],\n",
      "        [3.6622, 3.7098, 3.7117, 3.8772, 3.6435],\n",
      "        [3.4515, 3.4682, 3.5634, 3.5773, 3.4614],\n",
      "        [3.8384, 3.7699, 3.8690, 4.0505, 3.7042],\n",
      "        [3.8517, 3.8530, 3.8800, 3.9285, 4.0227],\n",
      "        [3.5332, 3.6294, 3.5354, 3.6437, 3.5647],\n",
      "        [3.6019, 3.8187, 3.6161, 3.7205, 3.6144],\n",
      "        [3.4530, 3.4825, 3.5877, 3.5829, 3.4477],\n",
      "        [3.5068, 3.6103, 3.5345, 3.6350, 3.5439],\n",
      "        [3.5291, 3.6549, 3.6750, 3.7609, 3.5485],\n",
      "        [3.6171, 3.5625, 3.6957, 3.6730, 3.6524],\n",
      "        [3.7904, 3.8059, 3.9755, 3.8012, 3.6056],\n",
      "        [3.9308, 3.8752, 3.8529, 3.9967, 3.8980],\n",
      "        [3.6646, 3.7098, 3.6643, 3.7271, 3.6225],\n",
      "        [3.3989, 3.5684, 3.6112, 3.5504, 3.4735],\n",
      "        [3.8743, 3.7774, 3.8472, 3.9279, 3.8449],\n",
      "        [3.5381, 3.6382, 3.5358, 3.6650, 3.5623],\n",
      "        [3.7542, 3.8558, 3.7288, 3.7963, 3.7960],\n",
      "        [3.5191, 3.6183, 3.5318, 3.6251, 3.5550],\n",
      "        [3.3722, 3.4075, 3.5258, 3.4791, 3.3800],\n",
      "        [4.0203, 3.7615, 3.9667, 4.4034, 4.1965],\n",
      "        [3.7054, 3.7959, 3.7246, 3.7476, 3.6792],\n",
      "        [3.3246, 3.4671, 3.4811, 3.4171, 3.4081],\n",
      "        [3.6228, 3.8381, 3.7396, 3.7859, 3.7975],\n",
      "        [3.5730, 3.6716, 3.7754, 3.7208, 3.6669],\n",
      "        [3.7008, 3.8355, 3.7145, 3.9246, 3.7561],\n",
      "        [3.5549, 3.5815, 3.7621, 3.5835, 3.7452]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4045, 3.5300, 3.5971, 3.5448, 3.4699],\n",
      "        [3.6607, 3.6680, 3.5632, 3.7769, 3.7297],\n",
      "        [3.5340, 3.6918, 3.7049, 3.6714, 3.6502],\n",
      "        [3.5541, 3.6480, 3.6824, 3.6291, 3.5109],\n",
      "        [3.4240, 3.6464, 3.6586, 3.5822, 3.5400],\n",
      "        [3.7393, 3.6659, 3.7648, 3.9262, 3.5887],\n",
      "        [3.8608, 3.6643, 3.7537, 4.1420, 3.9045],\n",
      "        [3.4778, 3.5445, 3.6158, 3.5593, 3.5185],\n",
      "        [3.6806, 3.7793, 3.8303, 3.7252, 3.5700],\n",
      "        [3.7024, 3.8356, 3.7213, 3.9238, 3.7578],\n",
      "        [3.7219, 3.8237, 3.8351, 3.7792, 3.5825],\n",
      "        [3.5410, 3.5627, 3.6684, 3.6646, 3.5850],\n",
      "        [3.6138, 3.5442, 3.6680, 3.6522, 3.6423],\n",
      "        [3.4880, 3.5542, 3.4504, 3.6725, 3.4270],\n",
      "        [3.6985, 3.7970, 3.8046, 3.9079, 3.6882],\n",
      "        [3.7908, 3.5487, 3.7524, 3.9971, 3.9158],\n",
      "        [3.4124, 3.6002, 3.6334, 3.5543, 3.4935],\n",
      "        [3.7017, 3.7878, 3.7117, 3.8199, 3.6955],\n",
      "        [3.3522, 3.4857, 3.4998, 3.4427, 3.4368],\n",
      "        [3.5503, 3.5516, 3.6689, 3.6466, 3.5730],\n",
      "        [3.5042, 3.6086, 3.5303, 3.6129, 3.5349],\n",
      "        [3.6468, 3.6870, 3.7853, 3.7558, 3.6375],\n",
      "        [3.9102, 3.8238, 3.8477, 3.9659, 3.8613],\n",
      "        [3.5537, 3.5501, 3.6680, 3.6438, 3.5738],\n",
      "        [3.5422, 3.6446, 3.5384, 3.6845, 3.5643],\n",
      "        [3.5628, 3.5635, 3.6597, 3.6408, 3.6408],\n",
      "        [3.7537, 3.9304, 3.8190, 3.9469, 3.8221],\n",
      "        [3.5737, 3.5712, 3.6902, 3.6627, 3.6407],\n",
      "        [3.6106, 3.5516, 3.6854, 3.6947, 3.5926],\n",
      "        [3.5337, 3.6337, 3.5447, 3.6652, 3.5610],\n",
      "        [3.4598, 3.4741, 3.5894, 3.5868, 3.4481],\n",
      "        [4.0064, 4.0801, 3.7405, 3.8911, 3.6896],\n",
      "        [3.4427, 3.5683, 3.5311, 3.5463, 3.5059],\n",
      "        [3.5389, 3.6397, 3.5425, 3.6731, 3.5603],\n",
      "        [3.6301, 3.6248, 3.7926, 3.7401, 3.6695],\n",
      "        [3.4102, 3.5535, 3.5370, 3.5629, 3.4681],\n",
      "        [3.5788, 3.7036, 3.5400, 3.6301, 3.5780],\n",
      "        [3.8927, 3.6995, 3.8872, 3.9940, 3.8085],\n",
      "        [3.8802, 3.8590, 3.9161, 4.0242, 3.8518],\n",
      "        [3.5309, 3.5002, 3.6640, 3.6205, 3.5331],\n",
      "        [3.8027, 3.9816, 3.8418, 3.9594, 3.9128],\n",
      "        [3.8224, 3.7959, 3.8647, 3.9941, 3.9885],\n",
      "        [3.8816, 3.6622, 3.7656, 4.1790, 3.9340],\n",
      "        [3.5889, 3.5693, 3.7255, 3.6603, 3.5967],\n",
      "        [3.4384, 3.5715, 3.5286, 3.5468, 3.5046],\n",
      "        [3.5192, 3.6266, 3.5440, 3.6398, 3.5492],\n",
      "        [3.7153, 3.6485, 3.7144, 3.6571, 3.5331],\n",
      "        [4.0348, 4.1618, 4.1538, 4.2092, 4.2738],\n",
      "        [3.5536, 3.5879, 3.6803, 3.6765, 3.6022],\n",
      "        [3.4577, 3.4866, 3.5995, 3.5848, 3.4523],\n",
      "        [3.5355, 3.6295, 3.6204, 3.6224, 3.5802],\n",
      "        [3.6677, 3.6917, 3.7701, 3.7365, 3.7575],\n",
      "        [3.6837, 3.7883, 3.7907, 3.7779, 3.5812],\n",
      "        [3.5075, 3.5301, 3.6522, 3.6111, 3.5477],\n",
      "        [3.6132, 3.5526, 3.6948, 3.6698, 3.6489],\n",
      "        [3.4660, 3.5578, 3.5306, 3.6118, 3.4864],\n",
      "        [3.5677, 3.9092, 3.8450, 3.7501, 3.6339],\n",
      "        [3.4573, 3.4733, 3.5775, 3.5931, 3.4789],\n",
      "        [3.5684, 3.6709, 3.5594, 3.7129, 3.5866],\n",
      "        [3.4532, 3.6719, 3.8291, 3.6399, 3.6624],\n",
      "        [3.6303, 3.8681, 3.7704, 3.7946, 3.8066],\n",
      "        [3.5900, 3.4786, 3.6536, 3.8089, 3.4934],\n",
      "        [3.5666, 3.7058, 3.6027, 3.8063, 3.5378],\n",
      "        [3.6174, 3.5489, 3.6892, 3.6846, 3.5851]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6311, 3.7269, 3.6895, 3.7611, 3.6941],\n",
      "        [3.5560, 3.7107, 3.6560, 3.7003, 3.6628],\n",
      "        [3.5166, 3.5344, 3.6152, 3.6770, 3.5073],\n",
      "        [3.4461, 3.4630, 3.5677, 3.5716, 3.4552],\n",
      "        [3.3718, 3.4139, 3.5453, 3.4845, 3.3849],\n",
      "        [3.6845, 3.7664, 3.7163, 3.6527, 3.6555],\n",
      "        [3.6493, 3.5996, 3.7311, 3.6303, 3.5654],\n",
      "        [3.4305, 3.5021, 3.5964, 3.5618, 3.4808],\n",
      "        [3.9598, 3.8025, 3.9519, 4.0958, 3.8810],\n",
      "        [3.6705, 3.6220, 3.7424, 3.7319, 3.6183],\n",
      "        [3.7726, 3.9453, 3.8434, 3.9633, 3.8413],\n",
      "        [3.5801, 3.7931, 3.7237, 3.6902, 3.5105],\n",
      "        [3.4766, 3.5552, 3.6718, 3.6635, 3.5820],\n",
      "        [3.7020, 3.7114, 3.6092, 3.8140, 3.7711],\n",
      "        [3.8048, 3.7685, 3.8977, 3.8984, 3.6354],\n",
      "        [3.4259, 3.4917, 3.5894, 3.5518, 3.4657],\n",
      "        [3.8290, 3.9407, 3.7142, 3.7770, 3.7117],\n",
      "        [3.9165, 4.0511, 3.8858, 3.8406, 3.8111],\n",
      "        [3.6165, 3.6325, 3.7621, 3.7322, 3.7470],\n",
      "        [3.8087, 3.8334, 3.8826, 3.8644, 3.8691],\n",
      "        [3.8888, 3.7080, 3.8833, 4.2829, 4.1083],\n",
      "        [4.1584, 4.3429, 3.9579, 4.0558, 3.8589],\n",
      "        [3.4354, 3.4718, 3.5786, 3.5705, 3.4615],\n",
      "        [3.7107, 3.7912, 3.7355, 3.7359, 3.6783],\n",
      "        [3.5442, 3.6032, 3.6363, 3.6330, 3.5870],\n",
      "        [3.4476, 3.4424, 3.5566, 3.5787, 3.4485],\n",
      "        [3.7443, 3.9748, 3.8589, 3.9894, 3.8914],\n",
      "        [3.4569, 3.4804, 3.4734, 3.6117, 3.4207],\n",
      "        [3.6796, 3.7940, 3.8524, 3.8003, 3.6917],\n",
      "        [3.5310, 3.5568, 3.5412, 3.6086, 3.6241],\n",
      "        [3.8441, 3.7059, 3.8675, 3.9699, 3.7620],\n",
      "        [3.4155, 3.6359, 3.6576, 3.5608, 3.5206],\n",
      "        [4.0736, 4.0303, 3.9410, 4.2725, 3.8559],\n",
      "        [3.5673, 3.6354, 3.6043, 3.7373, 3.6045],\n",
      "        [3.4577, 3.5768, 3.5334, 3.5717, 3.5085],\n",
      "        [3.6433, 3.6503, 3.6524, 3.7880, 3.6559],\n",
      "        [3.7396, 3.7213, 3.8251, 3.8614, 3.5645],\n",
      "        [3.3751, 3.4229, 3.5503, 3.4958, 3.3848],\n",
      "        [3.5270, 3.4776, 3.6043, 3.6045, 3.6559],\n",
      "        [3.5466, 3.6912, 3.6040, 3.7739, 3.5309],\n",
      "        [3.3333, 3.4910, 3.5600, 3.4991, 3.4761],\n",
      "        [4.0518, 4.1570, 3.9465, 3.9453, 3.8546],\n",
      "        [3.6824, 3.7782, 3.6940, 3.7359, 3.7919],\n",
      "        [3.7196, 3.8556, 3.7655, 3.8104, 3.7362],\n",
      "        [3.7032, 3.8354, 3.7272, 3.9226, 3.7593],\n",
      "        [3.8700, 3.8675, 3.8140, 3.9296, 3.9073],\n",
      "        [3.9626, 3.8842, 3.9475, 4.0548, 3.9741],\n",
      "        [3.5730, 3.5681, 3.7289, 3.6944, 3.6271],\n",
      "        [4.0016, 4.0703, 3.7388, 3.8732, 3.6952],\n",
      "        [3.4884, 3.5464, 3.4284, 3.6730, 3.4052],\n",
      "        [3.5351, 3.7040, 3.6982, 3.6765, 3.6138],\n",
      "        [3.6143, 3.5988, 3.7907, 3.8315, 3.8273],\n",
      "        [3.7032, 3.8354, 3.7272, 3.9226, 3.7593],\n",
      "        [3.5396, 3.5787, 3.6731, 3.5415, 3.3847],\n",
      "        [3.7299, 3.8070, 3.8459, 3.9417, 3.6945],\n",
      "        [3.5508, 3.6488, 3.5458, 3.6781, 3.5616],\n",
      "        [3.4715, 3.8463, 3.8099, 3.6981, 3.7834],\n",
      "        [3.6761, 3.8103, 3.6996, 3.8867, 3.7174],\n",
      "        [3.5320, 3.5464, 3.6853, 3.6680, 3.6387],\n",
      "        [3.4315, 3.4747, 3.5764, 3.5519, 3.4490],\n",
      "        [3.5669, 3.4804, 3.6312, 3.5461, 3.4824],\n",
      "        [3.6879, 3.9760, 3.8546, 3.8654, 3.9137],\n",
      "        [3.4952, 3.5623, 3.5712, 3.6823, 3.5430],\n",
      "        [3.4618, 3.4739, 3.6634, 3.5866, 3.5163]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8033, 3.9837, 3.8538, 3.9573, 3.9202],\n",
      "        [3.7187, 3.8876, 3.7821, 3.8165, 3.7425],\n",
      "        [3.6417, 3.6691, 3.7138, 3.7169, 3.6319],\n",
      "        [3.6642, 3.8026, 3.6973, 3.7459, 3.6830],\n",
      "        [3.6344, 3.9398, 3.7426, 3.8974, 3.7909],\n",
      "        [3.4815, 3.5932, 3.5378, 3.5891, 3.5210],\n",
      "        [3.9487, 3.9230, 3.8835, 4.1112, 3.8279],\n",
      "        [3.4998, 3.5486, 3.6704, 3.6445, 3.5662],\n",
      "        [3.7179, 3.8589, 3.8663, 3.8614, 3.7151],\n",
      "        [4.0069, 3.8505, 3.9084, 4.1160, 3.9291],\n",
      "        [3.4082, 3.6429, 3.4931, 3.6303, 3.4439],\n",
      "        [3.5477, 3.5339, 3.6822, 3.6387, 3.5582],\n",
      "        [3.5599, 3.5855, 3.7676, 3.5962, 3.7357],\n",
      "        [3.4936, 3.6010, 3.5344, 3.6134, 3.5226],\n",
      "        [3.4487, 3.4356, 3.5514, 3.5838, 3.4559],\n",
      "        [3.8036, 3.7524, 3.8350, 4.0372, 3.7346],\n",
      "        [3.7563, 3.5374, 3.7462, 3.9470, 3.8885],\n",
      "        [3.3696, 3.5206, 3.5616, 3.5418, 3.4925],\n",
      "        [3.7585, 4.0261, 3.8311, 3.9925, 3.9032],\n",
      "        [3.5643, 3.5568, 3.6916, 3.6483, 3.5851],\n",
      "        [3.8366, 3.5326, 3.7639, 4.0531, 3.9523],\n",
      "        [3.3324, 3.4660, 3.4932, 3.4156, 3.4106],\n",
      "        [3.4264, 3.4915, 3.5939, 3.5512, 3.4667],\n",
      "        [3.8916, 3.7943, 3.8678, 3.9353, 3.8447],\n",
      "        [3.7084, 3.7940, 3.7292, 3.8191, 3.7096],\n",
      "        [3.6276, 3.6986, 3.7438, 3.7129, 3.7632],\n",
      "        [3.8831, 3.8316, 3.8092, 4.0883, 3.8394],\n",
      "        [3.7648, 3.7706, 3.8419, 3.8612, 3.9108],\n",
      "        [3.5386, 3.5479, 3.6598, 3.6372, 3.5677],\n",
      "        [4.0459, 3.9247, 3.9243, 4.1676, 4.0206],\n",
      "        [3.8823, 3.8528, 3.9340, 4.0278, 3.8607],\n",
      "        [3.5482, 3.5085, 3.6572, 3.5812, 3.5170],\n",
      "        [3.5170, 3.5599, 3.6046, 3.5668, 3.5665],\n",
      "        [3.4534, 3.6075, 3.5341, 3.6268, 3.5033],\n",
      "        [3.5392, 3.5609, 3.6667, 3.6459, 3.5732],\n",
      "        [3.9149, 3.9453, 4.0213, 4.1344, 4.1527],\n",
      "        [3.5276, 3.4773, 3.6085, 3.6039, 3.6570],\n",
      "        [3.4001, 3.5339, 3.5277, 3.4958, 3.4742],\n",
      "        [3.7806, 3.8629, 3.8862, 3.8753, 3.9378],\n",
      "        [3.8203, 3.8769, 3.8567, 3.8843, 3.8724],\n",
      "        [3.4462, 3.5366, 3.6485, 3.5923, 3.4808],\n",
      "        [3.5219, 3.6237, 3.5422, 3.6508, 3.5437],\n",
      "        [3.6188, 3.5486, 3.6996, 3.6829, 3.5876],\n",
      "        [3.6875, 3.7027, 3.7543, 3.7154, 3.4760],\n",
      "        [3.4933, 3.5476, 3.6611, 3.6455, 3.5618],\n",
      "        [3.4856, 3.6661, 3.5521, 3.6703, 3.4829],\n",
      "        [3.5471, 3.5426, 3.6761, 3.6397, 3.5701],\n",
      "        [3.9510, 4.0223, 3.9839, 4.1932, 3.9884],\n",
      "        [3.4551, 3.5299, 3.5175, 3.6192, 3.4850],\n",
      "        [3.9213, 3.7372, 3.9019, 4.3043, 4.1169],\n",
      "        [3.7204, 3.8611, 3.7328, 3.7784, 3.7571],\n",
      "        [3.4851, 3.5369, 3.6553, 3.6419, 3.5534],\n",
      "        [3.8043, 3.9307, 3.9219, 3.9481, 3.8765],\n",
      "        [3.4331, 3.6338, 3.7583, 3.5949, 3.6052],\n",
      "        [3.4913, 3.6019, 3.5411, 3.6018, 3.5297],\n",
      "        [3.5432, 3.5450, 3.6291, 3.6085, 3.6281],\n",
      "        [3.5768, 3.6755, 3.5588, 3.7152, 3.5858],\n",
      "        [3.4934, 3.4528, 3.5754, 3.6054, 3.4446],\n",
      "        [3.5676, 3.6076, 3.6469, 3.7971, 3.6249],\n",
      "        [3.4883, 3.4377, 3.5517, 3.5801, 3.4406],\n",
      "        [3.7385, 3.5109, 3.5838, 3.6342, 3.6928],\n",
      "        [3.7162, 3.7821, 3.8414, 3.8486, 3.6645],\n",
      "        [3.5269, 3.6428, 3.5549, 3.6549, 3.5622],\n",
      "        [3.7675, 3.6049, 3.7022, 3.7385, 3.7138]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5283, 3.6074, 3.6743, 3.6751, 3.6717],\n",
      "        [3.3739, 3.5071, 3.5286, 3.4652, 3.4648],\n",
      "        [3.5667, 3.5373, 3.7138, 3.6021, 3.6275],\n",
      "        [3.6820, 3.7262, 3.7733, 3.8866, 3.6733],\n",
      "        [3.6066, 3.6618, 3.7166, 3.6855, 3.6349],\n",
      "        [3.7076, 3.8105, 3.7520, 3.8198, 3.7145],\n",
      "        [3.8625, 3.6637, 3.7742, 4.1411, 3.9089],\n",
      "        [3.7038, 3.8347, 3.7425, 3.9229, 3.7621],\n",
      "        [3.6582, 3.6748, 3.7717, 3.6974, 3.7712],\n",
      "        [3.6059, 3.7351, 3.6210, 3.6558, 3.6212],\n",
      "        [3.4406, 3.5825, 3.5839, 3.6357, 3.4990],\n",
      "        [3.5428, 3.5740, 3.6865, 3.6607, 3.5824],\n",
      "        [3.4672, 3.4030, 3.6654, 3.4045, 3.5907],\n",
      "        [3.5577, 3.6000, 3.7103, 3.6802, 3.6143],\n",
      "        [3.5338, 3.6543, 3.7266, 3.7040, 3.5641],\n",
      "        [3.5493, 3.5222, 3.6981, 3.6259, 3.5652],\n",
      "        [3.7937, 3.8496, 3.9213, 3.8723, 3.9830],\n",
      "        [3.5277, 3.5278, 3.6134, 3.5867, 3.6090],\n",
      "        [3.7504, 3.6754, 3.7443, 3.6894, 3.5664],\n",
      "        [3.6122, 3.5330, 3.6901, 3.6751, 3.5455],\n",
      "        [3.6317, 3.6240, 3.8127, 3.7391, 3.6738],\n",
      "        [3.5327, 3.5456, 3.7000, 3.6682, 3.6415],\n",
      "        [3.5323, 3.6364, 3.5647, 3.6563, 3.5647],\n",
      "        [3.4949, 3.5552, 3.6694, 3.6524, 3.5630],\n",
      "        [3.5509, 3.7118, 3.6662, 3.6928, 3.6584],\n",
      "        [3.5415, 3.6327, 3.5517, 3.6635, 3.5500],\n",
      "        [3.6362, 3.5697, 3.7043, 3.6613, 3.6633],\n",
      "        [3.5275, 3.5577, 3.7922, 3.5252, 3.7287],\n",
      "        [3.4544, 3.4782, 3.4784, 3.6117, 3.3904],\n",
      "        [3.3373, 3.4654, 3.5019, 3.4307, 3.4261],\n",
      "        [3.5504, 3.7104, 3.7615, 3.6957, 3.5414],\n",
      "        [3.4812, 3.5890, 3.5494, 3.5858, 3.5330],\n",
      "        [3.5929, 3.5569, 3.7516, 3.6797, 3.6386],\n",
      "        [3.4589, 3.5820, 3.5543, 3.5678, 3.5215],\n",
      "        [3.5712, 3.6093, 3.6611, 3.7783, 3.6452],\n",
      "        [3.9680, 3.7499, 3.9351, 4.3423, 4.1212],\n",
      "        [3.7209, 3.7315, 3.7758, 3.8538, 3.8412],\n",
      "        [3.3858, 3.4371, 3.5756, 3.5177, 3.3999],\n",
      "        [3.4776, 3.5347, 3.6550, 3.6432, 3.5486],\n",
      "        [3.6623, 3.7530, 3.8069, 3.8269, 3.7703],\n",
      "        [3.5555, 3.5808, 3.6958, 3.6604, 3.5929],\n",
      "        [3.7207, 3.8607, 3.7448, 3.7796, 3.7589],\n",
      "        [3.4166, 3.5214, 3.7230, 3.5693, 3.5880],\n",
      "        [3.7651, 3.7702, 3.8534, 3.8625, 3.9126],\n",
      "        [3.7831, 3.7732, 3.8556, 3.8608, 3.9096],\n",
      "        [3.4695, 3.5744, 3.5391, 3.5715, 3.5076],\n",
      "        [3.5475, 3.5883, 3.6949, 3.6720, 3.5913],\n",
      "        [3.8737, 3.9388, 3.9104, 3.9314, 3.9360],\n",
      "        [3.3096, 3.4631, 3.5676, 3.4709, 3.4522],\n",
      "        [3.4223, 3.5074, 3.6148, 3.5527, 3.4731],\n",
      "        [3.4034, 3.5229, 3.5388, 3.4991, 3.4700],\n",
      "        [3.6652, 3.6305, 3.7302, 3.6054, 3.4716],\n",
      "        [3.5568, 3.5664, 3.7159, 3.6733, 3.6142],\n",
      "        [3.6913, 3.4827, 3.6004, 3.6559, 3.6331],\n",
      "        [3.5566, 3.6080, 3.6982, 3.6600, 3.7430],\n",
      "        [3.4123, 3.4582, 3.5846, 3.5310, 3.4481],\n",
      "        [3.5410, 3.6374, 3.5621, 3.6633, 3.5681],\n",
      "        [3.5558, 3.6470, 3.7001, 3.6280, 3.5152],\n",
      "        [3.7273, 3.5472, 3.7621, 3.9022, 3.8673],\n",
      "        [3.9934, 4.0659, 3.7666, 3.8764, 3.7055],\n",
      "        [3.8083, 3.9575, 3.9943, 3.9036, 3.6691],\n",
      "        [3.6392, 3.6970, 3.7599, 3.7088, 3.7781],\n",
      "        [3.6458, 3.5622, 3.9450, 3.7627, 3.7375],\n",
      "        [3.6373, 3.6935, 3.6668, 3.7506, 3.6621]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4022, 3.5921, 3.6578, 3.5602, 3.4979],\n",
      "        [3.4879, 3.5453, 3.6861, 3.6573, 3.5822],\n",
      "        [3.7767, 3.8415, 3.8416, 3.8423, 3.8205],\n",
      "        [3.5116, 3.8134, 3.8026, 3.7417, 3.7370],\n",
      "        [3.5435, 3.6049, 3.6968, 3.6626, 3.7194],\n",
      "        [3.6979, 3.8020, 3.7519, 3.7910, 3.6848],\n",
      "        [3.4644, 3.5520, 3.5600, 3.6101, 3.4966],\n",
      "        [3.6445, 3.8322, 3.7569, 3.8726, 3.7148],\n",
      "        [3.5798, 3.6623, 3.7134, 3.6599, 3.6270],\n",
      "        [3.5018, 3.6190, 3.7112, 3.6916, 3.5218],\n",
      "        [3.9457, 3.8336, 4.0035, 4.1017, 3.8900],\n",
      "        [3.4613, 3.4611, 3.5945, 3.5986, 3.4748],\n",
      "        [3.6379, 3.6673, 3.8027, 3.7421, 3.6595],\n",
      "        [3.5400, 3.6200, 3.6028, 3.6507, 3.5882],\n",
      "        [3.7287, 3.6550, 3.7509, 4.0073, 3.8132],\n",
      "        [3.4740, 3.4870, 3.6982, 3.6035, 3.5310],\n",
      "        [3.4417, 3.4424, 3.5802, 3.5769, 3.4473],\n",
      "        [4.0843, 4.1845, 3.9922, 3.9792, 3.8759],\n",
      "        [3.6912, 3.7084, 3.6395, 3.8055, 3.7557],\n",
      "        [3.8240, 3.7964, 3.8935, 3.9689, 3.7810],\n",
      "        [3.5598, 3.6627, 3.5766, 3.6998, 3.5814],\n",
      "        [3.5736, 3.6538, 3.6948, 3.7875, 3.6187],\n",
      "        [3.5574, 3.5903, 3.6392, 3.7165, 3.5746],\n",
      "        [3.5566, 3.6081, 3.7082, 3.6619, 3.7444],\n",
      "        [3.7912, 3.9359, 3.9601, 3.8646, 3.6193],\n",
      "        [3.6986, 3.8660, 3.7535, 3.7598, 3.7277],\n",
      "        [3.7835, 3.8505, 3.9015, 3.8759, 3.9352],\n",
      "        [3.4586, 3.4842, 3.4934, 3.6184, 3.4148],\n",
      "        [3.5711, 3.5302, 3.7381, 3.6916, 3.6925],\n",
      "        [3.5548, 3.5872, 3.7112, 3.6776, 3.6076],\n",
      "        [3.5244, 3.6313, 3.8652, 3.6922, 3.7209],\n",
      "        [3.6569, 3.6108, 3.7236, 3.6280, 3.4665],\n",
      "        [4.0214, 4.0768, 3.7852, 3.8928, 3.7023],\n",
      "        [3.6566, 3.6554, 3.7334, 3.7235, 3.6110],\n",
      "        [3.4671, 3.4032, 3.6751, 3.4064, 3.5920],\n",
      "        [3.5824, 3.5710, 3.7401, 3.6722, 3.6405],\n",
      "        [3.7082, 3.8985, 3.8896, 3.8738, 3.8585],\n",
      "        [3.5448, 3.6026, 3.6594, 3.6352, 3.5910],\n",
      "        [3.4273, 3.5553, 3.5572, 3.5279, 3.5036],\n",
      "        [3.4743, 3.5931, 3.5640, 3.5866, 3.5296],\n",
      "        [3.5708, 3.6276, 3.6240, 3.7274, 3.5978],\n",
      "        [3.9215, 3.7370, 3.9225, 4.3069, 4.1201],\n",
      "        [3.5358, 3.7035, 3.7232, 3.6790, 3.6179],\n",
      "        [3.5485, 3.6933, 3.7379, 3.6805, 3.6281],\n",
      "        [3.4844, 3.5715, 3.5802, 3.6272, 3.5427],\n",
      "        [3.4227, 3.6317, 3.6761, 3.5798, 3.5259],\n",
      "        [3.5667, 3.6692, 3.5761, 3.7104, 3.5900],\n",
      "        [3.7683, 3.6046, 3.7217, 3.7413, 3.7170],\n",
      "        [3.3926, 3.4424, 3.5480, 3.5000, 3.4422],\n",
      "        [3.7031, 3.7874, 3.7436, 3.8211, 3.7011],\n",
      "        [3.9416, 3.7785, 3.9541, 4.0833, 3.9074],\n",
      "        [3.5428, 3.5428, 3.6948, 3.6477, 3.5761],\n",
      "        [3.8548, 3.8530, 3.8302, 3.9211, 3.9054],\n",
      "        [3.6323, 3.7648, 3.7098, 3.7772, 3.6464],\n",
      "        [3.6830, 3.9428, 3.9010, 3.8457, 3.8420],\n",
      "        [3.4540, 3.5613, 3.5333, 3.6197, 3.5003],\n",
      "        [3.7417, 3.7435, 4.0072, 3.7291, 3.6084],\n",
      "        [3.7037, 3.8349, 3.7531, 3.9251, 3.7634],\n",
      "        [3.4133, 3.6142, 3.6682, 3.5698, 3.5184],\n",
      "        [3.5207, 3.6812, 3.7065, 3.5649, 3.5348],\n",
      "        [3.4715, 3.5525, 3.6878, 3.6259, 3.4855],\n",
      "        [3.4462, 3.6051, 3.5477, 3.6257, 3.5016],\n",
      "        [3.5746, 3.5633, 3.7256, 3.6653, 3.6355],\n",
      "        [3.5581, 3.5478, 3.7597, 3.6925, 3.6024]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5378, 3.6946, 3.7359, 3.6835, 3.6152],\n",
      "        [3.6453, 3.8323, 3.7667, 3.8746, 3.7158],\n",
      "        [3.5275, 3.4786, 3.7290, 3.5045, 3.6313],\n",
      "        [3.6920, 3.6756, 3.8681, 3.7184, 3.4683],\n",
      "        [3.5936, 3.5628, 3.7892, 3.7327, 3.7167],\n",
      "        [3.5686, 3.7052, 3.6402, 3.8094, 3.5443],\n",
      "        [3.5603, 3.6627, 3.5862, 3.7020, 3.5823],\n",
      "        [3.5493, 3.5511, 3.7043, 3.6487, 3.5786],\n",
      "        [3.6859, 3.7877, 3.8323, 3.7811, 3.5879],\n",
      "        [3.4113, 3.4246, 3.5834, 3.5572, 3.4567],\n",
      "        [3.9441, 3.7537, 3.9528, 4.3308, 4.1259],\n",
      "        [3.8019, 3.8769, 3.8212, 3.8640, 3.8751],\n",
      "        [3.5325, 3.5822, 3.6238, 3.5839, 3.5604],\n",
      "        [3.8698, 3.8375, 3.9356, 4.0072, 3.7389],\n",
      "        [3.6160, 3.5025, 3.7226, 3.8342, 3.5240],\n",
      "        [3.9653, 3.8835, 3.9829, 4.0594, 3.9803],\n",
      "        [3.6317, 3.7195, 3.8965, 3.7762, 3.7400],\n",
      "        [3.6323, 3.6244, 3.8326, 3.7433, 3.6760],\n",
      "        [3.5539, 3.6424, 3.6681, 3.7090, 3.6814],\n",
      "        [3.7150, 3.7982, 3.8705, 3.8472, 3.6977],\n",
      "        [3.7354, 3.7309, 3.7866, 3.8615, 3.8326],\n",
      "        [3.5550, 3.6528, 3.5868, 3.6892, 3.5801],\n",
      "        [3.4070, 3.6192, 3.6737, 3.5564, 3.5091],\n",
      "        [3.7146, 3.8407, 3.9001, 3.7914, 3.6218],\n",
      "        [3.6008, 3.6709, 3.7351, 3.6931, 3.7332],\n",
      "        [3.5766, 3.5664, 3.7870, 3.6866, 3.6437],\n",
      "        [3.5478, 3.6907, 3.6363, 3.7781, 3.5360],\n",
      "        [3.5820, 3.6775, 3.7261, 3.6970, 3.6621],\n",
      "        [3.7426, 3.8300, 3.8934, 3.7994, 3.6014],\n",
      "        [3.8832, 3.8589, 3.9581, 4.0281, 3.8593],\n",
      "        [3.5558, 3.5496, 3.7078, 3.6470, 3.5802],\n",
      "        [3.5532, 3.5147, 3.7335, 3.5722, 3.6288],\n",
      "        [3.4860, 3.5348, 3.6907, 3.6349, 3.5682],\n",
      "        [3.8555, 3.7988, 3.9428, 4.0692, 3.7306],\n",
      "        [3.6432, 3.6249, 3.8384, 3.7966, 3.6301],\n",
      "        [3.5745, 3.5966, 3.8137, 3.7133, 3.6529],\n",
      "        [3.4380, 3.5565, 3.6938, 3.5993, 3.5022],\n",
      "        [3.8858, 3.8796, 3.8643, 3.9507, 3.9341],\n",
      "        [3.4976, 3.4386, 3.6585, 3.6111, 3.5777],\n",
      "        [3.7204, 3.7174, 3.7774, 3.8530, 3.8226],\n",
      "        [3.3764, 3.4224, 3.5807, 3.4998, 3.3897],\n",
      "        [3.5474, 3.5333, 3.7130, 3.6367, 3.5610],\n",
      "        [3.4673, 3.7079, 3.7234, 3.6654, 3.7420],\n",
      "        [3.4073, 3.6098, 3.6741, 3.5636, 3.5089],\n",
      "        [3.6285, 3.5433, 3.9617, 3.7488, 3.7202],\n",
      "        [3.6463, 3.5625, 3.9650, 3.7672, 3.7397],\n",
      "        [3.6443, 3.7233, 3.9049, 3.7813, 3.7287],\n",
      "        [3.5399, 3.5607, 3.6966, 3.6508, 3.5770],\n",
      "        [3.6018, 3.7631, 3.7273, 3.6949, 3.6915],\n",
      "        [3.6324, 3.8680, 3.8097, 3.7979, 3.8133],\n",
      "        [3.5346, 3.6322, 3.5852, 3.6605, 3.5703],\n",
      "        [3.5276, 3.6426, 3.5838, 3.6598, 3.5661],\n",
      "        [3.4958, 3.5689, 3.6051, 3.5651, 3.5109],\n",
      "        [3.4858, 3.5366, 3.6848, 3.6467, 3.5572],\n",
      "        [3.7450, 3.7425, 4.0171, 3.7277, 3.6068],\n",
      "        [3.4706, 3.5629, 3.7079, 3.6277, 3.4900],\n",
      "        [3.6079, 3.6098, 3.8059, 3.7211, 3.6645],\n",
      "        [3.7660, 3.7890, 3.8565, 3.8571, 3.8527],\n",
      "        [3.7759, 3.7878, 3.8496, 3.8960, 3.9011],\n",
      "        [3.4469, 3.6412, 3.7918, 3.6029, 3.6170],\n",
      "        [3.3539, 3.5011, 3.5846, 3.5367, 3.4827],\n",
      "        [3.6556, 3.8201, 3.7808, 3.8824, 3.7134],\n",
      "        [3.6775, 3.8056, 3.7319, 3.8874, 3.7175],\n",
      "        [3.5541, 3.5050, 3.5948, 3.7247, 3.4820]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6885, 3.6480, 3.8071, 3.8554, 3.5870],\n",
      "        [3.8090, 3.9577, 4.0241, 3.9096, 3.6731],\n",
      "        [3.4650, 3.6319, 3.8925, 3.6356, 3.7314],\n",
      "        [3.8807, 3.7764, 3.9025, 3.9322, 3.8568],\n",
      "        [3.3383, 3.4653, 3.5270, 3.4360, 3.4300],\n",
      "        [3.7106, 3.7813, 3.9349, 3.8677, 3.8337],\n",
      "        [3.5689, 3.7050, 3.6483, 3.8109, 3.5460],\n",
      "        [3.4195, 3.6056, 3.6831, 3.5751, 3.5183],\n",
      "        [3.4129, 3.6368, 3.8007, 3.5794, 3.5908],\n",
      "        [3.4473, 3.5361, 3.6840, 3.5988, 3.4864],\n",
      "        [3.5587, 3.4690, 3.6606, 3.5299, 3.4773],\n",
      "        [3.7123, 3.8471, 3.7964, 3.8225, 3.7310],\n",
      "        [3.8385, 3.6528, 3.7916, 4.1091, 3.8821],\n",
      "        [3.7046, 3.8346, 3.7720, 3.9291, 3.7661],\n",
      "        [3.9093, 3.9966, 3.7783, 3.8200, 3.7223],\n",
      "        [3.5482, 3.5286, 3.7177, 3.6467, 3.5581],\n",
      "        [3.4309, 3.4151, 3.5763, 3.5675, 3.4313],\n",
      "        [3.5947, 3.5587, 3.7680, 3.6791, 3.6450],\n",
      "        [3.7149, 3.8404, 3.9089, 3.7929, 3.6235],\n",
      "        [3.5695, 3.6144, 3.7348, 3.6622, 3.7716],\n",
      "        [3.6590, 3.8016, 3.7335, 3.7358, 3.6790],\n",
      "        [4.1666, 4.3522, 4.0059, 4.0927, 3.8793],\n",
      "        [3.5987, 3.6704, 3.7289, 3.7868, 3.6684],\n",
      "        [3.5545, 3.5486, 3.7258, 3.6729, 3.6515],\n",
      "        [3.6898, 3.8206, 3.8216, 3.8575, 3.8611],\n",
      "        [3.4914, 3.5969, 3.5750, 3.6006, 3.5340],\n",
      "        [3.6328, 3.8678, 3.8182, 3.7995, 3.8150],\n",
      "        [3.4593, 3.4805, 3.5143, 3.6177, 3.4280],\n",
      "        [3.5884, 3.6904, 3.7426, 3.7154, 3.6750],\n",
      "        [3.4573, 3.6596, 3.5672, 3.6411, 3.4735],\n",
      "        [3.3104, 3.4630, 3.5945, 3.4764, 3.4560],\n",
      "        [3.5006, 3.6066, 3.5772, 3.6193, 3.5383],\n",
      "        [3.4342, 3.6334, 3.7960, 3.6017, 3.6108],\n",
      "        [3.9021, 3.8989, 3.9229, 4.0731, 3.8960],\n",
      "        [3.7481, 3.8262, 3.8762, 3.7432, 3.7479],\n",
      "        [3.5402, 3.5604, 3.7051, 3.6524, 3.5787],\n",
      "        [3.5504, 3.4927, 3.6837, 3.5718, 3.5064],\n",
      "        [3.5234, 3.6034, 3.6148, 3.6389, 3.5792],\n",
      "        [3.5509, 3.4559, 3.6461, 3.5263, 3.4647],\n",
      "        [3.4083, 3.4948, 3.6275, 3.5482, 3.4637],\n",
      "        [3.7587, 3.7611, 3.8660, 3.8547, 3.8643],\n",
      "        [3.4149, 3.6094, 3.6828, 3.5631, 3.5141],\n",
      "        [3.4888, 3.5451, 3.7041, 3.6611, 3.5848],\n",
      "        [3.5007, 3.6355, 3.7204, 3.7456, 3.5221],\n",
      "        [3.5579, 3.6079, 3.7263, 3.6654, 3.7470],\n",
      "        [3.5448, 3.4987, 3.5962, 3.7229, 3.4782],\n",
      "        [3.5482, 3.6904, 3.6443, 3.7795, 3.5377],\n",
      "        [3.4801, 3.5987, 3.5892, 3.5959, 3.5348],\n",
      "        [3.5276, 3.6087, 3.6145, 3.6386, 3.5798],\n",
      "        [3.6671, 3.9040, 3.8208, 3.8211, 3.7458],\n",
      "        [3.5432, 3.5618, 3.7176, 3.6694, 3.5930],\n",
      "        [3.4291, 3.6505, 3.7113, 3.5895, 3.5495],\n",
      "        [3.6452, 3.6495, 3.6935, 3.7934, 3.6627],\n",
      "        [4.0479, 3.8913, 4.0033, 4.1544, 3.9874],\n",
      "        [3.5957, 3.5645, 3.7886, 3.7483, 3.6276],\n",
      "        [3.5549, 3.7552, 3.7738, 3.6217, 3.6891],\n",
      "        [3.5935, 3.7988, 3.6988, 3.7322, 3.6464],\n",
      "        [3.7067, 3.7369, 3.8859, 3.7573, 3.5453],\n",
      "        [3.4593, 3.6120, 3.7793, 3.6400, 3.6459],\n",
      "        [3.5420, 3.6457, 3.7618, 3.7152, 3.5532],\n",
      "        [3.9876, 3.8790, 3.9318, 4.1397, 3.9518],\n",
      "        [3.4681, 3.4029, 3.6925, 3.4099, 3.5946],\n",
      "        [3.5417, 3.6374, 3.5898, 3.6691, 3.5719],\n",
      "        [3.4171, 3.6353, 3.6968, 3.5667, 3.5273]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5404, 3.6197, 3.6774, 3.6297, 3.5981],\n",
      "        [3.6705, 3.6224, 3.7899, 3.7424, 3.6202],\n",
      "        [3.9073, 3.8437, 3.9470, 4.0842, 3.8819],\n",
      "        [3.6214, 3.8771, 3.9407, 3.8551, 3.8240],\n",
      "        [3.8206, 3.5359, 3.8123, 4.0376, 3.9451],\n",
      "        [3.4283, 3.5547, 3.5808, 3.5334, 3.5073],\n",
      "        [3.4871, 3.6652, 3.5944, 3.6783, 3.4903],\n",
      "        [3.6103, 3.8914, 3.8841, 3.7722, 3.6302],\n",
      "        [3.6009, 3.5974, 3.8054, 3.7348, 3.6628],\n",
      "        [3.7416, 3.8829, 3.7676, 3.7595, 3.7241],\n",
      "        [3.5011, 3.5445, 3.7140, 3.6525, 3.5729],\n",
      "        [3.7050, 3.6430, 3.7637, 3.6501, 3.5321],\n",
      "        [3.5488, 3.5331, 3.7271, 3.6468, 3.5650],\n",
      "        [3.7159, 3.8603, 3.8129, 3.8181, 3.7355],\n",
      "        [3.5435, 3.5824, 3.7304, 3.6808, 3.6006],\n",
      "        [3.7007, 3.6938, 3.8179, 3.7248, 3.5316],\n",
      "        [3.5476, 3.5597, 3.7186, 3.6570, 3.5866],\n",
      "        [3.4597, 3.4836, 3.5175, 3.6238, 3.4187],\n",
      "        [3.6184, 3.8077, 3.7772, 3.7721, 3.7848],\n",
      "        [3.6172, 3.6080, 3.8208, 3.7313, 3.6670],\n",
      "        [4.0866, 4.1841, 4.0180, 3.9850, 3.8802],\n",
      "        [3.6795, 3.6296, 3.7998, 3.7566, 3.6289],\n",
      "        [3.5096, 3.5919, 3.6104, 3.6297, 3.5645],\n",
      "        [3.4884, 3.7976, 3.7961, 3.7135, 3.7574],\n",
      "        [3.4550, 3.5607, 3.5575, 3.6252, 3.5041],\n",
      "        [3.7186, 3.6471, 3.7691, 3.6637, 3.5429],\n",
      "        [3.8907, 3.7070, 3.9355, 4.2901, 4.1172],\n",
      "        [3.4703, 3.5908, 3.7564, 3.6361, 3.5136],\n",
      "        [3.8576, 3.6716, 3.8127, 4.1501, 3.9130],\n",
      "        [3.4476, 3.4618, 3.6160, 3.5792, 3.4628],\n",
      "        [3.5186, 3.7538, 3.7227, 3.6431, 3.5441],\n",
      "        [3.4569, 3.4539, 3.6163, 3.5859, 3.4649],\n",
      "        [3.9872, 4.0698, 3.8220, 3.8972, 3.7390],\n",
      "        [3.7089, 3.8199, 3.8828, 3.7791, 3.5921],\n",
      "        [3.8111, 3.8324, 3.9316, 3.8724, 3.8775],\n",
      "        [3.4150, 3.5002, 3.6389, 3.5542, 3.4702],\n",
      "        [3.5409, 3.6383, 3.5975, 3.6800, 3.5694],\n",
      "        [3.5482, 3.5282, 3.7250, 3.6486, 3.5594],\n",
      "        [3.5576, 3.6354, 3.7463, 3.6609, 3.5086],\n",
      "        [4.0454, 4.0135, 3.9870, 4.2548, 3.8560],\n",
      "        [3.4234, 3.4916, 3.6355, 3.5569, 3.4717],\n",
      "        [3.6336, 3.7647, 3.7387, 3.7838, 3.6503],\n",
      "        [3.5533, 3.6306, 3.7205, 3.8417, 3.5647],\n",
      "        [3.6550, 3.8215, 3.7966, 3.8862, 3.7183],\n",
      "        [3.6777, 3.8049, 3.7483, 3.8912, 3.7205],\n",
      "        [3.5486, 3.6970, 3.6936, 3.7079, 3.6597],\n",
      "        [3.4335, 3.5002, 3.6632, 3.5817, 3.4587],\n",
      "        [3.6994, 3.8102, 3.8579, 3.9141, 3.7107],\n",
      "        [3.8843, 3.8584, 3.9747, 4.0318, 3.8625],\n",
      "        [3.5820, 3.7447, 3.7272, 3.6830, 3.6850],\n",
      "        [3.3494, 3.4804, 3.5431, 3.4445, 3.4388],\n",
      "        [3.7744, 3.9445, 3.8980, 3.9715, 3.8495],\n",
      "        [3.5053, 3.5573, 3.6719, 3.5847, 3.5550],\n",
      "        [3.6993, 3.7786, 3.9159, 3.7639, 3.5959],\n",
      "        [3.4147, 3.4796, 3.6286, 3.5528, 3.4626],\n",
      "        [3.4428, 3.6793, 3.8762, 3.6624, 3.6524],\n",
      "        [3.6869, 3.7731, 3.7537, 3.7441, 3.7947],\n",
      "        [4.0218, 4.1176, 3.9485, 3.9261, 3.8139],\n",
      "        [3.4980, 3.4380, 3.6740, 3.6144, 3.5807],\n",
      "        [3.7801, 3.8544, 3.8096, 3.8275, 3.8497],\n",
      "        [3.7527, 3.9934, 3.9846, 3.9130, 3.8887],\n",
      "        [3.5695, 3.5643, 3.7267, 3.6569, 3.6496],\n",
      "        [3.4407, 3.5702, 3.5806, 3.5533, 3.5137],\n",
      "        [3.5636, 3.7952, 3.6845, 3.8035, 3.6665]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.9073, 3.8014, 3.9018, 4.0476, 3.8461],\n",
      "        [3.5513, 3.6438, 3.6018, 3.6910, 3.5751],\n",
      "        [3.6594, 3.6735, 3.8121, 3.7055, 3.7781],\n",
      "        [3.6496, 3.5497, 3.9615, 3.7669, 3.7354],\n",
      "        [3.6698, 3.6972, 3.6669, 3.7289, 3.7303],\n",
      "        [3.4974, 3.5386, 3.6910, 3.6537, 3.5055],\n",
      "        [3.5771, 3.5389, 3.7807, 3.7104, 3.7051],\n",
      "        [3.7324, 3.8055, 3.9050, 3.9516, 3.7048],\n",
      "        [3.5337, 3.5681, 3.7279, 3.6721, 3.5864],\n",
      "        [3.7875, 3.6109, 3.7871, 4.0713, 3.8454],\n",
      "        [3.5761, 3.6648, 3.6130, 3.7197, 3.5872],\n",
      "        [3.7251, 3.6603, 3.8655, 3.8258, 3.6823],\n",
      "        [3.4548, 3.5602, 3.5633, 3.6267, 3.5060],\n",
      "        [3.4723, 3.5513, 3.7176, 3.6329, 3.4911],\n",
      "        [3.8944, 3.7927, 3.9201, 3.9452, 3.8546],\n",
      "        [3.6697, 3.8929, 3.9104, 3.8363, 3.8941],\n",
      "        [3.9924, 4.0860, 3.9364, 3.8944, 3.7981],\n",
      "        [4.0488, 4.0253, 4.0570, 4.2925, 4.0316],\n",
      "        [3.8022, 3.7713, 3.9028, 3.9831, 3.9894],\n",
      "        [3.4400, 3.4589, 3.6246, 3.5718, 3.4655],\n",
      "        [3.6040, 3.6713, 3.7474, 3.7289, 3.7271],\n",
      "        [3.5951, 3.7389, 3.6991, 3.6532, 3.6485],\n",
      "        [3.5420, 3.5773, 3.7327, 3.6769, 3.5948],\n",
      "        [3.7093, 3.8976, 3.9221, 3.8812, 3.8645],\n",
      "        [3.3689, 3.4983, 3.5603, 3.4693, 3.4601],\n",
      "        [3.5699, 3.6094, 3.7493, 3.6653, 3.7741],\n",
      "        [3.4358, 3.4980, 3.6095, 3.5647, 3.4874],\n",
      "        [3.9963, 4.0654, 3.8074, 3.8852, 3.7130],\n",
      "        [3.5723, 3.6523, 3.7540, 3.6621, 3.5188],\n",
      "        [3.5926, 3.5767, 3.7463, 3.6764, 3.6367],\n",
      "        [3.8740, 3.8529, 3.9378, 4.0466, 3.8229],\n",
      "        [3.3785, 3.5169, 3.5723, 3.4880, 3.4710],\n",
      "        [3.7724, 3.7050, 3.8915, 3.8948, 3.7123],\n",
      "        [3.5590, 3.7458, 3.7699, 3.6333, 3.6839],\n",
      "        [3.5129, 3.6190, 3.7664, 3.6756, 3.7386],\n",
      "        [3.3284, 3.4655, 3.5412, 3.4240, 3.4205],\n",
      "        [3.6642, 3.7849, 3.8329, 3.7541, 3.5714],\n",
      "        [3.4717, 3.6215, 3.7970, 3.6853, 3.6816],\n",
      "        [3.5694, 3.5637, 3.7326, 3.6581, 3.6514],\n",
      "        [3.5323, 3.5643, 3.8415, 3.5442, 3.7335],\n",
      "        [3.4091, 3.4555, 3.5858, 3.5245, 3.4622],\n",
      "        [3.4457, 3.6120, 3.6886, 3.7191, 3.4658],\n",
      "        [3.9923, 4.0722, 3.9226, 3.8911, 3.7681],\n",
      "        [3.5366, 3.6276, 3.6022, 3.6512, 3.5773],\n",
      "        [3.4364, 3.4911, 3.6518, 3.5881, 3.4842],\n",
      "        [3.7775, 3.9391, 3.8574, 3.7021, 3.7387],\n",
      "        [3.6327, 3.8670, 3.8317, 3.8029, 3.8181],\n",
      "        [3.4552, 3.4773, 3.5176, 3.6205, 3.3975],\n",
      "        [3.6371, 3.6214, 3.8529, 3.7573, 3.6846],\n",
      "        [3.5455, 3.6202, 3.7028, 3.6071, 3.6047],\n",
      "        [3.5047, 3.5699, 3.6286, 3.6804, 3.5579],\n",
      "        [3.5964, 3.9213, 3.8330, 3.8523, 3.8181],\n",
      "        [3.4431, 3.6575, 3.7222, 3.5902, 3.5690],\n",
      "        [3.5690, 3.9397, 3.9011, 3.6980, 3.6408],\n",
      "        [3.5385, 3.5377, 3.7160, 3.6433, 3.5726],\n",
      "        [3.7600, 3.8468, 3.7963, 3.8146, 3.8141],\n",
      "        [3.5596, 3.5914, 3.7438, 3.6966, 3.6035],\n",
      "        [3.5211, 3.6743, 3.6499, 3.7522, 3.5334],\n",
      "        [3.6055, 3.8170, 3.6855, 3.7274, 3.6272],\n",
      "        [3.4214, 3.5052, 3.6490, 3.5584, 3.4780],\n",
      "        [3.4790, 3.5870, 3.5967, 3.5831, 3.5471],\n",
      "        [3.7593, 4.0248, 3.8870, 4.0026, 3.9123],\n",
      "        [3.5701, 3.6690, 3.6216, 3.7214, 3.5975],\n",
      "        [3.4262, 3.6448, 3.7153, 3.5905, 3.5511]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8044, 3.9802, 3.9157, 3.9692, 3.9260],\n",
      "        [3.4275, 3.5733, 3.6004, 3.5486, 3.5182],\n",
      "        [3.6952, 3.8357, 3.8748, 3.9320, 3.7317],\n",
      "        [3.9662, 3.8822, 4.0114, 4.0655, 3.9871],\n",
      "        [3.5732, 3.6705, 3.6300, 3.7219, 3.6041],\n",
      "        [3.6761, 3.6990, 3.6775, 3.7356, 3.7436],\n",
      "        [3.6924, 3.7703, 3.7706, 3.8236, 3.7055],\n",
      "        [3.4939, 3.4515, 3.6297, 3.6162, 3.4543],\n",
      "        [3.3618, 3.4984, 3.5638, 3.4609, 3.4536],\n",
      "        [4.0866, 4.1837, 4.0296, 3.9876, 3.8836],\n",
      "        [3.7363, 3.8501, 3.7977, 3.7930, 3.7813],\n",
      "        [3.5482, 3.5326, 3.7386, 3.6491, 3.5682],\n",
      "        [3.5496, 3.5213, 3.7445, 3.6356, 3.5737],\n",
      "        [3.7739, 3.7945, 3.8862, 3.8503, 3.9246],\n",
      "        [3.4866, 3.6648, 3.6051, 3.6809, 3.4939],\n",
      "        [3.5765, 3.5652, 3.8134, 3.6922, 3.6498],\n",
      "        [3.6991, 3.7025, 3.8308, 3.8152, 3.8514],\n",
      "        [3.4760, 3.5790, 3.6359, 3.6051, 3.5477],\n",
      "        [3.7193, 3.8400, 3.8843, 3.8714, 3.7333],\n",
      "        [3.5319, 3.5565, 3.6116, 3.6213, 3.6346],\n",
      "        [3.5623, 3.6020, 3.7551, 3.7020, 3.6243],\n",
      "        [3.6710, 3.8731, 3.9015, 3.8174, 3.6909],\n",
      "        [3.3887, 3.4796, 3.5286, 3.5834, 3.3996],\n",
      "        [3.5769, 3.6784, 3.6219, 3.7317, 3.6035],\n",
      "        [3.4244, 3.6019, 3.6983, 3.5850, 3.5317],\n",
      "        [3.5291, 3.6066, 3.7233, 3.6853, 3.6798],\n",
      "        [3.5428, 3.5710, 3.6443, 3.6970, 3.5492],\n",
      "        [3.5693, 3.6134, 3.7533, 3.6661, 3.7758],\n",
      "        [3.4555, 3.4752, 3.5261, 3.6192, 3.4103],\n",
      "        [4.1372, 4.3036, 3.9734, 4.0148, 3.8846],\n",
      "        [3.8300, 3.7770, 3.9436, 4.0559, 3.7200],\n",
      "        [3.7314, 3.5190, 3.6528, 3.6474, 3.6969],\n",
      "        [3.5658, 3.7132, 3.8000, 3.7125, 3.5859],\n",
      "        [3.7777, 3.6759, 3.8021, 3.8268, 3.7908],\n",
      "        [3.4287, 3.5518, 3.5902, 3.5340, 3.5114],\n",
      "        [3.5125, 3.8124, 3.8396, 3.7502, 3.7443],\n",
      "        [3.6584, 3.8007, 3.7525, 3.7401, 3.6834],\n",
      "        [3.4127, 3.5616, 3.6775, 3.5635, 3.5038],\n",
      "        [3.7408, 3.5093, 3.6378, 3.6446, 3.7035],\n",
      "        [3.9905, 4.0947, 3.9685, 3.8962, 3.8422],\n",
      "        [3.5685, 3.5607, 3.7654, 3.6307, 3.5869],\n",
      "        [3.4038, 3.5220, 3.5818, 3.5088, 3.4782],\n",
      "        [3.8374, 3.7146, 3.9230, 3.9432, 3.7598],\n",
      "        [3.6558, 3.6763, 3.8184, 3.7241, 3.7627],\n",
      "        [3.4110, 3.4235, 3.6096, 3.5630, 3.4624],\n",
      "        [3.5012, 3.7895, 3.7411, 3.6146, 3.4940],\n",
      "        [3.7764, 3.7866, 3.8780, 3.9020, 3.9077],\n",
      "        [3.5529, 3.5865, 3.7463, 3.6860, 3.6115],\n",
      "        [3.4704, 3.5618, 3.7333, 3.6337, 3.4960],\n",
      "        [3.5403, 3.6189, 3.6385, 3.6588, 3.5951],\n",
      "        [3.4307, 3.5918, 3.6948, 3.5782, 3.5331],\n",
      "        [3.6257, 3.7872, 3.8185, 3.7405, 3.5500],\n",
      "        [3.6367, 3.6215, 3.8582, 3.7583, 3.6860],\n",
      "        [3.4595, 3.4849, 3.6627, 3.5940, 3.4646],\n",
      "        [3.7587, 3.8557, 3.8139, 3.8079, 3.8108],\n",
      "        [3.4647, 3.5509, 3.5951, 3.6180, 3.5035],\n",
      "        [3.7022, 3.8519, 3.7787, 3.7782, 3.7411],\n",
      "        [3.8868, 3.8787, 3.8911, 3.9565, 3.9405],\n",
      "        [3.7134, 3.7894, 3.9406, 3.7819, 3.6013],\n",
      "        [3.5502, 3.5393, 3.7333, 3.6488, 3.5767],\n",
      "        [3.6982, 3.5303, 3.6504, 3.6454, 3.6912],\n",
      "        [3.8230, 3.8361, 3.9445, 3.9105, 4.0167],\n",
      "        [3.8376, 3.5313, 3.8203, 4.0630, 3.9633],\n",
      "        [3.5504, 3.4550, 3.6639, 3.5304, 3.4692]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3689, 3.4983, 3.5690, 3.4710, 3.4635],\n",
      "        [3.6296, 3.5390, 3.9832, 3.7496, 3.7149],\n",
      "        [3.4968, 3.6396, 3.7429, 3.7552, 3.5175],\n",
      "        [3.6880, 3.7778, 3.9046, 3.7872, 3.7096],\n",
      "        [3.4069, 3.4167, 3.6093, 3.5547, 3.4650],\n",
      "        [3.4822, 3.5917, 3.5962, 3.6006, 3.5327],\n",
      "        [3.5758, 3.5618, 3.7653, 3.6732, 3.6443],\n",
      "        [3.8939, 3.7003, 3.9451, 3.9624, 3.8221],\n",
      "        [3.4749, 3.6797, 3.6011, 3.6475, 3.4835],\n",
      "        [3.6430, 3.9077, 3.8727, 3.8247, 3.8326],\n",
      "        [3.4168, 3.5339, 3.5831, 3.5242, 3.4871],\n",
      "        [3.4457, 3.6122, 3.7006, 3.7215, 3.4689],\n",
      "        [3.4705, 3.5411, 3.6028, 3.6170, 3.4955],\n",
      "        [4.1783, 4.2866, 4.0465, 4.0330, 3.8646],\n",
      "        [3.3790, 3.5090, 3.5710, 3.4838, 3.4656],\n",
      "        [3.5772, 3.5714, 3.7356, 3.6559, 3.6656],\n",
      "        [3.4607, 3.6145, 3.6417, 3.5989, 3.5844],\n",
      "        [3.5354, 3.6318, 3.6151, 3.6752, 3.5750],\n",
      "        [3.4625, 3.5300, 3.7076, 3.6315, 3.4800],\n",
      "        [3.6162, 3.7762, 3.7705, 3.6973, 3.7033],\n",
      "        [3.5721, 3.5974, 3.7497, 3.5754, 3.4286],\n",
      "        [3.6649, 3.6217, 3.8056, 3.6526, 3.5827],\n",
      "        [3.6566, 3.7047, 3.7491, 3.7221, 3.6372],\n",
      "        [3.4444, 3.6774, 3.8912, 3.6674, 3.6537],\n",
      "        [3.5791, 3.7110, 3.6259, 3.6421, 3.5960],\n",
      "        [3.4431, 3.6575, 3.7311, 3.5920, 3.5725],\n",
      "        [3.6038, 3.5504, 3.7740, 3.6808, 3.6601],\n",
      "        [3.5963, 3.6686, 3.7656, 3.7244, 3.7299],\n",
      "        [3.6571, 3.6965, 3.8394, 3.7379, 3.6872],\n",
      "        [3.7941, 3.8285, 3.9459, 3.8908, 3.9896],\n",
      "        [3.7122, 3.8461, 3.8207, 3.8276, 3.7374],\n",
      "        [3.5105, 3.6238, 3.7608, 3.6943, 3.5267],\n",
      "        [3.6281, 3.8478, 3.8251, 3.7984, 3.8155],\n",
      "        [3.7217, 3.8612, 3.8062, 3.7943, 3.7692],\n",
      "        [3.6714, 3.8730, 3.9064, 3.8183, 3.6927],\n",
      "        [3.5793, 3.6154, 3.7659, 3.6640, 3.8001],\n",
      "        [3.7041, 3.8336, 3.7964, 3.9346, 3.7724],\n",
      "        [3.7026, 3.4957, 3.6581, 3.6674, 3.6539],\n",
      "        [3.4272, 3.4900, 3.6520, 3.5625, 3.4784],\n",
      "        [3.6476, 3.4760, 3.8733, 3.7504, 3.6583],\n",
      "        [3.5210, 3.6743, 3.6590, 3.7539, 3.5370],\n",
      "        [3.6944, 3.8778, 3.7851, 3.6292, 3.6779],\n",
      "        [3.5992, 3.7337, 3.6967, 3.6585, 3.6406],\n",
      "        [3.5275, 3.6811, 3.7641, 3.6703, 3.6564],\n",
      "        [3.8168, 3.7686, 3.7734, 3.8511, 3.8348],\n",
      "        [3.9032, 3.8980, 3.9473, 4.0784, 3.9028],\n",
      "        [3.5296, 3.6065, 3.7281, 3.6860, 3.6815],\n",
      "        [3.5820, 3.7441, 3.7435, 3.6860, 3.6897],\n",
      "        [3.5347, 3.5203, 3.7375, 3.6444, 3.5641],\n",
      "        [3.8937, 3.8810, 3.8911, 3.9427, 3.9474],\n",
      "        [3.5331, 3.6545, 3.7660, 3.7725, 3.5643],\n",
      "        [3.7019, 3.8312, 3.7951, 3.9332, 3.7690],\n",
      "        [3.5224, 3.6222, 3.6022, 3.6625, 3.5552],\n",
      "        [3.7363, 3.7665, 3.8843, 3.7998, 3.8310],\n",
      "        [3.6542, 3.6066, 3.7991, 3.6503, 3.5744],\n",
      "        [3.6995, 3.8096, 3.8745, 3.9173, 3.7158],\n",
      "        [3.7285, 3.7459, 3.9019, 3.8664, 3.6212],\n",
      "        [3.6423, 3.8880, 3.8615, 3.8229, 3.8343],\n",
      "        [3.8082, 3.8838, 4.0240, 4.0681, 4.0983],\n",
      "        [3.6403, 3.6779, 3.7179, 3.7802, 3.6755],\n",
      "        [3.5388, 3.7719, 3.8374, 3.5985, 3.7035],\n",
      "        [3.4438, 3.4283, 3.6135, 3.5877, 3.4450],\n",
      "        [3.7223, 3.8721, 3.9146, 3.8533, 3.7418],\n",
      "        [3.8008, 3.9309, 3.9790, 3.9508, 3.8803]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4381, 3.4625, 3.6387, 3.5724, 3.4689],\n",
      "        [3.8272, 3.5218, 3.8054, 4.0702, 3.9729],\n",
      "        [3.7188, 3.7312, 3.9143, 3.7740, 3.6010],\n",
      "        [3.7044, 3.6184, 3.8472, 3.9325, 3.6418],\n",
      "        [3.5785, 3.7436, 3.7439, 3.6468, 3.6707],\n",
      "        [3.9063, 4.0215, 3.9105, 3.8289, 3.7717],\n",
      "        [3.8208, 3.7906, 3.9473, 3.9482, 3.8033],\n",
      "        [3.5604, 3.4877, 3.7081, 3.5717, 3.5090],\n",
      "        [3.4147, 3.5983, 3.7028, 3.5644, 3.5094],\n",
      "        [3.6485, 3.6736, 3.7796, 3.8388, 3.6527],\n",
      "        [3.3787, 3.5167, 3.5845, 3.4899, 3.4759],\n",
      "        [3.6081, 3.7969, 3.7275, 3.5494, 3.6106],\n",
      "        [3.5689, 3.6336, 3.6724, 3.7489, 3.6197],\n",
      "        [3.5864, 3.5804, 3.8071, 3.7190, 3.6464],\n",
      "        [3.7043, 3.8332, 3.8004, 3.9349, 3.7739],\n",
      "        [3.7325, 3.5185, 3.6607, 3.6483, 3.7002],\n",
      "        [3.4756, 3.6419, 3.7419, 3.7619, 3.5177],\n",
      "        [3.8470, 3.7570, 3.9497, 4.0483, 3.7310],\n",
      "        [3.5518, 3.5304, 3.6561, 3.7251, 3.5171],\n",
      "        [3.5382, 3.6304, 3.6126, 3.6678, 3.5784],\n",
      "        [3.8787, 3.6581, 3.8447, 4.1948, 3.9448],\n",
      "        [3.5822, 3.7438, 3.7474, 3.6862, 3.6911],\n",
      "        [3.8235, 3.5436, 3.8257, 4.0419, 3.9634],\n",
      "        [3.5233, 3.6021, 3.6407, 3.6443, 3.5868],\n",
      "        [3.6119, 3.7812, 3.8010, 3.7981, 3.6194],\n",
      "        [3.5950, 3.5571, 3.7938, 3.6838, 3.6526],\n",
      "        [3.6088, 3.8182, 3.7534, 3.8551, 3.7067],\n",
      "        [3.6885, 3.8370, 3.9118, 3.8553, 3.7915],\n",
      "        [3.8723, 3.8326, 3.8958, 4.1067, 3.8542],\n",
      "        [3.5626, 3.6592, 3.6171, 3.7096, 3.5897],\n",
      "        [3.4709, 3.5614, 3.7409, 3.6346, 3.4996],\n",
      "        [3.7677, 3.8436, 3.9558, 3.8289, 3.6295],\n",
      "        [3.5601, 3.5568, 3.8087, 3.7039, 3.6289],\n",
      "        [3.5056, 3.5403, 3.7491, 3.6517, 3.5760],\n",
      "        [3.5813, 3.7915, 3.7993, 3.7022, 3.5246],\n",
      "        [3.5527, 3.5716, 3.7437, 3.6734, 3.5969],\n",
      "        [3.7572, 3.6807, 3.8120, 3.7179, 3.6049],\n",
      "        [3.6946, 3.8775, 3.7888, 3.6294, 3.6794],\n",
      "        [3.3668, 3.4894, 3.4801, 3.5696, 3.4151],\n",
      "        [3.7447, 3.6628, 3.8549, 3.9215, 3.6159],\n",
      "        [3.5724, 3.6086, 3.7231, 3.7905, 3.6566],\n",
      "        [3.7020, 3.8308, 3.7991, 3.9335, 3.7704],\n",
      "        [3.7160, 3.7968, 3.9072, 3.8545, 3.7073],\n",
      "        [3.4425, 3.4407, 3.6239, 3.5855, 3.4572],\n",
      "        [3.5480, 3.5869, 3.7516, 3.6831, 3.6025],\n",
      "        [3.7019, 3.8299, 3.7941, 3.9253, 3.7622],\n",
      "        [3.9165, 3.8212, 3.9243, 3.9761, 3.8794],\n",
      "        [3.5419, 3.6314, 3.6063, 3.6747, 3.5613],\n",
      "        [3.7807, 3.8237, 3.9542, 3.8710, 3.9685],\n",
      "        [3.6964, 3.8031, 3.7840, 3.7528, 3.7099],\n",
      "        [3.7145, 3.6865, 3.9282, 3.7535, 3.5070],\n",
      "        [3.6448, 3.8624, 3.9123, 3.7743, 3.7615],\n",
      "        [3.6056, 3.8165, 3.6992, 3.7292, 3.6320],\n",
      "        [3.7894, 3.8058, 3.9874, 3.9920, 3.7296],\n",
      "        [3.4902, 3.5443, 3.4930, 3.6836, 3.4203],\n",
      "        [3.5960, 3.6715, 3.7686, 3.7214, 3.7399],\n",
      "        [3.6510, 3.5974, 3.7989, 3.6409, 3.5801],\n",
      "        [3.6478, 3.6443, 3.7544, 3.7843, 3.7682],\n",
      "        [3.6419, 3.7823, 3.7906, 3.7998, 3.6687],\n",
      "        [3.4416, 3.5786, 3.7326, 3.6112, 3.5198],\n",
      "        [3.4887, 3.7967, 3.8158, 3.7172, 3.7640],\n",
      "        [3.7064, 3.7357, 3.9139, 3.7625, 3.5527],\n",
      "        [3.4098, 3.5394, 3.5945, 3.5158, 3.5034],\n",
      "        [3.6405, 3.6775, 3.7215, 3.7804, 3.6769]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4932, 3.5919, 3.6450, 3.6208, 3.5782],\n",
      "        [3.4449, 3.4275, 3.6203, 3.5879, 3.4482],\n",
      "        [4.0776, 4.0293, 4.0385, 4.2879, 3.8738],\n",
      "        [3.4052, 3.5212, 3.5922, 3.5098, 3.4837],\n",
      "        [3.5825, 3.6597, 3.7584, 3.6671, 3.6389],\n",
      "        [3.8398, 3.7138, 3.9346, 3.9443, 3.7657],\n",
      "        [3.7102, 3.8145, 3.8188, 3.8239, 3.7337],\n",
      "        [3.6435, 3.8872, 3.8686, 3.8232, 3.8379],\n",
      "        [3.6891, 3.6528, 3.8318, 3.6952, 3.5637],\n",
      "        [3.4373, 3.4950, 3.6835, 3.5880, 3.4655],\n",
      "        [3.4853, 3.5358, 3.7135, 3.6423, 3.5027],\n",
      "        [3.7600, 3.8856, 3.7772, 3.7526, 3.7209],\n",
      "        [3.4927, 3.5893, 3.5950, 3.6106, 3.5290],\n",
      "        [3.7718, 3.8534, 3.9676, 3.8930, 3.9344],\n",
      "        [3.7074, 3.8644, 3.8046, 3.7896, 3.7495],\n",
      "        [3.5800, 3.4957, 3.7216, 3.5692, 3.5180],\n",
      "        [3.6139, 3.5490, 3.7649, 3.7046, 3.6106],\n",
      "        [3.5424, 3.6356, 3.6197, 3.6746, 3.5813],\n",
      "        [3.7050, 3.7800, 3.8085, 3.7001, 3.6865],\n",
      "        [3.5281, 3.8056, 3.7847, 3.6573, 3.5148],\n",
      "        [3.3557, 3.4833, 3.5695, 3.4523, 3.4546],\n",
      "        [3.4902, 3.4611, 3.6582, 3.6044, 3.4731],\n",
      "        [3.7720, 3.7753, 3.9162, 3.8740, 3.8774],\n",
      "        [3.5763, 3.6526, 3.7502, 3.7981, 3.6307],\n",
      "        [3.4913, 3.5975, 3.6121, 3.5945, 3.5517],\n",
      "        [3.7650, 3.5433, 3.8253, 3.9611, 3.9058],\n",
      "        [3.9316, 3.8620, 3.9907, 4.0798, 3.8865],\n",
      "        [3.4543, 3.4297, 3.6234, 3.5882, 3.4567],\n",
      "        [3.6847, 3.7590, 3.9593, 3.8442, 3.7890],\n",
      "        [3.6609, 3.7920, 3.7645, 3.8882, 3.7207],\n",
      "        [3.7031, 3.8303, 3.8025, 3.9335, 3.7724],\n",
      "        [3.6195, 3.8065, 3.7999, 3.7756, 3.7937],\n",
      "        [3.5354, 3.5639, 3.8771, 3.5227, 3.7580],\n",
      "        [3.5744, 3.5840, 3.8401, 3.7054, 3.6622],\n",
      "        [3.4866, 3.5948, 3.6047, 3.6076, 3.5393],\n",
      "        [3.7600, 3.6033, 3.7784, 4.0800, 3.8246],\n",
      "        [3.6150, 3.5587, 3.7849, 3.6834, 3.6680],\n",
      "        [3.5490, 3.6887, 3.6727, 3.7850, 3.5483],\n",
      "        [3.7157, 3.8073, 3.9403, 3.8602, 3.7965],\n",
      "        [3.9571, 3.8982, 3.9962, 4.1443, 3.7531],\n",
      "        [3.4730, 3.5378, 3.7068, 3.6639, 3.5597],\n",
      "        [3.5338, 3.8042, 3.7923, 3.6709, 3.5188],\n",
      "        [3.5141, 3.6175, 3.6162, 3.6369, 3.5635],\n",
      "        [3.4896, 3.5969, 3.6037, 3.6138, 3.5425],\n",
      "        [3.5777, 3.6690, 3.8558, 3.7299, 3.6867],\n",
      "        [3.7030, 3.8294, 3.7975, 3.9254, 3.7642],\n",
      "        [3.5510, 3.6397, 3.6242, 3.6727, 3.5950],\n",
      "        [3.5943, 3.7970, 3.7296, 3.7372, 3.6563],\n",
      "        [3.5964, 3.4793, 3.7609, 3.8376, 3.5141],\n",
      "        [3.5565, 3.5850, 3.7608, 3.6866, 3.6197],\n",
      "        [3.7053, 3.8327, 3.8038, 3.9349, 3.7759],\n",
      "        [3.7410, 3.7389, 4.0500, 3.7358, 3.6110],\n",
      "        [3.4080, 3.4159, 3.6160, 3.5549, 3.4684],\n",
      "        [3.5048, 3.8339, 3.8083, 3.7366, 3.7909],\n",
      "        [3.3813, 3.4250, 3.6184, 3.5178, 3.4069],\n",
      "        [4.0578, 4.1550, 4.0202, 3.9569, 3.8725],\n",
      "        [3.4821, 3.6375, 3.7344, 3.7570, 3.5034],\n",
      "        [3.7265, 3.8571, 3.9103, 3.8600, 3.7455],\n",
      "        [3.4170, 3.5112, 3.6686, 3.5595, 3.4847],\n",
      "        [3.4560, 3.4654, 3.6456, 3.5862, 3.4803],\n",
      "        [3.6114, 3.5321, 3.7255, 3.6493, 3.6498],\n",
      "        [3.4283, 3.4892, 3.6587, 3.5627, 3.4818],\n",
      "        [3.4368, 3.6552, 3.7391, 3.5975, 3.5703],\n",
      "        [3.4472, 3.6116, 3.7095, 3.7223, 3.4722]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3892, 3.4714, 3.5235, 3.5731, 3.4158],\n",
      "        [3.4958, 3.5446, 3.7321, 3.6566, 3.5795],\n",
      "        [3.3707, 3.4316, 3.5788, 3.4766, 3.4405],\n",
      "        [3.4969, 3.4116, 3.5944, 3.5857, 3.4458],\n",
      "        [3.5492, 3.5305, 3.7540, 3.6431, 3.5751],\n",
      "        [4.0519, 3.9812, 4.0503, 4.2163, 3.9396],\n",
      "        [3.8112, 3.8876, 4.0411, 4.0647, 4.1128],\n",
      "        [3.6316, 3.5376, 3.9928, 3.7497, 3.7209],\n",
      "        [3.4601, 3.4775, 3.5446, 3.6224, 3.4404],\n",
      "        [3.4232, 3.5037, 3.6671, 3.5601, 3.4873],\n",
      "        [3.7048, 3.4893, 3.6648, 3.6607, 3.6581],\n",
      "        [3.8587, 3.7971, 3.9963, 4.0783, 3.7452],\n",
      "        [3.4568, 3.4377, 3.6306, 3.5951, 3.4748],\n",
      "        [3.4238, 3.5363, 3.6913, 3.5757, 3.5119],\n",
      "        [3.4760, 3.5849, 3.6134, 3.5770, 3.5470],\n",
      "        [3.8937, 3.8559, 4.0067, 4.0270, 3.8887],\n",
      "        [3.9135, 3.7181, 3.9736, 4.3148, 4.1384],\n",
      "        [3.5528, 3.5915, 3.8737, 3.7792, 3.6722],\n",
      "        [3.8316, 3.7818, 3.9465, 3.9553, 3.8041],\n",
      "        [3.3991, 3.5176, 3.5870, 3.5029, 3.4829],\n",
      "        [3.3707, 3.4970, 3.5774, 3.4710, 3.4697],\n",
      "        [3.6192, 3.5009, 3.7739, 3.8430, 3.5378],\n",
      "        [3.5741, 3.5729, 3.8314, 3.6955, 3.6584],\n",
      "        [3.5704, 3.7055, 3.8250, 3.7141, 3.5704],\n",
      "        [3.8025, 3.8408, 3.9488, 3.8863, 3.9691],\n",
      "        [3.6299, 3.9152, 3.8334, 3.8737, 3.7956],\n",
      "        [3.8347, 3.9385, 3.7945, 3.7891, 3.7313],\n",
      "        [3.5473, 3.6000, 3.7075, 3.6443, 3.6060],\n",
      "        [3.5234, 3.6777, 3.7525, 3.5718, 3.5492],\n",
      "        [3.5514, 3.8623, 3.7651, 3.8341, 3.7296],\n",
      "        [3.5370, 3.6406, 3.7705, 3.7726, 3.5925],\n",
      "        [3.5451, 3.5697, 3.6579, 3.6978, 3.5576],\n",
      "        [3.6649, 3.6002, 3.8169, 3.6346, 3.6284],\n",
      "        [3.5604, 3.6545, 3.7691, 3.8262, 3.5925],\n",
      "        [3.5523, 3.6447, 3.6291, 3.6940, 3.5915],\n",
      "        [3.4759, 3.8434, 3.8856, 3.7111, 3.8030],\n",
      "        [3.4997, 3.4358, 3.6993, 3.6175, 3.5918],\n",
      "        [3.7060, 3.8320, 3.8065, 3.9348, 3.7785],\n",
      "        [3.5190, 3.6629, 3.6648, 3.7549, 3.5409],\n",
      "        [3.6037, 3.6679, 3.7772, 3.6990, 3.7468],\n",
      "        [3.6290, 3.6126, 3.8581, 3.7471, 3.6838],\n",
      "        [3.9265, 3.8498, 3.9846, 4.0697, 3.8734],\n",
      "        [3.4165, 3.4982, 3.6628, 3.5574, 3.4813],\n",
      "        [3.9697, 3.8803, 4.0261, 4.0661, 3.9955],\n",
      "        [3.5354, 3.5663, 3.7477, 3.6738, 3.5954],\n",
      "        [3.6731, 3.6959, 3.8718, 3.7631, 3.6962],\n",
      "        [3.5996, 3.5932, 3.7616, 3.7040, 3.6394],\n",
      "        [3.4592, 3.6573, 3.5973, 3.6465, 3.4875],\n",
      "        [3.4387, 3.4834, 3.6599, 3.5731, 3.4860],\n",
      "        [3.6203, 3.8059, 3.8023, 3.7754, 3.7965],\n",
      "        [3.3510, 3.4787, 3.5655, 3.4476, 3.4502],\n",
      "        [3.7177, 3.6685, 3.8709, 3.8825, 3.6321],\n",
      "        [3.9609, 3.9056, 3.9876, 4.0635, 3.9751],\n",
      "        [3.5459, 3.8410, 3.8754, 3.7748, 3.8150],\n",
      "        [3.5630, 3.7326, 3.7716, 3.6413, 3.6820],\n",
      "        [3.7136, 3.4968, 3.6713, 3.6591, 3.6803],\n",
      "        [3.5714, 3.6690, 3.6366, 3.7271, 3.6091],\n",
      "        [3.4609, 3.4783, 3.5452, 3.6229, 3.4409],\n",
      "        [3.4920, 3.5509, 3.5240, 3.6814, 3.4481],\n",
      "        [3.6707, 3.7063, 3.7480, 3.7350, 3.6449],\n",
      "        [3.6882, 3.7847, 3.8755, 3.7874, 3.6019],\n",
      "        [3.7939, 3.8636, 3.8955, 3.8515, 3.8749],\n",
      "        [3.5517, 3.6390, 3.6267, 3.6725, 3.5975],\n",
      "        [3.8374, 3.8006, 3.9810, 3.9189, 3.9647]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8594, 3.7971, 3.9992, 4.0794, 3.7490],\n",
      "        [3.5625, 3.5024, 3.7624, 3.6730, 3.6950],\n",
      "        [3.6928, 3.8042, 3.9227, 3.8206, 3.7019],\n",
      "        [3.7768, 3.9424, 3.9283, 3.9759, 3.8645],\n",
      "        [3.5410, 3.8476, 3.8220, 3.7805, 3.8033],\n",
      "        [3.4151, 3.5601, 3.6920, 3.5653, 3.5152],\n",
      "        [3.9016, 3.8328, 3.9257, 3.9596, 3.9142],\n",
      "        [3.5329, 3.4946, 3.7416, 3.6273, 3.5609],\n",
      "        [3.6714, 3.6424, 3.7675, 3.8561, 3.7222],\n",
      "        [3.8361, 3.8064, 3.9609, 3.9857, 3.8161],\n",
      "        [3.7850, 3.8618, 3.9694, 3.8940, 3.9599],\n",
      "        [3.8292, 3.9628, 3.8903, 3.7628, 3.7280],\n",
      "        [3.8331, 3.8653, 4.0242, 3.8749, 3.6773],\n",
      "        [3.4145, 3.5264, 3.6797, 3.5594, 3.4939],\n",
      "        [3.5902, 3.5521, 3.8036, 3.6918, 3.6092],\n",
      "        [3.3453, 3.4735, 3.5662, 3.4402, 3.4438],\n",
      "        [3.5182, 3.6164, 3.7408, 3.7252, 3.6095],\n",
      "        [3.3642, 3.4970, 3.5777, 3.4628, 3.4650],\n",
      "        [3.4764, 3.8434, 3.8875, 3.7121, 3.8063],\n",
      "        [3.4476, 3.4526, 3.6423, 3.5806, 3.4732],\n",
      "        [3.7681, 3.8263, 3.9524, 3.8669, 3.9270],\n",
      "        [3.5838, 3.6197, 3.7721, 3.6031, 3.4495],\n",
      "        [3.8872, 3.6592, 3.8516, 4.1889, 3.9598],\n",
      "        [3.4447, 3.6772, 3.9017, 3.6668, 3.6670],\n",
      "        [3.5067, 3.5398, 3.7480, 3.6526, 3.5868],\n",
      "        [3.5709, 3.5590, 3.7810, 3.6324, 3.5982],\n",
      "        [3.6804, 3.8239, 3.8572, 3.9047, 3.7386],\n",
      "        [3.7074, 3.7087, 3.6851, 3.8253, 3.7940],\n",
      "        [3.4811, 3.5855, 3.6166, 3.5859, 3.5596],\n",
      "        [3.3195, 3.4614, 3.6359, 3.4868, 3.4995],\n",
      "        [3.7064, 3.8319, 3.8084, 3.9358, 3.7819],\n",
      "        [3.5885, 3.5791, 3.8145, 3.7197, 3.6544],\n",
      "        [3.9727, 3.9309, 3.9893, 4.1660, 3.9586],\n",
      "        [3.6247, 3.6455, 3.7705, 3.7356, 3.7244],\n",
      "        [3.7690, 3.7698, 3.9269, 3.8814, 3.9328],\n",
      "        [3.3844, 3.5145, 3.5881, 3.4966, 3.4877],\n",
      "        [3.4641, 3.4582, 3.6460, 3.6080, 3.4924],\n",
      "        [3.7003, 3.8252, 3.8017, 3.9268, 3.7721],\n",
      "        [3.5168, 3.5308, 3.6895, 3.6824, 3.5215],\n",
      "        [3.5582, 3.5009, 3.7408, 3.6725, 3.7003],\n",
      "        [3.4462, 3.7113, 3.6377, 3.4328, 3.6090],\n",
      "        [3.6304, 3.7872, 3.8329, 3.7422, 3.5636],\n",
      "        [3.4241, 3.5363, 3.6930, 3.5767, 3.5151],\n",
      "        [3.4570, 3.5590, 3.5832, 3.6296, 3.5190],\n",
      "        [3.5366, 3.6294, 3.6277, 3.6684, 3.5871],\n",
      "        [3.6971, 3.4798, 3.6596, 3.6667, 3.6529],\n",
      "        [3.7476, 3.9238, 3.8985, 3.9419, 3.8422],\n",
      "        [3.6256, 3.6275, 3.7702, 3.7717, 3.6467],\n",
      "        [3.6320, 3.5375, 3.9947, 3.7507, 3.7242],\n",
      "        [3.4190, 3.5514, 3.6984, 3.5745, 3.5180],\n",
      "        [3.5521, 3.6389, 3.6286, 3.6735, 3.6007],\n",
      "        [3.4947, 3.7290, 3.7723, 3.7031, 3.7412],\n",
      "        [3.5246, 3.6206, 3.6134, 3.6637, 3.5642],\n",
      "        [3.7003, 3.8526, 3.9236, 3.8603, 3.8215],\n",
      "        [3.6434, 3.6936, 3.8222, 3.7188, 3.7973],\n",
      "        [3.4980, 3.5956, 3.6090, 3.6135, 3.5581],\n",
      "        [3.7943, 3.8637, 3.8972, 3.8524, 3.8783],\n",
      "        [3.5333, 3.4699, 3.6750, 3.6126, 3.6774],\n",
      "        [3.4293, 3.4885, 3.6628, 3.5635, 3.4876],\n",
      "        [3.5756, 3.6480, 3.7612, 3.8317, 3.6118],\n",
      "        [3.5986, 3.6262, 3.7932, 3.6755, 3.8363],\n",
      "        [4.0964, 4.1846, 3.9724, 3.9537, 3.7964],\n",
      "        [3.4844, 3.7836, 3.8238, 3.7138, 3.7489],\n",
      "        [3.5550, 3.5116, 3.7717, 3.5755, 3.6472]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5576, 3.7039, 3.6900, 3.8086, 3.5637],\n",
      "        [3.4257, 3.6449, 3.8585, 3.5825, 3.6114],\n",
      "        [3.5157, 3.8105, 3.8568, 3.7544, 3.7585],\n",
      "        [3.9133, 3.9943, 3.8156, 3.8285, 3.7415],\n",
      "        [3.5298, 3.4754, 3.7726, 3.5138, 3.6514],\n",
      "        [3.7042, 3.8292, 3.8085, 3.9368, 3.7812],\n",
      "        [3.4894, 3.6632, 3.6209, 3.6852, 3.5094],\n",
      "        [3.6094, 3.6720, 3.7941, 3.7217, 3.7595],\n",
      "        [3.5246, 3.6204, 3.6146, 3.6659, 3.5670],\n",
      "        [3.5716, 3.7023, 3.8176, 3.6961, 3.7784],\n",
      "        [3.6035, 3.5892, 3.8422, 3.7389, 3.6836],\n",
      "        [3.7163, 3.8118, 3.9170, 3.8539, 3.7510],\n",
      "        [3.5425, 3.6283, 3.7401, 3.6584, 3.6370],\n",
      "        [3.4106, 3.5308, 3.6789, 3.5568, 3.4968],\n",
      "        [3.6956, 3.7686, 3.7892, 3.8275, 3.7198],\n",
      "        [3.7086, 3.8878, 3.9423, 3.8748, 3.8810],\n",
      "        [3.5031, 3.5419, 3.7429, 3.6585, 3.5899],\n",
      "        [3.5367, 3.6291, 3.6289, 3.6706, 3.5898],\n",
      "        [3.6740, 3.5589, 3.9894, 3.8007, 3.7668],\n",
      "        [4.1410, 4.3019, 3.9909, 4.0188, 3.8997],\n",
      "        [3.6523, 3.6836, 3.8691, 3.7691, 3.6641],\n",
      "        [3.9206, 3.7152, 3.9737, 4.3178, 4.1426],\n",
      "        [3.5795, 3.6765, 3.6393, 3.7358, 3.6170],\n",
      "        [3.5823, 3.5559, 3.8204, 3.6917, 3.6610],\n",
      "        [3.4573, 3.6684, 3.9082, 3.6531, 3.6894],\n",
      "        [3.7032, 3.6910, 3.8456, 3.7301, 3.5486],\n",
      "        [3.3484, 3.4780, 3.5692, 3.4488, 3.4570],\n",
      "        [3.6718, 3.6266, 3.8058, 3.7396, 3.6363],\n",
      "        [3.7175, 3.8372, 3.9464, 3.8005, 3.6420],\n",
      "        [3.3514, 3.4784, 3.5681, 3.4508, 3.4561],\n",
      "        [3.6265, 3.8309, 3.8243, 3.7938, 3.8223],\n",
      "        [3.4151, 3.5598, 3.6931, 3.5676, 3.5180],\n",
      "        [3.6050, 3.8889, 3.9430, 3.8388, 3.8671],\n",
      "        [3.5980, 3.7374, 3.7244, 3.6593, 3.6640],\n",
      "        [3.6736, 3.6872, 3.8526, 3.7477, 3.7839],\n",
      "        [3.4729, 3.5601, 3.7488, 3.6378, 3.5103],\n",
      "        [3.5544, 3.7093, 3.8346, 3.7148, 3.5640],\n",
      "        [3.5578, 3.7148, 3.7423, 3.6994, 3.6796],\n",
      "        [3.4227, 3.5093, 3.6734, 3.5769, 3.4998],\n",
      "        [3.4120, 3.6347, 3.8372, 3.5952, 3.6165],\n",
      "        [3.4152, 3.4556, 3.6429, 3.5445, 3.4703],\n",
      "        [4.0498, 4.2341, 3.9292, 3.9667, 3.7974],\n",
      "        [3.4700, 3.4000, 3.7270, 3.4174, 3.6128],\n",
      "        [3.3769, 3.5046, 3.5861, 3.4788, 3.4872],\n",
      "        [3.5624, 3.6596, 3.6306, 3.7122, 3.6017],\n",
      "        [3.7253, 3.6068, 3.7637, 4.0015, 3.7909],\n",
      "        [3.9706, 3.8800, 4.0294, 4.0693, 4.0019],\n",
      "        [3.7273, 3.8537, 3.8097, 3.7952, 3.7740],\n",
      "        [3.4382, 3.5356, 3.6881, 3.5794, 3.5325],\n",
      "        [3.7649, 3.8392, 3.8330, 3.8932, 3.8355],\n",
      "        [3.4335, 3.4744, 3.6552, 3.5681, 3.4861],\n",
      "        [3.5537, 3.5607, 3.7527, 3.6743, 3.6018],\n",
      "        [3.8315, 3.5324, 3.8237, 4.0681, 3.9810],\n",
      "        [3.7342, 3.7444, 3.9149, 3.8636, 3.6332],\n",
      "        [3.5436, 3.5420, 3.7364, 3.6492, 3.5915],\n",
      "        [3.5615, 3.6544, 3.7736, 3.8298, 3.5992],\n",
      "        [3.6521, 3.5478, 3.9842, 3.7722, 3.7508],\n",
      "        [3.3880, 3.3806, 3.5943, 3.5876, 3.4407],\n",
      "        [3.6862, 3.9403, 3.9563, 3.8581, 3.8639],\n",
      "        [3.7273, 3.8460, 3.8096, 3.7956, 3.7807],\n",
      "        [3.5455, 3.7699, 3.8388, 3.6132, 3.7169],\n",
      "        [3.5619, 3.7035, 3.8252, 3.7125, 3.5720],\n",
      "        [3.4086, 3.5977, 3.7114, 3.5662, 3.5230],\n",
      "        [3.4447, 3.4451, 3.6391, 3.5818, 3.4726]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6955, 3.7680, 3.7911, 3.8299, 3.7241],\n",
      "        [3.9804, 4.0203, 4.0838, 4.2391, 4.0291],\n",
      "        [3.7094, 3.8632, 3.8150, 3.7966, 3.7638],\n",
      "        [3.6658, 3.7317, 3.7860, 3.7523, 3.8276],\n",
      "        [3.4549, 3.5585, 3.7567, 3.6315, 3.5046],\n",
      "        [3.7835, 3.8220, 3.9661, 3.8775, 3.9845],\n",
      "        [3.5793, 3.6759, 3.6409, 3.7382, 3.6212],\n",
      "        [3.5645, 3.6571, 3.6277, 3.7151, 3.6042],\n",
      "        [3.4069, 3.4522, 3.6363, 3.5407, 3.4488],\n",
      "        [3.4084, 3.5972, 3.7129, 3.5686, 3.5273],\n",
      "        [3.5651, 3.6513, 3.7744, 3.6688, 3.5458],\n",
      "        [3.6440, 3.6752, 3.7251, 3.7831, 3.6897],\n",
      "        [3.4836, 3.7726, 3.7441, 3.5986, 3.4951],\n",
      "        [3.6976, 3.8168, 3.9159, 3.8558, 3.7751],\n",
      "        [3.7244, 3.7135, 3.8249, 3.8651, 3.8480],\n",
      "        [3.9139, 3.7172, 3.9788, 4.3203, 4.1491],\n",
      "        [3.7063, 3.8310, 3.8116, 3.9407, 3.7891],\n",
      "        [3.7063, 3.8310, 3.8116, 3.9407, 3.7891],\n",
      "        [3.4765, 3.8426, 3.8903, 3.7171, 3.8134],\n",
      "        [3.5488, 3.5323, 3.7514, 3.6594, 3.5887],\n",
      "        [3.5346, 3.5786, 3.6668, 3.5964, 3.5843],\n",
      "        [3.5295, 3.4748, 3.7742, 3.5161, 3.6556],\n",
      "        [3.4425, 3.5675, 3.6086, 3.5621, 3.5350],\n",
      "        [3.5697, 3.6403, 3.7765, 3.6727, 3.5292],\n",
      "        [3.7499, 3.6005, 3.7963, 3.7470, 3.7064],\n",
      "        [3.8967, 3.8790, 3.9051, 3.9482, 3.9645],\n",
      "        [3.5400, 3.6283, 3.6230, 3.6733, 3.5929],\n",
      "        [3.4493, 3.4587, 3.6452, 3.5875, 3.4834],\n",
      "        [3.4178, 3.5097, 3.6753, 3.5648, 3.4974],\n",
      "        [3.5634, 3.5811, 3.8423, 3.6126, 3.7646],\n",
      "        [3.8496, 3.6942, 3.9424, 3.9782, 3.7909],\n",
      "        [3.6578, 3.5927, 3.9164, 3.8333, 3.6390],\n",
      "        [3.3709, 3.4309, 3.5830, 3.4822, 3.4506],\n",
      "        [3.6500, 3.4736, 3.8875, 3.7558, 3.6744],\n",
      "        [3.5716, 3.7991, 3.8078, 3.6948, 3.5331],\n",
      "        [3.5684, 3.5149, 3.7833, 3.6881, 3.7118],\n",
      "        [3.5549, 3.5107, 3.7746, 3.5800, 3.6543],\n",
      "        [3.4093, 3.6349, 3.7084, 3.6201, 3.6996],\n",
      "        [3.8330, 3.8644, 4.0275, 3.8795, 3.6845],\n",
      "        [3.5496, 3.6960, 3.7957, 3.7053, 3.6273],\n",
      "        [3.5624, 3.6502, 3.6223, 3.7070, 3.5929],\n",
      "        [3.6857, 3.7607, 3.7959, 3.8112, 3.7798],\n",
      "        [3.6331, 3.9435, 3.8689, 3.9027, 3.8457],\n",
      "        [3.5514, 3.6945, 3.7277, 3.7174, 3.6811],\n",
      "        [3.5506, 3.5300, 3.7575, 3.6552, 3.5862],\n",
      "        [3.4240, 3.5355, 3.6957, 3.5812, 3.5221],\n",
      "        [3.7057, 3.4884, 3.6693, 3.6659, 3.6679],\n",
      "        [3.4772, 3.6262, 3.6777, 3.6247, 3.6110],\n",
      "        [3.4178, 3.5097, 3.6753, 3.5648, 3.4974],\n",
      "        [3.6050, 3.7319, 3.7017, 3.6774, 3.6537],\n",
      "        [3.6611, 3.6880, 3.7960, 3.8743, 3.6700],\n",
      "        [3.3814, 3.5182, 3.6061, 3.4897, 3.5016],\n",
      "        [3.3846, 3.3720, 3.6021, 3.5759, 3.4517],\n",
      "        [3.7842, 3.6214, 3.7905, 3.7792, 3.7590],\n",
      "        [3.9787, 4.0493, 3.8334, 3.8849, 3.7393],\n",
      "        [3.7960, 3.8016, 4.0754, 3.8172, 3.6388],\n",
      "        [3.9124, 3.7997, 3.9255, 4.0550, 3.8678],\n",
      "        [3.5453, 3.5704, 3.7539, 3.6768, 3.6083],\n",
      "        [3.6299, 3.6652, 3.7924, 3.7121, 3.6680],\n",
      "        [3.4269, 3.4829, 3.6607, 3.5686, 3.4932],\n",
      "        [3.5522, 3.6898, 3.7952, 3.6954, 3.6531],\n",
      "        [3.5956, 3.7501, 3.7798, 3.7900, 3.6297],\n",
      "        [3.4461, 3.4667, 3.6558, 3.5821, 3.4898],\n",
      "        [3.5368, 3.5178, 3.7519, 3.6498, 3.5803]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5217, 3.8592, 3.9017, 3.7827, 3.8425],\n",
      "        [3.6020, 3.7310, 3.7152, 3.6672, 3.6612],\n",
      "        [3.4185, 3.6315, 3.7316, 3.5796, 3.5544],\n",
      "        [3.8243, 3.8768, 3.8848, 3.8952, 3.9286],\n",
      "        [3.8965, 3.8783, 3.9062, 3.9499, 3.9683],\n",
      "        [3.5689, 3.7103, 3.8224, 3.7220, 3.6082],\n",
      "        [3.3802, 3.5141, 3.5947, 3.4969, 3.4943],\n",
      "        [3.5490, 3.7941, 3.8007, 3.6824, 3.5285],\n",
      "        [4.0163, 4.0761, 3.8236, 3.9071, 3.7259],\n",
      "        [3.4416, 3.4556, 3.6486, 3.5805, 3.4881],\n",
      "        [3.5040, 3.6324, 3.7680, 3.7606, 3.5488],\n",
      "        [3.5443, 3.5666, 3.8980, 3.5357, 3.7816],\n",
      "        [3.5518, 3.5179, 3.7644, 3.6434, 3.5954],\n",
      "        [3.3118, 3.4589, 3.6308, 3.4890, 3.4827],\n",
      "        [3.5436, 3.5738, 3.7587, 3.6857, 3.6176],\n",
      "        [3.5955, 3.7493, 3.7814, 3.7921, 3.6336],\n",
      "        [4.1421, 4.3012, 3.9863, 4.0037, 3.9004],\n",
      "        [3.7460, 3.6632, 3.8757, 3.9482, 3.6247],\n",
      "        [3.6918, 3.6583, 3.8368, 3.7189, 3.5682],\n",
      "        [3.4134, 3.6098, 3.7214, 3.5747, 3.5397],\n",
      "        [3.5418, 3.6159, 3.7069, 3.6405, 3.6230],\n",
      "        [3.6107, 3.8153, 3.7650, 3.8619, 3.7255],\n",
      "        [3.6088, 3.7880, 3.7421, 3.7480, 3.6847],\n",
      "        [3.7037, 3.8277, 3.8114, 3.9412, 3.7894],\n",
      "        [3.7334, 3.6669, 3.7980, 3.9943, 3.8263],\n",
      "        [3.5783, 3.6667, 3.8633, 3.7369, 3.7032],\n",
      "        [3.4387, 3.4140, 3.6175, 3.5804, 3.4586],\n",
      "        [3.5610, 3.7425, 3.7954, 3.6423, 3.7069],\n",
      "        [3.4769, 3.6769, 3.6154, 3.6553, 3.5050],\n",
      "        [3.4737, 3.5353, 3.7156, 3.6708, 3.5760],\n",
      "        [3.4421, 3.5667, 3.6096, 3.5639, 3.5387],\n",
      "        [3.4725, 3.5616, 3.7716, 3.7041, 3.6305],\n",
      "        [3.4114, 3.6333, 3.8399, 3.5996, 3.6246],\n",
      "        [3.5380, 3.5932, 3.8458, 3.7677, 3.7772],\n",
      "        [3.4376, 3.5342, 3.6907, 3.5835, 3.5404],\n",
      "        [3.4510, 3.4308, 3.6260, 3.6018, 3.4862],\n",
      "        [3.5640, 3.6850, 3.8103, 3.6927, 3.7618],\n",
      "        [3.7551, 3.6708, 3.8102, 3.7065, 3.5964],\n",
      "        [3.4816, 3.5395, 3.6953, 3.5763, 3.5523],\n",
      "        [3.5489, 3.7585, 3.8255, 3.6237, 3.7175],\n",
      "        [3.7419, 3.7363, 4.0592, 3.7433, 3.6285],\n",
      "        [3.7969, 3.7669, 3.9437, 3.8834, 3.9469],\n",
      "        [3.6298, 3.7021, 3.7347, 3.7460, 3.7365],\n",
      "        [3.4129, 3.4203, 3.6285, 3.5709, 3.4837],\n",
      "        [3.5532, 3.5593, 3.7556, 3.6783, 3.6095],\n",
      "        [3.8608, 3.8494, 3.9788, 3.9475, 4.0615],\n",
      "        [3.6461, 3.7188, 3.9499, 3.7952, 3.7571],\n",
      "        [3.6261, 3.8295, 3.8272, 3.7979, 3.8304],\n",
      "        [3.7109, 3.8067, 3.8227, 3.8382, 3.7454],\n",
      "        [4.0253, 4.1141, 3.9795, 3.9366, 3.8402],\n",
      "        [3.4237, 3.5347, 3.6967, 3.5830, 3.5257],\n",
      "        [3.3969, 3.5229, 3.5954, 3.5123, 3.5045],\n",
      "        [3.6030, 3.7282, 3.7039, 3.6690, 3.6531],\n",
      "        [3.5431, 3.6039, 3.7498, 3.6862, 3.7269],\n",
      "        [3.4200, 3.5435, 3.6035, 3.5406, 3.5187],\n",
      "        [3.5483, 3.6375, 3.7507, 3.6225, 3.5359],\n",
      "        [3.3949, 3.4385, 3.6000, 3.5159, 3.4711],\n",
      "        [3.7334, 3.9161, 3.8993, 3.9338, 3.8481],\n",
      "        [3.4396, 3.4087, 3.6199, 3.5859, 3.4554],\n",
      "        [3.7050, 3.7921, 3.8955, 3.9258, 3.7238],\n",
      "        [3.5681, 3.5186, 3.7827, 3.6782, 3.6863],\n",
      "        [3.6652, 3.6594, 3.9082, 3.8182, 3.6714],\n",
      "        [3.5427, 3.8615, 3.8362, 3.7966, 3.8206],\n",
      "        [3.7058, 3.8494, 3.8051, 3.7894, 3.7646]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5667, 3.7125, 3.8208, 3.7217, 3.5972],\n",
      "        [3.4276, 3.4801, 3.6637, 3.5753, 3.4986],\n",
      "        [3.4180, 3.5351, 3.6058, 3.5377, 3.5361],\n",
      "        [3.4829, 3.5841, 3.6134, 3.6053, 3.5657],\n",
      "        [3.5288, 3.4730, 3.7758, 3.5192, 3.6622],\n",
      "        [3.7874, 3.8468, 3.9672, 3.8998, 3.9688],\n",
      "        [3.7414, 3.7353, 4.0598, 3.7449, 3.6315],\n",
      "        [3.4376, 3.5380, 3.7163, 3.6079, 3.5128],\n",
      "        [3.6738, 3.8697, 3.9245, 3.8279, 3.7175],\n",
      "        [3.5711, 3.6648, 3.6476, 3.7322, 3.6230],\n",
      "        [3.9517, 3.7389, 4.0159, 4.3597, 4.1864],\n",
      "        [3.5804, 3.8993, 3.7963, 3.8739, 3.7972],\n",
      "        [3.9205, 3.8068, 3.9357, 4.0575, 3.8762],\n",
      "        [3.5702, 3.5234, 3.7936, 3.7049, 3.7204],\n",
      "        [3.7431, 3.7673, 3.8933, 3.8416, 3.8621],\n",
      "        [3.5430, 3.5334, 3.6934, 3.6177, 3.6505],\n",
      "        [3.3346, 3.4611, 3.5609, 3.4350, 3.4452],\n",
      "        [3.9648, 4.0330, 4.0676, 4.2351, 4.0394],\n",
      "        [3.4803, 3.5387, 3.7479, 3.6833, 3.6230],\n",
      "        [3.5794, 3.5519, 3.7781, 3.6525, 3.6616],\n",
      "        [3.7156, 3.8095, 3.9206, 3.8596, 3.7622],\n",
      "        [3.9440, 3.7929, 4.0069, 4.0819, 3.9246],\n",
      "        [3.7960, 3.9273, 4.0281, 3.8757, 3.6655],\n",
      "        [3.4560, 3.5450, 3.5858, 3.6403, 3.5306],\n",
      "        [3.4106, 3.5777, 3.7063, 3.5811, 3.5357],\n",
      "        [3.5991, 3.5906, 3.7681, 3.7129, 3.6564],\n",
      "        [3.6075, 3.6067, 3.7668, 3.7415, 3.6549],\n",
      "        [3.4437, 3.4429, 3.6422, 3.5871, 3.4829],\n",
      "        [3.4467, 3.4501, 3.6466, 3.5879, 3.4862],\n",
      "        [3.9262, 3.8503, 3.9976, 4.0875, 3.8967],\n",
      "        [3.6660, 3.7505, 3.8868, 3.8555, 3.8052],\n",
      "        [3.7006, 3.8134, 3.9165, 3.8542, 3.7826],\n",
      "        [3.6622, 3.7515, 3.9097, 3.8664, 3.7795],\n",
      "        [3.5746, 3.5806, 3.8487, 3.7139, 3.6817],\n",
      "        [3.7650, 3.9326, 3.9118, 3.9602, 3.8724],\n",
      "        [3.4942, 3.7265, 3.7767, 3.7111, 3.7546],\n",
      "        [3.4952, 3.5936, 3.6212, 3.6101, 3.5791],\n",
      "        [3.7779, 3.7821, 4.0592, 3.7892, 3.6165],\n",
      "        [3.7768, 3.7909, 3.9089, 3.8620, 3.9506],\n",
      "        [3.7676, 3.8822, 3.9923, 3.8360, 3.5875],\n",
      "        [3.5560, 3.6474, 3.6342, 3.7050, 3.6102],\n",
      "        [3.4733, 3.5344, 3.7161, 3.6721, 3.5788],\n",
      "        [3.5861, 3.6475, 3.7610, 3.6674, 3.6564],\n",
      "        [3.4955, 3.4255, 3.6119, 3.5999, 3.4663],\n",
      "        [4.0492, 4.0095, 4.0327, 4.2702, 3.8878],\n",
      "        [3.5878, 3.5764, 3.8190, 3.7273, 3.6679],\n",
      "        [3.4551, 3.5842, 3.8500, 3.6392, 3.6846],\n",
      "        [3.7633, 3.6006, 3.7825, 3.7555, 3.7390],\n",
      "        [3.9541, 3.9192, 3.9868, 4.1375, 3.8666],\n",
      "        [3.4724, 3.5794, 3.6090, 3.5958, 3.5524],\n",
      "        [3.5590, 3.5946, 3.7802, 3.7084, 3.6430],\n",
      "        [3.9071, 3.8104, 3.9579, 4.0543, 3.9075],\n",
      "        [4.0587, 4.1518, 4.0290, 3.9657, 3.8931],\n",
      "        [3.7364, 3.7358, 3.9381, 3.7951, 3.6244],\n",
      "        [3.4606, 3.5771, 3.6179, 3.5873, 3.5544],\n",
      "        [3.5479, 3.6365, 3.7510, 3.6236, 3.5387],\n",
      "        [3.5651, 3.7905, 3.7156, 3.8145, 3.6944],\n",
      "        [3.4446, 3.5015, 3.6930, 3.5999, 3.4915],\n",
      "        [3.4571, 3.5249, 3.5908, 3.6396, 3.5200],\n",
      "        [3.4135, 3.6451, 3.5683, 3.6386, 3.4801],\n",
      "        [3.9239, 3.8465, 3.9964, 4.0861, 3.8896],\n",
      "        [3.5952, 3.7484, 3.7825, 3.7938, 3.6366],\n",
      "        [3.9077, 3.6486, 3.8575, 4.2316, 3.9912],\n",
      "        [3.6360, 3.7225, 3.7819, 3.7835, 3.7308]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6708, 3.8887, 3.9388, 3.8491, 3.9244],\n",
      "        [3.4965, 3.5928, 3.6148, 3.6229, 3.5738],\n",
      "        [3.4556, 3.4619, 3.6557, 3.5960, 3.5014],\n",
      "        [3.5555, 3.6471, 3.6358, 3.7068, 3.6126],\n",
      "        [3.7048, 3.8289, 3.8150, 3.9460, 3.7983],\n",
      "        [3.6085, 3.5147, 3.7522, 3.6878, 3.5715],\n",
      "        [3.6062, 3.6668, 3.7772, 3.7406, 3.7555],\n",
      "        [3.6608, 3.6684, 3.8381, 3.7156, 3.8058],\n",
      "        [3.5674, 3.5719, 3.7812, 3.6993, 3.6511],\n",
      "        [3.4494, 3.4361, 3.6377, 3.5991, 3.4850],\n",
      "        [3.8315, 3.7800, 3.9554, 3.9660, 3.8249],\n",
      "        [3.7931, 3.8610, 3.9028, 3.8617, 3.8945],\n",
      "        [3.3499, 3.4760, 3.5724, 3.4577, 3.4691],\n",
      "        [3.6911, 3.7711, 3.7954, 3.7664, 3.8257],\n",
      "        [3.6199, 3.4986, 3.7861, 3.8548, 3.5586],\n",
      "        [3.7788, 3.9346, 3.8841, 3.7144, 3.7678],\n",
      "        [3.3541, 3.4821, 3.5815, 3.4561, 3.4729],\n",
      "        [3.7104, 3.6537, 3.7672, 3.9488, 3.7956],\n",
      "        [3.4071, 3.5241, 3.6797, 3.5650, 3.5094],\n",
      "        [3.4270, 3.4798, 3.6652, 3.5769, 3.5009],\n",
      "        [3.5534, 3.5674, 3.7579, 3.6835, 3.6204],\n",
      "        [3.5454, 3.4934, 3.6364, 3.7382, 3.5091],\n",
      "        [3.5282, 3.4727, 3.7773, 3.5210, 3.6646],\n",
      "        [3.5523, 3.6426, 3.6287, 3.7002, 3.5989],\n",
      "        [3.5381, 3.6233, 3.7044, 3.6433, 3.6196],\n",
      "        [3.4827, 3.4868, 3.7610, 3.6299, 3.5645],\n",
      "        [3.6439, 3.9035, 3.8911, 3.8353, 3.8587],\n",
      "        [3.7062, 3.7743, 3.8156, 3.6891, 3.7076],\n",
      "        [3.7363, 3.6641, 3.8671, 3.9370, 3.6332],\n",
      "        [3.4724, 3.4826, 3.6796, 3.6065, 3.5051],\n",
      "        [3.6078, 3.7870, 3.7443, 3.7511, 3.6900],\n",
      "        [3.6914, 3.8014, 3.9295, 3.8301, 3.7181],\n",
      "        [3.7817, 3.6712, 3.8240, 3.8373, 3.8171],\n",
      "        [3.5539, 3.5818, 3.7692, 3.6969, 3.6382],\n",
      "        [3.3939, 3.4374, 3.6020, 3.5190, 3.4764],\n",
      "        [3.5395, 3.5076, 3.7352, 3.6108, 3.5627],\n",
      "        [3.7936, 3.8572, 3.8569, 3.8446, 3.8854],\n",
      "        [3.4631, 3.5258, 3.7235, 3.6420, 3.5055],\n",
      "        [3.4477, 3.4367, 3.6397, 3.5985, 3.4877],\n",
      "        [3.4900, 3.7926, 3.8294, 3.7278, 3.7878],\n",
      "        [3.8593, 3.8481, 3.8861, 3.9393, 3.9406],\n",
      "        [3.3739, 3.4082, 3.6191, 3.5048, 3.4226],\n",
      "        [3.8624, 3.8781, 3.9020, 3.9341, 3.9422],\n",
      "        [3.7427, 3.8739, 3.8043, 3.7735, 3.7533],\n",
      "        [3.8483, 3.7223, 3.8517, 3.8657, 3.8626],\n",
      "        [3.3779, 3.4948, 3.4915, 3.5685, 3.4427],\n",
      "        [3.7035, 3.4836, 3.6675, 3.6818, 3.6597],\n",
      "        [3.9067, 3.8102, 3.9598, 4.0561, 3.9100],\n",
      "        [3.5872, 3.8064, 3.7409, 3.8436, 3.7175],\n",
      "        [3.4698, 3.7636, 3.7776, 3.5257, 3.7196],\n",
      "        [3.5636, 3.5581, 3.7905, 3.6992, 3.6480],\n",
      "        [3.5496, 3.5707, 3.7617, 3.6789, 3.6182],\n",
      "        [3.8069, 3.8031, 4.0210, 4.0200, 3.7621],\n",
      "        [3.5919, 3.5630, 3.8149, 3.6803, 3.6367],\n",
      "        [3.7145, 3.7855, 3.8200, 3.7575, 3.7168],\n",
      "        [3.6465, 3.6515, 3.7875, 3.7346, 3.6482],\n",
      "        [3.6455, 3.8584, 3.9266, 3.7847, 3.7860],\n",
      "        [3.5488, 3.4904, 3.7151, 3.6547, 3.7130],\n",
      "        [3.4786, 3.6164, 3.6511, 3.7108, 3.5441],\n",
      "        [3.6974, 3.7994, 3.7981, 3.7631, 3.7341],\n",
      "        [3.7072, 3.8853, 3.9477, 3.8823, 3.8949],\n",
      "        [3.6065, 3.5546, 3.8025, 3.6944, 3.6829],\n",
      "        [3.7682, 3.7673, 3.9350, 3.8941, 3.9502],\n",
      "        [3.6251, 3.8284, 3.8296, 3.8011, 3.8358]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6950, 3.6541, 3.8419, 3.7110, 3.5999],\n",
      "        [3.5385, 3.5998, 3.6826, 3.7040, 3.5946],\n",
      "        [3.6125, 3.5271, 3.7324, 3.6561, 3.6720],\n",
      "        [3.8432, 3.7970, 3.9610, 4.0005, 3.8419],\n",
      "        [3.4795, 3.5262, 3.7377, 3.6701, 3.6055],\n",
      "        [4.0523, 3.7475, 4.0409, 4.3800, 4.2489],\n",
      "        [3.7591, 3.5319, 3.8265, 3.9719, 3.9288],\n",
      "        [3.5562, 3.7113, 3.8290, 3.7297, 3.6041],\n",
      "        [3.8387, 3.7814, 3.8855, 3.8947, 3.8473],\n",
      "        [3.4127, 3.5476, 3.6230, 3.5867, 3.5104],\n",
      "        [3.9488, 3.9708, 4.0590, 4.1736, 3.9387],\n",
      "        [3.5636, 3.5807, 3.8460, 3.6202, 3.7868],\n",
      "        [4.1371, 4.2258, 4.0774, 4.0496, 3.9354],\n",
      "        [3.3353, 3.4853, 3.6403, 3.5241, 3.5166],\n",
      "        [3.6405, 3.5464, 4.0107, 3.7844, 3.7630],\n",
      "        [3.6117, 3.7188, 3.8654, 3.8322, 3.7600],\n",
      "        [3.5203, 3.4787, 3.7387, 3.6310, 3.5673],\n",
      "        [3.7979, 3.8460, 3.9983, 3.9025, 4.0226],\n",
      "        [3.5117, 3.5519, 3.6923, 3.5989, 3.5898],\n",
      "        [3.6491, 3.8987, 3.8967, 3.8412, 3.8670],\n",
      "        [3.8939, 3.8547, 4.0173, 4.0416, 3.9119],\n",
      "        [3.5473, 3.6993, 3.7982, 3.7116, 3.6444],\n",
      "        [3.6282, 3.8334, 3.8355, 3.8092, 3.8424],\n",
      "        [3.7021, 3.5259, 3.6722, 3.6592, 3.7189],\n",
      "        [3.5742, 3.6662, 3.6536, 3.7371, 3.6325],\n",
      "        [3.5837, 3.9113, 3.9543, 3.7800, 3.6885],\n",
      "        [3.6716, 3.6934, 3.6972, 3.7449, 3.7615],\n",
      "        [3.3901, 3.4333, 3.5991, 3.5144, 3.4746],\n",
      "        [3.6650, 3.7301, 3.7922, 3.7622, 3.8389],\n",
      "        [3.8803, 3.6545, 3.8608, 4.2088, 3.9713],\n",
      "        [3.6400, 3.7589, 3.9135, 3.8763, 3.7700],\n",
      "        [3.7050, 3.8291, 3.8163, 3.9497, 3.8002],\n",
      "        [3.5948, 3.7127, 3.6702, 3.6722, 3.6346],\n",
      "        [3.7865, 3.7707, 3.9390, 3.8970, 3.9492],\n",
      "        [3.9895, 3.7583, 4.0717, 4.3938, 4.2381],\n",
      "        [3.5365, 3.6271, 3.7627, 3.7348, 3.6701],\n",
      "        [3.5530, 3.6323, 3.7727, 3.8632, 3.5821],\n",
      "        [3.5481, 3.6434, 3.6364, 3.7043, 3.6078],\n",
      "        [3.7579, 3.9253, 3.9179, 3.9718, 3.8654],\n",
      "        [3.3985, 3.5289, 3.6042, 3.5259, 3.5156],\n",
      "        [3.4729, 3.5344, 3.7190, 3.6773, 3.5829],\n",
      "        [3.5707, 3.6647, 3.6504, 3.7376, 3.6271],\n",
      "        [3.5491, 3.4906, 3.7163, 3.6579, 3.7147],\n",
      "        [3.4075, 3.5826, 3.7065, 3.5731, 3.5293],\n",
      "        [3.5439, 3.6026, 3.8592, 3.7902, 3.7949],\n",
      "        [3.5612, 3.6485, 3.6267, 3.7155, 3.6035],\n",
      "        [3.6203, 3.4989, 3.7877, 3.8587, 3.5605],\n",
      "        [3.4222, 3.5012, 3.6756, 3.5737, 3.5080],\n",
      "        [3.9527, 4.0296, 3.8370, 3.8750, 3.7654],\n",
      "        [3.4058, 3.5431, 3.6886, 3.5699, 3.5158],\n",
      "        [3.7963, 3.7661, 3.9479, 3.8921, 3.9546],\n",
      "        [3.4606, 3.4452, 3.6461, 3.6086, 3.4927],\n",
      "        [3.6716, 3.7278, 3.7902, 3.7631, 3.8241],\n",
      "        [3.4422, 3.5751, 3.7461, 3.6253, 3.5462],\n",
      "        [3.7215, 3.8824, 3.8659, 3.8427, 3.7826],\n",
      "        [3.4180, 3.5578, 3.6992, 3.5842, 3.5413],\n",
      "        [3.5357, 3.7964, 3.8027, 3.6797, 3.5323],\n",
      "        [3.5197, 3.7503, 3.7640, 3.6626, 3.5774],\n",
      "        [3.6558, 3.6100, 3.8162, 3.6703, 3.5857],\n",
      "        [3.4560, 3.6663, 3.9138, 3.6643, 3.7042],\n",
      "        [3.5284, 3.4729, 3.7785, 3.5245, 3.6664],\n",
      "        [3.7040, 3.4839, 3.6687, 3.6852, 3.6614],\n",
      "        [3.5290, 3.6769, 3.7827, 3.6836, 3.6832],\n",
      "        [3.4388, 3.4079, 3.6231, 3.5922, 3.4620]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5465, 3.6418, 3.6322, 3.7021, 3.6070],\n",
      "        [3.7049, 3.8307, 3.8171, 3.9528, 3.8015],\n",
      "        [3.7049, 3.8307, 3.8171, 3.9528, 3.8015],\n",
      "        [3.6500, 3.6418, 3.7707, 3.8009, 3.7957],\n",
      "        [3.4596, 3.5726, 3.6141, 3.5994, 3.5494],\n",
      "        [3.5600, 3.6037, 3.7694, 3.6854, 3.7805],\n",
      "        [3.5610, 3.5544, 3.8248, 3.7208, 3.6557],\n",
      "        [3.5592, 3.5872, 3.6996, 3.7429, 3.6135],\n",
      "        [3.4492, 3.6107, 3.7275, 3.7418, 3.4984],\n",
      "        [3.4371, 3.4884, 3.6797, 3.6062, 3.5151],\n",
      "        [3.5211, 3.8598, 3.9058, 3.7931, 3.8508],\n",
      "        [3.7499, 3.6002, 3.8016, 3.7583, 3.7180],\n",
      "        [3.4132, 3.5785, 3.7080, 3.5783, 3.5282],\n",
      "        [3.5568, 3.5769, 3.7685, 3.6879, 3.6308],\n",
      "        [3.4298, 3.5493, 3.6123, 3.5513, 3.5416],\n",
      "        [3.7742, 3.6004, 3.7821, 3.7663, 3.7541],\n",
      "        [3.6706, 3.6256, 3.8127, 3.7531, 3.6524],\n",
      "        [3.7209, 3.8444, 3.8486, 3.8512, 3.7744],\n",
      "        [3.5316, 3.5520, 3.8749, 3.5400, 3.7722],\n",
      "        [3.6074, 3.5951, 3.8345, 3.7210, 3.7021],\n",
      "        [3.8499, 3.6905, 3.9399, 3.9914, 3.7970],\n",
      "        [3.7986, 3.9394, 4.0322, 3.8965, 3.6726],\n",
      "        [3.4313, 3.4114, 3.6178, 3.5883, 3.4639],\n",
      "        [3.7556, 4.0005, 3.9423, 3.8598, 4.0690],\n",
      "        [3.4487, 3.4203, 3.6249, 3.6005, 3.4803],\n",
      "        [3.4656, 3.5483, 3.6178, 3.6355, 3.5336],\n",
      "        [3.7790, 3.9365, 3.8862, 3.7210, 3.7709],\n",
      "        [3.7209, 3.8672, 3.8135, 3.7700, 3.7664],\n",
      "        [3.4286, 3.5708, 3.6226, 3.5659, 3.5485],\n",
      "        [3.6090, 3.6056, 3.8573, 3.7453, 3.7013],\n",
      "        [3.4532, 3.5881, 3.6421, 3.6623, 3.5427],\n",
      "        [3.6331, 3.6202, 3.8847, 3.7680, 3.7132],\n",
      "        [3.7196, 3.7289, 3.9314, 3.7906, 3.6280],\n",
      "        [3.4652, 3.7681, 3.7770, 3.5370, 3.7308],\n",
      "        [3.5197, 3.7520, 3.7650, 3.6658, 3.5787],\n",
      "        [3.7768, 3.8948, 3.9328, 3.9402, 4.0190],\n",
      "        [3.4528, 3.6352, 3.5809, 3.6451, 3.5000],\n",
      "        [3.4453, 3.5321, 3.7150, 3.6087, 3.5193],\n",
      "        [3.5882, 3.6070, 3.7777, 3.6073, 3.4710],\n",
      "        [3.7688, 3.6915, 3.8965, 3.8941, 3.7347],\n",
      "        [3.4560, 3.6678, 3.9146, 3.6673, 3.7055],\n",
      "        [4.2185, 4.3235, 4.0930, 4.0964, 3.9292],\n",
      "        [3.6440, 3.9053, 3.8934, 3.8418, 3.8619],\n",
      "        [3.5707, 3.6662, 3.6513, 3.7405, 3.6284],\n",
      "        [3.7063, 3.4930, 3.6765, 3.6835, 3.6810],\n",
      "        [3.5282, 3.6050, 3.6558, 3.6608, 3.6138],\n",
      "        [3.5245, 3.6773, 3.7785, 3.6857, 3.6681],\n",
      "        [3.7049, 3.8307, 3.8171, 3.9528, 3.8015],\n",
      "        [3.5562, 3.5831, 3.7739, 3.7032, 3.6443],\n",
      "        [3.5696, 3.6318, 3.6880, 3.7662, 3.6479],\n",
      "        [3.7038, 3.8958, 3.8504, 3.8487, 3.7762],\n",
      "        [3.5429, 3.5348, 3.6967, 3.6250, 3.6556],\n",
      "        [3.9674, 4.0158, 4.0749, 4.2135, 4.0139],\n",
      "        [3.5465, 3.5178, 3.7474, 3.6158, 3.5744],\n",
      "        [3.4725, 3.4844, 3.6816, 3.6128, 3.5082],\n",
      "        [3.6798, 3.8790, 3.9947, 3.8685, 3.7191],\n",
      "        [3.6552, 3.6039, 3.8178, 3.6670, 3.6028],\n",
      "        [3.6207, 3.6116, 3.8646, 3.7873, 3.6488],\n",
      "        [3.5661, 3.5317, 3.7820, 3.6259, 3.6671],\n",
      "        [3.8771, 3.8861, 3.9170, 3.9486, 3.9575],\n",
      "        [3.6166, 3.8731, 3.9710, 3.8670, 3.8588],\n",
      "        [3.7923, 3.9322, 4.0249, 3.8907, 3.6571],\n",
      "        [3.9433, 3.8026, 4.0181, 4.1423, 3.9748],\n",
      "        [3.5661, 3.6477, 3.7558, 3.6599, 3.6523]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5685, 3.5894, 3.8553, 3.6000, 3.7954],\n",
      "        [3.5720, 3.6620, 3.7278, 3.7705, 3.6851],\n",
      "        [3.7765, 3.9440, 3.9384, 3.9951, 3.8855],\n",
      "        [3.6637, 3.4644, 3.9150, 3.7788, 3.6864],\n",
      "        [3.6018, 3.7890, 3.8279, 3.8782, 3.6492],\n",
      "        [3.4655, 3.7699, 3.7772, 3.5396, 3.7316],\n",
      "        [3.8438, 3.8010, 3.9626, 4.0061, 3.8443],\n",
      "        [3.3475, 3.4790, 3.5756, 3.4640, 3.4741],\n",
      "        [3.4916, 3.5020, 3.7702, 3.6509, 3.5772],\n",
      "        [3.5232, 3.6174, 3.8306, 3.7626, 3.7780],\n",
      "        [3.8662, 3.6624, 3.8481, 4.1707, 3.9504],\n",
      "        [3.5623, 3.6346, 3.6782, 3.6974, 3.6472],\n",
      "        [3.5208, 3.4617, 3.6652, 3.6102, 3.6875],\n",
      "        [3.5692, 3.6066, 3.7884, 3.7319, 3.6617],\n",
      "        [3.3702, 3.4978, 3.5866, 3.4896, 3.4927],\n",
      "        [3.5747, 3.6695, 3.6547, 3.7426, 3.6345],\n",
      "        [3.6171, 3.8751, 3.9712, 3.8697, 3.8597],\n",
      "        [3.6133, 3.8265, 3.7782, 3.8768, 3.7411],\n",
      "        [3.5721, 3.9092, 3.9482, 3.7839, 3.6798],\n",
      "        [3.4431, 3.5586, 3.6101, 3.5745, 3.5384],\n",
      "        [3.3868, 3.3818, 3.6008, 3.6033, 3.4570],\n",
      "        [3.5070, 3.5397, 3.7653, 3.6709, 3.6035],\n",
      "        [3.6057, 3.5492, 3.7922, 3.6983, 3.6882],\n",
      "        [3.4094, 3.6017, 3.7161, 3.5807, 3.5405],\n",
      "        [3.7601, 3.9879, 3.9704, 4.0287, 3.9514],\n",
      "        [3.7651, 3.7945, 3.9749, 3.9934, 3.7437],\n",
      "        [3.4036, 3.5662, 3.7010, 3.5786, 3.5189],\n",
      "        [3.5805, 3.9033, 3.8007, 3.8847, 3.8038],\n",
      "        [3.4691, 3.5404, 3.7202, 3.6911, 3.5869],\n",
      "        [3.5819, 3.5797, 3.8041, 3.7306, 3.6674],\n",
      "        [3.6048, 3.7600, 3.7941, 3.8034, 3.6488],\n",
      "        [3.5311, 3.5596, 3.6427, 3.6455, 3.6674],\n",
      "        [3.6998, 3.8311, 3.8980, 3.9487, 3.7555],\n",
      "        [3.4483, 3.5347, 3.7237, 3.6236, 3.5225],\n",
      "        [3.8503, 3.6971, 3.9490, 3.9916, 3.8046],\n",
      "        [3.7557, 3.6195, 3.8025, 4.0078, 3.8250],\n",
      "        [3.4450, 3.4275, 3.6327, 3.6061, 3.4726],\n",
      "        [3.5629, 3.5826, 3.8475, 3.6267, 3.7776],\n",
      "        [3.5191, 3.4797, 3.7341, 3.6322, 3.5667],\n",
      "        [3.6487, 3.6413, 3.7715, 3.8336, 3.6965],\n",
      "        [3.7036, 3.9314, 3.9874, 3.8726, 3.8668],\n",
      "        [4.0497, 4.2355, 3.9364, 3.9831, 3.8149],\n",
      "        [3.5378, 3.6267, 3.6312, 3.6726, 3.6091],\n",
      "        [3.5503, 3.5743, 3.7640, 3.6879, 3.6219],\n",
      "        [3.8622, 3.7197, 3.9725, 4.0212, 3.8278],\n",
      "        [3.9788, 4.0512, 3.8393, 3.8988, 3.7524],\n",
      "        [3.5245, 3.6017, 3.6559, 3.6635, 3.6141],\n",
      "        [3.9630, 3.9062, 3.9985, 4.0836, 3.9988],\n",
      "        [3.8967, 3.8812, 3.9108, 3.9621, 3.9777],\n",
      "        [3.6919, 3.7751, 3.7984, 3.7767, 3.8298],\n",
      "        [3.6691, 3.9026, 3.8663, 3.8463, 3.7821],\n",
      "        [3.5840, 3.5638, 3.7854, 3.6686, 3.6734],\n",
      "        [3.5561, 3.6506, 3.6380, 3.7158, 3.6165],\n",
      "        [3.4417, 3.5691, 3.6139, 3.5756, 3.5479],\n",
      "        [3.5614, 3.6605, 3.6377, 3.7287, 3.6186],\n",
      "        [3.7069, 3.4948, 3.6767, 3.6860, 3.6818],\n",
      "        [3.8420, 3.7158, 3.9486, 3.9636, 3.7933],\n",
      "        [3.5212, 3.6179, 3.6273, 3.6473, 3.5922],\n",
      "        [3.4376, 3.5413, 3.7200, 3.6184, 3.5193],\n",
      "        [3.7425, 3.8083, 3.8492, 3.8231, 3.8415],\n",
      "        [3.9565, 3.9802, 3.9960, 4.2229, 4.0043],\n",
      "        [3.8627, 3.7932, 4.0104, 4.1036, 3.7751],\n",
      "        [3.6514, 3.5488, 3.9915, 3.7892, 3.7681],\n",
      "        [3.5517, 3.6453, 3.6394, 3.7137, 3.6143]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7025, 3.7059, 3.8608, 3.8454, 3.8846],\n",
      "        [3.6048, 3.7623, 3.7943, 3.8056, 3.6493],\n",
      "        [3.4082, 3.6067, 3.7152, 3.5822, 3.5411],\n",
      "        [3.6085, 3.5251, 3.7262, 3.6513, 3.6636],\n",
      "        [3.9691, 3.9980, 4.0646, 4.2008, 3.9752],\n",
      "        [3.5599, 3.5479, 3.8215, 3.7225, 3.6412],\n",
      "        [3.3989, 3.5342, 3.6052, 3.5329, 3.5183],\n",
      "        [3.5705, 3.6591, 3.7677, 3.7148, 3.6829],\n",
      "        [3.3797, 3.5185, 3.5987, 3.5101, 3.5041],\n",
      "        [3.3423, 3.4751, 3.5659, 3.4610, 3.4621],\n",
      "        [3.4810, 3.5991, 3.6302, 3.6221, 3.5704],\n",
      "        [3.7159, 3.8155, 3.9250, 3.8727, 3.7692],\n",
      "        [3.4088, 3.5709, 3.7007, 3.5779, 3.5252],\n",
      "        [3.6824, 3.9484, 3.9651, 3.8721, 3.8760],\n",
      "        [3.5432, 3.6086, 3.7546, 3.7000, 3.7362],\n",
      "        [3.5725, 3.6102, 3.7783, 3.6860, 3.8058],\n",
      "        [3.4390, 3.4642, 3.6539, 3.5927, 3.4961],\n",
      "        [3.3866, 3.3839, 3.6008, 3.6051, 3.4575],\n",
      "        [3.7049, 3.7950, 3.8049, 3.7986, 3.8274],\n",
      "        [3.4128, 3.6144, 3.7254, 3.5884, 3.5497],\n",
      "        [3.9464, 3.7543, 4.0077, 4.3595, 4.1669],\n",
      "        [3.8124, 3.6462, 3.8093, 3.8121, 3.8025],\n",
      "        [3.6739, 3.6213, 3.8279, 3.7639, 3.6613],\n",
      "        [3.5362, 3.8024, 3.8042, 3.6875, 3.5350],\n",
      "        [3.5546, 3.5443, 3.7550, 3.6752, 3.6159],\n",
      "        [3.6941, 3.7267, 3.7270, 3.8280, 3.7809],\n",
      "        [3.3184, 3.4646, 3.6436, 3.5069, 3.5200],\n",
      "        [3.4079, 3.5881, 3.7074, 3.5802, 3.5320],\n",
      "        [3.6601, 3.8029, 3.7777, 3.7618, 3.7154],\n",
      "        [3.5984, 3.9228, 3.8632, 3.8758, 3.8517],\n",
      "        [3.8623, 3.7085, 3.9551, 3.9940, 3.8134],\n",
      "        [3.5512, 3.6988, 3.7346, 3.7341, 3.6947],\n",
      "        [3.5470, 3.6458, 3.6324, 3.7065, 3.6083],\n",
      "        [3.6664, 3.7862, 3.8648, 3.7768, 3.6044],\n",
      "        [3.6922, 3.6955, 3.8697, 3.7400, 3.8417],\n",
      "        [3.6195, 3.9443, 3.8285, 3.9209, 3.8330],\n",
      "        [3.6287, 3.6154, 3.8685, 3.7696, 3.7077],\n",
      "        [3.5477, 3.6969, 3.8074, 3.7096, 3.7151],\n",
      "        [3.4074, 3.5516, 3.6923, 3.5754, 3.5183],\n",
      "        [3.8764, 3.8359, 3.9214, 4.1321, 3.8864],\n",
      "        [3.5598, 3.4696, 3.7010, 3.5557, 3.5129],\n",
      "        [3.5637, 3.6608, 3.6332, 3.7311, 3.6174],\n",
      "        [3.4927, 3.5162, 3.7688, 3.6580, 3.5896],\n",
      "        [3.4916, 3.5041, 3.7702, 3.6528, 3.5777],\n",
      "        [3.6810, 3.6301, 3.8358, 3.7814, 3.6639],\n",
      "        [3.7465, 3.8047, 3.9217, 3.8597, 3.9404],\n",
      "        [3.3634, 3.4999, 3.5852, 3.4820, 3.4854],\n",
      "        [3.6021, 3.5900, 3.8478, 3.7616, 3.6974],\n",
      "        [3.5420, 3.5501, 3.7545, 3.6875, 3.6194],\n",
      "        [3.6184, 3.6085, 3.8566, 3.7566, 3.7021],\n",
      "        [3.4712, 3.5919, 3.7885, 3.6607, 3.5495],\n",
      "        [3.5724, 3.6095, 3.7426, 3.8336, 3.6674],\n",
      "        [3.3347, 3.4663, 3.5645, 3.4466, 3.4521],\n",
      "        [3.4663, 3.5806, 3.6220, 3.5937, 3.5545],\n",
      "        [3.9245, 3.8528, 4.0021, 4.1010, 3.8970],\n",
      "        [3.4900, 3.4377, 3.6289, 3.6123, 3.4809],\n",
      "        [3.5142, 3.6196, 3.6286, 3.6580, 3.5894],\n",
      "        [3.5228, 3.5416, 3.7718, 3.6953, 3.6968],\n",
      "        [3.7375, 3.6707, 3.8710, 3.9495, 3.6381],\n",
      "        [3.6042, 3.6708, 3.7880, 3.7193, 3.7700],\n",
      "        [3.9079, 3.8171, 3.9631, 4.0669, 3.9150],\n",
      "        [3.4019, 3.6112, 3.7182, 3.5823, 3.5432],\n",
      "        [3.6733, 3.6150, 3.8349, 3.6583, 3.6648],\n",
      "        [3.6122, 3.7254, 3.8671, 3.8417, 3.7628]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7759, 3.8551, 3.9816, 3.8560, 3.6631],\n",
      "        [3.6140, 3.5529, 3.7778, 3.7278, 3.6381],\n",
      "        [3.4755, 3.8484, 3.8952, 3.7358, 3.8277],\n",
      "        [3.5119, 3.4590, 3.7216, 3.6531, 3.6251],\n",
      "        [3.7108, 3.9015, 3.9529, 3.9070, 3.9008],\n",
      "        [3.6405, 3.8798, 3.9173, 3.8142, 3.6893],\n",
      "        [4.0525, 3.7555, 4.0418, 4.3899, 4.2532],\n",
      "        [3.4578, 3.5640, 3.6081, 3.5890, 3.5408],\n",
      "        [3.5598, 3.7522, 3.7433, 3.6598, 3.6854],\n",
      "        [3.5509, 3.7007, 3.7343, 3.7358, 3.6958],\n",
      "        [3.7060, 3.7907, 3.8088, 3.8528, 3.7417],\n",
      "        [3.5718, 3.6160, 3.7766, 3.6873, 3.8071],\n",
      "        [3.6615, 3.7665, 3.7594, 3.8018, 3.7480],\n",
      "        [3.6835, 3.6319, 3.7772, 3.9068, 3.7462],\n",
      "        [3.3273, 3.4578, 3.5586, 3.4417, 3.4441],\n",
      "        [3.5486, 3.5903, 3.7678, 3.7056, 3.6311],\n",
      "        [3.6283, 3.8409, 3.8365, 3.8181, 3.8463],\n",
      "        [3.5360, 3.5232, 3.7570, 3.6674, 3.5946],\n",
      "        [3.4125, 3.6003, 3.7155, 3.5976, 3.5488],\n",
      "        [3.5543, 3.5460, 3.7546, 3.6768, 3.6171],\n",
      "        [3.5690, 3.6504, 3.7655, 3.8355, 3.6349],\n",
      "        [3.7152, 3.7923, 3.9666, 3.8057, 3.6338],\n",
      "        [3.6863, 3.7946, 3.7995, 3.7842, 3.7354],\n",
      "        [3.6219, 3.6157, 3.8598, 3.7638, 3.7147],\n",
      "        [3.4567, 3.5320, 3.5943, 3.6533, 3.5281],\n",
      "        [3.8265, 3.8601, 3.9915, 3.9287, 4.0412],\n",
      "        [3.9597, 3.9038, 4.0166, 4.1717, 3.7845],\n",
      "        [3.5781, 3.6575, 3.7671, 3.8228, 3.6590],\n",
      "        [3.7356, 3.7068, 3.9565, 3.8051, 3.5718],\n",
      "        [3.7770, 3.7993, 3.9131, 3.8783, 3.9589],\n",
      "        [3.5427, 3.6347, 3.6217, 3.6976, 3.5900],\n",
      "        [3.5919, 3.9342, 3.8195, 3.9104, 3.8153],\n",
      "        [3.5421, 3.5798, 3.7595, 3.5734, 3.4259],\n",
      "        [3.5702, 3.6609, 3.7673, 3.7163, 3.6840],\n",
      "        [3.6706, 3.6468, 3.7750, 3.8774, 3.7436],\n",
      "        [3.6739, 3.8783, 3.9291, 3.8430, 3.7260],\n",
      "        [3.9065, 3.9032, 3.9691, 4.1022, 3.9367],\n",
      "        [3.7136, 3.7062, 3.8613, 3.7556, 3.5771],\n",
      "        [3.9075, 3.9165, 3.9770, 4.1269, 3.9550],\n",
      "        [3.5112, 3.5913, 3.6583, 3.6047, 3.5677],\n",
      "        [3.4374, 3.4499, 3.6412, 3.5987, 3.4862],\n",
      "        [3.7266, 3.8244, 3.9283, 3.8102, 3.6280],\n",
      "        [3.4723, 3.6181, 3.8268, 3.6737, 3.6890],\n",
      "        [3.5908, 3.8035, 3.8255, 3.7316, 3.5579],\n",
      "        [3.8343, 3.8905, 3.8957, 3.9182, 3.9344],\n",
      "        [3.5054, 3.8380, 3.8205, 3.7600, 3.8181],\n",
      "        [3.5655, 3.8064, 3.7440, 3.5594, 3.7121],\n",
      "        [3.7051, 3.8367, 3.8169, 3.9591, 3.8041],\n",
      "        [3.6623, 3.7604, 3.9146, 3.8848, 3.7881],\n",
      "        [3.5196, 3.5883, 3.6555, 3.6195, 3.5699],\n",
      "        [3.7702, 3.7904, 3.9611, 3.8491, 3.8563],\n",
      "        [3.5480, 3.7651, 3.8289, 3.6390, 3.7277],\n",
      "        [3.4177, 3.5421, 3.6091, 3.5511, 3.5441],\n",
      "        [3.9914, 3.8833, 3.9909, 4.1741, 3.9927],\n",
      "        [3.7236, 3.8637, 3.9526, 3.8982, 3.7610],\n",
      "        [3.5393, 3.9674, 3.9475, 3.7412, 3.6664],\n",
      "        [3.7211, 3.8625, 3.8161, 3.8169, 3.7843],\n",
      "        [3.7902, 3.5385, 3.8347, 4.0277, 3.9522],\n",
      "        [3.6661, 3.7592, 3.8916, 3.8737, 3.8137],\n",
      "        [3.6129, 3.8305, 3.7778, 3.8801, 3.7427],\n",
      "        [3.5602, 3.6096, 3.7692, 3.6911, 3.7827],\n",
      "        [3.4701, 3.5641, 3.7696, 3.7195, 3.6443],\n",
      "        [3.6971, 3.7752, 3.8080, 3.6959, 3.7027],\n",
      "        [3.5343, 3.8093, 3.8079, 3.6951, 3.5475]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7795, 3.8458, 3.8987, 3.8749, 3.8619],\n",
      "        [4.1417, 4.3102, 3.9899, 4.0210, 3.9125],\n",
      "        [3.7457, 3.5953, 3.7898, 3.7593, 3.7138],\n",
      "        [3.7028, 3.5344, 3.6720, 3.6691, 3.7231],\n",
      "        [3.7265, 3.8542, 3.8190, 3.8208, 3.8014],\n",
      "        [3.4997, 3.5287, 3.7666, 3.6648, 3.5957],\n",
      "        [3.6804, 3.7707, 3.7904, 3.8253, 3.7934],\n",
      "        [3.4285, 3.5727, 3.7368, 3.6143, 3.5478],\n",
      "        [3.5597, 3.5027, 3.7533, 3.6954, 3.7160],\n",
      "        [3.5483, 3.5640, 3.7507, 3.6781, 3.6164],\n",
      "        [3.5478, 3.5596, 3.7523, 3.6806, 3.6202],\n",
      "        [3.5777, 3.6827, 3.6454, 3.7569, 3.6362],\n",
      "        [3.5831, 3.6655, 3.9386, 3.7823, 3.7924],\n",
      "        [3.9585, 3.8973, 3.9790, 4.1360, 3.7464],\n",
      "        [3.7589, 3.9942, 3.9695, 4.0333, 3.9539],\n",
      "        [3.7725, 3.7578, 3.8915, 3.8593, 3.9013],\n",
      "        [3.4365, 3.5004, 3.6941, 3.6114, 3.4936],\n",
      "        [3.5555, 3.7103, 3.6958, 3.8293, 3.5843],\n",
      "        [3.6701, 3.6482, 3.7743, 3.8785, 3.7443],\n",
      "        [3.5690, 3.6020, 3.8636, 3.8274, 3.8364],\n",
      "        [3.4597, 3.6041, 3.6550, 3.6999, 3.5436],\n",
      "        [3.7105, 3.7855, 3.8205, 3.7267, 3.7163],\n",
      "        [3.5824, 3.6645, 3.7683, 3.6879, 3.6654],\n",
      "        [3.5503, 3.6449, 3.6358, 3.6965, 3.6226],\n",
      "        [3.6653, 3.8070, 3.7791, 3.7805, 3.7270],\n",
      "        [3.5179, 3.6232, 3.7511, 3.7497, 3.6319],\n",
      "        [3.5576, 3.5838, 3.8572, 3.6164, 3.7817],\n",
      "        [3.9802, 3.9347, 3.9693, 4.1963, 3.8243],\n",
      "        [3.4312, 3.5965, 3.7159, 3.6026, 3.5671],\n",
      "        [3.8630, 3.7575, 3.8808, 3.9027, 3.8800],\n",
      "        [3.5812, 3.7403, 3.7825, 3.6904, 3.7167],\n",
      "        [3.3554, 3.4928, 3.5808, 3.4743, 3.4869],\n",
      "        [3.7136, 4.0060, 3.9714, 3.9255, 3.9483],\n",
      "        [3.6909, 3.6660, 3.8398, 3.7350, 3.5793],\n",
      "        [3.7185, 3.8732, 3.9589, 3.9056, 3.7605],\n",
      "        [3.6249, 3.8396, 3.7358, 3.7661, 3.6855],\n",
      "        [3.3286, 3.4822, 3.6352, 3.5262, 3.5038],\n",
      "        [3.5931, 3.9064, 3.9162, 3.7701, 3.6408],\n",
      "        [3.6958, 3.6818, 3.8459, 3.7432, 3.5791],\n",
      "        [3.9269, 3.8572, 3.9994, 4.0981, 3.9013],\n",
      "        [3.7503, 3.6074, 3.8008, 3.7655, 3.7211],\n",
      "        [3.7724, 3.8988, 3.9931, 3.8533, 3.6054],\n",
      "        [3.4295, 3.5562, 3.6114, 3.5579, 3.5448],\n",
      "        [3.4399, 3.8294, 3.8453, 3.6848, 3.8125],\n",
      "        [3.5005, 3.5795, 3.6470, 3.5961, 3.5579],\n",
      "        [3.4997, 3.6800, 3.9585, 3.6958, 3.8004],\n",
      "        [3.3937, 3.4460, 3.6031, 3.5317, 3.4828],\n",
      "        [3.6329, 3.6276, 3.8837, 3.7756, 3.7166],\n",
      "        [3.6488, 3.7911, 3.8566, 3.7725, 3.5990],\n",
      "        [3.8231, 3.7985, 3.9647, 3.9727, 3.8365],\n",
      "        [3.6356, 3.9446, 3.8290, 3.9333, 3.8358],\n",
      "        [3.6509, 3.6902, 3.8752, 3.7901, 3.6835],\n",
      "        [3.6284, 3.6287, 3.8825, 3.7745, 3.7141],\n",
      "        [3.4097, 3.5195, 3.6757, 3.5764, 3.5108],\n",
      "        [3.4208, 3.5156, 3.6790, 3.5970, 3.5188],\n",
      "        [3.5317, 3.6114, 3.7491, 3.7097, 3.7123],\n",
      "        [3.5824, 3.6645, 3.7683, 3.6879, 3.6654],\n",
      "        [3.8079, 3.8176, 4.0224, 4.0371, 3.7730],\n",
      "        [3.4115, 3.6551, 3.5683, 3.6549, 3.4909],\n",
      "        [3.6688, 3.9780, 3.8888, 3.9604, 3.8739],\n",
      "        [3.5787, 3.5606, 3.7808, 3.6678, 3.6702],\n",
      "        [3.4456, 3.5025, 3.5768, 3.6429, 3.4363],\n",
      "        [3.7211, 3.6365, 3.8838, 3.9786, 3.6840],\n",
      "        [3.4382, 3.4672, 3.6528, 3.5951, 3.4977]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[4.0388, 3.9076, 4.0735, 4.1987, 4.0380],\n",
      "        [3.6062, 3.5644, 3.8022, 3.7078, 3.6899],\n",
      "        [3.7500, 3.6085, 3.7997, 3.7663, 3.7223],\n",
      "        [3.7271, 3.8570, 3.9113, 3.8824, 3.7726],\n",
      "        [3.4475, 3.4283, 3.6230, 3.6078, 3.4842],\n",
      "        [3.5402, 3.9464, 3.9341, 3.7498, 3.6688],\n",
      "        [3.4587, 3.6172, 3.8192, 3.6708, 3.6860],\n",
      "        [3.5434, 3.5470, 3.7544, 3.6809, 3.6172],\n",
      "        [3.4537, 3.5755, 3.7677, 3.6579, 3.5274],\n",
      "        [3.6077, 3.4184, 3.8591, 3.7340, 3.6406],\n",
      "        [3.6324, 3.6286, 3.8827, 3.7764, 3.7179],\n",
      "        [3.6107, 3.9434, 3.8659, 3.9131, 3.8460],\n",
      "        [3.5984, 3.4876, 3.7797, 3.8657, 3.5456],\n",
      "        [3.5511, 3.4976, 3.7224, 3.6789, 3.7198],\n",
      "        [3.7146, 3.6926, 3.9427, 3.7787, 3.5386],\n",
      "        [3.4119, 3.6549, 3.5708, 3.6539, 3.4910],\n",
      "        [3.5871, 3.8200, 3.8827, 3.8310, 3.8580],\n",
      "        [3.6663, 3.8103, 3.7855, 3.7675, 3.7302],\n",
      "        [3.7140, 3.8438, 3.8455, 3.8672, 3.7737],\n",
      "        [3.3689, 3.4387, 3.5861, 3.5001, 3.4672],\n",
      "        [3.5477, 3.5650, 3.7497, 3.6788, 3.6176],\n",
      "        [4.0508, 3.8986, 4.0614, 4.1914, 4.0310],\n",
      "        [3.4595, 3.5774, 3.6109, 3.5997, 3.5500],\n",
      "        [3.5369, 3.6552, 3.7956, 3.7995, 3.5959],\n",
      "        [3.5391, 3.8551, 3.8283, 3.8049, 3.8266],\n",
      "        [3.5601, 3.5223, 3.7832, 3.7088, 3.7201],\n",
      "        [3.4171, 3.4898, 3.6248, 3.5660, 3.5108],\n",
      "        [3.7018, 3.8368, 3.8139, 3.9596, 3.8025],\n",
      "        [3.4456, 3.4895, 3.6851, 3.6086, 3.4894],\n",
      "        [3.6030, 3.8967, 3.9481, 3.8616, 3.8877],\n",
      "        [3.8872, 3.8610, 4.0194, 4.0665, 3.9109],\n",
      "        [3.6143, 3.7889, 3.8226, 3.8273, 3.6529],\n",
      "        [3.6443, 3.6295, 3.8877, 3.8279, 3.6709],\n",
      "        [3.5819, 3.6656, 3.7672, 3.6884, 3.6665],\n",
      "        [3.6341, 3.5982, 3.8817, 3.9082, 3.9078],\n",
      "        [3.8042, 3.9902, 3.9422, 3.9957, 3.9679],\n",
      "        [4.0525, 3.9907, 4.0665, 4.2467, 3.9713],\n",
      "        [3.8015, 3.9373, 3.9988, 3.9766, 3.9152],\n",
      "        [3.4904, 3.8312, 3.8018, 3.7633, 3.7939],\n",
      "        [3.4715, 3.6277, 3.8236, 3.7125, 3.7187],\n",
      "        [3.3620, 3.5039, 3.5831, 3.4850, 3.4883],\n",
      "        [3.7743, 3.6087, 3.7801, 3.7744, 3.7584],\n",
      "        [3.3620, 3.5039, 3.5831, 3.4850, 3.4883],\n",
      "        [3.7760, 3.9039, 3.9310, 3.9484, 4.0235],\n",
      "        [3.6079, 3.6797, 3.7996, 3.7422, 3.7793],\n",
      "        [3.6910, 3.8285, 3.8717, 3.8981, 3.9023],\n",
      "        [3.7011, 3.8158, 3.8936, 3.9428, 3.7493],\n",
      "        [3.7200, 3.8655, 3.8149, 3.8195, 3.7863],\n",
      "        [3.5591, 3.5038, 3.7522, 3.6961, 3.7172],\n",
      "        [4.0488, 4.0214, 4.0381, 4.2898, 3.8995],\n",
      "        [3.8819, 3.7481, 3.8620, 3.9016, 3.8385],\n",
      "        [3.6975, 3.6464, 3.8539, 3.8117, 3.6895],\n",
      "        [3.5771, 3.6837, 3.6444, 3.7576, 3.6374],\n",
      "        [3.7685, 3.8493, 3.9699, 3.8521, 3.6606],\n",
      "        [3.7320, 3.6758, 3.8004, 4.0117, 3.8395],\n",
      "        [3.5008, 3.5492, 3.7481, 3.6800, 3.6102],\n",
      "        [3.7269, 3.7733, 3.8961, 3.8432, 3.8735],\n",
      "        [3.9032, 3.7804, 4.0024, 4.0714, 3.8771],\n",
      "        [3.6812, 3.9527, 3.9631, 3.8755, 3.8792],\n",
      "        [3.7363, 3.6756, 3.8700, 3.9536, 3.6415],\n",
      "        [4.0501, 3.9324, 4.0312, 4.2138, 4.0704],\n",
      "        [3.8504, 3.7652, 3.9729, 4.0780, 3.7662],\n",
      "        [3.4687, 3.5667, 3.7678, 3.7214, 3.6461],\n",
      "        [3.7099, 3.6637, 3.7674, 3.9629, 3.8034]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4875, 3.5511, 3.7428, 3.6918, 3.6262],\n",
      "        [3.6918, 3.8123, 3.9289, 3.8445, 3.7285],\n",
      "        [3.7167, 3.7952, 3.8209, 3.7539, 3.7282],\n",
      "        [3.3737, 3.4186, 3.6178, 3.5178, 3.4327],\n",
      "        [4.0893, 4.1917, 4.0507, 4.0141, 3.9234],\n",
      "        [3.4437, 3.4345, 3.6295, 3.6112, 3.4785],\n",
      "        [3.5903, 3.8071, 3.8229, 3.7336, 3.5629],\n",
      "        [3.6908, 3.6679, 3.8374, 3.7358, 3.5834],\n",
      "        [3.5620, 3.5899, 3.8438, 3.6320, 3.7840],\n",
      "        [3.5968, 3.7470, 3.7301, 3.6833, 3.6878],\n",
      "        [3.9908, 3.7740, 4.0744, 4.4080, 4.2585],\n",
      "        [3.6309, 3.8822, 3.9193, 3.8162, 3.6871],\n",
      "        [3.8995, 3.7990, 3.9471, 3.9723, 3.8942],\n",
      "        [3.9191, 3.7242, 3.9785, 4.3414, 4.1680],\n",
      "        [3.4971, 3.5680, 3.6509, 3.7187, 3.5932],\n",
      "        [3.9989, 3.9707, 4.0517, 4.2328, 4.0102],\n",
      "        [3.5808, 3.5639, 3.8236, 3.7130, 3.6840],\n",
      "        [3.4185, 3.6253, 3.7262, 3.6042, 3.5723],\n",
      "        [3.3552, 3.4946, 3.5787, 3.4750, 3.4908],\n",
      "        [3.5705, 3.7152, 3.8354, 3.7435, 3.6013],\n",
      "        [3.9352, 3.8609, 3.9832, 4.0987, 3.9229],\n",
      "        [3.8499, 3.7008, 3.9381, 3.9989, 3.8053],\n",
      "        [3.5371, 3.6633, 3.8066, 3.7500, 3.6110],\n",
      "        [3.5432, 3.5794, 3.7563, 3.6960, 3.6269],\n",
      "        [3.6828, 3.7321, 3.8444, 3.9246, 3.7203],\n",
      "        [3.9502, 3.7872, 4.0140, 4.1172, 3.9573],\n",
      "        [3.7061, 3.7171, 3.6906, 3.8481, 3.8206],\n",
      "        [3.5640, 3.8099, 3.7410, 3.5613, 3.7168],\n",
      "        [3.6849, 3.7706, 3.8002, 3.8318, 3.8000],\n",
      "        [3.6065, 3.5652, 3.8010, 3.7079, 3.6927],\n",
      "        [3.4905, 3.6046, 3.6211, 3.6186, 3.5835],\n",
      "        [3.8052, 3.8849, 3.8760, 3.9001, 3.9211],\n",
      "        [3.6641, 3.6694, 3.9093, 3.8358, 3.6872],\n",
      "        [3.4597, 3.4556, 3.6439, 3.6189, 3.5007],\n",
      "        [3.4437, 3.4345, 3.6295, 3.6112, 3.4785],\n",
      "        [3.6656, 3.7915, 3.8616, 3.7802, 3.6104],\n",
      "        [3.6271, 3.8373, 3.7919, 3.8913, 3.7534],\n",
      "        [3.5259, 3.6788, 3.7146, 3.7302, 3.6852],\n",
      "        [3.5194, 3.7622, 3.7628, 3.6746, 3.5864],\n",
      "        [3.7565, 3.6804, 3.8936, 3.9784, 3.6522],\n",
      "        [3.6113, 3.5387, 3.7330, 3.6702, 3.6795],\n",
      "        [3.6941, 3.7786, 3.7948, 3.8491, 3.7440],\n",
      "        [3.5034, 3.7917, 3.7681, 3.6456, 3.5232],\n",
      "        [3.9557, 3.9888, 3.9935, 4.2285, 4.0121],\n",
      "        [3.5649, 3.6655, 3.9386, 3.7652, 3.7932],\n",
      "        [3.5500, 3.4984, 3.7212, 3.6016, 3.5482],\n",
      "        [3.5702, 3.6752, 3.6482, 3.7485, 3.6355],\n",
      "        [3.3101, 3.4688, 3.6318, 3.5060, 3.4983],\n",
      "        [3.5749, 3.5676, 3.7867, 3.7005, 3.6753],\n",
      "        [3.8302, 3.5411, 3.8280, 4.0908, 4.0052],\n",
      "        [3.6801, 3.6352, 3.8324, 3.7850, 3.6701],\n",
      "        [3.9953, 4.0801, 3.9482, 3.9179, 3.8084],\n",
      "        [3.5444, 3.5642, 3.7488, 3.6897, 3.6295],\n",
      "        [3.7925, 3.7267, 3.9281, 3.9246, 3.7700],\n",
      "        [3.4175, 3.4906, 3.6236, 3.5661, 3.5136],\n",
      "        [3.5775, 3.6802, 3.6371, 3.7526, 3.6323],\n",
      "        [3.4412, 3.5662, 3.6105, 3.5731, 3.5458],\n",
      "        [3.7048, 3.7102, 3.8456, 3.7609, 3.5589],\n",
      "        [3.3351, 3.5382, 3.7949, 3.5291, 3.6212],\n",
      "        [3.4360, 3.5438, 3.6915, 3.6004, 3.5557],\n",
      "        [3.7423, 3.7490, 4.0694, 3.7653, 3.6542],\n",
      "        [3.3620, 3.4977, 3.4869, 3.5751, 3.4485],\n",
      "        [3.5376, 3.6844, 3.6717, 3.8048, 3.5689],\n",
      "        [3.5472, 3.7686, 3.8257, 3.6408, 3.7321]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6451, 3.6724, 3.7903, 3.7458, 3.6828],\n",
      "        [3.5389, 3.6970, 3.7905, 3.7055, 3.7014],\n",
      "        [3.9054, 3.7089, 3.9743, 4.0294, 3.8665],\n",
      "        [3.5615, 3.4952, 3.7182, 3.5970, 3.5455],\n",
      "        [3.5526, 3.6506, 3.6267, 3.7185, 3.6154],\n",
      "        [3.4717, 3.6537, 3.7252, 3.5513, 3.5437],\n",
      "        [3.5397, 3.6333, 3.7580, 3.7319, 3.7041],\n",
      "        [3.5590, 3.8508, 3.8906, 3.8110, 3.8547],\n",
      "        [3.5755, 3.6428, 3.5999, 3.7354, 3.5349],\n",
      "        [3.7319, 3.7171, 3.9060, 3.8863, 3.6115],\n",
      "        [3.3548, 3.5070, 3.6283, 3.5682, 3.5292],\n",
      "        [3.7841, 3.7762, 3.9618, 3.9220, 3.9668],\n",
      "        [3.8194, 3.7771, 3.7869, 3.8752, 3.8736],\n",
      "        [3.8003, 3.9492, 4.0279, 3.9050, 3.6824],\n",
      "        [3.4930, 3.5217, 3.7643, 3.6622, 3.5980],\n",
      "        [3.4179, 3.5599, 3.7015, 3.5982, 3.5463],\n",
      "        [3.5477, 3.6261, 3.7240, 3.6295, 3.6431],\n",
      "        [3.4607, 3.4561, 3.6426, 3.6194, 3.5029],\n",
      "        [3.6186, 3.5388, 3.7461, 3.7194, 3.5873],\n",
      "        [3.5643, 3.5919, 3.8419, 3.6317, 3.7976],\n",
      "        [3.5803, 3.9127, 3.7963, 3.8905, 3.8130],\n",
      "        [3.5645, 3.6666, 3.6307, 3.7503, 3.6310],\n",
      "        [3.6499, 3.7937, 3.8531, 3.7739, 3.6057],\n",
      "        [3.3631, 3.4983, 3.4857, 3.5757, 3.4507],\n",
      "        [3.8516, 3.7015, 3.9370, 3.9994, 3.8079],\n",
      "        [3.5877, 3.8193, 3.8305, 3.7447, 3.5662],\n",
      "        [3.7323, 3.7538, 3.9189, 3.8930, 3.6605],\n",
      "        [3.5996, 3.7630, 3.7802, 3.7256, 3.7285],\n",
      "        [4.1034, 4.2510, 3.9756, 4.0088, 3.8764],\n",
      "        [3.6031, 3.6035, 3.8361, 3.7635, 3.7061],\n",
      "        [3.8314, 3.5417, 3.8267, 4.0916, 4.0076],\n",
      "        [3.5427, 3.6432, 3.6278, 3.6999, 3.6153],\n",
      "        [3.4956, 3.7428, 3.7862, 3.7246, 3.8152],\n",
      "        [3.4335, 3.5792, 3.7391, 3.6212, 3.5594],\n",
      "        [3.5525, 3.4989, 3.7198, 3.6794, 3.7248],\n",
      "        [3.4380, 3.4917, 3.6651, 3.5975, 3.5169],\n",
      "        [3.6921, 3.6487, 3.8534, 3.8836, 3.6283],\n",
      "        [3.6050, 3.7689, 3.7750, 3.7250, 3.7362],\n",
      "        [3.6440, 3.7921, 3.8478, 3.7717, 3.5997],\n",
      "        [3.5649, 3.8105, 3.7397, 3.5618, 3.7191],\n",
      "        [3.7220, 3.8946, 3.8628, 3.8543, 3.7938],\n",
      "        [3.5066, 3.4509, 3.7596, 3.4996, 3.6640],\n",
      "        [3.8129, 3.8400, 3.9606, 3.9014, 3.9221],\n",
      "        [3.7047, 3.7173, 3.8423, 3.7621, 3.5483],\n",
      "        [3.7860, 3.6309, 3.7913, 3.7996, 3.7804],\n",
      "        [3.4464, 3.4610, 3.6459, 3.6038, 3.5004],\n",
      "        [3.5200, 3.5920, 3.6513, 3.6219, 3.5767],\n",
      "        [3.6812, 3.9238, 3.9591, 3.8829, 3.9604],\n",
      "        [3.6033, 3.5979, 3.8445, 3.7619, 3.7096],\n",
      "        [3.7473, 3.9346, 3.9043, 3.9671, 3.8723],\n",
      "        [3.5352, 3.8137, 3.8042, 3.6978, 3.5551],\n",
      "        [3.5229, 3.5472, 3.7672, 3.6995, 3.7050],\n",
      "        [3.6653, 3.6700, 3.9080, 3.8364, 3.6896],\n",
      "        [3.5384, 3.7837, 3.8507, 3.6465, 3.7247],\n",
      "        [3.6105, 3.7446, 3.7021, 3.7004, 3.6710],\n",
      "        [3.7179, 3.8681, 3.8469, 3.8472, 3.7799],\n",
      "        [3.5012, 3.7978, 3.7466, 3.6266, 3.5391],\n",
      "        [3.8371, 3.8183, 3.9670, 4.0109, 3.8478],\n",
      "        [3.6162, 3.6164, 3.8604, 3.7587, 3.7078],\n",
      "        [3.7281, 3.8573, 3.8160, 3.8230, 3.8086],\n",
      "        [3.5948, 3.6731, 3.7762, 3.8029, 3.7157],\n",
      "        [3.5642, 3.5668, 3.7224, 3.6609, 3.6876],\n",
      "        [4.0905, 4.1925, 4.0493, 4.0147, 3.9259],\n",
      "        [3.6023, 3.5743, 3.8439, 3.7848, 3.7678]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4127, 3.6500, 3.5624, 3.6668, 3.4989],\n",
      "        [3.5520, 3.5833, 3.7579, 3.6942, 3.6323],\n",
      "        [3.5521, 3.5402, 3.7571, 3.6759, 3.6095],\n",
      "        [3.7916, 3.7780, 3.9409, 3.9733, 3.7965],\n",
      "        [3.8389, 3.7878, 3.9747, 4.0885, 3.7672],\n",
      "        [3.5634, 3.6693, 3.6317, 3.7350, 3.6289],\n",
      "        [3.8802, 3.8981, 3.9114, 3.9577, 3.9697],\n",
      "        [3.7138, 3.7893, 3.8156, 3.7284, 3.7247],\n",
      "        [3.5419, 3.5454, 3.7400, 3.6708, 3.6148],\n",
      "        [3.4731, 3.5736, 3.7691, 3.7230, 3.6500],\n",
      "        [3.8216, 3.6904, 3.7870, 3.8400, 3.8242],\n",
      "        [3.5834, 3.6229, 3.7781, 3.6864, 3.8378],\n",
      "        [3.5989, 3.7558, 3.7454, 3.6815, 3.7038],\n",
      "        [4.0437, 3.9106, 4.0700, 4.2004, 4.0465],\n",
      "        [3.6321, 3.8566, 3.8401, 3.8242, 3.8566],\n",
      "        [3.3731, 3.5273, 3.6320, 3.5788, 3.5449],\n",
      "        [3.7135, 3.7894, 3.9693, 3.8991, 3.8810],\n",
      "        [3.2499, 3.4192, 3.6054, 3.4530, 3.4660],\n",
      "        [3.6938, 3.7377, 3.9325, 3.7814, 3.6568],\n",
      "        [3.6127, 3.7458, 3.7008, 3.7009, 3.6730],\n",
      "        [3.6673, 3.6711, 3.9065, 3.8368, 3.6914],\n",
      "        [3.4939, 3.6034, 3.6147, 3.6352, 3.5864],\n",
      "        [3.7633, 3.6126, 3.7857, 4.1060, 3.8623],\n",
      "        [3.4601, 3.5687, 3.6026, 3.5917, 3.5493],\n",
      "        [3.5860, 3.5795, 3.8003, 3.7295, 3.6688],\n",
      "        [3.5366, 3.5759, 3.7523, 3.6993, 3.6283],\n",
      "        [3.7475, 3.8361, 3.9396, 3.8298, 3.6489],\n",
      "        [3.5518, 3.5153, 3.7288, 3.6186, 3.5685],\n",
      "        [3.7689, 3.9102, 3.9026, 3.7489, 3.8260],\n",
      "        [3.8891, 3.8935, 3.9031, 3.9572, 3.9814],\n",
      "        [3.4152, 3.6574, 3.5671, 3.6550, 3.4978],\n",
      "        [3.6013, 3.4891, 3.7668, 3.8521, 3.5505],\n",
      "        [3.9097, 3.9090, 3.9638, 4.1052, 3.9470],\n",
      "        [3.3131, 3.4704, 3.6290, 3.5068, 3.5023],\n",
      "        [4.0308, 4.0855, 3.8390, 3.9259, 3.7528],\n",
      "        [3.4552, 3.5989, 3.6362, 3.6709, 3.5542],\n",
      "        [3.7339, 3.7182, 3.9045, 3.8866, 3.6134],\n",
      "        [3.6103, 3.5315, 3.7197, 3.6546, 3.6726],\n",
      "        [3.4510, 3.5935, 3.7476, 3.6435, 3.5656],\n",
      "        [3.5277, 3.6386, 3.9167, 3.7276, 3.7701],\n",
      "        [3.9236, 3.8543, 3.9896, 4.0993, 3.9023],\n",
      "        [3.5166, 3.6155, 3.6149, 3.6643, 3.5989],\n",
      "        [3.5472, 3.5030, 3.7760, 3.5690, 3.6813],\n",
      "        [3.4750, 3.7926, 3.8903, 3.7165, 3.8129],\n",
      "        [3.5323, 3.7928, 3.7260, 3.5422, 3.7137],\n",
      "        [3.5961, 3.8079, 3.7370, 3.7619, 3.6929],\n",
      "        [3.5375, 3.5724, 3.8825, 3.5486, 3.7950],\n",
      "        [3.5527, 3.5577, 3.7504, 3.6811, 3.6257],\n",
      "        [3.7662, 3.8578, 3.8266, 3.8476, 3.8599],\n",
      "        [3.6806, 4.0105, 3.8999, 3.9763, 3.9046],\n",
      "        [3.5674, 3.5992, 3.7693, 3.7190, 3.6635],\n",
      "        [3.8024, 3.8860, 4.0388, 4.0834, 4.1331],\n",
      "        [3.9737, 3.8127, 4.0341, 4.1330, 3.9406],\n",
      "        [3.4623, 3.4877, 3.5496, 3.6481, 3.4749],\n",
      "        [3.4836, 3.5484, 3.7229, 3.6902, 3.5984],\n",
      "        [3.5359, 3.6432, 3.6289, 3.6932, 3.6137],\n",
      "        [3.8374, 3.8120, 3.9591, 4.0176, 3.8435],\n",
      "        [3.7223, 3.8774, 3.9542, 3.9075, 3.7699],\n",
      "        [3.7475, 3.8361, 3.9396, 3.8298, 3.6489],\n",
      "        [3.7626, 3.8575, 3.8324, 3.9297, 3.9698],\n",
      "        [3.6540, 3.6938, 3.8702, 3.7919, 3.6919],\n",
      "        [3.5532, 3.6483, 3.6309, 3.6984, 3.6306],\n",
      "        [3.7212, 3.8481, 3.8979, 3.8849, 3.7749],\n",
      "        [3.5446, 3.5518, 3.7376, 3.6719, 3.6186]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7175, 3.6555, 3.7907, 3.6689, 3.5853],\n",
      "        [3.8569, 3.7818, 3.8567, 3.9062, 3.8457],\n",
      "        [3.5098, 3.6286, 3.7740, 3.7268, 3.5624],\n",
      "        [3.9561, 3.7899, 4.0099, 4.1182, 3.9635],\n",
      "        [3.5662, 3.5182, 3.7690, 3.7006, 3.7307],\n",
      "        [3.3921, 3.4817, 3.5267, 3.5986, 3.4513],\n",
      "        [3.9255, 3.8564, 3.9865, 4.0937, 3.9065],\n",
      "        [3.3591, 3.4924, 3.5732, 3.4762, 3.4913],\n",
      "        [3.5881, 3.6292, 3.7737, 3.6267, 3.4799],\n",
      "        [3.6984, 3.8092, 3.8107, 3.8227, 3.7345],\n",
      "        [3.4904, 3.8425, 3.8116, 3.7499, 3.8264],\n",
      "        [3.4365, 3.5466, 3.6865, 3.5941, 3.5526],\n",
      "        [3.5534, 3.5840, 3.7564, 3.6943, 3.6336],\n",
      "        [3.5042, 3.6570, 3.6616, 3.7525, 3.5700],\n",
      "        [3.5392, 3.6768, 3.9009, 3.6705, 3.6675],\n",
      "        [3.5716, 3.5259, 3.7807, 3.7088, 3.7361],\n",
      "        [3.4478, 3.7661, 3.7522, 3.5261, 3.7187],\n",
      "        [3.4160, 3.5606, 3.6166, 3.5981, 3.5243],\n",
      "        [3.4213, 3.5424, 3.5937, 3.5490, 3.5274],\n",
      "        [3.4920, 3.5535, 3.7383, 3.6928, 3.6316],\n",
      "        [4.2230, 4.3372, 4.0852, 4.1059, 3.9429],\n",
      "        [3.4177, 3.5065, 3.6666, 3.5824, 3.5150],\n",
      "        [3.4273, 3.4996, 3.6615, 3.5847, 3.5165],\n",
      "        [3.7989, 3.8292, 3.9618, 3.9249, 3.7843],\n",
      "        [3.7182, 3.6951, 3.9404, 3.7831, 3.5280],\n",
      "        [3.4934, 3.4385, 3.6907, 3.6333, 3.6214],\n",
      "        [3.5619, 3.7614, 3.8245, 3.8869, 3.6545],\n",
      "        [3.9108, 3.7817, 3.9981, 4.0678, 3.8892],\n",
      "        [3.6481, 3.8974, 3.8750, 3.8489, 3.8768],\n",
      "        [3.7893, 3.6326, 3.7882, 3.8002, 3.7837],\n",
      "        [3.6977, 3.6831, 3.9132, 3.7517, 3.5175],\n",
      "        [3.6476, 3.7939, 3.8447, 3.7721, 3.6028],\n",
      "        [3.6776, 3.6286, 3.8199, 3.7686, 3.6728],\n",
      "        [3.5633, 3.4768, 3.6931, 3.5605, 3.5243],\n",
      "        [3.9297, 3.8611, 3.9959, 4.1070, 3.9100],\n",
      "        [3.4518, 3.5440, 3.7159, 3.6297, 3.5339],\n",
      "        [3.8505, 3.8329, 3.9853, 3.9777, 3.8472],\n",
      "        [3.4327, 3.5627, 3.6062, 3.5614, 3.5529],\n",
      "        [3.6184, 3.5602, 3.7776, 3.7208, 3.6585],\n",
      "        [3.4851, 3.5491, 3.7214, 3.6903, 3.5997],\n",
      "        [3.4750, 3.5332, 3.7090, 3.6622, 3.5253],\n",
      "        [3.4272, 3.6512, 3.7375, 3.6034, 3.5809],\n",
      "        [3.5991, 3.5637, 3.8114, 3.7144, 3.6889],\n",
      "        [3.5840, 3.6255, 3.7826, 3.6176, 3.4770],\n",
      "        [3.4643, 3.4936, 3.6777, 3.6200, 3.5070],\n",
      "        [3.6888, 3.7863, 3.9194, 3.7613, 3.6246],\n",
      "        [3.9159, 3.8544, 3.9886, 4.1201, 3.9325],\n",
      "        [3.5620, 3.5880, 3.8503, 3.6183, 3.7911],\n",
      "        [3.6384, 3.8764, 3.8549, 3.8305, 3.8639],\n",
      "        [3.5893, 3.7153, 3.6465, 3.6765, 3.6357],\n",
      "        [3.3793, 3.5147, 3.5852, 3.4999, 3.5155],\n",
      "        [3.7541, 3.9998, 4.0085, 3.9355, 3.9387],\n",
      "        [3.9408, 3.8635, 3.9792, 4.1001, 3.9291],\n",
      "        [3.7177, 3.8020, 3.8084, 3.7837, 3.7394],\n",
      "        [3.8204, 3.7901, 3.8856, 3.8903, 3.8663],\n",
      "        [3.6744, 3.6522, 3.7674, 3.8803, 3.7537],\n",
      "        [3.6185, 3.5405, 3.7548, 3.7124, 3.5976],\n",
      "        [3.5428, 3.6523, 3.7782, 3.8012, 3.6291],\n",
      "        [3.5798, 3.6031, 3.8310, 3.6558, 3.7990],\n",
      "        [3.8556, 3.7034, 3.9341, 3.9997, 3.8114],\n",
      "        [3.4212, 3.5616, 3.6985, 3.5985, 3.5492],\n",
      "        [3.7791, 3.6118, 3.7745, 3.7759, 3.7670],\n",
      "        [3.5546, 3.5006, 3.7167, 3.6028, 3.5535],\n",
      "        [3.6060, 3.5973, 3.8399, 3.7665, 3.7089]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.9307, 3.8316, 3.9311, 4.0031, 3.9207],\n",
      "        [3.7411, 3.8890, 3.8190, 3.6913, 3.6884],\n",
      "        [3.7243, 3.8438, 3.8800, 3.8814, 3.7722],\n",
      "        [3.5738, 3.6010, 3.7659, 3.7196, 3.6655],\n",
      "        [3.5160, 3.5424, 3.6038, 3.6252, 3.6554],\n",
      "        [3.6143, 3.4833, 3.7637, 3.8656, 3.5689],\n",
      "        [3.5831, 3.7408, 3.7448, 3.7148, 3.7229],\n",
      "        [3.6994, 3.8483, 3.9199, 3.8825, 3.8340],\n",
      "        [3.6722, 3.4753, 3.9055, 3.7856, 3.6988],\n",
      "        [4.0649, 4.0391, 4.0927, 4.3289, 4.0848],\n",
      "        [3.8071, 3.9306, 3.9343, 3.7719, 3.8611],\n",
      "        [3.7810, 3.9121, 3.7996, 3.8033, 3.7754],\n",
      "        [3.5074, 3.4543, 3.6248, 3.6192, 3.5009],\n",
      "        [3.4892, 3.6073, 3.6209, 3.6268, 3.5820],\n",
      "        [3.9164, 4.0336, 3.9165, 3.8555, 3.8133],\n",
      "        [3.7986, 3.9273, 4.0269, 3.9287, 3.7182],\n",
      "        [3.4843, 3.7264, 3.7688, 3.7089, 3.8044],\n",
      "        [3.6299, 3.6244, 3.8553, 3.7965, 3.6622],\n",
      "        [3.5320, 3.6262, 3.6175, 3.6605, 3.6117],\n",
      "        [3.7789, 3.7978, 3.9512, 3.8527, 3.8676],\n",
      "        [3.6898, 3.7327, 3.8658, 3.8248, 3.8509],\n",
      "        [3.4369, 3.5615, 3.6050, 3.5576, 3.5472],\n",
      "        [3.5921, 3.6710, 3.9295, 3.7849, 3.8028],\n",
      "        [3.5683, 3.5564, 3.8121, 3.7280, 3.6536],\n",
      "        [3.9769, 4.0503, 4.0646, 4.2542, 4.0622],\n",
      "        [3.9847, 3.9456, 3.9953, 4.1977, 3.9966],\n",
      "        [4.1498, 4.3164, 3.9886, 4.0430, 3.9310],\n",
      "        [4.0040, 3.8349, 4.0541, 4.1627, 3.9877],\n",
      "        [3.5795, 3.6786, 3.6421, 3.7500, 3.6416],\n",
      "        [3.5846, 3.6047, 3.8545, 3.7473, 3.7032],\n",
      "        [3.4339, 3.4948, 3.6564, 3.5883, 3.5177],\n",
      "        [3.7685, 3.5465, 3.8182, 3.9855, 3.9446],\n",
      "        [3.4311, 3.5475, 3.6914, 3.6011, 3.5469],\n",
      "        [3.5726, 3.6694, 3.6259, 3.7512, 3.6347],\n",
      "        [3.8081, 3.8624, 3.9903, 3.9178, 4.0387],\n",
      "        [3.8162, 3.9359, 3.8421, 3.7582, 3.7230],\n",
      "        [3.5457, 3.8119, 3.7956, 3.6928, 3.5479],\n",
      "        [3.8904, 3.6693, 3.8529, 4.2228, 3.9878],\n",
      "        [3.4770, 3.5655, 3.6083, 3.6471, 3.5414],\n",
      "        [3.5482, 3.5471, 3.7366, 3.6714, 3.6168],\n",
      "        [3.4292, 3.5563, 3.5978, 3.5536, 3.5379],\n",
      "        [3.6383, 3.9273, 3.8343, 3.9001, 3.8323],\n",
      "        [3.9382, 3.8632, 3.9920, 4.1015, 3.9133],\n",
      "        [3.8399, 3.5447, 3.8218, 4.0932, 4.0118],\n",
      "        [3.4146, 3.4641, 3.6317, 3.5599, 3.4736],\n",
      "        [3.8568, 3.8049, 3.8757, 3.9134, 3.8772],\n",
      "        [3.8720, 3.8114, 4.0057, 4.1103, 3.7871],\n",
      "        [3.5796, 3.5904, 3.8388, 3.7302, 3.6963],\n",
      "        [3.5763, 3.5316, 3.7778, 3.6983, 3.7083],\n",
      "        [3.7159, 3.5053, 3.6672, 3.6932, 3.6945],\n",
      "        [3.7309, 3.8811, 3.8057, 3.7810, 3.7806],\n",
      "        [3.7192, 3.7730, 3.8992, 3.7823, 3.7634],\n",
      "        [3.6266, 3.5592, 3.7690, 3.7012, 3.7029],\n",
      "        [3.6508, 3.7758, 3.9070, 3.8942, 3.7865],\n",
      "        [3.8663, 3.8506, 3.9644, 4.0359, 3.8244],\n",
      "        [3.5825, 3.6611, 3.7703, 3.6861, 3.5617],\n",
      "        [3.5682, 3.6488, 3.7500, 3.6513, 3.5643],\n",
      "        [3.5830, 3.6800, 3.6453, 3.7495, 3.6470],\n",
      "        [3.9045, 3.8716, 4.0101, 4.0547, 3.9293],\n",
      "        [3.4103, 3.5421, 3.5924, 3.5320, 3.5273],\n",
      "        [3.5608, 3.6533, 3.6219, 3.7194, 3.6192],\n",
      "        [3.7994, 3.5456, 3.8257, 4.0323, 3.9641],\n",
      "        [3.5167, 3.5452, 3.7468, 3.6816, 3.6181],\n",
      "        [3.9102, 3.8536, 3.9809, 4.1142, 3.9322]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4553, 3.5696, 3.5989, 3.5817, 3.5509],\n",
      "        [3.7039, 3.7888, 3.9145, 3.8144, 3.7524],\n",
      "        [3.7321, 3.8090, 3.9133, 3.8828, 3.7501],\n",
      "        [3.5817, 3.5466, 3.7730, 3.6398, 3.6800],\n",
      "        [3.4619, 3.4508, 3.6287, 3.6149, 3.5009],\n",
      "        [3.6104, 3.7650, 3.7785, 3.8154, 3.6582],\n",
      "        [3.8739, 3.6828, 3.8389, 4.1819, 3.9634],\n",
      "        [3.4726, 3.6103, 3.6447, 3.7030, 3.5541],\n",
      "        [3.7655, 3.8447, 3.8164, 3.9066, 3.8743],\n",
      "        [3.6829, 3.6745, 3.7876, 3.7694, 3.6797],\n",
      "        [3.5763, 3.5330, 3.6469, 3.7577, 3.5527],\n",
      "        [3.6377, 3.5670, 3.7579, 3.6951, 3.7072],\n",
      "        [3.4573, 3.4794, 3.6498, 3.6026, 3.5146],\n",
      "        [3.5627, 3.7105, 3.7911, 3.7289, 3.6536],\n",
      "        [3.5669, 3.5332, 3.6518, 3.7549, 3.5437],\n",
      "        [3.5606, 3.7730, 3.8169, 3.6428, 3.7382],\n",
      "        [3.7093, 3.6878, 3.8351, 3.7463, 3.5898],\n",
      "        [3.8301, 3.7921, 3.8817, 3.8918, 3.8677],\n",
      "        [3.6382, 3.8475, 3.7253, 3.7690, 3.6963],\n",
      "        [3.7402, 3.8320, 3.9168, 3.8143, 3.6395],\n",
      "        [3.8668, 3.7989, 3.9855, 4.1010, 3.7794],\n",
      "        [3.7186, 3.8444, 3.8055, 3.9637, 3.8159],\n",
      "        [3.6275, 3.5621, 3.7738, 3.7223, 3.6598],\n",
      "        [3.4362, 3.6531, 3.7336, 3.6046, 3.5820],\n",
      "        [3.6485, 3.8777, 3.8527, 3.8348, 3.8655],\n",
      "        [3.5626, 3.5428, 3.7517, 3.6776, 3.6120],\n",
      "        [3.5621, 3.5050, 3.7051, 3.6694, 3.7284],\n",
      "        [3.7767, 3.8528, 3.8278, 3.9170, 3.8661],\n",
      "        [3.8871, 3.8905, 3.9317, 4.0828, 3.9177],\n",
      "        [3.9505, 3.8428, 3.9317, 4.0124, 3.9478],\n",
      "        [3.9283, 3.9750, 3.9919, 3.9955, 4.0304],\n",
      "        [3.4644, 3.6252, 3.7199, 3.7545, 3.5142],\n",
      "        [3.7455, 3.7157, 4.0088, 3.7883, 3.6201],\n",
      "        [3.5197, 3.6171, 3.6074, 3.6498, 3.5903],\n",
      "        [3.5718, 3.6444, 3.7666, 3.6874, 3.5537],\n",
      "        [3.4602, 3.4514, 3.6307, 3.6144, 3.5037],\n",
      "        [3.5606, 3.7730, 3.8169, 3.6428, 3.7382],\n",
      "        [3.7186, 3.8444, 3.8055, 3.9637, 3.8159],\n",
      "        [3.8592, 3.8094, 3.9523, 3.9737, 3.7354],\n",
      "        [3.6641, 3.6555, 3.7595, 3.8115, 3.8098],\n",
      "        [3.4677, 3.5805, 3.7581, 3.6601, 3.5364],\n",
      "        [3.4771, 3.5122, 3.5489, 3.6550, 3.5139],\n",
      "        [3.5719, 3.8547, 3.8834, 3.8129, 3.8590],\n",
      "        [3.6899, 3.7761, 3.7902, 3.7800, 3.8503],\n",
      "        [3.6204, 3.6215, 3.7593, 3.7604, 3.6743],\n",
      "        [3.8618, 3.8977, 3.8904, 3.9427, 3.9389],\n",
      "        [3.9306, 4.0159, 3.8211, 3.8712, 3.7799],\n",
      "        [3.5789, 3.8853, 3.8242, 3.8485, 3.8387],\n",
      "        [3.7247, 3.9096, 3.9419, 3.9116, 3.9130],\n",
      "        [3.8702, 3.7189, 3.9421, 4.0076, 3.8233],\n",
      "        [3.7396, 3.8758, 3.8233, 3.8297, 3.8159],\n",
      "        [3.6619, 3.6185, 3.7725, 3.6488, 3.5036],\n",
      "        [3.6514, 3.6320, 3.8710, 3.7886, 3.7312],\n",
      "        [3.5464, 3.5745, 3.8579, 3.5729, 3.7792],\n",
      "        [3.5360, 3.6325, 3.6104, 3.6897, 3.5965],\n",
      "        [3.9971, 3.9421, 3.9605, 4.2009, 3.8381],\n",
      "        [3.3418, 3.4757, 3.5558, 3.4507, 3.4651],\n",
      "        [3.6217, 3.6853, 3.7704, 3.7841, 3.7649],\n",
      "        [3.5749, 3.6458, 3.6669, 3.7052, 3.6601],\n",
      "        [3.6941, 3.9301, 3.8709, 3.8673, 3.8103],\n",
      "        [4.0843, 3.9692, 4.0812, 4.2915, 4.0836],\n",
      "        [3.6368, 3.8878, 3.9650, 3.8876, 3.8723],\n",
      "        [3.8386, 3.5554, 3.8306, 4.0708, 4.0058],\n",
      "        [3.7132, 3.8826, 3.9253, 3.8791, 3.8948]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7950, 3.8087, 3.9001, 3.8848, 3.9717],\n",
      "        [3.6852, 3.6138, 3.9180, 3.8518, 3.7101],\n",
      "        [3.5775, 3.4992, 3.7089, 3.5996, 3.5498],\n",
      "        [3.5858, 3.5722, 3.7746, 3.6599, 3.6314],\n",
      "        [3.7087, 3.7405, 3.9250, 3.7836, 3.6595],\n",
      "        [3.5241, 3.4811, 3.7130, 3.6312, 3.5652],\n",
      "        [4.1546, 4.2441, 4.0641, 4.0642, 3.9519],\n",
      "        [3.7818, 3.6158, 3.7726, 3.7754, 3.7590],\n",
      "        [3.6602, 3.7005, 3.8633, 3.7856, 3.7335],\n",
      "        [3.4395, 3.5171, 3.6684, 3.5899, 3.5246],\n",
      "        [3.4244, 3.6483, 3.8158, 3.6131, 3.6824],\n",
      "        [3.6210, 3.6808, 3.7743, 3.7250, 3.7823],\n",
      "        [3.4044, 3.6627, 3.8472, 3.5911, 3.6624],\n",
      "        [3.5436, 3.5613, 3.7516, 3.7067, 3.7090],\n",
      "        [3.6260, 3.6853, 3.7879, 3.7448, 3.7890],\n",
      "        [3.7168, 3.8896, 3.9402, 3.8773, 3.7560],\n",
      "        [3.8123, 3.8753, 3.8474, 3.8648, 3.9044],\n",
      "        [3.5246, 3.6143, 3.8463, 3.7077, 3.7234],\n",
      "        [3.5598, 3.5815, 3.7453, 3.6976, 3.6320],\n",
      "        [3.7633, 3.7524, 4.0581, 3.7647, 3.6588],\n",
      "        [3.7129, 3.6881, 3.8329, 3.7468, 3.5899],\n",
      "        [3.6797, 3.6123, 3.8046, 3.6717, 3.6537],\n",
      "        [3.7725, 3.7542, 3.9339, 3.8746, 3.6622],\n",
      "        [3.6318, 3.5700, 3.7822, 3.7084, 3.7051],\n",
      "        [3.5380, 3.6355, 3.6200, 3.6774, 3.6048],\n",
      "        [3.6060, 3.5645, 3.7986, 3.7197, 3.6426],\n",
      "        [3.5758, 3.6441, 3.7569, 3.8789, 3.6155],\n",
      "        [3.4479, 3.4869, 3.6485, 3.5914, 3.5151],\n",
      "        [3.4022, 3.4271, 3.6101, 3.5281, 3.4466],\n",
      "        [3.6369, 3.8192, 3.8005, 3.8031, 3.8339],\n",
      "        [3.6052, 3.8256, 3.8706, 3.8342, 3.8679],\n",
      "        [3.5356, 3.5960, 3.6424, 3.6241, 3.5809],\n",
      "        [3.5281, 3.4673, 3.7135, 3.6659, 3.6497],\n",
      "        [3.5807, 3.5733, 3.7784, 3.7157, 3.6644],\n",
      "        [3.5945, 3.6890, 3.6330, 3.7606, 3.6470],\n",
      "        [3.9952, 3.7253, 3.9497, 4.3020, 4.1903],\n",
      "        [3.4798, 3.5411, 3.7119, 3.6584, 3.5223],\n",
      "        [3.5500, 3.5823, 3.8004, 3.7028, 3.6512],\n",
      "        [3.7032, 3.7757, 3.7904, 3.8351, 3.8078],\n",
      "        [3.9284, 3.8138, 3.9307, 3.9930, 3.9107],\n",
      "        [3.5081, 3.6066, 3.6029, 3.6330, 3.5816],\n",
      "        [3.5536, 3.6383, 3.6178, 3.6806, 3.6221],\n",
      "        [3.9074, 3.8677, 4.0081, 4.0701, 3.9227],\n",
      "        [3.7623, 3.5200, 3.6473, 3.6727, 3.7468],\n",
      "        [3.4453, 3.5789, 3.7242, 3.6177, 3.5582],\n",
      "        [3.4336, 3.5445, 3.5879, 3.5507, 3.5287],\n",
      "        [3.9394, 3.8589, 3.9808, 4.0961, 3.9084],\n",
      "        [3.5806, 3.5960, 3.8325, 3.6341, 3.8018],\n",
      "        [4.0011, 3.9426, 3.9585, 4.2015, 3.8385],\n",
      "        [3.6211, 3.7843, 3.7832, 3.7216, 3.7424],\n",
      "        [3.5825, 3.6608, 3.7414, 3.6687, 3.6648],\n",
      "        [4.0440, 3.8709, 4.0188, 4.1540, 4.0149],\n",
      "        [3.5460, 3.6388, 3.6138, 3.6882, 3.6086],\n",
      "        [3.8125, 3.8156, 4.0667, 3.8413, 3.6662],\n",
      "        [3.7162, 3.8380, 3.7966, 3.9552, 3.8063],\n",
      "        [3.9768, 3.9943, 3.9834, 4.2325, 4.0207],\n",
      "        [3.6386, 3.6411, 3.8337, 3.7703, 3.8036],\n",
      "        [3.4705, 3.4574, 3.6295, 3.6169, 3.5048],\n",
      "        [3.7233, 3.8404, 3.7952, 3.9537, 3.8019],\n",
      "        [3.7623, 3.8391, 3.9317, 3.8318, 3.6517],\n",
      "        [3.7278, 3.8293, 3.8203, 3.8516, 3.7741],\n",
      "        [3.6901, 3.6401, 3.7909, 3.6478, 3.5288],\n",
      "        [3.7072, 3.7863, 3.7861, 3.7810, 3.8443],\n",
      "        [3.6869, 3.7415, 3.8925, 3.7584, 3.6186]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8677, 3.8359, 3.9775, 3.9802, 3.8492],\n",
      "        [3.4556, 3.5483, 3.6793, 3.6029, 3.5619],\n",
      "        [3.8616, 3.7350, 3.8255, 3.8740, 3.8803],\n",
      "        [3.5904, 3.5741, 3.7436, 3.6844, 3.6948],\n",
      "        [3.8966, 3.8800, 3.8808, 3.9676, 3.9651],\n",
      "        [3.5254, 3.6484, 3.7617, 3.7841, 3.5731],\n",
      "        [3.8099, 3.6226, 3.8018, 4.1015, 3.8931],\n",
      "        [3.8442, 3.8891, 3.9180, 3.9236, 3.9288],\n",
      "        [3.7076, 3.6466, 3.8209, 3.7956, 3.6772],\n",
      "        [3.6334, 3.7371, 3.8531, 3.8514, 3.7772],\n",
      "        [3.5686, 3.6654, 3.7889, 3.7537, 3.6185],\n",
      "        [3.5419, 3.5513, 3.7561, 3.7018, 3.7093],\n",
      "        [3.5686, 3.6535, 3.6220, 3.7205, 3.6271],\n",
      "        [3.5200, 3.6164, 3.6036, 3.6517, 3.5857],\n",
      "        [3.6009, 3.5784, 3.7875, 3.7059, 3.6854],\n",
      "        [3.5981, 3.5821, 3.7372, 3.6802, 3.7058],\n",
      "        [3.5423, 3.6274, 3.6115, 3.6618, 3.6122],\n",
      "        [3.6499, 3.8598, 3.8307, 3.8263, 3.8593],\n",
      "        [3.9067, 3.8975, 3.8936, 3.9594, 3.9844],\n",
      "        [3.6033, 3.7257, 3.6400, 3.6769, 3.6413],\n",
      "        [3.8456, 3.8066, 3.9507, 3.9770, 3.8496],\n",
      "        [3.7578, 3.8962, 3.9401, 3.8809, 3.7814],\n",
      "        [3.4760, 3.4640, 3.6357, 3.6152, 3.5100],\n",
      "        [3.4848, 3.5900, 3.6068, 3.5995, 3.5665],\n",
      "        [3.5464, 3.5614, 3.7496, 3.7066, 3.7088],\n",
      "        [3.8042, 3.8386, 3.9571, 3.9044, 4.0125],\n",
      "        [3.4437, 3.6590, 3.8489, 3.6078, 3.6420],\n",
      "        [3.4273, 3.5803, 3.6851, 3.5836, 3.5370],\n",
      "        [3.6995, 3.7559, 3.7993, 3.7991, 3.8604],\n",
      "        [3.5700, 3.5983, 3.7556, 3.7119, 3.6451],\n",
      "        [3.5682, 3.5520, 3.7420, 3.6789, 3.6236],\n",
      "        [3.5587, 3.5484, 3.7305, 3.6727, 3.6173],\n",
      "        [3.6927, 3.5725, 3.9805, 3.8263, 3.7972],\n",
      "        [3.5238, 3.8032, 3.7562, 3.6453, 3.5406],\n",
      "        [3.4671, 3.4335, 3.6099, 3.6105, 3.4934],\n",
      "        [3.7443, 3.8090, 3.9079, 3.9661, 3.7488],\n",
      "        [3.6264, 3.5698, 3.7882, 3.7105, 3.6988],\n",
      "        [3.7221, 3.7036, 3.8363, 3.7531, 3.5778],\n",
      "        [3.5277, 3.6407, 3.7715, 3.7325, 3.5747],\n",
      "        [3.3298, 3.4735, 3.6196, 3.5085, 3.5046],\n",
      "        [3.8163, 3.7850, 3.8719, 3.8653, 3.8617],\n",
      "        [3.5800, 3.8030, 3.6991, 3.8319, 3.7140],\n",
      "        [3.4284, 3.6393, 3.7157, 3.5929, 3.5700],\n",
      "        [3.5672, 3.6584, 3.6220, 3.7178, 3.6227],\n",
      "        [3.6240, 3.7844, 3.7812, 3.7214, 3.7421],\n",
      "        [3.6428, 3.5704, 3.7696, 3.7048, 3.7085],\n",
      "        [3.7248, 3.4988, 3.6542, 3.6992, 3.6769],\n",
      "        [3.7352, 4.0129, 3.9565, 3.9295, 3.9597],\n",
      "        [3.7290, 3.7468, 3.9162, 3.7896, 3.5937],\n",
      "        [3.5071, 3.6768, 3.6136, 3.7095, 3.5413],\n",
      "        [3.5329, 3.6369, 3.7807, 3.7180, 3.7748],\n",
      "        [3.5788, 3.6443, 3.7552, 3.8789, 3.6155],\n",
      "        [3.4616, 3.4517, 3.6242, 3.6114, 3.4958],\n",
      "        [3.4995, 3.6413, 3.8137, 3.6784, 3.7070],\n",
      "        [3.5690, 3.8102, 3.7915, 3.7037, 3.5520],\n",
      "        [3.5006, 3.5514, 3.7135, 3.6921, 3.6009],\n",
      "        [3.5146, 3.7470, 3.7749, 3.7269, 3.8194],\n",
      "        [3.4361, 3.5319, 3.7723, 3.6073, 3.6391],\n",
      "        [3.4731, 3.5721, 3.7456, 3.6527, 3.5304],\n",
      "        [3.5526, 3.5918, 3.6564, 3.6178, 3.6097],\n",
      "        [3.5762, 3.5432, 3.7710, 3.6906, 3.6296],\n",
      "        [3.4900, 3.6577, 3.7136, 3.5529, 3.5471],\n",
      "        [3.8740, 3.7996, 3.9817, 4.1016, 3.7798],\n",
      "        [3.5191, 3.6175, 3.6045, 3.6581, 3.5826]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5296, 3.5463, 3.7386, 3.6826, 3.6207],\n",
      "        [3.5505, 3.4878, 3.7615, 3.5374, 3.6833],\n",
      "        [3.8208, 3.9321, 3.9258, 3.7729, 3.8639],\n",
      "        [3.8351, 3.9033, 4.0341, 4.0948, 4.1543],\n",
      "        [3.5633, 3.5597, 3.7369, 3.6935, 3.6342],\n",
      "        [4.0659, 3.9143, 4.0588, 4.2026, 4.0527],\n",
      "        [3.5777, 3.5969, 3.7563, 3.7136, 3.6603],\n",
      "        [3.6081, 3.5815, 3.7901, 3.7099, 3.6930],\n",
      "        [3.7325, 3.8243, 3.8110, 3.8581, 3.7711],\n",
      "        [3.5420, 3.4935, 3.7224, 3.6451, 3.5848],\n",
      "        [3.5444, 3.6328, 3.6043, 3.6897, 3.5987],\n",
      "        [3.7319, 3.7291, 3.8618, 3.8593, 3.8816],\n",
      "        [3.7930, 3.7862, 3.9213, 3.9181, 3.9718],\n",
      "        [3.5052, 3.6015, 3.6006, 3.6363, 3.5776],\n",
      "        [3.5159, 3.4623, 3.6354, 3.6434, 3.4993],\n",
      "        [3.5695, 3.6432, 3.6970, 3.6701, 3.6500],\n",
      "        [3.5984, 3.6820, 3.8483, 3.7571, 3.7274],\n",
      "        [3.5108, 3.5679, 3.7187, 3.7185, 3.6111],\n",
      "        [3.7637, 3.7509, 4.0451, 3.7647, 3.6539],\n",
      "        [3.4239, 3.5564, 3.6759, 3.5817, 3.5292],\n",
      "        [3.4456, 3.4942, 3.6094, 3.5776, 3.5300],\n",
      "        [3.4616, 3.4694, 3.6354, 3.5993, 3.5114],\n",
      "        [3.5024, 3.5533, 3.6815, 3.5952, 3.5761],\n",
      "        [3.4616, 3.4694, 3.6354, 3.5993, 3.5114],\n",
      "        [3.7288, 3.7933, 3.8045, 3.7269, 3.7280],\n",
      "        [3.4578, 3.4900, 3.6509, 3.5962, 3.5201],\n",
      "        [3.5718, 3.5540, 3.7325, 3.6795, 3.6295],\n",
      "        [3.5917, 3.6090, 3.8468, 3.8316, 3.8499],\n",
      "        [3.4307, 3.6392, 3.7137, 3.5925, 3.5723],\n",
      "        [3.7874, 3.9522, 3.8991, 3.9793, 3.8957],\n",
      "        [3.7628, 3.7779, 3.8866, 3.8283, 3.8770],\n",
      "        [3.8825, 3.8229, 3.9657, 4.0031, 3.7393],\n",
      "        [3.5667, 3.5059, 3.7644, 3.5704, 3.6857],\n",
      "        [3.7487, 3.8695, 3.9051, 3.8875, 3.7874],\n",
      "        [3.6954, 3.6400, 3.7870, 3.6474, 3.5308],\n",
      "        [3.5135, 3.6007, 3.5901, 3.6371, 3.5689],\n",
      "        [3.5694, 3.7735, 3.8104, 3.6426, 3.7402],\n",
      "        [3.5739, 3.6577, 3.6136, 3.7168, 3.6179],\n",
      "        [3.5687, 3.6300, 3.7104, 3.6306, 3.6490],\n",
      "        [3.5694, 3.5455, 3.7395, 3.6817, 3.6166],\n",
      "        [3.7502, 3.8628, 3.8951, 3.8850, 3.7846],\n",
      "        [3.6647, 3.8893, 3.9005, 3.8193, 3.7049],\n",
      "        [3.7027, 3.8376, 3.8483, 3.9316, 3.7750],\n",
      "        [3.9767, 3.6977, 3.9217, 4.3006, 4.1703],\n",
      "        [3.6834, 3.6839, 3.8212, 3.7305, 3.8235],\n",
      "        [3.7005, 3.8154, 3.7676, 3.9235, 3.7708],\n",
      "        [3.5802, 3.5170, 3.7278, 3.6886, 3.7409],\n",
      "        [3.7205, 3.4921, 3.6500, 3.6926, 3.6875],\n",
      "        [3.9517, 3.8675, 3.9875, 4.1104, 3.9214],\n",
      "        [3.4488, 3.5007, 3.6532, 3.5884, 3.5215],\n",
      "        [3.6494, 3.7892, 3.7913, 3.7297, 3.7508],\n",
      "        [3.5632, 3.6294, 3.6445, 3.6867, 3.6407],\n",
      "        [3.5883, 3.5453, 3.7644, 3.6361, 3.6829],\n",
      "        [3.7275, 3.8447, 3.7991, 3.9637, 3.8182],\n",
      "        [3.6215, 3.6803, 3.7695, 3.7504, 3.7739],\n",
      "        [3.5906, 3.6531, 3.7627, 3.6921, 3.5558],\n",
      "        [3.9342, 3.8139, 3.9266, 3.9925, 3.9131],\n",
      "        [3.5406, 3.5960, 3.6384, 3.6236, 3.5829],\n",
      "        [3.5006, 3.6030, 3.6031, 3.6245, 3.5800],\n",
      "        [3.5097, 3.5558, 3.7280, 3.6941, 3.6350],\n",
      "        [3.5710, 3.6654, 3.7870, 3.7534, 3.6209],\n",
      "        [3.5956, 3.6811, 3.6371, 3.7504, 3.6497],\n",
      "        [3.6979, 3.9200, 3.9367, 3.8721, 3.9606],\n",
      "        [3.4353, 3.5763, 3.6870, 3.5989, 3.5553]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6262, 3.6005, 3.8177, 3.7416, 3.7026],\n",
      "        [3.5792, 3.7657, 3.7953, 3.6538, 3.7397],\n",
      "        [3.6714, 3.7959, 3.7950, 3.8329, 3.7180],\n",
      "        [3.5866, 3.5942, 3.8266, 3.6352, 3.7943],\n",
      "        [3.6710, 3.8738, 3.9094, 3.8026, 3.8075],\n",
      "        [3.9616, 3.7154, 3.9525, 4.3603, 4.1677],\n",
      "        [3.7911, 3.8731, 3.9738, 3.9372, 3.9878],\n",
      "        [3.7308, 3.7202, 3.8497, 3.8625, 3.9058],\n",
      "        [3.4107, 3.4466, 3.6197, 3.5537, 3.4552],\n",
      "        [3.3757, 3.5153, 3.6205, 3.5585, 3.5434],\n",
      "        [3.5435, 3.6301, 3.7341, 3.7545, 3.6477],\n",
      "        [3.7810, 4.0156, 3.9216, 3.8725, 4.0882],\n",
      "        [3.5674, 3.5806, 3.8807, 3.5566, 3.8074],\n",
      "        [3.6350, 3.6105, 3.8321, 3.7536, 3.7113],\n",
      "        [3.4372, 3.5760, 3.6849, 3.5997, 3.5571],\n",
      "        [3.6218, 3.6382, 3.7796, 3.6989, 3.8710],\n",
      "        [3.5291, 3.5517, 3.7370, 3.6800, 3.6235],\n",
      "        [3.5556, 3.5656, 3.8539, 3.5509, 3.7894],\n",
      "        [3.5669, 3.5812, 3.7390, 3.6979, 3.6358],\n",
      "        [3.3965, 3.5954, 3.4867, 3.6162, 3.4475],\n",
      "        [3.6113, 3.8220, 3.7233, 3.8607, 3.7386],\n",
      "        [3.6189, 3.5657, 3.7989, 3.7166, 3.6940],\n",
      "        [3.5073, 3.7963, 3.8118, 3.7419, 3.7854],\n",
      "        [3.9974, 4.0094, 4.0451, 4.2091, 3.9955],\n",
      "        [3.4712, 3.4331, 3.6058, 3.6109, 3.4973],\n",
      "        [4.0154, 4.0832, 3.8391, 3.9286, 3.7929],\n",
      "        [3.9210, 3.8949, 3.8909, 3.9712, 3.9964],\n",
      "        [3.5833, 3.6441, 3.7514, 3.8798, 3.6198],\n",
      "        [3.7393, 3.9158, 3.8276, 3.6893, 3.7866],\n",
      "        [3.5539, 3.5087, 3.7330, 3.6575, 3.5941],\n",
      "        [3.4679, 3.4353, 3.6076, 3.6056, 3.4914],\n",
      "        [3.5711, 3.5581, 3.7336, 3.6802, 3.6300],\n",
      "        [3.4833, 3.5914, 3.6023, 3.6057, 3.5772],\n",
      "        [3.6192, 3.6773, 3.7617, 3.8058, 3.7247],\n",
      "        [3.7525, 3.6434, 3.8791, 4.0025, 3.7076],\n",
      "        [3.5629, 3.5480, 3.7263, 3.6732, 3.6212],\n",
      "        [3.5636, 3.7035, 3.7783, 3.7189, 3.6947],\n",
      "        [3.5036, 3.6081, 3.6108, 3.6284, 3.5864],\n",
      "        [3.5949, 3.6592, 3.7486, 3.8421, 3.6521],\n",
      "        [3.6039, 3.6661, 3.7498, 3.8291, 3.6760],\n",
      "        [3.9011, 3.9825, 3.7993, 3.8372, 3.7767],\n",
      "        [3.7420, 3.8003, 3.8047, 3.7572, 3.7393],\n",
      "        [3.6378, 3.5605, 3.7585, 3.7337, 3.6538],\n",
      "        [3.5252, 3.6107, 3.5920, 3.6593, 3.5790],\n",
      "        [3.6314, 3.5342, 3.7056, 3.6563, 3.6787],\n",
      "        [4.0404, 4.0928, 3.8089, 3.9275, 3.7534],\n",
      "        [3.9735, 3.8109, 3.9937, 4.1025, 3.9525],\n",
      "        [3.5304, 3.6110, 3.5941, 3.6648, 3.5774],\n",
      "        [3.4353, 3.5627, 3.6046, 3.6002, 3.5295],\n",
      "        [3.4299, 3.4276, 3.6083, 3.5814, 3.5097],\n",
      "        [4.1957, 4.3664, 4.0282, 4.1272, 3.9362],\n",
      "        [3.6385, 3.9054, 3.9057, 3.8072, 3.6858],\n",
      "        [3.6402, 3.5525, 3.7495, 3.7284, 3.6157],\n",
      "        [3.5828, 3.4788, 3.6809, 3.5630, 3.5295],\n",
      "        [3.4722, 3.4508, 3.6205, 3.6157, 3.5048],\n",
      "        [3.5786, 3.5142, 3.6267, 3.7588, 3.5353],\n",
      "        [3.6416, 3.6091, 3.8553, 3.8718, 3.8892],\n",
      "        [3.7574, 3.6810, 3.7822, 4.0156, 3.8536],\n",
      "        [3.5440, 3.5363, 3.7238, 3.6411, 3.6031],\n",
      "        [3.7080, 3.7363, 3.8276, 3.9281, 3.7314],\n",
      "        [3.6003, 3.6818, 3.8461, 3.7579, 3.7293],\n",
      "        [3.4674, 3.5086, 3.6659, 3.6149, 3.5446],\n",
      "        [3.4759, 3.6018, 3.6226, 3.6731, 3.5606],\n",
      "        [3.6926, 3.9159, 3.8466, 3.8550, 3.7997]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6219, 3.5737, 3.8104, 3.7826, 3.6819],\n",
      "        [3.7929, 3.9130, 3.8871, 3.7518, 3.8340],\n",
      "        [3.5942, 3.5716, 3.7666, 3.6607, 3.6364],\n",
      "        [3.7309, 3.8439, 3.7953, 3.9651, 3.8213],\n",
      "        [3.7970, 3.7986, 3.8880, 3.8933, 3.9117],\n",
      "        [3.5766, 3.6537, 3.6102, 3.7215, 3.6248],\n",
      "        [3.5007, 3.8562, 3.8729, 3.7422, 3.8441],\n",
      "        [3.6187, 3.8121, 3.7217, 3.7644, 3.7007],\n",
      "        [3.5356, 3.6169, 3.5981, 3.6571, 3.6037],\n",
      "        [3.9803, 3.6971, 3.9179, 4.3020, 4.1736],\n",
      "        [3.4901, 3.5608, 3.5970, 3.6463, 3.5522],\n",
      "        [3.4329, 3.6478, 3.8078, 3.6139, 3.6875],\n",
      "        [3.9875, 3.9939, 3.9759, 4.2341, 4.0275],\n",
      "        [3.7020, 3.8874, 3.9088, 3.8498, 3.7453],\n",
      "        [3.5643, 3.5613, 3.7337, 3.6897, 3.6341],\n",
      "        [3.6964, 3.6385, 3.7907, 3.7644, 3.6714],\n",
      "        [3.6066, 3.5777, 3.7816, 3.7067, 3.6907],\n",
      "        [3.8585, 3.8110, 3.9383, 4.0086, 3.8450],\n",
      "        [3.5453, 3.4928, 3.7187, 3.6464, 3.5877],\n",
      "        [3.5164, 3.6059, 3.5954, 3.6337, 3.5866],\n",
      "        [3.4438, 3.6291, 3.7081, 3.6075, 3.5837],\n",
      "        [3.6253, 3.6340, 3.7810, 3.6998, 3.8730],\n",
      "        [3.6827, 3.7141, 3.7460, 3.7487, 3.6838],\n",
      "        [3.9192, 3.8232, 3.8779, 3.9733, 3.9243],\n",
      "        [3.6017, 3.6048, 3.8169, 3.6584, 3.8054],\n",
      "        [3.6500, 3.5667, 3.7478, 3.6960, 3.7124],\n",
      "        [3.4319, 3.5968, 3.6861, 3.5867, 3.5491],\n",
      "        [3.6250, 3.7666, 3.7631, 3.7283, 3.7380],\n",
      "        [3.7061, 3.7194, 3.8889, 3.7803, 3.6136],\n",
      "        [3.7468, 3.8509, 3.8873, 3.9010, 3.7839],\n",
      "        [3.6100, 3.7550, 3.7429, 3.7132, 3.7365],\n",
      "        [3.5714, 3.5311, 3.7255, 3.6278, 3.5934],\n",
      "        [3.5454, 3.6605, 3.8669, 3.6679, 3.6550],\n",
      "        [3.7978, 3.9133, 3.7881, 3.8061, 3.7814],\n",
      "        [3.5886, 3.8143, 3.7226, 3.5650, 3.7286],\n",
      "        [3.4022, 3.4314, 3.6051, 3.5321, 3.4439],\n",
      "        [3.6995, 3.7838, 3.8948, 3.8243, 3.7613],\n",
      "        [4.0538, 3.8704, 4.0112, 4.1555, 4.0208],\n",
      "        [3.5382, 3.5283, 3.7153, 3.6370, 3.5968],\n",
      "        [3.8773, 3.7842, 3.9800, 4.0988, 3.7759],\n",
      "        [3.7195, 3.6588, 3.8325, 3.8910, 3.6426],\n",
      "        [3.7928, 3.8727, 3.9723, 3.9382, 3.9891],\n",
      "        [3.6529, 3.7885, 3.7875, 3.7308, 3.7539],\n",
      "        [3.5006, 3.6912, 3.6001, 3.6761, 3.5343],\n",
      "        [3.4397, 3.5097, 3.6512, 3.5845, 3.5215],\n",
      "        [3.5876, 3.7458, 3.7607, 3.6702, 3.7226],\n",
      "        [3.9760, 3.8413, 4.0384, 4.1505, 3.9591],\n",
      "        [3.5705, 3.5015, 3.6894, 3.6675, 3.7281],\n",
      "        [3.6114, 3.5868, 3.8039, 3.7435, 3.7041],\n",
      "        [3.5934, 3.7290, 3.8055, 3.7453, 3.6230],\n",
      "        [3.5859, 3.4986, 3.7011, 3.6005, 3.5548],\n",
      "        [3.5789, 3.5328, 3.6421, 3.7562, 3.5490],\n",
      "        [3.6148, 3.5723, 3.8151, 3.7519, 3.7272],\n",
      "        [3.5999, 3.7415, 3.7330, 3.7170, 3.7287],\n",
      "        [3.6377, 3.8027, 3.9237, 3.8768, 3.7442],\n",
      "        [3.7064, 3.9304, 3.8610, 3.8687, 3.8158],\n",
      "        [3.5661, 3.6404, 3.7253, 3.6834, 3.6722],\n",
      "        [4.0749, 3.7585, 4.0105, 4.3916, 4.2649],\n",
      "        [3.9282, 3.8544, 3.9695, 4.1174, 3.9388],\n",
      "        [3.7756, 3.6797, 3.8653, 3.9741, 3.6567],\n",
      "        [3.5766, 3.5492, 3.7367, 3.6785, 3.6255],\n",
      "        [3.6233, 3.7649, 3.7695, 3.8175, 3.6641],\n",
      "        [3.7475, 3.8806, 3.9394, 3.9112, 3.7794],\n",
      "        [3.9229, 3.8729, 3.9984, 4.0578, 3.9370]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.9292, 3.8538, 3.9680, 4.1186, 3.9406],\n",
      "        [3.5223, 3.6577, 3.6451, 3.7580, 3.5807],\n",
      "        [3.8330, 3.9949, 3.9207, 4.0011, 3.9813],\n",
      "        [3.5862, 3.6708, 3.6150, 3.7385, 3.6383],\n",
      "        [3.6740, 3.7951, 3.7921, 3.8347, 3.7210],\n",
      "        [3.6541, 3.8411, 3.7719, 3.8960, 3.7674],\n",
      "        [3.5809, 3.5029, 3.7207, 3.6938, 3.7319],\n",
      "        [3.6222, 3.5666, 3.7848, 3.7113, 3.6989],\n",
      "        [3.4829, 3.5703, 3.5862, 3.5950, 3.5585],\n",
      "        [3.8657, 3.8225, 3.9494, 4.0160, 3.8618],\n",
      "        [3.5910, 3.5591, 3.7525, 3.6871, 3.6398],\n",
      "        [3.7176, 3.6711, 3.8171, 3.7403, 3.5969],\n",
      "        [3.6948, 3.6127, 3.9086, 3.8535, 3.7169],\n",
      "        [3.5800, 3.6097, 3.6922, 3.7603, 3.6724],\n",
      "        [3.6156, 3.8320, 3.7288, 3.8679, 3.7466],\n",
      "        [3.9371, 3.7836, 3.9840, 4.0731, 3.8999],\n",
      "        [3.6879, 3.6827, 3.8157, 3.7324, 3.8281],\n",
      "        [3.7041, 3.6399, 3.7708, 3.6470, 3.5454],\n",
      "        [3.6763, 3.6742, 3.8590, 3.8063, 3.7153],\n",
      "        [3.9443, 3.8155, 3.9117, 4.0805, 3.9061],\n",
      "        [3.7529, 3.8683, 3.8996, 3.8897, 3.7923],\n",
      "        [4.0219, 3.8918, 3.9703, 4.1833, 4.0145],\n",
      "        [3.3783, 3.5747, 3.4791, 3.5964, 3.4454],\n",
      "        [3.5220, 3.5532, 3.6775, 3.6005, 3.6035],\n",
      "        [3.5772, 3.4647, 3.6632, 3.5607, 3.5195],\n",
      "        [3.4023, 3.4155, 3.5892, 3.5141, 3.4437],\n",
      "        [3.6242, 3.7512, 3.7112, 3.6888, 3.7019],\n",
      "        [4.0757, 3.7580, 4.0089, 4.3927, 4.2667],\n",
      "        [3.6965, 3.6532, 3.7517, 3.8839, 3.7620],\n",
      "        [3.8375, 3.7781, 3.9645, 3.9410, 3.7014],\n",
      "        [3.6032, 3.5712, 3.7601, 3.7009, 3.6921],\n",
      "        [3.6290, 3.6007, 3.8256, 3.7664, 3.7207],\n",
      "        [3.5208, 3.5555, 3.7199, 3.6859, 3.6221],\n",
      "        [3.5848, 3.6086, 3.7607, 3.7205, 3.6726],\n",
      "        [4.2716, 4.3666, 4.1003, 4.1239, 3.9827],\n",
      "        [3.7369, 3.8185, 3.9014, 3.8806, 3.7851],\n",
      "        [3.8159, 3.8641, 3.9493, 3.9277, 3.9977],\n",
      "        [3.8446, 3.7913, 3.8700, 3.8942, 3.8754],\n",
      "        [3.5927, 3.8103, 3.7032, 3.5619, 3.6912],\n",
      "        [3.7317, 3.8433, 3.7936, 3.9661, 3.8231],\n",
      "        [3.4229, 3.5879, 3.8280, 3.5899, 3.7096],\n",
      "        [3.5825, 3.5578, 3.7369, 3.6833, 3.6366],\n",
      "        [3.7295, 3.8409, 3.7923, 3.9646, 3.8195],\n",
      "        [3.5199, 3.7409, 3.7572, 3.7327, 3.7805],\n",
      "        [3.6780, 3.6547, 3.7480, 3.8138, 3.8171],\n",
      "        [3.8450, 3.7813, 3.7685, 3.8794, 3.8858],\n",
      "        [3.9948, 3.8995, 3.9133, 4.0804, 4.0372],\n",
      "        [3.7519, 3.8863, 3.9083, 3.8822, 3.7909],\n",
      "        [3.5773, 3.6531, 3.6086, 3.7224, 3.6265],\n",
      "        [3.5721, 3.5305, 3.7238, 3.6287, 3.5950],\n",
      "        [3.3720, 3.4890, 3.5535, 3.4726, 3.4931],\n",
      "        [3.4392, 3.6468, 3.8189, 3.6154, 3.6473],\n",
      "        [3.7680, 3.8209, 3.8253, 3.8331, 3.8624],\n",
      "        [3.5805, 3.6534, 3.6023, 3.7213, 3.6206],\n",
      "        [3.5910, 3.6008, 3.7522, 3.7228, 3.6728],\n",
      "        [3.5824, 3.6599, 3.6193, 3.7299, 3.6362],\n",
      "        [3.6028, 3.6471, 3.6766, 3.7722, 3.6671],\n",
      "        [3.5289, 3.6521, 3.7511, 3.7911, 3.5702],\n",
      "        [3.6404, 3.5550, 3.7484, 3.7205, 3.6426],\n",
      "        [3.6773, 3.5603, 3.9679, 3.7997, 3.7882],\n",
      "        [3.7317, 3.8433, 3.7936, 3.9661, 3.8231],\n",
      "        [3.4681, 3.4563, 3.6234, 3.6066, 3.5079],\n",
      "        [3.3570, 3.4660, 3.5410, 3.4510, 3.4656],\n",
      "        [3.5823, 3.6056, 3.6676, 3.7142, 3.6140]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4494, 3.6516, 3.7202, 3.6078, 3.5902],\n",
      "        [3.7381, 3.6672, 3.7442, 3.9693, 3.8214],\n",
      "        [3.7385, 3.8789, 3.8010, 3.8305, 3.8018],\n",
      "        [3.3788, 3.5741, 3.4774, 3.5976, 3.4467],\n",
      "        [3.4578, 3.4692, 3.6271, 3.6008, 3.5134],\n",
      "        [3.5262, 3.6576, 3.6446, 3.7571, 3.5796],\n",
      "        [3.8730, 3.8656, 3.9599, 3.9619, 4.0824],\n",
      "        [3.6147, 3.5895, 3.7971, 3.7496, 3.6950],\n",
      "        [3.4587, 3.5469, 3.6695, 3.5987, 3.5618],\n",
      "        [3.5807, 3.5218, 3.7548, 3.6049, 3.6877],\n",
      "        [3.8320, 3.8051, 3.9339, 4.0032, 4.0453],\n",
      "        [3.6996, 3.6232, 3.8084, 3.6686, 3.6855],\n",
      "        [3.6756, 3.7986, 3.7907, 3.8438, 3.7143],\n",
      "        [3.4432, 3.5427, 3.5771, 3.5533, 3.5367],\n",
      "        [3.7853, 3.9432, 3.8949, 3.9890, 3.8903],\n",
      "        [3.5280, 3.8009, 3.7273, 3.6324, 3.5523],\n",
      "        [3.6258, 3.6663, 3.7528, 3.6936, 3.6953],\n",
      "        [3.6493, 3.6391, 3.8222, 3.7733, 3.8118],\n",
      "        [3.5475, 3.6334, 3.6089, 3.6802, 3.6126],\n",
      "        [3.6574, 3.5487, 3.9775, 3.7816, 3.7656],\n",
      "        [3.5779, 3.6524, 3.6067, 3.7236, 3.6277],\n",
      "        [3.4314, 3.5560, 3.6649, 3.5855, 3.5384],\n",
      "        [3.5040, 3.6301, 3.6289, 3.7303, 3.5696],\n",
      "        [3.5892, 3.6682, 3.6087, 3.7403, 3.6378],\n",
      "        [3.5128, 3.5791, 3.6142, 3.6660, 3.6013],\n",
      "        [3.5815, 3.5478, 3.7471, 3.6874, 3.6349],\n",
      "        [3.3930, 3.4992, 3.4723, 3.5992, 3.4653],\n",
      "        [3.4451, 3.6278, 3.7046, 3.6095, 3.5867],\n",
      "        [3.6431, 3.5508, 3.7445, 3.7310, 3.6196],\n",
      "        [3.5489, 3.6308, 3.5972, 3.6930, 3.6045],\n",
      "        [3.9446, 4.0154, 3.8082, 3.8753, 3.7886],\n",
      "        [3.5697, 3.5794, 3.7339, 3.7006, 3.6397],\n",
      "        [3.6873, 3.6180, 3.7617, 3.6666, 3.5240],\n",
      "        [3.4159, 3.4458, 3.5762, 3.5297, 3.4973],\n",
      "        [3.5966, 3.6776, 3.6268, 3.7543, 3.6501],\n",
      "        [3.4381, 3.5611, 3.5996, 3.6026, 3.5336],\n",
      "        [3.5790, 3.5396, 3.6477, 3.7551, 3.5656],\n",
      "        [3.4726, 3.4927, 3.6627, 3.6142, 3.5066],\n",
      "        [3.6093, 3.6688, 3.7435, 3.6931, 3.6833],\n",
      "        [3.9656, 3.8643, 3.9627, 4.1066, 3.9397],\n",
      "        [4.0889, 3.9453, 4.0683, 4.2465, 4.0787],\n",
      "        [3.5786, 3.5009, 3.6991, 3.6840, 3.7367],\n",
      "        [3.6010, 3.5933, 3.8267, 3.7368, 3.7089],\n",
      "        [3.6878, 3.8551, 3.9284, 3.8497, 3.7149],\n",
      "        [3.6337, 3.5677, 3.7787, 3.7133, 3.7068],\n",
      "        [3.4554, 3.4814, 3.6359, 3.5942, 3.5186],\n",
      "        [3.6617, 3.6929, 3.6857, 3.7740, 3.6980],\n",
      "        [3.4492, 3.5152, 3.6574, 3.5926, 3.5325],\n",
      "        [3.6383, 3.5412, 3.7108, 3.6749, 3.6933],\n",
      "        [3.8310, 3.8459, 3.9619, 3.9403, 3.8118],\n",
      "        [3.7443, 3.8720, 3.8267, 3.8525, 3.7929],\n",
      "        [3.6886, 3.6819, 3.8137, 3.7337, 3.8292],\n",
      "        [3.7048, 3.6391, 3.7690, 3.6483, 3.5466],\n",
      "        [4.0187, 4.0820, 3.8344, 3.9315, 3.7972],\n",
      "        [3.9579, 3.8627, 3.9772, 4.1075, 3.9229],\n",
      "        [3.8254, 3.9403, 4.0069, 3.8985, 3.6935],\n",
      "        [3.7786, 4.0002, 3.9907, 3.9411, 3.9488],\n",
      "        [3.6257, 3.6036, 3.7471, 3.7352, 3.6837],\n",
      "        [3.4819, 3.6163, 3.5873, 3.6692, 3.5699],\n",
      "        [3.8581, 3.8036, 3.9250, 4.0446, 4.0574],\n",
      "        [3.6779, 3.7932, 3.9172, 3.9256, 3.8068],\n",
      "        [3.7405, 3.8186, 3.8880, 3.8086, 3.6349],\n",
      "        [3.5739, 3.5905, 3.7426, 3.7109, 3.6483],\n",
      "        [3.5351, 3.6390, 3.7630, 3.7373, 3.5830]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5813, 3.5460, 3.7564, 3.6824, 3.6314],\n",
      "        [3.5580, 3.7242, 3.8133, 3.7122, 3.6986],\n",
      "        [3.5887, 3.5119, 3.7429, 3.7027, 3.7365],\n",
      "        [3.5819, 3.6593, 3.6115, 3.7275, 3.6391],\n",
      "        [3.5991, 3.8115, 3.7885, 3.7220, 3.5704],\n",
      "        [3.7570, 3.7108, 3.9841, 3.7889, 3.6215],\n",
      "        [3.4357, 3.6366, 3.7045, 3.5964, 3.5800],\n",
      "        [3.6752, 3.7935, 3.7885, 3.8372, 3.7242],\n",
      "        [3.5876, 3.4964, 3.6956, 3.6034, 3.5592],\n",
      "        [3.8918, 3.8938, 3.8783, 3.9571, 3.9715],\n",
      "        [3.6435, 3.5499, 3.7425, 3.7318, 3.6214],\n",
      "        [3.4745, 3.5434, 3.6968, 3.6350, 3.5449],\n",
      "        [3.8020, 3.9021, 3.9669, 3.8614, 3.6262],\n",
      "        [3.7736, 3.5173, 3.6345, 3.6768, 3.7574],\n",
      "        [3.5863, 3.6570, 3.6044, 3.7326, 3.6295],\n",
      "        [3.6440, 3.7623, 3.7398, 3.8142, 3.6949],\n",
      "        [3.5209, 3.4595, 3.6264, 3.6475, 3.5068],\n",
      "        [3.5828, 3.5939, 3.7470, 3.7179, 3.6677],\n",
      "        [3.6413, 3.7346, 3.8422, 3.8576, 3.7878],\n",
      "        [3.7553, 3.6636, 3.7809, 3.7063, 3.6128],\n",
      "        [3.5997, 3.6355, 3.6575, 3.7684, 3.6616],\n",
      "        [3.5711, 3.5494, 3.7296, 3.6880, 3.6362],\n",
      "        [3.4693, 3.5631, 3.5845, 3.5851, 3.5574],\n",
      "        [3.6520, 3.5645, 3.7421, 3.6989, 3.7167],\n",
      "        [3.9821, 4.0927, 4.1500, 4.1850, 4.2586],\n",
      "        [3.4720, 3.5018, 3.5525, 3.6508, 3.4688],\n",
      "        [3.7279, 3.8412, 3.8707, 3.9616, 3.7796],\n",
      "        [3.6396, 3.8007, 3.9183, 3.8810, 3.7492],\n",
      "        [3.5794, 3.5387, 3.6458, 3.7559, 3.5673],\n",
      "        [3.4628, 3.5454, 3.6681, 3.6065, 3.5718],\n",
      "        [3.5951, 3.5985, 3.8266, 3.6120, 3.8176],\n",
      "        [3.6013, 3.6445, 3.5787, 3.7414, 3.5498],\n",
      "        [3.5335, 3.6457, 3.7514, 3.7892, 3.5834],\n",
      "        [3.4956, 3.4093, 3.7066, 3.4443, 3.6512],\n",
      "        [3.8869, 3.8494, 3.9473, 4.0423, 3.8364],\n",
      "        [3.4863, 3.4571, 3.6208, 3.6252, 3.5165],\n",
      "        [3.5421, 3.6373, 3.6085, 3.6807, 3.6126],\n",
      "        [3.4654, 3.4363, 3.6038, 3.6112, 3.4968],\n",
      "        [3.7451, 3.6562, 3.7710, 3.6910, 3.6026],\n",
      "        [3.4632, 3.4777, 3.6344, 3.6110, 3.5241],\n",
      "        [4.2616, 4.3514, 4.1016, 4.1501, 3.9682],\n",
      "        [3.4345, 3.5775, 3.6740, 3.5871, 3.5469],\n",
      "        [3.4064, 3.5283, 3.5851, 3.5136, 3.5367],\n",
      "        [3.7367, 3.6499, 3.7729, 3.6841, 3.5886],\n",
      "        [3.6342, 3.8037, 3.7200, 3.7710, 3.7170],\n",
      "        [3.6153, 3.8212, 3.8086, 3.7511, 3.5812],\n",
      "        [3.5600, 3.6145, 3.6850, 3.6582, 3.6286],\n",
      "        [3.5373, 3.6147, 3.5928, 3.6598, 3.6083],\n",
      "        [3.6132, 3.7158, 3.6293, 3.6842, 3.6480],\n",
      "        [3.4343, 3.5694, 3.6747, 3.5964, 3.5545],\n",
      "        [3.5793, 3.7018, 3.7741, 3.7220, 3.6884],\n",
      "        [3.4551, 3.5621, 3.5876, 3.5665, 3.5639],\n",
      "        [3.6983, 3.6363, 3.7850, 3.7673, 3.6759],\n",
      "        [3.5872, 3.7585, 3.7170, 3.6691, 3.7068],\n",
      "        [3.6312, 3.6800, 3.7553, 3.8271, 3.7287],\n",
      "        [3.8072, 3.8510, 3.8717, 3.8828, 3.8836],\n",
      "        [3.4666, 3.5688, 3.5848, 3.5916, 3.5640],\n",
      "        [3.8326, 3.9400, 3.9734, 3.9844, 3.9360],\n",
      "        [3.9123, 3.7507, 3.8371, 3.9093, 3.8600],\n",
      "        [3.5220, 3.5986, 3.5862, 3.6448, 3.5794],\n",
      "        [4.0010, 3.9071, 3.9232, 4.0791, 4.0312],\n",
      "        [3.5629, 3.5672, 3.6191, 3.6595, 3.6893],\n",
      "        [3.5941, 3.6757, 3.6110, 3.7513, 3.6498],\n",
      "        [3.5928, 3.8121, 3.7884, 3.7160, 3.5678]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5189, 3.6073, 3.5916, 3.6443, 3.5945],\n",
      "        [3.5455, 3.5581, 3.6929, 3.7089, 3.5827],\n",
      "        [3.6111, 3.9157, 3.8149, 3.8823, 3.8490],\n",
      "        [3.4706, 3.4403, 3.6067, 3.6241, 3.5097],\n",
      "        [3.4455, 3.6260, 3.7014, 3.6105, 3.5903],\n",
      "        [3.5013, 3.5932, 3.5957, 3.6076, 3.5944],\n",
      "        [3.4959, 3.5407, 3.5912, 3.6480, 3.5482],\n",
      "        [3.5730, 3.5279, 3.7185, 3.6311, 3.5997],\n",
      "        [3.5488, 3.5501, 3.5999, 3.6444, 3.6784],\n",
      "        [3.6652, 3.7356, 3.7610, 3.8093, 3.7643],\n",
      "        [3.6709, 3.6369, 3.8593, 3.7978, 3.7456],\n",
      "        [3.7603, 3.7178, 3.8826, 3.8936, 3.6288],\n",
      "        [3.7746, 3.9377, 3.8808, 3.9736, 3.8895],\n",
      "        [3.7267, 3.8441, 3.8719, 3.9659, 3.7899],\n",
      "        [3.5743, 3.5544, 3.7252, 3.6839, 3.6375],\n",
      "        [3.7100, 3.8887, 3.9664, 3.8838, 3.7453],\n",
      "        [3.9052, 3.7167, 3.9313, 3.9719, 3.8599],\n",
      "        [3.5341, 3.4773, 3.6986, 3.6352, 3.5762],\n",
      "        [3.5479, 3.6316, 3.6058, 3.6811, 3.6163],\n",
      "        [3.4012, 3.5151, 3.5632, 3.5109, 3.5195],\n",
      "        [3.7434, 4.0089, 3.9436, 3.9340, 3.9722],\n",
      "        [3.7607, 3.7545, 3.8954, 3.9004, 3.6777],\n",
      "        [3.7113, 3.9543, 3.9367, 3.8832, 3.9014],\n",
      "        [3.4005, 3.4262, 3.5647, 3.5084, 3.4910],\n",
      "        [3.7575, 3.5545, 3.8056, 3.9462, 3.9341],\n",
      "        [3.5797, 3.5479, 3.6583, 3.7451, 3.5819],\n",
      "        [3.5473, 3.6268, 3.7262, 3.7589, 3.6556],\n",
      "        [3.6024, 3.5684, 3.7611, 3.7072, 3.6932],\n",
      "        [3.4292, 3.5740, 3.6731, 3.5899, 3.5429],\n",
      "        [3.8204, 3.8709, 3.9791, 3.8709, 3.7099],\n",
      "        [3.7883, 3.6824, 3.8718, 3.9878, 3.6739],\n",
      "        [3.5493, 3.5472, 3.7434, 3.7060, 3.7209],\n",
      "        [3.9464, 3.8131, 3.9075, 4.0842, 3.9115],\n",
      "        [3.4706, 3.4403, 3.6067, 3.6241, 3.5097],\n",
      "        [3.4921, 3.5861, 3.5947, 3.6033, 3.5783],\n",
      "        [4.1241, 4.1981, 3.9524, 3.9861, 3.8435],\n",
      "        [3.7655, 3.7371, 3.8883, 3.8941, 3.6521],\n",
      "        [3.4973, 3.5480, 3.5940, 3.6475, 3.5488],\n",
      "        [3.5799, 3.5425, 3.7413, 3.6808, 3.6296],\n",
      "        [3.4125, 3.5226, 3.5717, 3.5157, 3.5280],\n",
      "        [3.9492, 3.9555, 4.0797, 4.1837, 4.2254],\n",
      "        [3.7435, 3.6939, 3.9159, 3.7862, 3.5602],\n",
      "        [3.6958, 3.7655, 3.8653, 3.8880, 3.8398],\n",
      "        [3.6170, 3.6158, 3.7506, 3.6218, 3.4957],\n",
      "        [3.7635, 3.8856, 3.9033, 3.8836, 3.7878],\n",
      "        [3.7486, 3.8576, 3.8214, 3.8662, 3.8013],\n",
      "        [3.6332, 3.8059, 3.7144, 3.5807, 3.6621],\n",
      "        [3.3961, 3.4400, 3.5612, 3.5063, 3.4878],\n",
      "        [3.5767, 3.8066, 3.7791, 3.7083, 3.5642],\n",
      "        [3.8871, 3.8484, 3.9461, 4.0429, 3.8384],\n",
      "        [3.8611, 3.8082, 3.9323, 4.0128, 3.8524],\n",
      "        [3.6253, 3.7487, 3.7061, 3.6915, 3.7069],\n",
      "        [3.6565, 3.6610, 3.7556, 3.7673, 3.7759],\n",
      "        [3.5369, 3.6152, 3.6017, 3.6753, 3.6126],\n",
      "        [3.9554, 3.8598, 3.9762, 4.1151, 3.9249],\n",
      "        [3.5856, 3.6516, 3.7352, 3.6639, 3.5761],\n",
      "        [3.4845, 3.6671, 3.5808, 3.6777, 3.5378],\n",
      "        [3.7739, 3.8503, 3.8757, 3.7540, 3.8091],\n",
      "        [3.6091, 3.7440, 3.7555, 3.6987, 3.7392],\n",
      "        [3.6753, 3.7925, 3.7873, 3.8376, 3.7263],\n",
      "        [3.7178, 3.6692, 3.8154, 3.7362, 3.6028],\n",
      "        [3.9870, 3.8932, 3.8714, 4.0610, 4.0574],\n",
      "        [3.6788, 3.6052, 3.7842, 3.6730, 3.6323],\n",
      "        [3.6072, 3.9160, 3.7727, 3.8966, 3.8297]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6053, 3.5753, 3.7457, 3.7013, 3.7089],\n",
      "        [3.6111, 3.7221, 3.6274, 3.6837, 3.6554],\n",
      "        [3.5704, 3.5765, 3.8703, 3.5607, 3.8158],\n",
      "        [3.5167, 3.5516, 3.4804, 3.7145, 3.4750],\n",
      "        [3.7894, 3.8962, 3.7652, 3.7887, 3.7748],\n",
      "        [3.6345, 3.7692, 3.7682, 3.8199, 3.6781],\n",
      "        [3.8870, 3.8480, 3.9447, 4.0437, 3.8398],\n",
      "        [3.5477, 3.5127, 3.7004, 3.6326, 3.5912],\n",
      "        [3.9037, 3.8872, 3.9145, 4.0900, 3.9329],\n",
      "        [3.6575, 3.5466, 3.9727, 3.7834, 3.7705],\n",
      "        [3.4328, 3.5569, 3.6632, 3.5856, 3.5432],\n",
      "        [3.7444, 3.7955, 3.9372, 3.8158, 3.6585],\n",
      "        [3.4694, 3.7646, 3.7299, 3.5329, 3.7327],\n",
      "        [3.5666, 3.5529, 3.7122, 3.6809, 3.6335],\n",
      "        [3.9747, 3.8802, 3.9230, 4.0406, 3.9760],\n",
      "        [3.6558, 3.7516, 3.7255, 3.7966, 3.7165],\n",
      "        [3.5708, 3.6597, 3.7707, 3.8106, 3.6408],\n",
      "        [3.2842, 3.4153, 3.5757, 3.4737, 3.4963],\n",
      "        [3.9414, 3.8248, 3.9368, 4.0813, 3.9457],\n",
      "        [3.5824, 3.7620, 3.7851, 3.6582, 3.7485],\n",
      "        [3.5166, 3.6097, 3.6748, 3.5496, 3.5933],\n",
      "        [4.0871, 3.9934, 4.0408, 4.2580, 4.0001],\n",
      "        [3.6189, 3.8082, 3.7969, 3.7416, 3.5837],\n",
      "        [3.5915, 3.6600, 3.7483, 3.6926, 3.5827],\n",
      "        [3.5686, 3.5420, 3.6663, 3.6380, 3.6773],\n",
      "        [3.7508, 3.8688, 3.7894, 3.8311, 3.8123],\n",
      "        [3.7943, 3.8036, 3.9449, 4.0087, 3.7722],\n",
      "        [3.6535, 3.8405, 3.8037, 3.8237, 3.8670],\n",
      "        [3.5806, 3.5293, 3.6343, 3.7602, 3.5569],\n",
      "        [3.6783, 3.7910, 3.9127, 3.9283, 3.8126],\n",
      "        [3.4706, 3.4755, 3.6320, 3.6076, 3.5273],\n",
      "        [3.4438, 3.5685, 3.6709, 3.6016, 3.5689],\n",
      "        [3.7638, 3.7384, 3.8736, 3.8698, 3.9435],\n",
      "        [3.5673, 3.6410, 3.5980, 3.7182, 3.6303],\n",
      "        [3.7413, 3.6929, 3.9177, 3.7900, 3.5420],\n",
      "        [3.5605, 3.5081, 3.7237, 3.6647, 3.6036],\n",
      "        [3.4413, 3.6156, 3.6926, 3.5997, 3.5761],\n",
      "        [3.7882, 3.6821, 3.8705, 3.9887, 3.6754],\n",
      "        [3.4974, 3.6535, 3.6991, 3.5569, 3.5596],\n",
      "        [3.4423, 3.5262, 3.6579, 3.5909, 3.5393],\n",
      "        [3.6151, 3.8199, 3.8059, 3.7522, 3.5846],\n",
      "        [3.6076, 3.6625, 3.7407, 3.8344, 3.6855],\n",
      "        [3.3367, 3.4695, 3.6059, 3.5130, 3.5175],\n",
      "        [3.5260, 3.6132, 3.5910, 3.6625, 3.5957],\n",
      "        [3.7236, 3.6839, 3.8166, 3.7515, 3.6029],\n",
      "        [3.9805, 3.7517, 3.9898, 4.3878, 4.2226],\n",
      "        [3.9672, 3.8389, 3.9134, 4.0187, 3.9632],\n",
      "        [3.7011, 3.6358, 3.7753, 3.6527, 3.5418],\n",
      "        [3.7327, 3.8385, 3.7876, 3.9642, 3.8283],\n",
      "        [4.1698, 4.3165, 3.9606, 4.0307, 3.9382],\n",
      "        [3.7870, 3.5440, 3.7981, 3.9924, 3.9587],\n",
      "        [3.9198, 3.8643, 3.9931, 4.0766, 3.9385],\n",
      "        [3.5058, 3.5936, 3.5959, 3.6162, 3.6051],\n",
      "        [3.6302, 3.4904, 3.7569, 3.8760, 3.5717],\n",
      "        [3.5735, 3.6814, 3.7223, 3.7642, 3.7042],\n",
      "        [3.6905, 3.6091, 3.7950, 3.6686, 3.6776],\n",
      "        [3.7451, 3.7617, 3.9080, 3.7989, 3.5953],\n",
      "        [3.5678, 3.9731, 3.9179, 3.7521, 3.6930],\n",
      "        [3.9883, 3.8969, 3.8582, 4.0548, 4.0742],\n",
      "        [3.5777, 3.5639, 3.7244, 3.6848, 3.6407],\n",
      "        [3.8397, 3.9632, 4.0401, 3.9486, 3.7362],\n",
      "        [3.3728, 3.4863, 3.5475, 3.4754, 3.4993],\n",
      "        [3.5220, 3.5784, 3.6298, 3.7178, 3.6160],\n",
      "        [3.5095, 3.6331, 3.6386, 3.6919, 3.5564]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6979, 3.6344, 3.7806, 3.7694, 3.6822],\n",
      "        [3.6205, 3.5826, 3.7448, 3.7119, 3.6982],\n",
      "        [3.6955, 3.6095, 3.9004, 3.8576, 3.7261],\n",
      "        [4.0862, 4.1666, 4.0008, 3.9925, 3.9307],\n",
      "        [3.6281, 3.5735, 3.8165, 3.7938, 3.7881],\n",
      "        [3.5936, 3.4846, 3.6831, 3.5825, 3.5523],\n",
      "        [3.7288, 3.8251, 3.8900, 3.8807, 3.8200],\n",
      "        [3.4381, 3.6194, 3.6945, 3.5996, 3.5777],\n",
      "        [3.6879, 3.8523, 3.9221, 3.8526, 3.7230],\n",
      "        [3.9477, 4.0594, 3.9395, 3.8873, 3.8856],\n",
      "        [3.4585, 3.5443, 3.6634, 3.6014, 3.5696],\n",
      "        [3.6438, 3.7605, 3.7358, 3.8165, 3.7016],\n",
      "        [3.7423, 3.8409, 3.8578, 3.8887, 3.7892],\n",
      "        [3.5080, 3.5932, 3.7631, 3.6619, 3.6680],\n",
      "        [3.5656, 3.6632, 3.7643, 3.8116, 3.6261],\n",
      "        [3.9391, 3.7219, 3.9447, 4.3486, 4.1863],\n",
      "        [3.4660, 3.4648, 3.6222, 3.6053, 3.5249],\n",
      "        [3.8029, 3.7595, 3.8607, 3.8702, 3.9306],\n",
      "        [3.6064, 3.5750, 3.8014, 3.7229, 3.7072],\n",
      "        [3.5724, 3.4976, 3.6795, 3.6723, 3.7386],\n",
      "        [3.4827, 3.4592, 3.6205, 3.6209, 3.5256],\n",
      "        [3.6872, 3.7988, 3.7462, 3.9230, 3.7767],\n",
      "        [3.7547, 3.8275, 3.8965, 3.8209, 3.6563],\n",
      "        [3.5867, 3.5974, 3.7428, 3.7317, 3.6642],\n",
      "        [3.5957, 3.6484, 3.7489, 3.6979, 3.5692],\n",
      "        [3.5865, 3.6673, 3.6072, 3.7423, 3.6475],\n",
      "        [3.4683, 3.4469, 3.6090, 3.6171, 3.5115],\n",
      "        [3.6119, 3.7338, 3.6745, 3.8729, 3.6280],\n",
      "        [3.5775, 3.5271, 3.7379, 3.6706, 3.6335],\n",
      "        [3.4375, 3.6577, 3.5403, 3.6643, 3.5180],\n",
      "        [3.6722, 3.8410, 3.7875, 3.9132, 3.7832],\n",
      "        [3.5139, 3.5511, 3.7141, 3.7003, 3.6486],\n",
      "        [3.9157, 3.8726, 3.9639, 4.0910, 3.8780],\n",
      "        [4.0306, 3.9084, 3.9865, 4.1769, 3.9194],\n",
      "        [4.0714, 4.1698, 4.2235, 4.2602, 4.3571],\n",
      "        [3.4864, 3.4911, 3.6547, 3.6274, 3.5240],\n",
      "        [3.6204, 3.5674, 3.7877, 3.7190, 3.7070],\n",
      "        [3.6409, 3.5577, 3.7541, 3.7289, 3.6758],\n",
      "        [3.5701, 3.5878, 3.7358, 3.7173, 3.6627],\n",
      "        [3.7732, 3.8342, 3.9135, 3.8377, 3.6682],\n",
      "        [3.4655, 3.5631, 3.6990, 3.6413, 3.5588],\n",
      "        [3.4678, 3.6865, 3.8762, 3.7012, 3.7155],\n",
      "        [3.4361, 3.5459, 3.5790, 3.5473, 3.5594],\n",
      "        [3.6576, 3.7259, 3.9119, 3.8175, 3.8068],\n",
      "        [3.7183, 3.7845, 3.8949, 3.8214, 3.7686],\n",
      "        [3.5748, 3.5933, 3.7367, 3.7162, 3.6584],\n",
      "        [3.7448, 3.7612, 3.9064, 3.8000, 3.5983],\n",
      "        [3.4404, 3.4851, 3.6316, 3.5878, 3.5241],\n",
      "        [3.4050, 3.5232, 3.5690, 3.5210, 3.5317],\n",
      "        [3.4715, 3.5045, 3.5489, 3.6523, 3.4629],\n",
      "        [3.3597, 3.4710, 3.5350, 3.4572, 3.4793],\n",
      "        [3.6519, 3.7546, 3.8610, 3.8806, 3.7852],\n",
      "        [3.9036, 3.8867, 3.9130, 4.0913, 3.9360],\n",
      "        [3.5088, 3.6514, 3.7387, 3.8027, 3.5795],\n",
      "        [3.4682, 3.5654, 3.5801, 3.5875, 3.5668],\n",
      "        [3.7467, 3.8049, 3.8936, 3.8901, 3.7672],\n",
      "        [3.5774, 3.5633, 3.7228, 3.6859, 3.6436],\n",
      "        [3.9644, 3.8632, 3.9432, 4.0952, 3.9613],\n",
      "        [3.4685, 3.4529, 3.6154, 3.6106, 3.5168],\n",
      "        [3.8802, 3.7332, 3.8228, 3.8910, 3.8987],\n",
      "        [3.9802, 3.7512, 3.9882, 4.3892, 4.2257],\n",
      "        [3.8162, 3.7849, 3.9103, 3.9260, 3.9842],\n",
      "        [3.4951, 3.4074, 3.7024, 3.4462, 3.6570],\n",
      "        [3.6102, 3.5739, 3.7908, 3.7571, 3.7154]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4320, 3.5937, 3.6749, 3.5936, 3.5620],\n",
      "        [3.5315, 3.4508, 3.7311, 3.5094, 3.6853],\n",
      "        [3.4967, 3.5693, 3.7224, 3.6690, 3.5589],\n",
      "        [3.6482, 3.8894, 3.9405, 3.8914, 3.8958],\n",
      "        [3.5335, 3.5471, 3.7077, 3.6700, 3.6431],\n",
      "        [3.4441, 3.6374, 3.7023, 3.6155, 3.6039],\n",
      "        [3.5805, 3.5106, 3.6142, 3.7665, 3.5498],\n",
      "        [3.5886, 3.6089, 3.7469, 3.7384, 3.6861],\n",
      "        [3.5335, 3.6308, 3.7555, 3.7516, 3.5954],\n",
      "        [3.4371, 3.6043, 3.6835, 3.6096, 3.5778],\n",
      "        [3.5455, 3.4896, 3.7073, 3.6536, 3.6004],\n",
      "        [3.6378, 3.5393, 3.7026, 3.6798, 3.7034],\n",
      "        [3.6332, 3.7699, 3.7650, 3.8232, 3.6842],\n",
      "        [3.4232, 3.5396, 3.5737, 3.5459, 3.5483],\n",
      "        [3.3998, 3.6557, 3.6172, 3.4357, 3.5922],\n",
      "        [3.5915, 3.6485, 3.6882, 3.7546, 3.7621],\n",
      "        [3.7195, 3.6813, 3.8874, 3.7619, 3.5367],\n",
      "        [3.5780, 3.7061, 3.7035, 3.7496, 3.7268],\n",
      "        [3.5413, 3.6352, 3.7571, 3.7415, 3.5915],\n",
      "        [3.8608, 3.8499, 3.9043, 4.0351, 3.8428],\n",
      "        [3.5314, 3.6135, 3.5867, 3.6577, 3.6086],\n",
      "        [3.5028, 3.7955, 3.8684, 3.7323, 3.8392],\n",
      "        [3.6807, 3.6139, 3.7833, 3.6865, 3.6345],\n",
      "        [3.7929, 3.6120, 3.7537, 3.7844, 3.7795],\n",
      "        [3.7726, 3.7472, 3.8454, 3.8449, 3.9127],\n",
      "        [3.7357, 3.7427, 3.8990, 3.7979, 3.6122],\n",
      "        [3.4025, 3.4284, 3.5943, 3.5386, 3.4568],\n",
      "        [3.5543, 3.6348, 3.5951, 3.6957, 3.6268],\n",
      "        [3.6042, 3.5444, 3.7765, 3.7467, 3.7662],\n",
      "        [3.5156, 3.4298, 3.5809, 3.6200, 3.4957],\n",
      "        [3.5610, 3.5269, 3.7247, 3.6809, 3.6240],\n",
      "        [3.6962, 3.6434, 3.8010, 3.7162, 3.6229],\n",
      "        [3.3665, 3.4805, 3.5348, 3.4737, 3.4917],\n",
      "        [3.7362, 3.8221, 3.7961, 3.8666, 3.7881],\n",
      "        [3.8316, 3.8865, 4.0024, 4.0862, 4.1643],\n",
      "        [3.5690, 3.5799, 3.7263, 3.7069, 3.6519],\n",
      "        [3.6613, 3.6007, 3.8506, 3.9211, 3.9365],\n",
      "        [3.9380, 3.7228, 3.9429, 4.3513, 4.1888],\n",
      "        [3.7046, 3.7082, 3.6720, 3.7730, 3.8088],\n",
      "        [3.4807, 3.6146, 3.5798, 3.6744, 3.5801],\n",
      "        [3.4516, 3.5050, 3.6452, 3.6058, 3.5503],\n",
      "        [3.6534, 3.6274, 3.8413, 3.7745, 3.7439],\n",
      "        [3.4323, 3.6254, 3.6878, 3.5978, 3.5779],\n",
      "        [3.6647, 3.6981, 3.7015, 3.7944, 3.7323],\n",
      "        [3.5678, 3.8728, 3.8065, 3.8263, 3.8618],\n",
      "        [3.6762, 3.8019, 3.7886, 3.7252, 3.7976],\n",
      "        [3.5792, 3.6522, 3.7117, 3.7882, 3.7484],\n",
      "        [3.7398, 3.8166, 3.8797, 3.8138, 3.6457],\n",
      "        [3.5794, 3.6072, 3.6826, 3.7667, 3.6841],\n",
      "        [3.4438, 3.5533, 3.5761, 3.5672, 3.5585],\n",
      "        [3.5854, 3.5142, 3.7277, 3.7060, 3.7478],\n",
      "        [3.5129, 3.6734, 3.5974, 3.7176, 3.5603],\n",
      "        [3.7381, 3.8346, 3.9030, 3.8057, 3.6780],\n",
      "        [3.6239, 3.7490, 3.7014, 3.6956, 3.7140],\n",
      "        [3.5888, 3.5294, 3.6262, 3.7663, 3.5713],\n",
      "        [3.5568, 3.6204, 3.7197, 3.7365, 3.7206],\n",
      "        [3.9304, 3.7126, 3.9371, 4.0016, 3.8904],\n",
      "        [3.5971, 3.6702, 3.6954, 3.7866, 3.7173],\n",
      "        [3.6241, 3.7622, 3.7588, 3.8257, 3.6787],\n",
      "        [3.5594, 3.6695, 3.7202, 3.7768, 3.7052],\n",
      "        [3.6564, 3.8561, 3.8137, 3.8350, 3.8784],\n",
      "        [3.5668, 3.5557, 3.7214, 3.7021, 3.6503],\n",
      "        [3.9043, 3.9485, 3.9450, 3.9789, 4.0109],\n",
      "        [3.6020, 3.7799, 3.7728, 3.8662, 3.6647]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6259, 3.4909, 3.7423, 3.8658, 3.5779],\n",
      "        [3.4998, 3.4924, 3.7233, 3.6496, 3.6024],\n",
      "        [3.9995, 3.9494, 3.9959, 4.2310, 4.0215],\n",
      "        [3.9858, 3.8912, 3.8775, 4.0679, 4.0573],\n",
      "        [3.6290, 3.7526, 3.6963, 3.7064, 3.7117],\n",
      "        [3.9937, 3.8979, 3.9017, 4.0893, 4.0529],\n",
      "        [3.7339, 3.5033, 3.6430, 3.7054, 3.7187],\n",
      "        [3.6606, 3.8751, 3.8297, 3.8458, 3.8875],\n",
      "        [3.6825, 3.8299, 3.7983, 3.9274, 3.7887],\n",
      "        [3.5451, 3.6321, 3.5995, 3.6865, 3.6258],\n",
      "        [3.5824, 3.5630, 3.7288, 3.6965, 3.6585],\n",
      "        [3.4797, 3.4792, 3.5216, 3.6616, 3.5221],\n",
      "        [3.7255, 3.8410, 3.8627, 3.9680, 3.7917],\n",
      "        [3.5596, 3.6390, 3.6007, 3.7122, 3.6377],\n",
      "        [3.5781, 3.6529, 3.7099, 3.7898, 3.7514],\n",
      "        [3.6717, 3.6633, 3.7537, 3.7609, 3.6859],\n",
      "        [3.6183, 3.5686, 3.7840, 3.7230, 3.7121],\n",
      "        [3.5576, 3.4784, 3.6468, 3.6441, 3.7280],\n",
      "        [3.9697, 4.0330, 3.7898, 3.8803, 3.7929],\n",
      "        [3.6164, 3.5750, 3.7820, 3.7084, 3.6750],\n",
      "        [3.6822, 3.6036, 3.8870, 3.8652, 3.6867],\n",
      "        [3.8470, 3.6901, 3.7588, 3.8532, 3.8514],\n",
      "        [3.5870, 3.8121, 3.7090, 3.5742, 3.7444],\n",
      "        [3.3527, 3.4729, 3.5341, 3.4599, 3.4856],\n",
      "        [3.9357, 3.7113, 3.9476, 4.0455, 3.8964],\n",
      "        [3.4394, 3.5596, 3.5910, 3.5634, 3.5746],\n",
      "        [3.5687, 3.6271, 3.6357, 3.6944, 3.6657],\n",
      "        [3.5580, 3.5090, 3.7186, 3.6698, 3.6115],\n",
      "        [3.5496, 3.6889, 3.7435, 3.7059, 3.7026],\n",
      "        [3.7297, 3.8411, 3.7817, 3.9740, 3.8382],\n",
      "        [3.7956, 3.8511, 3.9356, 3.8651, 3.6926],\n",
      "        [3.5726, 3.5670, 3.7169, 3.6917, 3.6481],\n",
      "        [3.9530, 3.8222, 3.9101, 4.0906, 3.9234],\n",
      "        [3.7458, 3.8589, 3.8149, 3.8718, 3.8113],\n",
      "        [3.5647, 3.8578, 3.7944, 3.8182, 3.8582],\n",
      "        [3.7522, 3.7770, 3.8620, 3.8567, 3.9048],\n",
      "        [3.5774, 3.5571, 3.7260, 3.6941, 3.6501],\n",
      "        [3.7297, 3.8411, 3.7817, 3.9740, 3.8382],\n",
      "        [3.6077, 3.5493, 3.7832, 3.7602, 3.7713],\n",
      "        [3.5613, 3.6860, 3.6408, 3.8170, 3.5967],\n",
      "        [3.5782, 3.5302, 3.6292, 3.7651, 3.5652],\n",
      "        [3.6973, 3.5695, 3.9608, 3.8363, 3.8188],\n",
      "        [3.5846, 3.7585, 3.7090, 3.6750, 3.7186],\n",
      "        [3.5650, 3.9746, 3.9125, 3.7568, 3.7017],\n",
      "        [3.7006, 3.9170, 3.9194, 3.8832, 3.9805],\n",
      "        [3.6009, 3.6451, 3.6652, 3.7801, 3.6817],\n",
      "        [3.4303, 3.5577, 3.6582, 3.5904, 3.5511],\n",
      "        [3.9221, 3.7963, 3.9010, 3.9880, 3.9176],\n",
      "        [3.5015, 3.6289, 3.6193, 3.7369, 3.5825],\n",
      "        [3.9280, 3.8523, 3.9564, 4.1278, 3.9575],\n",
      "        [3.6803, 3.6219, 3.7809, 3.6942, 3.6214],\n",
      "        [3.8819, 3.7082, 3.9191, 4.0132, 3.8443],\n",
      "        [3.5806, 3.5873, 3.7335, 3.7086, 3.6657],\n",
      "        [3.7275, 3.8387, 3.7804, 3.9726, 3.8347],\n",
      "        [3.5799, 3.5935, 3.7389, 3.7239, 3.6794],\n",
      "        [3.5633, 3.5520, 3.7390, 3.7176, 3.7274],\n",
      "        [3.7108, 3.8026, 3.7659, 3.7985, 3.7688],\n",
      "        [3.4834, 3.4816, 3.6299, 3.6354, 3.5527],\n",
      "        [3.5793, 3.5112, 3.6124, 3.7681, 3.5527],\n",
      "        [3.6307, 3.7459, 3.6776, 3.7153, 3.7044],\n",
      "        [3.4701, 3.8315, 3.8246, 3.7115, 3.8450],\n",
      "        [3.4663, 3.4542, 3.6118, 3.6143, 3.5219],\n",
      "        [3.4385, 3.6063, 3.6828, 3.6003, 3.5710],\n",
      "        [3.8082, 3.7936, 3.9161, 3.8137, 3.6181]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5437, 3.6284, 3.7180, 3.7656, 3.6684],\n",
      "        [3.7133, 3.7398, 3.7133, 3.8496, 3.7944],\n",
      "        [3.5817, 3.7263, 3.7147, 3.7349, 3.7338],\n",
      "        [4.0829, 4.1686, 3.9950, 3.9979, 3.9385],\n",
      "        [4.0415, 4.0912, 3.7930, 3.9390, 3.7737],\n",
      "        [3.5879, 3.5991, 3.7382, 3.7319, 3.6897],\n",
      "        [3.8849, 3.6808, 3.8138, 4.1952, 3.9881],\n",
      "        [3.3692, 3.4872, 3.5409, 3.4810, 3.5092],\n",
      "        [3.4663, 3.4359, 3.5969, 3.6241, 3.5078],\n",
      "        [3.9783, 3.8845, 3.9290, 4.1011, 4.0033],\n",
      "        [3.8070, 3.7939, 3.9141, 3.8148, 3.6204],\n",
      "        [3.3973, 3.5158, 3.5553, 3.5172, 3.5309],\n",
      "        [3.4701, 3.6495, 3.8044, 3.6496, 3.6920],\n",
      "        [3.6393, 3.6169, 3.7401, 3.7794, 3.7007],\n",
      "        [3.5741, 3.5289, 3.7324, 3.6758, 3.6408],\n",
      "        [3.5749, 3.5782, 3.7270, 3.7152, 3.6588],\n",
      "        [3.4556, 3.4196, 3.5830, 3.6065, 3.4992],\n",
      "        [3.8601, 3.8046, 3.7764, 3.9253, 3.9054],\n",
      "        [3.9535, 3.9814, 3.9780, 4.1800, 3.9821],\n",
      "        [3.5917, 3.4867, 3.6753, 3.5957, 3.5602],\n",
      "        [3.8315, 3.9386, 4.0110, 3.9382, 3.7117],\n",
      "        [3.7609, 3.8154, 3.8995, 3.9949, 3.7775],\n",
      "        [3.5801, 3.6480, 3.7431, 3.8922, 3.6255],\n",
      "        [3.4406, 3.4917, 3.5916, 3.5787, 3.5432],\n",
      "        [3.6083, 3.7354, 3.6691, 3.8778, 3.6356],\n",
      "        [3.6835, 3.6985, 3.7651, 3.9086, 3.7210],\n",
      "        [3.5712, 3.5952, 3.7310, 3.7211, 3.6661],\n",
      "        [3.5917, 3.5437, 3.7477, 3.6509, 3.7030],\n",
      "        [3.6929, 3.7147, 3.7202, 3.7714, 3.7037],\n",
      "        [4.0016, 3.8140, 4.0062, 4.1506, 3.9715],\n",
      "        [3.4397, 3.5608, 3.6700, 3.6105, 3.5736],\n",
      "        [3.7825, 4.0028, 3.9331, 4.0482, 3.9911],\n",
      "        [3.7284, 3.8414, 3.7798, 3.9751, 3.8406],\n",
      "        [3.6157, 3.7555, 3.7279, 3.7370, 3.7540],\n",
      "        [3.7091, 3.7853, 3.8901, 3.7743, 3.6494],\n",
      "        [3.7093, 3.7918, 3.8496, 3.8221, 3.6582],\n",
      "        [4.0760, 4.1644, 3.9163, 3.9707, 3.8330],\n",
      "        [3.4986, 3.4927, 3.7214, 3.6507, 3.6046],\n",
      "        [3.9168, 3.7164, 3.9362, 4.3371, 4.1940],\n",
      "        [3.4604, 3.4194, 3.5884, 3.6154, 3.4990],\n",
      "        [3.5995, 3.7816, 3.7692, 3.8689, 3.6706],\n",
      "        [3.7660, 3.7748, 3.8672, 3.8406, 3.9002],\n",
      "        [4.1622, 4.2431, 4.0403, 4.0766, 3.9770],\n",
      "        [3.7205, 3.7869, 3.7705, 3.8626, 3.7846],\n",
      "        [3.4928, 3.5810, 3.5713, 3.6191, 3.5822],\n",
      "        [3.8162, 3.7797, 3.9120, 3.9886, 3.8265],\n",
      "        [3.5454, 3.6242, 3.5912, 3.6720, 3.6356],\n",
      "        [3.5892, 3.5175, 3.7359, 3.7133, 3.7567],\n",
      "        [3.6907, 3.7935, 3.8276, 3.7941, 3.6418],\n",
      "        [3.6290, 3.5575, 3.7542, 3.7161, 3.7235],\n",
      "        [3.5756, 3.5386, 3.6363, 3.7628, 3.5813],\n",
      "        [3.8930, 3.7311, 3.9406, 4.0442, 3.8701],\n",
      "        [3.6420, 3.9570, 3.7920, 3.9379, 3.8711],\n",
      "        [3.6166, 3.7505, 3.7121, 3.6950, 3.7269],\n",
      "        [3.6471, 3.8855, 3.9384, 3.8997, 3.8973],\n",
      "        [3.7526, 3.8690, 3.7859, 3.8396, 3.8338],\n",
      "        [3.6836, 3.8006, 3.7407, 3.9279, 3.7846],\n",
      "        [3.6956, 3.6798, 3.8808, 3.8441, 3.7320],\n",
      "        [3.4958, 3.5597, 3.7081, 3.6718, 3.5604],\n",
      "        [3.6623, 3.6989, 3.6977, 3.7971, 3.7375],\n",
      "        [3.5039, 3.5483, 3.6924, 3.7028, 3.6242],\n",
      "        [3.8854, 3.7173, 3.9202, 4.0227, 3.8503],\n",
      "        [3.9996, 3.9375, 3.9349, 4.2077, 3.8618],\n",
      "        [3.6528, 3.8465, 3.8012, 3.8346, 3.8825]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4546, 3.5460, 3.6561, 3.6066, 3.5789],\n",
      "        [3.5788, 3.6039, 3.6524, 3.7237, 3.6328],\n",
      "        [3.5764, 3.5306, 3.6255, 3.7666, 3.5694],\n",
      "        [3.7036, 3.6368, 3.7960, 3.8001, 3.7022],\n",
      "        [3.4900, 3.5583, 3.6873, 3.5713, 3.7154],\n",
      "        [3.4845, 3.6212, 3.6191, 3.6315, 3.6479],\n",
      "        [3.5753, 3.5489, 3.6481, 3.7523, 3.5958],\n",
      "        [3.4601, 3.4705, 3.6160, 3.6093, 3.5329],\n",
      "        [3.5566, 3.6711, 3.7147, 3.7798, 3.7126],\n",
      "        [4.0670, 4.1721, 4.2152, 4.2668, 4.3679],\n",
      "        [3.4751, 3.6248, 3.6959, 3.7680, 3.5424],\n",
      "        [3.4393, 3.5416, 3.5642, 3.5611, 3.5536],\n",
      "        [3.7491, 3.6684, 3.8563, 3.8706, 3.7553],\n",
      "        [3.7522, 3.8693, 3.7840, 3.8402, 3.8359],\n",
      "        [3.6677, 3.6732, 3.7551, 3.7589, 3.7123],\n",
      "        [3.4587, 3.4987, 3.6418, 3.6271, 3.5533],\n",
      "        [3.8280, 3.8457, 3.9489, 3.9500, 3.8306],\n",
      "        [3.4260, 3.5737, 3.6638, 3.5957, 3.5599],\n",
      "        [3.5447, 3.5483, 3.7327, 3.7134, 3.7348],\n",
      "        [3.5615, 3.5591, 3.7163, 3.7002, 3.6541],\n",
      "        [3.7815, 3.6817, 3.7759, 3.7395, 3.6460],\n",
      "        [3.6092, 3.5844, 3.7863, 3.7542, 3.7241],\n",
      "        [3.5696, 3.6980, 3.6467, 3.8235, 3.6139],\n",
      "        [3.7279, 3.8415, 3.7778, 3.9756, 3.8426],\n",
      "        [3.5861, 3.7174, 3.7982, 3.7549, 3.6311],\n",
      "        [3.7064, 3.6367, 3.7380, 3.9234, 3.7833],\n",
      "        [3.7327, 3.5036, 3.6393, 3.7074, 3.7233],\n",
      "        [3.9989, 4.0072, 4.0277, 4.2233, 4.0195],\n",
      "        [3.5996, 3.6024, 3.7990, 3.6692, 3.8256],\n",
      "        [3.7887, 3.5537, 3.7997, 4.0035, 3.9719],\n",
      "        [3.5660, 3.5810, 3.7205, 3.7102, 3.6589],\n",
      "        [3.4588, 3.4776, 3.6228, 3.6182, 3.5395],\n",
      "        [3.7279, 3.8415, 3.7778, 3.9756, 3.8426],\n",
      "        [3.9014, 3.9811, 3.7812, 3.8493, 3.7988],\n",
      "        [3.4794, 3.5685, 3.5714, 3.6039, 3.5767],\n",
      "        [3.7590, 3.8657, 3.7873, 3.8432, 3.8459],\n",
      "        [4.0166, 4.1071, 3.9528, 3.9382, 3.9150],\n",
      "        [3.4770, 3.4463, 3.6027, 3.6411, 3.5393],\n",
      "        [3.7863, 3.6886, 3.7890, 3.7578, 3.6729],\n",
      "        [3.5016, 3.5947, 3.5872, 3.6224, 3.6173],\n",
      "        [3.6406, 3.5399, 3.7124, 3.7340, 3.6170],\n",
      "        [3.4587, 3.4545, 3.6038, 3.6139, 3.5219],\n",
      "        [3.7279, 3.8415, 3.7778, 3.9756, 3.8426],\n",
      "        [4.0277, 3.9754, 4.0175, 4.2508, 4.0502],\n",
      "        [3.6786, 3.6223, 3.7770, 3.6959, 3.6255],\n",
      "        [3.5950, 3.6108, 3.7974, 3.6665, 3.8227],\n",
      "        [3.8136, 3.6200, 3.7787, 4.1143, 3.9191],\n",
      "        [3.6441, 3.6232, 3.8264, 3.8092, 3.6883],\n",
      "        [3.5203, 3.4405, 3.7193, 3.4865, 3.6906],\n",
      "        [3.7676, 3.8898, 3.7706, 3.8054, 3.7974],\n",
      "        [3.4820, 3.6206, 3.7817, 3.6856, 3.7208],\n",
      "        [3.5942, 3.6711, 3.6898, 3.7899, 3.7244],\n",
      "        [3.5828, 3.7591, 3.7051, 3.6765, 3.7230],\n",
      "        [3.6165, 3.5844, 3.7373, 3.7174, 3.7076],\n",
      "        [3.5503, 3.6491, 3.5966, 3.7049, 3.6409],\n",
      "        [3.5816, 3.8525, 3.8550, 3.8256, 3.8857],\n",
      "        [3.6352, 3.5400, 3.6968, 3.6830, 3.7103],\n",
      "        [3.5167, 3.4212, 3.5659, 3.6232, 3.5053],\n",
      "        [3.5061, 3.7870, 3.7146, 3.6334, 3.5492],\n",
      "        [3.6580, 3.6916, 3.6717, 3.7821, 3.7151],\n",
      "        [3.6076, 3.5719, 3.7401, 3.7370, 3.7227],\n",
      "        [3.7332, 3.8238, 3.7905, 3.8698, 3.7955],\n",
      "        [3.5668, 3.6620, 3.7621, 3.8171, 3.6544],\n",
      "        [3.6999, 3.7753, 3.7636, 3.7932, 3.8770]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6643, 3.7769, 3.8767, 3.9111, 3.8175],\n",
      "        [3.7530, 3.7129, 3.9775, 3.8003, 3.6464],\n",
      "        [3.4701, 3.5931, 3.7135, 3.6562, 3.5947],\n",
      "        [3.7399, 3.5063, 3.6416, 3.6997, 3.7453],\n",
      "        [3.6279, 3.7469, 3.6720, 3.7170, 3.7105],\n",
      "        [3.5817, 3.6601, 3.5881, 3.7402, 3.6452],\n",
      "        [3.4637, 3.5867, 3.7066, 3.6494, 3.5878],\n",
      "        [3.9836, 3.8985, 3.8471, 4.0622, 4.0886],\n",
      "        [3.4170, 3.5863, 3.8100, 3.6002, 3.7286],\n",
      "        [3.4989, 3.6161, 3.7774, 3.7077, 3.7455],\n",
      "        [3.7175, 3.7170, 3.6611, 3.8525, 3.8350],\n",
      "        [3.4306, 3.5894, 3.6700, 3.6101, 3.5811],\n",
      "        [3.6357, 3.7364, 3.8288, 3.8662, 3.8068],\n",
      "        [3.4748, 3.6798, 3.8719, 3.6913, 3.7455],\n",
      "        [3.7547, 3.6014, 3.7348, 4.0714, 3.8616],\n",
      "        [3.6525, 3.7154, 3.7017, 3.7794, 3.7879],\n",
      "        [3.4270, 3.4622, 3.6018, 3.5717, 3.5004],\n",
      "        [3.7057, 3.9552, 3.9240, 3.8909, 3.9169],\n",
      "        [3.5837, 3.5115, 3.7290, 3.7107, 3.7533],\n",
      "        [3.8766, 3.7348, 3.8134, 3.8979, 3.9110],\n",
      "        [3.8210, 3.8415, 3.9276, 3.9380, 4.0642],\n",
      "        [3.5417, 3.4904, 3.6997, 3.6574, 3.6084],\n",
      "        [3.7579, 3.8862, 3.8902, 3.8911, 3.8030],\n",
      "        [3.5726, 3.6513, 3.5915, 3.7316, 3.6464],\n",
      "        [3.6426, 3.5551, 3.7414, 3.7354, 3.6693],\n",
      "        [3.5863, 3.6684, 3.7481, 3.8711, 3.6615],\n",
      "        [3.6142, 3.8119, 3.7026, 3.7746, 3.7223],\n",
      "        [3.5889, 3.5299, 3.7464, 3.7118, 3.7354],\n",
      "        [3.9677, 3.9423, 3.9666, 4.1647, 4.0099],\n",
      "        [3.5990, 3.6203, 3.7056, 3.8320, 3.7280],\n",
      "        [3.5001, 3.5998, 3.5811, 3.6357, 3.6043],\n",
      "        [3.6828, 3.8540, 3.9124, 3.8581, 3.7337],\n",
      "        [3.8622, 3.8162, 3.9542, 3.9731, 4.0360],\n",
      "        [4.2687, 4.3659, 4.0818, 4.1353, 4.0040],\n",
      "        [3.6855, 3.7917, 3.8208, 3.7931, 3.6429],\n",
      "        [3.7912, 3.7967, 3.9181, 3.8667, 3.8953],\n",
      "        [3.8124, 3.9252, 3.9945, 3.9424, 3.7458],\n",
      "        [3.6930, 3.6359, 3.7709, 3.7753, 3.6930],\n",
      "        [3.4578, 3.4246, 3.5821, 3.6106, 3.5053],\n",
      "        [3.5422, 3.6323, 3.5939, 3.6882, 3.6312],\n",
      "        [3.5960, 3.5920, 3.8106, 3.7458, 3.7271],\n",
      "        [3.5731, 3.5705, 3.7190, 3.7103, 3.6579],\n",
      "        [3.6156, 3.5688, 3.7780, 3.7250, 3.7175],\n",
      "        [3.8613, 3.7196, 3.8934, 3.9779, 3.8496],\n",
      "        [3.7665, 3.8898, 3.7686, 3.8056, 3.7988],\n",
      "        [3.5012, 3.6053, 3.5909, 3.6389, 3.6090],\n",
      "        [3.4453, 3.4910, 3.5876, 3.5889, 3.5543],\n",
      "        [3.5641, 3.9515, 3.8950, 3.7650, 3.7078],\n",
      "        [3.7693, 4.0250, 3.8761, 4.0258, 3.9732],\n",
      "        [3.6052, 3.5756, 3.7813, 3.7633, 3.7261],\n",
      "        [3.6731, 3.6059, 3.7712, 3.6810, 3.6467],\n",
      "        [3.5822, 3.5722, 3.7415, 3.7198, 3.6915],\n",
      "        [3.7352, 3.8058, 3.7849, 3.7961, 3.7660],\n",
      "        [3.6941, 3.6798, 3.8768, 3.8449, 3.7353],\n",
      "        [3.5314, 3.5987, 3.6051, 3.6711, 3.6373],\n",
      "        [4.1957, 4.3650, 4.0070, 4.1402, 3.9601],\n",
      "        [3.5338, 3.5260, 3.6957, 3.6477, 3.6178],\n",
      "        [3.5107, 3.8223, 3.7395, 3.7685, 3.7950],\n",
      "        [3.8564, 3.8095, 3.9204, 4.0214, 3.8687],\n",
      "        [3.8361, 3.7663, 3.9044, 4.1001, 3.8264],\n",
      "        [3.7837, 3.6131, 3.7511, 4.1216, 3.8924],\n",
      "        [3.6559, 3.9484, 3.7794, 3.9395, 3.8617],\n",
      "        [3.7165, 3.7849, 3.7588, 3.8632, 3.7793],\n",
      "        [3.7266, 3.8413, 3.7757, 3.9758, 3.8440]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8553, 3.8100, 3.9184, 4.0228, 3.8696],\n",
      "        [3.5676, 3.7711, 3.7840, 3.6555, 3.7650],\n",
      "        [3.9475, 3.8231, 3.9013, 4.1001, 3.9285],\n",
      "        [3.7345, 3.8179, 3.8696, 3.8189, 3.6553],\n",
      "        [3.8060, 3.9018, 3.8906, 3.7817, 3.8656],\n",
      "        [3.4435, 3.6390, 3.6897, 3.6281, 3.6051],\n",
      "        [3.5854, 3.6611, 3.7348, 3.7007, 3.5968],\n",
      "        [3.5614, 3.6442, 3.5907, 3.7144, 3.6471],\n",
      "        [3.9766, 4.0459, 3.7972, 3.9037, 3.8103],\n",
      "        [3.5976, 3.5741, 3.7683, 3.7452, 3.7092],\n",
      "        [3.6615, 3.8036, 3.7756, 3.7430, 3.7867],\n",
      "        [3.7888, 3.9115, 3.8659, 3.7643, 3.8569],\n",
      "        [3.7592, 3.8234, 3.9080, 3.8920, 3.9739],\n",
      "        [3.6600, 3.5602, 3.9675, 3.8119, 3.8060],\n",
      "        [3.6224, 3.7939, 3.8972, 3.9015, 3.7688],\n",
      "        [3.7391, 3.8170, 3.9115, 3.9019, 3.8651],\n",
      "        [3.9776, 3.8915, 3.8316, 4.0581, 4.0864],\n",
      "        [4.0148, 4.1074, 3.9485, 3.9401, 3.9173],\n",
      "        [3.5753, 3.5882, 3.7320, 3.7289, 3.6901],\n",
      "        [3.7342, 3.6354, 3.8295, 3.9829, 3.7259],\n",
      "        [4.1622, 4.2780, 4.0027, 4.0744, 3.9190],\n",
      "        [3.5648, 3.5661, 3.7091, 3.7058, 3.6635],\n",
      "        [3.3972, 3.5077, 3.4548, 3.5975, 3.4877],\n",
      "        [3.4300, 3.5475, 3.5681, 3.5540, 3.5707],\n",
      "        [3.4531, 3.5670, 3.5720, 3.5925, 3.5756],\n",
      "        [3.6020, 3.5755, 3.7598, 3.7191, 3.7126],\n",
      "        [3.8901, 3.7099, 3.7900, 3.9131, 3.8907],\n",
      "        [3.4664, 3.4919, 3.6454, 3.6237, 3.5258],\n",
      "        [3.5938, 3.6174, 3.7341, 3.7040, 3.8450],\n",
      "        [3.4401, 3.5547, 3.5662, 3.5669, 3.5655],\n",
      "        [3.4283, 3.5405, 3.6436, 3.5924, 3.5533],\n",
      "        [3.4600, 3.5688, 3.5699, 3.6003, 3.5815],\n",
      "        [3.4369, 3.5611, 3.6641, 3.6125, 3.5776],\n",
      "        [4.0797, 4.0404, 4.0594, 4.3468, 4.1203],\n",
      "        [3.6929, 3.5705, 3.9527, 3.8396, 3.8252],\n",
      "        [3.5635, 3.5813, 3.7163, 3.7117, 3.6611],\n",
      "        [3.8206, 3.7821, 3.8446, 3.8801, 3.8925],\n",
      "        [3.6066, 3.7182, 3.6145, 3.6936, 3.6680],\n",
      "        [3.5762, 3.6584, 3.6002, 3.7406, 3.6570],\n",
      "        [3.6816, 3.6185, 3.7436, 3.6781, 3.5440],\n",
      "        [3.6019, 3.5653, 3.7832, 3.7292, 3.7173],\n",
      "        [3.6660, 3.8433, 3.7758, 3.9206, 3.7951],\n",
      "        [3.5861, 3.5635, 3.7305, 3.7013, 3.6663],\n",
      "        [3.5440, 3.6102, 3.6145, 3.6838, 3.6543],\n",
      "        [3.5276, 3.4784, 3.6844, 3.6445, 3.5915],\n",
      "        [3.6708, 3.7958, 3.8146, 3.7894, 3.6390],\n",
      "        [3.6228, 3.5980, 3.7941, 3.7547, 3.7257],\n",
      "        [3.9416, 3.7275, 3.9380, 4.3624, 4.2050],\n",
      "        [3.7980, 3.8599, 3.9372, 3.8742, 3.7037],\n",
      "        [3.7501, 3.6637, 3.7654, 3.7164, 3.6319],\n",
      "        [3.5812, 3.6403, 3.6324, 3.7194, 3.6878],\n",
      "        [3.8096, 3.7891, 3.8985, 3.9338, 3.9974],\n",
      "        [3.7701, 3.8150, 3.8802, 3.8027, 3.8225],\n",
      "        [3.7595, 3.5270, 3.6345, 3.6903, 3.7709],\n",
      "        [3.5522, 3.5721, 3.6045, 3.6691, 3.7096],\n",
      "        [3.8884, 3.8071, 3.9722, 4.1296, 3.8243],\n",
      "        [3.5263, 3.4518, 3.7214, 3.5143, 3.6939],\n",
      "        [3.6037, 3.5500, 3.7751, 3.7639, 3.7775],\n",
      "        [3.9293, 3.8430, 3.8910, 4.0033, 3.9807],\n",
      "        [3.5161, 3.5623, 3.6990, 3.7032, 3.6421],\n",
      "        [3.7811, 3.8588, 3.7942, 3.9453, 4.0001],\n",
      "        [3.8457, 3.8871, 3.8901, 3.9377, 3.9571],\n",
      "        [3.6710, 3.6731, 3.8395, 3.8178, 3.7363],\n",
      "        [3.6206, 3.6815, 3.7433, 3.7608, 3.8089]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5655, 3.5000, 3.6656, 3.6811, 3.7505],\n",
      "        [3.5994, 3.5649, 3.7434, 3.7309, 3.7322],\n",
      "        [3.5531, 3.5072, 3.7096, 3.6732, 3.6168],\n",
      "        [3.6026, 3.6685, 3.7230, 3.7043, 3.7030],\n",
      "        [3.4031, 3.3920, 3.5566, 3.6243, 3.4966],\n",
      "        [3.7153, 3.7182, 3.6569, 3.8556, 3.8362],\n",
      "        [3.4556, 3.4937, 3.6254, 3.6134, 3.5486],\n",
      "        [3.5737, 3.6603, 3.5941, 3.7378, 3.6574],\n",
      "        [3.4323, 3.5744, 3.6605, 3.6132, 3.5808],\n",
      "        [3.7462, 3.8139, 3.8839, 3.9020, 3.7861],\n",
      "        [3.7178, 3.6501, 3.8096, 3.8311, 3.7275],\n",
      "        [3.6252, 3.5585, 3.7458, 3.7201, 3.7279],\n",
      "        [3.4641, 3.5434, 3.6710, 3.6329, 3.5606],\n",
      "        [3.4391, 3.5200, 3.6359, 3.6142, 3.5567],\n",
      "        [3.5593, 3.8595, 3.7840, 3.8233, 3.8653],\n",
      "        [3.7429, 3.8816, 3.8876, 3.8962, 3.8137],\n",
      "        [3.6784, 3.8297, 3.7882, 3.9321, 3.7939],\n",
      "        [3.6666, 3.6647, 3.7433, 3.7659, 3.6926],\n",
      "        [3.4751, 3.4841, 3.5072, 3.6612, 3.4831],\n",
      "        [3.5678, 3.5364, 3.7162, 3.6950, 3.6340],\n",
      "        [3.7790, 3.5467, 3.7827, 4.0041, 3.9738],\n",
      "        [3.4894, 3.5999, 3.7432, 3.6802, 3.5898],\n",
      "        [3.9606, 3.8860, 3.8253, 4.0623, 4.0961],\n",
      "        [3.9763, 3.9875, 4.0177, 4.2076, 3.9888],\n",
      "        [3.4585, 3.4676, 3.6086, 3.6136, 3.5367],\n",
      "        [3.4608, 3.4498, 3.5954, 3.6254, 3.5233],\n",
      "        [3.4706, 3.6006, 3.5981, 3.6868, 3.5845],\n",
      "        [3.9473, 3.8638, 3.9597, 4.1264, 3.9442],\n",
      "        [4.0131, 4.1653, 3.8246, 3.9268, 3.7884],\n",
      "        [3.5141, 3.5807, 3.6150, 3.7274, 3.6310],\n",
      "        [3.9844, 3.9934, 3.9543, 4.2523, 4.0533],\n",
      "        [3.4306, 3.6061, 3.6717, 3.6157, 3.5873],\n",
      "        [3.4901, 3.5920, 3.5695, 3.6277, 3.5991],\n",
      "        [4.2768, 4.3744, 4.0824, 4.1518, 4.0050],\n",
      "        [3.5769, 3.5646, 3.7186, 3.7014, 3.6652],\n",
      "        [3.4933, 3.5950, 3.5798, 3.6175, 3.6105],\n",
      "        [3.5935, 3.5932, 3.8062, 3.7490, 3.7283],\n",
      "        [3.8985, 3.9825, 3.7751, 3.8526, 3.8015],\n",
      "        [3.5013, 3.6568, 3.7261, 3.8110, 3.5934],\n",
      "        [3.7084, 3.7961, 3.8409, 3.8298, 3.6678],\n",
      "        [3.5801, 3.5258, 3.7397, 3.7274, 3.7571],\n",
      "        [3.6965, 3.8877, 3.8857, 3.8646, 3.7697],\n",
      "        [3.4245, 3.4634, 3.5978, 3.5746, 3.5017],\n",
      "        [3.9488, 3.8238, 3.9006, 4.0964, 3.9309],\n",
      "        [3.7204, 3.8429, 3.8524, 3.9732, 3.7988],\n",
      "        [3.5734, 3.6629, 3.7040, 3.7682, 3.7814],\n",
      "        [3.4587, 3.5696, 3.5678, 3.6018, 3.5819],\n",
      "        [3.4923, 3.7117, 3.6019, 3.4767, 3.6306],\n",
      "        [3.5374, 3.5419, 3.6535, 3.7293, 3.5905],\n",
      "        [3.3961, 3.5085, 3.4527, 3.5990, 3.4882],\n",
      "        [3.7421, 3.7450, 3.6813, 3.8824, 3.8515],\n",
      "        [3.6114, 3.5507, 3.7781, 3.7725, 3.7814],\n",
      "        [3.6824, 3.4755, 3.8703, 3.8016, 3.7273],\n",
      "        [3.5311, 3.5273, 3.6914, 3.6507, 3.6189],\n",
      "        [3.5550, 3.6379, 3.5755, 3.7162, 3.6261],\n",
      "        [3.6879, 3.6127, 3.8867, 3.8666, 3.7383],\n",
      "        [3.5578, 3.5621, 3.6992, 3.6942, 3.6505],\n",
      "        [3.3856, 3.4994, 3.4539, 3.6106, 3.4851],\n",
      "        [4.0685, 3.7581, 3.9861, 4.4091, 4.2891],\n",
      "        [3.7348, 3.8443, 3.8437, 3.8976, 3.8018],\n",
      "        [3.4067, 3.4825, 3.4922, 3.6147, 3.4809],\n",
      "        [3.4734, 3.4480, 3.5966, 3.6353, 3.5365],\n",
      "        [3.5100, 3.6046, 3.5729, 3.6466, 3.6093],\n",
      "        [3.4899, 3.6553, 3.6834, 3.5662, 3.5737]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.9157, 3.8225, 3.8522, 3.9913, 3.9517],\n",
      "        [3.4949, 3.5879, 3.6129, 3.6477, 3.6191],\n",
      "        [3.3591, 3.4825, 3.5216, 3.4807, 3.5012],\n",
      "        [3.5546, 3.8747, 3.7687, 3.8412, 3.8416],\n",
      "        [3.7018, 3.9570, 3.9174, 3.8953, 3.9184],\n",
      "        [3.6991, 3.7188, 3.8635, 3.7953, 3.6364],\n",
      "        [3.6191, 3.8086, 3.8041, 3.9078, 3.6906],\n",
      "        [3.7198, 3.8902, 3.9076, 3.8949, 3.7868],\n",
      "        [3.4994, 3.5972, 3.5718, 3.6383, 3.6126],\n",
      "        [3.8137, 3.5583, 3.7971, 4.0544, 4.0042],\n",
      "        [3.4852, 3.5075, 3.5230, 3.6897, 3.5605],\n",
      "        [3.9708, 3.7552, 3.9716, 4.4022, 4.2385],\n",
      "        [3.8468, 3.8513, 3.9240, 3.9625, 4.0950],\n",
      "        [3.5776, 3.7573, 3.7511, 3.6777, 3.7561],\n",
      "        [3.6778, 3.8024, 3.7302, 3.9328, 3.7893],\n",
      "        [3.4805, 3.5398, 3.6792, 3.6733, 3.5503],\n",
      "        [3.6728, 3.6163, 3.7686, 3.6947, 3.6438],\n",
      "        [3.7226, 3.9289, 3.8068, 3.8793, 3.8151],\n",
      "        [3.5707, 3.5964, 3.7237, 3.7299, 3.6831],\n",
      "        [3.7225, 3.8432, 3.7691, 3.9801, 3.8455],\n",
      "        [3.5800, 3.5132, 3.7225, 3.7150, 3.7547],\n",
      "        [3.9103, 3.7849, 3.8987, 3.9843, 3.9403],\n",
      "        [3.4505, 3.5682, 3.5678, 3.5950, 3.5762],\n",
      "        [3.5933, 3.6042, 3.8159, 3.7653, 3.7310],\n",
      "        [3.5117, 3.6067, 3.5794, 3.6432, 3.6261],\n",
      "        [4.0127, 4.1089, 3.9440, 3.9429, 3.9179],\n",
      "        [3.5475, 3.6922, 3.7355, 3.7118, 3.7254],\n",
      "        [3.4363, 3.6396, 3.6884, 3.6226, 3.6136],\n",
      "        [3.4746, 3.5699, 3.5634, 3.6081, 3.5795],\n",
      "        [3.5508, 3.6788, 3.8596, 3.6897, 3.6961],\n",
      "        [3.5117, 3.6086, 3.5671, 3.6670, 3.6034],\n",
      "        [3.8771, 3.7827, 3.8174, 3.9265, 3.8801],\n",
      "        [3.5008, 3.7896, 3.7064, 3.6372, 3.5520],\n",
      "        [3.8555, 3.9541, 3.7617, 3.8355, 3.7983],\n",
      "        [3.5796, 3.7222, 3.7040, 3.7567, 3.7476],\n",
      "        [3.7225, 3.8432, 3.7691, 3.9801, 3.8455],\n",
      "        [4.2758, 4.3750, 4.0801, 4.1530, 4.0052],\n",
      "        [3.6045, 3.5860, 3.7778, 3.7589, 3.7268],\n",
      "        [3.5650, 3.7726, 3.7795, 3.6580, 3.7655],\n",
      "        [3.4709, 3.5707, 3.7146, 3.6676, 3.5586],\n",
      "        [3.9994, 3.9177, 3.9121, 4.1012, 4.0621],\n",
      "        [3.4565, 3.5647, 3.6948, 3.6484, 3.5811],\n",
      "        [3.8185, 3.7834, 3.8402, 3.8832, 3.8935],\n",
      "        [3.6644, 3.6567, 3.6869, 3.8404, 3.7391],\n",
      "        [3.9416, 3.8586, 3.9499, 4.1200, 3.9383],\n",
      "        [3.9624, 3.8756, 3.8221, 4.0421, 4.0767],\n",
      "        [3.7923, 3.7074, 3.8536, 3.9233, 3.7819],\n",
      "        [3.4798, 3.6225, 3.6106, 3.6356, 3.6506],\n",
      "        [3.7203, 3.4907, 3.6221, 3.7109, 3.7166],\n",
      "        [3.6376, 3.5498, 3.7025, 3.6987, 3.7235],\n",
      "        [3.7015, 3.6381, 3.7294, 3.9282, 3.7861],\n",
      "        [3.5764, 3.6703, 3.5968, 3.7482, 3.6673],\n",
      "        [3.5666, 3.7163, 3.7535, 3.7430, 3.6891],\n",
      "        [3.8114, 3.7818, 3.9020, 3.9938, 3.8316],\n",
      "        [3.4974, 3.6069, 3.5847, 3.6428, 3.6105],\n",
      "        [3.6166, 3.6042, 3.7248, 3.7478, 3.7039],\n",
      "        [3.8586, 3.5425, 3.7980, 4.1123, 4.0381],\n",
      "        [3.5262, 3.6429, 3.7422, 3.7504, 3.6055],\n",
      "        [3.6879, 3.9276, 3.8252, 3.8611, 3.8253],\n",
      "        [3.4348, 3.5480, 3.5645, 3.5700, 3.5828],\n",
      "        [3.6119, 3.5704, 3.7715, 3.7293, 3.7189],\n",
      "        [3.5007, 3.4998, 3.7169, 3.6638, 3.6085],\n",
      "        [3.7628, 3.8922, 3.7623, 3.8096, 3.8003],\n",
      "        [3.5619, 3.5464, 3.6487, 3.6484, 3.6956]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6045, 3.7553, 3.7149, 3.7297, 3.7600],\n",
      "        [3.5590, 3.6472, 3.5850, 3.7281, 3.6437],\n",
      "        [3.5685, 3.6500, 3.5889, 3.7173, 3.6612],\n",
      "        [3.7236, 3.8434, 3.7669, 3.9823, 3.8454],\n",
      "        [3.6229, 3.6785, 3.7339, 3.8110, 3.7847],\n",
      "        [3.6478, 3.7567, 3.7068, 3.8095, 3.7332],\n",
      "        [3.4850, 3.5571, 3.7029, 3.7296, 3.6586],\n",
      "        [3.6647, 3.9184, 3.8444, 3.8714, 3.9052],\n",
      "        [3.4559, 3.5512, 3.6715, 3.6429, 3.5597],\n",
      "        [3.4551, 3.5071, 3.5897, 3.6099, 3.5607],\n",
      "        [3.4624, 3.5078, 3.6370, 3.6316, 3.5685],\n",
      "        [3.5941, 3.6059, 3.7227, 3.6191, 3.4961],\n",
      "        [3.3741, 3.4974, 3.5353, 3.4937, 3.5243],\n",
      "        [3.5395, 3.6316, 3.7061, 3.7723, 3.6736],\n",
      "        [3.5686, 3.5017, 3.6747, 3.6231, 3.5817],\n",
      "        [3.5780, 3.5999, 3.6519, 3.7712, 3.6566],\n",
      "        [3.3480, 3.4798, 3.5934, 3.5461, 3.5564],\n",
      "        [3.5005, 3.5973, 3.5698, 3.6404, 3.6125],\n",
      "        [3.4387, 3.5560, 3.5600, 3.5714, 3.5661],\n",
      "        [3.6027, 3.6690, 3.7187, 3.7075, 3.7031],\n",
      "        [3.4207, 3.5552, 3.6453, 3.5988, 3.5547],\n",
      "        [3.5696, 3.5037, 3.6669, 3.6872, 3.7560],\n",
      "        [3.5839, 3.5693, 3.6769, 3.6798, 3.7194],\n",
      "        [3.6081, 3.5634, 3.7628, 3.7384, 3.6701],\n",
      "        [3.8059, 3.8799, 3.9309, 3.9505, 4.0274],\n",
      "        [3.7177, 3.8311, 3.8730, 3.8980, 3.8323],\n",
      "        [3.6261, 3.7750, 3.7496, 3.8326, 3.6955],\n",
      "        [3.5128, 3.6088, 3.5651, 3.6691, 3.6033],\n",
      "        [3.5576, 3.5610, 3.7057, 3.7068, 3.6567],\n",
      "        [3.4615, 3.4520, 3.5912, 3.6269, 3.5240],\n",
      "        [3.6253, 3.5591, 3.7415, 3.7234, 3.7279],\n",
      "        [3.8401, 3.7550, 3.9172, 4.0776, 3.7591],\n",
      "        [3.6117, 3.7578, 3.7153, 3.7438, 3.7587],\n",
      "        [3.9354, 3.9754, 3.9522, 4.0155, 4.0598],\n",
      "        [3.7136, 3.7106, 3.7842, 3.7706, 3.5582],\n",
      "        [3.5697, 3.5948, 3.6238, 3.6882, 3.7260],\n",
      "        [4.0441, 3.9290, 3.9739, 4.2455, 4.1011],\n",
      "        [3.8202, 3.7982, 3.8538, 3.9692, 3.9860],\n",
      "        [3.5999, 3.6679, 3.7220, 3.8471, 3.7025],\n",
      "        [3.7493, 3.6652, 3.7590, 3.7219, 3.6328],\n",
      "        [3.4555, 3.5677, 3.5624, 3.5915, 3.5735],\n",
      "        [4.0177, 4.0870, 3.9021, 3.9405, 3.8444],\n",
      "        [3.7119, 3.7905, 3.7516, 3.8058, 3.8734],\n",
      "        [3.6858, 3.7183, 3.7638, 3.9347, 3.7326],\n",
      "        [3.9698, 3.8834, 3.9029, 4.0566, 3.9948],\n",
      "        [3.5883, 3.6784, 3.6032, 3.7685, 3.6703],\n",
      "        [3.4236, 3.5566, 3.6414, 3.5995, 3.5580],\n",
      "        [3.8781, 3.7105, 3.9058, 4.0224, 3.8520],\n",
      "        [3.8662, 3.7337, 3.7924, 3.8954, 3.9134],\n",
      "        [3.5409, 3.6316, 3.5739, 3.7071, 3.6245],\n",
      "        [3.7240, 3.8418, 3.7676, 3.9775, 3.8441],\n",
      "        [3.5165, 3.4545, 3.5855, 3.6376, 3.5291],\n",
      "        [3.6896, 3.6460, 3.7842, 3.7266, 3.6323],\n",
      "        [3.6215, 3.6039, 3.7867, 3.7490, 3.7315],\n",
      "        [3.9502, 3.8660, 3.9533, 4.1237, 3.9470],\n",
      "        [3.6252, 3.6740, 3.7333, 3.7381, 3.7099],\n",
      "        [3.9792, 3.7926, 3.9716, 4.1437, 3.9981],\n",
      "        [3.6400, 3.5570, 3.7328, 3.7421, 3.6707],\n",
      "        [3.7160, 3.6866, 3.7966, 3.7652, 3.6179],\n",
      "        [3.5390, 3.5159, 3.6805, 3.6457, 3.6056],\n",
      "        [3.7367, 3.8257, 3.8758, 3.8987, 3.8126],\n",
      "        [3.4891, 3.6005, 3.7390, 3.6833, 3.5899],\n",
      "        [3.4406, 3.5474, 3.6524, 3.6193, 3.5751],\n",
      "        [3.8982, 3.9515, 3.9279, 3.9894, 4.0204]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7306, 3.7455, 3.8805, 3.8103, 3.6231],\n",
      "        [3.9006, 3.9835, 3.7687, 3.8583, 3.8031],\n",
      "        [3.5627, 3.5069, 3.7305, 3.5891, 3.7115],\n",
      "        [4.0421, 4.0929, 3.7787, 3.9491, 3.7800],\n",
      "        [3.7700, 3.6177, 3.7334, 4.0913, 3.8771],\n",
      "        [3.5808, 3.6471, 3.7225, 3.9004, 3.6487],\n",
      "        [3.5427, 3.7933, 3.8400, 3.7052, 3.9169],\n",
      "        [3.3300, 3.4727, 3.5844, 3.5275, 3.5335],\n",
      "        [3.4990, 3.6016, 3.5707, 3.6440, 3.6072],\n",
      "        [3.7360, 3.9161, 3.7953, 3.7099, 3.8123],\n",
      "        [3.4272, 3.5961, 3.6569, 3.6048, 3.5730],\n",
      "        [3.4880, 3.5608, 3.6748, 3.5797, 3.7195],\n",
      "        [3.7101, 3.7969, 3.8343, 3.8356, 3.6694],\n",
      "        [3.7307, 3.7926, 3.9210, 3.9226, 3.9131],\n",
      "        [3.9308, 3.6653, 3.8108, 4.2783, 4.0440],\n",
      "        [3.3830, 3.5075, 3.5365, 3.5060, 3.5260],\n",
      "        [3.4541, 3.5093, 3.6458, 3.6311, 3.5350],\n",
      "        [3.4891, 3.5763, 3.7221, 3.7440, 3.6816],\n",
      "        [3.7208, 3.8477, 3.8483, 3.9830, 3.8088],\n",
      "        [3.4954, 3.6012, 3.5727, 3.6415, 3.6092],\n",
      "        [3.7436, 3.7511, 3.9036, 3.8306, 3.6672],\n",
      "        [3.8620, 3.8111, 3.9095, 4.0351, 3.8834],\n",
      "        [3.6188, 3.7537, 3.6832, 3.7072, 3.7260],\n",
      "        [4.0188, 4.1006, 3.9133, 3.9467, 3.8764],\n",
      "        [4.0168, 3.8952, 3.9421, 4.2038, 4.0428],\n",
      "        [3.4624, 3.4505, 3.5891, 3.6308, 3.5249],\n",
      "        [3.7331, 3.9098, 3.9012, 3.9338, 3.9446],\n",
      "        [3.6710, 3.5615, 3.9389, 3.8184, 3.8111],\n",
      "        [3.5973, 3.6835, 3.5899, 3.7749, 3.6687],\n",
      "        [3.5202, 3.6552, 3.6574, 3.7641, 3.6274],\n",
      "        [3.8062, 3.7974, 3.8509, 3.9546, 3.9877],\n",
      "        [3.6421, 3.6252, 3.8137, 3.8182, 3.6925],\n",
      "        [3.9572, 3.8663, 3.9408, 4.1262, 3.9536],\n",
      "        [3.3950, 3.5172, 3.5415, 3.5259, 3.5368],\n",
      "        [3.4101, 3.4900, 3.5043, 3.6312, 3.4750],\n",
      "        [3.6223, 3.5774, 3.7959, 3.8094, 3.8015],\n",
      "        [3.6493, 3.6342, 3.8304, 3.8008, 3.7542],\n",
      "        [3.4423, 3.5474, 3.6502, 3.6215, 3.5765],\n",
      "        [3.9463, 3.8611, 3.9366, 4.1190, 3.9512],\n",
      "        [3.5676, 3.5574, 3.7018, 3.7002, 3.6553],\n",
      "        [3.5609, 3.6288, 3.6604, 3.6800, 3.6748],\n",
      "        [3.6914, 3.6529, 3.7227, 3.9031, 3.7847],\n",
      "        [3.4488, 3.5634, 3.5645, 3.5819, 3.5833],\n",
      "        [3.4780, 3.5620, 3.5644, 3.6616, 3.5642],\n",
      "        [3.6880, 3.6777, 3.6012, 3.8321, 3.8159],\n",
      "        [3.7170, 3.6416, 3.8025, 3.9750, 3.7180],\n",
      "        [4.2069, 4.3293, 3.9944, 4.0930, 3.9780],\n",
      "        [3.9597, 3.8692, 3.9098, 4.1006, 3.9832],\n",
      "        [3.5263, 3.6161, 3.5689, 3.6693, 3.6197],\n",
      "        [3.4184, 3.5418, 3.5562, 3.5572, 3.5592],\n",
      "        [3.6417, 3.8189, 3.7636, 3.8240, 3.8643],\n",
      "        [3.8272, 3.8520, 3.9088, 3.9510, 4.0459],\n",
      "        [3.5892, 3.5455, 3.7330, 3.6603, 3.7087],\n",
      "        [3.8067, 3.9036, 3.8817, 3.7890, 3.8676],\n",
      "        [3.5655, 3.6358, 3.7692, 3.7558, 3.7477],\n",
      "        [3.6887, 3.7722, 3.8424, 3.9048, 3.8601],\n",
      "        [3.7124, 3.7885, 3.8746, 3.8360, 3.7821],\n",
      "        [3.9249, 4.0093, 3.8925, 4.0684, 4.1227],\n",
      "        [3.7231, 3.8401, 3.7585, 3.9751, 3.8353],\n",
      "        [3.4268, 3.5378, 3.6315, 3.6002, 3.5548],\n",
      "        [3.7852, 3.8995, 3.9457, 3.8750, 3.6479],\n",
      "        [3.6974, 3.7789, 3.7510, 3.8018, 3.8814],\n",
      "        [3.6549, 3.8889, 3.8718, 3.8407, 3.7265],\n",
      "        [3.7447, 3.8818, 3.9105, 3.9323, 3.8058]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5929, 3.6726, 3.6750, 3.8004, 3.7297],\n",
      "        [3.6605, 3.6661, 3.7367, 3.8586, 3.7240],\n",
      "        [3.4572, 3.4886, 3.6156, 3.6176, 3.5481],\n",
      "        [3.7261, 3.8433, 3.7623, 3.9867, 3.8481],\n",
      "        [3.5606, 3.6443, 3.7133, 3.7719, 3.7182],\n",
      "        [3.9375, 3.7841, 3.9561, 4.0975, 3.9263],\n",
      "        [3.7444, 3.7510, 3.9013, 3.8325, 3.6682],\n",
      "        [3.5071, 3.4387, 3.6457, 3.6535, 3.6583],\n",
      "        [3.5366, 3.6416, 3.7377, 3.7550, 3.6052],\n",
      "        [3.5847, 3.7211, 3.7838, 3.7652, 3.6370],\n",
      "        [3.4587, 3.4212, 3.5718, 3.6262, 3.5061],\n",
      "        [3.3530, 3.4654, 3.5125, 3.4695, 3.4883],\n",
      "        [3.8248, 3.8834, 3.8193, 3.9202, 3.9545],\n",
      "        [3.4576, 3.4561, 3.5891, 3.6241, 3.5271],\n",
      "        [3.7778, 4.0156, 3.8859, 3.8963, 4.1161],\n",
      "        [3.8017, 3.8261, 3.8980, 3.9515, 3.9927],\n",
      "        [3.7412, 3.8006, 3.7720, 3.7792, 3.7666],\n",
      "        [3.9609, 3.8676, 3.9342, 4.1275, 3.9660],\n",
      "        [3.8090, 3.6340, 3.7605, 4.1079, 3.9190],\n",
      "        [3.4269, 3.4268, 3.5751, 3.6017, 3.5358],\n",
      "        [3.4940, 3.5613, 3.6914, 3.6826, 3.5674],\n",
      "        [3.4632, 3.5683, 3.5586, 3.6027, 3.5811],\n",
      "        [3.4039, 3.5397, 3.5689, 3.5920, 3.5525],\n",
      "        [3.9761, 3.9471, 3.9244, 4.2192, 4.0367],\n",
      "        [3.7975, 3.9638, 3.8850, 4.0261, 3.9330],\n",
      "        [3.4369, 3.5213, 3.6278, 3.6066, 3.5526],\n",
      "        [4.0787, 3.9074, 4.0106, 4.2215, 4.0809],\n",
      "        [3.7128, 3.6713, 3.7894, 3.7551, 3.6218],\n",
      "        [3.5405, 3.5356, 3.6894, 3.6627, 3.6289],\n",
      "        [3.4268, 3.5808, 3.6504, 3.6082, 3.5679],\n",
      "        [3.8204, 3.7878, 3.8962, 3.9380, 4.0065],\n",
      "        [3.4848, 3.5111, 3.5085, 3.6765, 3.5442],\n",
      "        [3.7542, 3.7757, 3.8717, 3.9116, 3.7246],\n",
      "        [3.8320, 3.9408, 3.9526, 4.0136, 3.9665],\n",
      "        [3.5224, 3.6096, 3.5595, 3.6798, 3.6054],\n",
      "        [3.7261, 3.8217, 3.8413, 3.9699, 3.7923],\n",
      "        [3.8157, 3.7820, 3.8955, 4.0003, 3.8342],\n",
      "        [3.4970, 3.6910, 3.5696, 3.6971, 3.5607],\n",
      "        [3.4380, 3.6311, 3.6734, 3.6199, 3.6021],\n",
      "        [3.5081, 3.5420, 3.6799, 3.6971, 3.6517],\n",
      "        [3.7876, 3.5557, 3.7846, 4.0161, 3.9773],\n",
      "        [3.7014, 3.6397, 3.7408, 3.6682, 3.5702],\n",
      "        [3.4226, 3.5416, 3.5505, 3.5537, 3.5578],\n",
      "        [3.7377, 4.0118, 3.9174, 3.9531, 3.9919],\n",
      "        [3.5561, 3.5737, 3.8326, 3.5721, 3.8254],\n",
      "        [3.6877, 3.6314, 3.7686, 3.7035, 3.6546],\n",
      "        [3.8833, 3.8222, 3.9294, 4.0278, 3.7688],\n",
      "        [3.6241, 3.6037, 3.7822, 3.7534, 3.7341],\n",
      "        [3.6554, 3.5989, 3.8154, 3.8355, 3.7509],\n",
      "        [3.6813, 3.8025, 3.7235, 3.9394, 3.7918],\n",
      "        [3.5907, 3.6783, 3.5988, 3.7727, 3.6729],\n",
      "        [3.6558, 3.8364, 3.7731, 3.8403, 3.8812],\n",
      "        [3.5965, 3.5710, 3.7577, 3.7504, 3.7012],\n",
      "        [3.4614, 3.5919, 3.5983, 3.6949, 3.5829],\n",
      "        [3.6298, 3.5678, 3.7494, 3.7328, 3.7292],\n",
      "        [3.4398, 3.5554, 3.5564, 3.5802, 3.5705],\n",
      "        [3.5910, 3.6444, 3.6356, 3.7986, 3.6936],\n",
      "        [3.7143, 3.7908, 3.7472, 3.8101, 3.8758],\n",
      "        [3.7863, 3.9561, 3.8631, 4.0022, 3.9263],\n",
      "        [3.8050, 3.7957, 3.8971, 3.8265, 3.6271],\n",
      "        [3.5718, 3.7120, 3.7496, 3.7520, 3.6855],\n",
      "        [3.5397, 3.5679, 3.6291, 3.6271, 3.6506],\n",
      "        [3.6250, 3.6061, 3.7860, 3.7891, 3.7409],\n",
      "        [3.5643, 3.5707, 3.7075, 3.7245, 3.6714]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.9343, 3.7256, 3.9193, 4.3722, 4.2023],\n",
      "        [3.7438, 3.8506, 3.8518, 3.9249, 3.8108],\n",
      "        [3.9600, 3.8688, 3.9187, 4.1149, 3.9789],\n",
      "        [3.4320, 3.6517, 3.5158, 3.6921, 3.5335],\n",
      "        [3.4289, 3.6270, 3.6653, 3.6127, 3.5903],\n",
      "        [3.7555, 3.6027, 3.7196, 4.0857, 3.8662],\n",
      "        [3.7032, 3.7184, 3.8547, 3.8040, 3.6392],\n",
      "        [3.8096, 3.6335, 3.7583, 4.1103, 3.9196],\n",
      "        [3.5541, 3.6442, 3.5804, 3.7183, 3.6473],\n",
      "        [3.9334, 3.7715, 3.9417, 4.0962, 3.9116],\n",
      "        [3.5035, 3.5967, 3.5633, 3.6464, 3.6155],\n",
      "        [3.6720, 3.7988, 3.8866, 3.9481, 3.8335],\n",
      "        [3.5965, 3.5931, 3.7951, 3.7591, 3.7312],\n",
      "        [3.5726, 3.6526, 3.5766, 3.7440, 3.6509],\n",
      "        [3.7547, 3.8903, 3.7724, 3.7177, 3.7200],\n",
      "        [3.7276, 3.8385, 3.7520, 3.9783, 3.8344],\n",
      "        [3.3957, 3.4275, 3.5386, 3.5271, 3.5098],\n",
      "        [3.5558, 3.6397, 3.5815, 3.7182, 3.6507],\n",
      "        [3.5877, 3.5646, 3.7174, 3.7129, 3.6698],\n",
      "        [3.5941, 3.6614, 3.7149, 3.8666, 3.6822],\n",
      "        [3.4008, 3.5253, 3.5456, 3.5380, 3.5464],\n",
      "        [3.4907, 3.5423, 3.5646, 3.6671, 3.5673],\n",
      "        [3.5178, 3.5524, 3.6460, 3.6220, 3.6276],\n",
      "        [3.5873, 3.9132, 3.7394, 3.9196, 3.8293],\n",
      "        [3.6258, 3.7858, 3.7526, 3.8575, 3.6851],\n",
      "        [3.9029, 3.8508, 3.8704, 4.1678, 3.9405],\n",
      "        [3.4359, 3.4878, 3.6074, 3.6051, 3.5390],\n",
      "        [3.7062, 3.9566, 3.9084, 3.9041, 3.9213],\n",
      "        [3.3965, 3.5165, 3.5372, 3.5296, 3.5383],\n",
      "        [3.5632, 3.6274, 3.6076, 3.7105, 3.6697],\n",
      "        [3.7159, 3.8375, 3.8181, 3.9303, 3.9477],\n",
      "        [3.8625, 3.8159, 3.9117, 4.0474, 3.8821],\n",
      "        [3.5726, 3.6526, 3.5766, 3.7440, 3.6509],\n",
      "        [3.5749, 3.7043, 3.7449, 3.7419, 3.7105],\n",
      "        [3.6299, 3.6070, 3.7772, 3.7577, 3.7467],\n",
      "        [3.8187, 4.0233, 3.8777, 4.0051, 4.0522],\n",
      "        [3.8603, 3.9022, 3.9033, 3.9426, 3.9396],\n",
      "        [3.4396, 3.4925, 3.5732, 3.5912, 3.5507],\n",
      "        [3.5003, 3.5428, 3.6713, 3.7051, 3.6309],\n",
      "        [4.0790, 4.2338, 3.8634, 3.9836, 3.8844],\n",
      "        [3.4231, 3.5411, 3.5483, 3.5556, 3.5583],\n",
      "        [3.5136, 3.6091, 3.5650, 3.6634, 3.6138],\n",
      "        [3.4465, 3.4940, 3.6110, 3.6125, 3.5488],\n",
      "        [3.4865, 3.5594, 3.5638, 3.6682, 3.5777],\n",
      "        [3.7394, 3.8751, 3.7959, 3.8737, 3.8173],\n",
      "        [3.7830, 3.6889, 3.8460, 4.0084, 3.6968],\n",
      "        [3.5809, 3.8542, 3.8372, 3.8388, 3.8921],\n",
      "        [3.4803, 3.4877, 3.5018, 3.6725, 3.5077],\n",
      "        [3.6566, 3.7065, 3.7682, 3.7732, 3.8484],\n",
      "        [3.5823, 3.5665, 3.7690, 3.7574, 3.7010],\n",
      "        [3.7043, 3.8910, 3.9380, 3.9044, 3.7646],\n",
      "        [3.6426, 3.6207, 3.8088, 3.8051, 3.7538],\n",
      "        [3.8312, 3.9376, 3.7958, 3.7850, 3.7550],\n",
      "        [3.7148, 3.7389, 3.8826, 3.8087, 3.6904],\n",
      "        [3.5292, 3.6371, 3.7341, 3.7671, 3.6097],\n",
      "        [3.6054, 3.9186, 3.7865, 3.9029, 3.8688],\n",
      "        [3.3557, 3.4730, 3.5118, 3.4739, 3.4937],\n",
      "        [3.5659, 3.5507, 3.7006, 3.7090, 3.6574],\n",
      "        [3.4496, 3.5605, 3.5607, 3.5813, 3.5783],\n",
      "        [3.5275, 3.5654, 3.6501, 3.6379, 3.6325],\n",
      "        [3.6690, 3.6561, 3.6781, 3.8493, 3.7422],\n",
      "        [3.4508, 3.6587, 3.6950, 3.6448, 3.6296],\n",
      "        [3.5753, 3.9355, 3.8837, 3.7909, 3.7114],\n",
      "        [3.4453, 3.6396, 3.6767, 3.6385, 3.6084]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4619, 3.4669, 3.5957, 3.6244, 3.5402],\n",
      "        [3.6102, 3.6589, 3.7047, 3.7091, 3.7057],\n",
      "        [3.7745, 3.5992, 3.7335, 3.7930, 3.7615],\n",
      "        [3.5765, 3.6596, 3.5811, 3.7488, 3.6607],\n",
      "        [3.7120, 3.7956, 3.8274, 3.8415, 3.6714],\n",
      "        [3.5558, 3.5718, 3.8094, 3.5991, 3.8086],\n",
      "        [3.6928, 3.7146, 3.6985, 3.7867, 3.7115],\n",
      "        [3.5602, 3.6360, 3.6494, 3.6849, 3.6679],\n",
      "        [3.5048, 3.6346, 3.6105, 3.7124, 3.5745],\n",
      "        [3.7025, 3.6385, 3.7364, 3.6721, 3.5711],\n",
      "        [3.5027, 3.5505, 3.6425, 3.6202, 3.6052],\n",
      "        [3.3749, 3.5736, 3.4467, 3.6194, 3.4698],\n",
      "        [3.4686, 3.6506, 3.7822, 3.6643, 3.6994],\n",
      "        [3.9463, 3.8598, 3.9373, 4.1254, 3.9447],\n",
      "        [3.9382, 3.7852, 3.9509, 4.1067, 3.9247],\n",
      "        [3.7452, 3.8753, 3.7615, 3.8525, 3.8331],\n",
      "        [3.6029, 3.7562, 3.7031, 3.7017, 3.7437],\n",
      "        [3.4542, 3.5053, 3.6182, 3.6213, 3.5655],\n",
      "        [3.8648, 3.8228, 3.9156, 4.0428, 3.8887],\n",
      "        [3.6614, 3.6649, 3.7322, 3.8624, 3.7248],\n",
      "        [3.5965, 3.6215, 3.7172, 3.7168, 3.8495],\n",
      "        [3.5601, 3.7851, 3.7930, 3.6726, 3.7583],\n",
      "        [3.8622, 3.9499, 3.7515, 3.8480, 3.8008],\n",
      "        [3.9427, 3.8111, 3.8854, 4.0237, 3.9495],\n",
      "        [3.3915, 3.5059, 3.5313, 3.5206, 3.5356],\n",
      "        [3.9678, 3.8746, 3.8109, 4.0529, 4.0799],\n",
      "        [3.6313, 3.5274, 3.6975, 3.7333, 3.6201],\n",
      "        [3.6292, 3.6791, 3.7294, 3.7509, 3.8148],\n",
      "        [3.5450, 3.4698, 3.6064, 3.6414, 3.7301],\n",
      "        [3.7267, 3.8420, 3.7577, 3.9905, 3.8488],\n",
      "        [3.8355, 3.8973, 3.9854, 4.1290, 4.1783],\n",
      "        [3.6565, 3.8556, 3.7351, 3.6449, 3.7846],\n",
      "        [3.4241, 3.5537, 3.6365, 3.6062, 3.5577],\n",
      "        [3.8282, 3.9369, 3.9433, 4.0102, 3.9639],\n",
      "        [3.6111, 3.8241, 3.8244, 3.8613, 3.9011],\n",
      "        [3.6121, 3.5705, 3.7780, 3.7782, 3.7536],\n",
      "        [3.5006, 3.6002, 3.5641, 3.6493, 3.6089],\n",
      "        [3.4587, 3.4253, 3.5651, 3.6243, 3.5102],\n",
      "        [3.4092, 3.4442, 3.5831, 3.5773, 3.4821],\n",
      "        [3.5610, 3.5616, 3.6860, 3.7056, 3.6539],\n",
      "        [3.8569, 3.8753, 3.9743, 3.9297, 3.7429],\n",
      "        [3.5582, 3.6357, 3.5745, 3.7053, 3.6532],\n",
      "        [3.6116, 3.8996, 3.7636, 3.8874, 3.8443],\n",
      "        [3.4578, 3.6642, 3.6927, 3.6488, 3.6405],\n",
      "        [3.5826, 3.5658, 3.7668, 3.7591, 3.7012],\n",
      "        [3.4343, 3.5360, 3.6304, 3.6092, 3.5568],\n",
      "        [3.4710, 3.5933, 3.6961, 3.6695, 3.5990],\n",
      "        [3.5977, 3.6588, 3.7206, 3.7125, 3.5928],\n",
      "        [3.9703, 3.9432, 3.9489, 4.1805, 4.0150],\n",
      "        [3.6095, 3.8236, 3.7774, 3.7724, 3.6034],\n",
      "        [3.9067, 3.7470, 3.8178, 3.9549, 3.9324],\n",
      "        [3.6188, 3.6055, 3.8114, 3.9082, 3.9128],\n",
      "        [3.5883, 3.5677, 3.6679, 3.6878, 3.7231],\n",
      "        [3.5100, 3.6748, 3.5734, 3.7350, 3.5741],\n",
      "        [3.6070, 3.6674, 3.7096, 3.7155, 3.7068],\n",
      "        [3.4449, 3.6574, 3.8046, 3.6330, 3.6729],\n",
      "        [3.5913, 3.6771, 3.5943, 3.7764, 3.6736],\n",
      "        [3.3511, 3.4731, 3.5121, 3.4744, 3.4953],\n",
      "        [3.6646, 3.6762, 3.8061, 3.8046, 3.7428],\n",
      "        [3.4407, 3.5542, 3.5520, 3.5837, 3.5712],\n",
      "        [3.3560, 3.4722, 3.5097, 3.4753, 3.4939],\n",
      "        [3.5620, 3.6458, 3.5762, 3.7359, 3.6470],\n",
      "        [3.5562, 3.5065, 3.6966, 3.6850, 3.6201],\n",
      "        [3.5760, 3.5515, 3.6969, 3.7083, 3.6595]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3839, 3.4992, 3.4341, 3.6034, 3.4871],\n",
      "        [3.6010, 3.5688, 3.7221, 3.7265, 3.7172],\n",
      "        [3.8174, 3.9424, 3.9630, 3.9299, 3.7032],\n",
      "        [3.5156, 3.4374, 3.5560, 3.6437, 3.5162],\n",
      "        [3.5898, 3.5298, 3.7267, 3.7280, 3.7409],\n",
      "        [3.5626, 3.6620, 3.7415, 3.8311, 3.6419],\n",
      "        [4.0047, 3.8139, 3.9833, 4.1691, 3.9813],\n",
      "        [3.6017, 3.5897, 3.7331, 3.7609, 3.7111],\n",
      "        [3.8478, 3.7889, 3.8324, 3.9232, 3.9061],\n",
      "        [3.5246, 3.8035, 3.7124, 3.6709, 3.5732],\n",
      "        [3.6966, 3.6275, 3.7659, 3.7987, 3.7063],\n",
      "        [3.5173, 3.5793, 3.5998, 3.7391, 3.6350],\n",
      "        [3.5692, 3.6302, 3.6050, 3.7086, 3.6789],\n",
      "        [3.7095, 3.7891, 3.8718, 3.8436, 3.7920],\n",
      "        [3.8282, 3.9361, 3.9409, 4.0114, 3.9645],\n",
      "        [3.4997, 3.6346, 3.6202, 3.6684, 3.6663],\n",
      "        [3.7611, 3.7476, 3.8823, 3.8420, 3.6758],\n",
      "        [3.7360, 3.6358, 3.8196, 3.9956, 3.7263],\n",
      "        [3.4983, 3.5571, 3.6463, 3.6128, 3.6065],\n",
      "        [3.7409, 3.8471, 3.8915, 3.8525, 3.7059],\n",
      "        [3.7335, 3.8160, 3.7616, 3.8371, 3.7740],\n",
      "        [3.4619, 3.5679, 3.5528, 3.6134, 3.5858],\n",
      "        [3.6496, 3.5633, 3.7081, 3.7222, 3.7394],\n",
      "        [3.6605, 3.7384, 3.7301, 3.8322, 3.7859],\n",
      "        [3.5853, 3.5112, 3.7091, 3.7266, 3.7589],\n",
      "        [3.4988, 3.5393, 3.6763, 3.7099, 3.6515],\n",
      "        [3.6251, 3.5964, 3.7861, 3.7968, 3.7419],\n",
      "        [3.5815, 3.6688, 3.5785, 3.7628, 3.6636],\n",
      "        [3.7920, 3.8433, 3.9028, 3.9328, 3.9982],\n",
      "        [3.6433, 3.9413, 3.7754, 3.9550, 3.8809],\n",
      "        [3.5596, 3.6381, 3.5694, 3.7211, 3.6504],\n",
      "        [3.6199, 3.5639, 3.7467, 3.7371, 3.7238],\n",
      "        [3.7605, 3.8253, 3.8901, 3.9063, 3.9786],\n",
      "        [3.7248, 3.8793, 3.7675, 3.8302, 3.8135],\n",
      "        [3.9421, 3.8261, 3.9076, 4.1070, 3.9667],\n",
      "        [3.5848, 3.7448, 3.7211, 3.6957, 3.7496],\n",
      "        [3.6946, 3.9032, 3.8804, 3.8957, 3.9759],\n",
      "        [3.6933, 3.6506, 3.7135, 3.9102, 3.7874],\n",
      "        [3.5801, 3.5633, 3.7031, 3.7141, 3.6693],\n",
      "        [3.4543, 3.5455, 3.6346, 3.6213, 3.5855],\n",
      "        [3.5610, 3.6703, 3.7528, 3.7823, 3.6532],\n",
      "        [3.8011, 3.8590, 3.9188, 3.8893, 3.7090],\n",
      "        [3.5553, 3.5884, 3.6133, 3.6435, 3.6419],\n",
      "        [3.6684, 3.6725, 3.7329, 3.7750, 3.7193],\n",
      "        [3.6450, 3.6372, 3.7175, 3.8256, 3.7125],\n",
      "        [3.5814, 3.7273, 3.6913, 3.7505, 3.7428],\n",
      "        [3.6943, 3.6931, 3.7522, 3.7562, 3.5375],\n",
      "        [3.4579, 3.5660, 3.5525, 3.6051, 3.5796],\n",
      "        [3.5609, 3.5523, 3.7131, 3.7352, 3.7383],\n",
      "        [3.6377, 3.5375, 3.6715, 3.6939, 3.7175],\n",
      "        [3.5804, 3.6685, 3.5836, 3.7593, 3.6712],\n",
      "        [3.4421, 3.5538, 3.5491, 3.5798, 3.5699],\n",
      "        [3.5741, 3.5013, 3.6557, 3.6963, 3.7605],\n",
      "        [3.4288, 3.5938, 3.6480, 3.6110, 3.5753],\n",
      "        [3.5572, 3.5707, 3.5876, 3.6816, 3.7124],\n",
      "        [3.3847, 3.5052, 3.5279, 3.5121, 3.5283],\n",
      "        [3.9371, 3.7299, 3.9230, 4.3800, 4.2120],\n",
      "        [3.4024, 3.3827, 3.5478, 3.6218, 3.5074],\n",
      "        [3.6135, 3.8109, 3.7661, 3.7631, 3.6032],\n",
      "        [3.5576, 3.5688, 3.6894, 3.7154, 3.6574],\n",
      "        [3.7713, 3.7461, 3.8150, 3.8637, 3.9258],\n",
      "        [3.7451, 3.7490, 3.8945, 3.8375, 3.6694],\n",
      "        [3.9987, 3.9407, 3.9118, 4.2252, 3.8726],\n",
      "        [3.8840, 3.8494, 3.9137, 4.0681, 3.8596]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7266, 3.6985, 3.7883, 3.7824, 3.6110],\n",
      "        [3.5697, 3.7698, 3.7632, 3.6702, 3.7695],\n",
      "        [3.8432, 3.7534, 3.9042, 4.0887, 3.7636],\n",
      "        [3.6827, 3.6179, 3.7610, 3.6963, 3.6778],\n",
      "        [3.4684, 3.4903, 3.6257, 3.6378, 3.5305],\n",
      "        [3.4377, 3.5259, 3.6254, 3.6130, 3.5583],\n",
      "        [3.6279, 3.8065, 3.6843, 3.7950, 3.7395],\n",
      "        [3.9401, 4.0075, 3.7630, 3.8841, 3.8065],\n",
      "        [3.4929, 3.5688, 3.6928, 3.6880, 3.5728],\n",
      "        [3.6941, 3.5696, 3.9320, 3.8552, 3.8299],\n",
      "        [3.5705, 3.5479, 3.6948, 3.7078, 3.6555],\n",
      "        [3.5089, 3.6529, 3.6983, 3.8193, 3.5819],\n",
      "        [3.5875, 3.8826, 3.7714, 3.8781, 3.8722],\n",
      "        [3.4275, 3.4609, 3.5804, 3.5873, 3.5061],\n",
      "        [3.6907, 3.9149, 3.8035, 3.8830, 3.8293],\n",
      "        [3.7854, 3.8987, 3.7328, 3.8123, 3.7943],\n",
      "        [3.5667, 3.6329, 3.7576, 3.7639, 3.7502],\n",
      "        [3.7940, 3.6116, 3.7243, 3.8079, 3.7974],\n",
      "        [3.5579, 3.6340, 3.5699, 3.7075, 3.6542],\n",
      "        [3.4354, 3.5719, 3.6428, 3.6258, 3.5850],\n",
      "        [3.5435, 3.7907, 3.8282, 3.7133, 3.9196],\n",
      "        [3.5822, 3.7594, 3.6810, 3.6929, 3.7301],\n",
      "        [3.5984, 3.6442, 3.6374, 3.7981, 3.6930],\n",
      "        [3.6493, 3.8411, 3.7707, 3.8476, 3.8868],\n",
      "        [3.7268, 3.8387, 3.7535, 3.9881, 3.8485],\n",
      "        [3.7507, 3.8715, 3.7605, 3.8573, 3.8435],\n",
      "        [3.4407, 3.6366, 3.6729, 3.6341, 3.6175],\n",
      "        [3.7918, 3.7957, 3.8947, 3.8845, 3.9008],\n",
      "        [3.7183, 3.6398, 3.7919, 3.9835, 3.7209],\n",
      "        [3.9269, 4.0064, 3.8806, 4.0770, 4.1254],\n",
      "        [3.8904, 3.8864, 3.8351, 3.9756, 3.9960],\n",
      "        [3.5136, 3.5262, 3.6873, 3.7065, 3.7209],\n",
      "        [3.9417, 3.8685, 3.9426, 4.1650, 3.9798],\n",
      "        [3.9786, 3.8155, 3.9602, 4.1888, 4.0290],\n",
      "        [4.0262, 3.9138, 3.9554, 4.2013, 3.9400],\n",
      "        [3.6007, 3.5707, 3.7724, 3.7497, 3.7249],\n",
      "        [3.9454, 4.0607, 3.9066, 3.9110, 3.9026],\n",
      "        [3.9441, 3.9569, 4.0433, 4.2123, 4.2480],\n",
      "        [3.5840, 3.5855, 3.7931, 3.6484, 3.8360],\n",
      "        [3.5330, 3.5622, 3.6321, 3.6390, 3.6369],\n",
      "        [4.2161, 4.3375, 3.9872, 4.1108, 3.9899],\n",
      "        [3.5481, 3.6891, 3.7154, 3.7236, 3.7139],\n",
      "        [3.4751, 3.4695, 3.5955, 3.6379, 3.5476],\n",
      "        [3.6561, 3.5960, 3.8061, 3.8420, 3.7527],\n",
      "        [3.5730, 3.4614, 3.6236, 3.5882, 3.5433],\n",
      "        [3.7377, 3.7091, 3.7975, 3.7894, 3.6217],\n",
      "        [3.4194, 3.5282, 3.5424, 3.5579, 3.5714],\n",
      "        [3.7733, 3.7468, 3.8150, 3.8676, 3.9298],\n",
      "        [3.8203, 3.9382, 3.9676, 3.9245, 3.7174],\n",
      "        [3.5688, 3.5889, 3.7039, 3.7361, 3.6730],\n",
      "        [3.5103, 3.4432, 3.5671, 3.6451, 3.5249],\n",
      "        [3.7264, 3.8403, 3.7528, 3.9929, 3.8498],\n",
      "        [3.4991, 3.6281, 3.5918, 3.7545, 3.5936],\n",
      "        [3.7264, 3.8403, 3.7528, 3.9929, 3.8498],\n",
      "        [3.5975, 3.5681, 3.7485, 3.7567, 3.7030],\n",
      "        [3.6660, 3.6827, 3.6663, 3.8326, 3.7475],\n",
      "        [3.5684, 3.6541, 3.5759, 3.7450, 3.6550],\n",
      "        [3.8108, 3.7817, 3.8689, 3.9625, 3.7564],\n",
      "        [3.5761, 3.5294, 3.6019, 3.7831, 3.5769],\n",
      "        [3.8363, 3.9010, 3.9876, 4.1284, 4.1874],\n",
      "        [3.5384, 3.6254, 3.7276, 3.7287, 3.8137],\n",
      "        [3.7863, 3.8708, 3.7844, 3.8738, 3.8941],\n",
      "        [3.7715, 3.7451, 3.8126, 3.8651, 3.9263],\n",
      "        [3.4932, 3.6235, 3.7627, 3.7073, 3.7325]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5718, 3.7096, 3.7383, 3.7589, 3.6871],\n",
      "        [3.9399, 3.7810, 3.9449, 4.1062, 3.9285],\n",
      "        [3.4171, 3.5315, 3.5373, 3.5581, 3.5580],\n",
      "        [3.6297, 3.9012, 3.8869, 3.8974, 3.9328],\n",
      "        [4.0786, 3.9051, 3.9990, 4.2297, 4.0829],\n",
      "        [3.7248, 3.8266, 3.8557, 3.9048, 3.8374],\n",
      "        [3.7919, 3.7876, 3.8736, 3.9521, 4.0052],\n",
      "        [3.7345, 3.6932, 3.8811, 3.8143, 3.5598],\n",
      "        [3.5742, 3.5789, 3.6944, 3.7301, 3.6693],\n",
      "        [3.4309, 3.4611, 3.5505, 3.5796, 3.5395],\n",
      "        [3.5663, 3.5009, 3.7169, 3.5995, 3.7142],\n",
      "        [3.8817, 3.7333, 3.7891, 3.9188, 3.9209],\n",
      "        [3.4914, 3.5469, 3.5584, 3.6711, 3.5689],\n",
      "        [3.5501, 3.4827, 3.7140, 3.5664, 3.7115],\n",
      "        [3.4401, 3.5495, 3.6287, 3.6232, 3.5833],\n",
      "        [3.5400, 3.5915, 3.5926, 3.6517, 3.6128],\n",
      "        [3.5059, 3.5434, 3.6609, 3.6968, 3.5737],\n",
      "        [3.4651, 3.5045, 3.6213, 3.6424, 3.5727],\n",
      "        [3.8897, 3.8863, 3.8327, 3.9767, 3.9959],\n",
      "        [3.5676, 3.6539, 3.5736, 3.7459, 3.6549],\n",
      "        [3.5554, 3.8003, 3.8101, 3.6614, 3.7930],\n",
      "        [3.5495, 3.6343, 3.5636, 3.7160, 3.6406],\n",
      "        [3.7372, 3.7088, 3.7952, 3.7904, 3.6215],\n",
      "        [3.6677, 3.6712, 3.7281, 3.7772, 3.7195],\n",
      "        [3.8320, 3.9376, 3.9407, 4.0212, 3.9679],\n",
      "        [3.7053, 3.7998, 3.8757, 3.8697, 3.7788],\n",
      "        [3.4933, 3.6520, 3.6629, 3.5801, 3.5780],\n",
      "        [3.7626, 3.7495, 4.0033, 3.7976, 3.6916],\n",
      "        [3.9962, 3.9140, 3.9310, 4.1283, 4.0552],\n",
      "        [3.4335, 3.5340, 3.6235, 3.6122, 3.5577],\n",
      "        [3.8217, 3.8299, 3.9063, 3.9598, 3.8219],\n",
      "        [3.8281, 3.7831, 3.8679, 4.0478, 4.0716],\n",
      "        [3.5656, 3.5783, 3.6051, 3.7538, 3.6275],\n",
      "        [3.5425, 3.7905, 3.8258, 3.7142, 3.9195],\n",
      "        [3.5167, 3.6031, 3.5540, 3.6671, 3.6224],\n",
      "        [3.5914, 3.7254, 3.7644, 3.7748, 3.6651],\n",
      "        [3.6038, 3.5737, 3.7372, 3.7357, 3.7173],\n",
      "        [4.0003, 4.0490, 4.0108, 4.2934, 4.1014],\n",
      "        [3.4295, 3.5386, 3.6216, 3.6074, 3.5579],\n",
      "        [3.7364, 3.8163, 3.8467, 3.8359, 3.6605],\n",
      "        [3.5642, 3.6489, 3.5652, 3.7504, 3.6517],\n",
      "        [3.4475, 3.6510, 3.6772, 3.6468, 3.6292],\n",
      "        [3.5643, 3.5757, 3.8332, 3.5850, 3.8330],\n",
      "        [4.0565, 4.0867, 3.7816, 3.9598, 3.7897],\n",
      "        [3.5644, 3.5888, 3.7012, 3.7406, 3.6792],\n",
      "        [3.4256, 3.5277, 3.5414, 3.5626, 3.5534],\n",
      "        [3.5898, 3.4850, 3.6469, 3.6149, 3.5682],\n",
      "        [4.2720, 4.3648, 4.0557, 4.1547, 4.0100],\n",
      "        [3.6050, 3.5485, 3.7525, 3.7810, 3.7821],\n",
      "        [3.9453, 3.8585, 3.9304, 4.1292, 3.9456],\n",
      "        [3.4661, 3.5725, 3.5535, 3.6099, 3.5936],\n",
      "        [3.6147, 3.7511, 3.6839, 3.7129, 3.7359],\n",
      "        [3.5157, 3.6103, 3.6394, 3.5739, 3.6183],\n",
      "        [3.5631, 3.5842, 3.6972, 3.7351, 3.6716],\n",
      "        [3.5690, 3.7696, 3.7608, 3.6711, 3.7693],\n",
      "        [3.8884, 3.8937, 3.8404, 3.9845, 3.9947],\n",
      "        [4.0121, 4.0261, 3.9987, 4.2658, 4.0736],\n",
      "        [3.5751, 3.5496, 3.6900, 3.7117, 3.6603],\n",
      "        [3.5687, 3.5413, 3.6921, 3.7119, 3.6460],\n",
      "        [3.5617, 3.6613, 3.7371, 3.8334, 3.6420],\n",
      "        [3.5399, 3.5393, 3.6336, 3.7433, 3.5950],\n",
      "        [3.5888, 3.5680, 3.7217, 3.6892, 3.6626],\n",
      "        [3.4797, 3.4850, 3.4928, 3.6771, 3.5089],\n",
      "        [3.4982, 3.6153, 3.7524, 3.7255, 3.7507]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.9936, 4.0327, 4.0048, 4.2762, 4.0895],\n",
      "        [3.4403, 3.5169, 3.6137, 3.6312, 3.5614],\n",
      "        [3.6237, 3.8043, 3.7667, 3.9244, 3.7019],\n",
      "        [3.5687, 3.4965, 3.6430, 3.6992, 3.7559],\n",
      "        [3.8872, 3.8933, 3.8380, 3.9882, 3.9952],\n",
      "        [3.5991, 3.5671, 3.7149, 3.7322, 3.7179],\n",
      "        [3.5790, 3.6674, 3.5715, 3.7683, 3.6642],\n",
      "        [3.5726, 3.7080, 3.6699, 3.7736, 3.7419],\n",
      "        [3.7153, 3.8110, 3.7521, 3.8575, 3.7695],\n",
      "        [3.9759, 3.8848, 3.8982, 4.1250, 4.0136],\n",
      "        [3.5796, 3.5980, 3.7058, 3.7587, 3.6811],\n",
      "        [3.7121, 3.6675, 3.7753, 3.7661, 3.6240],\n",
      "        [3.6163, 3.5906, 3.7785, 3.7946, 3.7418],\n",
      "        [3.5171, 3.5773, 3.6772, 3.7498, 3.6446],\n",
      "        [3.5874, 3.5676, 3.7192, 3.6927, 3.6630],\n",
      "        [3.5985, 3.9203, 3.7331, 3.9255, 3.8513],\n",
      "        [3.7011, 3.7154, 3.8432, 3.8125, 3.6402],\n",
      "        [3.5079, 3.6725, 3.5643, 3.7416, 3.5761],\n",
      "        [3.9851, 3.8405, 4.0023, 4.1776, 3.9851],\n",
      "        [3.6533, 3.9500, 3.7524, 3.9610, 3.8678],\n",
      "        [3.9690, 3.9410, 3.9394, 4.1885, 4.0164],\n",
      "        [4.2450, 4.3388, 4.0223, 4.1446, 3.9796],\n",
      "        [3.4459, 3.6714, 3.8188, 3.7020, 3.7170],\n",
      "        [3.5555, 3.6410, 3.5601, 3.7404, 3.6404],\n",
      "        [3.7259, 3.7217, 3.8028, 3.8984, 3.9372],\n",
      "        [3.4980, 3.6329, 3.6130, 3.6740, 3.6671],\n",
      "        [3.5178, 3.4509, 3.5675, 3.6516, 3.5337],\n",
      "        [3.6684, 3.8002, 3.7501, 3.8743, 3.7417],\n",
      "        [3.4477, 3.7527, 3.6798, 3.5494, 3.7469],\n",
      "        [3.7097, 3.7864, 3.7334, 3.8151, 3.8776],\n",
      "        [3.4724, 3.5319, 3.6365, 3.5965, 3.5865],\n",
      "        [3.4757, 3.5347, 3.5300, 3.6883, 3.5713],\n",
      "        [3.5923, 3.6764, 3.5882, 3.7825, 3.6803],\n",
      "        [3.7749, 3.7375, 3.9172, 3.8779, 3.6205],\n",
      "        [3.6888, 3.9817, 3.8198, 3.9984, 3.9186],\n",
      "        [4.0082, 3.9065, 3.9197, 4.2314, 4.0662],\n",
      "        [3.5097, 3.4361, 3.6324, 3.6691, 3.6547],\n",
      "        [3.4286, 3.6339, 3.6648, 3.6232, 3.6022],\n",
      "        [3.6081, 3.6236, 3.7793, 3.7784, 3.8134],\n",
      "        [3.7391, 3.8151, 3.8863, 3.9223, 3.8698],\n",
      "        [3.9821, 3.8937, 3.8317, 4.0918, 4.0796],\n",
      "        [3.5711, 3.5497, 3.7426, 3.7571, 3.6945],\n",
      "        [3.8128, 3.8700, 3.9387, 3.9005, 3.7304],\n",
      "        [3.5083, 3.4426, 3.5624, 3.6493, 3.5252],\n",
      "        [3.6282, 3.6040, 3.7654, 3.7662, 3.7481],\n",
      "        [3.7286, 3.8044, 3.8320, 3.9826, 3.7823],\n",
      "        [3.8082, 3.7935, 3.8344, 3.9684, 3.9921],\n",
      "        [3.4281, 3.6080, 3.6496, 3.6185, 3.5850],\n",
      "        [3.6408, 3.9403, 3.7683, 3.9613, 3.8815],\n",
      "        [3.5648, 3.6468, 3.6983, 3.9130, 3.6185],\n",
      "        [3.4266, 3.5922, 3.6410, 3.6163, 3.5759],\n",
      "        [3.8851, 3.8141, 3.9504, 4.1486, 3.8270],\n",
      "        [3.7301, 3.8250, 3.7621, 3.8913, 3.8036],\n",
      "        [3.3947, 3.5133, 3.5260, 3.5372, 3.5399],\n",
      "        [3.9231, 3.8543, 3.9241, 4.1530, 3.9712],\n",
      "        [3.6098, 3.8291, 3.6846, 3.8991, 3.7724],\n",
      "        [3.6754, 3.6126, 3.7477, 3.7124, 3.6480],\n",
      "        [3.4512, 3.4820, 3.5956, 3.6224, 3.5474],\n",
      "        [3.5923, 3.6764, 3.5882, 3.7825, 3.6803],\n",
      "        [3.7179, 3.8159, 3.7341, 3.8130, 3.7847],\n",
      "        [3.5742, 3.5288, 3.5973, 3.7874, 3.5772],\n",
      "        [3.7219, 3.8373, 3.7467, 3.9960, 3.8465],\n",
      "        [3.4625, 3.5844, 3.6799, 3.6690, 3.5936],\n",
      "        [3.6976, 3.8860, 3.8631, 3.8831, 3.7740]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.9371, 3.7667, 3.8761, 4.3802, 4.1875],\n",
      "        [3.8323, 3.8198, 3.9518, 4.0810, 3.8188],\n",
      "        [3.5572, 3.5525, 3.7037, 3.7453, 3.7399],\n",
      "        [3.4643, 3.5057, 3.5125, 3.6817, 3.4815],\n",
      "        [3.8292, 3.9389, 3.9358, 4.0293, 3.9695],\n",
      "        [3.7345, 3.8437, 3.8183, 3.9205, 3.8079],\n",
      "        [3.5908, 3.7226, 3.7720, 3.7859, 3.6451],\n",
      "        [3.7242, 3.7236, 3.8005, 3.9032, 3.9383],\n",
      "        [3.3976, 3.5236, 3.5321, 3.5495, 3.5491],\n",
      "        [3.5785, 3.4957, 3.6524, 3.6372, 3.5818],\n",
      "        [3.5540, 3.6426, 3.5579, 3.7445, 3.6414],\n",
      "        [3.4358, 3.5458, 3.5425, 3.5896, 3.5883],\n",
      "        [3.8304, 3.9644, 3.9981, 3.9820, 3.7563],\n",
      "        [3.8064, 3.7927, 3.8712, 3.9595, 4.0039],\n",
      "        [3.5243, 3.5461, 3.5483, 3.6638, 3.6902],\n",
      "        [3.4779, 3.5788, 3.5456, 3.6369, 3.5925],\n",
      "        [3.7404, 3.8078, 3.8546, 3.9225, 3.7865],\n",
      "        [3.5367, 3.5738, 3.6267, 3.6493, 3.6466],\n",
      "        [3.6833, 3.7501, 3.7268, 3.8181, 3.8897],\n",
      "        [3.8222, 3.9233, 3.7348, 3.8424, 3.8000],\n",
      "        [3.5178, 3.6564, 3.6006, 3.7896, 3.6053],\n",
      "        [3.4553, 3.4246, 3.5538, 3.6350, 3.5126],\n",
      "        [3.7213, 3.8894, 3.8850, 3.9172, 3.7921],\n",
      "        [3.5602, 3.5518, 3.6739, 3.7111, 3.6543],\n",
      "        [3.8244, 3.9401, 3.9291, 4.0197, 3.9607],\n",
      "        [3.7449, 3.8845, 3.8595, 3.9184, 3.8187],\n",
      "        [3.9733, 4.0940, 4.1040, 4.2238, 4.2854],\n",
      "        [3.7556, 3.7047, 3.8326, 3.9627, 3.7167],\n",
      "        [3.8268, 3.9736, 3.8303, 4.0061, 4.1078],\n",
      "        [3.6897, 3.6506, 3.7040, 3.9202, 3.7892],\n",
      "        [3.5081, 3.8066, 3.7603, 3.7839, 3.8404],\n",
      "        [3.6249, 3.7752, 3.7301, 3.8526, 3.7011],\n",
      "        [3.5782, 3.5864, 3.7860, 3.6575, 3.8249],\n",
      "        [3.8041, 3.8698, 3.7839, 3.9043, 3.9366],\n",
      "        [3.7106, 3.9013, 3.7608, 3.7035, 3.8062],\n",
      "        [3.5823, 3.5172, 3.7062, 3.7402, 3.7654],\n",
      "        [3.7522, 3.7389, 3.7787, 3.9336, 3.9342],\n",
      "        [3.4132, 3.5865, 3.7807, 3.6259, 3.7358],\n",
      "        [3.9576, 3.8841, 3.7990, 4.0841, 4.1009],\n",
      "        [3.6996, 3.6378, 3.7250, 3.6833, 3.5737],\n",
      "        [3.8273, 3.9734, 3.8359, 4.0019, 4.1025],\n",
      "        [3.8246, 3.8063, 3.8883, 4.0412, 4.0727],\n",
      "        [3.5253, 3.5368, 3.6912, 3.7144, 3.6466],\n",
      "        [3.6252, 3.8076, 3.6729, 3.6136, 3.6840],\n",
      "        [3.6500, 3.6743, 3.7255, 3.7693, 3.7269],\n",
      "        [3.4515, 3.4196, 3.5508, 3.6316, 3.5096],\n",
      "        [3.7293, 3.8319, 3.7651, 3.8891, 3.8099],\n",
      "        [3.6474, 3.7976, 3.7758, 3.8067, 3.6299],\n",
      "        [3.7224, 3.8413, 3.7456, 4.0018, 3.8511],\n",
      "        [3.3951, 3.4130, 3.5446, 3.5465, 3.4701],\n",
      "        [3.7425, 3.5058, 3.6134, 3.7275, 3.7561],\n",
      "        [4.0431, 4.0910, 3.7606, 3.9667, 3.7847],\n",
      "        [3.6157, 3.6777, 3.7132, 3.8434, 3.7568],\n",
      "        [3.5864, 3.7120, 3.6199, 3.8796, 3.6314],\n",
      "        [3.5538, 3.5690, 3.6800, 3.7255, 3.6590],\n",
      "        [3.5260, 3.4779, 3.6581, 3.6686, 3.5973],\n",
      "        [3.4260, 3.6466, 3.6441, 3.6802, 3.7598],\n",
      "        [3.5782, 3.6474, 3.7056, 3.9180, 3.6531],\n",
      "        [3.5143, 3.5508, 3.6323, 3.6340, 3.6303],\n",
      "        [3.5905, 3.6614, 3.7018, 3.8800, 3.6849],\n",
      "        [3.6862, 3.6330, 3.7344, 3.6628, 3.5569],\n",
      "        [3.5050, 3.6550, 3.6919, 3.8286, 3.5834],\n",
      "        [3.3742, 3.4949, 3.5156, 3.5109, 3.5299],\n",
      "        [3.7773, 3.8765, 3.9301, 3.8731, 3.6310]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4846, 3.5073, 3.5002, 3.7131, 3.5670],\n",
      "        [3.3929, 3.5165, 3.5239, 3.5425, 3.5429],\n",
      "        [3.6001, 3.8059, 3.7484, 3.7710, 3.6021],\n",
      "        [3.5996, 3.5663, 3.7552, 3.7568, 3.7239],\n",
      "        [3.5158, 3.6158, 3.5512, 3.6963, 3.6168],\n",
      "        [3.5316, 3.6386, 3.5661, 3.7156, 3.6372],\n",
      "        [3.7467, 3.8310, 3.8560, 3.8570, 3.6759],\n",
      "        [3.7209, 3.8433, 3.7448, 4.0053, 3.8518],\n",
      "        [3.5776, 3.6416, 3.6050, 3.7460, 3.6945],\n",
      "        [3.6553, 3.5627, 3.9389, 3.8397, 3.8125],\n",
      "        [3.5630, 3.6191, 3.6848, 3.7467, 3.7840],\n",
      "        [3.9565, 3.9115, 3.8994, 4.2111, 3.8691],\n",
      "        [4.0758, 4.0463, 4.0310, 4.3789, 4.1290],\n",
      "        [3.3943, 3.4301, 3.5582, 3.5684, 3.4729],\n",
      "        [3.7686, 3.7328, 3.8454, 3.9457, 3.6595],\n",
      "        [3.5177, 3.6095, 3.5430, 3.6971, 3.6091],\n",
      "        [3.7016, 3.7004, 3.6191, 3.8693, 3.8188],\n",
      "        [3.7802, 3.9025, 3.7253, 3.8251, 3.7962],\n",
      "        [3.7384, 3.9028, 3.7967, 3.8979, 3.8347],\n",
      "        [3.5960, 3.5062, 3.6623, 3.6384, 3.5896],\n",
      "        [3.8857, 3.8898, 3.8273, 3.9885, 3.9982],\n",
      "        [3.4272, 3.5482, 3.5413, 3.5791, 3.5777],\n",
      "        [3.4625, 3.4635, 3.5812, 3.6445, 3.5386],\n",
      "        [3.8233, 3.7834, 3.8168, 3.9102, 3.9025],\n",
      "        [3.5839, 3.5716, 3.7210, 3.7561, 3.6987],\n",
      "        [3.6347, 3.6093, 3.8042, 3.9150, 3.9201],\n",
      "        [3.6001, 3.7315, 3.5894, 3.7199, 3.6792],\n",
      "        [3.7091, 3.9034, 3.7600, 3.7070, 3.8070],\n",
      "        [3.4702, 3.4399, 3.5669, 3.6530, 3.5276],\n",
      "        [3.4220, 3.5560, 3.6204, 3.6204, 3.5643],\n",
      "        [3.9390, 3.9606, 4.0351, 4.2260, 4.2500],\n",
      "        [3.8589, 3.8171, 3.8972, 4.0653, 3.8855],\n",
      "        [3.4492, 3.5455, 3.6478, 3.6574, 3.5591],\n",
      "        [3.7679, 3.7818, 3.8246, 3.9055, 3.9210],\n",
      "        [3.5880, 3.5897, 3.7767, 3.7729, 3.7298],\n",
      "        [3.5516, 3.8303, 3.8140, 3.8329, 3.8530],\n",
      "        [3.6334, 3.8875, 3.8969, 3.9212, 3.9110],\n",
      "        [3.6019, 3.5739, 3.7082, 3.7667, 3.7317],\n",
      "        [3.7038, 3.7941, 3.8152, 3.8529, 3.6696],\n",
      "        [3.6422, 3.6798, 3.7425, 3.7737, 3.8129],\n",
      "        [3.9728, 3.6982, 3.8679, 4.3494, 4.2045],\n",
      "        [3.4480, 3.6010, 3.6473, 3.6438, 3.6114],\n",
      "        [3.9542, 3.8797, 3.9415, 4.1594, 3.9699],\n",
      "        [3.4867, 3.5823, 3.5386, 3.6468, 3.5931],\n",
      "        [3.5128, 3.5640, 3.6713, 3.7307, 3.6487],\n",
      "        [3.5911, 3.5720, 3.6880, 3.7244, 3.7296],\n",
      "        [3.4508, 3.5088, 3.6270, 3.6498, 3.5399],\n",
      "        [3.7428, 3.7251, 3.7656, 3.9195, 3.9160],\n",
      "        [3.4720, 3.4487, 3.5716, 3.6603, 3.5432],\n",
      "        [3.7395, 3.7412, 3.8616, 3.8425, 3.6758],\n",
      "        [3.7645, 3.7401, 3.7687, 3.9406, 3.9237],\n",
      "        [3.5806, 3.6171, 3.6981, 3.7358, 3.8287],\n",
      "        [3.6842, 3.7184, 3.7421, 3.9576, 3.7391],\n",
      "        [3.5093, 3.5237, 3.6992, 3.7056, 3.6353],\n",
      "        [3.7506, 3.6649, 3.7380, 3.7456, 3.6409],\n",
      "        [3.6375, 3.6213, 3.7940, 3.8214, 3.7567],\n",
      "        [3.4449, 3.5606, 3.5465, 3.5962, 3.5818],\n",
      "        [3.9809, 3.9110, 3.9134, 4.1873, 3.8012],\n",
      "        [3.9216, 4.0282, 3.8969, 4.0969, 4.1460],\n",
      "        [3.7854, 3.6900, 3.7575, 3.7895, 3.6849],\n",
      "        [3.6050, 3.8257, 3.8117, 3.8767, 3.9055],\n",
      "        [3.7707, 3.8373, 3.8493, 3.8184, 3.8324],\n",
      "        [3.4765, 3.4837, 3.5947, 3.6649, 3.5662],\n",
      "        [3.4055, 3.4828, 3.4682, 3.6386, 3.4885]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5713, 3.5915, 3.6966, 3.7431, 3.6789],\n",
      "        [3.5606, 3.5054, 3.7109, 3.6138, 3.7160],\n",
      "        [3.8204, 3.8623, 3.8896, 3.9712, 4.0465],\n",
      "        [3.6666, 3.9151, 3.8264, 3.9005, 3.9182],\n",
      "        [3.6514, 3.8798, 3.7915, 3.8777, 3.9010],\n",
      "        [3.5531, 3.5237, 3.6646, 3.6724, 3.6125],\n",
      "        [3.5444, 3.4872, 3.7080, 3.5806, 3.7133],\n",
      "        [3.6239, 3.5599, 3.7193, 3.7493, 3.7348],\n",
      "        [3.9766, 3.9902, 3.9909, 4.2409, 3.9960],\n",
      "        [3.6777, 3.6124, 3.7446, 3.7174, 3.6859],\n",
      "        [3.5706, 3.5979, 3.7017, 3.7584, 3.6927],\n",
      "        [3.6247, 3.8123, 3.8747, 3.9240, 3.7767],\n",
      "        [3.7375, 3.8115, 3.8532, 3.9299, 3.7874],\n",
      "        [4.0344, 4.0850, 3.7530, 3.9573, 3.7895],\n",
      "        [3.6325, 3.8019, 3.7581, 3.8787, 3.7029],\n",
      "        [3.8378, 3.7621, 3.8997, 4.1098, 3.7675],\n",
      "        [3.6764, 3.6644, 3.7202, 3.8030, 3.6965],\n",
      "        [3.6871, 3.6746, 3.7266, 3.8145, 3.7145],\n",
      "        [3.7291, 3.8310, 3.8470, 3.8545, 3.6758],\n",
      "        [3.5401, 3.4720, 3.5935, 3.6591, 3.7337],\n",
      "        [3.4384, 3.5169, 3.6118, 3.6313, 3.5587],\n",
      "        [3.5617, 3.6584, 3.5674, 3.7602, 3.6571],\n",
      "        [3.4801, 3.5611, 3.5487, 3.6866, 3.5810],\n",
      "        [3.4961, 3.5385, 3.6422, 3.7262, 3.5688],\n",
      "        [3.4364, 3.6412, 3.6620, 3.6523, 3.6178],\n",
      "        [3.8591, 3.8263, 3.9024, 4.0627, 3.8920],\n",
      "        [3.5766, 3.6460, 3.6085, 3.7482, 3.6946],\n",
      "        [3.5058, 3.4340, 3.5431, 3.6541, 3.5117],\n",
      "        [3.9733, 3.8684, 3.9096, 4.0994, 4.0194],\n",
      "        [3.5915, 3.6850, 3.5700, 3.7981, 3.6734],\n",
      "        [3.6339, 3.5431, 3.6805, 3.7672, 3.6259],\n",
      "        [3.4386, 3.5017, 3.5990, 3.6280, 3.5519],\n",
      "        [3.7020, 3.7953, 3.7321, 3.8993, 3.7897],\n",
      "        [3.5694, 3.6624, 3.5680, 3.7663, 3.6637],\n",
      "        [3.9755, 3.9455, 3.9260, 4.2122, 3.9328],\n",
      "        [3.7555, 3.8203, 3.8643, 4.0304, 3.7898],\n",
      "        [3.8700, 3.8072, 3.9284, 4.1514, 3.8202],\n",
      "        [3.6665, 3.6191, 3.7142, 3.6934, 3.5383],\n",
      "        [3.3956, 3.5261, 3.5340, 3.5504, 3.5544],\n",
      "        [3.6370, 3.5595, 3.7062, 3.7460, 3.7380],\n",
      "        [3.7616, 3.9486, 3.8375, 4.0154, 3.9141],\n",
      "        [3.6498, 3.8589, 3.7217, 3.6635, 3.7882],\n",
      "        [3.5896, 3.5845, 3.7685, 3.7683, 3.7275],\n",
      "        [3.5112, 3.5656, 3.6705, 3.7342, 3.6488],\n",
      "        [3.5597, 3.5827, 3.5990, 3.7680, 3.6301],\n",
      "        [3.7323, 3.6530, 3.7098, 4.0473, 3.8665],\n",
      "        [3.5629, 3.5460, 3.6861, 3.7264, 3.6481],\n",
      "        [3.5967, 3.6719, 3.7011, 3.8747, 3.7094],\n",
      "        [3.8222, 3.7849, 3.8162, 3.9140, 3.9027],\n",
      "        [3.7491, 3.8929, 3.7569, 3.7377, 3.7237],\n",
      "        [3.7701, 3.7428, 3.9132, 3.8895, 3.6222],\n",
      "        [3.5382, 3.6380, 3.5568, 3.7150, 3.6429],\n",
      "        [3.9303, 3.7738, 3.9267, 4.1187, 3.9158],\n",
      "        [3.5685, 3.5467, 3.6986, 3.7212, 3.6518],\n",
      "        [3.8801, 3.8207, 3.9466, 4.1619, 3.8288],\n",
      "        [3.7192, 3.8449, 3.7439, 4.0090, 3.8519],\n",
      "        [3.7108, 3.8169, 3.7483, 3.8692, 3.7715],\n",
      "        [3.5597, 3.6303, 3.6000, 3.7275, 3.6788],\n",
      "        [3.6223, 3.8113, 3.6714, 3.6207, 3.6849],\n",
      "        [3.4523, 3.5061, 3.6252, 3.6559, 3.5380],\n",
      "        [3.9168, 3.8763, 3.9492, 4.1061, 3.9695],\n",
      "        [3.7370, 3.8882, 3.7423, 3.8351, 3.8108],\n",
      "        [3.6225, 3.4930, 3.7092, 3.9139, 3.6090],\n",
      "        [3.8124, 3.6169, 3.6410, 3.8060, 3.8268]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5789, 3.8081, 3.6479, 3.8798, 3.7481],\n",
      "        [3.5805, 3.5460, 3.7100, 3.6833, 3.7137],\n",
      "        [3.7174, 3.8461, 3.7429, 4.0127, 3.8516],\n",
      "        [3.6566, 3.6880, 3.6632, 3.8538, 3.7520],\n",
      "        [3.4282, 3.6100, 3.6459, 3.6353, 3.5840],\n",
      "        [3.5197, 3.6122, 3.5433, 3.7094, 3.6074],\n",
      "        [3.7787, 3.7618, 3.8267, 3.9548, 3.9663],\n",
      "        [3.8027, 3.7876, 3.8592, 3.9829, 3.7582],\n",
      "        [3.4948, 3.6647, 3.7011, 3.8458, 3.6004],\n",
      "        [3.5672, 3.5055, 3.6440, 3.7165, 3.7631],\n",
      "        [3.5615, 3.7756, 3.7535, 3.6897, 3.7713],\n",
      "        [3.3997, 3.4277, 3.5539, 3.5715, 3.4808],\n",
      "        [3.4212, 3.5728, 3.6304, 3.6373, 3.5787],\n",
      "        [3.9603, 3.8791, 3.7965, 4.0756, 4.0829],\n",
      "        [3.4237, 3.4661, 3.5436, 3.5964, 3.5418],\n",
      "        [3.5858, 3.6394, 3.6127, 3.8109, 3.6869],\n",
      "        [3.4719, 3.6720, 3.5388, 3.7197, 3.5628],\n",
      "        [3.8284, 3.8296, 3.9491, 4.0949, 3.8238],\n",
      "        [3.4909, 3.6335, 3.5824, 3.7728, 3.5961],\n",
      "        [3.4255, 3.6243, 3.6540, 3.6382, 3.5957],\n",
      "        [3.5980, 3.5803, 3.7496, 3.8001, 3.7337],\n",
      "        [3.3227, 3.4752, 3.5636, 3.5534, 3.5383],\n",
      "        [3.5368, 3.5292, 3.5997, 3.6544, 3.6886],\n",
      "        [3.4498, 3.5701, 3.5409, 3.6241, 3.5821],\n",
      "        [3.5090, 3.6538, 3.6981, 3.8308, 3.5992],\n",
      "        [3.5539, 3.7042, 3.7216, 3.7546, 3.7397],\n",
      "        [3.4305, 3.6330, 3.6548, 3.6433, 3.6060],\n",
      "        [3.4205, 3.5979, 3.6362, 3.6300, 3.5778],\n",
      "        [3.6309, 3.9673, 3.7561, 3.9765, 3.8823],\n",
      "        [3.7350, 3.9059, 3.7949, 3.9055, 3.8347],\n",
      "        [3.6852, 3.6550, 3.7015, 3.9306, 3.7900],\n",
      "        [3.4452, 3.4879, 3.5909, 3.6366, 3.5491],\n",
      "        [3.8428, 3.7936, 3.8211, 3.9453, 3.9097],\n",
      "        [4.0092, 3.9010, 3.9214, 4.2360, 4.0484],\n",
      "        [3.5770, 3.5761, 3.7099, 3.7558, 3.6996],\n",
      "        [3.5316, 3.7745, 3.6959, 3.7248, 3.6283],\n",
      "        [3.5192, 3.6807, 3.6673, 3.6200, 3.5999],\n",
      "        [3.5658, 3.4992, 3.6490, 3.7221, 3.7606],\n",
      "        [3.6045, 3.8165, 3.7543, 3.7845, 3.6050],\n",
      "        [3.5720, 3.6612, 3.5599, 3.7748, 3.6539],\n",
      "        [3.4577, 3.5100, 3.6142, 3.6601, 3.5750],\n",
      "        [3.7174, 3.8461, 3.7429, 4.0127, 3.8516],\n",
      "        [3.4987, 3.5976, 3.5398, 3.6685, 3.5990],\n",
      "        [3.9209, 3.8009, 3.8635, 4.0312, 3.9370],\n",
      "        [3.5952, 3.6130, 3.7990, 3.8040, 3.7406],\n",
      "        [3.5676, 3.5555, 3.6830, 3.7299, 3.6621],\n",
      "        [3.4460, 3.5479, 3.6461, 3.6640, 3.5590],\n",
      "        [3.6411, 3.8468, 3.7614, 3.8670, 3.8892],\n",
      "        [3.4517, 3.4238, 3.5537, 3.6508, 3.5099],\n",
      "        [3.6000, 3.5835, 3.7334, 3.7793, 3.7056],\n",
      "        [3.5927, 3.5087, 3.6606, 3.6454, 3.5893],\n",
      "        [3.7064, 3.6873, 3.8473, 3.8015, 3.5510],\n",
      "        [3.8150, 3.9544, 3.9577, 3.9565, 3.7202],\n",
      "        [3.4431, 3.4845, 3.5894, 3.6366, 3.5448],\n",
      "        [3.8057, 3.7790, 3.8566, 4.0255, 3.8380],\n",
      "        [3.9985, 3.7253, 3.8939, 4.3614, 4.2271],\n",
      "        [3.5815, 3.6208, 3.7146, 3.7884, 3.7092],\n",
      "        [3.4400, 3.6563, 3.6700, 3.6638, 3.6316],\n",
      "        [3.7832, 3.8016, 3.8847, 3.9045, 3.9029],\n",
      "        [3.4783, 3.6241, 3.5854, 3.6661, 3.6573],\n",
      "        [3.6985, 3.7031, 3.6173, 3.8764, 3.8187],\n",
      "        [3.4724, 3.4903, 3.4859, 3.6942, 3.5115],\n",
      "        [4.1231, 4.2619, 3.9064, 4.0629, 3.9175],\n",
      "        [4.0123, 4.0305, 4.0156, 4.2924, 4.0709]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5757, 3.5107, 3.6804, 3.7502, 3.7602],\n",
      "        [3.9765, 3.8990, 3.8384, 4.1124, 4.0707],\n",
      "        [3.3692, 3.4995, 3.5122, 3.5237, 3.5304],\n",
      "        [3.4270, 3.4695, 3.5782, 3.6150, 3.5338],\n",
      "        [3.7144, 3.8444, 3.7405, 4.0149, 3.8475],\n",
      "        [3.4411, 3.5637, 3.5437, 3.6061, 3.5813],\n",
      "        [3.5489, 3.6401, 3.5595, 3.7294, 3.6556],\n",
      "        [3.7603, 3.8246, 3.8488, 3.9261, 3.9909],\n",
      "        [3.7150, 3.8213, 3.7429, 3.8792, 3.7720],\n",
      "        [3.6741, 3.6663, 3.7183, 3.8101, 3.6957],\n",
      "        [3.7700, 3.9556, 3.8462, 4.0399, 3.9182],\n",
      "        [3.5294, 3.6777, 3.6023, 3.8313, 3.6127],\n",
      "        [3.5339, 3.6375, 3.6832, 3.8071, 3.6797],\n",
      "        [3.6864, 3.9073, 3.7332, 3.8793, 3.9616],\n",
      "        [3.5088, 3.5675, 3.6685, 3.7414, 3.6480],\n",
      "        [3.9345, 3.7335, 3.9064, 4.4061, 4.2118],\n",
      "        [3.4115, 3.5442, 3.5350, 3.5855, 3.5638],\n",
      "        [3.4365, 3.6428, 3.6593, 3.6633, 3.6113],\n",
      "        [3.9855, 3.9066, 3.8350, 4.1233, 4.0848],\n",
      "        [3.5190, 3.5539, 3.6663, 3.7123, 3.6574],\n",
      "        [3.9995, 4.0697, 3.7682, 3.9613, 3.8020],\n",
      "        [3.7835, 3.8129, 3.9002, 4.0590, 3.7956],\n",
      "        [3.4644, 3.5945, 3.7143, 3.7025, 3.5789],\n",
      "        [3.7258, 3.6447, 3.8077, 4.0233, 3.7279],\n",
      "        [3.5612, 3.5730, 3.6783, 3.7333, 3.6604],\n",
      "        [3.5920, 3.5787, 3.7378, 3.7834, 3.7154],\n",
      "        [3.3555, 3.4847, 3.4966, 3.5124, 3.5073],\n",
      "        [3.5754, 3.5197, 3.6874, 3.7493, 3.7636],\n",
      "        [3.5660, 3.6004, 3.6971, 3.7659, 3.6885],\n",
      "        [3.5134, 3.5875, 3.5771, 3.6475, 3.6018],\n",
      "        [3.8401, 3.5594, 3.7689, 4.1286, 4.0412],\n",
      "        [3.6609, 3.6595, 3.6605, 3.8757, 3.7453],\n",
      "        [3.9283, 3.7757, 3.9248, 4.1264, 3.9153],\n",
      "        [3.7240, 3.8176, 3.7444, 3.9108, 3.8018],\n",
      "        [4.0117, 4.0314, 4.0145, 4.2963, 4.0704],\n",
      "        [3.7171, 3.6528, 3.7306, 3.7244, 3.5984],\n",
      "        [3.7257, 3.5476, 3.5991, 3.7207, 3.7810],\n",
      "        [3.6168, 3.7626, 3.6588, 3.7490, 3.7252],\n",
      "        [3.4426, 3.5635, 3.5419, 3.6085, 3.5887],\n",
      "        [3.5782, 3.5960, 3.7722, 3.6866, 3.8235],\n",
      "        [3.6951, 3.6430, 3.7216, 3.6972, 3.5738],\n",
      "        [3.5638, 3.5708, 3.6806, 3.7314, 3.6611],\n",
      "        [3.6733, 3.8347, 3.7596, 3.9696, 3.8003],\n",
      "        [3.4862, 3.5685, 3.6809, 3.7532, 3.6690],\n",
      "        [3.4805, 3.5551, 3.6470, 3.7500, 3.6333],\n",
      "        [4.0296, 3.8735, 3.9438, 4.2253, 4.0316],\n",
      "        [3.5054, 3.5270, 3.6965, 3.7159, 3.6345],\n",
      "        [3.6261, 3.5351, 3.6521, 3.7059, 3.7090],\n",
      "        [3.5737, 3.6449, 3.6022, 3.7563, 3.6938],\n",
      "        [3.7129, 3.8354, 3.8488, 3.9326, 3.8388],\n",
      "        [3.5753, 3.7278, 3.6784, 3.7930, 3.7534],\n",
      "        [3.5186, 3.6191, 3.5473, 3.6986, 3.6238],\n",
      "        [3.7989, 3.8459, 3.8988, 3.9621, 4.0492],\n",
      "        [3.8585, 3.7869, 3.8681, 4.1419, 3.8177],\n",
      "        [3.5973, 3.5811, 3.7485, 3.8036, 3.7332],\n",
      "        [3.4497, 3.5034, 3.6076, 3.6652, 3.5620],\n",
      "        [3.9733, 3.8449, 3.9894, 4.2096, 3.9923],\n",
      "        [3.5353, 3.4779, 3.6644, 3.7185, 3.6813],\n",
      "        [3.6901, 3.7654, 3.7425, 3.8541, 3.8947],\n",
      "        [3.6038, 3.8174, 3.7532, 3.7881, 3.6044],\n",
      "        [3.3525, 3.4756, 3.4954, 3.5125, 3.5109],\n",
      "        [3.7152, 3.7280, 3.7898, 3.9129, 3.9352],\n",
      "        [3.7383, 3.8869, 3.7632, 3.8873, 3.8535],\n",
      "        [3.5669, 3.6642, 3.5660, 3.7732, 3.6630]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5948, 3.9239, 3.7673, 3.9342, 3.8714],\n",
      "        [3.9327, 3.7883, 3.9358, 4.1341, 3.9301],\n",
      "        [3.5230, 3.5320, 3.6612, 3.6902, 3.6231],\n",
      "        [3.7963, 3.7668, 3.8172, 3.9238, 3.9525],\n",
      "        [3.5047, 3.6148, 3.6294, 3.5972, 3.6129],\n",
      "        [3.5034, 3.5575, 3.4379, 3.7617, 3.4970],\n",
      "        [3.5655, 3.6572, 3.5518, 3.7723, 3.6466],\n",
      "        [3.7460, 3.8955, 3.7536, 3.7485, 3.7224],\n",
      "        [4.0717, 4.2396, 3.8446, 4.0154, 3.8867],\n",
      "        [3.4187, 3.5409, 3.6087, 3.6323, 3.5586],\n",
      "        [3.5046, 3.7464, 3.7050, 3.7870, 3.8098],\n",
      "        [3.7302, 3.8083, 3.7498, 3.8303, 3.7684],\n",
      "        [3.6884, 3.8223, 3.7128, 3.9833, 3.8075],\n",
      "        [3.7048, 3.7803, 3.7527, 3.8485, 3.8407],\n",
      "        [3.7135, 3.8450, 3.7391, 4.0185, 3.8467],\n",
      "        [3.4806, 3.7225, 3.6982, 3.7579, 3.8282],\n",
      "        [4.0054, 3.7840, 3.9996, 4.4778, 4.3024],\n",
      "        [3.3517, 3.4760, 3.4942, 3.5157, 3.5103],\n",
      "        [3.4257, 3.5107, 3.6009, 3.6356, 3.5490],\n",
      "        [3.8560, 3.6679, 3.7618, 4.2035, 3.9681],\n",
      "        [3.4372, 3.4980, 3.5925, 3.6414, 3.5511],\n",
      "        [3.6962, 3.7397, 3.7718, 3.9838, 3.7618],\n",
      "        [3.9897, 3.8886, 3.9546, 4.1555, 4.0720],\n",
      "        [3.7135, 3.8450, 3.7391, 4.0185, 3.8467],\n",
      "        [3.8742, 3.8085, 3.8113, 3.9758, 3.9197],\n",
      "        [3.3824, 3.4445, 3.5171, 3.5525, 3.5092],\n",
      "        [3.4409, 3.5663, 3.5419, 3.6137, 3.5872],\n",
      "        [3.7220, 3.8346, 3.7550, 3.9147, 3.8044],\n",
      "        [3.5912, 3.5527, 3.7350, 3.7975, 3.7834],\n",
      "        [3.5073, 3.6556, 3.6959, 3.8385, 3.5980],\n",
      "        [3.5311, 3.7987, 3.8158, 3.7412, 3.9215],\n",
      "        [3.4551, 3.8394, 3.7832, 3.7575, 3.8594],\n",
      "        [3.6760, 3.7825, 3.6889, 3.8651, 3.7964],\n",
      "        [3.5680, 3.5940, 3.6933, 3.7539, 3.6773],\n",
      "        [3.7457, 3.6678, 3.7367, 4.1014, 3.9008],\n",
      "        [3.6302, 3.6209, 3.7802, 3.8198, 3.7469],\n",
      "        [3.2578, 3.4255, 3.5381, 3.5061, 3.5003],\n",
      "        [3.7255, 3.6714, 3.6941, 4.0229, 3.8469],\n",
      "        [3.5356, 3.5303, 3.5975, 3.6612, 3.6875],\n",
      "        [3.9973, 3.8202, 3.9693, 4.2001, 3.9833],\n",
      "        [3.4938, 3.6006, 3.5449, 3.6750, 3.6176],\n",
      "        [3.5752, 3.6509, 3.6840, 3.7053, 3.5971],\n",
      "        [3.5789, 3.5472, 3.7078, 3.6903, 3.7123],\n",
      "        [3.6236, 3.6921, 3.7086, 3.8415, 3.8004],\n",
      "        [3.8424, 3.8576, 3.8961, 4.0052, 4.1006],\n",
      "        [3.8185, 3.8586, 3.8851, 3.9889, 4.0493],\n",
      "        [3.6207, 3.4282, 3.7880, 3.7910, 3.6828],\n",
      "        [3.9878, 3.9504, 3.8979, 4.2579, 3.8737],\n",
      "        [3.5539, 3.5578, 3.6691, 3.7287, 3.6534],\n",
      "        [3.4926, 3.5544, 3.6546, 3.7466, 3.6334],\n",
      "        [3.7157, 3.8474, 3.7404, 4.0199, 3.8502],\n",
      "        [4.0268, 4.0276, 3.9775, 4.3465, 4.0998],\n",
      "        [3.8258, 3.9039, 3.9683, 4.1609, 4.1797],\n",
      "        [3.4824, 3.5909, 3.5466, 3.6678, 3.6145],\n",
      "        [3.6292, 3.9693, 3.7537, 3.9841, 3.8811],\n",
      "        [3.8073, 3.9978, 3.8508, 4.0470, 3.9940],\n",
      "        [3.4394, 3.5028, 3.5972, 3.6408, 3.5523],\n",
      "        [3.5173, 3.5546, 3.6825, 3.7343, 3.6516],\n",
      "        [3.5651, 3.6009, 3.6959, 3.7695, 3.6878],\n",
      "        [3.9040, 3.8810, 3.9198, 4.1446, 3.8960],\n",
      "        [3.4565, 3.4820, 3.5877, 3.6554, 3.5475],\n",
      "        [3.4294, 3.5460, 3.5296, 3.6010, 3.5615],\n",
      "        [3.5567, 3.5719, 3.6772, 3.7477, 3.6686],\n",
      "        [3.5954, 3.9387, 3.7297, 3.8196, 3.9296]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3408, 3.4772, 3.4952, 3.5034, 3.4971],\n",
      "        [3.4183, 3.5741, 3.6267, 3.6474, 3.5767],\n",
      "        [3.3969, 3.4289, 3.5503, 3.5813, 3.4790],\n",
      "        [3.4844, 3.7321, 3.7012, 3.7707, 3.8416],\n",
      "        [3.5231, 3.4702, 3.6527, 3.7246, 3.6812],\n",
      "        [3.7855, 3.9726, 3.8623, 4.0657, 3.9349],\n",
      "        [3.5299, 3.5199, 3.6534, 3.6855, 3.6089],\n",
      "        [3.7845, 3.8566, 3.8929, 3.9163, 3.7047],\n",
      "        [3.5515, 3.6449, 3.5478, 3.7581, 3.6331],\n",
      "        [3.4440, 3.5714, 3.5398, 3.6345, 3.5805],\n",
      "        [3.5930, 3.6298, 3.7157, 3.6763, 3.5092],\n",
      "        [3.5709, 3.7626, 3.7219, 3.7205, 3.7597],\n",
      "        [3.4192, 3.5452, 3.6109, 3.6347, 3.5582],\n",
      "        [3.5479, 3.6439, 3.5540, 3.7511, 3.6504],\n",
      "        [3.5638, 3.5492, 3.6941, 3.7353, 3.6494],\n",
      "        [3.5497, 3.9618, 3.8588, 3.8124, 3.7111],\n",
      "        [3.7154, 3.6534, 3.7280, 3.7315, 3.5969],\n",
      "        [3.6220, 3.6137, 3.7750, 3.8126, 3.7384],\n",
      "        [3.5761, 3.8096, 3.6443, 3.8903, 3.7461],\n",
      "        [3.5030, 3.7466, 3.7037, 3.7907, 3.8091],\n",
      "        [3.5615, 3.6603, 3.5564, 3.7733, 3.6477],\n",
      "        [3.7453, 3.6075, 3.6996, 4.1205, 3.8675],\n",
      "        [3.3386, 3.4661, 3.4875, 3.4979, 3.4864],\n",
      "        [3.8546, 3.8292, 3.8977, 4.0780, 3.8897],\n",
      "        [3.6935, 3.8424, 3.7894, 3.9928, 3.8068],\n",
      "        [3.7073, 3.7991, 3.7321, 3.9118, 3.7947],\n",
      "        [3.7614, 3.6217, 3.7088, 4.1307, 3.8801],\n",
      "        [3.4900, 3.6399, 3.6047, 3.6986, 3.6668],\n",
      "        [3.5492, 3.5587, 3.6976, 3.7667, 3.7381],\n",
      "        [3.5600, 3.5976, 3.6893, 3.7753, 3.6808],\n",
      "        [3.5172, 3.4564, 3.6890, 3.5580, 3.6969],\n",
      "        [3.3931, 3.5438, 3.5467, 3.6264, 3.5546],\n",
      "        [4.0094, 4.1707, 3.7936, 3.9715, 3.7929],\n",
      "        [3.5656, 3.7194, 3.6219, 3.8889, 3.6287],\n",
      "        [3.7018, 3.6456, 3.7762, 3.8710, 3.7238],\n",
      "        [3.3861, 3.5200, 3.5178, 3.5605, 3.5401],\n",
      "        [3.5495, 3.5672, 3.6682, 3.7380, 3.6543],\n",
      "        [3.6813, 3.7557, 3.7191, 3.8422, 3.8727],\n",
      "        [3.7502, 3.7576, 3.9918, 3.8279, 3.6907],\n",
      "        [3.9326, 3.9657, 4.0294, 4.2457, 4.2475],\n",
      "        [3.4937, 3.6036, 3.5442, 3.6915, 3.6074],\n",
      "        [3.5820, 3.6762, 3.6525, 3.8354, 3.7318],\n",
      "        [3.9217, 3.6704, 3.7862, 4.3197, 4.0469],\n",
      "        [3.4725, 3.7679, 3.6842, 3.5786, 3.7353],\n",
      "        [3.9315, 3.8759, 3.7672, 4.0827, 4.0882],\n",
      "        [3.6083, 3.7602, 3.6592, 3.7470, 3.7286],\n",
      "        [3.8218, 3.9433, 3.7759, 3.8197, 3.7566],\n",
      "        [3.7812, 3.8138, 3.8976, 4.0667, 3.7940],\n",
      "        [3.8506, 3.8045, 3.8855, 4.0482, 3.8813],\n",
      "        [3.3742, 3.5102, 3.5130, 3.5404, 3.5293],\n",
      "        [3.5164, 3.6460, 3.7153, 3.8039, 3.6109],\n",
      "        [3.5227, 3.4636, 3.6930, 3.5601, 3.7036],\n",
      "        [3.5658, 3.6699, 3.6737, 3.8135, 3.7860],\n",
      "        [3.5866, 3.6508, 3.6241, 3.8272, 3.6934],\n",
      "        [3.8807, 3.7234, 3.8832, 4.0750, 3.8611],\n",
      "        [3.6178, 3.8141, 3.6667, 3.6350, 3.6828],\n",
      "        [3.8179, 3.7915, 3.8569, 4.0787, 4.0717],\n",
      "        [3.5549, 3.6570, 3.6904, 3.9414, 3.6181],\n",
      "        [3.7473, 3.8346, 3.8744, 3.9412, 3.9783],\n",
      "        [3.4429, 3.5845, 3.6684, 3.6774, 3.5956],\n",
      "        [3.6693, 3.6589, 3.6962, 3.8734, 3.8453],\n",
      "        [3.5503, 3.5605, 3.6658, 3.7346, 3.6522],\n",
      "        [3.5697, 3.4811, 3.6252, 3.6210, 3.5557],\n",
      "        [3.5765, 3.6814, 3.5627, 3.8040, 3.6720]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8564, 3.7120, 3.7560, 3.9307, 3.9041],\n",
      "        [3.6306, 3.7728, 3.8156, 3.9401, 3.8020],\n",
      "        [3.7303, 3.9087, 3.7897, 3.9197, 3.8316],\n",
      "        [3.7785, 3.8039, 3.8793, 3.9186, 3.8997],\n",
      "        [3.4408, 3.4898, 3.5859, 3.6497, 3.5461],\n",
      "        [3.7072, 3.7141, 3.7562, 3.8143, 3.5623],\n",
      "        [3.8324, 3.7866, 3.7145, 3.9404, 3.9099],\n",
      "        [3.5013, 3.7472, 3.7022, 3.7936, 3.8082],\n",
      "        [3.5279, 3.5722, 3.6058, 3.6640, 3.6514],\n",
      "        [4.1572, 4.3267, 3.9189, 4.1109, 3.9649],\n",
      "        [3.5429, 3.5803, 3.5718, 3.7176, 3.7113],\n",
      "        [3.9688, 3.8955, 3.8725, 4.1399, 4.0256],\n",
      "        [3.7944, 3.8782, 3.7764, 3.9305, 3.9338],\n",
      "        [3.6553, 3.9230, 3.8157, 3.9151, 3.9079],\n",
      "        [3.9650, 3.7035, 3.8611, 4.3715, 4.2013],\n",
      "        [4.0069, 4.0417, 4.0224, 4.3228, 4.0875],\n",
      "        [3.4143, 3.5345, 3.5296, 3.5919, 3.5529],\n",
      "        [3.8421, 3.6967, 3.7180, 3.9099, 3.8683],\n",
      "        [3.5423, 3.5851, 3.7368, 3.7643, 3.6809],\n",
      "        [3.5447, 3.6490, 3.5503, 3.7677, 3.6387],\n",
      "        [4.0283, 4.2005, 3.8136, 4.0010, 3.8070],\n",
      "        [3.8230, 3.9050, 3.9655, 4.1681, 4.1776],\n",
      "        [3.9697, 3.8977, 3.8693, 4.1378, 4.0290],\n",
      "        [3.4383, 3.6630, 3.6735, 3.6791, 3.6301],\n",
      "        [3.6053, 3.5745, 3.7413, 3.7745, 3.7218],\n",
      "        [3.7128, 3.9186, 3.7727, 3.9228, 3.8234],\n",
      "        [3.7071, 3.6594, 3.7821, 3.9514, 3.6682],\n",
      "        [3.6417, 3.6806, 3.7181, 3.7932, 3.7244],\n",
      "        [3.4136, 3.4629, 3.5715, 3.6186, 3.5112],\n",
      "        [3.4359, 3.5117, 3.6015, 3.6564, 3.5634],\n",
      "        [3.6148, 3.7839, 3.7227, 3.8791, 3.6981],\n",
      "        [4.0666, 4.2560, 3.8580, 4.0563, 3.8614],\n",
      "        [3.5060, 3.5859, 3.6672, 3.7787, 3.6426],\n",
      "        [3.5217, 3.6302, 3.5477, 3.7340, 3.6226],\n",
      "        [3.4691, 3.5849, 3.5382, 3.6595, 3.5903],\n",
      "        [3.6614, 3.6221, 3.7083, 3.7101, 3.5348],\n",
      "        [3.8054, 3.8851, 3.7851, 3.9314, 3.9378],\n",
      "        [3.5347, 3.6351, 3.6791, 3.8055, 3.7032],\n",
      "        [3.7019, 3.8550, 3.8515, 3.9482, 3.8683],\n",
      "        [3.6729, 3.4818, 3.8382, 3.8483, 3.7307],\n",
      "        [3.7344, 3.6889, 3.8062, 3.9775, 3.7051],\n",
      "        [3.8140, 3.7775, 3.9159, 3.9834, 3.7011],\n",
      "        [3.6375, 3.6439, 3.7699, 3.8340, 3.8374],\n",
      "        [3.5031, 3.6129, 3.5375, 3.7100, 3.6063],\n",
      "        [3.9544, 3.8834, 3.8909, 4.1529, 3.9930],\n",
      "        [3.6955, 3.8001, 3.7261, 3.9174, 3.7866],\n",
      "        [3.6310, 3.6272, 3.7810, 3.8319, 3.7563],\n",
      "        [3.4366, 3.5035, 3.5945, 3.6470, 3.5504],\n",
      "        [3.6178, 3.6857, 3.7106, 3.7874, 3.8147],\n",
      "        [3.9112, 3.9004, 3.8338, 4.0357, 4.0246],\n",
      "        [3.5511, 3.5790, 3.6763, 3.7530, 3.6591],\n",
      "        [3.7536, 3.8161, 3.8643, 4.0472, 3.7860],\n",
      "        [3.5851, 3.6514, 3.6227, 3.8301, 3.6924],\n",
      "        [3.6605, 3.6801, 3.8048, 3.8668, 3.7399],\n",
      "        [3.5090, 3.6191, 3.5436, 3.7096, 3.6166],\n",
      "        [3.4634, 3.4606, 3.5670, 3.6759, 3.5356],\n",
      "        [3.6838, 3.6991, 3.7356, 3.7902, 3.5369],\n",
      "        [3.6160, 3.4978, 3.7037, 3.9328, 3.6056],\n",
      "        [3.5819, 3.6950, 3.5780, 3.8173, 3.6862],\n",
      "        [3.9049, 3.8978, 3.8381, 4.0503, 4.0196],\n",
      "        [4.0591, 3.7650, 3.9523, 4.4624, 4.2929],\n",
      "        [3.9867, 3.9598, 3.9282, 4.2711, 4.0359],\n",
      "        [3.5108, 3.8065, 3.6960, 3.7090, 3.5611],\n",
      "        [3.5683, 3.4817, 3.6239, 3.6238, 3.5546]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5473, 3.5614, 3.6630, 3.7398, 3.6498],\n",
      "        [3.7519, 3.9008, 3.7314, 3.8598, 3.8008],\n",
      "        [3.5904, 3.7522, 3.6722, 3.7888, 3.7476],\n",
      "        [3.4849, 3.6356, 3.5760, 3.7880, 3.5921],\n",
      "        [3.5800, 3.6551, 3.7012, 3.7546, 3.5829],\n",
      "        [3.4810, 3.7331, 3.6983, 3.7761, 3.8396],\n",
      "        [3.5691, 3.6736, 3.5557, 3.7986, 3.6594],\n",
      "        [3.4148, 3.5999, 3.6298, 3.6449, 3.5736],\n",
      "        [3.5187, 3.6021, 3.5822, 3.6689, 3.6086],\n",
      "        [3.5271, 3.5649, 3.5529, 3.7043, 3.6970],\n",
      "        [3.7884, 3.8657, 3.8999, 3.9274, 3.7066],\n",
      "        [3.5397, 3.6517, 3.6959, 3.8413, 3.6817],\n",
      "        [3.6818, 3.7880, 3.7243, 3.8484, 3.8802],\n",
      "        [3.7272, 3.8568, 3.8232, 3.9519, 3.8089],\n",
      "        [3.5550, 3.8186, 3.7290, 3.7673, 3.5816],\n",
      "        [3.5482, 3.7068, 3.7153, 3.7707, 3.7349],\n",
      "        [3.6124, 3.7595, 3.6357, 3.7715, 3.7142],\n",
      "        [3.8856, 3.7385, 3.9007, 4.1028, 3.8787],\n",
      "        [3.8487, 3.9582, 3.7315, 3.8875, 3.7990],\n",
      "        [3.4646, 3.4675, 3.5737, 3.6766, 3.5397],\n",
      "        [4.1973, 4.3364, 3.9660, 4.1398, 3.9787],\n",
      "        [3.5590, 3.5780, 3.6806, 3.7626, 3.6605],\n",
      "        [3.5280, 3.6386, 3.5564, 3.7378, 3.6342],\n",
      "        [3.8708, 3.8095, 3.8075, 3.9852, 3.9168],\n",
      "        [3.7235, 3.6560, 3.7222, 3.7458, 3.6115],\n",
      "        [3.4352, 3.5037, 3.5932, 3.6492, 3.5492],\n",
      "        [3.4789, 3.8630, 3.8129, 3.8072, 3.8722],\n",
      "        [3.4787, 3.5761, 3.6768, 3.7213, 3.5708],\n",
      "        [3.6108, 3.6044, 3.7581, 3.8055, 3.7273],\n",
      "        [3.5702, 3.7529, 3.7029, 3.7331, 3.7471],\n",
      "        [3.6104, 3.7720, 3.7053, 3.7910, 3.7634],\n",
      "        [3.7137, 3.8280, 3.8160, 4.0134, 3.7920],\n",
      "        [3.8997, 3.8824, 3.9156, 4.1544, 3.8925],\n",
      "        [3.7295, 3.8568, 3.8283, 3.9652, 3.8100],\n",
      "        [3.7414, 3.7317, 3.7523, 3.9564, 3.9090],\n",
      "        [3.6998, 3.9910, 3.8630, 3.9714, 4.0024],\n",
      "        [3.5294, 3.6360, 3.5447, 3.7507, 3.6261],\n",
      "        [3.9635, 3.7038, 3.8597, 4.3741, 4.2000],\n",
      "        [3.4674, 3.4931, 3.4802, 3.7097, 3.5081],\n",
      "        [3.6321, 3.5294, 3.7215, 3.9432, 3.6129],\n",
      "        [3.6272, 3.4576, 3.7999, 3.8396, 3.7624],\n",
      "        [3.5432, 3.6492, 3.5489, 3.7699, 3.6373],\n",
      "        [3.7714, 3.6203, 3.7130, 4.1767, 3.8960],\n",
      "        [3.9325, 3.8696, 3.9095, 4.1678, 3.9516],\n",
      "        [3.4989, 3.5343, 3.6714, 3.7418, 3.7179],\n",
      "        [3.5600, 3.5553, 3.6235, 3.7031, 3.7098],\n",
      "        [3.4815, 3.6592, 3.6495, 3.6129, 3.5758],\n",
      "        [3.7092, 3.8538, 3.8206, 4.0283, 3.8097],\n",
      "        [3.5570, 3.5063, 3.6452, 3.6681, 3.5826],\n",
      "        [3.7947, 3.6177, 3.7050, 3.8478, 3.8068],\n",
      "        [3.4926, 3.5474, 3.6541, 3.7381, 3.6499],\n",
      "        [3.9098, 3.8654, 3.9129, 4.1883, 3.9681],\n",
      "        [3.6991, 3.6674, 3.7634, 3.7866, 3.6316],\n",
      "        [3.9464, 3.8759, 3.9092, 4.1740, 3.9653],\n",
      "        [3.9830, 3.9523, 3.8938, 4.2682, 3.8701],\n",
      "        [3.8050, 3.6385, 3.7185, 3.8724, 3.8236],\n",
      "        [3.5555, 3.7780, 3.7470, 3.7056, 3.7665],\n",
      "        [3.5767, 3.5498, 3.7061, 3.7027, 3.7080],\n",
      "        [3.5794, 3.6705, 3.6934, 3.9089, 3.6811],\n",
      "        [3.4238, 3.5256, 3.6030, 3.6456, 3.5523],\n",
      "        [3.5474, 3.6518, 3.6893, 3.8153, 3.7176],\n",
      "        [3.7571, 3.8422, 3.8645, 3.8981, 3.6832],\n",
      "        [3.5079, 3.4517, 3.6334, 3.7096, 3.6571],\n",
      "        [3.5520, 3.6413, 3.7413, 3.7989, 3.7477]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7093, 3.8484, 3.7345, 4.0304, 3.8453],\n",
      "        [3.3367, 3.4779, 3.4910, 3.5095, 3.4937],\n",
      "        [3.8037, 3.6896, 3.7477, 3.9273, 3.8730],\n",
      "        [3.8296, 3.7872, 3.7115, 3.9444, 3.9073],\n",
      "        [3.8173, 3.9462, 3.9248, 4.0583, 3.9638],\n",
      "        [3.5635, 3.7387, 3.7536, 3.8144, 3.6506],\n",
      "        [3.6889, 3.7859, 3.7137, 3.8976, 3.8358],\n",
      "        [3.5709, 3.6619, 3.6429, 3.8126, 3.7725],\n",
      "        [3.7280, 3.8303, 3.7293, 3.9715, 3.9504],\n",
      "        [3.7003, 3.7983, 3.7201, 3.9188, 3.7824],\n",
      "        [3.6803, 3.6431, 3.7237, 3.7077, 3.5521],\n",
      "        [3.7740, 3.8540, 3.8826, 3.9752, 3.9939],\n",
      "        [3.8527, 3.5504, 3.7530, 4.1778, 4.0605],\n",
      "        [3.3701, 3.5109, 3.5088, 3.5466, 3.5259],\n",
      "        [3.9560, 3.9507, 3.9263, 4.2246, 4.0122],\n",
      "        [3.6944, 3.7976, 3.7210, 3.8504, 3.8726],\n",
      "        [3.8361, 3.8794, 3.9107, 4.0084, 4.0857],\n",
      "        [3.7002, 3.7445, 3.8579, 3.8489, 3.6864],\n",
      "        [3.4120, 3.5850, 3.6240, 3.6481, 3.5662],\n",
      "        [3.6887, 3.7238, 3.8301, 3.8441, 3.6351],\n",
      "        [3.5025, 3.5571, 3.6219, 3.6602, 3.6256],\n",
      "        [3.7093, 3.8484, 3.7345, 4.0304, 3.8453],\n",
      "        [3.5194, 3.6517, 3.7126, 3.8010, 3.6031],\n",
      "        [3.3768, 3.5109, 3.5100, 3.5561, 3.5338],\n",
      "        [3.4489, 3.4551, 3.5608, 3.6741, 3.5242],\n",
      "        [3.4299, 3.6441, 3.6524, 3.6763, 3.6063],\n",
      "        [3.6692, 3.7599, 3.7166, 3.8491, 3.8835],\n",
      "        [3.7934, 3.6178, 3.7036, 3.8495, 3.8056],\n",
      "        [3.4296, 3.5048, 3.5902, 3.6481, 3.5461],\n",
      "        [3.6710, 3.7996, 3.7808, 3.8483, 3.6444],\n",
      "        [3.7876, 3.8588, 3.8163, 3.9466, 3.9018],\n",
      "        [3.6068, 3.5064, 3.7015, 3.9243, 3.5872],\n",
      "        [3.6231, 3.5565, 3.6899, 3.7940, 3.6397],\n",
      "        [4.1822, 4.3634, 3.9599, 4.1660, 3.9492],\n",
      "        [3.3843, 3.4345, 3.5487, 3.5910, 3.4678],\n",
      "        [3.6783, 3.7452, 3.8255, 3.8232, 3.6450],\n",
      "        [3.5719, 3.6822, 3.5584, 3.8105, 3.6682],\n",
      "        [3.9436, 3.8775, 3.8944, 4.1606, 3.9761],\n",
      "        [3.4140, 3.5749, 3.6225, 3.6538, 3.5731],\n",
      "        [3.7289, 3.8117, 3.7410, 3.8354, 3.7735],\n",
      "        [3.7611, 3.8154, 3.8739, 4.0600, 3.7858],\n",
      "        [3.8920, 3.7261, 3.8818, 4.0394, 3.8794],\n",
      "        [3.4566, 3.4532, 3.5582, 3.6772, 3.5253],\n",
      "        [3.8090, 4.0115, 3.8622, 4.0689, 4.0098],\n",
      "        [3.6221, 3.7753, 3.6889, 3.8781, 3.7151],\n",
      "        [3.4680, 3.7688, 3.6798, 3.5855, 3.7317],\n",
      "        [3.4914, 3.5997, 3.5320, 3.6849, 3.5934],\n",
      "        [3.5706, 3.6223, 3.6887, 3.7610, 3.8226],\n",
      "        [3.4709, 3.5676, 3.6463, 3.6245, 3.7197],\n",
      "        [4.1514, 4.2522, 3.9949, 4.1351, 3.9827],\n",
      "        [3.7306, 3.7193, 3.9273, 3.8512, 3.6369],\n",
      "        [3.7927, 3.9095, 3.8523, 3.8354, 3.8659],\n",
      "        [3.5507, 3.6335, 3.5911, 3.7475, 3.6728],\n",
      "        [3.4432, 3.4838, 3.5819, 3.6698, 3.5430],\n",
      "        [3.5044, 3.5531, 3.6395, 3.7448, 3.5803],\n",
      "        [3.6412, 3.6685, 3.7043, 3.8308, 3.7951],\n",
      "        [3.5389, 3.6447, 3.5593, 3.7553, 3.6487],\n",
      "        [3.4434, 3.5092, 3.6163, 3.6757, 3.5323],\n",
      "        [3.4158, 3.5951, 3.6308, 3.6599, 3.5832],\n",
      "        [3.8886, 3.9087, 3.8375, 4.0294, 4.0028],\n",
      "        [3.4966, 3.6118, 3.5463, 3.6825, 3.6184],\n",
      "        [3.9992, 3.7853, 3.9937, 4.4895, 4.2977],\n",
      "        [3.9818, 3.9180, 3.8693, 4.1460, 4.0520],\n",
      "        [3.5516, 3.5953, 3.6841, 3.7799, 3.6700]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6538, 3.7100, 3.7464, 3.8102, 3.8563],\n",
      "        [3.9531, 3.7710, 3.9231, 4.4447, 4.2110],\n",
      "        [3.4936, 3.6110, 3.5363, 3.7029, 3.6070],\n",
      "        [3.7146, 3.7231, 3.7644, 3.8313, 3.5805],\n",
      "        [3.4428, 3.4311, 3.5421, 3.6631, 3.5054],\n",
      "        [3.7018, 3.7127, 3.7501, 3.8167, 3.5566],\n",
      "        [3.3457, 3.4766, 3.4873, 3.5259, 3.5043],\n",
      "        [4.0631, 4.2566, 3.8535, 4.0616, 3.8567],\n",
      "        [3.9272, 3.9672, 4.0232, 4.2546, 4.2413],\n",
      "        [3.9655, 3.8718, 3.8997, 4.1241, 4.0128],\n",
      "        [3.8476, 3.5484, 3.7637, 4.1664, 4.0374],\n",
      "        [3.5300, 3.5310, 3.5906, 3.6723, 3.6812],\n",
      "        [3.6028, 3.7616, 3.6535, 3.7551, 3.7226],\n",
      "        [3.6338, 3.9346, 3.7601, 3.9690, 3.8593],\n",
      "        [3.8719, 3.7117, 3.8663, 4.0782, 3.8455],\n",
      "        [3.4454, 3.7297, 3.5644, 3.5243, 3.6671],\n",
      "        [3.8369, 3.5391, 3.7409, 4.1727, 4.0434],\n",
      "        [3.9407, 3.9897, 3.9327, 4.2424, 3.9860],\n",
      "        [3.7664, 3.8661, 3.7529, 3.9992, 3.9973],\n",
      "        [3.5482, 3.6565, 3.5486, 3.7857, 3.6458],\n",
      "        [3.8118, 3.9473, 3.9165, 4.0498, 3.9528],\n",
      "        [3.5627, 3.6145, 3.7010, 3.7944, 3.6881],\n",
      "        [3.6649, 3.8384, 3.7510, 3.9854, 3.7948],\n",
      "        [3.8462, 3.8120, 3.7308, 3.9819, 3.9081],\n",
      "        [3.5848, 3.5801, 3.7296, 3.7982, 3.7081],\n",
      "        [3.8268, 3.7678, 3.8895, 4.1351, 3.7586],\n",
      "        [3.6884, 3.8434, 3.7836, 4.0009, 3.8010],\n",
      "        [3.4793, 3.7183, 3.5657, 3.5275, 3.6298],\n",
      "        [3.4318, 3.5262, 3.6008, 3.6570, 3.5641],\n",
      "        [3.3678, 3.5054, 3.4139, 3.6397, 3.4844],\n",
      "        [3.4503, 3.6575, 3.7575, 3.7045, 3.6941],\n",
      "        [3.7359, 3.5635, 3.7519, 4.0128, 3.9495],\n",
      "        [3.5526, 3.5624, 3.6717, 3.7460, 3.6516],\n",
      "        [3.4826, 3.6356, 3.5729, 3.7905, 3.5889],\n",
      "        [3.5662, 3.6461, 3.5938, 3.7705, 3.6865],\n",
      "        [3.4800, 3.5595, 3.6669, 3.7674, 3.6665],\n",
      "        [3.5440, 3.4836, 3.6004, 3.6993, 3.7345],\n",
      "        [3.4653, 3.4883, 3.5836, 3.6898, 3.5584],\n",
      "        [3.7495, 3.9010, 3.7285, 3.8625, 3.7972],\n",
      "        [3.6754, 3.6396, 3.7226, 3.6910, 3.5494],\n",
      "        [3.5748, 3.5318, 3.7064, 3.7775, 3.7634],\n",
      "        [3.3623, 3.5006, 3.5041, 3.5372, 3.5238],\n",
      "        [3.7502, 3.7733, 3.8260, 3.9812, 3.9657],\n",
      "        [3.7195, 3.8425, 3.8528, 3.8657, 3.6861],\n",
      "        [3.4077, 3.5453, 3.5232, 3.5939, 3.5546],\n",
      "        [3.4656, 3.4634, 3.5669, 3.6853, 3.5334],\n",
      "        [3.5942, 3.9068, 3.7395, 3.9282, 3.8396],\n",
      "        [3.7709, 3.9042, 3.9143, 3.9205, 3.6427],\n",
      "        [3.4307, 3.4988, 3.5854, 3.6522, 3.5446],\n",
      "        [3.8612, 3.7381, 3.7611, 3.9481, 3.9178],\n",
      "        [3.9568, 4.0421, 3.7439, 3.9390, 3.7989],\n",
      "        [3.3743, 3.5339, 3.5567, 3.6433, 3.5738],\n",
      "        [3.6500, 3.8092, 3.7356, 3.7960, 3.7860],\n",
      "        [3.5668, 3.8076, 3.6338, 3.8972, 3.7408],\n",
      "        [3.6276, 3.7914, 3.7069, 3.7883, 3.7716],\n",
      "        [3.6308, 3.6852, 3.7311, 3.7992, 3.8049],\n",
      "        [3.5550, 3.5469, 3.6822, 3.7442, 3.6373],\n",
      "        [3.4816, 3.6957, 3.5423, 3.7395, 3.5602],\n",
      "        [3.8327, 3.5611, 3.7606, 4.1444, 4.0342],\n",
      "        [3.6150, 3.6777, 3.7006, 3.7857, 3.7091],\n",
      "        [4.0637, 4.0113, 3.9885, 4.3298, 4.0182],\n",
      "        [3.9853, 3.7313, 3.8799, 4.3786, 4.2188],\n",
      "        [3.5766, 3.5943, 3.7656, 3.7981, 3.7215],\n",
      "        [3.5546, 3.5062, 3.6422, 3.6706, 3.5792]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5222, 3.5404, 3.6592, 3.7073, 3.6244],\n",
      "        [3.5937, 3.7033, 3.7001, 3.8149, 3.7528],\n",
      "        [3.3686, 3.5105, 3.5058, 3.5486, 3.5247],\n",
      "        [3.4217, 3.6346, 3.6437, 3.6616, 3.5992],\n",
      "        [3.4902, 3.6646, 3.6794, 3.8620, 3.5771],\n",
      "        [3.8996, 3.8816, 3.9319, 4.1404, 3.9485],\n",
      "        [3.8440, 3.9617, 3.7263, 3.8895, 3.7970],\n",
      "        [4.0078, 4.0933, 3.8679, 3.9920, 3.8442],\n",
      "        [3.5691, 3.5365, 3.5772, 3.8243, 3.5812],\n",
      "        [3.8127, 3.8999, 3.7974, 3.9769, 3.9580],\n",
      "        [3.4037, 3.5450, 3.5252, 3.6004, 3.5577],\n",
      "        [3.5616, 3.5048, 3.6409, 3.7479, 3.7566],\n",
      "        [3.5172, 3.4707, 3.6457, 3.7336, 3.6765],\n",
      "        [3.5790, 3.6306, 3.6649, 3.9120, 3.7115],\n",
      "        [3.5328, 3.6206, 3.5748, 3.7354, 3.6546],\n",
      "        [3.4518, 3.4970, 3.6054, 3.6745, 3.5257],\n",
      "        [3.6264, 3.6270, 3.7750, 3.8381, 3.7524],\n",
      "        [3.9845, 3.7310, 3.8783, 4.3801, 4.2200],\n",
      "        [3.3449, 3.4763, 3.4858, 3.5271, 3.5050],\n",
      "        [3.4639, 3.7881, 3.6923, 3.6163, 3.7717],\n",
      "        [4.1148, 4.2652, 3.8951, 4.0840, 3.9105],\n",
      "        [3.3959, 3.6657, 3.7739, 3.6527, 3.6934],\n",
      "        [3.4950, 3.6086, 3.5396, 3.7004, 3.6160],\n",
      "        [3.6696, 3.7992, 3.7776, 3.8506, 3.6431],\n",
      "        [3.5924, 3.6721, 3.6843, 3.7561, 3.7033],\n",
      "        [3.5249, 3.6382, 3.5518, 3.7414, 3.6317],\n",
      "        [3.4310, 3.5259, 3.5993, 3.6582, 3.5649],\n",
      "        [3.7906, 3.8030, 3.8574, 3.9940, 3.9966],\n",
      "        [3.8982, 3.7244, 3.8884, 4.4019, 4.1991],\n",
      "        [3.6833, 3.6430, 3.7226, 3.7153, 3.5569],\n",
      "        [3.3885, 3.6677, 3.7742, 3.6572, 3.6880],\n",
      "        [3.7086, 3.7337, 3.7870, 3.9371, 3.9311],\n",
      "        [3.6486, 3.5788, 3.9310, 3.8716, 3.8169],\n",
      "        [3.8710, 3.7161, 3.8733, 4.0777, 3.8532],\n",
      "        [3.4649, 3.4963, 3.4724, 3.7177, 3.4958],\n",
      "        [3.5444, 3.5741, 3.6654, 3.7524, 3.6526],\n",
      "        [3.5600, 3.6053, 3.5894, 3.7492, 3.7375],\n",
      "        [3.6689, 3.6244, 3.7037, 3.7316, 3.5435],\n",
      "        [3.9389, 3.8304, 3.8619, 4.1615, 3.9304],\n",
      "        [3.5704, 3.8103, 3.6370, 3.8993, 3.7413],\n",
      "        [3.5382, 3.6200, 3.6299, 3.7186, 3.6466],\n",
      "        [3.4458, 3.4762, 3.5703, 3.6679, 3.5384],\n",
      "        [3.8531, 3.7118, 3.7503, 3.9378, 3.9011],\n",
      "        [3.5512, 3.6943, 3.6706, 3.8276, 3.7191],\n",
      "        [3.7685, 3.6199, 3.7085, 4.1809, 3.8936],\n",
      "        [3.4688, 3.7854, 3.6951, 3.6115, 3.7635],\n",
      "        [3.7934, 3.6392, 3.7309, 4.1551, 3.9162],\n",
      "        [3.8110, 3.8029, 3.8203, 4.0231, 3.9871],\n",
      "        [3.5541, 3.7116, 3.7219, 3.7821, 3.7531],\n",
      "        [3.8349, 3.8593, 3.8872, 4.0192, 4.0946],\n",
      "        [3.6735, 3.6827, 3.5691, 3.8784, 3.8134],\n",
      "        [3.5391, 3.6452, 3.5528, 3.7673, 3.6435],\n",
      "        [3.6257, 3.8934, 3.8892, 3.9596, 3.9051],\n",
      "        [3.5909, 3.8317, 3.7522, 3.8149, 3.5981],\n",
      "        [3.5559, 3.5853, 3.6799, 3.7722, 3.6618],\n",
      "        [3.4951, 3.6113, 3.5433, 3.6846, 3.6172],\n",
      "        [3.7320, 3.8739, 3.8371, 3.9570, 3.8139],\n",
      "        [3.5585, 3.6651, 3.5560, 3.7886, 3.6564],\n",
      "        [3.9871, 3.9255, 3.8752, 4.1578, 4.0614],\n",
      "        [3.5535, 3.7242, 3.7180, 3.7963, 3.6881],\n",
      "        [3.5528, 3.5742, 3.6683, 3.7495, 3.6536],\n",
      "        [4.0205, 3.8761, 3.9337, 4.2443, 4.0246],\n",
      "        [3.9424, 3.7214, 3.8874, 4.4377, 4.1929],\n",
      "        [3.3953, 3.4938, 3.4742, 3.6754, 3.4755]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5782, 3.7180, 3.7352, 3.7855, 3.8340],\n",
      "        [3.4633, 3.4882, 3.5813, 3.6919, 3.5595],\n",
      "        [3.6997, 3.7433, 3.6444, 3.9039, 3.8227],\n",
      "        [4.0575, 3.9516, 3.9495, 4.2989, 4.1177],\n",
      "        [3.5472, 3.7869, 3.7561, 3.7027, 3.7704],\n",
      "        [3.5252, 3.6461, 3.8355, 3.8001, 3.8011],\n",
      "        [3.6228, 3.5431, 3.6483, 3.7344, 3.7137],\n",
      "        [3.4960, 3.5281, 3.6862, 3.7326, 3.6285],\n",
      "        [3.5499, 3.6946, 3.6699, 3.8285, 3.7195],\n",
      "        [3.9963, 3.7852, 3.9897, 4.4933, 4.2975],\n",
      "        [3.6860, 3.9228, 3.7365, 3.9112, 3.9696],\n",
      "        [3.5228, 3.4943, 3.6523, 3.7087, 3.6063],\n",
      "        [3.5425, 3.5521, 3.6624, 3.7410, 3.6440],\n",
      "        [3.5872, 3.6302, 3.7077, 3.6854, 3.5046],\n",
      "        [3.7374, 3.7631, 3.8151, 3.9764, 3.9579],\n",
      "        [3.7586, 3.7545, 3.7947, 3.9101, 3.9262],\n",
      "        [3.8154, 3.7842, 3.9019, 4.0115, 3.7210],\n",
      "        [3.6174, 3.6904, 3.7173, 3.8147, 3.8177],\n",
      "        [3.7150, 3.7500, 3.8473, 3.8574, 3.6193],\n",
      "        [3.4420, 3.5366, 3.6055, 3.6631, 3.5787],\n",
      "        [3.5587, 3.6712, 3.6657, 3.8239, 3.7813],\n",
      "        [3.7223, 3.6684, 3.7961, 3.9234, 3.7429],\n",
      "        [3.4058, 3.5451, 3.5210, 3.5958, 3.5556],\n",
      "        [3.9260, 3.8684, 3.9133, 4.1794, 3.9383],\n",
      "        [3.4744, 3.5384, 3.6338, 3.7286, 3.5547],\n",
      "        [3.6082, 3.8177, 3.6627, 3.8364, 3.7350],\n",
      "        [3.5730, 3.5316, 3.7041, 3.7797, 3.7647],\n",
      "        [3.6551, 3.9185, 3.8134, 3.9249, 3.9112],\n",
      "        [3.8602, 4.0026, 3.8367, 3.8860, 3.8630],\n",
      "        [3.6204, 3.5563, 3.6862, 3.7971, 3.6392],\n",
      "        [3.6218, 3.5446, 3.6517, 3.7391, 3.7138],\n",
      "        [3.6281, 3.6436, 3.6946, 3.8673, 3.7075],\n",
      "        [3.5857, 3.5819, 3.6911, 3.7646, 3.7240],\n",
      "        [3.9638, 3.8985, 3.8624, 4.1456, 4.0255],\n",
      "        [3.8699, 3.7164, 3.8725, 4.0788, 3.8536],\n",
      "        [3.7064, 3.8481, 3.7306, 4.0334, 3.8444],\n",
      "        [3.6515, 3.6786, 3.7091, 3.8159, 3.7151],\n",
      "        [3.5562, 3.6018, 3.6863, 3.7831, 3.6819],\n",
      "        [3.9085, 4.0159, 3.8582, 4.1189, 4.1201],\n",
      "        [4.0123, 3.8424, 3.9826, 4.2458, 4.0229],\n",
      "        [3.4141, 3.4677, 3.5321, 3.6154, 3.5356],\n",
      "        [3.8129, 3.7881, 3.8044, 3.9401, 3.8968],\n",
      "        [3.7958, 3.7825, 3.8447, 4.0481, 3.8314],\n",
      "        [3.7128, 3.7267, 3.6100, 3.9190, 3.8547],\n",
      "        [3.5506, 3.7038, 3.6017, 3.8777, 3.6175],\n",
      "        [3.5298, 3.8300, 3.7187, 3.7547, 3.5830],\n",
      "        [3.5859, 3.8498, 3.7926, 3.9205, 3.9030],\n",
      "        [3.7954, 3.5523, 3.7512, 4.1087, 3.9941],\n",
      "        [3.6754, 3.6567, 3.6896, 3.9511, 3.7837],\n",
      "        [3.7286, 3.7994, 3.8421, 3.9623, 3.7517],\n",
      "        [3.8690, 3.7411, 3.7714, 3.9612, 3.9197],\n",
      "        [3.5512, 3.7778, 3.7415, 3.7102, 3.7639],\n",
      "        [3.4088, 3.5602, 3.6070, 3.6462, 3.5578],\n",
      "        [3.5677, 3.6513, 3.6746, 3.7185, 3.5916],\n",
      "        [3.8713, 3.9035, 3.8213, 4.0258, 3.9901],\n",
      "        [3.7774, 3.8028, 3.9738, 3.8796, 3.6605],\n",
      "        [3.4809, 3.6466, 3.7431, 3.7471, 3.7341],\n",
      "        [3.7499, 3.8277, 3.8380, 3.9447, 3.9843],\n",
      "        [3.8885, 3.9427, 3.9029, 4.0349, 3.9839],\n",
      "        [3.5746, 3.6768, 3.6443, 3.8450, 3.7272],\n",
      "        [3.5358, 3.5100, 3.6678, 3.7227, 3.6203],\n",
      "        [3.6127, 3.7616, 3.6270, 3.7758, 3.7066],\n",
      "        [3.4088, 3.6538, 3.6295, 3.7122, 3.7565],\n",
      "        [3.7745, 3.9005, 3.9106, 3.9232, 3.6323]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5297, 3.6949, 3.6366, 3.8046, 3.7213],\n",
      "        [3.6838, 3.6439, 3.7491, 3.8590, 3.7041],\n",
      "        [3.5183, 3.8993, 3.6574, 3.7371, 3.8266],\n",
      "        [3.4217, 3.6186, 3.6384, 3.6718, 3.5945],\n",
      "        [3.4427, 3.4731, 3.5692, 3.6661, 3.5367],\n",
      "        [3.4112, 3.6419, 3.6473, 3.6569, 3.5974],\n",
      "        [3.6882, 3.8021, 3.7185, 3.9262, 3.7834],\n",
      "        [3.6054, 3.6415, 3.7123, 3.7688, 3.8943],\n",
      "        [3.7740, 3.7758, 3.8250, 3.9641, 3.9477],\n",
      "        [4.0045, 3.9280, 3.9335, 4.2501, 3.9353],\n",
      "        [4.1825, 4.3745, 3.9607, 4.2024, 3.9614],\n",
      "        [3.6168, 3.5605, 3.6871, 3.7892, 3.6633],\n",
      "        [3.7661, 3.6208, 3.7068, 4.1830, 3.8942],\n",
      "        [3.4576, 3.4538, 3.5573, 3.6884, 3.5365],\n",
      "        [3.6656, 3.6912, 3.7544, 3.8200, 3.8328],\n",
      "        [3.9728, 4.0017, 3.9138, 4.3164, 4.0544],\n",
      "        [4.0592, 4.0557, 4.0160, 4.4142, 4.1218],\n",
      "        [3.8045, 3.7402, 3.8500, 4.0039, 3.8093],\n",
      "        [3.9827, 4.0599, 3.9905, 4.3410, 4.0973],\n",
      "        [3.5430, 3.6460, 3.5388, 3.7684, 3.6285],\n",
      "        [3.5413, 3.7866, 3.7640, 3.6906, 3.7678],\n",
      "        [3.4419, 3.5688, 3.6569, 3.6980, 3.5804],\n",
      "        [3.4171, 3.8205, 3.7431, 3.7444, 3.8402],\n",
      "        [3.7382, 3.6849, 3.7162, 4.0878, 3.8784],\n",
      "        [3.7339, 3.6604, 3.7211, 3.7663, 3.6215],\n",
      "        [3.4473, 3.4397, 3.5438, 3.6721, 3.5148],\n",
      "        [3.8189, 3.8053, 3.8550, 4.1028, 4.0700],\n",
      "        [3.8199, 3.8210, 3.8767, 4.1101, 4.0813],\n",
      "        [3.8422, 3.8075, 3.8763, 4.0609, 3.8767],\n",
      "        [3.4566, 3.4613, 3.5594, 3.6837, 3.5321],\n",
      "        [3.6895, 3.7925, 3.8408, 3.8323, 3.6512],\n",
      "        [3.9320, 3.8764, 3.9176, 4.1823, 3.9470],\n",
      "        [3.7510, 3.6950, 3.8060, 4.0491, 3.6832],\n",
      "        [3.5551, 3.6528, 3.6678, 3.7065, 3.5830],\n",
      "        [3.5740, 3.6851, 3.5706, 3.8178, 3.6749],\n",
      "        [3.5180, 3.5470, 3.6141, 3.7753, 3.5826],\n",
      "        [3.6362, 3.8635, 3.7075, 3.6896, 3.7814],\n",
      "        [3.9266, 3.8710, 3.9031, 4.1745, 3.9496],\n",
      "        [3.6347, 3.6386, 3.7979, 3.8513, 3.7539],\n",
      "        [3.7197, 3.8320, 3.8522, 3.9332, 3.8400],\n",
      "        [3.7050, 3.8488, 3.7296, 4.0345, 3.8444],\n",
      "        [3.4439, 3.5733, 3.5318, 3.6399, 3.5798],\n",
      "        [4.0171, 4.0305, 3.9667, 4.3649, 4.0945],\n",
      "        [3.6779, 3.6995, 3.7279, 3.7986, 3.5336],\n",
      "        [3.3710, 3.5345, 3.5535, 3.6464, 3.5748],\n",
      "        [3.4937, 3.5164, 3.6868, 3.7284, 3.6165],\n",
      "        [3.5510, 3.8786, 3.7210, 3.8956, 3.8230],\n",
      "        [3.4184, 3.5334, 3.6034, 3.6516, 3.5538],\n",
      "        [3.6637, 3.6163, 3.7307, 3.7429, 3.6783],\n",
      "        [3.3664, 3.5112, 3.5043, 3.5504, 3.5249],\n",
      "        [3.6911, 3.6506, 3.7503, 3.8666, 3.7046],\n",
      "        [3.4450, 3.4555, 3.5561, 3.6782, 3.5233],\n",
      "        [3.5770, 3.7187, 3.7342, 3.7867, 3.8338],\n",
      "        [3.4121, 3.6540, 3.7543, 3.6820, 3.6666],\n",
      "        [3.5640, 3.6755, 3.8527, 3.8403, 3.8282],\n",
      "        [3.6644, 3.7612, 3.7119, 3.8535, 3.8825],\n",
      "        [3.7124, 3.7171, 3.7627, 3.8343, 3.5943],\n",
      "        [3.9981, 4.0444, 4.0082, 4.3471, 4.0934],\n",
      "        [3.5491, 3.8198, 3.7226, 3.7729, 3.5790],\n",
      "        [3.5607, 3.5619, 3.7364, 3.7997, 3.6817],\n",
      "        [3.4826, 3.5560, 3.6442, 3.7611, 3.6278],\n",
      "        [3.5312, 3.5853, 3.5649, 3.7267, 3.7093],\n",
      "        [3.6850, 3.7688, 3.7057, 3.7485, 3.7237],\n",
      "        [3.8826, 3.9583, 3.8900, 4.0432, 4.0189]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7037, 3.8507, 3.7286, 4.0352, 3.8441],\n",
      "        [3.4914, 3.4395, 3.5285, 3.6792, 3.5044],\n",
      "        [3.5696, 3.6513, 3.6030, 3.8451, 3.6910],\n",
      "        [3.6862, 3.6446, 3.6901, 3.9834, 3.7861],\n",
      "        [3.4496, 3.5506, 3.6386, 3.6968, 3.5620],\n",
      "        [3.7873, 3.9123, 3.8465, 3.8406, 3.8645],\n",
      "        [3.5627, 3.8232, 3.6570, 3.6355, 3.7511],\n",
      "        [3.6367, 3.6706, 3.6988, 3.8365, 3.7942],\n",
      "        [3.4153, 3.6286, 3.6392, 3.6708, 3.5968],\n",
      "        [3.4108, 3.5306, 3.5923, 3.6455, 3.5480],\n",
      "        [3.7268, 3.7241, 3.9293, 3.8600, 3.6429],\n",
      "        [3.5768, 3.6947, 3.5616, 3.8283, 3.6740],\n",
      "        [3.5913, 3.5791, 3.7502, 3.8227, 3.7494],\n",
      "        [3.3800, 3.3919, 3.5223, 3.6631, 3.5023],\n",
      "        [3.5669, 3.5787, 3.7003, 3.7299, 3.6567],\n",
      "        [3.5869, 3.8349, 3.7494, 3.8175, 3.5980],\n",
      "        [3.7348, 3.6711, 3.7252, 4.1175, 3.8954],\n",
      "        [3.5368, 3.6437, 3.5470, 3.7473, 3.6491],\n",
      "        [3.7278, 3.6623, 3.8179, 4.0804, 3.7363],\n",
      "        [3.8381, 3.8088, 3.8986, 4.1706, 3.8040],\n",
      "        [3.5838, 3.7550, 3.6648, 3.7957, 3.7449],\n",
      "        [3.7215, 3.9122, 3.7809, 3.9292, 3.8279],\n",
      "        [3.4331, 3.5873, 3.6583, 3.6881, 3.5904],\n",
      "        [3.5912, 3.5971, 3.7359, 3.8174, 3.7141],\n",
      "        [3.4554, 3.4631, 3.5584, 3.6845, 3.5318],\n",
      "        [3.4798, 3.6078, 3.5369, 3.6907, 3.6051],\n",
      "        [3.9186, 3.8833, 3.9193, 4.2130, 3.9749],\n",
      "        [3.6808, 3.9424, 3.7955, 3.9402, 3.8395],\n",
      "        [3.8449, 3.8344, 3.8874, 4.0916, 3.8848],\n",
      "        [3.6072, 3.5025, 3.6958, 3.9427, 3.6026],\n",
      "        [3.9873, 3.9222, 3.9010, 4.2757, 4.0611],\n",
      "        [3.5557, 3.6668, 3.5574, 3.7955, 3.6564],\n",
      "        [3.9484, 3.7736, 3.9187, 4.4496, 4.2129],\n",
      "        [3.5597, 3.6778, 3.5531, 3.8041, 3.6586],\n",
      "        [3.4245, 3.5069, 3.5845, 3.6529, 3.5448],\n",
      "        [3.7126, 3.7525, 3.8453, 3.8591, 3.6189],\n",
      "        [3.5685, 3.6204, 3.7800, 3.9094, 3.8767],\n",
      "        [3.5022, 3.5605, 3.6647, 3.7532, 3.6461],\n",
      "        [3.5651, 3.6089, 3.6882, 3.7920, 3.6929],\n",
      "        [3.3822, 3.5308, 3.5199, 3.5742, 3.5477],\n",
      "        [3.6040, 3.7745, 3.6978, 3.7978, 3.7606],\n",
      "        [3.5629, 3.7336, 3.7526, 3.8162, 3.6339],\n",
      "        [3.5418, 3.6352, 3.6263, 3.7273, 3.6729],\n",
      "        [3.4526, 3.6902, 3.8254, 3.7515, 3.7464],\n",
      "        [3.6206, 3.5455, 3.6462, 3.7366, 3.7132],\n",
      "        [3.8086, 4.0030, 3.8198, 4.0517, 4.0149],\n",
      "        [3.6580, 3.6305, 3.7289, 3.7556, 3.6265],\n",
      "        [3.5535, 3.6692, 3.5514, 3.8005, 3.6539],\n",
      "        [3.5610, 3.7663, 3.7116, 3.7324, 3.7541],\n",
      "        [3.4584, 3.5760, 3.5256, 3.6586, 3.5789],\n",
      "        [3.6178, 3.5588, 3.6843, 3.7991, 3.6390],\n",
      "        [3.4548, 3.5565, 3.6461, 3.6949, 3.5750],\n",
      "        [3.5398, 3.6316, 3.5819, 3.7764, 3.6299],\n",
      "        [3.6659, 3.8021, 3.7748, 3.8535, 3.6430],\n",
      "        [3.4862, 3.6684, 3.6768, 3.8648, 3.5777],\n",
      "        [3.4732, 3.7363, 3.6906, 3.7832, 3.8378],\n",
      "        [3.8505, 3.7145, 3.7477, 3.9417, 3.9020],\n",
      "        [3.5337, 3.6860, 3.6694, 3.8400, 3.7146],\n",
      "        [3.5446, 3.6770, 3.7170, 3.8785, 3.6575],\n",
      "        [3.5473, 3.5920, 3.6765, 3.6443, 3.4618],\n",
      "        [3.5589, 3.5728, 3.6778, 3.7571, 3.6641],\n",
      "        [3.6239, 3.8633, 3.6503, 3.8405, 3.7241],\n",
      "        [3.4192, 3.5538, 3.5268, 3.6201, 3.5825],\n",
      "        [3.4097, 3.5480, 3.6010, 3.6457, 3.5532]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4161, 3.5684, 3.5406, 3.6200, 3.5813],\n",
      "        [3.4693, 3.4175, 3.6485, 3.5084, 3.6652],\n",
      "        [3.5320, 3.5139, 3.6649, 3.7257, 3.6205],\n",
      "        [3.5537, 3.7425, 3.7621, 3.8209, 3.6268],\n",
      "        [3.4533, 3.4483, 3.5506, 3.6828, 3.5207],\n",
      "        [3.5634, 3.7423, 3.7334, 3.8148, 3.6603],\n",
      "        [3.5765, 3.9372, 3.7132, 3.9666, 3.8463],\n",
      "        [3.6745, 3.7737, 3.7289, 3.8754, 3.8877],\n",
      "        [3.9976, 4.1201, 3.9025, 4.0020, 3.9178],\n",
      "        [3.7247, 3.8039, 3.8390, 3.9656, 3.7517],\n",
      "        [3.7626, 3.8626, 3.7485, 3.9894, 3.8909],\n",
      "        [3.6533, 3.6260, 3.6988, 3.7197, 3.5313],\n",
      "        [3.7001, 3.8498, 3.7263, 4.0348, 3.8408],\n",
      "        [3.5415, 3.6357, 3.5771, 3.7550, 3.6660],\n",
      "        [3.5753, 3.6919, 3.5545, 3.8240, 3.6663],\n",
      "        [3.2450, 3.4303, 3.5258, 3.5214, 3.4945],\n",
      "        [3.5613, 3.6776, 3.5495, 3.8208, 3.6625],\n",
      "        [3.5497, 3.6614, 3.5458, 3.7887, 3.6469],\n",
      "        [3.5897, 3.6355, 3.7609, 3.8178, 3.8083],\n",
      "        [3.5603, 3.6498, 3.5888, 3.7752, 3.6875],\n",
      "        [3.7499, 3.8268, 3.8353, 3.8625, 3.8219],\n",
      "        [3.9598, 3.9032, 3.8593, 4.1490, 4.0256],\n",
      "        [3.6462, 3.8168, 3.7308, 3.9162, 3.7365],\n",
      "        [3.6540, 3.8123, 3.7327, 3.7885, 3.8067],\n",
      "        [4.0266, 3.7830, 3.9805, 4.5282, 4.2930],\n",
      "        [3.6972, 3.6758, 3.7535, 3.7975, 3.6420],\n",
      "        [3.9296, 3.8880, 3.9250, 4.2011, 3.9573],\n",
      "        [3.5849, 3.5983, 3.7161, 3.8103, 3.7078],\n",
      "        [3.4934, 3.4478, 3.5297, 3.6861, 3.5116],\n",
      "        [3.6220, 3.7954, 3.7013, 3.7937, 3.7723],\n",
      "        [3.5555, 3.7364, 3.6590, 3.8057, 3.7398],\n",
      "        [3.5766, 3.5794, 3.7247, 3.7992, 3.6982],\n",
      "        [3.7330, 3.7686, 3.8121, 3.9797, 3.9579],\n",
      "        [3.4125, 3.6677, 3.4904, 3.7251, 3.5321],\n",
      "        [3.8099, 3.7920, 3.8016, 3.9440, 3.8971],\n",
      "        [3.4480, 3.6228, 3.5225, 3.7313, 3.5878],\n",
      "        [3.7022, 3.8522, 3.7276, 4.0362, 3.8443],\n",
      "        [3.7948, 3.9503, 3.9367, 3.9703, 3.7058],\n",
      "        [3.7162, 3.8285, 3.8242, 3.8794, 3.6552],\n",
      "        [3.8374, 3.8242, 3.8741, 4.0861, 3.8700],\n",
      "        [3.7844, 3.7853, 3.8503, 4.0402, 3.8379],\n",
      "        [3.4283, 3.5682, 3.5305, 3.6244, 3.5752],\n",
      "        [3.5810, 3.5862, 3.7452, 3.7885, 3.7179],\n",
      "        [3.6495, 3.4966, 3.8066, 3.8491, 3.7275],\n",
      "        [3.6341, 3.6078, 3.7817, 3.8854, 3.7480],\n",
      "        [3.5065, 3.5471, 3.6744, 3.7479, 3.6404],\n",
      "        [3.5671, 3.6219, 3.7789, 3.9104, 3.8771],\n",
      "        [3.5054, 3.6239, 3.5340, 3.7172, 3.6176],\n",
      "        [3.7022, 3.8522, 3.7276, 4.0362, 3.8443],\n",
      "        [3.4045, 3.4663, 3.5622, 3.6277, 3.5076],\n",
      "        [3.5608, 3.6772, 3.5476, 3.8056, 3.6572],\n",
      "        [3.5737, 3.6359, 3.6612, 3.9161, 3.7120],\n",
      "        [3.9379, 3.8209, 3.9117, 4.1027, 3.9953],\n",
      "        [3.7841, 3.8842, 3.7666, 3.9413, 3.9302],\n",
      "        [3.5331, 3.8275, 3.7189, 3.7648, 3.5751],\n",
      "        [3.6673, 3.9292, 3.7788, 3.9279, 3.8248],\n",
      "        [3.5645, 3.6262, 3.6817, 3.7676, 3.8213],\n",
      "        [3.5419, 3.5868, 3.6701, 3.6373, 3.4583],\n",
      "        [3.4939, 3.5645, 3.6561, 3.7551, 3.6420],\n",
      "        [3.7356, 3.6882, 3.7141, 4.0898, 3.8785],\n",
      "        [3.2599, 3.4346, 3.5263, 3.5391, 3.5218],\n",
      "        [3.9009, 3.8710, 3.9045, 4.1972, 3.9662],\n",
      "        [3.6717, 3.6538, 3.7459, 3.7807, 3.6313],\n",
      "        [3.4175, 3.5501, 3.5177, 3.6160, 3.5561]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6014, 3.6953, 3.6982, 3.8219, 3.8088],\n",
      "        [3.8709, 3.7924, 3.7782, 3.9892, 3.8857],\n",
      "        [3.5704, 3.8045, 3.7205, 3.9346, 3.6756],\n",
      "        [3.8802, 3.7212, 3.7463, 3.9796, 3.8986],\n",
      "        [3.9185, 4.0230, 3.7382, 3.9297, 3.8017],\n",
      "        [3.5694, 3.7391, 3.7542, 3.8234, 3.6386],\n",
      "        [4.0411, 3.9339, 3.9874, 4.2881, 4.0855],\n",
      "        [3.4039, 3.5392, 3.5193, 3.6014, 3.5488],\n",
      "        [3.7443, 3.6776, 3.7193, 3.7878, 3.6478],\n",
      "        [3.6220, 3.5374, 3.7128, 3.9524, 3.6114],\n",
      "        [3.5623, 3.6687, 3.6351, 3.8194, 3.7711],\n",
      "        [3.8885, 3.8681, 3.8384, 4.2204, 3.9364],\n",
      "        [3.4340, 3.6741, 3.6628, 3.6911, 3.6364],\n",
      "        [3.8128, 3.9170, 3.9610, 4.1769, 4.1819],\n",
      "        [3.7184, 3.8293, 3.8651, 3.9613, 3.8638],\n",
      "        [3.5689, 3.9401, 3.8596, 3.8669, 3.7208],\n",
      "        [3.4194, 3.6488, 3.6453, 3.6778, 3.6102],\n",
      "        [3.4561, 3.4995, 3.5929, 3.6866, 3.5320],\n",
      "        [3.3955, 3.5430, 3.5151, 3.5969, 3.5536],\n",
      "        [3.8004, 4.0159, 3.8536, 4.0766, 4.0040],\n",
      "        [3.8313, 3.8009, 3.8062, 3.9725, 3.9043],\n",
      "        [3.4247, 3.5312, 3.5946, 3.6622, 3.5645],\n",
      "        [3.6446, 3.6458, 3.8015, 3.9036, 3.7081],\n",
      "        [3.5664, 3.6882, 3.5645, 3.8203, 3.6690],\n",
      "        [3.9270, 3.8286, 3.8499, 4.1623, 3.9311],\n",
      "        [3.7014, 3.7416, 3.7821, 3.9419, 3.9313],\n",
      "        [3.4571, 3.4970, 3.4707, 3.7168, 3.5050],\n",
      "        [3.7324, 3.7883, 3.8371, 3.9643, 3.7222],\n",
      "        [3.6535, 3.6260, 3.7268, 3.7515, 3.6419],\n",
      "        [3.6003, 3.7629, 3.6262, 3.7686, 3.7063],\n",
      "        [3.5498, 3.5406, 3.6821, 3.7366, 3.6446],\n",
      "        [3.9342, 3.9273, 3.8747, 4.2404, 3.8628],\n",
      "        [3.4373, 3.7352, 3.5578, 3.5300, 3.6676],\n",
      "        [3.4141, 3.6011, 3.6222, 3.6617, 3.5827],\n",
      "        [3.5863, 3.9652, 3.7304, 3.9893, 3.8558],\n",
      "        [3.4050, 3.5682, 3.6058, 3.6478, 3.5568],\n",
      "        [3.6732, 3.6395, 3.7381, 3.8435, 3.7014],\n",
      "        [3.6986, 3.8513, 3.7252, 4.0353, 3.8404],\n",
      "        [3.8120, 3.9116, 3.9540, 4.1803, 4.1738],\n",
      "        [3.8279, 3.9894, 3.8082, 3.8646, 3.7894],\n",
      "        [3.4028, 3.4369, 3.5409, 3.6491, 3.5320],\n",
      "        [3.4567, 3.6194, 3.5691, 3.7715, 3.5820],\n",
      "        [3.3607, 3.5103, 3.4080, 3.6451, 3.4851],\n",
      "        [3.7357, 3.7644, 3.9786, 3.8411, 3.6835],\n",
      "        [3.5407, 3.5882, 3.6690, 3.6378, 3.4580],\n",
      "        [3.8426, 3.9145, 3.8128, 4.0159, 3.9664],\n",
      "        [3.7201, 3.8217, 3.8362, 3.9594, 3.7804],\n",
      "        [3.4558, 3.5787, 3.5236, 3.6599, 3.5787],\n",
      "        [3.5908, 3.5619, 3.7352, 3.8303, 3.7807],\n",
      "        [3.3626, 3.5153, 3.5014, 3.5524, 3.5242],\n",
      "        [3.4008, 3.5500, 3.5172, 3.5989, 3.5549],\n",
      "        [3.5794, 3.5867, 3.6952, 3.7729, 3.7135],\n",
      "        [3.5408, 3.5158, 3.6947, 3.6388, 3.7074],\n",
      "        [3.4430, 3.4879, 3.5743, 3.6717, 3.5415],\n",
      "        [3.5597, 3.8262, 3.6547, 3.6371, 3.7509],\n",
      "        [3.6877, 3.8069, 3.7134, 3.8632, 3.8710],\n",
      "        [3.4443, 3.4731, 3.5638, 3.6746, 3.5314],\n",
      "        [3.7747, 3.8443, 3.8629, 4.0073, 3.9889],\n",
      "        [3.7765, 3.6246, 3.7000, 3.8549, 3.7955],\n",
      "        [3.3264, 3.4897, 3.5545, 3.5969, 3.5553],\n",
      "        [3.9426, 3.8988, 3.7810, 4.1222, 4.0951],\n",
      "        [3.9136, 3.9250, 3.8820, 4.1895, 3.9809],\n",
      "        [3.5234, 3.6958, 3.6694, 3.6645, 3.6080],\n",
      "        [3.7421, 3.8329, 3.7587, 3.9050, 3.8812]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4574, 3.7953, 3.6917, 3.6210, 3.7707],\n",
      "        [3.5725, 3.5958, 3.6983, 3.7874, 3.6943],\n",
      "        [3.5761, 3.9404, 3.7168, 3.9674, 3.8454],\n",
      "        [3.8355, 3.8404, 3.9107, 4.0407, 4.0358],\n",
      "        [3.5387, 3.6546, 3.5451, 3.7822, 3.6436],\n",
      "        [3.4763, 3.6416, 3.5710, 3.7957, 3.5888],\n",
      "        [3.6715, 3.6630, 3.6898, 3.9549, 3.7829],\n",
      "        [3.4316, 3.5909, 3.6605, 3.6895, 3.5893],\n",
      "        [3.5207, 3.6529, 3.8354, 3.8041, 3.8001],\n",
      "        [3.3275, 3.4908, 3.5587, 3.5970, 3.5547],\n",
      "        [3.6620, 3.8341, 3.6968, 3.8573, 3.7655],\n",
      "        [3.7256, 3.8981, 3.8449, 3.9540, 3.8116],\n",
      "        [3.4789, 3.6061, 3.5434, 3.6790, 3.6187],\n",
      "        [3.7556, 4.0629, 3.8349, 4.1108, 3.9909],\n",
      "        [3.5971, 3.5843, 3.7481, 3.8554, 3.7040],\n",
      "        [3.7497, 3.7516, 3.7570, 3.9749, 3.9164],\n",
      "        [3.4979, 3.4514, 3.6757, 3.5443, 3.6892],\n",
      "        [3.6098, 3.6837, 3.6980, 3.7919, 3.7088],\n",
      "        [3.7946, 3.9529, 3.9403, 3.9709, 3.7047],\n",
      "        [3.7020, 3.8548, 3.7313, 4.0368, 3.8434],\n",
      "        [3.5177, 3.5736, 3.5493, 3.7129, 3.6940],\n",
      "        [4.0001, 4.0967, 3.7767, 4.0047, 3.8176],\n",
      "        [3.7498, 3.8484, 3.8591, 3.9072, 3.6797],\n",
      "        [3.4380, 3.5427, 3.6057, 3.6665, 3.5773],\n",
      "        [3.5676, 3.7094, 3.7262, 3.7827, 3.8080],\n",
      "        [3.6889, 3.8703, 3.8452, 3.9545, 3.8802],\n",
      "        [3.6183, 3.9606, 3.7519, 4.0035, 3.8755],\n",
      "        [3.8480, 3.8225, 3.8789, 4.0521, 3.7623],\n",
      "        [3.6410, 3.7098, 3.6499, 3.8574, 3.7412],\n",
      "        [3.5262, 3.7049, 3.6946, 3.7684, 3.7070],\n",
      "        [3.4331, 3.5777, 3.5323, 3.6468, 3.5748],\n",
      "        [3.7208, 3.5075, 3.5902, 3.7779, 3.7143],\n",
      "        [3.5585, 3.6134, 3.6893, 3.7985, 3.6743],\n",
      "        [3.6837, 3.8111, 3.7171, 3.8593, 3.8760],\n",
      "        [3.6082, 3.7846, 3.6948, 3.7992, 3.7673],\n",
      "        [3.4226, 3.6613, 3.6620, 3.6712, 3.6080],\n",
      "        [3.7948, 3.8941, 3.7793, 3.9432, 3.9333],\n",
      "        [3.6482, 3.6666, 3.6499, 3.8963, 3.7385],\n",
      "        [3.9617, 3.8948, 3.8692, 4.1197, 4.0011],\n",
      "        [3.4292, 3.4925, 3.5780, 3.6597, 3.5370],\n",
      "        [3.5033, 3.5637, 3.5364, 3.7003, 3.6831],\n",
      "        [3.7622, 3.8650, 3.7517, 3.9900, 3.8898],\n",
      "        [3.6365, 3.7557, 3.7079, 3.8794, 3.7804],\n",
      "        [3.4388, 3.7814, 3.6749, 3.6009, 3.7461],\n",
      "        [3.7838, 3.8872, 3.7706, 3.9422, 3.9293],\n",
      "        [4.0646, 4.1846, 3.9458, 4.0637, 3.9423],\n",
      "        [3.8049, 3.8687, 3.8761, 4.0080, 4.0425],\n",
      "        [3.5487, 3.6093, 3.6863, 3.7843, 3.6710],\n",
      "        [3.6428, 3.5858, 3.9305, 3.8761, 3.8160],\n",
      "        [3.5045, 3.5912, 3.5757, 3.7791, 3.6322],\n",
      "        [3.6762, 3.9894, 3.8837, 3.9718, 3.9805],\n",
      "        [3.9282, 3.8299, 3.8543, 4.1626, 3.9306],\n",
      "        [3.7506, 3.7878, 3.8211, 3.9070, 3.9066],\n",
      "        [3.4445, 3.5246, 3.6142, 3.6852, 3.5364],\n",
      "        [3.4554, 3.5483, 3.5143, 3.7246, 3.5655],\n",
      "        [3.6038, 3.7935, 3.7177, 3.8907, 3.6941],\n",
      "        [3.7547, 3.8229, 3.8706, 4.0679, 3.7845],\n",
      "        [3.6399, 3.7460, 3.8641, 3.8904, 3.8054],\n",
      "        [3.6111, 3.9218, 3.7125, 3.8480, 3.9073],\n",
      "        [3.5480, 3.5971, 3.6795, 3.7684, 3.6607],\n",
      "        [3.5608, 3.6816, 3.8536, 3.8430, 3.8272],\n",
      "        [3.4934, 3.6189, 3.5315, 3.7197, 3.6018],\n",
      "        [3.5533, 3.5611, 3.6179, 3.7119, 3.7061],\n",
      "        [3.7210, 3.8636, 3.8231, 3.9740, 3.8066]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6006, 3.8077, 3.7322, 3.9103, 3.6807],\n",
      "        [3.5480, 3.5835, 3.6719, 3.7546, 3.6532],\n",
      "        [3.4287, 3.5730, 3.5371, 3.6256, 3.5742],\n",
      "        [4.1045, 4.2183, 3.8994, 4.0593, 3.8598],\n",
      "        [3.9714, 3.8639, 3.9911, 4.2258, 3.9825],\n",
      "        [3.6144, 3.5753, 3.7060, 3.7968, 3.6870],\n",
      "        [3.7025, 3.8574, 3.7353, 4.0374, 3.8435],\n",
      "        [3.9862, 3.9307, 3.9100, 4.2792, 4.0610],\n",
      "        [3.7836, 3.9017, 3.9006, 4.0111, 4.0254],\n",
      "        [3.5557, 3.7805, 3.7329, 3.7255, 3.7600],\n",
      "        [3.9600, 3.8353, 3.9431, 4.2403, 4.0250],\n",
      "        [3.4413, 3.4852, 3.5735, 3.6727, 3.5376],\n",
      "        [3.4991, 3.8245, 3.6944, 3.7166, 3.5657],\n",
      "        [3.7507, 3.5415, 3.5995, 3.7552, 3.7777],\n",
      "        [3.4925, 3.5369, 3.6903, 3.7368, 3.6281],\n",
      "        [3.5211, 3.6556, 3.8390, 3.8048, 3.8002],\n",
      "        [3.6216, 3.6399, 3.7852, 3.8707, 3.6895],\n",
      "        [3.5503, 3.6562, 3.6313, 3.8043, 3.7649],\n",
      "        [3.5602, 3.5808, 3.7452, 3.8057, 3.6971],\n",
      "        [3.5130, 3.4791, 3.6444, 3.7315, 3.6639],\n",
      "        [3.4464, 3.5202, 3.5030, 3.7152, 3.4763],\n",
      "        [3.3517, 3.5001, 3.4983, 3.5386, 3.5118],\n",
      "        [3.5536, 3.5640, 3.6077, 3.8118, 3.5979],\n",
      "        [3.9730, 3.9186, 3.8284, 4.1463, 4.0777],\n",
      "        [3.6298, 3.5808, 3.7038, 3.7773, 3.7353],\n",
      "        [3.4461, 3.5158, 3.5025, 3.7159, 3.4879],\n",
      "        [3.4179, 3.5548, 3.5243, 3.6172, 3.5551],\n",
      "        [3.3644, 3.5187, 3.5088, 3.5531, 3.5236],\n",
      "        [3.6801, 3.8150, 3.7049, 3.8709, 3.7758],\n",
      "        [3.4512, 3.6971, 3.8309, 3.7540, 3.7460],\n",
      "        [3.3762, 3.5285, 3.5137, 3.5732, 3.5344],\n",
      "        [4.0110, 4.0945, 3.7591, 3.9909, 3.7897],\n",
      "        [3.6670, 3.5179, 3.8413, 3.8603, 3.7378],\n",
      "        [3.9593, 3.9068, 3.8710, 4.1527, 4.0214],\n",
      "        [3.5542, 3.5717, 3.6897, 3.7798, 3.7265],\n",
      "        [3.4372, 3.4693, 3.5633, 3.6725, 3.5234],\n",
      "        [3.6213, 3.5708, 3.7030, 3.7971, 3.6700],\n",
      "        [4.1476, 4.2965, 3.9639, 4.1388, 3.9189],\n",
      "        [3.4694, 3.6414, 3.7446, 3.7514, 3.7264],\n",
      "        [3.7812, 3.8640, 3.8590, 3.9826, 4.0102],\n",
      "        [3.3290, 3.4744, 3.4833, 3.5105, 3.4807],\n",
      "        [3.7846, 3.7912, 3.8577, 4.0418, 3.8371],\n",
      "        [3.5532, 3.5587, 3.6905, 3.7494, 3.6447],\n",
      "        [3.4081, 3.5909, 3.6217, 3.6507, 3.5629],\n",
      "        [3.5855, 3.8424, 3.7564, 3.8200, 3.5971],\n",
      "        [3.6417, 3.9094, 3.8390, 3.8958, 3.7294],\n",
      "        [3.5796, 3.5612, 3.7297, 3.8123, 3.7748],\n",
      "        [3.5462, 3.8295, 3.7288, 3.7760, 3.5777],\n",
      "        [3.4496, 3.8548, 3.6324, 3.6847, 3.7487],\n",
      "        [3.5678, 3.7269, 3.6096, 3.9133, 3.6254],\n",
      "        [3.6440, 3.7152, 3.7968, 3.8594, 3.7602],\n",
      "        [3.6479, 3.7820, 3.6800, 3.8709, 3.7615],\n",
      "        [3.9543, 4.1129, 4.0932, 4.2647, 4.2778],\n",
      "        [3.6935, 3.8092, 3.7211, 3.9273, 3.7811],\n",
      "        [3.5808, 3.6881, 3.6947, 3.9057, 3.7020],\n",
      "        [3.6245, 3.6528, 3.6990, 3.8714, 3.7064],\n",
      "        [4.0535, 3.9636, 3.9564, 4.3046, 4.1175],\n",
      "        [3.8827, 3.9184, 3.8376, 4.0377, 4.0010],\n",
      "        [3.5816, 3.9351, 3.7616, 3.9527, 3.8652],\n",
      "        [3.5487, 3.5150, 3.6437, 3.6769, 3.5797],\n",
      "        [4.0536, 4.0548, 3.9655, 4.3807, 3.9477],\n",
      "        [3.9799, 3.7408, 3.8820, 4.3865, 4.2219],\n",
      "        [3.4999, 3.8184, 3.6948, 3.7197, 3.5557],\n",
      "        [3.9604, 3.9090, 3.7934, 4.1210, 4.0855]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3784, 3.4290, 3.5372, 3.5796, 3.4633],\n",
      "        [3.7291, 3.8242, 3.8280, 3.8332, 3.8052],\n",
      "        [3.6093, 3.7895, 3.7019, 3.8008, 3.7670],\n",
      "        [3.4709, 3.6020, 3.5446, 3.6850, 3.6077],\n",
      "        [3.4557, 3.4636, 3.5656, 3.7012, 3.5407],\n",
      "        [3.7791, 3.8314, 3.8377, 3.9660, 3.9999],\n",
      "        [3.4070, 3.5738, 3.6166, 3.6492, 3.5557],\n",
      "        [3.5562, 3.7445, 3.6705, 3.8082, 3.7384],\n",
      "        [3.5605, 3.5829, 3.7486, 3.8066, 3.6969],\n",
      "        [3.7121, 3.9283, 3.8753, 3.9898, 3.9419],\n",
      "        [3.7785, 3.9698, 3.8066, 3.8087, 3.8120],\n",
      "        [3.5684, 3.6939, 3.5765, 3.8218, 3.6683],\n",
      "        [3.6756, 3.8345, 3.7113, 4.0015, 3.8004],\n",
      "        [3.8566, 3.8788, 3.9450, 4.0612, 4.0675],\n",
      "        [3.5479, 3.6673, 3.5624, 3.7905, 3.6533],\n",
      "        [3.4880, 3.6916, 3.5552, 3.7811, 3.5729],\n",
      "        [3.8784, 3.8766, 3.8553, 4.2258, 3.9366],\n",
      "        [3.5850, 3.5934, 3.7455, 3.8261, 3.7265],\n",
      "        [3.4322, 3.5006, 3.5864, 3.6611, 3.5410],\n",
      "        [3.9029, 3.9125, 3.8340, 4.0490, 4.0198],\n",
      "        [3.6497, 3.7004, 3.7195, 3.9414, 3.7211],\n",
      "        [3.5346, 3.6050, 3.5973, 3.6869, 3.6366],\n",
      "        [3.5516, 3.5643, 3.6857, 3.7544, 3.6447],\n",
      "        [3.5545, 3.5739, 3.6931, 3.7807, 3.7262],\n",
      "        [3.3766, 3.5305, 3.5167, 3.5740, 3.5340],\n",
      "        [3.5678, 3.6353, 3.6125, 3.7649, 3.7437],\n",
      "        [3.4915, 3.6139, 3.5333, 3.7062, 3.5928],\n",
      "        [3.6102, 3.6977, 3.7113, 3.8007, 3.8094],\n",
      "        [4.1773, 4.3746, 3.9629, 4.1753, 3.9470],\n",
      "        [3.5448, 3.6692, 3.5578, 3.7827, 3.6468],\n",
      "        [3.9264, 3.8884, 3.9315, 4.1935, 3.9439],\n",
      "        [3.7609, 3.6160, 3.7162, 3.8444, 3.7607],\n",
      "        [3.7371, 3.7706, 3.9911, 3.8426, 3.6821],\n",
      "        [3.5642, 3.5318, 3.6836, 3.7719, 3.7564],\n",
      "        [3.9223, 3.8837, 3.9222, 4.1802, 3.9404],\n",
      "        [3.4182, 3.5568, 3.5274, 3.6179, 3.5547],\n",
      "        [3.7441, 3.9185, 3.7378, 3.8719, 3.7992],\n",
      "        [3.4645, 3.5935, 3.6955, 3.7961, 3.6760],\n",
      "        [3.7787, 3.7574, 3.8475, 4.0966, 3.7317],\n",
      "        [3.7034, 3.8619, 3.8206, 4.0352, 3.7984],\n",
      "        [3.4112, 3.4779, 3.5390, 3.6199, 3.5339],\n",
      "        [3.4399, 3.8540, 3.7803, 3.7772, 3.8534],\n",
      "        [3.5514, 3.5893, 3.6830, 3.7724, 3.6569],\n",
      "        [3.4712, 3.5867, 3.6783, 3.7303, 3.5667],\n",
      "        [3.7437, 3.7881, 3.8334, 3.9895, 3.9658],\n",
      "        [3.7116, 3.7132, 3.8693, 3.8585, 3.5515],\n",
      "        [3.7057, 3.9596, 3.9086, 3.9563, 3.9070],\n",
      "        [3.4994, 3.6735, 3.5934, 3.8240, 3.5986],\n",
      "        [3.4089, 3.6258, 3.6398, 3.6557, 3.5784],\n",
      "        [3.6952, 3.8339, 3.7436, 3.9000, 3.7638],\n",
      "        [3.2453, 3.4375, 3.5358, 3.5233, 3.4930],\n",
      "        [3.8354, 3.8067, 3.8178, 3.9748, 3.9041],\n",
      "        [3.5904, 3.8321, 3.7510, 3.8106, 3.5960],\n",
      "        [3.5631, 3.5421, 3.7083, 3.7865, 3.7560],\n",
      "        [3.7049, 3.8033, 3.8772, 3.8679, 3.6671],\n",
      "        [3.6124, 3.9284, 3.8496, 3.8828, 3.7073],\n",
      "        [3.5534, 3.6688, 3.5504, 3.7897, 3.6399],\n",
      "        [3.4326, 3.4850, 3.5762, 3.6680, 3.5315],\n",
      "        [3.4385, 3.5652, 3.6436, 3.6939, 3.5572],\n",
      "        [4.0427, 4.1948, 4.1733, 4.3401, 4.3692],\n",
      "        [3.5551, 3.6177, 3.8049, 3.8815, 3.7347],\n",
      "        [3.8948, 3.8953, 3.9392, 4.1476, 3.9477],\n",
      "        [3.5595, 3.7815, 3.6680, 3.7399, 3.7230],\n",
      "        [3.4082, 3.5852, 3.6256, 3.6612, 3.5703]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8120, 3.8644, 3.8856, 3.9818, 3.9531],\n",
      "        [3.4984, 3.8298, 3.7015, 3.7180, 3.5654],\n",
      "        [3.9714, 3.8689, 3.9972, 4.2274, 3.9826],\n",
      "        [3.4870, 3.4566, 3.6271, 3.7043, 3.6560],\n",
      "        [3.5414, 3.7289, 3.7177, 3.7959, 3.6916],\n",
      "        [3.6488, 3.6737, 3.6593, 3.8982, 3.7387],\n",
      "        [3.5473, 3.6392, 3.6822, 3.7819, 3.7758],\n",
      "        [3.5534, 3.7542, 3.7780, 3.8242, 3.6259],\n",
      "        [3.5706, 3.6904, 3.6543, 3.8501, 3.7259],\n",
      "        [3.7190, 3.8712, 3.8281, 3.9627, 3.8056],\n",
      "        [3.8027, 3.7029, 3.7543, 3.9394, 3.8741],\n",
      "        [3.5474, 3.6698, 3.5652, 3.7909, 3.6536],\n",
      "        [3.3147, 3.4921, 3.5694, 3.5823, 3.5574],\n",
      "        [3.4594, 3.5058, 3.4849, 3.7191, 3.5050],\n",
      "        [3.6985, 3.6695, 3.7806, 3.8915, 3.7263],\n",
      "        [3.4647, 3.4975, 3.6741, 3.6973, 3.5969],\n",
      "        [3.6229, 3.8055, 3.7141, 3.7966, 3.7710],\n",
      "        [3.9217, 3.8868, 3.9258, 4.1809, 3.9407],\n",
      "        [3.9980, 4.1299, 3.9156, 4.0049, 3.9169],\n",
      "        [3.9414, 3.8505, 3.8673, 4.0916, 3.9629],\n",
      "        [3.7105, 3.7360, 3.7714, 3.8398, 3.5807],\n",
      "        [3.8051, 3.8766, 3.8872, 4.0103, 4.0425],\n",
      "        [3.5424, 3.6698, 3.5570, 3.7927, 3.6460],\n",
      "        [3.6797, 3.8201, 3.7112, 3.8725, 3.7758],\n",
      "        [3.5007, 3.5749, 3.6787, 3.7570, 3.6460],\n",
      "        [3.4752, 3.6716, 3.6519, 3.6232, 3.5713],\n",
      "        [3.4865, 3.8295, 3.7552, 3.8228, 3.8361],\n",
      "        [3.8960, 3.9123, 3.8410, 4.0641, 4.0151],\n",
      "        [3.4628, 3.5573, 3.6519, 3.7279, 3.5489],\n",
      "        [3.6939, 3.6887, 3.7683, 3.8077, 3.6179],\n",
      "        [3.5267, 3.7125, 3.7044, 3.7705, 3.7068],\n",
      "        [3.5489, 3.6733, 3.5673, 3.7922, 3.6536],\n",
      "        [3.5890, 3.8497, 3.6323, 3.8014, 3.6888],\n",
      "        [3.4024, 3.5717, 3.6203, 3.6504, 3.5528],\n",
      "        [3.9180, 3.7887, 3.8724, 4.4206, 4.1837],\n",
      "        [3.5993, 3.5243, 3.7132, 3.9346, 3.5868],\n",
      "        [3.4654, 3.8179, 3.8183, 3.7955, 3.8458],\n",
      "        [3.7325, 3.7804, 3.8283, 3.9830, 3.9569],\n",
      "        [3.7948, 3.9019, 3.7907, 3.9455, 3.9333],\n",
      "        [3.4233, 3.5329, 3.6088, 3.6593, 3.5506],\n",
      "        [3.6941, 3.7966, 3.7309, 3.7660, 3.7385],\n",
      "        [3.5655, 3.6362, 3.6946, 3.7707, 3.8201],\n",
      "        [3.5625, 3.6991, 3.7216, 3.9380, 3.6632],\n",
      "        [3.6448, 3.8240, 3.7473, 3.9119, 3.7438],\n",
      "        [3.5316, 3.6624, 3.5630, 3.7652, 3.6427],\n",
      "        [3.9245, 3.8495, 3.8943, 4.1610, 3.9636],\n",
      "        [3.7988, 3.8419, 3.9309, 4.1048, 3.8046],\n",
      "        [3.4455, 3.5922, 3.5447, 3.6510, 3.5882],\n",
      "        [3.7001, 3.8599, 3.7405, 4.0373, 3.8399],\n",
      "        [3.7390, 3.6826, 3.7352, 3.7808, 3.6353],\n",
      "        [3.5547, 3.6201, 3.8075, 3.8819, 3.7351],\n",
      "        [3.4452, 3.4525, 3.5548, 3.6764, 3.5138],\n",
      "        [3.4918, 3.5779, 3.4635, 3.7765, 3.5134],\n",
      "        [3.4319, 3.5979, 3.6697, 3.6911, 3.5890],\n",
      "        [3.6762, 3.9129, 3.8577, 3.9270, 3.7668],\n",
      "        [3.4518, 3.6659, 3.5111, 3.7266, 3.5459],\n",
      "        [3.6561, 3.8407, 3.7048, 3.8432, 3.7557],\n",
      "        [3.7336, 3.6732, 3.7322, 3.7716, 3.6215],\n",
      "        [3.7820, 3.8791, 3.9043, 3.9388, 3.7033],\n",
      "        [3.6909, 3.6600, 3.7786, 3.8868, 3.7190],\n",
      "        [3.4628, 3.5825, 3.6524, 3.6335, 3.7180],\n",
      "        [3.7990, 3.9601, 3.9560, 3.9694, 3.7094],\n",
      "        [3.4374, 3.5119, 3.5966, 3.6698, 3.5473],\n",
      "        [3.4460, 3.4813, 3.5778, 3.6766, 3.5308]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8842, 3.6931, 3.7915, 4.3081, 4.0202],\n",
      "        [3.8015, 4.0283, 3.8724, 4.0798, 4.0036],\n",
      "        [3.5440, 3.6011, 3.5988, 3.7965, 3.6224],\n",
      "        [3.4589, 3.7324, 3.7024, 3.7745, 3.8206],\n",
      "        [3.7015, 3.8410, 3.7455, 3.9033, 3.7653],\n",
      "        [3.6115, 3.8509, 3.6977, 3.9565, 3.7757],\n",
      "        [3.7026, 3.9362, 3.7791, 3.9364, 3.8187],\n",
      "        [3.5547, 3.6798, 3.5723, 3.7988, 3.6558],\n",
      "        [3.5622, 3.9419, 3.7244, 3.9731, 3.8250],\n",
      "        [3.6690, 3.6354, 3.8600, 3.9270, 3.7368],\n",
      "        [3.4159, 3.6110, 3.6376, 3.6634, 3.5818],\n",
      "        [3.7242, 3.8658, 3.8103, 3.8099, 3.8051],\n",
      "        [3.3148, 3.4940, 3.5715, 3.5822, 3.5573],\n",
      "        [3.7643, 3.6359, 3.7204, 4.1881, 3.8948],\n",
      "        [3.5337, 3.5923, 3.7962, 3.6457, 3.8013],\n",
      "        [3.4798, 3.8196, 3.7583, 3.8182, 3.8127],\n",
      "        [3.6111, 3.6927, 3.7090, 3.7939, 3.7088],\n",
      "        [3.5431, 3.5789, 3.6733, 3.7518, 3.6489],\n",
      "        [3.7809, 3.8714, 3.8686, 3.9844, 4.0100],\n",
      "        [3.9259, 3.8939, 3.9382, 4.1945, 3.9442],\n",
      "        [3.6521, 3.6263, 3.7399, 3.7398, 3.6590],\n",
      "        [3.7047, 3.8322, 3.7412, 3.9351, 3.7837],\n",
      "        [3.7404, 3.8586, 3.7497, 3.9762, 3.8790],\n",
      "        [3.5387, 3.5838, 3.6730, 3.7536, 3.6487],\n",
      "        [3.5480, 3.7939, 3.7529, 3.7161, 3.7613],\n",
      "        [3.9800, 3.7478, 3.8908, 4.3882, 4.2227],\n",
      "        [3.5511, 3.6018, 3.6922, 3.7786, 3.6610],\n",
      "        [3.5160, 3.6941, 3.6034, 3.8527, 3.6060],\n",
      "        [3.4583, 3.6295, 3.5848, 3.7733, 3.5814],\n",
      "        [3.6479, 3.5947, 3.6946, 3.7677, 3.7395],\n",
      "        [3.6917, 4.0076, 3.8702, 3.9818, 3.9989],\n",
      "        [3.4935, 3.6775, 3.7044, 3.8598, 3.5925],\n",
      "        [3.6457, 3.7046, 3.6566, 3.8772, 3.7423],\n",
      "        [3.2964, 3.4759, 3.5647, 3.5621, 3.5417],\n",
      "        [3.4197, 3.5737, 3.5384, 3.6275, 3.5668],\n",
      "        [3.8277, 3.5769, 3.7709, 4.1536, 4.0375],\n",
      "        [3.6151, 3.6876, 3.7083, 3.7926, 3.7123],\n",
      "        [3.7251, 3.6914, 3.8233, 3.9351, 3.7565],\n",
      "        [3.5681, 3.6984, 3.5817, 3.8222, 3.6685],\n",
      "        [4.2419, 4.3778, 4.0540, 4.2276, 3.9867],\n",
      "        [3.3764, 3.5347, 3.5212, 3.5743, 3.5343],\n",
      "        [3.5345, 3.6093, 3.6020, 3.6872, 3.6369],\n",
      "        [3.5006, 3.7854, 3.7234, 3.8098, 3.8447],\n",
      "        [3.6751, 3.9479, 3.8022, 3.9192, 3.8312],\n",
      "        [3.5553, 3.5524, 3.5937, 3.8276, 3.5717],\n",
      "        [3.4462, 3.5222, 3.5105, 3.7171, 3.4880],\n",
      "        [3.6190, 3.5615, 3.6811, 3.7969, 3.6196],\n",
      "        [3.5216, 3.6510, 3.5523, 3.7600, 3.6229],\n",
      "        [3.9675, 3.8164, 3.9495, 4.2089, 3.9991],\n",
      "        [3.5398, 3.5527, 3.6034, 3.6904, 3.6844],\n",
      "        [3.6526, 3.7181, 3.8047, 3.8687, 3.7208],\n",
      "        [3.5532, 3.5800, 3.6899, 3.7584, 3.6554],\n",
      "        [3.6103, 3.7024, 3.7163, 3.8014, 3.8096],\n",
      "        [3.6321, 3.9869, 3.7593, 4.0155, 3.8757],\n",
      "        [3.7730, 3.9936, 3.8684, 4.0841, 3.9298],\n",
      "        [3.7337, 3.9125, 3.7558, 3.7683, 3.7157],\n",
      "        [3.7289, 3.8288, 3.8332, 3.8337, 3.8054],\n",
      "        [3.5538, 3.5707, 3.6159, 3.8131, 3.5979],\n",
      "        [3.4377, 3.5859, 3.5403, 3.6429, 3.5722],\n",
      "        [3.4657, 3.5143, 3.5999, 3.6920, 3.5774],\n",
      "        [3.3646, 3.5249, 3.5162, 3.5542, 3.5234],\n",
      "        [3.4706, 3.5687, 3.5518, 3.7123, 3.5634],\n",
      "        [3.8028, 3.9142, 3.9715, 4.1703, 4.1659],\n",
      "        [3.6316, 3.8812, 3.7748, 3.9018, 3.8876]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[4.0239, 4.1052, 3.7542, 3.9885, 3.7825],\n",
      "        [3.7034, 3.8659, 3.7463, 4.0383, 3.8431],\n",
      "        [3.6608, 3.8563, 3.7633, 3.9937, 3.7951],\n",
      "        [3.5618, 3.6627, 3.6064, 3.7772, 3.6864],\n",
      "        [3.4317, 3.6678, 3.7651, 3.7084, 3.6850],\n",
      "        [3.8371, 3.8277, 3.9220, 4.1756, 3.8035],\n",
      "        [3.6590, 3.8248, 3.7076, 3.9903, 3.7868],\n",
      "        [3.9418, 3.9092, 3.7988, 4.1225, 4.0933],\n",
      "        [3.7359, 3.8009, 3.8565, 3.9666, 3.7215],\n",
      "        [3.7861, 3.8680, 3.9042, 3.9874, 4.0415],\n",
      "        [3.7492, 3.8772, 3.8346, 3.8250, 3.8229],\n",
      "        [3.7006, 3.7245, 3.7937, 3.8203, 3.8783],\n",
      "        [3.5627, 3.9877, 3.8693, 3.8065, 3.7129],\n",
      "        [3.4385, 3.4773, 3.5732, 3.6733, 3.5229],\n",
      "        [3.4614, 3.5127, 3.4854, 3.7231, 3.4950],\n",
      "        [3.5602, 3.7880, 3.6754, 3.7403, 3.7227],\n",
      "        [3.5651, 3.6624, 3.7058, 3.7597, 3.5788],\n",
      "        [4.0040, 3.9382, 3.9652, 4.2954, 4.0487],\n",
      "        [3.6160, 3.9921, 3.7601, 4.0055, 3.8744],\n",
      "        [3.6736, 3.7050, 3.8473, 3.9080, 3.7347],\n",
      "        [3.4550, 3.5553, 3.6332, 3.6340, 3.5808],\n",
      "        [3.5964, 3.9576, 3.7906, 3.9591, 3.8932],\n",
      "        [3.7095, 3.9267, 3.8795, 3.9781, 3.9418],\n",
      "        [3.5416, 3.6621, 3.5546, 3.7720, 3.6272],\n",
      "        [3.4068, 3.5502, 3.5362, 3.6027, 3.5479],\n",
      "        [3.9224, 3.9857, 4.0362, 4.2640, 4.2420],\n",
      "        [3.4451, 3.4732, 3.5711, 3.6805, 3.5224],\n",
      "        [3.6564, 3.6374, 3.7446, 3.7532, 3.6412],\n",
      "        [3.6330, 3.9887, 3.7614, 4.0153, 3.8754],\n",
      "        [3.6005, 3.6259, 3.7028, 3.8047, 3.7011],\n",
      "        [3.5798, 3.6947, 3.8644, 3.8625, 3.8302],\n",
      "        [3.7202, 3.7327, 3.7896, 3.8356, 3.6157],\n",
      "        [3.6923, 3.8964, 3.8596, 3.9574, 3.8975],\n",
      "        [4.1504, 4.3447, 3.9264, 4.1248, 3.9599],\n",
      "        [3.5483, 3.5796, 3.6842, 3.7535, 3.6518],\n",
      "        [3.3634, 3.5216, 3.4249, 3.6466, 3.4846],\n",
      "        [3.4093, 3.5987, 3.6310, 3.6513, 3.5624],\n",
      "        [3.4931, 3.4899, 3.5968, 3.7065, 3.5355],\n",
      "        [3.7034, 3.7558, 3.8045, 3.9445, 3.9300],\n",
      "        [3.4485, 3.5135, 3.6181, 3.6797, 3.5240],\n",
      "        [4.2285, 4.3673, 4.0196, 4.1894, 3.9732],\n",
      "        [3.5247, 3.6455, 3.5482, 3.7510, 3.6125],\n",
      "        [3.4612, 3.6102, 3.5539, 3.6738, 3.5996],\n",
      "        [3.5549, 3.5619, 3.6043, 3.8239, 3.5851],\n",
      "        [3.5340, 4.0087, 3.8790, 3.8205, 3.7022],\n",
      "        [3.5346, 3.7476, 3.7669, 3.7811, 3.7121],\n",
      "        [3.6057, 3.6223, 3.7784, 3.8393, 3.7402],\n",
      "        [3.7790, 3.9758, 3.8133, 3.8089, 3.8118],\n",
      "        [3.8122, 3.8028, 3.9169, 4.0171, 3.7189],\n",
      "        [3.5690, 3.6999, 3.5836, 3.8219, 3.6682],\n",
      "        [3.6650, 3.4990, 3.8457, 3.8609, 3.7257],\n",
      "        [3.4591, 3.5108, 3.6104, 3.6880, 3.5308],\n",
      "        [3.7949, 3.8961, 3.9365, 3.9407, 3.7222],\n",
      "        [3.6625, 3.8571, 3.7752, 3.8143, 3.8014],\n",
      "        [3.6150, 3.5814, 3.7096, 3.8080, 3.6768],\n",
      "        [3.5102, 3.6382, 3.5614, 3.7406, 3.6270],\n",
      "        [3.5596, 3.6212, 3.6316, 3.8248, 3.6552],\n",
      "        [3.5753, 3.6957, 3.5750, 3.8201, 3.6579],\n",
      "        [3.5988, 3.7059, 3.7164, 3.8833, 3.7493],\n",
      "        [3.7091, 3.7221, 3.7803, 3.8285, 3.6051],\n",
      "        [3.4877, 3.8332, 3.7593, 3.8227, 3.8358],\n",
      "        [3.7451, 3.9749, 3.8408, 4.0488, 3.9064],\n",
      "        [3.4195, 3.5675, 3.5418, 3.6228, 3.5812],\n",
      "        [3.4622, 3.5149, 3.6162, 3.6906, 3.5338]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4849, 3.6221, 3.5518, 3.7044, 3.6011],\n",
      "        [3.7042, 3.8677, 3.7479, 4.0374, 3.8425],\n",
      "        [3.6166, 3.9942, 3.7617, 4.0048, 3.8739],\n",
      "        [4.2440, 4.3812, 4.0574, 4.2263, 3.9859],\n",
      "        [3.5360, 3.9014, 3.7465, 3.9001, 3.8409],\n",
      "        [3.6132, 3.6958, 3.7119, 3.7927, 3.7080],\n",
      "        [3.5117, 3.6385, 3.5529, 3.7245, 3.6242],\n",
      "        [3.3428, 3.4935, 3.4986, 3.5313, 3.5030],\n",
      "        [3.6784, 3.6614, 3.7361, 3.7154, 3.5500],\n",
      "        [3.7053, 3.8634, 3.7399, 4.0268, 3.8283],\n",
      "        [3.4076, 3.5519, 3.5374, 3.6018, 3.5474],\n",
      "        [3.6231, 3.5805, 3.7150, 3.7972, 3.6696],\n",
      "        [3.3550, 3.5970, 3.4365, 3.6631, 3.4684],\n",
      "        [3.7472, 3.8371, 3.8747, 4.0606, 3.7815],\n",
      "        [3.5335, 3.8569, 3.8153, 3.8674, 3.8467],\n",
      "        [3.4585, 3.6479, 3.7504, 3.7464, 3.7204],\n",
      "        [3.4593, 3.4859, 3.5839, 3.6852, 3.5355],\n",
      "        [3.7585, 3.7634, 3.9043, 3.9315, 3.6544],\n",
      "        [3.5908, 3.8555, 3.6381, 3.8006, 3.6880],\n",
      "        [3.5568, 3.8820, 3.8232, 3.8907, 3.8905],\n",
      "        [3.7020, 3.8652, 3.7466, 4.0360, 3.8390],\n",
      "        [3.6162, 3.5850, 3.7181, 3.7969, 3.6865],\n",
      "        [3.7720, 3.7059, 3.7471, 3.8058, 3.6520],\n",
      "        [3.6049, 3.7831, 3.6514, 3.7824, 3.7102],\n",
      "        [3.4815, 3.8231, 3.7615, 3.8171, 3.8119],\n",
      "        [4.1133, 4.2845, 3.9101, 4.0902, 3.9090],\n",
      "        [3.5144, 3.6499, 3.5623, 3.7324, 3.6273],\n",
      "        [4.0607, 3.9839, 4.0316, 4.3303, 4.1034],\n",
      "        [3.5690, 3.5443, 3.7173, 3.7816, 3.7580],\n",
      "        [3.9880, 3.9090, 3.9617, 4.1788, 4.0685],\n",
      "        [3.7210, 3.8527, 3.8571, 3.9568, 3.8114],\n",
      "        [3.6949, 3.8205, 3.7339, 3.9286, 3.7805],\n",
      "        [3.7033, 3.8445, 3.7490, 3.9023, 3.7645],\n",
      "        [3.4624, 3.4818, 3.5800, 3.6915, 3.5326],\n",
      "        [3.4917, 3.4943, 3.6027, 3.7002, 3.5363],\n",
      "        [3.6459, 3.7252, 3.8087, 3.8596, 3.7592],\n",
      "        [3.4424, 3.5914, 3.5446, 3.6551, 3.5800],\n",
      "        [3.5401, 3.6372, 3.6169, 3.7879, 3.6373],\n",
      "        [3.6742, 3.6752, 3.7045, 3.9557, 3.7824],\n",
      "        [3.4262, 3.7818, 3.6783, 3.5903, 3.7396],\n",
      "        [3.4837, 3.5734, 3.6314, 3.6634, 3.6005],\n",
      "        [3.6954, 3.9158, 3.7335, 3.7319, 3.7463],\n",
      "        [3.6578, 3.8464, 3.7106, 3.8424, 3.7549],\n",
      "        [3.4716, 3.6228, 3.7177, 3.7340, 3.5872],\n",
      "        [3.7020, 3.8652, 3.7466, 4.0360, 3.8390],\n",
      "        [3.4312, 3.5845, 3.5473, 3.6297, 3.5799],\n",
      "        [3.3731, 3.5278, 3.5203, 3.5624, 3.5307],\n",
      "        [3.5415, 3.8046, 3.7784, 3.6938, 3.7641],\n",
      "        [3.5037, 3.8725, 3.7493, 3.8412, 3.8601],\n",
      "        [3.6597, 3.8266, 3.7091, 3.9893, 3.7863],\n",
      "        [3.4737, 3.7373, 3.5779, 3.5344, 3.6286],\n",
      "        [3.6838, 3.9425, 3.7516, 3.9162, 3.9674],\n",
      "        [3.5668, 3.5828, 3.7081, 3.7584, 3.6589],\n",
      "        [3.8465, 3.6885, 3.7688, 4.2235, 3.9641],\n",
      "        [3.6285, 3.7872, 3.6931, 3.8679, 3.7308],\n",
      "        [3.5056, 3.5747, 3.6708, 3.7329, 3.6482],\n",
      "        [3.7310, 3.8418, 3.8610, 3.9636, 3.7852],\n",
      "        [3.5051, 3.6720, 3.7287, 3.8204, 3.6048],\n",
      "        [3.7290, 3.8938, 3.8522, 3.9625, 3.8122],\n",
      "        [3.8973, 3.8979, 3.9551, 4.1526, 3.9531],\n",
      "        [3.5976, 3.7892, 3.6859, 3.7591, 3.7323],\n",
      "        [3.5390, 3.7016, 3.7352, 3.8825, 3.6384],\n",
      "        [3.7396, 3.7851, 3.8564, 3.9737, 3.6948],\n",
      "        [3.5514, 3.5653, 3.6960, 3.7508, 3.6377]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7830, 3.8774, 3.8738, 3.9822, 4.0096],\n",
      "        [3.4910, 3.4711, 3.5621, 3.6861, 3.5183],\n",
      "        [3.4844, 3.6601, 3.6103, 3.7116, 3.6598],\n",
      "        [3.5593, 3.5671, 3.7203, 3.7627, 3.6562],\n",
      "        [3.4314, 3.6829, 3.6817, 3.6876, 3.6242],\n",
      "        [3.5614, 3.5226, 3.6542, 3.6708, 3.5744],\n",
      "        [3.5009, 3.4652, 3.6914, 3.5434, 3.6886],\n",
      "        [3.6136, 3.6351, 3.7837, 3.8259, 3.7333],\n",
      "        [3.3896, 3.4490, 3.5568, 3.5930, 3.4730],\n",
      "        [3.4685, 3.7470, 3.7045, 3.7763, 3.8229],\n",
      "        [3.4411, 3.4462, 3.5587, 3.6737, 3.5018],\n",
      "        [3.5678, 3.8315, 3.6523, 3.9039, 3.7405],\n",
      "        [3.6542, 3.6316, 3.7439, 3.7373, 3.6586],\n",
      "        [3.4337, 3.4483, 3.5527, 3.6669, 3.5026],\n",
      "        [3.4736, 3.6164, 3.5475, 3.6804, 3.5975],\n",
      "        [3.7315, 3.8440, 3.8621, 3.9625, 3.7856],\n",
      "        [3.4999, 3.8381, 3.7097, 3.7159, 3.5646],\n",
      "        [3.9406, 3.9018, 3.8988, 4.1591, 3.9808],\n",
      "        [3.7455, 3.9295, 3.7491, 3.8705, 3.7989],\n",
      "        [3.3933, 3.5139, 3.4893, 3.6792, 3.4752],\n",
      "        [3.4510, 3.6655, 3.6789, 3.8328, 3.5460],\n",
      "        [3.7642, 3.8783, 3.7677, 3.9894, 3.8886],\n",
      "        [3.7863, 3.8300, 3.8785, 3.9997, 3.9954],\n",
      "        [3.5420, 3.8066, 3.7792, 3.6926, 3.7643],\n",
      "        [3.4618, 3.5093, 3.4927, 3.7156, 3.4616],\n",
      "        [3.5607, 3.6959, 3.5725, 3.8050, 3.6576],\n",
      "        [3.6345, 3.8846, 3.7244, 3.6922, 3.7796],\n",
      "        [3.4945, 3.5779, 3.4446, 3.7777, 3.4920],\n",
      "        [3.4811, 3.8892, 3.6452, 3.7023, 3.7813],\n",
      "        [3.5579, 3.5209, 3.6520, 3.7465, 3.7524],\n",
      "        [3.5870, 3.5999, 3.7123, 3.7981, 3.7240],\n",
      "        [3.3736, 3.4644, 3.5230, 3.5671, 3.5022],\n",
      "        [3.7046, 3.8698, 3.7490, 4.0362, 3.8430],\n",
      "        [3.6853, 3.8279, 3.7380, 3.8597, 3.8753],\n",
      "        [4.0070, 4.1143, 3.8830, 3.9969, 3.8432],\n",
      "        [3.5364, 3.9035, 3.7475, 3.8990, 3.8413],\n",
      "        [3.7842, 3.8246, 3.8418, 3.9713, 3.9376],\n",
      "        [3.6693, 3.7452, 3.7463, 3.9889, 3.7305],\n",
      "        [3.4977, 3.6348, 3.6329, 3.6136, 3.6044],\n",
      "        [3.4344, 3.5101, 3.5952, 3.6591, 3.5407],\n",
      "        [3.5542, 3.7423, 3.6736, 3.8150, 3.7349],\n",
      "        [3.6018, 3.6297, 3.7053, 3.8026, 3.7010],\n",
      "        [3.9195, 3.8242, 3.8696, 4.0607, 3.9333],\n",
      "        [3.6750, 3.7662, 3.8395, 3.8286, 3.6422],\n",
      "        [3.6736, 3.5352, 3.8533, 3.8614, 3.7397],\n",
      "        [3.6240, 3.6481, 3.7910, 3.8424, 3.7523],\n",
      "        [3.4259, 3.5400, 3.6149, 3.6568, 3.5500],\n",
      "        [3.5518, 3.5674, 3.6970, 3.7497, 3.6382],\n",
      "        [3.8426, 3.8304, 3.8950, 4.0641, 3.8754],\n",
      "        [3.4577, 3.4712, 3.5727, 3.6747, 3.5315],\n",
      "        [3.4171, 3.6316, 3.6492, 3.6566, 3.5752],\n",
      "        [3.5664, 3.5830, 3.6382, 3.7170, 3.7102],\n",
      "        [3.9648, 3.8401, 3.9497, 4.1875, 3.9807],\n",
      "        [3.6001, 3.7101, 3.7195, 3.8815, 3.7493],\n",
      "        [3.5732, 3.6381, 3.7860, 3.7871, 3.7970],\n",
      "        [3.5810, 3.6302, 3.7059, 3.6696, 3.4930],\n",
      "        [3.4621, 3.5059, 3.5996, 3.6979, 3.5596],\n",
      "        [3.5215, 3.5923, 3.6154, 3.6732, 3.6465],\n",
      "        [3.8028, 4.0368, 3.8779, 4.0777, 4.0080],\n",
      "        [3.4302, 3.5237, 3.6037, 3.6563, 3.5451],\n",
      "        [3.5711, 3.6359, 3.7962, 3.9071, 3.8758],\n",
      "        [3.6468, 3.8326, 3.7563, 3.9101, 3.7434],\n",
      "        [3.6887, 3.6646, 3.7282, 3.7179, 3.5672],\n",
      "        [3.4523, 3.6181, 3.6852, 3.7109, 3.5933]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "Episode: 2/3, Total Reward: 220\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7199, 3.8561, 3.8715, 3.9338, 3.8382],\n",
      "        [3.5455, 3.5590, 3.6795, 3.6965, 3.6126],\n",
      "        [3.5272, 3.9681, 3.7471, 3.8089, 3.9375],\n",
      "        [3.6204, 3.8047, 3.8337, 3.9514, 3.7970],\n",
      "        [3.5815, 3.6475, 3.7094, 3.7631, 3.8427],\n",
      "        [3.5682, 3.5470, 3.7098, 3.7737, 3.7585],\n",
      "        [3.4290, 3.6806, 3.6742, 3.6837, 3.6226],\n",
      "        [4.0349, 4.1936, 3.8394, 3.9936, 3.8245],\n",
      "        [3.8852, 4.0154, 3.7567, 3.9116, 3.8000],\n",
      "        [3.5601, 3.6391, 3.7176, 3.7898, 3.6910],\n",
      "        [3.4126, 3.5902, 3.5586, 3.6658, 3.5514],\n",
      "        [3.6867, 3.7315, 3.6264, 3.9076, 3.8282],\n",
      "        [3.4967, 3.5842, 3.6778, 3.7542, 3.6411],\n",
      "        [3.5449, 3.6795, 3.5651, 3.7890, 3.6456],\n",
      "        [3.4459, 3.4839, 3.5810, 3.6721, 3.5269],\n",
      "        [3.6456, 3.8419, 3.8840, 4.0014, 3.8279],\n",
      "        [3.7048, 3.8726, 3.7505, 4.0349, 3.8430],\n",
      "        [3.4142, 3.6883, 3.5066, 3.7257, 3.5328],\n",
      "        [3.5872, 3.6532, 3.7266, 3.6870, 3.5030],\n",
      "        [3.4993, 3.5793, 3.6350, 3.6645, 3.6233],\n",
      "        [3.4458, 3.4781, 3.5748, 3.6789, 3.5217],\n",
      "        [3.3665, 3.5267, 3.5216, 3.5486, 3.5201],\n",
      "        [3.5033, 3.5848, 3.6868, 3.7535, 3.6457],\n",
      "        [3.6750, 3.6799, 3.7067, 3.9533, 3.7828],\n",
      "        [3.3649, 3.5280, 3.4283, 3.6435, 3.4847],\n",
      "        [3.6484, 3.7123, 3.6618, 3.8736, 3.7420],\n",
      "        [3.7319, 3.8469, 3.8636, 3.9613, 3.7856],\n",
      "        [3.6347, 3.9743, 3.7377, 3.8522, 3.9420],\n",
      "        [3.4753, 3.5709, 3.6700, 3.7519, 3.6434],\n",
      "        [3.6100, 3.6603, 3.7322, 3.7707, 3.8924],\n",
      "        [3.6372, 3.7036, 3.7275, 3.8027, 3.7191],\n",
      "        [3.5018, 3.9918, 3.7327, 3.7531, 3.8397],\n",
      "        [3.5365, 3.6430, 3.6466, 3.7208, 3.6454],\n",
      "        [3.9172, 3.7546, 3.9119, 4.0812, 3.9017],\n",
      "        [3.9215, 3.8042, 3.9323, 4.1506, 3.9092],\n",
      "        [3.5412, 3.5919, 3.6790, 3.7500, 3.6483],\n",
      "        [3.4425, 3.4657, 3.5657, 3.6751, 3.5131],\n",
      "        [3.5141, 3.6244, 3.5942, 3.6746, 3.6048],\n",
      "        [3.7027, 3.8702, 3.7492, 4.0335, 3.8395],\n",
      "        [3.4261, 3.7050, 3.8179, 3.7403, 3.7113],\n",
      "        [3.5381, 3.5764, 3.6325, 3.7925, 3.5850],\n",
      "        [3.5699, 3.6423, 3.7999, 3.9099, 3.8768],\n",
      "        [3.5323, 3.4969, 3.5960, 3.6857, 3.7248],\n",
      "        [3.4935, 3.5582, 3.6847, 3.7487, 3.7142],\n",
      "        [3.3739, 3.4671, 3.5242, 3.5659, 3.5021],\n",
      "        [3.5909, 3.8507, 3.6771, 3.9310, 3.7616],\n",
      "        [3.5022, 3.6419, 3.5551, 3.7174, 3.6117],\n",
      "        [3.4115, 3.4616, 3.5672, 3.6564, 3.5300],\n",
      "        [3.5319, 3.5127, 3.7138, 3.6050, 3.7038],\n",
      "        [3.6077, 3.7113, 3.7224, 3.8244, 3.7987],\n",
      "        [3.8164, 3.9307, 3.9779, 4.1799, 4.1732],\n",
      "        [3.5421, 3.6934, 3.7295, 3.8790, 3.6606],\n",
      "        [3.4297, 3.5347, 3.6120, 3.6645, 3.5580],\n",
      "        [4.0295, 3.9132, 3.9755, 4.2393, 4.0499],\n",
      "        [3.7674, 3.8090, 3.8437, 3.9958, 3.9374],\n",
      "        [3.6728, 3.6031, 3.9288, 3.8980, 3.8224],\n",
      "        [3.7803, 3.9827, 3.8169, 3.8057, 3.8117],\n",
      "        [3.4969, 3.6282, 3.5930, 3.7134, 3.6423],\n",
      "        [3.7316, 3.8370, 3.8392, 3.8301, 3.8049],\n",
      "        [3.4925, 3.4990, 3.6050, 3.6979, 3.5366],\n",
      "        [3.5780, 3.7156, 3.5826, 3.8280, 3.6731],\n",
      "        [3.4621, 3.6737, 3.7700, 3.7268, 3.7115],\n",
      "        [3.5638, 3.9277, 3.7472, 3.8353, 3.9906],\n",
      "        [3.9886, 3.9490, 3.9305, 4.2790, 4.0614]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7760, 4.0097, 3.8766, 4.0771, 3.9319],\n",
      "        [3.4113, 3.6810, 3.7750, 3.6814, 3.6638],\n",
      "        [3.8101, 3.9660, 3.9402, 4.0589, 3.9660],\n",
      "        [3.6904, 3.8315, 3.7435, 3.8622, 3.8696],\n",
      "        [3.7962, 3.9059, 3.9425, 3.9366, 3.7216],\n",
      "        [3.4459, 3.4809, 3.5765, 3.6782, 3.5213],\n",
      "        [3.9796, 4.1716, 3.7689, 3.9392, 3.8040],\n",
      "        [3.5675, 3.6032, 3.7218, 3.7289, 3.6552],\n",
      "        [3.4415, 3.5024, 3.5905, 3.6647, 3.5334],\n",
      "        [3.5276, 3.6410, 3.5937, 3.7368, 3.6528],\n",
      "        [3.5436, 3.5630, 3.6096, 3.6862, 3.6833],\n",
      "        [3.5626, 3.5984, 3.7613, 3.8029, 3.6968],\n",
      "        [3.6735, 3.9408, 3.8761, 3.9406, 3.9697],\n",
      "        [3.5347, 3.7257, 3.7175, 3.7664, 3.7209],\n",
      "        [3.7645, 3.9195, 3.9337, 4.0169, 4.0121],\n",
      "        [3.6038, 3.5956, 3.7411, 3.7795, 3.7175],\n",
      "        [3.4315, 3.5897, 3.5517, 3.6223, 3.5734],\n",
      "        [3.6193, 3.5828, 3.7102, 3.7933, 3.6424],\n",
      "        [3.4238, 3.5845, 3.5445, 3.6182, 3.5641],\n",
      "        [3.5799, 3.7443, 3.7522, 3.7871, 3.8301],\n",
      "        [3.4585, 3.4793, 3.5779, 3.6886, 3.5346],\n",
      "        [3.8014, 3.9734, 3.9662, 3.9649, 3.7083],\n",
      "        [3.4936, 3.6347, 3.5542, 3.6976, 3.6072],\n",
      "        [3.6866, 3.7684, 3.7834, 3.9986, 3.7542],\n",
      "        [3.6734, 3.8203, 3.7456, 3.8561, 3.8759],\n",
      "        [3.5864, 3.5833, 3.7543, 3.8215, 3.7770],\n",
      "        [3.6265, 3.8187, 3.7235, 3.7925, 3.7698],\n",
      "        [3.8139, 3.8129, 3.9229, 4.0131, 3.7183],\n",
      "        [3.9158, 3.7605, 3.9210, 4.4214, 4.2118],\n",
      "        [3.5948, 3.7907, 3.6875, 3.7563, 3.7284],\n",
      "        [3.8027, 3.8559, 3.9420, 4.1010, 3.8041],\n",
      "        [3.5623, 3.8481, 3.6779, 3.6354, 3.7492],\n",
      "        [3.7439, 4.0331, 3.8891, 4.1059, 3.9793],\n",
      "        [3.5746, 3.7213, 3.5923, 3.8247, 3.6811],\n",
      "        [3.5795, 3.7080, 3.7244, 3.9397, 3.6787],\n",
      "        [3.6510, 3.9497, 3.7483, 3.8766, 3.9346],\n",
      "        [3.6696, 4.0196, 3.8228, 4.0372, 3.9118],\n",
      "        [4.0007, 4.0742, 4.0306, 4.3489, 4.0923],\n",
      "        [3.5415, 3.6672, 3.6428, 3.7258, 3.6628],\n",
      "        [3.7563, 3.8705, 3.8565, 3.8485, 3.8230],\n",
      "        [3.7613, 3.6620, 3.7377, 4.0907, 3.8678],\n",
      "        [4.0329, 4.1244, 3.7657, 4.0012, 3.7785],\n",
      "        [3.7228, 3.8515, 3.8895, 3.9591, 3.8623],\n",
      "        [3.4967, 3.5871, 3.6796, 3.7536, 3.6408],\n",
      "        [3.4055, 3.6053, 3.6362, 3.6497, 3.5561],\n",
      "        [3.6210, 3.5610, 3.6578, 3.7249, 3.7003],\n",
      "        [3.5977, 3.9675, 3.7962, 3.9554, 3.8928],\n",
      "        [3.6477, 3.8300, 3.7891, 3.8458, 3.6301],\n",
      "        [3.8276, 3.5795, 3.7848, 4.1483, 4.0261],\n",
      "        [4.0296, 3.9167, 3.9778, 4.2390, 4.0498],\n",
      "        [3.6494, 3.8357, 3.7510, 3.8000, 3.7839],\n",
      "        [3.6635, 3.6421, 3.7506, 3.7428, 3.6768],\n",
      "        [3.5657, 3.5573, 3.7204, 3.7829, 3.7559],\n",
      "        [3.9351, 3.8710, 3.8672, 4.0893, 3.9953],\n",
      "        [3.8853, 4.0186, 3.7586, 3.9110, 3.7997],\n",
      "        [3.4383, 3.6947, 3.6845, 3.6881, 3.6345],\n",
      "        [3.5011, 3.4708, 3.6944, 3.5414, 3.6882],\n",
      "        [3.3939, 3.4740, 3.5377, 3.5898, 3.5150],\n",
      "        [3.5638, 3.7618, 3.7789, 3.8172, 3.6324],\n",
      "        [3.5775, 3.6783, 3.6355, 3.8376, 3.6868],\n",
      "        [3.5509, 3.5323, 3.6588, 3.6738, 3.5790],\n",
      "        [3.6394, 3.6629, 3.8171, 3.8606, 3.7570],\n",
      "        [3.8354, 3.8403, 3.8854, 4.1194, 4.0775],\n",
      "        [4.0525, 3.7940, 3.9670, 4.4740, 4.2923]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4620, 3.6792, 3.7731, 3.7252, 3.7103],\n",
      "        [3.4440, 3.6102, 3.5527, 3.6463, 3.5855],\n",
      "        [3.6939, 3.8323, 3.8234, 3.8866, 3.6640],\n",
      "        [3.4723, 3.4413, 3.6715, 3.5050, 3.6624],\n",
      "        [3.5608, 3.7038, 3.5772, 3.8022, 3.6565],\n",
      "        [3.7222, 3.9411, 3.8057, 3.9291, 3.8258],\n",
      "        [3.5698, 3.6478, 3.8030, 3.9083, 3.8758],\n",
      "        [3.8184, 3.8606, 3.9617, 4.1178, 3.8112],\n",
      "        [3.5934, 3.9579, 3.8573, 3.8454, 3.6765],\n",
      "        [3.4297, 3.5399, 3.6149, 3.6628, 3.5567],\n",
      "        [3.4952, 3.6659, 3.7617, 3.8111, 3.7828],\n",
      "        [3.7665, 3.6337, 3.7301, 3.8407, 3.7607],\n",
      "        [3.6453, 3.8484, 3.8879, 4.0003, 3.8269],\n",
      "        [3.4620, 3.6157, 3.5533, 3.6728, 3.5879],\n",
      "        [3.3599, 3.5229, 3.5192, 3.5389, 3.5172],\n",
      "        [3.6085, 3.6693, 3.7320, 3.7685, 3.8901],\n",
      "        [3.5522, 3.6859, 3.5706, 3.7858, 3.6446],\n",
      "        [3.6212, 3.5748, 3.6901, 3.7918, 3.6187],\n",
      "        [3.6342, 3.8953, 3.7834, 3.8966, 3.8860],\n",
      "        [3.4633, 3.4917, 3.5854, 3.6876, 3.5317],\n",
      "        [3.7308, 3.6523, 3.7079, 4.0994, 3.8501],\n",
      "        [3.5507, 3.8074, 3.7610, 3.7108, 3.7589],\n",
      "        [3.6337, 3.6445, 3.7166, 3.6933, 3.5119],\n",
      "        [3.7415, 3.9289, 3.8892, 3.9509, 3.8073],\n",
      "        [3.4656, 3.6120, 3.7094, 3.7910, 3.6739],\n",
      "        [3.4844, 3.6289, 3.5563, 3.6873, 3.6096],\n",
      "        [3.8332, 3.8913, 3.9097, 4.0225, 4.0932],\n",
      "        [3.6058, 3.6330, 3.7736, 3.8108, 3.7235],\n",
      "        [3.5010, 3.4732, 3.6956, 3.5404, 3.6873],\n",
      "        [3.3699, 3.5317, 3.4365, 3.6607, 3.4861],\n",
      "        [3.7046, 3.8780, 3.7539, 4.0333, 3.8418],\n",
      "        [3.5532, 3.6013, 3.6918, 3.7490, 3.6526],\n",
      "        [3.4884, 3.5786, 3.6751, 3.7488, 3.6314],\n",
      "        [3.5877, 3.8631, 3.8183, 3.9079, 3.8985],\n",
      "        [3.7297, 3.9043, 3.8577, 3.9586, 3.8114],\n",
      "        [3.9395, 4.0225, 3.9529, 4.2469, 3.9850],\n",
      "        [3.4905, 3.6387, 3.5550, 3.7046, 3.6054],\n",
      "        [3.8986, 3.9096, 3.9616, 4.1488, 3.9524],\n",
      "        [3.8548, 3.8563, 3.9045, 4.0929, 3.8893],\n",
      "        [3.5932, 3.6057, 3.7739, 3.8215, 3.7480],\n",
      "        [3.4947, 3.5563, 3.7072, 3.7330, 3.6272],\n",
      "        [3.7293, 3.9703, 3.7858, 3.9469, 4.0075],\n",
      "        [3.6241, 3.5815, 3.8344, 3.8799, 3.7112],\n",
      "        [3.4814, 3.8974, 3.6496, 3.6995, 3.7800],\n",
      "        [3.5301, 3.9388, 3.7061, 3.7837, 3.8668],\n",
      "        [3.4327, 3.5145, 3.5980, 3.6562, 3.5352],\n",
      "        [3.7046, 3.8780, 3.7539, 4.0333, 3.8418],\n",
      "        [3.9666, 3.9326, 3.8511, 4.1325, 4.0622],\n",
      "        [3.4726, 3.6141, 3.5459, 3.6724, 3.5839],\n",
      "        [3.5567, 3.5736, 3.6111, 3.8191, 3.5839],\n",
      "        [3.4806, 3.5773, 3.6653, 3.7492, 3.6247],\n",
      "        [3.5229, 3.6763, 3.8549, 3.8010, 3.7987],\n",
      "        [3.6273, 3.5897, 3.9488, 3.8541, 3.7940],\n",
      "        [3.6650, 3.8191, 3.8375, 3.9601, 3.8552],\n",
      "        [3.5868, 3.5988, 3.7616, 3.7847, 3.7147],\n",
      "        [3.7046, 3.8780, 3.7539, 4.0333, 3.8418],\n",
      "        [3.8595, 3.7410, 3.7706, 3.9432, 3.9029],\n",
      "        [3.8268, 3.8154, 3.7270, 3.9485, 3.9035],\n",
      "        [3.8056, 3.9637, 3.7454, 3.8770, 3.7911],\n",
      "        [3.9552, 3.7924, 3.9561, 4.4641, 4.2409],\n",
      "        [3.6664, 3.5108, 3.8525, 3.8561, 3.7243],\n",
      "        [3.7117, 3.8738, 3.7741, 3.9249, 3.8023],\n",
      "        [3.4316, 3.6908, 3.6859, 3.6846, 3.6228],\n",
      "        [3.4931, 3.4655, 3.5508, 3.6772, 3.5017]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7107, 3.9419, 3.8875, 3.9727, 3.9394],\n",
      "        [3.5623, 3.7693, 3.6922, 3.7939, 3.7340],\n",
      "        [3.8287, 3.9262, 3.8676, 3.9948, 3.9515],\n",
      "        [3.5088, 3.5739, 3.6997, 3.7449, 3.6377],\n",
      "        [3.6904, 3.8314, 3.8247, 3.8822, 3.6580],\n",
      "        [3.6536, 3.9513, 3.8356, 3.9246, 3.9073],\n",
      "        [3.7165, 3.6976, 3.6974, 4.0254, 3.8247],\n",
      "        [3.5659, 3.6236, 3.7941, 3.6876, 3.8258],\n",
      "        [3.4816, 3.6299, 3.5643, 3.6748, 3.6160],\n",
      "        [3.5175, 3.9310, 3.6794, 3.7365, 3.8225],\n",
      "        [3.4017, 3.5743, 3.5448, 3.6000, 3.5540],\n",
      "        [3.9742, 3.8004, 3.9477, 4.4647, 4.2107],\n",
      "        [3.7174, 3.8160, 3.8312, 3.8321, 3.7973],\n",
      "        [3.5211, 3.6617, 3.5673, 3.7458, 3.6299],\n",
      "        [3.4123, 3.5582, 3.6149, 3.6427, 3.5440],\n",
      "        [3.7426, 3.7782, 3.7889, 3.9682, 3.9257],\n",
      "        [3.5831, 3.9581, 3.7798, 3.9488, 3.8624],\n",
      "        [3.8704, 3.9364, 3.8446, 4.0267, 3.9864],\n",
      "        [3.5979, 3.8024, 3.6931, 3.7550, 3.7303],\n",
      "        [3.7021, 3.8777, 3.7537, 4.0312, 3.8372],\n",
      "        [3.6285, 3.5887, 3.9390, 3.8471, 3.7797],\n",
      "        [3.4666, 3.6030, 3.5605, 3.7200, 3.5623],\n",
      "        [3.5604, 3.5369, 3.6517, 3.7374, 3.7522],\n",
      "        [3.4210, 3.6618, 3.6664, 3.6686, 3.6014],\n",
      "        [3.5119, 3.6503, 3.5594, 3.7199, 3.6224],\n",
      "        [3.7439, 3.8579, 3.8756, 4.0577, 3.7802],\n",
      "        [3.6868, 3.8478, 3.7403, 3.8597, 3.7721],\n",
      "        [3.8887, 3.9066, 3.9102, 4.1549, 3.8997],\n",
      "        [3.5418, 3.6059, 3.6876, 3.7532, 3.6492],\n",
      "        [3.8080, 3.8486, 3.8977, 4.0769, 4.0635],\n",
      "        [4.0444, 4.2174, 4.1905, 4.3350, 4.3666],\n",
      "        [3.9273, 3.8247, 3.9494, 4.1526, 3.9224],\n",
      "        [3.4302, 3.5336, 3.6089, 3.6527, 3.5427],\n",
      "        [3.7042, 3.8801, 3.7550, 4.0326, 3.8407],\n",
      "        [3.4783, 3.8709, 3.8074, 3.8293, 3.8467],\n",
      "        [3.5672, 3.7125, 3.5781, 3.8126, 3.6639],\n",
      "        [3.6247, 3.6018, 3.7305, 3.7764, 3.7285],\n",
      "        [3.4584, 3.6150, 3.5523, 3.6595, 3.5888],\n",
      "        [3.5555, 3.6521, 3.6978, 3.7670, 3.7926],\n",
      "        [3.7589, 3.8492, 3.8947, 4.0651, 3.7824],\n",
      "        [3.4940, 3.6436, 3.5593, 3.7038, 3.6067],\n",
      "        [3.7180, 3.8456, 3.7572, 3.8563, 3.7663],\n",
      "        [3.5062, 3.6971, 3.7282, 3.8590, 3.6019],\n",
      "        [3.8850, 4.0236, 3.7612, 3.9097, 3.7979],\n",
      "        [3.4781, 3.5281, 3.6972, 3.7070, 3.6059],\n",
      "        [3.8983, 4.0691, 3.9050, 4.1361, 4.1332],\n",
      "        [3.3736, 3.4741, 3.5280, 3.5636, 3.4999],\n",
      "        [3.4316, 3.5962, 3.5533, 3.6250, 3.5780],\n",
      "        [3.4601, 3.6447, 3.5940, 3.7673, 3.5788],\n",
      "        [3.5032, 3.5890, 3.6894, 3.7512, 3.6434],\n",
      "        [4.0197, 4.0657, 3.9922, 4.3653, 4.0915],\n",
      "        [3.9182, 3.7562, 3.9110, 4.0708, 3.8996],\n",
      "        [3.4473, 3.4779, 3.5737, 3.6856, 3.5219],\n",
      "        [3.5857, 3.6265, 3.7303, 3.8020, 3.7032],\n",
      "        [3.6066, 3.7953, 3.6448, 3.7774, 3.6966],\n",
      "        [3.6782, 3.6703, 3.7531, 3.8400, 3.6854],\n",
      "        [3.7215, 3.8004, 3.8765, 3.8606, 3.6032],\n",
      "        [3.4625, 3.5263, 3.4930, 3.7177, 3.4930],\n",
      "        [3.5770, 3.6179, 3.7770, 3.7920, 3.7173],\n",
      "        [3.4786, 3.6878, 3.6614, 3.6172, 3.5677],\n",
      "        [3.5489, 3.7342, 3.6226, 3.8767, 3.6142],\n",
      "        [3.7982, 3.9290, 3.9722, 4.1465, 4.1600],\n",
      "        [3.6164, 3.5974, 3.7247, 3.7925, 3.6850],\n",
      "        [3.6157, 3.5623, 3.6533, 3.7265, 3.6949]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4916, 3.7828, 3.7191, 3.8019, 3.8007],\n",
      "        [3.4848, 3.7047, 3.7124, 3.8657, 3.5747],\n",
      "        [3.5762, 3.6302, 3.7905, 3.8021, 3.7227],\n",
      "        [3.7255, 3.7890, 3.8961, 3.8769, 3.6579],\n",
      "        [3.4464, 3.4795, 3.5758, 3.6854, 3.5206],\n",
      "        [3.4189, 3.6066, 3.6398, 3.6594, 3.5775],\n",
      "        [3.7037, 3.8802, 3.7580, 4.0276, 3.8380],\n",
      "        [3.3925, 3.5255, 3.4965, 3.6756, 3.4721],\n",
      "        [3.5221, 3.5284, 3.6821, 3.7133, 3.6060],\n",
      "        [3.7011, 3.8794, 3.7560, 4.0309, 3.8358],\n",
      "        [3.6588, 3.8260, 3.8649, 3.9710, 3.8274],\n",
      "        [3.7168, 3.8858, 3.8288, 3.9530, 3.7969],\n",
      "        [3.6515, 3.7122, 3.7282, 3.8211, 3.7080],\n",
      "        [3.5408, 3.7034, 3.7366, 3.8773, 3.6573],\n",
      "        [3.5687, 3.7168, 3.5898, 3.8201, 3.6676],\n",
      "        [3.5708, 3.6364, 3.7923, 3.6760, 3.8277],\n",
      "        [3.8750, 3.8424, 3.8274, 3.9937, 3.9132],\n",
      "        [3.5553, 3.7465, 3.7421, 3.7876, 3.7001],\n",
      "        [3.4423, 3.5043, 3.5936, 3.6641, 3.5313],\n",
      "        [3.5379, 3.7240, 3.6150, 3.8714, 3.5999],\n",
      "        [3.4606, 3.6831, 3.7763, 3.7243, 3.7077],\n",
      "        [3.5651, 3.5473, 3.6864, 3.7657, 3.7546],\n",
      "        [3.6228, 3.8963, 3.6779, 3.8399, 3.7195],\n",
      "        [3.5601, 3.5344, 3.6617, 3.6671, 3.5709],\n",
      "        [3.3509, 3.5515, 3.5798, 3.6215, 3.5611],\n",
      "        [3.7929, 4.0383, 3.8691, 4.0641, 3.9840],\n",
      "        [3.6236, 3.5755, 3.6721, 3.7394, 3.7076],\n",
      "        [3.4564, 3.6061, 3.5343, 3.7183, 3.5749],\n",
      "        [3.5861, 3.6150, 3.7628, 3.8209, 3.7233],\n",
      "        [3.6094, 3.6692, 3.7381, 3.7680, 3.8882],\n",
      "        [3.5636, 3.7660, 3.6952, 3.8116, 3.7416],\n",
      "        [3.7627, 3.8900, 3.7754, 3.9855, 3.8844],\n",
      "        [3.7626, 4.0046, 3.8601, 4.0552, 3.9193],\n",
      "        [3.8149, 3.9408, 3.9849, 4.1777, 4.1695],\n",
      "        [3.5504, 3.8817, 3.7883, 3.8911, 3.8650],\n",
      "        [3.6904, 3.6828, 3.7758, 3.8651, 3.7003],\n",
      "        [3.4249, 3.6753, 3.6706, 3.6771, 3.5991],\n",
      "        [3.7392, 3.9912, 3.8063, 3.9618, 4.0214],\n",
      "        [3.9234, 3.9107, 3.7836, 4.0935, 4.0785],\n",
      "        [3.8337, 3.5721, 3.7633, 4.1771, 4.0446],\n",
      "        [3.7983, 4.0649, 3.8723, 4.0515, 4.0428],\n",
      "        [3.9724, 3.8871, 4.0117, 4.2207, 3.9771],\n",
      "        [3.4447, 3.4868, 3.5808, 3.6764, 3.5180],\n",
      "        [3.9746, 3.9439, 3.8504, 4.1424, 4.0738],\n",
      "        [3.4419, 3.6047, 3.5528, 3.6502, 3.5768],\n",
      "        [3.9904, 3.9238, 3.9710, 4.1745, 4.0660],\n",
      "        [3.5413, 3.6819, 3.5749, 3.7662, 3.6421],\n",
      "        [3.5221, 3.6770, 3.7024, 3.8270, 3.6692],\n",
      "        [3.3778, 3.5509, 3.5320, 3.5680, 3.5304],\n",
      "        [3.6970, 3.7762, 3.6704, 3.9041, 3.8176],\n",
      "        [3.5624, 3.9605, 3.7373, 3.9681, 3.8210],\n",
      "        [3.7036, 3.8884, 3.8409, 4.0343, 3.8031],\n",
      "        [3.5750, 3.6690, 3.6950, 3.9151, 3.7078],\n",
      "        [3.6331, 3.6710, 3.8237, 3.8500, 3.7502],\n",
      "        [3.6826, 3.8214, 3.7386, 3.9017, 3.8304],\n",
      "        [3.7900, 3.8255, 3.8729, 4.0049, 3.7450],\n",
      "        [3.4643, 3.5468, 3.5022, 3.7187, 3.5374],\n",
      "        [3.5119, 3.9091, 3.6744, 3.7177, 3.8021],\n",
      "        [3.6026, 3.6156, 3.7885, 3.8580, 3.7958],\n",
      "        [3.8841, 4.0255, 3.7635, 3.9096, 3.7966],\n",
      "        [3.5655, 3.8504, 3.6648, 3.6291, 3.7066],\n",
      "        [3.4685, 3.6003, 3.5595, 3.7106, 3.5637],\n",
      "        [3.5948, 3.8510, 3.8892, 3.9632, 3.7635],\n",
      "        [3.8430, 3.8443, 3.7512, 3.9841, 3.9038]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7021, 3.8826, 3.7598, 4.0319, 3.8379],\n",
      "        [3.5708, 3.5648, 3.7302, 3.7793, 3.7590],\n",
      "        [3.6368, 3.6700, 3.8241, 3.8585, 3.7523],\n",
      "        [3.7017, 3.9091, 3.8756, 3.9597, 3.8800],\n",
      "        [3.4158, 3.5454, 3.6150, 3.6464, 3.5368],\n",
      "        [3.6250, 3.6777, 3.7223, 3.8659, 3.7008],\n",
      "        [3.7215, 3.9320, 3.7882, 3.9080, 3.8411],\n",
      "        [3.9035, 3.9356, 3.8535, 4.0435, 4.0145],\n",
      "        [3.5964, 3.7988, 3.7078, 3.7949, 3.7509],\n",
      "        [3.8452, 3.7036, 3.7803, 4.2192, 3.9605],\n",
      "        [3.5344, 3.5484, 3.6974, 3.7276, 3.6129],\n",
      "        [3.5491, 3.6940, 3.5706, 3.7860, 3.6426],\n",
      "        [3.4168, 3.5577, 3.6228, 3.6480, 3.5429],\n",
      "        [3.6904, 3.6992, 3.6969, 3.9824, 3.7967],\n",
      "        [4.0271, 3.8150, 4.0129, 4.5264, 4.2901],\n",
      "        [3.4626, 3.6031, 3.6689, 3.6277, 3.7125],\n",
      "        [3.9378, 3.7572, 3.9154, 4.4406, 4.1917],\n",
      "        [3.7744, 3.8328, 3.8868, 3.9786, 3.9795],\n",
      "        [3.7615, 4.0056, 3.8626, 4.0549, 3.9179],\n",
      "        [3.8170, 3.8701, 3.9675, 4.1190, 3.8116],\n",
      "        [3.3678, 3.5361, 3.4417, 3.6594, 3.4826],\n",
      "        [3.9643, 4.0329, 4.0069, 4.2699, 3.9826],\n",
      "        [3.4382, 3.5313, 3.6125, 3.6631, 3.5416],\n",
      "        [3.5132, 3.5039, 3.6721, 3.7344, 3.6727],\n",
      "        [3.8754, 3.7621, 3.9029, 4.0892, 3.8519],\n",
      "        [3.5732, 3.6050, 3.6659, 3.7291, 3.7125],\n",
      "        [3.3718, 3.4765, 3.5323, 3.5627, 3.4973],\n",
      "        [3.4404, 3.4752, 3.5740, 3.6722, 3.5081],\n",
      "        [3.7835, 3.8381, 3.8526, 3.9671, 3.9325],\n",
      "        [3.7437, 3.9132, 3.8728, 3.9393, 3.7882],\n",
      "        [3.4131, 3.6969, 3.5181, 3.7212, 3.5270],\n",
      "        [3.5262, 3.6729, 3.7034, 3.8143, 3.6935],\n",
      "        [3.9217, 3.9104, 3.9475, 4.1767, 3.9365],\n",
      "        [3.5706, 3.7046, 3.7101, 3.7852, 3.7172],\n",
      "        [3.6333, 3.6966, 3.7286, 3.8945, 3.7049],\n",
      "        [3.6361, 3.7849, 3.7389, 3.8763, 3.7753],\n",
      "        [3.5616, 3.6261, 3.7991, 3.6870, 3.8105],\n",
      "        [3.5770, 3.7161, 3.7324, 3.9383, 3.6744],\n",
      "        [3.4298, 3.5986, 3.5577, 3.6242, 3.5753],\n",
      "        [3.5807, 3.9785, 3.9024, 3.8653, 3.7247],\n",
      "        [3.8663, 3.7717, 3.7858, 3.9543, 3.9173],\n",
      "        [3.7661, 3.5557, 3.6066, 3.7490, 3.7811],\n",
      "        [3.6862, 3.6752, 3.7179, 3.9808, 3.7809],\n",
      "        [3.4214, 3.6762, 3.6737, 3.6722, 3.6035],\n",
      "        [3.8072, 3.8280, 3.8765, 4.0908, 4.0615],\n",
      "        [3.7380, 3.7376, 3.8328, 4.0357, 3.6812],\n",
      "        [3.8146, 3.9470, 3.9945, 4.1739, 4.1761],\n",
      "        [3.4403, 3.6006, 3.6826, 3.6945, 3.5730],\n",
      "        [3.4914, 3.5482, 3.7140, 3.7266, 3.6116],\n",
      "        [3.4334, 3.8798, 3.7853, 3.7595, 3.8475],\n",
      "        [3.5161, 3.5745, 3.6848, 3.7066, 3.6177],\n",
      "        [3.4079, 3.6541, 3.6624, 3.6580, 3.5793],\n",
      "        [3.9655, 3.8854, 4.0071, 4.2321, 3.9813],\n",
      "        [4.1503, 4.3636, 3.9395, 4.1188, 3.9545],\n",
      "        [3.4961, 3.9914, 3.7330, 3.7467, 3.8261],\n",
      "        [3.5651, 3.7148, 3.5827, 3.8118, 3.6612],\n",
      "        [3.8825, 3.9339, 3.8885, 4.1614, 3.9421],\n",
      "        [3.3849, 3.4361, 3.5564, 3.6776, 3.5025],\n",
      "        [3.3446, 3.5165, 3.5099, 3.5258, 3.4948],\n",
      "        [3.5709, 3.7363, 3.7507, 3.7778, 3.8009],\n",
      "        [3.4797, 3.5840, 3.6811, 3.7349, 3.6355],\n",
      "        [3.7017, 3.9236, 3.7678, 3.8937, 3.8150],\n",
      "        [3.8910, 3.7143, 3.8058, 4.2966, 4.0232],\n",
      "        [3.3828, 3.4702, 3.5721, 3.6039, 3.4661]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5743, 3.7256, 3.5941, 3.8242, 3.6677],\n",
      "        [3.5041, 3.6189, 3.6042, 3.7734, 3.6263],\n",
      "        [3.5350, 3.5679, 3.7041, 3.7398, 3.6272],\n",
      "        [3.8079, 3.8947, 3.9356, 4.0119, 3.8264],\n",
      "        [3.5378, 3.6022, 3.6902, 3.7465, 3.6426],\n",
      "        [3.4475, 3.4882, 3.5881, 3.6787, 3.5238],\n",
      "        [3.6993, 3.9266, 3.8811, 3.9505, 3.9174],\n",
      "        [3.5329, 3.9169, 3.7604, 3.8945, 3.8357],\n",
      "        [3.7418, 3.9443, 3.7631, 3.8665, 3.7934],\n",
      "        [3.4162, 3.6674, 3.6699, 3.6589, 3.5913],\n",
      "        [3.7009, 3.8830, 3.7625, 4.0311, 3.8373],\n",
      "        [3.6043, 3.7315, 3.7351, 3.8957, 3.7426],\n",
      "        [3.4759, 3.6905, 3.6683, 3.6156, 3.5642],\n",
      "        [3.8102, 3.9828, 3.9516, 4.0598, 3.9553],\n",
      "        [3.7802, 3.8934, 3.8402, 3.9484, 3.8927],\n",
      "        [3.6132, 3.5650, 3.6604, 3.7249, 3.6916],\n",
      "        [3.4584, 3.6818, 3.8723, 3.7384, 3.8016],\n",
      "        [3.5704, 3.6275, 3.7918, 3.7986, 3.7164],\n",
      "        [3.6861, 3.8260, 3.8729, 3.8286, 3.6434],\n",
      "        [3.8811, 3.8214, 3.8122, 3.9864, 3.8821],\n",
      "        [3.5841, 3.7747, 3.6500, 3.9303, 3.6349],\n",
      "        [4.0574, 4.0027, 4.0494, 4.3263, 4.0996],\n",
      "        [3.6630, 3.5158, 3.8607, 3.8540, 3.7198],\n",
      "        [3.4403, 3.5056, 3.5985, 3.6629, 3.5293],\n",
      "        [3.5927, 3.6657, 3.7932, 3.8134, 3.8018],\n",
      "        [3.5324, 3.5941, 3.7179, 3.7748, 3.7140],\n",
      "        [3.7382, 3.9341, 3.8975, 3.9486, 3.8027],\n",
      "        [3.6013, 3.8441, 3.7785, 3.8157, 3.5971],\n",
      "        [4.0594, 4.2917, 3.8798, 4.0629, 3.8506],\n",
      "        [3.6205, 3.8978, 3.6830, 3.8389, 3.7175],\n",
      "        [3.4771, 3.5822, 3.6734, 3.7473, 3.6203],\n",
      "        [3.5301, 3.5065, 3.6067, 3.6818, 3.7190],\n",
      "        [3.4963, 3.6135, 3.5992, 3.6602, 3.5806],\n",
      "        [3.8357, 3.9466, 3.8460, 3.9978, 3.9697],\n",
      "        [3.3811, 3.5604, 3.5483, 3.5698, 3.5409],\n",
      "        [3.8061, 3.9387, 3.8302, 3.9781, 3.9516],\n",
      "        [3.5268, 3.9941, 3.8865, 3.8092, 3.6884],\n",
      "        [3.5646, 3.5954, 3.6502, 3.7119, 3.7042],\n",
      "        [3.5883, 3.6164, 3.7418, 3.7740, 3.7113],\n",
      "        [3.7690, 3.6509, 3.7495, 3.8453, 3.7643],\n",
      "        [3.4929, 3.9975, 3.7372, 3.7486, 3.8307],\n",
      "        [3.6346, 3.6034, 3.9545, 3.8658, 3.7969],\n",
      "        [3.7951, 3.9190, 3.8464, 3.9480, 3.9309],\n",
      "        [3.8288, 3.9178, 3.9394, 4.0126, 4.0784],\n",
      "        [3.9136, 3.7739, 3.9303, 4.4263, 4.2064],\n",
      "        [4.0826, 4.1038, 4.0211, 4.4064, 3.9520],\n",
      "        [3.4319, 3.5470, 3.6230, 3.6616, 3.5545],\n",
      "        [3.4895, 3.7842, 3.7244, 3.8008, 3.7988],\n",
      "        [3.4165, 3.5993, 3.6509, 3.6616, 3.5701],\n",
      "        [3.5655, 3.6610, 3.6383, 3.7599, 3.7381],\n",
      "        [3.7319, 3.8705, 3.8719, 3.8851, 3.6613],\n",
      "        [3.7017, 3.8242, 3.7574, 3.7690, 3.7362],\n",
      "        [3.4932, 3.5945, 3.6891, 3.7508, 3.6356],\n",
      "        [3.8820, 3.7766, 3.9259, 4.1105, 3.8711],\n",
      "        [3.8061, 3.6722, 3.7434, 3.8801, 3.8196],\n",
      "        [3.4369, 3.4936, 3.5877, 3.6664, 3.5171],\n",
      "        [3.8953, 3.9157, 3.9705, 4.1473, 3.9479],\n",
      "        [3.6806, 3.6765, 3.7519, 3.7151, 3.5510],\n",
      "        [3.6357, 3.6705, 3.8267, 3.8577, 3.7518],\n",
      "        [3.6438, 3.8520, 3.7713, 3.9141, 3.7304],\n",
      "        [3.4424, 3.7038, 3.6920, 3.6794, 3.6349],\n",
      "        [3.9243, 4.0603, 3.7816, 3.9439, 3.8028],\n",
      "        [3.6741, 3.8535, 3.7313, 3.9901, 3.7896],\n",
      "        [3.8012, 3.8791, 3.9191, 4.0026, 3.8104]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6849, 3.9987, 3.9112, 3.9454, 3.9102],\n",
      "        [3.4699, 3.6584, 3.6010, 3.6830, 3.6423],\n",
      "        [3.8416, 3.9964, 3.7610, 3.8915, 3.7904],\n",
      "        [3.4832, 3.6739, 3.6145, 3.7487, 3.5658],\n",
      "        [3.5531, 3.6919, 3.5750, 3.7816, 3.6348],\n",
      "        [3.5467, 3.6444, 3.6292, 3.7400, 3.7188],\n",
      "        [3.6713, 3.9500, 3.8883, 3.9365, 3.9644],\n",
      "        [3.6153, 3.5811, 3.7120, 3.7814, 3.6218],\n",
      "        [3.9724, 3.8898, 4.0196, 4.2192, 3.9755],\n",
      "        [4.0252, 4.1245, 3.7717, 3.9812, 3.7776],\n",
      "        [3.5701, 3.8405, 3.7668, 3.9318, 3.6708],\n",
      "        [3.5409, 3.5992, 3.7022, 3.7600, 3.6522],\n",
      "        [3.6047, 3.8001, 3.6547, 3.7754, 3.6940],\n",
      "        [3.3780, 3.5511, 3.5411, 3.5598, 3.5375],\n",
      "        [3.7806, 3.7531, 3.8507, 3.9787, 3.7757],\n",
      "        [3.4136, 3.6277, 3.6547, 3.6475, 3.5611],\n",
      "        [3.9792, 4.0832, 4.0225, 4.3177, 4.0788],\n",
      "        [3.5974, 3.6744, 3.8499, 3.8436, 3.7491],\n",
      "        [3.4715, 3.6101, 3.7010, 3.7217, 3.5609],\n",
      "        [3.5716, 3.7375, 3.7556, 3.7758, 3.8006],\n",
      "        [3.4342, 3.6577, 3.6726, 3.6683, 3.6065],\n",
      "        [3.5492, 3.7633, 3.7513, 3.7958, 3.6808],\n",
      "        [3.7102, 3.6931, 3.8422, 4.0444, 3.7180],\n",
      "        [3.7029, 3.9386, 3.9052, 3.9495, 3.7783],\n",
      "        [3.6745, 3.7122, 3.7445, 3.8362, 3.7010],\n",
      "        [3.6084, 3.6602, 3.7190, 3.8254, 3.6944],\n",
      "        [3.7853, 3.8884, 3.9232, 3.9803, 4.0362],\n",
      "        [3.7979, 3.6521, 3.7321, 3.8544, 3.8032],\n",
      "        [3.4287, 3.5372, 3.6180, 3.6501, 3.5395],\n",
      "        [3.5966, 3.6483, 3.8167, 3.9506, 3.9052],\n",
      "        [3.4507, 3.6319, 3.6995, 3.7042, 3.5877],\n",
      "        [3.4136, 3.5748, 3.6344, 3.6448, 3.5459],\n",
      "        [3.5194, 3.6653, 3.5766, 3.7432, 3.6270],\n",
      "        [3.4758, 3.6385, 3.5715, 3.6828, 3.6009],\n",
      "        [3.4558, 3.4947, 3.5911, 3.6798, 3.5251],\n",
      "        [3.4548, 3.5721, 3.6494, 3.6257, 3.5755],\n",
      "        [3.5754, 4.0162, 3.8892, 3.8111, 3.7154],\n",
      "        [3.8851, 3.7133, 3.8117, 4.3015, 4.0164],\n",
      "        [3.7792, 3.7286, 3.7761, 3.8185, 3.6758],\n",
      "        [3.6362, 3.7863, 3.7438, 3.8747, 3.7752],\n",
      "        [3.5518, 3.7032, 3.5924, 3.7834, 3.6540],\n",
      "        [3.6732, 3.7230, 3.8650, 3.8999, 3.7291],\n",
      "        [3.4104, 3.6013, 3.5718, 3.6608, 3.5460],\n",
      "        [3.5811, 3.9620, 3.7895, 3.9464, 3.8593],\n",
      "        [3.2559, 3.4577, 3.5520, 3.5298, 3.5026],\n",
      "        [3.7340, 3.7662, 3.7864, 3.9479, 3.9039],\n",
      "        [3.7376, 3.9197, 3.7873, 3.9035, 3.8537],\n",
      "        [3.7863, 3.9185, 3.9240, 4.0006, 4.0133],\n",
      "        [3.7320, 3.6960, 3.7468, 3.7576, 3.6200],\n",
      "        [3.5110, 3.6948, 3.7478, 3.8046, 3.5969],\n",
      "        [3.4417, 3.5064, 3.6006, 3.6618, 3.5295],\n",
      "        [3.6755, 3.8543, 3.7336, 3.9890, 3.7899],\n",
      "        [3.6965, 3.8772, 3.7582, 4.0208, 3.8278],\n",
      "        [3.7134, 3.7505, 3.7939, 3.8312, 3.5877],\n",
      "        [3.4299, 3.6191, 3.5713, 3.6355, 3.5830],\n",
      "        [3.4075, 3.5968, 3.6392, 3.6406, 3.5499],\n",
      "        [3.7094, 3.7595, 3.6413, 3.9163, 3.8472],\n",
      "        [3.5635, 3.7019, 3.6764, 3.8152, 3.7648],\n",
      "        [3.6705, 3.8300, 3.7586, 3.8528, 3.8710],\n",
      "        [3.9914, 3.9261, 3.9790, 4.1724, 4.0649],\n",
      "        [3.7545, 4.0957, 3.8696, 4.1069, 3.9853],\n",
      "        [4.0228, 4.2366, 3.8372, 4.0063, 3.7966],\n",
      "        [3.7023, 3.8839, 3.7648, 4.0299, 3.8377],\n",
      "        [3.7422, 3.5946, 3.6412, 3.7575, 3.7915]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.9219, 4.0061, 4.0572, 4.2555, 4.2367],\n",
      "        [3.6148, 3.5964, 3.7373, 3.7697, 3.7207],\n",
      "        [3.7325, 3.5432, 3.6291, 3.7682, 3.7305],\n",
      "        [3.7044, 3.8801, 3.7586, 4.0180, 3.8235],\n",
      "        [3.8424, 3.9970, 3.7628, 3.8903, 3.7905],\n",
      "        [3.6676, 3.7153, 3.8618, 3.9043, 3.7151],\n",
      "        [3.5318, 4.0298, 3.9000, 3.8111, 3.6960],\n",
      "        [3.5410, 3.7065, 3.7460, 3.8742, 3.6561],\n",
      "        [3.8175, 3.8417, 3.8909, 4.0997, 4.0640],\n",
      "        [4.2559, 4.4143, 4.0708, 4.1940, 3.9983],\n",
      "        [3.6683, 3.7259, 3.7873, 3.8154, 3.8245],\n",
      "        [3.5482, 3.9861, 3.8928, 3.8325, 3.6970],\n",
      "        [3.7794, 3.8120, 3.8612, 3.9602, 3.9420],\n",
      "        [3.4164, 3.6559, 3.6697, 3.6527, 3.5824],\n",
      "        [3.8441, 3.8314, 3.8446, 3.9669, 3.9006],\n",
      "        [3.7259, 3.9234, 3.8804, 3.9468, 3.8066],\n",
      "        [3.9047, 3.9376, 3.8602, 4.0406, 4.0142],\n",
      "        [3.6753, 3.6710, 3.7731, 3.8389, 3.6891],\n",
      "        [3.6741, 3.7235, 3.8668, 3.8986, 3.7291],\n",
      "        [3.5487, 3.5983, 3.7018, 3.7413, 3.6465],\n",
      "        [3.5440, 3.5198, 3.6276, 3.6991, 3.7276],\n",
      "        [3.8337, 3.8499, 3.8995, 4.1146, 4.0726],\n",
      "        [3.6861, 3.7394, 3.6387, 3.8932, 3.8047],\n",
      "        [3.7320, 3.5384, 3.6269, 3.7615, 3.7287],\n",
      "        [4.0544, 4.0888, 4.0057, 4.3754, 3.9438],\n",
      "        [3.6967, 3.7101, 3.7908, 3.7983, 3.6121],\n",
      "        [3.6723, 3.7215, 3.7839, 3.7964, 3.8402],\n",
      "        [3.9918, 3.8624, 3.9954, 4.2163, 3.9726],\n",
      "        [3.5546, 3.6998, 3.5894, 3.7846, 3.6504],\n",
      "        [3.4012, 3.5784, 3.5556, 3.5960, 3.5509],\n",
      "        [3.5798, 3.6517, 3.7854, 3.7203, 3.8179],\n",
      "        [3.5616, 3.7117, 3.8855, 3.8354, 3.8212],\n",
      "        [3.8205, 3.8241, 3.8390, 3.9389, 3.8928],\n",
      "        [3.7500, 3.8961, 3.8546, 3.8157, 3.8172],\n",
      "        [3.6312, 3.5866, 3.6954, 3.7472, 3.7162],\n",
      "        [3.6120, 3.9562, 3.8783, 3.8742, 3.7011],\n",
      "        [3.7032, 3.8844, 3.7666, 4.0286, 3.8377],\n",
      "        [3.8094, 4.0193, 3.8489, 4.0353, 4.0940],\n",
      "        [3.4499, 3.4894, 3.5919, 3.6764, 3.5241],\n",
      "        [3.9658, 4.0352, 4.0141, 4.2672, 3.9824],\n",
      "        [3.6998, 3.7750, 3.8190, 3.9301, 3.9223],\n",
      "        [3.5266, 3.6493, 3.6070, 3.7313, 3.6479],\n",
      "        [3.5752, 3.6722, 3.7044, 3.9120, 3.7065],\n",
      "        [3.5663, 3.5993, 3.7256, 3.7505, 3.6544],\n",
      "        [3.4775, 3.7312, 3.5722, 3.7377, 3.5564],\n",
      "        [3.4565, 3.6089, 3.5432, 3.7147, 3.5732],\n",
      "        [3.4729, 3.5892, 3.6705, 3.7550, 3.6181],\n",
      "        [3.5343, 3.6789, 3.5873, 3.7553, 3.6405],\n",
      "        [3.3691, 3.5381, 3.4483, 3.6564, 3.4824],\n",
      "        [3.6690, 3.8016, 3.7300, 3.8719, 3.8205],\n",
      "        [3.5072, 3.6480, 3.5650, 3.7239, 3.5944],\n",
      "        [3.5338, 3.6787, 3.5891, 3.7534, 3.6414],\n",
      "        [3.5353, 3.6797, 3.5859, 3.7633, 3.6374],\n",
      "        [3.9748, 3.9986, 3.9353, 4.2741, 3.8642],\n",
      "        [3.6761, 3.9687, 3.8240, 3.9100, 3.8255],\n",
      "        [3.5397, 3.6540, 3.6347, 3.7794, 3.6325],\n",
      "        [3.4778, 3.6702, 3.6025, 3.7875, 3.5832],\n",
      "        [3.4185, 3.6688, 3.6738, 3.6564, 3.5914],\n",
      "        [3.4181, 3.5595, 3.6292, 3.6448, 3.5425],\n",
      "        [3.5226, 3.9368, 3.7152, 3.7741, 3.8522],\n",
      "        [3.6322, 4.0128, 3.7906, 4.0065, 3.8787],\n",
      "        [3.5637, 3.6537, 3.7292, 3.7955, 3.6874],\n",
      "        [3.5896, 3.8623, 3.6923, 3.9252, 3.7562],\n",
      "        [3.8656, 3.7256, 3.8014, 4.2574, 3.9910]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.9746, 4.0120, 3.9942, 4.2987, 4.0270],\n",
      "        [3.7634, 3.5901, 3.7790, 4.0581, 3.9712],\n",
      "        [3.6952, 3.7029, 3.7914, 3.7864, 3.6224],\n",
      "        [3.5517, 3.7005, 3.5875, 3.7846, 3.6480],\n",
      "        [3.4616, 3.6227, 3.5664, 3.6666, 3.5836],\n",
      "        [3.5233, 3.9377, 3.7165, 3.7726, 3.8520],\n",
      "        [3.5291, 3.9966, 3.8918, 3.8050, 3.6885],\n",
      "        [3.4358, 3.6592, 3.6756, 3.6653, 3.6061],\n",
      "        [3.5713, 3.7770, 3.7840, 3.8123, 3.6531],\n",
      "        [3.5725, 3.7749, 3.7983, 3.8164, 3.6327],\n",
      "        [3.4341, 3.4629, 3.5697, 3.6584, 3.4970],\n",
      "        [3.8074, 3.8543, 3.9106, 4.0720, 4.0604],\n",
      "        [3.3779, 3.4592, 3.5714, 3.5760, 3.4596],\n",
      "        [3.4378, 3.7045, 3.6990, 3.6804, 3.6289],\n",
      "        [3.7159, 3.8651, 3.8759, 3.9460, 3.8013],\n",
      "        [3.5417, 3.7472, 3.6859, 3.7972, 3.7193],\n",
      "        [3.4018, 3.5793, 3.5568, 3.5944, 3.5507],\n",
      "        [3.5660, 3.7316, 3.7465, 3.7620, 3.7989],\n",
      "        [3.7143, 3.7398, 3.8938, 3.8445, 3.5641],\n",
      "        [3.7256, 3.7870, 3.6775, 3.9315, 3.8437],\n",
      "        [3.6970, 3.8415, 3.7615, 3.9203, 3.7846],\n",
      "        [3.7151, 3.7579, 3.7951, 3.8290, 3.5750],\n",
      "        [3.7439, 3.8188, 3.8652, 3.9806, 3.9607],\n",
      "        [3.6733, 3.7223, 3.7852, 3.7948, 3.8399],\n",
      "        [3.4990, 3.6489, 3.6493, 3.6043, 3.5981],\n",
      "        [4.0052, 4.1276, 3.8117, 3.9965, 3.8124],\n",
      "        [3.7963, 3.9834, 3.9758, 3.9609, 3.6978],\n",
      "        [3.7292, 3.5781, 3.6262, 3.7451, 3.7693],\n",
      "        [3.6004, 3.6348, 3.7967, 3.8245, 3.7305],\n",
      "        [3.8528, 3.8597, 3.9632, 4.1779, 3.8088],\n",
      "        [3.7060, 3.9415, 3.7884, 3.8999, 3.8188],\n",
      "        [3.6810, 3.8440, 3.7365, 3.8629, 3.7700],\n",
      "        [3.5772, 3.6229, 3.7893, 3.7866, 3.7140],\n",
      "        [3.6633, 3.6668, 3.7730, 3.7423, 3.6310],\n",
      "        [3.5448, 3.6341, 3.7175, 3.7747, 3.6662],\n",
      "        [3.6791, 3.7550, 3.6577, 3.8287, 3.8105],\n",
      "        [3.6829, 3.9337, 3.9443, 3.9414, 3.7512],\n",
      "        [3.5440, 3.5949, 3.6948, 3.7370, 3.6414],\n",
      "        [3.8642, 3.8679, 3.9350, 4.0726, 3.7568],\n",
      "        [3.9539, 4.0044, 3.9416, 4.2731, 4.0302],\n",
      "        [3.5528, 3.5036, 3.6357, 3.6215, 3.5323],\n",
      "        [3.9386, 3.9204, 3.9332, 4.1624, 3.9709],\n",
      "        [3.6380, 3.7158, 3.7436, 3.7948, 3.7133],\n",
      "        [3.6263, 3.5970, 3.9623, 3.8476, 3.7892],\n",
      "        [3.7018, 3.8828, 3.7665, 4.0255, 3.8340],\n",
      "        [3.7597, 3.8184, 3.8566, 3.8986, 3.9021],\n",
      "        [3.5507, 3.6813, 3.6655, 3.7292, 3.6692],\n",
      "        [3.4612, 3.5810, 3.5741, 3.6858, 3.5540],\n",
      "        [3.5823, 3.6637, 3.7247, 3.7551, 3.8369],\n",
      "        [3.4124, 3.5633, 3.6269, 3.6371, 3.5406],\n",
      "        [3.3598, 3.5299, 3.5320, 3.5326, 3.5128],\n",
      "        [3.4015, 3.5843, 3.5706, 3.5888, 3.5621],\n",
      "        [3.4753, 3.5361, 3.6320, 3.6814, 3.5415],\n",
      "        [3.9502, 3.9197, 3.8200, 4.0924, 4.0691],\n",
      "        [3.6299, 3.8880, 3.7838, 3.8828, 3.8758],\n",
      "        [3.4802, 3.5843, 3.6785, 3.7435, 3.6204],\n",
      "        [3.4597, 3.6082, 3.5607, 3.6502, 3.5723],\n",
      "        [3.5623, 3.7126, 3.8867, 3.8338, 3.8210],\n",
      "        [4.0290, 3.8179, 4.0212, 4.5223, 4.2900],\n",
      "        [3.3697, 3.5391, 3.4495, 3.6549, 3.4822],\n",
      "        [3.7998, 3.8304, 3.9022, 4.0470, 3.8247],\n",
      "        [3.6521, 4.1160, 3.8933, 3.9613, 4.0013],\n",
      "        [3.4258, 3.6789, 3.6807, 3.6715, 3.5969],\n",
      "        [3.8392, 3.6957, 3.7620, 3.8944, 3.8519]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6832, 3.9342, 3.9452, 3.9395, 3.7506],\n",
      "        [3.4128, 3.5639, 3.6277, 3.6353, 3.5400],\n",
      "        [3.4846, 3.5905, 3.6504, 3.6514, 3.5949],\n",
      "        [3.7119, 3.6956, 3.8467, 4.0401, 3.7181],\n",
      "        [3.5732, 3.7146, 3.7318, 3.9103, 3.6737],\n",
      "        [3.5920, 3.7401, 3.7347, 3.8074, 3.7457],\n",
      "        [3.3373, 3.5027, 3.5154, 3.5021, 3.4784],\n",
      "        [3.5218, 3.6679, 3.5806, 3.7116, 3.6251],\n",
      "        [3.7424, 3.7916, 3.8947, 3.8744, 3.6617],\n",
      "        [3.4494, 3.5245, 3.6142, 3.6638, 3.5376],\n",
      "        [3.6192, 3.5930, 3.7259, 3.7849, 3.6371],\n",
      "        [3.5706, 3.6335, 3.7973, 3.6957, 3.8086],\n",
      "        [3.5420, 3.7478, 3.6868, 3.7955, 3.7188],\n",
      "        [3.5213, 3.6673, 3.5804, 3.7385, 3.6264],\n",
      "        [3.4734, 3.6121, 3.7049, 3.7169, 3.5600],\n",
      "        [3.8017, 4.0545, 3.8983, 4.0680, 4.0020],\n",
      "        [3.7372, 3.7682, 3.7907, 3.9432, 3.9033],\n",
      "        [3.6250, 3.5755, 3.7634, 3.9457, 3.6072],\n",
      "        [3.6377, 3.6806, 3.7994, 3.8348, 3.8274],\n",
      "        [3.9686, 3.8894, 4.0167, 4.2266, 3.9805],\n",
      "        [3.9957, 3.9281, 3.9834, 4.1677, 4.0648],\n",
      "        [3.4055, 3.5800, 3.5542, 3.5873, 3.5477],\n",
      "        [3.6048, 3.6054, 3.7565, 3.7707, 3.7116],\n",
      "        [3.7146, 3.7404, 3.8947, 3.8427, 3.5635],\n",
      "        [3.4640, 3.5343, 3.6364, 3.6776, 3.5273],\n",
      "        [3.7614, 3.8253, 3.8493, 3.9289, 3.9079],\n",
      "        [3.5189, 3.5827, 3.6495, 3.7663, 3.5751],\n",
      "        [3.4070, 3.6930, 3.6646, 3.7066, 3.7502],\n",
      "        [3.8586, 3.8860, 3.9494, 4.0519, 3.8741],\n",
      "        [3.5215, 3.6015, 3.6721, 3.7627, 3.5916],\n",
      "        [3.7845, 3.9348, 3.9369, 4.0008, 4.0191],\n",
      "        [3.5581, 3.6322, 3.7200, 3.7603, 3.6639],\n",
      "        [3.7806, 3.8941, 3.9200, 3.9203, 3.6924],\n",
      "        [3.7033, 3.9279, 3.7772, 3.8876, 3.8148],\n",
      "        [3.5361, 3.9197, 3.7668, 3.8887, 3.8353],\n",
      "        [3.4416, 3.5725, 3.6393, 3.6548, 3.5703],\n",
      "        [3.5585, 3.5388, 3.6593, 3.7273, 3.7428],\n",
      "        [3.8935, 3.7177, 3.8147, 4.2909, 4.0228],\n",
      "        [3.4633, 3.5242, 3.6158, 3.6844, 3.5517],\n",
      "        [3.6138, 3.6511, 3.8024, 3.8153, 3.7274],\n",
      "        [4.0810, 4.0927, 4.0483, 4.3490, 3.9351],\n",
      "        [3.6540, 3.7176, 3.8344, 3.8668, 3.7285],\n",
      "        [3.9627, 3.9403, 3.9039, 4.1411, 4.0198],\n",
      "        [3.5477, 3.7223, 3.7656, 3.8223, 3.6424],\n",
      "        [3.8509, 3.9168, 3.9382, 4.0296, 4.0979],\n",
      "        [3.6119, 3.6489, 3.7841, 3.7944, 3.7360],\n",
      "        [3.7824, 3.7304, 3.7800, 3.8141, 3.6756],\n",
      "        [3.5599, 3.6661, 3.6750, 3.6894, 3.6660],\n",
      "        [3.5576, 3.5896, 3.7243, 3.7462, 3.6479],\n",
      "        [3.8730, 3.7189, 3.8015, 4.2523, 3.9922],\n",
      "        [3.7021, 3.8834, 3.7675, 4.0236, 3.8335],\n",
      "        [3.4361, 3.6598, 3.6764, 3.6635, 3.6055],\n",
      "        [3.4481, 3.5186, 3.6126, 3.6606, 3.5341],\n",
      "        [3.5413, 3.6049, 3.6962, 3.7409, 3.6422],\n",
      "        [3.6040, 3.6196, 3.7997, 3.8511, 3.7935],\n",
      "        [3.3867, 3.4393, 3.5648, 3.6712, 3.5014],\n",
      "        [3.4166, 3.6145, 3.6552, 3.6545, 3.5722],\n",
      "        [3.4289, 3.6938, 3.6912, 3.6734, 3.6159],\n",
      "        [3.9742, 3.8406, 3.9750, 4.1980, 3.9933],\n",
      "        [3.6984, 3.8791, 3.7623, 4.0159, 3.8273],\n",
      "        [3.5334, 3.6045, 3.8238, 3.6080, 3.7988],\n",
      "        [3.5413, 3.6049, 3.6962, 3.7409, 3.6422],\n",
      "        [3.4977, 3.5016, 3.6045, 3.7013, 3.5168],\n",
      "        [3.6770, 3.8605, 3.7410, 3.9883, 3.7943]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4698, 3.7637, 3.7248, 3.7644, 3.8167],\n",
      "        [3.5583, 3.7073, 3.6913, 3.8109, 3.7526],\n",
      "        [3.5041, 3.8077, 3.7480, 3.7956, 3.8380],\n",
      "        [3.5707, 3.5845, 3.7347, 3.6930, 3.6973],\n",
      "        [3.5365, 3.7363, 3.7338, 3.7555, 3.7137],\n",
      "        [3.5662, 3.7923, 3.7345, 3.7291, 3.7345],\n",
      "        [3.5965, 3.5937, 3.7758, 3.8179, 3.7741],\n",
      "        [3.5770, 3.7151, 3.5970, 3.8054, 3.6514],\n",
      "        [3.6074, 3.8029, 3.6597, 3.7691, 3.6931],\n",
      "        [3.6647, 3.6677, 3.7744, 3.7386, 3.6295],\n",
      "        [3.5509, 3.6404, 3.7198, 3.7699, 3.6605],\n",
      "        [3.6114, 3.6624, 3.7235, 3.8187, 3.6928],\n",
      "        [3.4396, 3.8127, 3.7102, 3.5885, 3.7380],\n",
      "        [3.4361, 3.5259, 3.6138, 3.6465, 3.5336],\n",
      "        [3.5836, 3.6065, 3.7346, 3.7284, 3.6980],\n",
      "        [3.8678, 3.7274, 3.8042, 4.2525, 3.9897],\n",
      "        [3.7370, 3.9348, 3.7789, 3.7537, 3.7080],\n",
      "        [3.5274, 3.8397, 3.6818, 3.6046, 3.7349],\n",
      "        [3.6148, 3.8724, 3.7214, 3.9422, 3.7683],\n",
      "        [3.4562, 3.6113, 3.7113, 3.7058, 3.5489],\n",
      "        [3.5309, 3.6778, 3.5813, 3.7431, 3.6281],\n",
      "        [3.5116, 3.5201, 3.6802, 3.6904, 3.5855],\n",
      "        [3.6838, 3.9755, 3.9147, 3.9480, 3.9852],\n",
      "        [4.0049, 3.9749, 3.9846, 4.2436, 3.9302],\n",
      "        [3.5297, 3.6030, 3.7172, 3.7668, 3.7282],\n",
      "        [3.6016, 3.6348, 3.7748, 3.7792, 3.7171],\n",
      "        [3.5365, 3.6792, 3.5850, 3.7288, 3.6339],\n",
      "        [3.7576, 3.8814, 3.8735, 3.8378, 3.8161],\n",
      "        [3.4364, 3.5500, 3.6294, 3.6539, 3.5531],\n",
      "        [3.6091, 3.8102, 3.7359, 3.7870, 3.7514],\n",
      "        [3.5432, 3.6118, 3.7012, 3.7443, 3.6446],\n",
      "        [3.7556, 4.0626, 3.8927, 3.9372, 4.1019],\n",
      "        [3.5357, 3.6940, 3.7324, 3.8399, 3.6725],\n",
      "        [3.6738, 3.7539, 3.6539, 3.8192, 3.7972],\n",
      "        [3.9991, 4.0789, 4.0188, 4.3043, 4.0615],\n",
      "        [3.7864, 3.8503, 3.9003, 3.9881, 3.9893],\n",
      "        [3.5955, 3.6312, 3.7732, 3.8063, 3.7067],\n",
      "        [3.3794, 3.4664, 3.5447, 3.5563, 3.4984],\n",
      "        [3.4975, 3.5974, 3.6955, 3.7433, 3.6344],\n",
      "        [3.6647, 3.8748, 3.7859, 3.9792, 3.7863],\n",
      "        [3.5360, 3.5091, 3.6132, 3.6742, 3.7174],\n",
      "        [3.5421, 3.6876, 3.5872, 3.7662, 3.6352],\n",
      "        [3.7874, 3.8378, 3.9026, 3.8616, 3.6129],\n",
      "        [3.3752, 3.4803, 3.5413, 3.5543, 3.4953],\n",
      "        [4.1959, 4.3777, 3.9980, 4.1365, 3.9677],\n",
      "        [3.7186, 3.9244, 3.8057, 3.9129, 3.8066],\n",
      "        [3.5904, 3.9453, 3.7735, 3.9220, 3.8322],\n",
      "        [3.5870, 3.6450, 3.7899, 3.7176, 3.8190],\n",
      "        [3.4989, 3.6058, 3.6944, 3.7494, 3.6338],\n",
      "        [3.6291, 3.5948, 3.9529, 3.8373, 3.7747],\n",
      "        [3.5459, 3.6180, 3.7090, 3.6248, 3.4499],\n",
      "        [3.7232, 3.8654, 3.7606, 3.9644, 3.9386],\n",
      "        [3.9944, 4.1103, 3.7944, 3.9718, 3.7888],\n",
      "        [3.3333, 3.5010, 3.5120, 3.4964, 3.4733],\n",
      "        [3.6649, 3.7509, 3.8129, 3.8258, 3.7488],\n",
      "        [3.5922, 3.6690, 3.8451, 3.8366, 3.7393],\n",
      "        [3.5394, 3.5897, 3.6501, 3.7812, 3.5782],\n",
      "        [3.9252, 4.0566, 3.7803, 3.9184, 3.7945],\n",
      "        [3.4844, 3.5985, 3.6954, 3.7511, 3.6485],\n",
      "        [3.7430, 3.9371, 3.9043, 3.9406, 3.8013],\n",
      "        [3.7588, 3.7785, 3.8706, 3.9683, 3.6459],\n",
      "        [3.6567, 3.7470, 3.7791, 3.8039, 3.8473],\n",
      "        [3.7817, 3.9559, 3.8851, 4.0190, 4.0557],\n",
      "        [3.6088, 3.8527, 3.6930, 3.6364, 3.6691]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5518, 3.6068, 3.7024, 3.7483, 3.6450],\n",
      "        [3.4744, 3.8480, 3.8520, 3.7833, 3.8422],\n",
      "        [4.0595, 3.8126, 3.9941, 4.4699, 4.2934],\n",
      "        [3.8089, 3.9055, 3.9165, 3.9942, 4.0341],\n",
      "        [3.5026, 3.6983, 3.6599, 3.7976, 3.6165],\n",
      "        [3.7835, 3.8436, 3.9257, 3.9943, 3.9936],\n",
      "        [3.4237, 3.5943, 3.6443, 3.6473, 3.5685],\n",
      "        [3.6569, 3.7411, 3.8291, 3.8515, 3.7121],\n",
      "        [4.1705, 4.3696, 4.0163, 4.1584, 3.9379],\n",
      "        [3.4317, 3.5351, 3.6195, 3.6458, 3.5345],\n",
      "        [3.5186, 3.6805, 3.5890, 3.7297, 3.6214],\n",
      "        [3.6544, 4.1185, 3.8953, 3.9552, 3.9984],\n",
      "        [4.0189, 3.8867, 4.0217, 4.2385, 4.0146],\n",
      "        [3.4428, 3.5923, 3.6709, 3.6761, 3.5483],\n",
      "        [3.5529, 3.6898, 3.6688, 3.7909, 3.7571],\n",
      "        [3.6930, 3.8391, 3.8392, 3.8709, 3.6522],\n",
      "        [3.5199, 3.7172, 3.6267, 3.8351, 3.5977],\n",
      "        [3.4884, 3.6765, 3.6288, 3.6964, 3.6509],\n",
      "        [3.4123, 3.6122, 3.6529, 3.6438, 3.5616],\n",
      "        [3.4819, 3.5997, 3.6573, 3.6390, 3.5934],\n",
      "        [3.4273, 3.6932, 3.6957, 3.6544, 3.5984],\n",
      "        [3.5601, 3.6490, 3.6438, 3.7665, 3.6263],\n",
      "        [3.3801, 3.4679, 3.5451, 3.5543, 3.4972],\n",
      "        [3.8033, 4.0565, 3.8994, 4.0640, 3.9999],\n",
      "        [3.5464, 3.6693, 3.6161, 3.7401, 3.6571],\n",
      "        [3.4317, 3.5493, 3.6296, 3.6509, 3.5497],\n",
      "        [3.6066, 3.8690, 3.9080, 3.9421, 3.7606],\n",
      "        [4.1878, 4.4150, 3.9987, 4.1901, 3.9513],\n",
      "        [3.9953, 4.1118, 3.7948, 3.9697, 3.7876],\n",
      "        [3.4909, 3.6314, 3.5944, 3.7419, 3.5721],\n",
      "        [3.3537, 3.5279, 3.5287, 3.5202, 3.5042],\n",
      "        [3.5398, 3.6534, 3.8010, 3.8492, 3.8196],\n",
      "        [3.5423, 3.6660, 3.7067, 3.7736, 3.7424],\n",
      "        [3.5484, 3.5945, 3.7095, 3.7418, 3.6450],\n",
      "        [3.4748, 3.6286, 3.5726, 3.6680, 3.5997],\n",
      "        [3.6297, 3.5791, 3.6806, 3.7237, 3.7027],\n",
      "        [3.3834, 3.4706, 3.5781, 3.5816, 3.4571],\n",
      "        [3.5607, 3.7743, 3.7019, 3.7928, 3.7302],\n",
      "        [3.5411, 3.7242, 3.7587, 3.8686, 3.6326],\n",
      "        [3.4380, 3.6087, 3.5667, 3.6311, 3.5664],\n",
      "        [3.7992, 3.9887, 3.9758, 3.9582, 3.6858],\n",
      "        [3.5962, 3.6204, 3.7699, 3.7565, 3.6731],\n",
      "        [3.4643, 3.6218, 3.5668, 3.6535, 3.5773],\n",
      "        [3.6774, 3.6943, 3.7249, 3.9398, 3.7750],\n",
      "        [3.5714, 3.5994, 3.6572, 3.7020, 3.7014],\n",
      "        [3.5357, 3.7247, 3.8558, 3.7328, 3.6860],\n",
      "        [3.6327, 3.8466, 3.8004, 3.8280, 3.6130],\n",
      "        [3.4232, 3.6809, 3.6856, 3.6576, 3.6022],\n",
      "        [3.5153, 3.8705, 3.8144, 3.8407, 3.8121],\n",
      "        [3.7973, 3.8473, 3.9093, 3.9806, 3.9938],\n",
      "        [3.5764, 3.5805, 3.7491, 3.7834, 3.7586],\n",
      "        [3.7205, 4.0581, 3.9230, 3.9886, 3.9786],\n",
      "        [3.5626, 3.6436, 3.6540, 3.8080, 3.6472],\n",
      "        [3.4173, 3.5786, 3.6391, 3.6360, 3.5430],\n",
      "        [3.6647, 3.7455, 3.7550, 3.9548, 3.7155],\n",
      "        [3.6558, 3.6162, 3.7169, 3.7505, 3.7302],\n",
      "        [3.5608, 3.8106, 3.7647, 3.7094, 3.7496],\n",
      "        [3.6248, 3.4959, 3.8309, 3.8334, 3.7509],\n",
      "        [3.5749, 3.7224, 3.6093, 3.8046, 3.6661],\n",
      "        [3.5325, 3.7382, 3.7309, 3.7536, 3.6972],\n",
      "        [3.5426, 3.5985, 3.7266, 3.7658, 3.7245],\n",
      "        [3.5837, 3.9845, 3.9125, 3.8545, 3.7214],\n",
      "        [3.9698, 3.8686, 3.9779, 4.2273, 4.0174],\n",
      "        [3.5349, 3.5498, 3.7064, 3.7145, 3.6095]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4077, 3.6184, 3.6523, 3.6342, 3.5464],\n",
      "        [3.7281, 3.8531, 3.7756, 3.8268, 3.7623],\n",
      "        [3.5732, 3.6364, 3.7983, 3.6892, 3.8049],\n",
      "        [3.8354, 3.8587, 3.9124, 4.0993, 4.0686],\n",
      "        [3.8134, 4.0236, 3.8578, 4.0212, 4.0841],\n",
      "        [3.7662, 3.5936, 3.7809, 4.0505, 3.9675],\n",
      "        [3.7059, 3.7505, 3.7824, 3.8067, 3.5472],\n",
      "        [3.4383, 3.6627, 3.6774, 3.6571, 3.6019],\n",
      "        [3.7355, 3.8642, 3.8828, 3.9460, 3.7762],\n",
      "        [3.3698, 3.5480, 3.5386, 3.5347, 3.5136],\n",
      "        [3.9893, 4.0614, 4.0215, 4.2772, 4.0119],\n",
      "        [4.1532, 4.2952, 4.0285, 4.1255, 3.9702],\n",
      "        [3.5647, 3.9447, 3.7662, 3.8193, 3.9801],\n",
      "        [3.7042, 3.8865, 3.7685, 4.0170, 3.8300],\n",
      "        [3.6093, 3.6427, 3.7992, 3.8243, 3.7270],\n",
      "        [3.4865, 3.6394, 3.5713, 3.6731, 3.6015],\n",
      "        [3.8502, 3.8358, 3.8482, 3.9573, 3.8971],\n",
      "        [3.4453, 3.6117, 3.5647, 3.6369, 3.5710],\n",
      "        [3.7187, 3.7549, 3.7988, 3.8204, 3.5836],\n",
      "        [3.5383, 3.9226, 3.7680, 3.8825, 3.8317],\n",
      "        [4.0633, 4.0103, 4.0581, 4.3143, 4.0976],\n",
      "        [3.9263, 3.9184, 3.9585, 4.1646, 3.9337],\n",
      "        [3.5373, 3.6833, 3.5905, 3.7457, 3.6365],\n",
      "        [3.7138, 3.8647, 3.7732, 3.9188, 3.7861],\n",
      "        [3.4582, 3.6226, 3.7197, 3.7090, 3.5520],\n",
      "        [3.3815, 3.5578, 3.5437, 3.5548, 3.5245],\n",
      "        [3.5431, 3.6870, 3.5816, 3.7646, 3.6343],\n",
      "        [3.4693, 3.5225, 3.6996, 3.6790, 3.5881],\n",
      "        [3.7384, 3.9374, 3.7794, 3.7494, 3.7053],\n",
      "        [3.7656, 4.0122, 3.8729, 4.0427, 3.9134],\n",
      "        [3.5030, 3.4979, 3.5861, 3.6715, 3.5169],\n",
      "        [3.6036, 3.6126, 3.7690, 3.7680, 3.7072],\n",
      "        [3.9335, 3.9241, 3.9657, 4.1718, 3.9396],\n",
      "        [3.4646, 3.5283, 3.5121, 3.6990, 3.4527],\n",
      "        [3.4818, 3.6418, 3.7429, 3.7107, 3.6666],\n",
      "        [3.5533, 3.5854, 3.7180, 3.7268, 3.6286],\n",
      "        [3.5612, 3.7755, 3.7020, 3.7906, 3.7288],\n",
      "        [3.7139, 3.9515, 3.9026, 3.9590, 3.9317],\n",
      "        [3.5539, 3.6963, 3.5858, 3.7716, 3.6367],\n",
      "        [3.4234, 3.5894, 3.5629, 3.6037, 3.5716],\n",
      "        [3.4258, 3.6827, 3.6833, 3.6590, 3.5985],\n",
      "        [3.6449, 3.9445, 3.8747, 3.8785, 3.7186],\n",
      "        [3.7063, 3.8889, 3.7699, 4.0184, 3.8336],\n",
      "        [3.5540, 3.7040, 3.5894, 3.7766, 3.6442],\n",
      "        [3.3750, 3.7035, 3.6012, 3.4816, 3.5901],\n",
      "        [3.9424, 3.9456, 3.9206, 4.1675, 3.7799],\n",
      "        [3.5314, 3.7391, 3.6794, 3.7921, 3.7106],\n",
      "        [3.8898, 3.7831, 3.9338, 4.1000, 3.8675],\n",
      "        [3.5975, 3.7099, 3.7164, 3.7434, 3.6912],\n",
      "        [3.4237, 3.6820, 3.6856, 3.6553, 3.6007],\n",
      "        [3.6220, 3.6556, 3.8270, 3.9318, 3.9051],\n",
      "        [3.9787, 3.8954, 4.0254, 4.2092, 3.9714],\n",
      "        [3.3785, 3.6379, 3.4612, 3.6670, 3.4655],\n",
      "        [3.6264, 3.5920, 3.8498, 3.8656, 3.7027],\n",
      "        [3.5473, 3.7475, 3.7458, 3.7620, 3.7189],\n",
      "        [3.7180, 3.8205, 3.8624, 3.8401, 3.7803],\n",
      "        [3.5014, 3.5945, 3.6529, 3.6487, 3.6139],\n",
      "        [3.9957, 3.8240, 4.0249, 4.4810, 4.2811],\n",
      "        [3.7295, 3.9277, 3.8837, 3.9368, 3.8022],\n",
      "        [3.5691, 3.7212, 3.5954, 3.7840, 3.6607],\n",
      "        [3.5326, 3.6878, 3.5828, 3.7430, 3.6266],\n",
      "        [3.3540, 3.5585, 3.5917, 3.6082, 3.5548],\n",
      "        [3.4275, 3.5900, 3.6526, 3.6522, 3.5631],\n",
      "        [3.6161, 3.6541, 3.8034, 3.8090, 3.7239]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.9092, 4.0776, 3.9197, 4.1100, 4.1258],\n",
      "        [3.6259, 3.9042, 3.6901, 3.8249, 3.7129],\n",
      "        [3.5439, 3.6703, 3.6204, 3.7577, 3.6190],\n",
      "        [3.5046, 3.5773, 3.7206, 3.7212, 3.6228],\n",
      "        [3.5690, 3.6174, 3.7381, 3.7111, 3.6450],\n",
      "        [3.3875, 3.4768, 3.5813, 3.5888, 3.4610],\n",
      "        [3.9309, 4.0673, 3.7889, 3.9298, 3.7987],\n",
      "        [3.4989, 3.6499, 3.5787, 3.6756, 3.6146],\n",
      "        [3.6151, 3.9622, 3.8816, 3.8618, 3.6963],\n",
      "        [3.7257, 3.7935, 3.6778, 3.9216, 3.8388],\n",
      "        [3.7850, 3.9008, 3.8954, 3.9635, 4.0001],\n",
      "        [3.7235, 3.7634, 3.9618, 3.8360, 3.6198],\n",
      "        [3.5000, 3.7332, 3.9063, 3.7553, 3.8282],\n",
      "        [3.5911, 3.6208, 3.7252, 3.7487, 3.7119],\n",
      "        [3.6064, 3.8869, 3.6689, 3.8106, 3.6896],\n",
      "        [3.5943, 3.9714, 3.8734, 3.8285, 3.6672],\n",
      "        [3.5693, 3.7220, 3.5952, 3.7815, 3.6603],\n",
      "        [3.8415, 3.9538, 3.8534, 3.9836, 3.9657],\n",
      "        [3.7464, 3.8248, 3.8674, 3.9700, 3.9567],\n",
      "        [3.6519, 3.7283, 3.6797, 3.8551, 3.7320],\n",
      "        [3.7269, 3.8489, 3.7800, 3.8120, 3.7530],\n",
      "        [3.7224, 3.9396, 3.7755, 3.8402, 3.7970],\n",
      "        [3.6915, 3.8322, 3.8796, 3.8138, 3.6389],\n",
      "        [3.6968, 3.9429, 3.9044, 3.9382, 3.7617],\n",
      "        [3.4099, 3.6961, 3.7925, 3.6701, 3.6597],\n",
      "        [3.9264, 3.7781, 3.9344, 4.4128, 4.2005],\n",
      "        [3.5241, 3.6716, 3.5814, 3.7029, 3.6214],\n",
      "        [3.9485, 3.8586, 3.8989, 4.0586, 3.9432],\n",
      "        [3.6799, 4.0628, 3.8561, 4.0338, 3.9236],\n",
      "        [3.5394, 3.6884, 3.5805, 3.7574, 3.6245],\n",
      "        [3.4180, 3.5804, 3.6389, 3.6313, 3.5410],\n",
      "        [3.5541, 3.7056, 3.6946, 3.8276, 3.7499],\n",
      "        [3.4488, 3.4942, 3.5922, 3.6612, 3.5117],\n",
      "        [3.5391, 3.5552, 3.7067, 3.7128, 3.6083],\n",
      "        [3.8184, 3.9488, 3.9975, 4.1622, 4.1631],\n",
      "        [3.3767, 3.4836, 3.5416, 3.5476, 3.4922],\n",
      "        [3.3349, 3.5041, 3.5123, 3.4897, 3.4703],\n",
      "        [3.5281, 3.5191, 3.6907, 3.7204, 3.6665],\n",
      "        [3.7422, 3.9323, 3.8800, 3.9304, 3.7907],\n",
      "        [3.8978, 3.8085, 3.8361, 3.9737, 3.9262],\n",
      "        [3.5764, 3.5715, 3.7397, 3.7641, 3.7541],\n",
      "        [3.4760, 3.5781, 3.6683, 3.7115, 3.5426],\n",
      "        [3.4147, 3.6343, 3.6611, 3.6450, 3.5695],\n",
      "        [3.4553, 3.6378, 3.7041, 3.6904, 3.5826],\n",
      "        [3.6483, 3.8557, 3.7788, 3.8924, 3.7353],\n",
      "        [3.5333, 3.7284, 3.7051, 3.6444, 3.5952],\n",
      "        [3.6184, 3.7275, 3.7408, 3.7800, 3.7986],\n",
      "        [3.4080, 3.5835, 3.5550, 3.5787, 3.5439],\n",
      "        [3.7387, 3.5480, 3.6322, 3.7571, 3.7272],\n",
      "        [3.7998, 3.9905, 3.9756, 3.9533, 3.6838],\n",
      "        [3.8941, 3.9131, 3.8944, 4.2045, 3.9290],\n",
      "        [3.4654, 3.6197, 3.7189, 3.7731, 3.6675],\n",
      "        [3.4171, 3.6497, 3.6668, 3.6473, 3.5740],\n",
      "        [3.6367, 3.6789, 3.8356, 3.8340, 3.7438],\n",
      "        [3.4207, 3.5523, 3.6241, 3.6312, 3.5317],\n",
      "        [3.4205, 3.5316, 3.6142, 3.6301, 3.5238],\n",
      "        [3.5759, 3.6827, 3.6373, 3.8139, 3.6688],\n",
      "        [3.9878, 3.9716, 3.9163, 4.1450, 4.0521],\n",
      "        [3.4126, 3.6954, 3.7913, 3.6632, 3.6529],\n",
      "        [3.6838, 3.8482, 3.7384, 3.8528, 3.7655],\n",
      "        [3.5746, 3.6387, 3.7974, 3.6859, 3.8157],\n",
      "        [3.5882, 3.8770, 3.7918, 3.8000, 3.5862],\n",
      "        [3.5629, 3.7062, 3.5824, 3.7778, 3.6351],\n",
      "        [3.5438, 3.6086, 3.6969, 3.7322, 3.6383]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4455, 3.4821, 3.5878, 3.6557, 3.5022],\n",
      "        [3.6444, 3.7351, 3.6652, 3.8193, 3.7054],\n",
      "        [3.7928, 3.7729, 3.8857, 3.9839, 3.7818],\n",
      "        [3.4923, 3.6139, 3.6943, 3.7695, 3.6233],\n",
      "        [3.5493, 3.5242, 3.6350, 3.6853, 3.7214],\n",
      "        [4.0090, 4.1323, 3.8187, 3.9845, 3.8069],\n",
      "        [3.3818, 3.5589, 3.5481, 3.5505, 3.5229],\n",
      "        [3.5110, 3.5946, 3.7233, 3.7301, 3.6319],\n",
      "        [3.5994, 3.7336, 3.7440, 3.7957, 3.7458],\n",
      "        [3.4679, 3.5841, 3.6815, 3.7037, 3.5369],\n",
      "        [3.5797, 3.7325, 3.6060, 3.8078, 3.6627],\n",
      "        [3.6765, 3.5548, 3.8777, 3.8399, 3.7283],\n",
      "        [3.3359, 3.5877, 3.7515, 3.5833, 3.6423],\n",
      "        [3.7195, 3.9647, 3.8024, 3.7422, 3.7972],\n",
      "        [3.6798, 3.7178, 3.7540, 3.8207, 3.6950],\n",
      "        [3.8081, 3.8871, 3.9320, 3.9869, 3.8050],\n",
      "        [3.9319, 4.0830, 3.9273, 4.1328, 4.1396],\n",
      "        [3.5903, 3.6356, 3.7493, 3.7841, 3.6940],\n",
      "        [3.5617, 3.8127, 3.7695, 3.7027, 3.7463],\n",
      "        [3.4949, 3.6483, 3.5795, 3.6823, 3.6042],\n",
      "        [3.6109, 3.8039, 3.8368, 3.9117, 3.7965],\n",
      "        [3.6654, 3.8806, 3.7911, 3.9710, 3.7839],\n",
      "        [3.6949, 3.7903, 3.7105, 3.8913, 3.7865],\n",
      "        [3.4170, 3.6659, 3.6807, 3.6373, 3.5749],\n",
      "        [3.7754, 3.5628, 3.6212, 3.7333, 3.7772],\n",
      "        [3.4744, 3.6446, 3.7421, 3.7105, 3.5754],\n",
      "        [3.9797, 3.8967, 4.0304, 4.2050, 3.9698],\n",
      "        [3.5148, 3.7032, 3.7592, 3.7900, 3.5924],\n",
      "        [3.5930, 3.8682, 3.7016, 3.8169, 3.7105],\n",
      "        [3.4363, 3.6452, 3.6726, 3.6502, 3.5909],\n",
      "        [3.4182, 3.6692, 3.6835, 3.6478, 3.5874],\n",
      "        [3.5677, 3.7091, 3.6875, 3.8002, 3.7597],\n",
      "        [3.5988, 3.8739, 3.8245, 3.9524, 3.6814],\n",
      "        [3.7980, 3.5940, 3.7932, 4.0943, 3.9862],\n",
      "        [3.5564, 3.5942, 3.7160, 3.7288, 3.6359],\n",
      "        [3.6946, 3.6910, 3.7928, 3.8473, 3.6926],\n",
      "        [3.3966, 3.4882, 3.5581, 3.5703, 3.5044],\n",
      "        [3.4385, 3.5893, 3.6729, 3.6632, 3.5385],\n",
      "        [3.5067, 3.6995, 3.7583, 3.8004, 3.5966],\n",
      "        [3.4231, 3.5854, 3.5593, 3.5945, 3.5437],\n",
      "        [3.5240, 3.6056, 3.6777, 3.7521, 3.5865],\n",
      "        [3.6563, 3.6527, 3.7668, 3.7204, 3.6332],\n",
      "        [3.5954, 3.6252, 3.7615, 3.7821, 3.6864],\n",
      "        [3.4323, 3.6214, 3.6934, 3.6604, 3.5712],\n",
      "        [3.7751, 3.9620, 3.8678, 3.8029, 3.8424],\n",
      "        [3.5541, 3.5871, 3.7168, 3.7252, 3.6288],\n",
      "        [4.0093, 4.1504, 3.9214, 3.9800, 3.8620],\n",
      "        [3.4344, 3.6923, 3.7919, 3.6844, 3.6724],\n",
      "        [3.5869, 3.7993, 3.7435, 3.7465, 3.7413],\n",
      "        [3.7463, 3.9478, 3.7739, 3.8487, 3.7864],\n",
      "        [3.6783, 3.6964, 3.7296, 3.9333, 3.7719],\n",
      "        [3.8315, 3.9481, 3.8530, 3.9759, 3.9701],\n",
      "        [3.5316, 3.6950, 3.5933, 3.7406, 3.6313],\n",
      "        [3.4682, 3.5138, 3.6117, 3.6818, 3.5388],\n",
      "        [3.8513, 3.8370, 3.8530, 3.9530, 3.8957],\n",
      "        [3.7540, 3.7435, 3.8580, 4.0167, 3.6861],\n",
      "        [3.5192, 3.9256, 3.8598, 3.8586, 3.8834],\n",
      "        [3.6895, 3.8861, 3.8241, 3.9866, 3.7902],\n",
      "        [3.4424, 3.7389, 3.8605, 3.7482, 3.7141],\n",
      "        [3.5514, 3.6387, 3.7246, 3.7588, 3.6542],\n",
      "        [3.7080, 3.7301, 3.8011, 3.7991, 3.6052],\n",
      "        [3.5609, 3.6515, 3.6487, 3.7599, 3.6233],\n",
      "        [3.8097, 3.9085, 3.9220, 3.9875, 4.0312],\n",
      "        [3.3701, 3.5490, 3.5429, 3.5304, 3.5119]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7527, 3.8609, 3.9065, 4.0370, 3.7698],\n",
      "        [3.5735, 3.8494, 3.7843, 3.9152, 3.6654],\n",
      "        [3.7513, 3.9226, 3.8004, 3.8984, 3.8608],\n",
      "        [3.4117, 3.6030, 3.6523, 3.6233, 3.5422],\n",
      "        [3.4442, 3.4655, 3.5862, 3.6514, 3.4894],\n",
      "        [3.5806, 3.6927, 3.5690, 3.7855, 3.5607],\n",
      "        [3.5460, 3.7110, 3.7419, 3.9373, 3.6042],\n",
      "        [3.4641, 3.6050, 3.7122, 3.7575, 3.6400],\n",
      "        [3.3886, 3.4435, 3.5745, 3.6590, 3.4948],\n",
      "        [3.7656, 4.0138, 3.8827, 4.0366, 3.9103],\n",
      "        [3.5568, 3.7531, 3.7652, 3.7626, 3.7359],\n",
      "        [3.6363, 3.5912, 3.7066, 3.7314, 3.7083],\n",
      "        [3.5999, 3.6184, 3.8030, 3.8204, 3.7828],\n",
      "        [3.5579, 3.8319, 3.8149, 3.9498, 3.6795],\n",
      "        [3.9170, 3.7148, 3.8264, 4.3155, 4.0348],\n",
      "        [3.4144, 3.6076, 3.5853, 3.6437, 3.5385],\n",
      "        [3.5408, 3.5936, 3.6593, 3.7707, 3.5725],\n",
      "        [3.9013, 3.7569, 3.7966, 3.9600, 3.8908],\n",
      "        [3.4121, 3.6709, 3.6793, 3.6309, 3.5713],\n",
      "        [4.0487, 4.1373, 3.8080, 3.9822, 3.7732],\n",
      "        [3.4972, 3.7085, 3.7446, 3.8376, 3.5829],\n",
      "        [3.6007, 3.8137, 3.7180, 3.7354, 3.7201],\n",
      "        [3.9023, 3.9242, 3.9881, 4.1295, 3.9408],\n",
      "        [3.4634, 3.6917, 3.7973, 3.7045, 3.6977],\n",
      "        [3.6361, 3.9447, 3.8893, 3.8718, 3.7079],\n",
      "        [3.4059, 3.6623, 3.6772, 3.6286, 3.5666],\n",
      "        [3.6067, 3.8734, 3.9194, 3.9334, 3.7566],\n",
      "        [3.5678, 3.7754, 3.7178, 3.7924, 3.7329],\n",
      "        [3.7072, 3.9173, 3.8950, 3.9405, 3.8720],\n",
      "        [3.6013, 3.8085, 3.7024, 3.7394, 3.7098],\n",
      "        [3.6337, 4.0070, 3.8343, 3.9770, 3.8868],\n",
      "        [3.8977, 3.9471, 3.8718, 4.0144, 3.9995],\n",
      "        [3.6457, 3.8658, 3.9165, 3.9801, 3.8168],\n",
      "        [3.7263, 3.7559, 3.8201, 3.8109, 3.6029],\n",
      "        [3.7133, 3.8715, 3.8585, 4.0003, 3.7766],\n",
      "        [3.5867, 3.7996, 3.7480, 3.7445, 3.7398],\n",
      "        [3.4369, 3.4675, 3.5802, 3.6447, 3.4901],\n",
      "        [3.6138, 3.6799, 3.7559, 3.7474, 3.8770],\n",
      "        [3.5708, 3.5775, 3.6217, 3.8058, 3.5685],\n",
      "        [3.5404, 3.6559, 3.8099, 3.8410, 3.8149],\n",
      "        [3.5419, 3.7535, 3.7553, 3.7643, 3.6793],\n",
      "        [3.5238, 3.6058, 3.6817, 3.7502, 3.5849],\n",
      "        [3.7444, 3.7958, 3.9049, 3.8617, 3.6549],\n",
      "        [3.7034, 3.7794, 3.8379, 3.8808, 3.8716],\n",
      "        [3.5115, 3.6089, 3.6654, 3.6586, 3.6158],\n",
      "        [3.9667, 3.9813, 3.9997, 4.2413, 3.8233],\n",
      "        [3.7488, 3.9204, 3.8917, 3.9192, 3.7799],\n",
      "        [3.6806, 3.6823, 3.7716, 3.8125, 3.6799],\n",
      "        [3.4469, 3.5163, 3.6134, 3.6487, 3.5242],\n",
      "        [3.5854, 3.8570, 3.7846, 3.7800, 3.5797],\n",
      "        [3.6256, 3.4982, 3.8399, 3.8249, 3.7463],\n",
      "        [3.5190, 3.6829, 3.5979, 3.7212, 3.6170],\n",
      "        [3.4757, 3.5887, 3.6970, 3.7294, 3.6298],\n",
      "        [3.5925, 3.8783, 3.6685, 3.7777, 3.6754],\n",
      "        [3.6216, 3.6649, 3.7391, 3.8156, 3.6896],\n",
      "        [3.5994, 3.6615, 3.7416, 3.6636, 3.4967],\n",
      "        [3.4151, 3.5680, 3.6371, 3.6228, 3.5333],\n",
      "        [3.6832, 3.6826, 3.7659, 3.6919, 3.5386],\n",
      "        [3.5463, 3.8350, 3.8053, 3.6941, 3.7377],\n",
      "        [3.3858, 3.5852, 3.5826, 3.6150, 3.5351],\n",
      "        [3.4595, 3.8747, 3.6604, 3.6716, 3.7378],\n",
      "        [3.8930, 3.9181, 3.9352, 4.1360, 3.8889],\n",
      "        [3.8992, 3.9286, 3.9592, 4.1417, 3.8754],\n",
      "        [3.4578, 3.8918, 3.6776, 3.6648, 3.7389]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5022, 3.6524, 3.6620, 3.5880, 3.5887],\n",
      "        [3.5641, 3.6128, 3.7905, 3.7801, 3.6832],\n",
      "        [3.5025, 3.4992, 3.5982, 3.6632, 3.5121],\n",
      "        [3.6251, 3.9047, 3.7033, 3.8192, 3.7084],\n",
      "        [3.5525, 3.6156, 3.7173, 3.7289, 3.6386],\n",
      "        [3.5855, 3.7832, 3.6381, 3.7344, 3.6569],\n",
      "        [3.3994, 3.4925, 3.5695, 3.5743, 3.5049],\n",
      "        [3.5614, 3.6565, 3.7492, 3.7747, 3.6729],\n",
      "        [3.7020, 3.7835, 3.8374, 3.9120, 3.9142],\n",
      "        [3.8973, 3.9470, 3.8755, 4.0123, 3.9978],\n",
      "        [3.4742, 3.6257, 3.5729, 3.6498, 3.5711],\n",
      "        [3.4419, 3.6104, 3.5753, 3.6150, 3.5578],\n",
      "        [3.5726, 3.5580, 3.7075, 3.7354, 3.7502],\n",
      "        [3.5655, 3.6889, 3.6455, 3.7486, 3.6727],\n",
      "        [3.5388, 3.5524, 3.7203, 3.7053, 3.6030],\n",
      "        [3.4855, 3.5892, 3.6972, 3.7193, 3.6298],\n",
      "        [3.5520, 3.5466, 3.6872, 3.6508, 3.5647],\n",
      "        [3.7057, 3.8673, 3.7838, 3.8774, 3.7509],\n",
      "        [3.7201, 3.7124, 3.7334, 4.0157, 3.8274],\n",
      "        [3.5510, 3.7443, 3.6488, 3.8546, 3.6021],\n",
      "        [3.5479, 3.6984, 3.5997, 3.7552, 3.6332],\n",
      "        [3.7235, 3.8524, 3.7917, 3.8242, 3.7480],\n",
      "        [3.8517, 3.8522, 3.9861, 4.1564, 3.7912],\n",
      "        [3.8147, 3.6871, 3.7883, 4.1750, 3.9282],\n",
      "        [3.5574, 3.6053, 3.7267, 3.7315, 3.6413],\n",
      "        [3.6102, 3.7400, 3.7576, 3.8757, 3.7351],\n",
      "        [3.5442, 3.7139, 3.7646, 3.8566, 3.6482],\n",
      "        [3.9193, 3.7812, 3.9511, 4.4076, 4.1986],\n",
      "        [3.8368, 3.8554, 3.9159, 4.0971, 4.0635],\n",
      "        [3.4140, 3.6347, 3.6730, 3.6390, 3.5651],\n",
      "        [3.9315, 3.8449, 3.9039, 4.0363, 3.9218],\n",
      "        [3.5327, 3.6603, 3.6226, 3.7134, 3.6397],\n",
      "        [3.7136, 3.9530, 3.9154, 3.9504, 3.9266],\n",
      "        [3.4337, 3.6252, 3.5879, 3.6161, 3.5741],\n",
      "        [3.3866, 3.5715, 3.5757, 3.5496, 3.5388],\n",
      "        [3.4292, 3.6551, 3.6830, 3.6525, 3.5862],\n",
      "        [4.1713, 4.3720, 4.0295, 4.1473, 3.9311],\n",
      "        [3.6780, 3.7586, 3.7192, 3.8052, 3.6922],\n",
      "        [3.9593, 4.0851, 3.7924, 3.9216, 3.7856],\n",
      "        [3.5524, 3.7001, 3.6064, 3.7643, 3.6396],\n",
      "        [3.5829, 3.6121, 3.7045, 3.7187, 3.7064],\n",
      "        [3.7044, 4.0549, 3.9449, 3.9628, 3.9402],\n",
      "        [3.5330, 3.7285, 3.7166, 3.6384, 3.5904],\n",
      "        [3.8933, 3.9146, 3.9119, 4.1985, 3.9253],\n",
      "        [3.5570, 3.7055, 3.6052, 3.7665, 3.6418],\n",
      "        [3.4689, 3.5237, 3.7116, 3.6710, 3.5836],\n",
      "        [3.6693, 3.8799, 3.8087, 3.7857, 3.7852],\n",
      "        [3.4840, 3.6505, 3.5963, 3.6692, 3.5948],\n",
      "        [3.4221, 3.7072, 3.8261, 3.6509, 3.6494],\n",
      "        [3.5295, 3.6549, 3.6222, 3.7134, 3.6393],\n",
      "        [3.7581, 4.0058, 3.8897, 4.0403, 3.8970],\n",
      "        [3.7200, 3.9400, 3.7994, 3.8812, 3.8155],\n",
      "        [3.4267, 3.5583, 3.6405, 3.6281, 3.5333],\n",
      "        [3.8179, 3.9493, 4.0111, 4.1564, 4.1586],\n",
      "        [3.5384, 3.5557, 3.7193, 3.7071, 3.6042],\n",
      "        [3.5405, 3.6845, 3.5954, 3.7376, 3.6308],\n",
      "        [4.0114, 4.1362, 3.9159, 3.9718, 3.8285],\n",
      "        [3.5370, 3.6181, 3.8510, 3.5916, 3.7999],\n",
      "        [3.5071, 3.7065, 3.7671, 3.7876, 3.5926],\n",
      "        [3.6786, 3.6764, 3.7888, 3.8206, 3.6799],\n",
      "        [3.4997, 3.6499, 3.5835, 3.6810, 3.6027],\n",
      "        [3.8958, 3.7222, 3.8289, 4.2775, 4.0152],\n",
      "        [3.5525, 3.6156, 3.7173, 3.7289, 3.6386],\n",
      "        [3.6165, 3.8588, 3.8086, 3.8867, 3.6835]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6541, 3.5336, 3.8661, 3.8217, 3.7097],\n",
      "        [3.5492, 3.8275, 3.8097, 3.6765, 3.7482],\n",
      "        [3.6946, 3.9085, 3.9034, 3.9264, 3.8634],\n",
      "        [3.5582, 3.7608, 3.6685, 3.8726, 3.6073],\n",
      "        [3.4949, 3.5557, 3.7435, 3.7036, 3.6012],\n",
      "        [3.5547, 3.5993, 3.7837, 3.7687, 3.6735],\n",
      "        [3.9153, 3.9197, 3.9871, 4.1804, 3.9552],\n",
      "        [3.5450, 3.7119, 3.7562, 3.9328, 3.6014],\n",
      "        [3.5501, 3.6286, 3.7356, 3.6178, 3.4446],\n",
      "        [3.7416, 3.6006, 3.6579, 3.7342, 3.7762],\n",
      "        [3.4647, 3.5287, 3.6369, 3.6676, 3.5419],\n",
      "        [3.7312, 3.9369, 3.9395, 3.9615, 3.7862],\n",
      "        [3.7200, 3.8847, 3.9091, 3.8436, 3.6689],\n",
      "        [3.5613, 3.6025, 3.7951, 3.7748, 3.6659],\n",
      "        [3.6558, 3.7221, 3.8562, 3.8495, 3.7182],\n",
      "        [3.6180, 3.7393, 3.7622, 3.8336, 3.7778],\n",
      "        [3.5493, 3.5486, 3.7552, 3.6109, 3.6895],\n",
      "        [3.5211, 3.7088, 3.8560, 3.7142, 3.6586],\n",
      "        [3.5508, 3.5611, 3.7290, 3.7079, 3.6273],\n",
      "        [3.5023, 3.5937, 3.6905, 3.7223, 3.5615],\n",
      "        [3.9174, 3.7761, 3.9604, 4.3985, 4.1978],\n",
      "        [3.6818, 3.8202, 3.9364, 3.9183, 3.8358],\n",
      "        [3.5312, 3.8753, 3.7903, 3.7437, 3.5683],\n",
      "        [3.9382, 3.8492, 3.9261, 4.0326, 3.9287],\n",
      "        [3.6689, 3.8802, 3.8164, 3.7830, 3.7834],\n",
      "        [3.7145, 3.7455, 3.8220, 3.7991, 3.5889],\n",
      "        [3.5536, 3.5992, 3.7238, 3.7246, 3.6377],\n",
      "        [3.5935, 3.6231, 3.7214, 3.7233, 3.7153],\n",
      "        [3.4486, 3.4966, 3.6125, 3.6514, 3.5064],\n",
      "        [3.7050, 3.8908, 3.7916, 4.0070, 3.8271],\n",
      "        [3.5974, 3.7109, 3.7354, 3.7323, 3.6843],\n",
      "        [3.5776, 3.6585, 3.8266, 3.7582, 3.7803],\n",
      "        [4.0191, 4.1276, 3.8122, 3.9637, 3.7743],\n",
      "        [3.3756, 3.4845, 3.5607, 3.5392, 3.4863],\n",
      "        [3.4991, 3.6504, 3.5912, 3.6785, 3.6010],\n",
      "        [4.0083, 4.1328, 3.8347, 3.9780, 3.8022],\n",
      "        [3.4869, 3.5436, 3.7366, 3.6915, 3.5924],\n",
      "        [3.5233, 3.7299, 3.6494, 3.8213, 3.5925],\n",
      "        [3.4513, 3.6914, 3.7273, 3.8083, 3.5342],\n",
      "        [3.4621, 3.5348, 3.6512, 3.6577, 3.5144],\n",
      "        [3.6402, 3.6780, 3.8546, 3.8346, 3.7414],\n",
      "        [3.5247, 3.5368, 3.7140, 3.6901, 3.5945],\n",
      "        [3.6026, 3.6398, 3.8189, 3.8054, 3.7199],\n",
      "        [3.5569, 3.5909, 3.7434, 3.7216, 3.6296],\n",
      "        [3.5232, 3.6787, 3.6081, 3.7168, 3.6154],\n",
      "        [3.8846, 3.7728, 3.9358, 4.0576, 3.8446],\n",
      "        [3.7414, 3.8271, 3.9013, 3.9374, 3.7059],\n",
      "        [3.4433, 3.4658, 3.5976, 3.6469, 3.4862],\n",
      "        [3.5527, 3.6981, 3.6064, 3.7606, 3.6305],\n",
      "        [4.0374, 4.1400, 3.8027, 3.9767, 3.7635],\n",
      "        [3.8486, 3.9534, 3.8779, 3.9896, 3.9497],\n",
      "        [3.7260, 3.9370, 3.8114, 3.8804, 3.8232],\n",
      "        [3.4947, 3.5761, 3.7237, 3.7227, 3.6984],\n",
      "        [3.8031, 4.0573, 3.9221, 4.0511, 3.9871],\n",
      "        [3.7436, 3.9412, 3.9256, 3.9247, 3.7917],\n",
      "        [3.5460, 3.6720, 3.6363, 3.7271, 3.6495],\n",
      "        [3.7434, 4.0491, 3.9294, 4.0810, 3.9632],\n",
      "        [3.7363, 3.8885, 3.9331, 3.9290, 3.9564],\n",
      "        [3.5783, 3.6942, 3.6731, 3.8111, 3.6709],\n",
      "        [3.8749, 3.7237, 3.8238, 4.2365, 3.9830],\n",
      "        [3.5668, 3.5436, 3.6931, 3.7249, 3.7384],\n",
      "        [3.4372, 3.5898, 3.6877, 3.6564, 3.5335],\n",
      "        [3.4321, 3.5436, 3.6424, 3.6284, 3.5288],\n",
      "        [3.5713, 3.6656, 3.7615, 3.7849, 3.6837]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5297, 3.6822, 3.7443, 3.7887, 3.6817],\n",
      "        [3.4813, 3.6454, 3.6009, 3.6609, 3.5866],\n",
      "        [3.6951, 3.8450, 3.8679, 3.8588, 3.6470],\n",
      "        [3.5562, 3.7051, 3.6245, 3.7658, 3.6385],\n",
      "        [3.5568, 3.9546, 3.7613, 3.7876, 3.8705],\n",
      "        [3.6787, 3.9453, 3.9167, 3.8948, 3.7480],\n",
      "        [4.2475, 4.4073, 4.1087, 4.1935, 3.9670],\n",
      "        [3.5695, 3.7238, 3.6341, 3.7892, 3.6511],\n",
      "        [3.5619, 3.6491, 3.7548, 3.7678, 3.6554],\n",
      "        [3.5647, 3.7338, 3.7871, 3.9086, 3.6483],\n",
      "        [3.5074, 3.5963, 3.7374, 3.7213, 3.6281],\n",
      "        [3.7745, 3.5632, 3.6429, 3.7248, 3.7713],\n",
      "        [3.5041, 3.6282, 3.6275, 3.6356, 3.5768],\n",
      "        [3.7465, 3.7746, 3.8140, 3.9356, 3.8891],\n",
      "        [3.4933, 3.7918, 3.7602, 3.7756, 3.7871],\n",
      "        [3.5327, 3.6102, 3.8394, 3.6006, 3.7827],\n",
      "        [3.6323, 3.8893, 3.7754, 3.9377, 3.7697],\n",
      "        [3.5537, 3.5994, 3.7907, 3.7662, 3.6716],\n",
      "        [3.8029, 3.8464, 3.8868, 3.9804, 3.9693],\n",
      "        [3.5351, 3.6852, 3.6179, 3.7321, 3.6285],\n",
      "        [3.6462, 3.7432, 3.7113, 3.8260, 3.7227],\n",
      "        [4.1538, 4.3318, 4.0263, 4.1068, 3.8996],\n",
      "        [3.5705, 3.5331, 3.6895, 3.6265, 3.5446],\n",
      "        [3.7030, 3.7876, 3.8620, 3.9133, 3.9137],\n",
      "        [3.4611, 3.5350, 3.6578, 3.6551, 3.5125],\n",
      "        [3.4059, 3.6444, 3.6906, 3.6300, 3.5555],\n",
      "        [3.7063, 3.8975, 3.8823, 4.0076, 3.7887],\n",
      "        [3.5882, 3.6105, 3.8030, 3.7572, 3.6976],\n",
      "        [3.6952, 3.8227, 3.8038, 3.8356, 3.8138],\n",
      "        [3.5293, 3.6956, 3.6158, 3.7314, 3.6247],\n",
      "        [3.7172, 3.8027, 3.8900, 3.8465, 3.7723],\n",
      "        [3.9378, 3.9750, 3.9663, 4.2130, 3.8479],\n",
      "        [3.6502, 3.6105, 3.9704, 3.8388, 3.7872],\n",
      "        [3.9674, 3.9467, 3.8974, 4.1052, 4.0461],\n",
      "        [3.4706, 3.6095, 3.5843, 3.6896, 3.5187],\n",
      "        [3.5788, 3.6114, 3.7012, 3.7026, 3.6989],\n",
      "        [3.3706, 3.5447, 3.4774, 3.6343, 3.4705],\n",
      "        [3.7187, 3.8947, 3.8697, 3.9259, 3.7823],\n",
      "        [3.9279, 4.0371, 3.9960, 4.0577, 4.0382],\n",
      "        [3.5506, 3.6249, 3.7395, 3.7354, 3.6459],\n",
      "        [4.0595, 4.0683, 4.0757, 4.3083, 4.0049],\n",
      "        [3.8013, 4.0599, 3.9303, 4.0483, 3.9898],\n",
      "        [3.6458, 3.8578, 3.8121, 3.8815, 3.7281],\n",
      "        [3.7063, 3.8338, 3.9361, 3.8347, 3.6481],\n",
      "        [4.1031, 4.2502, 4.0322, 4.0642, 3.9400],\n",
      "        [3.4209, 3.5860, 3.5805, 3.5854, 3.5371],\n",
      "        [3.6773, 3.9750, 3.8561, 3.8868, 3.8128],\n",
      "        [3.6200, 3.6574, 3.8544, 3.9190, 3.8969],\n",
      "        [3.7267, 3.6960, 3.7810, 3.7262, 3.5936],\n",
      "        [3.5493, 3.7448, 3.6631, 3.8495, 3.5985],\n",
      "        [3.8916, 3.9157, 3.9318, 4.1932, 3.9219],\n",
      "        [3.4419, 3.5772, 3.6666, 3.6351, 3.5584],\n",
      "        [3.4517, 3.6613, 3.5874, 3.7015, 3.5700],\n",
      "        [3.5056, 3.5862, 3.7185, 3.6883, 3.6087],\n",
      "        [3.7618, 3.8607, 3.9393, 4.0384, 3.7672],\n",
      "        [3.4733, 3.6167, 3.7316, 3.6968, 3.5478],\n",
      "        [3.6239, 3.6035, 3.7639, 3.7664, 3.6531],\n",
      "        [3.4544, 3.4934, 3.6169, 3.6537, 3.5052],\n",
      "        [3.6001, 3.8710, 3.8345, 3.9416, 3.6816],\n",
      "        [3.5858, 3.9835, 3.7838, 3.8078, 3.9033],\n",
      "        [3.7425, 3.9413, 3.9326, 3.9220, 3.7897],\n",
      "        [3.6761, 3.9525, 3.7859, 3.8705, 3.9348],\n",
      "        [3.5509, 3.7020, 3.6078, 3.7597, 3.6305],\n",
      "        [3.5416, 3.6716, 3.6479, 3.7466, 3.6111]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3801, 3.4575, 3.5979, 3.5447, 3.4444],\n",
      "        [3.6344, 3.9928, 3.7950, 3.8202, 3.9219],\n",
      "        [3.5426, 3.7124, 3.7776, 3.9276, 3.5993],\n",
      "        [3.7049, 3.7303, 3.8337, 3.7874, 3.5974],\n",
      "        [3.9228, 3.9219, 4.0058, 4.1482, 3.9264],\n",
      "        [3.6527, 3.6530, 3.7994, 3.7086, 3.6251],\n",
      "        [3.5560, 3.5932, 3.7747, 3.7184, 3.6307],\n",
      "        [3.6629, 3.7558, 3.7541, 3.7844, 3.6858],\n",
      "        [3.8984, 3.9308, 4.0125, 4.1140, 3.9288],\n",
      "        [3.4145, 3.6697, 3.7147, 3.6357, 3.5795],\n",
      "        [3.4342, 3.8882, 3.8353, 3.7298, 3.8338],\n",
      "        [4.0445, 3.9809, 4.0919, 4.2582, 4.0713],\n",
      "        [3.5696, 3.6945, 3.7462, 3.6962, 3.5688],\n",
      "        [3.9159, 4.0859, 3.9153, 3.8996, 3.8217],\n",
      "        [3.5618, 3.6863, 3.6666, 3.7419, 3.6683],\n",
      "        [3.5656, 3.7227, 3.6310, 3.7827, 3.6482],\n",
      "        [3.6747, 3.7263, 3.8237, 3.7700, 3.8252],\n",
      "        [3.5718, 3.6447, 3.8424, 3.6451, 3.8109],\n",
      "        [3.6874, 3.8502, 3.8073, 3.8315, 3.8522],\n",
      "        [3.5939, 3.6682, 3.7694, 3.7266, 3.8439],\n",
      "        [3.6706, 3.6611, 3.9230, 3.8910, 3.7168],\n",
      "        [3.5356, 3.5561, 3.7446, 3.6996, 3.5999],\n",
      "        [3.7425, 3.9489, 3.8116, 3.8368, 3.7791],\n",
      "        [3.5336, 3.6258, 3.8043, 3.7420, 3.6589],\n",
      "        [3.5509, 3.5877, 3.7546, 3.7176, 3.6203],\n",
      "        [3.4563, 3.4847, 3.6264, 3.6508, 3.5008],\n",
      "        [3.5365, 3.6768, 3.7513, 3.7707, 3.7113],\n",
      "        [3.5974, 3.5893, 3.8657, 3.8355, 3.6670],\n",
      "        [3.5431, 3.6210, 3.7459, 3.7305, 3.6348],\n",
      "        [3.5469, 3.5485, 3.7725, 3.6055, 3.6866],\n",
      "        [3.8177, 3.8208, 3.9821, 4.1087, 3.7435],\n",
      "        [3.5235, 3.6812, 3.6186, 3.7073, 3.6166],\n",
      "        [3.4615, 3.6338, 3.6120, 3.6385, 3.5811],\n",
      "        [3.5594, 3.5421, 3.6959, 3.7050, 3.7294],\n",
      "        [3.9218, 3.7752, 3.9707, 4.0527, 3.8841],\n",
      "        [3.4046, 3.6443, 3.7006, 3.6272, 3.5545],\n",
      "        [3.7025, 3.8907, 3.8102, 4.0014, 3.8242],\n",
      "        [3.5432, 3.6000, 3.7352, 3.7131, 3.6284],\n",
      "        [3.5680, 3.7894, 3.8285, 3.7880, 3.6280],\n",
      "        [3.5300, 3.9514, 3.7596, 3.7537, 3.8480],\n",
      "        [3.6425, 3.6218, 4.0059, 3.8410, 3.7947],\n",
      "        [3.5208, 3.5345, 3.7256, 3.6806, 3.5891],\n",
      "        [3.5703, 3.6378, 3.8359, 3.6724, 3.7950],\n",
      "        [3.8203, 3.8745, 4.0200, 4.0875, 3.7941],\n",
      "        [3.5627, 3.7807, 3.7475, 3.7643, 3.7177],\n",
      "        [4.1946, 4.3541, 4.0568, 4.1061, 3.9190],\n",
      "        [3.5599, 3.5429, 3.7103, 3.6383, 3.5553],\n",
      "        [3.5207, 3.6120, 3.6712, 3.6401, 3.6282],\n",
      "        [3.4891, 3.8862, 3.7937, 3.8082, 3.8152],\n",
      "        [3.5307, 3.5299, 3.7694, 3.5721, 3.6836],\n",
      "        [3.7666, 3.7953, 3.8689, 3.8797, 3.9053],\n",
      "        [3.5485, 3.9206, 3.7975, 3.8658, 3.8024],\n",
      "        [3.5721, 3.6838, 3.6755, 3.8000, 3.6599],\n",
      "        [3.9672, 4.0980, 3.9830, 4.1539, 4.1705],\n",
      "        [3.4311, 3.6063, 3.6030, 3.5953, 3.5616],\n",
      "        [3.6951, 3.7068, 3.7376, 3.9512, 3.7829],\n",
      "        [3.8179, 3.8471, 3.8985, 3.9948, 3.9685],\n",
      "        [3.8537, 3.9518, 3.8978, 3.9891, 3.9487],\n",
      "        [3.5750, 3.7427, 3.7971, 3.7475, 3.7852],\n",
      "        [3.6094, 3.6670, 3.7625, 3.7977, 3.6807],\n",
      "        [3.3829, 3.5604, 3.5771, 3.5414, 3.5145],\n",
      "        [3.5928, 3.8651, 3.9490, 3.9334, 3.7501],\n",
      "        [3.5323, 3.6895, 3.6274, 3.7295, 3.6242],\n",
      "        [3.4275, 3.5389, 3.6545, 3.6238, 3.5247]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5342, 3.6598, 3.7099, 3.6858, 3.6257],\n",
      "        [3.6368, 3.9273, 3.8623, 3.8695, 3.8724],\n",
      "        [3.6915, 3.7061, 3.7534, 3.9512, 3.7820],\n",
      "        [3.4043, 3.6965, 3.8402, 3.6530, 3.6491],\n",
      "        [3.7213, 3.8769, 3.9277, 3.9197, 3.7919],\n",
      "        [3.8957, 3.8089, 3.8836, 3.9577, 3.9173],\n",
      "        [3.6662, 3.8421, 3.8648, 3.8193, 3.6215],\n",
      "        [3.7052, 3.8405, 3.9685, 3.9392, 3.8863],\n",
      "        [3.9259, 3.7973, 3.9896, 4.3975, 4.1917],\n",
      "        [3.6331, 3.9924, 3.8042, 3.8174, 3.9207],\n",
      "        [3.5911, 3.6249, 3.8027, 3.7674, 3.6774],\n",
      "        [3.4504, 3.6384, 3.7489, 3.6734, 3.5723],\n",
      "        [3.5490, 3.6977, 3.6333, 3.7525, 3.6267],\n",
      "        [3.5717, 4.0248, 3.9495, 3.7791, 3.7003],\n",
      "        [3.9788, 3.9143, 3.9854, 4.0994, 4.0002],\n",
      "        [3.5499, 3.6056, 3.7573, 3.7197, 3.6347],\n",
      "        [3.4230, 3.6955, 3.7397, 3.6326, 3.5860],\n",
      "        [3.5737, 3.9785, 3.8062, 3.9341, 3.8246],\n",
      "        [3.9517, 4.0128, 4.0062, 4.2453, 4.0186],\n",
      "        [3.7830, 3.7342, 3.8276, 3.7900, 3.6632],\n",
      "        [3.5598, 3.6129, 3.8257, 3.7697, 3.6778],\n",
      "        [3.5981, 3.8063, 3.7664, 3.7627, 3.7359],\n",
      "        [3.3529, 3.5304, 3.5706, 3.5015, 3.4915],\n",
      "        [3.8984, 3.9403, 3.9149, 4.0270, 3.9943],\n",
      "        [3.7151, 3.7556, 3.8448, 3.8016, 3.5730],\n",
      "        [3.7092, 3.7641, 3.6935, 3.8867, 3.8322],\n",
      "        [3.9446, 3.9334, 3.9843, 4.1314, 3.9724],\n",
      "        [3.9255, 3.9263, 4.0265, 4.1586, 3.9291],\n",
      "        [3.5360, 3.5747, 3.7582, 3.7096, 3.6136],\n",
      "        [3.8247, 3.8639, 3.9725, 4.0799, 4.0578],\n",
      "        [3.5708, 3.6835, 3.6846, 3.7972, 3.6588],\n",
      "        [3.6989, 3.8871, 3.8138, 3.9889, 3.8115],\n",
      "        [3.5483, 3.6156, 3.7527, 3.7183, 3.6332],\n",
      "        [3.9214, 3.9216, 4.0171, 4.1453, 3.9256],\n",
      "        [3.4525, 3.6150, 3.7559, 3.6821, 3.5353],\n",
      "        [3.4576, 3.6053, 3.6133, 3.6726, 3.5410],\n",
      "        [3.5350, 3.5678, 3.7336, 3.6632, 3.5833],\n",
      "        [3.6764, 3.6749, 3.8259, 3.8070, 3.6806],\n",
      "        [3.5645, 3.5714, 3.7837, 3.7492, 3.7365],\n",
      "        [3.5761, 3.6928, 3.6064, 3.7732, 3.5539],\n",
      "        [3.9273, 3.8688, 3.9028, 4.0226, 3.9434],\n",
      "        [3.5705, 3.7119, 3.7658, 3.7529, 3.7022],\n",
      "        [3.5447, 3.6903, 3.7721, 3.7742, 3.7175],\n",
      "        [3.7976, 4.0736, 3.9330, 4.0184, 4.0251],\n",
      "        [3.5294, 3.6305, 3.6649, 3.6955, 3.6894],\n",
      "        [3.4881, 3.4834, 3.7000, 3.6681, 3.6381],\n",
      "        [3.4851, 3.6387, 3.6100, 3.6544, 3.5718],\n",
      "        [3.5644, 3.6481, 3.7764, 3.7577, 3.6719],\n",
      "        [3.4969, 3.9990, 3.7906, 3.7147, 3.8100],\n",
      "        [3.4589, 3.6889, 3.9250, 3.7079, 3.7863],\n",
      "        [3.5666, 3.9822, 3.9581, 3.8300, 3.6984],\n",
      "        [3.8020, 3.9807, 3.9468, 3.8104, 3.8664],\n",
      "        [3.7490, 3.8878, 3.8237, 3.9417, 3.8740],\n",
      "        [3.5483, 3.7014, 3.6278, 3.7542, 3.6286],\n",
      "        [3.7202, 3.7664, 4.0217, 3.8223, 3.6166],\n",
      "        [3.5738, 3.7422, 3.8059, 3.7446, 3.7840],\n",
      "        [3.5819, 3.6594, 3.8791, 3.8053, 3.7174],\n",
      "        [3.5474, 3.6156, 3.7563, 3.7241, 3.6388],\n",
      "        [3.5696, 3.6886, 3.7502, 3.6856, 3.5674],\n",
      "        [3.6124, 3.9577, 3.7961, 3.8118, 3.8855],\n",
      "        [3.5366, 3.7325, 3.6723, 3.8390, 3.5835],\n",
      "        [3.7631, 3.5724, 3.6770, 3.7224, 3.7630],\n",
      "        [3.5867, 3.9490, 3.8221, 3.8987, 3.8187],\n",
      "        [3.6704, 3.7578, 3.7045, 3.7960, 3.7842]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5687, 3.6631, 3.7769, 3.7312, 3.7967],\n",
      "        [3.5280, 3.5297, 3.7868, 3.5679, 3.6809],\n",
      "        [3.6772, 3.8491, 3.7961, 3.8356, 3.7542],\n",
      "        [3.6961, 3.7145, 3.8448, 3.7751, 3.5944],\n",
      "        [3.8057, 3.9477, 3.8997, 3.9460, 3.9368],\n",
      "        [3.8835, 3.9849, 3.9944, 4.0000, 3.9579],\n",
      "        [3.5598, 3.8480, 3.7222, 3.8671, 3.7191],\n",
      "        [3.7504, 3.7899, 3.9962, 3.8788, 3.5875],\n",
      "        [3.7155, 3.9418, 3.8366, 3.8284, 3.7814],\n",
      "        [3.7768, 4.0011, 3.8914, 3.7694, 3.7889],\n",
      "        [3.3998, 3.6626, 3.7208, 3.6144, 3.5576],\n",
      "        [3.8976, 3.7568, 3.8432, 3.9468, 3.8831],\n",
      "        [3.4585, 3.5336, 3.5644, 3.6802, 3.4844],\n",
      "        [3.6032, 3.6492, 3.8431, 3.7657, 3.7084],\n",
      "        [3.7888, 3.6811, 3.8240, 4.1262, 3.8982],\n",
      "        [3.4593, 3.6246, 3.7813, 3.7551, 3.6524],\n",
      "        [3.5249, 3.6073, 3.7747, 3.7423, 3.7140],\n",
      "        [3.4537, 3.8749, 3.7061, 3.6577, 3.7289],\n",
      "        [3.8019, 3.9783, 3.8227, 3.8435, 3.7721],\n",
      "        [3.9790, 3.9006, 4.0841, 4.1911, 3.9618],\n",
      "        [3.9711, 4.0208, 4.0701, 4.2695, 4.0143],\n",
      "        [3.4022, 3.4722, 3.6348, 3.6116, 3.5095],\n",
      "        [3.7146, 3.8944, 3.8990, 3.9190, 3.7788],\n",
      "        [3.4973, 3.6521, 3.7010, 3.5763, 3.5811],\n",
      "        [3.4577, 3.5327, 3.5638, 3.6798, 3.4838],\n",
      "        [3.3707, 3.4844, 3.5936, 3.5300, 3.4810],\n",
      "        [3.5335, 3.6339, 3.6784, 3.6478, 3.6156],\n",
      "        [3.5878, 3.6092, 3.8216, 3.7558, 3.6486],\n",
      "        [3.6747, 4.0267, 3.9785, 3.9327, 3.9575],\n",
      "        [3.5208, 3.6810, 3.6362, 3.7032, 3.6142],\n",
      "        [3.6423, 3.7427, 3.7390, 3.8192, 3.7191],\n",
      "        [3.4075, 3.6814, 3.7342, 3.6194, 3.5726],\n",
      "        [3.4069, 3.6225, 3.7045, 3.6112, 3.5401],\n",
      "        [3.5996, 3.8877, 3.7265, 3.7933, 3.6780],\n",
      "        [3.4581, 3.6276, 3.6218, 3.6384, 3.5682],\n",
      "        [3.9072, 3.7946, 3.8866, 3.9742, 3.9180],\n",
      "        [3.6479, 3.9650, 3.8217, 3.8409, 3.9123],\n",
      "        [3.4540, 3.5255, 3.5634, 3.6825, 3.5076],\n",
      "        [4.0058, 3.9399, 4.0478, 4.1449, 4.0561],\n",
      "        [3.7444, 3.7888, 3.8619, 3.9338, 3.9068],\n",
      "        [3.5628, 3.7225, 3.6490, 3.7786, 3.6458],\n",
      "        [3.6243, 3.6103, 3.7972, 3.7427, 3.7085],\n",
      "        [3.7113, 3.9619, 3.9624, 3.9499, 3.9195],\n",
      "        [3.5431, 3.6143, 3.7617, 3.7280, 3.6406],\n",
      "        [3.5552, 3.5848, 3.6959, 3.6666, 3.6678],\n",
      "        [3.4551, 3.6635, 3.6201, 3.6988, 3.5716],\n",
      "        [3.6043, 3.8566, 3.7480, 3.6122, 3.6542],\n",
      "        [3.6953, 3.8242, 3.8145, 3.7280, 3.7176],\n",
      "        [3.5653, 3.8688, 3.8336, 3.7524, 3.5643],\n",
      "        [3.5326, 3.7400, 3.7898, 3.7303, 3.6983],\n",
      "        [3.5501, 3.5759, 3.7780, 3.7006, 3.6244],\n",
      "        [3.4616, 3.5845, 3.7298, 3.6876, 3.5265],\n",
      "        [3.5581, 3.8142, 3.7582, 3.7012, 3.7009],\n",
      "        [3.7676, 3.9349, 4.0078, 3.9748, 3.9856],\n",
      "        [3.4078, 3.5856, 3.6901, 3.6087, 3.5296],\n",
      "        [3.9477, 3.9247, 3.8797, 4.0639, 4.0530],\n",
      "        [3.6314, 3.5908, 3.7499, 3.7176, 3.6992],\n",
      "        [3.5383, 3.6160, 3.7588, 3.7198, 3.6303],\n",
      "        [3.6114, 3.8246, 3.7948, 3.8505, 3.6954],\n",
      "        [3.7643, 3.6618, 3.8017, 4.1514, 3.8751],\n",
      "        [3.4098, 3.6977, 3.5764, 3.7012, 3.5128],\n",
      "        [3.5539, 3.9055, 3.9032, 3.8523, 3.8700],\n",
      "        [3.8048, 3.9884, 4.0128, 4.0186, 3.9354],\n",
      "        [3.6499, 3.6528, 3.8168, 3.7045, 3.6224]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3627, 3.5502, 3.5978, 3.5131, 3.5003],\n",
      "        [3.6923, 3.8848, 3.8317, 3.9863, 3.8104],\n",
      "        [3.6668, 3.8451, 3.8858, 3.8181, 3.6207],\n",
      "        [3.4242, 3.6227, 3.7507, 3.6422, 3.5590],\n",
      "        [3.6485, 3.9635, 3.9158, 3.8886, 3.8860],\n",
      "        [3.5526, 3.6376, 3.7874, 3.7322, 3.6472],\n",
      "        [3.5802, 3.6645, 3.7916, 3.7251, 3.8180],\n",
      "        [3.4980, 3.5997, 3.7686, 3.7166, 3.6234],\n",
      "        [3.5309, 3.5685, 3.6797, 3.6399, 3.6553],\n",
      "        [3.7969, 3.8373, 3.9719, 4.0176, 3.8078],\n",
      "        [3.6708, 3.7268, 3.8495, 3.7644, 3.8208],\n",
      "        [3.7189, 3.9385, 3.8643, 3.8690, 3.8175],\n",
      "        [3.4615, 3.6139, 3.6372, 3.6844, 3.5420],\n",
      "        [3.6711, 3.6910, 3.8474, 3.7425, 3.6064],\n",
      "        [3.4090, 3.5782, 3.7979, 3.6413, 3.6411],\n",
      "        [3.7063, 3.9548, 3.9686, 3.9364, 3.9179],\n",
      "        [3.5583, 3.8071, 3.8158, 3.6944, 3.7273],\n",
      "        [3.9832, 3.7724, 3.9882, 4.3546, 4.2031],\n",
      "        [3.9148, 3.7460, 3.8966, 4.3011, 4.0453],\n",
      "        [3.5915, 3.9834, 3.8804, 3.9183, 3.8697],\n",
      "        [3.5184, 3.5981, 3.7902, 3.7358, 3.7130],\n",
      "        [3.4954, 3.5002, 3.6488, 3.6497, 3.5037],\n",
      "        [3.5823, 3.6705, 3.8099, 3.6501, 3.4809],\n",
      "        [3.5447, 3.6103, 3.7684, 3.7244, 3.6305],\n",
      "        [3.5396, 3.8670, 3.8359, 3.7361, 3.5544],\n",
      "        [3.8163, 3.8752, 4.0490, 4.0817, 3.7903],\n",
      "        [3.4257, 3.5443, 3.6850, 3.6175, 3.5219],\n",
      "        [3.5358, 3.6970, 3.6574, 3.7314, 3.6268],\n",
      "        [3.5106, 3.6125, 3.5477, 3.7584, 3.4828],\n",
      "        [3.5539, 3.5856, 3.7042, 3.6652, 3.6662],\n",
      "        [3.4349, 3.5339, 3.6832, 3.6259, 3.5206],\n",
      "        [3.5693, 3.7371, 3.6702, 3.7905, 3.6517],\n",
      "        [3.4974, 3.7003, 3.8232, 3.7712, 3.5757],\n",
      "        [3.6790, 3.7382, 3.8257, 3.7640, 3.5098],\n",
      "        [3.7434, 3.9246, 3.8646, 3.8825, 3.8517],\n",
      "        [3.7852, 3.8470, 3.9302, 3.9311, 3.9144],\n",
      "        [3.7049, 3.8837, 3.8534, 3.8974, 3.7763],\n",
      "        [3.8324, 3.5940, 3.8495, 4.1412, 4.0245],\n",
      "        [3.7333, 3.5411, 3.6869, 3.7445, 3.6981],\n",
      "        [3.6825, 3.8104, 3.8092, 3.7137, 3.7006],\n",
      "        [3.9736, 3.8468, 4.0421, 4.1712, 3.9769],\n",
      "        [3.5933, 3.6557, 3.8862, 3.9193, 3.8879],\n",
      "        [3.8856, 3.7859, 3.9982, 4.0795, 3.8549],\n",
      "        [3.7454, 3.6010, 3.7082, 3.7274, 3.7769],\n",
      "        [3.6338, 3.9287, 3.8797, 3.8666, 3.8695],\n",
      "        [3.5557, 3.5426, 3.7209, 3.6996, 3.7251],\n",
      "        [3.4880, 3.5768, 3.7685, 3.7117, 3.6918],\n",
      "        [3.7382, 3.8101, 3.9461, 3.9344, 3.6734],\n",
      "        [3.4522, 3.6162, 3.6087, 3.6835, 3.5560],\n",
      "        [3.6670, 3.8214, 3.8558, 3.8382, 3.8650],\n",
      "        [3.7269, 3.7014, 3.8167, 3.7092, 3.5973],\n",
      "        [3.5482, 3.6682, 3.7762, 3.7416, 3.7521],\n",
      "        [3.4437, 3.4799, 3.6436, 3.6366, 3.4910],\n",
      "        [3.8517, 3.8722, 3.9894, 4.0583, 3.8681],\n",
      "        [3.7683, 3.8282, 3.9299, 3.9575, 3.9147],\n",
      "        [3.8088, 3.8298, 4.0086, 3.9757, 3.6939],\n",
      "        [3.6484, 3.6536, 3.8255, 3.7029, 3.6208],\n",
      "        [3.9321, 3.9763, 4.0138, 4.2042, 3.8446],\n",
      "        [3.9447, 3.8158, 4.0283, 4.4170, 4.1945],\n",
      "        [3.7167, 3.6976, 3.7980, 4.0382, 3.8378],\n",
      "        [3.6274, 3.8523, 3.8668, 3.8037, 3.6007],\n",
      "        [3.6321, 3.8386, 3.8238, 3.8595, 3.7108],\n",
      "        [3.5337, 3.8475, 3.8840, 3.6614, 3.7558],\n",
      "        [3.5522, 4.0186, 3.9687, 3.7632, 3.6888]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7450, 3.6014, 3.7157, 3.7259, 3.7764],\n",
      "        [3.4316, 3.4671, 3.6428, 3.6256, 3.4793],\n",
      "        [3.4432, 3.5895, 3.7356, 3.6435, 3.5339],\n",
      "        [3.6867, 3.8413, 3.9612, 3.7990, 3.6297],\n",
      "        [3.5847, 3.6744, 3.9178, 3.8082, 3.7226],\n",
      "        [3.7864, 3.8364, 3.9612, 3.9680, 3.7241],\n",
      "        [3.4980, 3.4931, 3.7366, 3.6792, 3.6343],\n",
      "        [3.4354, 3.4722, 3.6459, 3.6291, 3.4823],\n",
      "        [3.5935, 3.8729, 3.8895, 3.9310, 3.6781],\n",
      "        [3.6478, 3.9642, 3.9236, 3.8867, 3.8855],\n",
      "        [3.5440, 3.6108, 3.7762, 3.7226, 3.6300],\n",
      "        [3.5458, 3.6460, 3.7980, 3.7433, 3.6466],\n",
      "        [3.4133, 3.5667, 3.7013, 3.6115, 3.5241],\n",
      "        [3.6349, 3.9500, 3.9078, 3.8740, 3.8742],\n",
      "        [3.6727, 3.6835, 3.8344, 3.7949, 3.6690],\n",
      "        [3.6113, 3.7294, 3.8149, 3.7587, 3.7847],\n",
      "        [3.5257, 3.5310, 3.8033, 3.5644, 3.6787],\n",
      "        [3.6002, 3.6463, 3.8608, 3.7730, 3.7011],\n",
      "        [3.4905, 3.6520, 3.6492, 3.6544, 3.6014],\n",
      "        [3.4675, 3.5803, 3.7375, 3.6902, 3.5290],\n",
      "        [3.7130, 3.8574, 3.8462, 3.8205, 3.7457],\n",
      "        [3.6260, 4.0209, 3.8719, 3.9738, 3.8603],\n",
      "        [3.6700, 3.6978, 3.7959, 3.9142, 3.7594],\n",
      "        [3.5308, 3.6905, 3.6532, 3.7361, 3.6115],\n",
      "        [3.6972, 3.8920, 3.8466, 3.9934, 3.8196],\n",
      "        [3.4705, 3.6261, 3.6345, 3.6369, 3.5618],\n",
      "        [3.8438, 3.8680, 3.9929, 4.0536, 3.8577],\n",
      "        [3.7137, 3.8423, 3.8511, 3.7644, 3.7321],\n",
      "        [3.5498, 3.7172, 3.8336, 3.9205, 3.6131],\n",
      "        [3.8616, 3.9045, 4.0050, 4.0768, 3.8287],\n",
      "        [3.6972, 3.8920, 3.8466, 3.9934, 3.8196],\n",
      "        [3.9387, 3.9361, 3.8965, 4.0800, 4.0696],\n",
      "        [3.4421, 3.6052, 3.6070, 3.6408, 3.5003],\n",
      "        [3.4558, 3.6218, 3.7927, 3.7507, 3.6535],\n",
      "        [3.7191, 3.9295, 3.8706, 3.8664, 3.8230],\n",
      "        [3.4263, 3.6076, 3.6356, 3.5879, 3.5570],\n",
      "        [3.7747, 4.0025, 3.9079, 3.7659, 3.7867],\n",
      "        [3.5107, 3.6844, 3.6604, 3.7038, 3.6065],\n",
      "        [3.6716, 3.7352, 3.8433, 3.8355, 3.7952],\n",
      "        [3.5883, 3.6243, 3.8429, 3.7309, 3.6583],\n",
      "        [3.4529, 3.6649, 3.6360, 3.6953, 3.5695],\n",
      "        [3.7480, 4.0686, 3.9714, 3.9076, 4.0841],\n",
      "        [3.7127, 3.8275, 3.9202, 3.7945, 3.7757],\n",
      "        [3.4189, 3.8054, 3.7712, 3.5492, 3.7153],\n",
      "        [3.7161, 3.6981, 3.8057, 4.0365, 3.8374],\n",
      "        [3.7994, 3.9427, 4.0744, 4.1282, 4.1418],\n",
      "        [3.7433, 3.7932, 3.9474, 3.9265, 3.6476],\n",
      "        [3.5503, 3.6001, 3.7812, 3.7140, 3.6320],\n",
      "        [3.8939, 3.9323, 4.0490, 4.1062, 3.9244],\n",
      "        [3.6086, 3.6769, 3.8202, 3.7303, 3.8658],\n",
      "        [4.0603, 4.2183, 3.9783, 3.9943, 3.8121],\n",
      "        [3.5668, 3.7204, 3.7526, 3.8060, 3.7017],\n",
      "        [3.6814, 3.8877, 3.8941, 3.9673, 3.7779],\n",
      "        [3.6972, 3.8920, 3.8466, 3.9934, 3.8196],\n",
      "        [3.4829, 3.6352, 3.6655, 3.7157, 3.5570],\n",
      "        [3.9199, 4.0624, 3.8560, 3.8908, 3.7787],\n",
      "        [3.4422, 3.4835, 3.6567, 3.6431, 3.4878],\n",
      "        [3.6177, 3.4999, 3.9027, 3.8078, 3.7354],\n",
      "        [3.5359, 3.6917, 3.6591, 3.7291, 3.6231],\n",
      "        [3.5216, 3.6357, 3.6937, 3.6913, 3.6881],\n",
      "        [3.5304, 3.5689, 3.6869, 3.6382, 3.6546],\n",
      "        [3.7123, 3.8958, 3.9160, 3.9155, 3.7767],\n",
      "        [3.5002, 3.7129, 3.8287, 3.8234, 3.5853],\n",
      "        [3.3621, 3.5507, 3.6050, 3.5113, 3.4997]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5839, 3.8804, 3.7400, 3.7587, 3.6639],\n",
      "        [3.8003, 3.8238, 4.0305, 3.9503, 3.6680],\n",
      "        [3.9590, 3.9443, 3.9092, 4.0775, 4.0608],\n",
      "        [3.6635, 3.7225, 3.9449, 3.8684, 3.6957],\n",
      "        [3.5088, 3.5049, 3.7984, 3.5280, 3.6708],\n",
      "        [3.6701, 3.6812, 3.8373, 3.6550, 3.5266],\n",
      "        [3.3388, 3.5165, 3.5895, 3.4880, 3.4791],\n",
      "        [3.6037, 3.8157, 3.8164, 3.7565, 3.7335],\n",
      "        [3.6360, 3.9779, 3.9443, 3.8800, 3.8748],\n",
      "        [3.5929, 3.6564, 3.9005, 3.9156, 3.8869],\n",
      "        [3.5982, 3.8538, 3.8706, 3.7773, 3.5791],\n",
      "        [3.4550, 3.6066, 3.7829, 3.7371, 3.6281],\n",
      "        [3.6259, 4.0170, 3.8700, 3.9726, 3.8509],\n",
      "        [3.6262, 3.7697, 3.7833, 3.7990, 3.7643],\n",
      "        [3.7802, 3.8616, 3.9946, 3.9574, 3.9742],\n",
      "        [3.4274, 3.6053, 3.6406, 3.5841, 3.5572],\n",
      "        [3.6811, 3.7454, 3.8858, 3.8004, 3.8117],\n",
      "        [3.8073, 4.0159, 4.1048, 3.9708, 3.7209],\n",
      "        [3.5235, 4.0400, 3.9932, 3.7728, 3.6768],\n",
      "        [3.5421, 3.8284, 3.8665, 3.6612, 3.7388],\n",
      "        [3.7063, 3.7658, 3.7252, 3.8799, 3.8279],\n",
      "        [3.5536, 3.5861, 3.7175, 3.6616, 3.6647],\n",
      "        [3.8427, 3.7132, 3.8711, 4.1838, 3.9434],\n",
      "        [3.8259, 3.6046, 3.8749, 4.1136, 4.0168],\n",
      "        [3.8145, 3.8654, 3.9991, 4.0723, 4.0564],\n",
      "        [3.6034, 3.6530, 3.8707, 3.7959, 3.7129],\n",
      "        [3.4572, 3.5272, 3.6962, 3.6560, 3.5356],\n",
      "        [3.6061, 3.9658, 3.9685, 3.8373, 3.6824],\n",
      "        [3.5390, 3.6237, 3.7887, 3.5955, 3.4334],\n",
      "        [3.7430, 3.9254, 3.8808, 3.8784, 3.8507],\n",
      "        [4.0746, 4.1032, 4.1533, 4.3150, 3.9198],\n",
      "        [3.5355, 3.6088, 3.7880, 3.7186, 3.6312],\n",
      "        [3.5357, 3.5947, 3.7786, 3.7026, 3.6199],\n",
      "        [3.4441, 3.6941, 3.7966, 3.7937, 3.5287],\n",
      "        [3.4960, 3.7199, 3.8352, 3.8265, 3.5759],\n",
      "        [3.5458, 3.8203, 3.8540, 3.6693, 3.7332],\n",
      "        [3.9779, 3.7765, 3.9987, 4.3480, 4.2020],\n",
      "        [3.5386, 3.7667, 3.8196, 3.7463, 3.6680],\n",
      "        [4.0610, 4.2184, 3.9849, 3.9923, 3.8114],\n",
      "        [3.7977, 3.8476, 3.9406, 3.9681, 3.9629],\n",
      "        [3.7093, 3.9106, 3.8874, 3.9050, 3.7898],\n",
      "        [3.3597, 3.5475, 3.5202, 3.6037, 3.4620],\n",
      "        [3.7523, 4.0558, 4.0553, 3.9750, 3.9404],\n",
      "        [3.7119, 3.7571, 3.8759, 3.7953, 3.5688],\n",
      "        [3.4091, 3.7081, 3.5995, 3.6856, 3.5099],\n",
      "        [3.6480, 3.9645, 3.9303, 3.8846, 3.8848],\n",
      "        [3.5458, 3.8203, 3.8540, 3.6693, 3.7332],\n",
      "        [3.9251, 3.9297, 4.0623, 4.1455, 3.9283],\n",
      "        [3.5378, 3.7146, 3.8262, 3.9180, 3.5958],\n",
      "        [3.4557, 3.5876, 3.6519, 3.6521, 3.5356],\n",
      "        [3.5492, 3.8357, 3.9020, 3.9301, 3.6712],\n",
      "        [3.4763, 3.6042, 3.7751, 3.7200, 3.6307],\n",
      "        [3.5769, 3.6169, 3.8402, 3.7570, 3.6728],\n",
      "        [3.5341, 3.7553, 3.8266, 3.7445, 3.6676],\n",
      "        [3.6895, 3.8383, 3.9588, 3.8437, 3.7529],\n",
      "        [3.5328, 3.5955, 3.7279, 3.7513, 3.5612],\n",
      "        [3.5384, 3.6014, 3.7765, 3.7036, 3.6233],\n",
      "        [3.5578, 3.6905, 3.7117, 3.7312, 3.6631],\n",
      "        [3.9462, 3.9263, 3.9035, 4.0584, 4.0503],\n",
      "        [3.5508, 3.6387, 3.8091, 3.7456, 3.6638],\n",
      "        [3.8934, 3.8105, 3.9156, 3.9523, 3.9135],\n",
      "        [3.6565, 3.8501, 3.8476, 3.7451, 3.7782],\n",
      "        [3.3738, 3.5608, 3.6167, 3.5295, 3.5099],\n",
      "        [3.5859, 3.6356, 3.8312, 3.7681, 3.6821]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6071, 3.9659, 3.9746, 3.8350, 3.6816],\n",
      "        [3.6354, 3.7211, 3.8268, 3.7587, 3.6928],\n",
      "        [3.6639, 3.9710, 3.9088, 3.8845, 3.7986],\n",
      "        [3.5550, 3.7084, 3.6680, 3.7523, 3.6207],\n",
      "        [3.5492, 3.6571, 3.7294, 3.7112, 3.7150],\n",
      "        [3.4351, 3.5346, 3.7025, 3.6199, 3.5185],\n",
      "        [3.4382, 3.4839, 3.6658, 3.6328, 3.4888],\n",
      "        [3.5675, 3.7265, 3.6954, 3.7742, 3.6498],\n",
      "        [3.4831, 3.5921, 3.7754, 3.7077, 3.6084],\n",
      "        [3.5438, 3.6303, 3.7999, 3.6012, 3.4362],\n",
      "        [3.8038, 3.9943, 4.0408, 4.0085, 3.9263],\n",
      "        [3.7831, 3.8982, 4.0208, 3.9409, 4.0172],\n",
      "        [3.6481, 3.5350, 3.9298, 3.8050, 3.7006],\n",
      "        [3.6714, 3.8625, 3.8274, 3.9484, 3.7705],\n",
      "        [3.6981, 3.8921, 3.8595, 3.9890, 3.8181],\n",
      "        [3.5384, 3.7279, 3.8763, 3.7933, 3.6128],\n",
      "        [3.5446, 3.6173, 3.7942, 3.7152, 3.6339],\n",
      "        [3.5668, 3.7856, 3.8775, 3.7760, 3.6346],\n",
      "        [3.4910, 3.5993, 3.5441, 3.7346, 3.4691],\n",
      "        [3.6596, 3.8805, 3.8730, 3.9471, 3.7682],\n",
      "        [3.4310, 3.5524, 3.7090, 3.6196, 3.5349],\n",
      "        [3.5894, 3.8075, 3.7445, 3.7243, 3.6667],\n",
      "        [3.5777, 3.9700, 3.8813, 3.9073, 3.8392],\n",
      "        [3.9857, 4.0651, 4.1110, 4.2489, 3.9962],\n",
      "        [3.5450, 3.5481, 3.7574, 3.6313, 3.5541],\n",
      "        [3.8550, 4.0475, 3.9588, 3.8443, 3.8345],\n",
      "        [3.3505, 3.5323, 3.6049, 3.4928, 3.4862],\n",
      "        [3.5534, 3.5374, 3.7275, 3.6818, 3.7173],\n",
      "        [3.6124, 3.5889, 3.8023, 3.7432, 3.6035],\n",
      "        [3.3301, 3.5176, 3.5968, 3.4703, 3.4657],\n",
      "        [3.5390, 3.6224, 3.7933, 3.7187, 3.6288],\n",
      "        [3.6360, 3.9504, 3.9200, 3.8697, 3.8727],\n",
      "        [3.4894, 3.4858, 3.7370, 3.6645, 3.6280],\n",
      "        [3.9069, 3.7959, 3.9157, 3.9678, 3.9147],\n",
      "        [3.6287, 3.9475, 3.9712, 3.8491, 3.6960],\n",
      "        [3.8228, 3.8313, 3.9285, 3.9022, 3.8744],\n",
      "        [3.4999, 3.8971, 3.8573, 3.7954, 3.8360],\n",
      "        [3.6981, 3.8921, 3.8595, 3.9890, 3.8181],\n",
      "        [3.6120, 3.6672, 3.9015, 3.7894, 3.7136],\n",
      "        [3.4288, 3.6274, 3.7757, 3.6415, 3.5620],\n",
      "        [3.8158, 3.8654, 4.0050, 4.0701, 4.0556],\n",
      "        [3.5994, 3.8158, 3.7855, 3.7274, 3.6943],\n",
      "        [3.7873, 4.0503, 3.9753, 4.0232, 3.9625],\n",
      "        [3.7424, 3.7758, 3.8728, 3.9213, 3.8820],\n",
      "        [3.5472, 3.6005, 3.7885, 3.7077, 3.6291],\n",
      "        [3.5361, 3.6109, 3.7831, 3.7070, 3.6237],\n",
      "        [3.7616, 3.5738, 3.7133, 3.7152, 3.7586],\n",
      "        [3.5776, 3.6122, 3.8198, 3.6954, 3.6794],\n",
      "        [3.7951, 3.9268, 3.9362, 3.9076, 3.9099],\n",
      "        [3.5887, 3.6324, 3.8606, 3.7701, 3.7005],\n",
      "        [3.7274, 3.8120, 3.9603, 3.8987, 3.9355],\n",
      "        [3.4251, 3.5534, 3.7113, 3.6210, 3.5327],\n",
      "        [3.4307, 3.5157, 3.6861, 3.6219, 3.5064],\n",
      "        [3.7105, 3.6955, 3.8415, 3.7029, 3.5695],\n",
      "        [3.9228, 3.9287, 4.0712, 4.1492, 3.9254],\n",
      "        [3.3971, 3.5720, 3.6287, 3.5493, 3.5194],\n",
      "        [3.5577, 3.7156, 3.6752, 3.7757, 3.6375],\n",
      "        [3.5267, 3.7295, 3.7826, 3.6191, 3.5787],\n",
      "        [3.5453, 3.7017, 3.6788, 3.7447, 3.6293],\n",
      "        [3.5861, 3.8693, 3.7796, 3.8884, 3.7364],\n",
      "        [3.3696, 3.4859, 3.6205, 3.5225, 3.4773],\n",
      "        [3.4394, 3.6136, 3.6481, 3.5965, 3.5536],\n",
      "        [3.4390, 3.5141, 3.6874, 3.6237, 3.5101],\n",
      "        [3.6999, 3.9525, 3.8952, 3.8627, 3.8025]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4536, 3.8760, 3.7385, 3.6478, 3.7241],\n",
      "        [3.5531, 3.5951, 3.8147, 3.7102, 3.6291],\n",
      "        [3.4956, 3.6189, 3.6964, 3.7425, 3.6015],\n",
      "        [3.4902, 3.5691, 3.8101, 3.6899, 3.6037],\n",
      "        [3.7469, 3.6010, 3.7322, 3.7203, 3.7742],\n",
      "        [3.9193, 3.9665, 4.0208, 4.1435, 3.9537],\n",
      "        [3.7180, 3.8539, 3.8701, 3.8027, 3.7369],\n",
      "        [3.6874, 3.8427, 3.9325, 3.8380, 3.6341],\n",
      "        [3.5393, 3.8259, 3.8833, 3.6429, 3.7334],\n",
      "        [3.6192, 3.6042, 3.8267, 3.7497, 3.6458],\n",
      "        [3.6878, 3.6851, 3.8373, 3.6728, 3.5434],\n",
      "        [4.0541, 4.1130, 4.1866, 4.3716, 4.1015],\n",
      "        [3.7543, 3.7557, 3.9789, 4.0180, 3.6735],\n",
      "        [3.9883, 4.0456, 4.1200, 4.2600, 4.0320],\n",
      "        [3.5747, 3.7293, 3.8492, 3.8964, 3.6584],\n",
      "        [3.7385, 3.6117, 3.7234, 3.7176, 3.7704],\n",
      "        [3.4493, 3.8889, 3.7512, 3.6375, 3.7211],\n",
      "        [3.5347, 3.7338, 3.7128, 3.8277, 3.5774],\n",
      "        [3.4014, 3.5854, 3.6387, 3.5513, 3.5279],\n",
      "        [3.7110, 3.9637, 3.9966, 3.9396, 3.9148],\n",
      "        [3.5478, 3.6069, 3.7998, 3.7085, 3.6290],\n",
      "        [3.5466, 3.5879, 3.8072, 3.6972, 3.6132],\n",
      "        [3.5404, 3.6403, 3.8113, 3.7362, 3.6458],\n",
      "        [3.6972, 3.7430, 3.8938, 3.7732, 3.8441],\n",
      "        [3.7580, 3.6776, 3.8441, 4.0479, 3.8438],\n",
      "        [3.4807, 3.6810, 3.7041, 3.7077, 3.5450],\n",
      "        [3.4415, 3.6086, 3.6494, 3.6003, 3.5481],\n",
      "        [3.5397, 3.6009, 3.7869, 3.6991, 3.6216],\n",
      "        [3.7719, 3.8928, 4.0157, 3.9601, 3.9640],\n",
      "        [3.5722, 3.6819, 3.8109, 3.8726, 3.6890],\n",
      "        [3.7009, 3.9197, 3.9772, 3.9158, 3.8586],\n",
      "        [3.6373, 3.7145, 3.8355, 3.8594, 3.6928],\n",
      "        [3.9231, 4.0621, 3.8735, 3.8843, 3.7764],\n",
      "        [3.6366, 3.9501, 3.9248, 3.8674, 3.8717],\n",
      "        [3.4594, 3.5045, 3.6875, 3.6443, 3.5073],\n",
      "        [4.0251, 3.8246, 4.1191, 4.4861, 4.2711],\n",
      "        [3.6510, 3.7205, 3.8271, 3.7773, 3.6847],\n",
      "        [3.5321, 3.6612, 3.7506, 3.6747, 3.6196],\n",
      "        [3.5419, 3.9401, 3.8256, 3.8908, 3.7680],\n",
      "        [3.4582, 3.6347, 3.6615, 3.6246, 3.5740],\n",
      "        [3.3990, 3.6973, 3.8676, 3.6337, 3.6778],\n",
      "        [3.4590, 3.5297, 3.7042, 3.6486, 3.5321],\n",
      "        [3.4658, 3.6102, 3.6449, 3.6728, 3.5106],\n",
      "        [3.8956, 4.0813, 4.0125, 4.0905, 4.1077],\n",
      "        [3.5466, 3.5536, 3.6823, 3.7792, 3.5291],\n",
      "        [3.6999, 3.8875, 3.8565, 3.9760, 3.8030],\n",
      "        [3.5368, 3.6083, 3.7984, 3.7140, 3.6295],\n",
      "        [3.9813, 3.9017, 4.1183, 4.1812, 3.9576],\n",
      "        [3.5795, 3.7280, 3.8349, 3.8605, 3.6797],\n",
      "        [3.9032, 3.9316, 4.0717, 4.0913, 3.9355],\n",
      "        [3.4054, 3.6409, 3.7426, 3.6031, 3.5418],\n",
      "        [3.5170, 3.6072, 3.7598, 3.7261, 3.5715],\n",
      "        [3.9413, 4.0383, 4.0634, 4.2037, 3.9601],\n",
      "        [3.8154, 3.7307, 3.8704, 3.8950, 3.8533],\n",
      "        [3.6987, 3.8917, 3.8645, 3.9866, 3.8172],\n",
      "        [3.3743, 3.4716, 3.6282, 3.5222, 3.4794],\n",
      "        [3.4468, 3.4962, 3.6821, 3.6375, 3.5040],\n",
      "        [3.5670, 3.5581, 3.8081, 3.7245, 3.7273],\n",
      "        [3.5582, 3.7152, 3.6800, 3.7734, 3.6366],\n",
      "        [3.9093, 3.9218, 4.0713, 4.1602, 3.9476],\n",
      "        [3.6251, 3.8339, 3.8297, 3.7464, 3.7428],\n",
      "        [3.5452, 3.6047, 3.7968, 3.7051, 3.6266],\n",
      "        [3.5766, 3.6504, 3.8152, 3.6232, 3.4678],\n",
      "        [3.5480, 3.6272, 3.9052, 3.6204, 3.7796]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4324, 3.5923, 3.7360, 3.6128, 3.5516],\n",
      "        [3.5749, 3.6276, 3.8830, 3.7458, 3.6923],\n",
      "        [4.0082, 4.0825, 4.1434, 4.2727, 4.0357],\n",
      "        [3.7516, 4.1042, 3.9781, 4.0633, 3.9633],\n",
      "        [3.6771, 3.7603, 3.7589, 3.7875, 3.7895],\n",
      "        [3.6852, 3.8340, 3.9784, 3.7828, 3.6220],\n",
      "        [3.5734, 3.7331, 3.6969, 3.7791, 3.6474],\n",
      "        [3.4387, 3.4659, 3.6692, 3.6257, 3.4756],\n",
      "        [3.4666, 3.6128, 3.8007, 3.7207, 3.6310],\n",
      "        [3.2536, 3.4642, 3.6472, 3.4864, 3.4805],\n",
      "        [3.6610, 3.6714, 3.8670, 3.7014, 3.6086],\n",
      "        [3.4798, 3.5896, 3.7785, 3.6940, 3.6168],\n",
      "        [3.5191, 3.6385, 3.6985, 3.6414, 3.5803],\n",
      "        [3.4788, 3.6029, 3.7902, 3.7126, 3.6277],\n",
      "        [3.3878, 3.5674, 3.6395, 3.5275, 3.5153],\n",
      "        [3.8966, 3.8091, 3.9309, 3.9460, 3.9108],\n",
      "        [3.7387, 3.7972, 3.9928, 3.8347, 3.6408],\n",
      "        [3.5590, 3.7140, 3.6830, 3.7557, 3.6303],\n",
      "        [3.9931, 3.9604, 4.0798, 4.2178, 4.0218],\n",
      "        [3.5261, 3.6822, 3.6756, 3.7060, 3.6086],\n",
      "        [3.4163, 3.6882, 3.7743, 3.6127, 3.5728],\n",
      "        [3.5904, 3.6228, 3.8403, 3.7293, 3.6892],\n",
      "        [3.5128, 3.6120, 3.5757, 3.7481, 3.4789],\n",
      "        [3.4989, 3.5782, 3.8140, 3.6914, 3.6067],\n",
      "        [3.4904, 3.5556, 3.8155, 3.6822, 3.5910],\n",
      "        [3.7153, 3.8593, 3.8770, 3.8102, 3.7400],\n",
      "        [3.6951, 3.9395, 3.8955, 3.8283, 3.7809],\n",
      "        [3.8275, 3.9493, 3.9490, 3.9471, 3.9548],\n",
      "        [3.7101, 3.7646, 3.7402, 3.8728, 3.8251],\n",
      "        [3.6324, 3.7051, 3.8346, 3.8479, 3.6828],\n",
      "        [3.6555, 3.8495, 3.8292, 3.9365, 3.7600],\n",
      "        [3.7785, 3.8667, 3.9714, 3.9149, 3.9733],\n",
      "        [3.5260, 3.7427, 3.7837, 3.7592, 3.6948],\n",
      "        [3.5502, 3.6200, 3.8087, 3.7210, 3.6296],\n",
      "        [3.7164, 3.9426, 3.8793, 3.8152, 3.7764],\n",
      "        [3.5358, 3.8466, 3.9121, 3.6501, 3.7506],\n",
      "        [3.9630, 3.9431, 3.9248, 4.0703, 4.0580],\n",
      "        [3.4770, 3.5895, 3.7753, 3.7031, 3.5997],\n",
      "        [3.5584, 3.6894, 3.7868, 3.6591, 3.5507],\n",
      "        [3.8822, 3.9992, 4.0201, 3.9941, 3.9870],\n",
      "        [3.5951, 3.8148, 3.8092, 3.7083, 3.7060],\n",
      "        [3.4379, 3.4712, 3.6669, 3.6203, 3.4788],\n",
      "        [3.8257, 3.5949, 3.8963, 4.1054, 4.0027],\n",
      "        [3.5811, 3.6150, 3.7983, 3.7061, 3.6927],\n",
      "        [3.6998, 3.7797, 3.9241, 3.8546, 3.8573],\n",
      "        [3.5332, 3.6175, 3.9137, 3.5903, 3.7703],\n",
      "        [3.9751, 4.0175, 4.0930, 4.2365, 4.0118],\n",
      "        [3.8082, 3.8358, 3.9839, 4.0464, 4.0398],\n",
      "        [3.4868, 3.6509, 3.6619, 3.6577, 3.5803],\n",
      "        [3.6121, 3.8202, 3.8264, 3.7489, 3.7385],\n",
      "        [3.4621, 3.5850, 3.7664, 3.6751, 3.5205],\n",
      "        [3.7011, 3.8866, 3.8615, 3.9733, 3.8019],\n",
      "        [3.5340, 3.5681, 3.7797, 3.6492, 3.5762],\n",
      "        [3.6500, 3.5338, 3.9392, 3.8002, 3.6985],\n",
      "        [3.4395, 3.6091, 3.7817, 3.6477, 3.5498],\n",
      "        [3.6615, 3.8320, 3.8275, 3.8349, 3.7658],\n",
      "        [3.9562, 3.9986, 4.0629, 4.1840, 3.9826],\n",
      "        [3.8343, 3.8829, 4.0138, 4.0786, 3.7744],\n",
      "        [3.8836, 3.8509, 3.9362, 3.9499, 3.8925],\n",
      "        [3.6697, 3.7200, 3.6961, 3.8334, 3.7842],\n",
      "        [3.5469, 3.7005, 3.6884, 3.7399, 3.6273],\n",
      "        [3.3796, 3.4380, 3.6442, 3.6289, 3.4669],\n",
      "        [3.6679, 3.8085, 3.8345, 3.8295, 3.8002],\n",
      "        [3.5106, 3.7193, 3.7719, 3.5935, 3.5602]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.9727, 3.8108, 4.0699, 4.4189, 4.1873],\n",
      "        [3.7802, 3.8968, 4.0236, 3.8783, 3.6695],\n",
      "        [3.4967, 3.5952, 3.7486, 3.6139, 3.5953],\n",
      "        [3.6533, 3.7186, 3.8383, 3.7721, 3.6824],\n",
      "        [3.5830, 3.7303, 3.8266, 3.7478, 3.7114],\n",
      "        [3.5665, 3.7225, 3.7089, 3.7670, 3.6413],\n",
      "        [3.4294, 3.6034, 3.6634, 3.5721, 3.5457],\n",
      "        [3.4458, 3.4868, 3.6859, 3.6381, 3.4966],\n",
      "        [3.5275, 3.6817, 3.8238, 3.7669, 3.6725],\n",
      "        [3.4185, 3.5851, 3.6500, 3.5638, 3.5267],\n",
      "        [3.8688, 3.9197, 4.0453, 4.0009, 4.0887],\n",
      "        [3.5788, 3.6275, 3.8294, 3.7349, 3.6646],\n",
      "        [3.8207, 3.8733, 4.0884, 4.0678, 3.7853],\n",
      "        [3.8867, 4.0346, 3.8823, 3.8616, 3.7734],\n",
      "        [3.9566, 3.9441, 4.0412, 4.1174, 3.9835],\n",
      "        [3.5192, 3.6883, 3.9689, 3.7520, 3.7701],\n",
      "        [3.8358, 3.5924, 3.8858, 4.1287, 4.0206],\n",
      "        [3.5026, 3.5848, 3.7913, 3.6657, 3.5982],\n",
      "        [3.5462, 3.7418, 3.8234, 3.7812, 3.6918],\n",
      "        [3.5915, 3.6234, 3.8573, 3.7300, 3.6883],\n",
      "        [3.6597, 3.6655, 3.8744, 3.6866, 3.6411],\n",
      "        [3.7411, 3.8277, 3.9835, 3.9129, 3.6946],\n",
      "        [3.3424, 3.5144, 3.6095, 3.4787, 3.4749],\n",
      "        [3.6153, 3.5866, 3.8188, 3.7358, 3.6006],\n",
      "        [3.4091, 3.5464, 3.7163, 3.5941, 3.5078],\n",
      "        [3.5342, 3.6594, 3.7620, 3.6696, 3.6173],\n",
      "        [3.7984, 4.0599, 4.0111, 4.0258, 3.9797],\n",
      "        [3.4316, 3.6450, 3.7640, 3.6187, 3.5731],\n",
      "        [3.5009, 3.5980, 3.8049, 3.7030, 3.6185],\n",
      "        [3.4332, 3.5534, 3.7272, 3.6144, 3.5316],\n",
      "        [3.5309, 3.6885, 3.6903, 3.7103, 3.6151],\n",
      "        [3.4273, 3.6213, 3.7857, 3.6283, 3.5532],\n",
      "        [3.6360, 3.6092, 3.8288, 3.7246, 3.7048],\n",
      "        [3.8164, 3.8211, 4.0599, 4.0885, 3.7366],\n",
      "        [3.7182, 3.8446, 4.0255, 3.8277, 3.6405],\n",
      "        [3.3787, 3.5587, 3.6374, 3.5183, 3.5067],\n",
      "        [3.5513, 3.5933, 3.8161, 3.7013, 3.6180],\n",
      "        [3.6096, 3.4688, 3.9136, 3.7565, 3.6475],\n",
      "        [3.4664, 3.5385, 3.7216, 3.6378, 3.5486],\n",
      "        [3.4985, 3.6592, 3.6733, 3.6727, 3.5814],\n",
      "        [3.6821, 3.8306, 3.8622, 3.8531, 3.8078],\n",
      "        [3.5125, 3.5024, 3.8200, 3.5180, 3.6666],\n",
      "        [3.4512, 3.4873, 3.6823, 3.6394, 3.5056],\n",
      "        [3.9228, 4.0113, 4.1697, 4.2097, 4.2132],\n",
      "        [3.7648, 3.5714, 3.7292, 3.7086, 3.7556],\n",
      "        [3.3723, 3.4838, 3.6359, 3.5152, 3.4740],\n",
      "        [3.5185, 3.6708, 3.6808, 3.6969, 3.6048],\n",
      "        [3.6379, 3.7805, 3.9983, 3.8368, 3.7739],\n",
      "        [3.5886, 3.6722, 3.9465, 3.7962, 3.7182],\n",
      "        [3.8135, 3.8917, 4.0119, 3.9254, 3.9214],\n",
      "        [3.9373, 3.9276, 4.0547, 4.1179, 3.9518],\n",
      "        [3.5524, 3.8338, 3.9291, 3.9200, 3.6680],\n",
      "        [4.0495, 4.1363, 3.8983, 3.9538, 3.7582],\n",
      "        [3.8059, 3.8876, 4.0328, 3.9556, 3.7885],\n",
      "        [3.4242, 3.5592, 3.7307, 3.6044, 3.5212],\n",
      "        [3.5807, 3.9677, 3.8979, 3.8996, 3.8360],\n",
      "        [3.7607, 3.8593, 4.0176, 4.0162, 3.7575],\n",
      "        [3.8128, 3.8282, 4.0465, 3.9614, 3.6884],\n",
      "        [3.5396, 3.6017, 3.7968, 3.6960, 3.6188],\n",
      "        [3.7196, 3.7658, 4.0793, 3.8039, 3.6074],\n",
      "        [3.4383, 3.7376, 3.9528, 3.7195, 3.6922],\n",
      "        [3.5912, 3.8033, 3.8204, 3.7321, 3.7286],\n",
      "        [3.8495, 3.8661, 4.0226, 4.0416, 3.8532],\n",
      "        [3.8643, 3.8729, 4.0441, 4.0278, 3.7328]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4335, 3.5280, 3.7179, 3.6045, 3.5109],\n",
      "        [3.8092, 3.9391, 4.1024, 4.1042, 4.1435],\n",
      "        [3.4517, 3.4861, 3.6884, 3.6368, 3.5042],\n",
      "        [3.2444, 3.4651, 3.6669, 3.4664, 3.4622],\n",
      "        [3.4566, 3.8730, 3.7557, 3.6399, 3.7202],\n",
      "        [3.6933, 3.7054, 3.9534, 3.9811, 3.6936],\n",
      "        [3.7584, 3.9233, 4.0624, 3.8491, 3.5906],\n",
      "        [3.5555, 3.7587, 3.7524, 3.8454, 3.5935],\n",
      "        [3.4140, 3.5794, 3.7411, 3.5957, 3.5209],\n",
      "        [3.4292, 3.5416, 3.7259, 3.6015, 3.5150],\n",
      "        [3.5751, 3.7012, 3.8264, 3.7030, 3.5628],\n",
      "        [3.5531, 3.7641, 3.8120, 3.7606, 3.7070],\n",
      "        [3.6232, 3.5917, 3.9574, 3.8278, 3.6822],\n",
      "        [3.4131, 3.6488, 3.7685, 3.6112, 3.5534],\n",
      "        [3.6713, 3.6994, 3.8353, 3.8338, 3.8112],\n",
      "        [3.9309, 4.0664, 3.9004, 3.8943, 3.7800],\n",
      "        [3.7614, 4.0135, 3.9894, 4.0050, 3.8937],\n",
      "        [3.6446, 3.7226, 3.9265, 3.7956, 3.7070],\n",
      "        [3.8344, 3.8580, 4.0240, 4.0616, 4.0486],\n",
      "        [3.4611, 3.5238, 3.7236, 3.6437, 3.5301],\n",
      "        [3.6974, 3.8689, 3.8653, 3.8009, 3.7497],\n",
      "        [3.7654, 3.8533, 4.0232, 3.9451, 3.9711],\n",
      "        [3.4328, 3.4657, 3.6758, 3.6137, 3.4737],\n",
      "        [3.4998, 3.6570, 3.6787, 3.6638, 3.5831],\n",
      "        [4.0590, 4.0127, 4.1961, 4.2734, 4.0815],\n",
      "        [3.5887, 3.6186, 3.8284, 3.7135, 3.6914],\n",
      "        [3.4089, 3.6130, 3.7548, 3.6033, 3.5394],\n",
      "        [3.4805, 3.6488, 3.6885, 3.6398, 3.5797],\n",
      "        [3.5356, 3.6795, 3.6921, 3.6931, 3.6194],\n",
      "        [3.5640, 3.7946, 3.8454, 3.6858, 3.7108],\n",
      "        [3.7393, 3.5460, 3.7352, 3.7257, 3.7101],\n",
      "        [3.5282, 3.6806, 3.8307, 3.7642, 3.6711],\n",
      "        [3.8505, 3.8650, 4.0292, 4.0389, 3.8517],\n",
      "        [3.6258, 3.5974, 4.0624, 3.7935, 3.7505],\n",
      "        [3.8125, 3.9899, 4.0714, 4.0074, 3.9303],\n",
      "        [3.4145, 3.6133, 3.7530, 3.6014, 3.5421],\n",
      "        [3.6751, 3.7237, 3.8909, 3.7483, 3.8131],\n",
      "        [3.6517, 4.1193, 4.0081, 3.9123, 3.9746],\n",
      "        [3.5810, 3.6096, 3.7941, 3.6897, 3.6902],\n",
      "        [3.4585, 3.6080, 3.6456, 3.6352, 3.5047],\n",
      "        [3.6983, 3.7837, 3.9450, 3.8813, 3.9005],\n",
      "        [3.8503, 3.5902, 3.8933, 4.1373, 4.0375],\n",
      "        [3.4998, 3.7169, 3.8683, 3.8140, 3.5713],\n",
      "        [3.4950, 3.6418, 3.6721, 3.6531, 3.5670],\n",
      "        [3.5772, 3.5822, 3.8577, 3.7474, 3.7416],\n",
      "        [3.7771, 3.7964, 4.0185, 4.0420, 3.7089],\n",
      "        [3.4911, 3.6495, 3.6826, 3.6330, 3.5869],\n",
      "        [3.5464, 3.5605, 3.7903, 3.6365, 3.5653],\n",
      "        [3.9495, 3.9340, 3.9335, 4.0672, 4.0643],\n",
      "        [3.8880, 3.9827, 4.0459, 3.9812, 3.9490],\n",
      "        [3.4464, 3.4856, 3.6920, 3.6355, 3.4952],\n",
      "        [3.7933, 3.8517, 4.0345, 3.9379, 3.9738],\n",
      "        [3.5572, 3.7095, 3.8677, 3.9053, 3.6238],\n",
      "        [3.5703, 3.5638, 3.8436, 3.7260, 3.7290],\n",
      "        [3.5370, 3.7681, 3.8919, 3.7216, 3.6774],\n",
      "        [3.8135, 3.8270, 4.0531, 3.9586, 3.6869],\n",
      "        [3.6752, 3.6878, 3.8891, 3.7262, 3.5996],\n",
      "        [3.5205, 3.5859, 3.7548, 3.7290, 3.5598],\n",
      "        [3.5502, 3.8166, 3.8817, 3.6565, 3.7270],\n",
      "        [3.9162, 3.7798, 4.0508, 4.3796, 4.1852],\n",
      "        [3.7020, 3.9342, 3.9978, 3.8990, 3.8925],\n",
      "        [3.7413, 3.9984, 3.9277, 3.9092, 3.9936],\n",
      "        [3.4422, 3.5107, 3.7092, 3.6136, 3.5054],\n",
      "        [3.7130, 3.8672, 3.8869, 3.8308, 3.7401]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5750, 3.7261, 3.7097, 3.7674, 3.6364],\n",
      "        [3.5243, 3.9404, 3.8294, 3.7252, 3.8260],\n",
      "        [3.5588, 3.5819, 3.7485, 3.6484, 3.6581],\n",
      "        [3.4135, 3.6484, 3.7735, 3.6101, 3.5529],\n",
      "        [3.5518, 3.6110, 3.8206, 3.6962, 3.6244],\n",
      "        [3.4179, 3.5632, 3.7397, 3.5961, 3.5171],\n",
      "        [3.5575, 3.5755, 3.7285, 3.7703, 3.5426],\n",
      "        [3.7240, 3.7529, 3.9216, 3.7783, 3.5851],\n",
      "        [3.5979, 3.8701, 3.9386, 3.9151, 3.6730],\n",
      "        [3.5010, 3.6512, 3.6771, 3.6698, 3.5721],\n",
      "        [3.8304, 3.8245, 3.8497, 3.8964, 3.8738],\n",
      "        [3.3388, 3.5131, 3.6202, 3.4604, 3.4592],\n",
      "        [3.7424, 3.6972, 3.8703, 3.7169, 3.5946],\n",
      "        [3.9010, 3.9289, 4.0914, 4.0901, 3.9179],\n",
      "        [3.6930, 3.7887, 3.8243, 3.8562, 3.7685],\n",
      "        [3.3318, 3.5029, 3.6146, 3.4541, 3.4500],\n",
      "        [3.7044, 3.7484, 3.8912, 3.7686, 3.5265],\n",
      "        [3.7439, 4.0005, 3.9865, 3.9928, 3.8768],\n",
      "        [3.4389, 3.5478, 3.6983, 3.6029, 3.5294],\n",
      "        [3.8071, 3.9862, 4.1180, 3.9395, 3.6791],\n",
      "        [3.5630, 3.7328, 3.8866, 3.8829, 3.6392],\n",
      "        [3.3671, 3.5298, 3.5711, 3.5141, 3.4383],\n",
      "        [4.0410, 4.2108, 3.9715, 3.9387, 3.7937],\n",
      "        [3.9356, 3.9252, 4.0900, 4.1306, 3.9279],\n",
      "        [3.4895, 3.8840, 3.8688, 3.7851, 3.8041],\n",
      "        [3.5752, 3.7303, 3.7158, 3.7726, 3.6445],\n",
      "        [3.5777, 3.7264, 3.8763, 3.8875, 3.6549],\n",
      "        [3.7850, 3.8975, 3.9573, 3.8963, 3.8661],\n",
      "        [3.8278, 3.5923, 3.9147, 4.0991, 4.0002],\n",
      "        [3.4828, 3.6386, 3.6806, 3.6341, 3.5812],\n",
      "        [3.9388, 3.9486, 4.0631, 4.1268, 3.7636],\n",
      "        [3.4162, 3.5080, 3.7072, 3.5778, 3.4960],\n",
      "        [3.6808, 3.9375, 4.0636, 3.8920, 3.7261],\n",
      "        [3.6243, 3.8682, 3.8780, 3.8204, 3.8317],\n",
      "        [3.5093, 3.6591, 3.6944, 3.6823, 3.5977],\n",
      "        [3.5953, 3.7316, 3.8505, 3.7604, 3.7264],\n",
      "        [3.7191, 3.8739, 3.9873, 3.8272, 3.6363],\n",
      "        [3.6551, 3.7413, 3.9428, 3.8096, 3.6896],\n",
      "        [3.9032, 3.9382, 3.9797, 4.0067, 3.9841],\n",
      "        [3.7185, 3.9402, 3.9000, 3.8086, 3.7736],\n",
      "        [4.0573, 3.8135, 4.1141, 4.4304, 4.2735],\n",
      "        [3.6760, 3.9730, 3.9445, 3.8607, 3.8006],\n",
      "        [3.5717, 4.0240, 4.0236, 3.7565, 3.6902],\n",
      "        [3.9119, 3.7918, 3.9439, 3.9575, 3.9099],\n",
      "        [3.5271, 3.6050, 3.8322, 3.7231, 3.7056],\n",
      "        [3.9772, 4.0151, 4.1162, 4.2297, 4.0092],\n",
      "        [3.4527, 3.4908, 3.6998, 3.6285, 3.4933],\n",
      "        [3.7874, 3.8632, 4.1522, 3.8536, 3.6521],\n",
      "        [3.7270, 3.8588, 3.9951, 3.9033, 3.7498],\n",
      "        [3.6873, 3.9597, 4.0205, 3.8922, 3.9362],\n",
      "        [3.7194, 3.8388, 3.8918, 3.7489, 3.7257],\n",
      "        [3.8122, 4.0232, 3.9671, 3.9849, 4.0677],\n",
      "        [3.7415, 3.9384, 4.0190, 3.8953, 3.7768],\n",
      "        [4.1921, 4.4148, 4.1132, 4.1470, 3.9278],\n",
      "        [3.6526, 3.8449, 3.9302, 3.7932, 3.6063],\n",
      "        [3.4184, 3.6021, 3.6839, 3.5639, 3.5497],\n",
      "        [3.4082, 3.6011, 3.7506, 3.5902, 3.5242],\n",
      "        [3.5380, 3.8437, 3.9295, 3.6432, 3.7468],\n",
      "        [3.9607, 4.1111, 4.0009, 3.9024, 3.8225],\n",
      "        [3.6925, 3.6855, 3.9202, 3.8274, 3.6892],\n",
      "        [3.4141, 3.7045, 3.6313, 3.6725, 3.5041],\n",
      "        [3.5668, 3.6088, 3.8399, 3.7047, 3.6367],\n",
      "        [3.5565, 3.9522, 3.8453, 3.7615, 3.8577],\n",
      "        [3.5405, 3.6136, 3.8160, 3.7006, 3.6217]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8013, 3.9230, 3.9677, 3.8945, 3.9037],\n",
      "        [3.3311, 3.5861, 3.8560, 3.5490, 3.6224],\n",
      "        [3.4835, 3.6422, 3.6831, 3.6366, 3.5704],\n",
      "        [3.6310, 4.0183, 3.9196, 3.9570, 3.8531],\n",
      "        [3.4810, 3.5942, 3.8008, 3.7064, 3.5966],\n",
      "        [3.4225, 3.6822, 3.7941, 3.6175, 3.5759],\n",
      "        [3.4393, 3.5213, 3.7267, 3.6187, 3.5095],\n",
      "        [3.4901, 3.4887, 3.6941, 3.6289, 3.4872],\n",
      "        [3.9143, 3.7736, 4.0525, 4.3727, 4.1757],\n",
      "        [3.6954, 3.8619, 4.0041, 3.8604, 3.7280],\n",
      "        [3.5026, 3.6257, 3.7133, 3.6090, 3.5638],\n",
      "        [3.4023, 3.6938, 3.8952, 3.6229, 3.6727],\n",
      "        [3.7365, 3.8746, 3.9987, 3.8321, 3.6357],\n",
      "        [3.5498, 3.7030, 3.7079, 3.7358, 3.6239],\n",
      "        [3.4862, 3.5894, 3.7893, 3.6786, 3.5362],\n",
      "        [3.6965, 3.9366, 3.8699, 3.6733, 3.7143],\n",
      "        [3.6122, 3.7055, 3.8364, 3.7038, 3.6806],\n",
      "        [3.8038, 3.9204, 4.0829, 3.9435, 4.0387],\n",
      "        [3.6468, 3.8432, 3.9295, 3.7897, 3.5997],\n",
      "        [3.5488, 3.5877, 3.8275, 3.6973, 3.6114],\n",
      "        [3.4573, 3.4884, 3.7059, 3.6189, 3.5014],\n",
      "        [3.5499, 3.5844, 3.8348, 3.6868, 3.6088],\n",
      "        [3.6151, 3.6034, 3.8509, 3.7491, 3.6480],\n",
      "        [3.8365, 3.8810, 4.0427, 4.0710, 3.7716],\n",
      "        [3.6695, 3.8557, 3.8667, 3.9355, 3.7720],\n",
      "        [3.5483, 3.6134, 3.8268, 3.7023, 3.6282],\n",
      "        [3.8436, 3.8446, 4.0541, 4.1103, 3.7874],\n",
      "        [3.4278, 3.6963, 3.8028, 3.6254, 3.5894],\n",
      "        [3.5660, 3.8566, 3.7914, 3.5759, 3.6782],\n",
      "        [3.6279, 3.7233, 3.8739, 3.7481, 3.7716],\n",
      "        [3.5847, 3.6649, 3.8419, 3.7062, 3.8094],\n",
      "        [3.9123, 3.7918, 3.9484, 3.9563, 3.9093],\n",
      "        [3.4273, 3.5365, 3.7305, 3.5996, 3.5125],\n",
      "        [3.5591, 3.5564, 3.7166, 3.7725, 3.5299],\n",
      "        [3.6530, 3.9613, 3.9690, 3.8693, 3.8780],\n",
      "        [3.5503, 3.5800, 3.8312, 3.6954, 3.6042],\n",
      "        [3.7313, 3.6620, 3.8406, 4.0471, 3.8223],\n",
      "        [3.6553, 3.7414, 3.9474, 3.8082, 3.6889],\n",
      "        [3.7143, 3.9076, 3.9273, 3.8903, 3.7834],\n",
      "        [4.2372, 4.3928, 4.1662, 4.1271, 3.9401],\n",
      "        [3.5609, 3.7113, 3.7066, 3.7478, 3.6267],\n",
      "        [3.4926, 3.5530, 3.8380, 3.6744, 3.5876],\n",
      "        [3.7018, 3.8880, 3.8943, 3.9756, 3.8123],\n",
      "        [3.6453, 3.7223, 3.9365, 3.7930, 3.7058],\n",
      "        [3.5338, 3.5478, 3.8196, 3.6705, 3.5921],\n",
      "        [3.6377, 3.6753, 3.9527, 3.8043, 3.7272],\n",
      "        [3.5954, 3.7316, 3.8551, 3.7590, 3.7256],\n",
      "        [3.9577, 4.1457, 4.2587, 4.2041, 4.2449],\n",
      "        [3.7624, 3.8578, 4.0348, 4.0111, 3.7551],\n",
      "        [3.9314, 3.8662, 3.9746, 4.0037, 3.9332],\n",
      "        [3.6375, 3.8859, 3.8948, 3.8333, 3.8466],\n",
      "        [3.7705, 3.9408, 4.0691, 3.8662, 3.5982],\n",
      "        [3.5561, 3.5836, 3.7413, 3.7652, 3.5552],\n",
      "        [3.5692, 3.6814, 3.8364, 3.6999, 3.5455],\n",
      "        [3.5618, 3.6661, 3.7837, 3.6432, 3.6394],\n",
      "        [3.4071, 3.6956, 3.7815, 3.6608, 3.7266],\n",
      "        [3.5204, 3.6761, 3.7042, 3.6872, 3.6010],\n",
      "        [3.5484, 3.6012, 3.8244, 3.6946, 3.6219],\n",
      "        [3.8830, 3.7556, 4.0172, 4.0339, 3.8178],\n",
      "        [3.5357, 3.7376, 3.8506, 3.7097, 3.6879],\n",
      "        [3.5717, 4.0242, 4.0289, 3.7553, 3.6896],\n",
      "        [3.4868, 3.5882, 3.8078, 3.6949, 3.6029],\n",
      "        [3.4206, 3.5339, 3.6920, 3.5767, 3.5156],\n",
      "        [3.7025, 3.9339, 4.0077, 3.8965, 3.8913]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3793, 3.5559, 3.6605, 3.5083, 3.5108],\n",
      "        [3.5560, 3.5646, 3.8557, 3.6111, 3.6704],\n",
      "        [3.4925, 3.5535, 3.8445, 3.6735, 3.5868],\n",
      "        [3.6870, 3.8318, 4.0093, 3.7739, 3.6174],\n",
      "        [3.6435, 3.7010, 3.8581, 3.7793, 3.7558],\n",
      "        [3.4358, 3.4639, 3.6920, 3.6084, 3.4713],\n",
      "        [3.4959, 3.6432, 3.7311, 3.6566, 3.6113],\n",
      "        [3.5851, 3.6992, 3.8431, 3.6984, 3.5524],\n",
      "        [3.4342, 3.5123, 3.7235, 3.6086, 3.4997],\n",
      "        [3.4179, 3.5711, 3.7571, 3.5944, 3.5193],\n",
      "        [3.5342, 3.5995, 3.8503, 3.7215, 3.6890],\n",
      "        [3.4184, 3.6862, 3.8028, 3.6040, 3.5678],\n",
      "        [3.5691, 3.6819, 3.8425, 3.6990, 3.5446],\n",
      "        [3.6452, 3.7514, 3.9011, 3.7642, 3.8088],\n",
      "        [3.5634, 3.5900, 3.7658, 3.6539, 3.6711],\n",
      "        [3.3926, 3.6335, 3.9172, 3.6047, 3.6972],\n",
      "        [3.7208, 3.9533, 3.9512, 3.8739, 3.7955],\n",
      "        [3.7529, 3.8864, 3.9003, 3.9178, 3.8613],\n",
      "        [3.4993, 3.4974, 3.7055, 3.6302, 3.4947],\n",
      "        [3.4074, 3.6231, 3.7716, 3.5938, 3.5299],\n",
      "        [4.0122, 4.0805, 4.1744, 4.2636, 4.0310],\n",
      "        [3.5455, 3.6997, 3.7166, 3.7273, 3.6184],\n",
      "        [3.5201, 3.6873, 3.9914, 3.7461, 3.7665],\n",
      "        [3.5529, 3.6656, 3.8367, 3.7223, 3.7431],\n",
      "        [3.8707, 3.7506, 3.9094, 3.8932, 3.8774],\n",
      "        [3.7372, 3.7082, 3.8891, 4.0625, 3.8657],\n",
      "        [3.6143, 3.6731, 3.8694, 3.7123, 3.8563],\n",
      "        [3.6295, 3.8481, 3.9320, 3.7836, 3.5897],\n",
      "        [3.7438, 3.8076, 4.0077, 3.9148, 3.6650],\n",
      "        [3.4331, 3.4657, 3.6913, 3.6105, 3.4718],\n",
      "        [3.7467, 3.5494, 3.7556, 3.7139, 3.7277],\n",
      "        [3.8949, 3.7836, 4.0563, 4.0605, 3.8467],\n",
      "        [3.5450, 3.9379, 3.8614, 3.8797, 3.7624],\n",
      "        [3.6116, 3.6510, 3.9077, 3.7464, 3.7104],\n",
      "        [3.5819, 3.7840, 3.7681, 3.7022, 3.6435],\n",
      "        [3.9285, 4.0600, 3.9088, 3.8731, 3.7710],\n",
      "        [3.4145, 3.6680, 3.7963, 3.6101, 3.5657],\n",
      "        [3.4236, 3.5568, 3.7471, 3.5952, 3.5156],\n",
      "        [3.4612, 3.6318, 3.6951, 3.6135, 3.5683],\n",
      "        [3.7345, 3.7319, 3.9704, 3.9333, 3.6724],\n",
      "        [3.4482, 3.5467, 3.6535, 3.6582, 3.4582],\n",
      "        [3.6614, 3.7466, 3.8827, 3.9100, 3.6921],\n",
      "        [3.4040, 3.5971, 3.7623, 3.5889, 3.5194],\n",
      "        [3.7540, 4.0655, 4.0264, 3.8887, 4.0755],\n",
      "        [3.5286, 3.6810, 3.8485, 3.7613, 3.6695],\n",
      "        [3.7165, 3.9281, 3.9359, 3.8674, 3.7822],\n",
      "        [3.7630, 3.9029, 3.9115, 3.9429, 3.9602],\n",
      "        [3.4585, 3.6037, 3.6878, 3.6501, 3.5292],\n",
      "        [3.4491, 3.5356, 3.7575, 3.6188, 3.4915],\n",
      "        [3.5676, 3.7886, 3.9221, 3.7631, 3.6165],\n",
      "        [3.5672, 3.8678, 3.9069, 3.7306, 3.5545],\n",
      "        [3.5380, 3.8440, 3.9399, 3.6408, 3.7449],\n",
      "        [3.5405, 3.6141, 3.8271, 3.6984, 3.6203],\n",
      "        [3.5719, 3.6422, 3.9281, 3.6189, 3.7969],\n",
      "        [3.5745, 3.5809, 3.8725, 3.7400, 3.7356],\n",
      "        [3.7380, 3.7500, 3.9966, 3.9826, 3.6618],\n",
      "        [3.5621, 3.6870, 3.7569, 3.7156, 3.6559],\n",
      "        [3.5832, 3.6124, 3.8600, 3.7167, 3.6754],\n",
      "        [3.4962, 3.6081, 3.8199, 3.7038, 3.6099],\n",
      "        [3.5771, 3.6253, 3.9120, 3.7370, 3.6878],\n",
      "        [3.6403, 3.7114, 3.8704, 3.8480, 3.6870],\n",
      "        [3.7421, 3.8799, 3.8973, 3.9129, 3.8429],\n",
      "        [3.4520, 3.4861, 3.7041, 3.6335, 3.5023],\n",
      "        [4.0422, 4.1385, 3.9030, 3.9469, 3.7484]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5882, 3.6336, 3.8698, 3.7460, 3.6717],\n",
      "        [3.4718, 3.5933, 3.8046, 3.7030, 3.5915],\n",
      "        [3.5604, 3.7119, 3.7191, 3.7459, 3.6249],\n",
      "        [3.9473, 3.8837, 4.0186, 4.0357, 3.9668],\n",
      "        [3.5969, 3.8131, 3.8466, 3.6989, 3.7005],\n",
      "        [4.1570, 4.2961, 4.1613, 4.0812, 3.9456],\n",
      "        [3.7459, 3.8777, 4.0244, 3.8901, 3.9521],\n",
      "        [3.5605, 3.9450, 3.9016, 3.7749, 3.9555],\n",
      "        [3.7014, 3.8886, 3.9074, 3.9737, 3.8104],\n",
      "        [3.9199, 4.0849, 4.0067, 3.8730, 3.8073],\n",
      "        [3.5762, 3.7401, 3.8850, 3.7207, 3.7690],\n",
      "        [3.7170, 3.8701, 4.0112, 3.8948, 3.7741],\n",
      "        [3.8068, 3.6559, 3.8661, 3.8058, 3.7798],\n",
      "        [3.5924, 3.6160, 3.9199, 3.7657, 3.7176],\n",
      "        [3.4416, 3.6116, 3.6885, 3.5947, 3.5479],\n",
      "        [3.4205, 3.6569, 3.7963, 3.6122, 3.5579],\n",
      "        [3.8483, 3.8509, 3.8874, 3.9292, 3.8737],\n",
      "        [3.3730, 3.4829, 3.6628, 3.5082, 3.4694],\n",
      "        [3.4748, 3.6231, 3.6901, 3.6183, 3.5527],\n",
      "        [3.7771, 3.7978, 4.0465, 4.0383, 3.7072],\n",
      "        [3.9296, 4.1130, 4.0530, 3.8963, 3.8614],\n",
      "        [3.5339, 3.6837, 3.7185, 3.7111, 3.6110],\n",
      "        [4.0035, 3.9703, 4.1585, 4.2348, 4.0248],\n",
      "        [3.7311, 3.8098, 4.0119, 3.8851, 3.9286],\n",
      "        [3.5247, 3.8422, 3.8098, 3.5582, 3.7079],\n",
      "        [3.6029, 3.8133, 3.8347, 3.7133, 3.6872],\n",
      "        [3.6126, 3.6537, 3.9330, 3.7661, 3.7012],\n",
      "        [3.6253, 3.7761, 4.0184, 3.8249, 3.7805],\n",
      "        [3.6293, 3.8484, 3.9379, 3.7825, 3.5886],\n",
      "        [3.5743, 3.5812, 3.8781, 3.7390, 3.7346],\n",
      "        [3.5737, 3.5701, 3.8675, 3.7245, 3.7315],\n",
      "        [3.5389, 3.5996, 3.8581, 3.7210, 3.7008],\n",
      "        [3.7615, 4.0144, 4.0132, 4.0008, 3.8908],\n",
      "        [3.3497, 3.5582, 3.7170, 3.5652, 3.5311],\n",
      "        [3.6464, 3.7081, 3.8690, 3.7789, 3.7609],\n",
      "        [3.3597, 3.5378, 3.6540, 3.4828, 3.4898],\n",
      "        [3.4897, 3.4893, 3.7057, 3.6270, 3.4853],\n",
      "        [3.4715, 3.6151, 3.8291, 3.6675, 3.5320],\n",
      "        [3.5558, 3.5648, 3.8612, 3.6100, 3.6692],\n",
      "        [3.4275, 3.6970, 3.8145, 3.6234, 3.5873],\n",
      "        [3.7385, 3.6480, 3.8586, 4.0785, 3.8339],\n",
      "        [3.5670, 3.7233, 3.7338, 3.7640, 3.6399],\n",
      "        [3.6871, 3.8849, 3.9528, 3.9484, 3.7689],\n",
      "        [3.5499, 3.6993, 3.7161, 3.7256, 3.6105],\n",
      "        [3.5627, 3.7341, 3.9067, 3.8803, 3.6374],\n",
      "        [3.6720, 3.6998, 3.8577, 3.8296, 3.8081],\n",
      "        [3.5988, 3.6705, 3.9304, 3.7580, 3.7737],\n",
      "        [3.6957, 3.8472, 3.9001, 3.8718, 3.7587],\n",
      "        [3.5955, 3.6604, 3.8629, 3.6280, 3.4776],\n",
      "        [3.4010, 3.5827, 3.6803, 3.5445, 3.5234],\n",
      "        [3.7488, 3.7072, 3.8895, 3.7235, 3.6063],\n",
      "        [4.0746, 4.2211, 4.1153, 4.0023, 3.9071],\n",
      "        [3.5743, 3.9790, 3.8929, 3.9105, 3.8120],\n",
      "        [3.4229, 3.7221, 3.9598, 3.6835, 3.6769],\n",
      "        [3.9248, 4.0111, 4.1998, 4.2025, 4.2087],\n",
      "        [3.4710, 3.4508, 3.8116, 3.4472, 3.6290],\n",
      "        [3.4159, 3.5086, 3.7232, 3.5745, 3.4933],\n",
      "        [3.4387, 3.5484, 3.7146, 3.5996, 3.5267],\n",
      "        [3.5892, 3.6188, 3.8494, 3.7089, 3.6880],\n",
      "        [3.8308, 3.6017, 3.9253, 4.0976, 4.0097],\n",
      "        [3.4642, 3.5247, 3.7519, 3.6312, 3.4961],\n",
      "        [3.7816, 3.9587, 4.0221, 3.9716, 4.0294],\n",
      "        [4.0702, 4.2983, 4.0146, 4.0077, 3.8223],\n",
      "        [3.7376, 3.9376, 3.9060, 3.7072, 3.6814]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7486, 3.7086, 3.8940, 3.7224, 3.6050],\n",
      "        [3.5699, 3.5897, 3.8711, 3.6475, 3.6686],\n",
      "        [3.9490, 3.8154, 4.1012, 4.3955, 4.1856],\n",
      "        [3.9118, 3.9216, 4.1257, 4.1469, 3.9413],\n",
      "        [3.6910, 3.6909, 3.9229, 3.8073, 3.6699],\n",
      "        [3.6750, 3.7583, 3.8371, 3.7697, 3.6720],\n",
      "        [3.6399, 3.8697, 4.0682, 3.9425, 3.7985],\n",
      "        [3.5428, 3.8282, 3.9243, 3.6540, 3.7093],\n",
      "        [3.6091, 3.9986, 3.9558, 3.9291, 3.8482],\n",
      "        [3.5124, 3.6713, 3.7153, 3.6707, 3.5948],\n",
      "        [3.6207, 3.6674, 3.9526, 3.7913, 3.7159],\n",
      "        [3.6167, 3.7155, 3.8588, 3.7305, 3.6721],\n",
      "        [3.4147, 3.6188, 3.7836, 3.6042, 3.5432],\n",
      "        [3.5537, 3.5904, 3.8567, 3.6891, 3.6128],\n",
      "        [3.5525, 3.7903, 3.9606, 3.7647, 3.5963],\n",
      "        [3.8101, 3.8383, 4.0803, 4.1098, 3.8017],\n",
      "        [3.5473, 3.6442, 3.8571, 3.7212, 3.6334],\n",
      "        [3.5065, 3.5947, 3.8520, 3.6910, 3.6102],\n",
      "        [3.5017, 4.0097, 3.8853, 3.6928, 3.8031],\n",
      "        [3.5600, 3.8144, 3.8397, 3.6778, 3.6881],\n",
      "        [3.4181, 3.6064, 3.7857, 3.6056, 3.5407],\n",
      "        [3.6151, 3.8318, 4.0145, 3.8933, 3.7678],\n",
      "        [3.7567, 3.7564, 4.0347, 4.0052, 3.6674],\n",
      "        [3.6250, 3.7776, 4.0229, 3.8237, 3.7790],\n",
      "        [3.6445, 3.8637, 3.9373, 3.8587, 3.7075],\n",
      "        [3.5301, 3.7406, 3.8657, 3.7072, 3.6698],\n",
      "        [3.4340, 3.5505, 3.7562, 3.6039, 3.5256],\n",
      "        [3.3778, 3.5591, 3.6683, 3.5119, 3.4998],\n",
      "        [3.7007, 3.7895, 3.9838, 3.8839, 3.8999],\n",
      "        [3.4941, 3.6040, 3.6134, 3.7160, 3.4814],\n",
      "        [3.6965, 3.9401, 3.9415, 3.8175, 3.7747],\n",
      "        [3.4861, 3.5903, 3.8246, 3.6918, 3.5998],\n",
      "        [3.6062, 3.6439, 3.9332, 3.7802, 3.7028],\n",
      "        [3.7212, 3.8532, 3.9158, 3.7893, 3.7291],\n",
      "        [3.4367, 3.7397, 3.9852, 3.7096, 3.6901],\n",
      "        [3.7406, 4.0888, 4.0179, 4.0328, 3.9395],\n",
      "        [3.5686, 3.6834, 3.8520, 3.6967, 3.5420],\n",
      "        [3.7566, 4.0548, 4.1129, 3.9560, 3.9300],\n",
      "        [3.3690, 3.5445, 3.5773, 3.6052, 3.4549],\n",
      "        [3.8751, 3.9411, 3.9891, 3.9625, 3.9563],\n",
      "        [3.5098, 3.6742, 3.7345, 3.7117, 3.5765],\n",
      "        [3.6284, 3.5808, 3.8069, 3.6837, 3.6747],\n",
      "        [3.4583, 3.6892, 4.0090, 3.6838, 3.7716],\n",
      "        [3.7166, 3.7550, 3.9291, 3.7774, 3.5586],\n",
      "        [3.5332, 3.6246, 3.8468, 3.7122, 3.6220],\n",
      "        [3.5447, 3.6140, 3.8402, 3.7044, 3.6284],\n",
      "        [3.7010, 3.7635, 3.7887, 3.8520, 3.7993],\n",
      "        [3.8195, 3.8466, 3.9992, 3.9674, 3.9528],\n",
      "        [3.8277, 3.8294, 3.9789, 3.8874, 3.8653],\n",
      "        [3.4605, 3.6240, 3.6962, 3.6080, 3.5517],\n",
      "        [3.3727, 3.4842, 3.6671, 3.5070, 3.4680],\n",
      "        [3.6661, 3.7071, 3.8743, 3.7696, 3.6535],\n",
      "        [3.5406, 3.7546, 3.8343, 3.7459, 3.6927],\n",
      "        [3.5630, 3.5914, 3.7750, 3.6517, 3.6685],\n",
      "        [3.5118, 3.6697, 3.7107, 3.6825, 3.5849],\n",
      "        [3.5433, 3.7592, 3.8844, 3.7334, 3.6563],\n",
      "        [3.4710, 3.6309, 3.7024, 3.6223, 3.5740],\n",
      "        [3.9540, 3.8058, 4.1138, 4.4102, 4.2117],\n",
      "        [3.6572, 3.7495, 3.9121, 3.7553, 3.8177],\n",
      "        [3.7525, 3.8884, 3.9105, 3.9153, 3.8586],\n",
      "        [3.4039, 3.5841, 3.6812, 3.5380, 3.5197],\n",
      "        [3.7187, 3.8761, 4.0092, 3.8227, 3.6323],\n",
      "        [4.0022, 3.9317, 4.1251, 4.1197, 4.0379],\n",
      "        [4.0121, 4.0824, 4.1852, 4.2612, 4.0286]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6606, 3.8402, 4.0158, 3.9026, 3.8257],\n",
      "        [3.5651, 3.6732, 3.8028, 3.7046, 3.7134],\n",
      "        [3.7426, 4.0045, 4.0136, 3.9880, 3.8726],\n",
      "        [3.9375, 3.9534, 4.0963, 4.1226, 3.7604],\n",
      "        [3.9862, 4.1906, 3.9223, 3.8809, 3.7693],\n",
      "        [3.6117, 3.6562, 3.9414, 3.7644, 3.6995],\n",
      "        [3.8518, 3.8375, 3.9880, 3.9155, 3.8730],\n",
      "        [3.8033, 3.8382, 4.0471, 3.9948, 3.7966],\n",
      "        [3.7505, 3.8622, 4.0434, 3.9989, 3.7488],\n",
      "        [3.4661, 3.5398, 3.7568, 3.6290, 3.5422],\n",
      "        [3.3723, 3.5501, 3.6672, 3.5006, 3.4962],\n",
      "        [3.4313, 3.6265, 3.8273, 3.6247, 3.5517],\n",
      "        [3.5334, 3.6834, 3.7122, 3.7087, 3.5912],\n",
      "        [3.9324, 3.8452, 4.0325, 4.0035, 3.9024],\n",
      "        [3.7424, 3.6109, 3.7699, 3.7055, 3.7623],\n",
      "        [3.6076, 3.8148, 3.8753, 3.7377, 3.7225],\n",
      "        [3.4361, 3.7407, 3.9888, 3.7090, 3.6896],\n",
      "        [3.5031, 3.7142, 3.9055, 3.8041, 3.5767],\n",
      "        [3.5837, 3.6203, 3.8974, 3.7428, 3.6734],\n",
      "        [3.4610, 3.7601, 3.8652, 3.7125, 3.7872],\n",
      "        [3.5416, 3.8681, 3.9160, 3.7131, 3.5434],\n",
      "        [3.4586, 3.8290, 3.8688, 3.5552, 3.7254],\n",
      "        [3.4697, 3.5893, 3.8255, 3.6898, 3.6073],\n",
      "        [4.0117, 4.0835, 4.1891, 4.2606, 4.0281],\n",
      "        [3.5559, 3.7158, 3.7375, 3.7401, 3.6323],\n",
      "        [3.4103, 3.5688, 3.7599, 3.5848, 3.5109],\n",
      "        [3.5337, 3.6895, 3.7192, 3.7156, 3.6009],\n",
      "        [3.5817, 3.6181, 3.9201, 3.7310, 3.6839],\n",
      "        [3.5142, 3.8483, 3.9860, 3.6963, 3.8784],\n",
      "        [3.6362, 3.8891, 3.9152, 3.8296, 3.8427],\n",
      "        [4.0043, 4.0854, 4.1645, 4.2548, 4.0337],\n",
      "        [3.6133, 3.8207, 3.8702, 3.7372, 3.7305],\n",
      "        [3.9278, 3.9333, 4.1376, 4.1345, 3.9251],\n",
      "        [3.7937, 3.6601, 3.8791, 3.8006, 3.7671],\n",
      "        [3.7560, 4.0558, 4.1169, 3.9553, 3.9295],\n",
      "        [3.5695, 3.7253, 3.7501, 3.7577, 3.6407],\n",
      "        [3.5679, 3.5545, 3.8304, 3.7088, 3.7225],\n",
      "        [3.7366, 3.7538, 4.0150, 3.9802, 3.6597],\n",
      "        [3.7521, 4.0669, 4.0740, 4.0556, 3.9606],\n",
      "        [3.6107, 3.9651, 3.8711, 3.7826, 3.8736],\n",
      "        [3.9534, 3.8069, 4.1178, 4.4098, 4.2116],\n",
      "        [3.9133, 3.7171, 3.9608, 4.2801, 4.0167],\n",
      "        [3.9374, 3.9305, 4.0985, 4.1095, 3.9470],\n",
      "        [3.5710, 3.6170, 3.8641, 3.7188, 3.6555],\n",
      "        [3.5267, 3.7440, 3.8325, 3.7484, 3.6881],\n",
      "        [3.4546, 3.4849, 3.7226, 3.6234, 3.4854],\n",
      "        [3.4333, 3.5514, 3.7598, 3.6033, 3.5250],\n",
      "        [3.6247, 3.6861, 3.8719, 3.8076, 3.6710],\n",
      "        [3.6682, 3.6769, 3.9075, 3.6919, 3.6137],\n",
      "        [3.4089, 3.5476, 3.7512, 3.5852, 3.5013],\n",
      "        [3.5300, 4.0162, 4.0474, 3.7607, 3.6676],\n",
      "        [3.6364, 3.7965, 3.9027, 3.8201, 3.7496],\n",
      "        [3.5704, 3.7198, 3.8179, 3.7850, 3.6903],\n",
      "        [3.5700, 3.7128, 3.8555, 3.7275, 3.6872],\n",
      "        [3.7268, 3.7930, 3.8207, 3.8789, 3.8149],\n",
      "        [3.7012, 3.9373, 4.0288, 3.8928, 3.8874],\n",
      "        [3.6739, 3.6970, 3.8600, 3.8936, 3.7484],\n",
      "        [3.5662, 3.8522, 3.8074, 3.8441, 3.7059],\n",
      "        [4.0880, 4.1213, 4.2249, 4.3483, 3.9410],\n",
      "        [3.7123, 3.8704, 3.9184, 3.8246, 3.7354],\n",
      "        [3.5632, 3.6186, 3.8751, 3.6682, 3.6199],\n",
      "        [3.9724, 4.0241, 4.1744, 4.2449, 4.0044],\n",
      "        [3.5733, 3.9819, 3.9018, 3.9088, 3.8102],\n",
      "        [3.6836, 3.8521, 4.0350, 3.8485, 3.7362]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.9241, 3.9310, 4.1404, 4.1330, 3.9176],\n",
      "        [3.6009, 3.6264, 3.9442, 3.8003, 3.7656],\n",
      "        [3.5636, 3.6072, 3.8701, 3.6971, 3.6263],\n",
      "        [3.6588, 3.7503, 3.9001, 3.9069, 3.6884],\n",
      "        [3.5471, 3.6880, 3.8043, 3.6767, 3.6393],\n",
      "        [3.5926, 3.6000, 3.9185, 3.7694, 3.7470],\n",
      "        [4.0518, 4.1045, 4.1963, 4.3188, 3.9197],\n",
      "        [3.6869, 3.8422, 4.0285, 3.8251, 3.7495],\n",
      "        [3.7194, 3.8704, 4.0505, 3.8981, 3.8268],\n",
      "        [3.7652, 3.6644, 3.8880, 4.1281, 3.8632],\n",
      "        [3.8509, 3.8389, 3.9912, 3.9155, 3.8723],\n",
      "        [3.6586, 3.6555, 4.0164, 3.8662, 3.6558],\n",
      "        [3.5387, 3.6716, 3.8543, 3.7276, 3.7158],\n",
      "        [3.9119, 3.7787, 4.0773, 4.3695, 4.1724],\n",
      "        [3.6463, 3.9243, 4.0230, 3.8108, 3.7924],\n",
      "        [3.7315, 3.7648, 4.0549, 3.8193, 3.5679],\n",
      "        [3.4561, 3.6073, 3.7045, 3.6470, 3.5256],\n",
      "        [3.6380, 3.6081, 3.8487, 3.7061, 3.6954],\n",
      "        [3.8830, 3.7657, 4.0447, 4.0342, 3.8191],\n",
      "        [3.5468, 3.5760, 3.7542, 3.6273, 3.6451],\n",
      "        [3.7301, 3.6082, 3.9290, 3.9617, 3.9201],\n",
      "        [3.3412, 3.5168, 3.6462, 3.4696, 3.4676],\n",
      "        [3.5986, 3.8801, 4.0792, 3.8953, 3.7373],\n",
      "        [3.5499, 3.6592, 3.7947, 3.6955, 3.7064],\n",
      "        [3.5833, 3.6212, 3.8796, 3.6837, 3.6745],\n",
      "        [3.8873, 3.9878, 4.0788, 3.9743, 3.9428],\n",
      "        [3.4171, 3.5876, 3.6881, 3.5547, 3.5196],\n",
      "        [3.5785, 3.8608, 3.9271, 3.7409, 3.5579],\n",
      "        [3.4736, 3.9833, 3.8620, 3.6691, 3.7749],\n",
      "        [3.6945, 3.8249, 3.9125, 3.8044, 3.7956],\n",
      "        [3.5130, 3.5840, 3.8330, 3.6485, 3.5869],\n",
      "        [3.6165, 3.6595, 3.9672, 3.8890, 3.8810],\n",
      "        [3.5409, 3.6734, 3.7551, 3.6938, 3.6307],\n",
      "        [3.4022, 3.5862, 3.6876, 3.5371, 3.5184],\n",
      "        [3.6235, 3.6875, 3.8751, 3.8074, 3.6703],\n",
      "        [3.6146, 3.7301, 3.8842, 3.7380, 3.7722],\n",
      "        [3.7010, 3.9553, 3.9640, 3.8472, 3.7942],\n",
      "        [3.5500, 3.6999, 3.7224, 3.7261, 3.6064],\n",
      "        [3.7410, 3.9532, 3.9265, 3.8080, 3.7646],\n",
      "        [3.5125, 3.6136, 3.6206, 3.7367, 3.4710],\n",
      "        [3.6768, 3.6819, 3.9071, 3.7814, 3.6521],\n",
      "        [3.8199, 3.8672, 4.0627, 4.0539, 4.0457],\n",
      "        [3.7467, 3.8709, 3.9336, 3.8429, 3.8423],\n",
      "        [3.8026, 3.9030, 4.0747, 3.9447, 4.0306],\n",
      "        [3.7623, 3.9489, 4.0953, 3.8612, 3.6051],\n",
      "        [3.4142, 3.5341, 3.7490, 3.5883, 3.4983],\n",
      "        [3.4968, 3.6617, 3.7132, 3.6637, 3.5746],\n",
      "        [3.9585, 3.8607, 4.0985, 4.0474, 3.9644],\n",
      "        [3.6184, 3.5711, 3.7956, 3.6699, 3.6592],\n",
      "        [3.4676, 3.9116, 3.9886, 3.7531, 3.8326],\n",
      "        [3.4058, 3.6545, 3.8014, 3.5919, 3.5406],\n",
      "        [3.7035, 3.7315, 3.9335, 3.7593, 3.5806],\n",
      "        [3.5517, 3.6076, 3.8555, 3.6957, 3.6216],\n",
      "        [3.8972, 3.9317, 4.0978, 4.1023, 3.8525],\n",
      "        [3.7246, 3.6975, 3.8939, 3.6972, 3.5775],\n",
      "        [3.7151, 4.0647, 4.0691, 3.9397, 3.9503],\n",
      "        [3.4045, 3.6022, 3.7745, 3.5864, 3.5189],\n",
      "        [3.4975, 3.4864, 3.8482, 3.4801, 3.6512],\n",
      "        [4.0095, 3.9415, 4.1374, 4.1231, 4.0423],\n",
      "        [3.7341, 3.5837, 3.7628, 3.6986, 3.7433],\n",
      "        [3.7385, 3.8297, 4.0268, 3.9038, 3.6873],\n",
      "        [3.7604, 3.7900, 3.9405, 3.9136, 3.8816],\n",
      "        [3.4836, 3.5934, 3.8120, 3.6746, 3.5315],\n",
      "        [3.4750, 3.5397, 3.8480, 3.6508, 3.5754]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5778, 3.8130, 3.8664, 3.6877, 3.6999],\n",
      "        [3.5246, 3.6919, 3.7265, 3.6981, 3.6008],\n",
      "        [3.3697, 3.4870, 3.6759, 3.5057, 3.4657],\n",
      "        [3.7155, 3.8141, 4.0390, 3.8009, 3.5692],\n",
      "        [3.5317, 3.6200, 3.9624, 3.5774, 3.7601],\n",
      "        [3.3658, 3.5410, 3.6040, 3.5166, 3.4333],\n",
      "        [4.0126, 3.9366, 4.1657, 4.1907, 3.9982],\n",
      "        [3.5814, 3.6701, 3.8669, 3.7018, 3.8033],\n",
      "        [3.6449, 3.9252, 4.0256, 3.8104, 3.7913],\n",
      "        [3.4723, 3.6418, 3.7156, 3.6084, 3.5729],\n",
      "        [4.2355, 4.4009, 4.1932, 4.1228, 3.9342],\n",
      "        [3.5299, 3.6278, 3.8562, 3.7111, 3.6198],\n",
      "        [3.9733, 3.8757, 4.1232, 4.1812, 3.9900],\n",
      "        [3.4568, 3.6274, 3.8693, 3.7290, 3.6368],\n",
      "        [3.5231, 3.6103, 3.8632, 3.7176, 3.6998],\n",
      "        [3.4168, 3.5709, 3.6434, 3.5717, 3.4644],\n",
      "        [3.7953, 4.0658, 4.0578, 4.0166, 3.9718],\n",
      "        [3.7806, 3.8460, 4.0502, 3.8113, 3.5837],\n",
      "        [3.6975, 3.8933, 3.9227, 3.9712, 3.8069],\n",
      "        [3.4259, 3.6958, 3.9308, 3.6420, 3.6460],\n",
      "        [3.4168, 3.5386, 3.7171, 3.5723, 3.5100],\n",
      "        [3.3977, 3.5869, 3.6934, 3.5420, 3.5198],\n",
      "        [3.3508, 3.5335, 3.6592, 3.4761, 3.4745],\n",
      "        [3.5320, 3.6841, 3.7285, 3.6863, 3.6130],\n",
      "        [3.6328, 3.8431, 3.9155, 3.8370, 3.7000],\n",
      "        [3.5610, 3.7899, 3.9324, 3.7554, 3.6239],\n",
      "        [3.5872, 3.8715, 4.0766, 3.9055, 3.7355],\n",
      "        [3.5818, 3.7037, 3.8608, 3.6947, 3.5472],\n",
      "        [3.4768, 3.6426, 3.7172, 3.6165, 3.5824],\n",
      "        [3.6494, 3.6555, 3.9021, 3.6795, 3.6074],\n",
      "        [3.5431, 3.5509, 3.8768, 3.5759, 3.6685],\n",
      "        [3.6070, 3.6672, 3.9520, 3.7680, 3.7059],\n",
      "        [3.7025, 3.9514, 4.0640, 3.8929, 3.7481],\n",
      "        [4.1872, 4.4121, 4.1366, 4.1095, 3.9082],\n",
      "        [3.6491, 3.8514, 3.9062, 3.7381, 3.7443],\n",
      "        [3.4770, 3.5995, 3.8272, 3.7022, 3.5915],\n",
      "        [3.4565, 3.5355, 3.6486, 3.6555, 3.4693],\n",
      "        [3.7060, 3.7114, 4.0334, 3.9902, 3.6960],\n",
      "        [3.6975, 3.8933, 3.9227, 3.9712, 3.8069],\n",
      "        [3.6975, 3.8933, 3.9227, 3.9712, 3.8069],\n",
      "        [3.8655, 3.9067, 4.0787, 4.0548, 3.8157],\n",
      "        [3.7313, 3.7373, 3.9917, 3.9303, 3.6680],\n",
      "        [3.4586, 3.5060, 3.7391, 3.6298, 3.4971],\n",
      "        [3.3437, 3.5061, 3.6177, 3.5369, 3.4429],\n",
      "        [3.9997, 3.9350, 4.1348, 4.1191, 4.0356],\n",
      "        [3.4897, 3.5710, 3.8632, 3.6755, 3.5944],\n",
      "        [3.6708, 3.8637, 3.8902, 3.9307, 3.7593],\n",
      "        [3.3633, 3.5522, 3.6709, 3.4905, 3.4864],\n",
      "        [3.5688, 3.6659, 3.8637, 3.7067, 3.7805],\n",
      "        [3.4915, 3.6464, 3.7080, 3.6463, 3.5606],\n",
      "        [3.7665, 3.9462, 4.0965, 3.8616, 3.5927],\n",
      "        [3.5458, 3.6432, 3.8646, 3.7265, 3.6380],\n",
      "        [3.8867, 3.9564, 4.0154, 3.9762, 3.9643],\n",
      "        [3.5988, 3.8561, 3.9395, 3.7579, 3.5672],\n",
      "        [3.3660, 3.5474, 3.5860, 3.6041, 3.4528],\n",
      "        [3.5824, 3.6012, 3.9157, 3.7623, 3.7427],\n",
      "        [3.7299, 3.8942, 4.0738, 3.8953, 3.9380],\n",
      "        [3.7442, 3.7773, 3.9334, 3.9048, 3.8704],\n",
      "        [3.7534, 4.0583, 4.1229, 3.9547, 3.9277],\n",
      "        [3.9804, 3.9173, 4.0855, 4.0773, 3.9846],\n",
      "        [3.6368, 3.6090, 3.8509, 3.7057, 3.6942],\n",
      "        [3.7605, 3.9615, 3.9118, 3.7979, 3.7542],\n",
      "        [3.6454, 3.7313, 3.8195, 3.8128, 3.7053],\n",
      "        [3.4165, 3.8041, 3.8395, 3.5225, 3.6954]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6803, 3.8644, 3.9040, 3.8034, 3.7376],\n",
      "        [3.5810, 3.6736, 3.8912, 3.6276, 3.4670],\n",
      "        [3.8534, 3.7410, 3.8934, 3.8705, 3.8359],\n",
      "        [3.8588, 3.8973, 4.1025, 4.0013, 3.8436],\n",
      "        [3.4157, 3.6008, 3.7828, 3.5999, 3.5381],\n",
      "        [3.8299, 3.8688, 4.1371, 4.1136, 3.7747],\n",
      "        [3.6820, 3.9668, 4.0540, 3.8866, 3.9283],\n",
      "        [3.6189, 3.6897, 3.8790, 3.8065, 3.6680],\n",
      "        [3.4652, 3.6492, 3.8757, 3.6688, 3.5469],\n",
      "        [3.9796, 3.8511, 4.1235, 4.1483, 3.9629],\n",
      "        [3.7335, 3.9442, 3.9215, 3.7050, 3.6763],\n",
      "        [3.5877, 3.8123, 3.8168, 3.7092, 3.6566],\n",
      "        [3.5289, 3.6055, 3.8723, 3.7184, 3.6834],\n",
      "        [4.2344, 4.4027, 4.1953, 4.1230, 3.9329],\n",
      "        [3.5452, 3.5234, 3.7638, 3.6450, 3.6926],\n",
      "        [3.9895, 3.8352, 4.1855, 4.4415, 4.2674],\n",
      "        [3.5591, 3.5955, 3.7849, 3.6504, 3.6644],\n",
      "        [3.4835, 3.6543, 3.7127, 3.6457, 3.5700],\n",
      "        [3.6941, 3.8920, 3.9235, 3.9699, 3.8021],\n",
      "        [3.5886, 3.6290, 3.8981, 3.7419, 3.6594],\n",
      "        [3.5587, 3.6687, 3.8619, 3.7114, 3.7589],\n",
      "        [3.5610, 3.6093, 3.8747, 3.6971, 3.6242],\n",
      "        [3.5668, 3.5613, 3.8335, 3.6998, 3.7258],\n",
      "        [3.5536, 3.8767, 3.9333, 3.7207, 3.5460],\n",
      "        [3.5265, 3.6930, 3.7356, 3.7009, 3.6061],\n",
      "        [3.5761, 3.7030, 3.8359, 3.6763, 3.6496],\n",
      "        [3.4775, 3.9137, 3.8054, 3.6413, 3.7417],\n",
      "        [3.4475, 3.4967, 3.7311, 3.6231, 3.4860],\n",
      "        [3.4430, 3.5325, 3.7558, 3.6133, 3.5061],\n",
      "        [3.9088, 3.7982, 3.9767, 3.9538, 3.9029],\n",
      "        [3.5443, 3.7015, 3.7328, 3.7267, 3.6098],\n",
      "        [3.5352, 3.6200, 3.8488, 3.6952, 3.6146],\n",
      "        [3.6706, 3.9784, 4.0537, 3.8842, 3.9460],\n",
      "        [3.4276, 3.6496, 3.8063, 3.6091, 3.5632],\n",
      "        [3.9911, 4.1138, 4.1866, 4.2842, 4.0593],\n",
      "        [3.4936, 3.6216, 3.7521, 3.7278, 3.5898],\n",
      "        [3.6434, 3.5035, 3.9965, 3.7729, 3.6579],\n",
      "        [3.8417, 4.0107, 3.9219, 3.8365, 3.7606],\n",
      "        [3.5318, 3.5706, 3.7525, 3.6175, 3.6386],\n",
      "        [3.6560, 3.6577, 4.0211, 3.8660, 3.6535],\n",
      "        [3.7108, 3.8628, 4.0068, 3.9640, 3.7405],\n",
      "        [3.4140, 3.6192, 3.7896, 3.6007, 3.5421],\n",
      "        [3.5596, 3.7911, 3.9349, 3.7555, 3.6226],\n",
      "        [3.7188, 3.9004, 4.0547, 3.8361, 3.6601],\n",
      "        [3.5574, 3.6719, 3.8084, 3.6388, 3.6318],\n",
      "        [3.5779, 3.8843, 3.9519, 3.7564, 3.5595],\n",
      "        [4.1979, 4.3895, 4.1496, 4.0855, 3.9351],\n",
      "        [3.9149, 3.7508, 3.9814, 4.2802, 4.0345],\n",
      "        [3.6376, 3.7465, 3.8233, 3.7968, 3.7071],\n",
      "        [3.6679, 3.7909, 4.0097, 3.7660, 3.6048],\n",
      "        [3.3962, 3.5931, 3.7087, 3.5364, 3.5298],\n",
      "        [3.6672, 3.9636, 4.0413, 3.8792, 3.9305],\n",
      "        [3.5519, 3.7604, 3.9040, 3.7290, 3.6648],\n",
      "        [3.8413, 3.5950, 3.9437, 4.1192, 4.0099],\n",
      "        [3.7127, 3.8643, 3.9300, 3.7983, 3.7299],\n",
      "        [3.5270, 3.6123, 3.9692, 3.5536, 3.7637],\n",
      "        [3.9241, 3.7804, 4.0774, 4.0251, 3.8666],\n",
      "        [3.5828, 3.8807, 3.9839, 3.8487, 3.8623],\n",
      "        [3.4222, 3.5424, 3.7573, 3.5954, 3.5056],\n",
      "        [3.6571, 3.6621, 3.9172, 3.6740, 3.6489],\n",
      "        [3.6961, 3.8945, 3.9250, 3.9713, 3.8056],\n",
      "        [3.3752, 3.5579, 3.5872, 3.5927, 3.4547],\n",
      "        [3.4515, 3.5866, 3.6911, 3.6621, 3.5280],\n",
      "        [3.5073, 3.6738, 3.7224, 3.6814, 3.5816]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7127, 3.8901, 4.0389, 3.8089, 3.6453],\n",
      "        [3.9178, 3.7861, 4.0893, 4.3746, 4.1761],\n",
      "        [3.5810, 3.7879, 3.7996, 3.8730, 3.6013],\n",
      "        [3.7328, 3.9380, 3.9648, 3.8482, 3.8245],\n",
      "        [3.9202, 3.9721, 4.0805, 4.1283, 3.9408],\n",
      "        [3.8888, 3.9250, 4.0792, 4.0964, 3.8625],\n",
      "        [3.7247, 3.8066, 4.1714, 3.7698, 3.6271],\n",
      "        [3.4633, 3.5574, 3.6651, 3.6806, 3.5211],\n",
      "        [3.7642, 3.8005, 3.9800, 3.8531, 3.8852],\n",
      "        [3.5549, 3.7188, 3.7374, 3.7435, 3.6190],\n",
      "        [3.6814, 3.7492, 3.9519, 3.7808, 3.7953],\n",
      "        [3.8490, 3.9301, 4.0962, 3.9792, 4.0657],\n",
      "        [3.7496, 3.6700, 3.8858, 4.0870, 3.8409],\n",
      "        [3.4030, 3.5867, 3.7729, 3.5848, 3.5108],\n",
      "        [3.7991, 3.9304, 4.1158, 3.9402, 4.0307],\n",
      "        [3.5306, 3.5584, 3.8533, 3.6701, 3.5807],\n",
      "        [3.7140, 3.7727, 4.1297, 3.7934, 3.5958],\n",
      "        [3.5397, 3.6198, 3.8532, 3.7033, 3.6238],\n",
      "        [3.5646, 3.5691, 3.8714, 3.7141, 3.7197],\n",
      "        [3.4142, 3.5908, 3.6938, 3.5542, 3.5159],\n",
      "        [3.7022, 3.8880, 4.0254, 3.8876, 3.7928],\n",
      "        [3.5424, 3.6212, 3.8566, 3.6982, 3.6204],\n",
      "        [3.6438, 3.7339, 3.8229, 3.8128, 3.7026],\n",
      "        [3.6475, 3.9717, 3.9120, 3.8158, 3.8936],\n",
      "        [3.5339, 3.6664, 3.7859, 3.7240, 3.5989],\n",
      "        [4.2602, 4.4303, 4.2281, 4.1364, 3.9621],\n",
      "        [3.5329, 3.5160, 3.7472, 3.6263, 3.6826],\n",
      "        [3.5922, 3.6864, 4.0020, 3.7872, 3.7163],\n",
      "        [3.6636, 3.7275, 4.0140, 3.8491, 3.6806],\n",
      "        [3.4532, 3.6182, 3.7041, 3.5976, 3.5394],\n",
      "        [3.4941, 3.5988, 3.8123, 3.6881, 3.5380],\n",
      "        [3.4451, 3.7373, 4.0032, 3.6931, 3.7044],\n",
      "        [3.5143, 3.8864, 3.9263, 3.6945, 3.5430],\n",
      "        [3.5587, 3.5970, 3.7860, 3.6503, 3.6629],\n",
      "        [3.8452, 3.9613, 4.0100, 3.9557, 3.9277],\n",
      "        [3.5570, 3.8119, 3.8980, 3.6709, 3.7098],\n",
      "        [3.4508, 3.6087, 3.6870, 3.6634, 3.5380],\n",
      "        [3.7897, 3.6008, 3.9363, 4.0577, 3.9623],\n",
      "        [3.4805, 3.5967, 3.8176, 3.6741, 3.5278],\n",
      "        [3.9335, 3.8459, 4.1119, 4.1024, 3.8849],\n",
      "        [3.4815, 3.6388, 3.7395, 3.6943, 3.5417],\n",
      "        [3.7778, 3.9504, 4.1073, 3.9493, 3.9879],\n",
      "        [3.5016, 3.6005, 3.8649, 3.6902, 3.6059],\n",
      "        [3.7343, 4.0585, 4.0665, 4.0473, 3.9406],\n",
      "        [3.5329, 3.5160, 3.7472, 3.6263, 3.6826],\n",
      "        [3.5789, 3.9008, 3.9805, 3.8628, 3.8631],\n",
      "        [3.5720, 3.7365, 3.9200, 3.8832, 3.6478],\n",
      "        [3.6235, 3.8384, 3.8863, 3.7312, 3.7287],\n",
      "        [3.5741, 3.6545, 3.8731, 3.6087, 3.4554],\n",
      "        [3.4297, 3.6163, 3.7072, 3.5842, 3.5357],\n",
      "        [3.6904, 3.8563, 3.9191, 3.8698, 3.7527],\n",
      "        [3.3338, 3.5028, 3.6248, 3.5120, 3.4419],\n",
      "        [3.6162, 3.7161, 3.8696, 3.7279, 3.6703],\n",
      "        [3.6903, 3.9522, 4.0618, 3.8949, 3.7334],\n",
      "        [3.4397, 3.6376, 3.8380, 3.6398, 3.5451],\n",
      "        [3.8163, 3.7348, 3.9276, 3.8833, 3.8411],\n",
      "        [3.4853, 3.6536, 3.7192, 3.6419, 3.5769],\n",
      "        [3.6130, 3.6035, 3.8720, 3.7403, 3.6035],\n",
      "        [3.7819, 3.9362, 4.0967, 3.9443, 3.9813],\n",
      "        [3.4558, 3.6387, 3.7177, 3.6098, 3.5611],\n",
      "        [3.5432, 3.5667, 3.8543, 3.6751, 3.6067],\n",
      "        [3.6499, 3.8778, 3.8829, 3.7818, 3.7170],\n",
      "        [3.4151, 3.5734, 3.6468, 3.5715, 3.4618],\n",
      "        [3.5452, 3.5932, 3.8632, 3.6896, 3.6019]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8403, 4.0190, 3.9244, 3.8346, 3.7584],\n",
      "        [3.5333, 3.6960, 3.7308, 3.7199, 3.6046],\n",
      "        [3.6563, 3.8487, 4.0299, 3.9028, 3.8200],\n",
      "        [3.2907, 3.5088, 3.7292, 3.4973, 3.4993],\n",
      "        [3.5348, 3.6979, 3.7356, 3.7081, 3.6066],\n",
      "        [3.6515, 3.8570, 3.8869, 3.9241, 3.7468],\n",
      "        [3.4174, 3.5723, 3.7736, 3.6056, 3.5134],\n",
      "        [3.5904, 3.6393, 3.8777, 3.7134, 3.6659],\n",
      "        [3.7739, 3.8696, 4.0893, 4.0219, 3.7502],\n",
      "        [3.5263, 3.6968, 3.7382, 3.7011, 3.6033],\n",
      "        [3.8078, 3.8463, 4.0379, 4.0355, 4.0267],\n",
      "        [3.6629, 3.9796, 3.9749, 3.8679, 3.7831],\n",
      "        [3.7156, 3.9649, 3.9767, 3.8709, 3.7866],\n",
      "        [3.7699, 3.8358, 4.0162, 3.9357, 3.8965],\n",
      "        [3.3470, 3.5624, 3.7267, 3.5746, 3.5174],\n",
      "        [3.5071, 3.6776, 3.7250, 3.6815, 3.5787],\n",
      "        [3.7397, 3.6181, 3.7795, 3.7064, 3.7568],\n",
      "        [3.4496, 3.7023, 3.6764, 3.6645, 3.5074],\n",
      "        [3.5785, 3.6224, 3.8828, 3.7139, 3.6665],\n",
      "        [3.5361, 3.6780, 3.8622, 3.7275, 3.7105],\n",
      "        [3.6738, 3.7652, 3.9867, 3.8018, 3.7181],\n",
      "        [3.5555, 3.7216, 3.7403, 3.7590, 3.6227],\n",
      "        [3.6288, 3.7123, 3.8891, 3.8359, 3.6693],\n",
      "        [3.5534, 3.8808, 3.9367, 3.7207, 3.5431],\n",
      "        [3.6346, 3.8795, 4.0884, 3.9423, 3.7924],\n",
      "        [3.6285, 3.9144, 3.8907, 3.6308, 3.7367],\n",
      "        [3.4118, 3.5605, 3.7655, 3.5890, 3.5006],\n",
      "        [3.6159, 3.9531, 4.0789, 3.8967, 3.8679],\n",
      "        [3.5160, 3.6833, 3.7244, 3.6961, 3.5837],\n",
      "        [3.9430, 3.9459, 3.9742, 4.0589, 4.0527],\n",
      "        [3.5590, 3.6260, 3.8850, 3.6681, 3.6141],\n",
      "        [3.4378, 3.6297, 3.7094, 3.5876, 3.5465],\n",
      "        [3.4133, 3.6828, 3.8160, 3.6006, 3.5539],\n",
      "        [3.7669, 4.0353, 4.0569, 4.0232, 3.8898],\n",
      "        [3.4094, 3.6775, 3.8189, 3.6064, 3.5563],\n",
      "        [3.5464, 3.6354, 3.8670, 3.7146, 3.6201],\n",
      "        [3.4354, 3.5239, 3.7489, 3.6058, 3.4933],\n",
      "        [3.5882, 3.6392, 3.9230, 3.7539, 3.6852],\n",
      "        [3.5906, 3.6755, 3.8744, 3.6980, 3.8195],\n",
      "        [3.4591, 3.6213, 3.8254, 3.5721, 3.6781],\n",
      "        [3.4862, 3.5838, 3.8522, 3.6892, 3.6749],\n",
      "        [3.4866, 3.4847, 3.7070, 3.6188, 3.4623],\n",
      "        [3.6989, 3.8080, 4.0128, 3.8819, 3.8718],\n",
      "        [3.6239, 3.8410, 3.8873, 3.7315, 3.7271],\n",
      "        [3.6125, 3.6727, 3.8796, 3.7764, 3.6616],\n",
      "        [3.4669, 3.5865, 3.8098, 3.6692, 3.5114],\n",
      "        [3.8482, 3.8694, 4.0730, 3.9894, 3.7193],\n",
      "        [3.4031, 3.6109, 3.7837, 3.5845, 3.5134],\n",
      "        [3.7885, 3.8439, 4.0395, 3.9463, 3.7069],\n",
      "        [3.6441, 3.7364, 3.8238, 3.8132, 3.7011],\n",
      "        [3.5267, 3.7363, 3.9975, 3.6875, 3.6517],\n",
      "        [3.5445, 3.6524, 3.8743, 3.7220, 3.6296],\n",
      "        [3.5381, 3.6157, 3.8481, 3.6917, 3.6103],\n",
      "        [3.6938, 3.8961, 3.9264, 3.9700, 3.7991],\n",
      "        [3.6351, 3.7273, 3.8862, 3.7419, 3.6764],\n",
      "        [3.6968, 3.8780, 3.9408, 3.8223, 3.8304],\n",
      "        [3.3713, 3.6476, 3.5988, 3.6241, 3.4360],\n",
      "        [3.4429, 3.5153, 3.7459, 3.6138, 3.4901],\n",
      "        [3.6356, 3.6926, 3.9488, 3.7844, 3.7921],\n",
      "        [3.5886, 3.6331, 3.9003, 3.7422, 3.6565],\n",
      "        [4.0088, 4.2258, 3.9633, 3.9245, 3.7456],\n",
      "        [3.7305, 3.8690, 4.0344, 3.9836, 3.7398],\n",
      "        [3.8686, 3.7334, 3.9553, 4.2064, 3.9628],\n",
      "        [3.5574, 3.8145, 3.8990, 3.6712, 3.7082]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7805, 3.8286, 4.0190, 3.9059, 3.9042],\n",
      "        [3.7707, 3.6550, 3.8943, 3.7885, 3.7248],\n",
      "        [3.3259, 3.5984, 3.8853, 3.5460, 3.6110],\n",
      "        [3.5880, 3.6343, 3.9032, 3.7214, 3.6743],\n",
      "        [3.5828, 3.8873, 3.9871, 3.8490, 3.8576],\n",
      "        [3.5437, 3.5564, 3.8189, 3.6151, 3.5375],\n",
      "        [3.7962, 3.9522, 4.1436, 4.0900, 4.1202],\n",
      "        [3.6176, 3.6136, 3.8868, 3.7364, 3.6309],\n",
      "        [3.4722, 3.6862, 3.7490, 3.7332, 3.5462],\n",
      "        [3.4599, 3.6223, 3.7197, 3.6615, 3.5228],\n",
      "        [3.6005, 3.5673, 3.9331, 3.8900, 3.5715],\n",
      "        [3.4329, 3.6008, 3.7886, 3.6079, 3.5442],\n",
      "        [3.5526, 3.6666, 3.8881, 3.7291, 3.6485],\n",
      "        [3.5479, 3.6386, 3.8635, 3.7115, 3.6208],\n",
      "        [3.3621, 3.5587, 3.6756, 3.4906, 3.4805],\n",
      "        [3.5900, 3.6083, 3.9264, 3.7703, 3.7405],\n",
      "        [3.5289, 3.7120, 3.9011, 3.7925, 3.6407],\n",
      "        [3.4785, 3.6530, 3.7180, 3.6418, 3.5604],\n",
      "        [3.8495, 3.7124, 3.9152, 3.8511, 3.8127],\n",
      "        [3.5766, 3.7975, 3.8006, 3.7003, 3.6344],\n",
      "        [3.8854, 3.9973, 4.0858, 3.9744, 3.9355],\n",
      "        [3.3892, 3.5449, 3.6499, 3.6203, 3.4358],\n",
      "        [3.4180, 3.7344, 3.9780, 3.6824, 3.6672],\n",
      "        [3.7203, 3.7289, 4.0024, 3.8708, 3.7155],\n",
      "        [3.6184, 3.5981, 3.9514, 3.8974, 3.5795],\n",
      "        [3.7644, 3.6146, 3.9415, 4.0137, 3.9394],\n",
      "        [3.8006, 3.9124, 4.0835, 3.9453, 4.0237],\n",
      "        [3.5369, 3.6824, 3.8081, 3.6665, 3.6294],\n",
      "        [3.5119, 3.5715, 3.8260, 3.6363, 3.5599],\n",
      "        [3.7822, 3.7439, 3.9280, 3.7681, 3.6426],\n",
      "        [3.5495, 3.6469, 3.8794, 3.7265, 3.6460],\n",
      "        [3.6116, 3.7509, 3.9012, 3.8005, 3.7526],\n",
      "        [3.9983, 3.9847, 4.1868, 4.2337, 4.0165],\n",
      "        [3.7095, 3.9739, 4.0571, 3.9249, 3.8977],\n",
      "        [3.6868, 3.6935, 3.8968, 3.6596, 3.5278],\n",
      "        [3.7777, 3.9158, 4.0622, 3.9219, 3.9692],\n",
      "        [3.5415, 3.5723, 3.8301, 3.6304, 3.5532],\n",
      "        [3.6629, 3.7759, 3.9201, 3.9261, 3.6883],\n",
      "        [3.8293, 3.9349, 4.1420, 3.9104, 3.6918],\n",
      "        [3.3615, 3.5529, 3.6759, 3.4887, 3.4776],\n",
      "        [3.4988, 3.6713, 3.9511, 3.7203, 3.7051],\n",
      "        [3.6508, 3.8537, 4.0576, 3.9141, 3.7932],\n",
      "        [3.7401, 3.6200, 3.7801, 3.7067, 3.7552],\n",
      "        [3.5376, 3.5864, 3.8430, 3.6361, 3.5701],\n",
      "        [3.7490, 4.0790, 4.0533, 3.8858, 4.0643],\n",
      "        [3.5466, 3.6233, 3.8566, 3.6913, 3.6129],\n",
      "        [3.5148, 3.6878, 3.7361, 3.6833, 3.5899],\n",
      "        [3.6917, 3.8779, 3.9279, 3.8393, 3.7229],\n",
      "        [3.4797, 3.5531, 3.8614, 3.6593, 3.5687],\n",
      "        [3.9472, 3.9493, 3.9760, 4.0609, 4.0518],\n",
      "        [3.7300, 3.5427, 3.7648, 3.7207, 3.6892],\n",
      "        [3.6270, 3.9002, 3.8977, 3.9071, 3.7457],\n",
      "        [3.3874, 3.6454, 3.9406, 3.6025, 3.6865],\n",
      "        [3.7775, 3.9719, 4.0423, 3.9702, 4.0198],\n",
      "        [3.7110, 3.9552, 3.9662, 3.8455, 3.7919],\n",
      "        [3.8839, 3.8609, 3.9916, 3.9408, 3.8775],\n",
      "        [3.4625, 3.6686, 3.7429, 3.6220, 3.5998],\n",
      "        [3.6071, 3.8734, 3.9766, 3.8511, 3.6611],\n",
      "        [3.5075, 3.6177, 3.7891, 3.6183, 3.5896],\n",
      "        [3.6962, 4.0674, 4.0855, 3.9249, 3.9114],\n",
      "        [3.6595, 3.8902, 3.9387, 3.9309, 3.7513],\n",
      "        [3.5513, 3.6042, 3.8739, 3.6968, 3.6142],\n",
      "        [3.6711, 3.9871, 3.9821, 3.8555, 3.7884],\n",
      "        [3.7173, 3.9363, 3.9676, 3.8652, 3.7803]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7478, 3.8028, 4.0940, 3.8530, 3.5635],\n",
      "        [3.4934, 3.6295, 3.7556, 3.7276, 3.5832],\n",
      "        [3.4897, 3.6622, 3.7244, 3.6334, 3.5809],\n",
      "        [3.5660, 3.6497, 3.9458, 3.6436, 3.7682],\n",
      "        [3.5320, 3.5872, 3.8593, 3.6851, 3.5916],\n",
      "        [3.6425, 3.9625, 3.9854, 3.8614, 3.8603],\n",
      "        [3.9794, 4.0303, 4.1396, 4.2259, 3.8371],\n",
      "        [3.6115, 3.8984, 3.8797, 3.8969, 3.7375],\n",
      "        [3.4410, 3.6157, 3.6820, 3.6191, 3.4795],\n",
      "        [3.5240, 3.6717, 3.7575, 3.6773, 3.6107],\n",
      "        [3.6956, 3.9027, 3.9292, 3.9713, 3.7989],\n",
      "        [3.5381, 3.6790, 3.9591, 3.8193, 3.7951],\n",
      "        [3.7188, 3.9088, 4.0583, 3.8362, 3.6533],\n",
      "        [3.7072, 3.8853, 4.0052, 3.9624, 3.7459],\n",
      "        [3.5142, 3.8932, 3.9296, 3.6944, 3.5378],\n",
      "        [3.4792, 3.5476, 3.7730, 3.6433, 3.4984],\n",
      "        [3.6475, 3.8602, 3.9688, 3.7876, 3.5922],\n",
      "        [3.6710, 3.7022, 3.9287, 3.7199, 3.5850],\n",
      "        [3.5370, 3.8803, 3.9301, 3.7123, 3.5338],\n",
      "        [3.9581, 3.9602, 4.0793, 4.0918, 3.9818],\n",
      "        [3.8188, 3.8928, 4.1418, 4.0617, 3.7741],\n",
      "        [3.4521, 3.5045, 3.7385, 3.6305, 3.4919],\n",
      "        [3.5660, 3.7472, 3.7621, 3.7645, 3.6392],\n",
      "        [3.7967, 3.8441, 4.0385, 3.9919, 3.7872],\n",
      "        [3.7110, 3.8716, 4.0108, 3.9643, 3.7340],\n",
      "        [3.4753, 3.6515, 3.7227, 3.6164, 3.5747],\n",
      "        [3.6025, 3.7555, 3.9132, 3.8403, 3.7080],\n",
      "        [3.7018, 3.9614, 4.0707, 3.8929, 3.7402],\n",
      "        [4.1723, 4.3908, 4.1709, 4.1096, 3.8996],\n",
      "        [3.8823, 3.7714, 4.0484, 4.0299, 3.8053],\n",
      "        [3.3470, 3.5664, 3.7275, 3.5744, 3.5138],\n",
      "        [3.8247, 3.8423, 3.9941, 3.8878, 3.8552],\n",
      "        [3.5464, 3.6316, 3.8636, 3.7090, 3.6128],\n",
      "        [3.4037, 3.6701, 3.8059, 3.5894, 3.5315],\n",
      "        [3.6973, 3.7242, 3.9366, 3.7369, 3.5957],\n",
      "        [3.7390, 3.9695, 3.9401, 3.8095, 3.7582],\n",
      "        [3.4320, 3.7834, 3.7404, 3.4701, 3.6206],\n",
      "        [3.7189, 3.8912, 4.0328, 3.8939, 3.7676],\n",
      "        [3.4510, 3.6835, 3.9190, 3.6827, 3.6753],\n",
      "        [3.4101, 3.6307, 3.7973, 3.6026, 3.5328],\n",
      "        [3.4813, 3.6027, 3.8397, 3.6913, 3.5903],\n",
      "        [3.6568, 3.6692, 3.9128, 3.6827, 3.6314],\n",
      "        [3.4184, 3.5701, 3.7706, 3.5915, 3.5029],\n",
      "        [3.4340, 3.5605, 3.7888, 3.6180, 3.4838],\n",
      "        [3.7778, 3.8740, 4.0781, 3.9394, 3.9546],\n",
      "        [3.6853, 3.7450, 4.0265, 3.7615, 3.4928],\n",
      "        [3.4199, 3.5713, 3.7761, 3.5947, 3.5049],\n",
      "        [3.6269, 3.9026, 3.8980, 3.9069, 3.7439],\n",
      "        [3.8117, 3.8386, 4.1263, 4.0803, 3.7234],\n",
      "        [3.7198, 3.7675, 3.9560, 3.7731, 3.5709],\n",
      "        [3.7157, 3.9602, 3.9806, 3.8511, 3.8074],\n",
      "        [3.5400, 3.6683, 3.8092, 3.6858, 3.6853],\n",
      "        [3.5346, 3.7019, 3.7367, 3.7080, 3.6031],\n",
      "        [3.6957, 3.8033, 4.0040, 3.8838, 3.8902],\n",
      "        [3.7904, 3.7876, 4.0328, 3.9436, 3.7502],\n",
      "        [3.4621, 3.5507, 3.7673, 3.6285, 3.5326],\n",
      "        [3.5349, 3.6279, 3.8523, 3.6953, 3.6081],\n",
      "        [3.7701, 3.8401, 4.0172, 3.9358, 3.8927],\n",
      "        [3.4559, 3.5451, 3.6546, 3.6559, 3.4624],\n",
      "        [3.5419, 3.8458, 3.9404, 3.6352, 3.7213],\n",
      "        [3.8028, 4.0064, 4.1090, 3.9908, 3.9066],\n",
      "        [3.6054, 3.6768, 3.9574, 3.7688, 3.6983],\n",
      "        [3.4305, 3.5368, 3.7460, 3.5932, 3.4854],\n",
      "        [3.7338, 3.9534, 3.9247, 3.7051, 3.6696]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3420, 3.5169, 3.6225, 3.5361, 3.4332],\n",
      "        [3.4016, 3.7135, 3.8128, 3.6565, 3.7117],\n",
      "        [3.5326, 3.7023, 3.7320, 3.7192, 3.5992],\n",
      "        [3.5875, 3.6390, 3.9033, 3.7208, 3.6705],\n",
      "        [3.6624, 3.9866, 3.9761, 3.8672, 3.7775],\n",
      "        [3.4801, 3.6527, 3.7100, 3.6281, 3.5462],\n",
      "        [3.5959, 3.8231, 3.8450, 3.7097, 3.6637],\n",
      "        [3.5770, 3.8952, 3.9570, 3.7555, 3.5509],\n",
      "        [3.5142, 3.6923, 3.7365, 3.6825, 3.5862],\n",
      "        [3.6412, 3.9832, 3.9978, 3.8610, 3.8551],\n",
      "        [3.6112, 3.9009, 3.8797, 3.8964, 3.7356],\n",
      "        [3.4226, 3.5801, 3.7755, 3.5989, 3.5162],\n",
      "        [3.4515, 3.5042, 3.7360, 3.6143, 3.4864],\n",
      "        [3.5827, 3.8968, 3.8113, 3.7394, 3.6421],\n",
      "        [3.7125, 3.7698, 3.9427, 3.7761, 3.5465],\n",
      "        [3.5468, 3.6091, 3.8604, 3.6891, 3.6031],\n",
      "        [3.5318, 3.7466, 3.9357, 3.8227, 3.6001],\n",
      "        [3.4334, 3.5585, 3.7755, 3.6222, 3.5075],\n",
      "        [3.4384, 3.6251, 3.7064, 3.5855, 3.5314],\n",
      "        [3.8485, 3.8837, 4.0731, 4.0317, 3.8358],\n",
      "        [3.5359, 3.7316, 3.9167, 3.9003, 3.5780],\n",
      "        [3.6276, 3.9154, 3.9378, 3.8340, 3.8393],\n",
      "        [3.7674, 4.0461, 4.0578, 4.0192, 3.8867],\n",
      "        [3.5573, 3.6823, 3.8104, 3.6379, 3.6230],\n",
      "        [3.5440, 3.6589, 3.8752, 3.7213, 3.6240],\n",
      "        [3.4696, 3.6274, 3.7159, 3.6777, 3.4976],\n",
      "        [3.6660, 3.6774, 4.0358, 3.8621, 3.6890],\n",
      "        [3.6247, 4.0388, 3.9543, 3.9528, 3.8379],\n",
      "        [3.5674, 3.7332, 3.7500, 3.7555, 3.6139],\n",
      "        [3.6903, 3.7641, 3.9173, 3.7497, 3.4965],\n",
      "        [3.3954, 3.5842, 3.6892, 3.5318, 3.4983],\n",
      "        [3.5771, 3.7442, 3.9067, 3.8467, 3.6615],\n",
      "        [3.5001, 3.6675, 3.7159, 3.6692, 3.5551],\n",
      "        [3.4113, 3.5668, 3.7661, 3.5882, 3.4950],\n",
      "        [3.4661, 3.6308, 3.8471, 3.6642, 3.5183],\n",
      "        [3.9183, 4.0419, 4.0986, 4.0071, 4.0057],\n",
      "        [3.6071, 3.9800, 3.8814, 3.7816, 3.8616],\n",
      "        [3.4749, 3.6646, 3.7296, 3.6324, 3.5635],\n",
      "        [3.6192, 3.8859, 3.9137, 3.8144, 3.8155],\n",
      "        [3.5224, 3.8876, 3.9309, 3.7016, 3.5283],\n",
      "        [3.5826, 3.7750, 3.9161, 3.7246, 3.7824],\n",
      "        [3.4129, 3.7021, 3.8258, 3.5993, 3.5526],\n",
      "        [3.7434, 3.9422, 3.9627, 3.8599, 3.8307],\n",
      "        [4.1872, 4.4278, 4.1413, 4.1092, 3.8982],\n",
      "        [3.4274, 3.4810, 3.7150, 3.6067, 3.4578],\n",
      "        [3.5043, 3.6741, 3.7209, 3.6612, 3.5799],\n",
      "        [3.4348, 3.5909, 3.7828, 3.6029, 3.5295],\n",
      "        [3.9569, 3.8937, 4.0484, 4.0351, 3.9224],\n",
      "        [3.7558, 4.0340, 4.0354, 3.9987, 3.8775],\n",
      "        [3.6036, 3.8292, 3.8864, 3.7362, 3.7104],\n",
      "        [3.6246, 4.0239, 3.9782, 3.9375, 3.8530],\n",
      "        [3.5603, 3.6199, 3.8783, 3.6972, 3.6162],\n",
      "        [3.4261, 3.5400, 3.7553, 3.5972, 3.4901],\n",
      "        [3.5332, 3.6159, 3.8780, 3.7188, 3.6879],\n",
      "        [3.4449, 3.6025, 3.8167, 3.6332, 3.5124],\n",
      "        [3.5328, 3.7055, 3.7382, 3.7165, 3.5976],\n",
      "        [3.5457, 3.7210, 3.7425, 3.7390, 3.6090],\n",
      "        [3.6848, 3.7614, 3.7907, 3.8384, 3.7643],\n",
      "        [3.4088, 3.6483, 3.7999, 3.5901, 3.5186],\n",
      "        [3.4958, 3.6166, 3.8545, 3.6939, 3.6017],\n",
      "        [3.6872, 3.9683, 3.9297, 3.6770, 3.7496],\n",
      "        [3.7039, 3.7245, 4.0454, 3.9901, 3.6871],\n",
      "        [3.9856, 4.0637, 4.2011, 4.2459, 4.0145],\n",
      "        [3.3991, 3.5980, 3.6950, 3.5360, 3.5077]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5364, 3.6161, 3.8458, 3.6838, 3.6005],\n",
      "        [3.5016, 3.5906, 3.8328, 3.6424, 3.5668],\n",
      "        [3.5542, 3.9648, 3.9217, 3.7712, 3.9396],\n",
      "        [3.5956, 3.9082, 3.8212, 3.7680, 3.6515],\n",
      "        [3.7321, 3.9501, 3.9687, 3.8472, 3.8156],\n",
      "        [3.5294, 3.5725, 3.8540, 3.6716, 3.5736],\n",
      "        [3.2896, 3.5169, 3.7293, 3.4956, 3.4919],\n",
      "        [3.6215, 3.8335, 3.8891, 3.8061, 3.6895],\n",
      "        [3.6692, 3.7130, 3.8698, 3.8927, 3.7353],\n",
      "        [3.4524, 3.8276, 3.8562, 3.5302, 3.6787],\n",
      "        [3.7480, 4.0862, 4.0532, 3.8842, 4.0582],\n",
      "        [3.7009, 3.9154, 4.0087, 3.9755, 3.7591],\n",
      "        [3.9211, 3.9838, 4.0821, 4.1271, 3.9317],\n",
      "        [3.7446, 3.7249, 3.9084, 3.7215, 3.5919],\n",
      "        [3.9931, 4.1274, 4.1899, 4.2830, 4.0488],\n",
      "        [3.4930, 3.5148, 3.7284, 3.6253, 3.4783],\n",
      "        [3.5272, 3.6421, 3.9141, 3.7130, 3.6317],\n",
      "        [3.8453, 3.9736, 4.0120, 3.9547, 3.9188],\n",
      "        [3.5864, 3.6343, 3.9391, 3.7633, 3.7031],\n",
      "        [3.5913, 3.8277, 3.8563, 3.6997, 3.6757],\n",
      "        [3.5521, 3.6040, 3.8885, 3.7022, 3.6117],\n",
      "        [3.4054, 3.5839, 3.7695, 3.5826, 3.4974],\n",
      "        [3.7401, 3.8984, 4.0485, 3.8874, 3.9369],\n",
      "        [3.4962, 3.6436, 3.7434, 3.6036, 3.5469],\n",
      "        [3.8425, 3.7165, 3.9131, 3.8473, 3.8141],\n",
      "        [3.5641, 3.6739, 3.9635, 3.8475, 3.8302],\n",
      "        [3.5282, 3.7047, 3.7308, 3.7138, 3.5880],\n",
      "        [3.8296, 3.9472, 4.1080, 3.9555, 4.0369],\n",
      "        [4.0082, 4.1727, 4.0647, 3.9379, 3.8239],\n",
      "        [3.9354, 3.8574, 4.1134, 4.1012, 3.8762],\n",
      "        [3.8049, 4.0318, 4.1791, 3.9487, 3.6963],\n",
      "        [3.9475, 3.8759, 4.0516, 4.0200, 3.9063],\n",
      "        [3.5403, 3.5788, 3.8296, 3.6290, 3.5475],\n",
      "        [3.6323, 3.9462, 3.9637, 3.8420, 3.8439],\n",
      "        [3.5555, 3.7047, 3.8344, 3.6449, 3.5278],\n",
      "        [3.6328, 3.7994, 4.0440, 3.8264, 3.7531],\n",
      "        [3.6635, 3.6930, 3.9170, 3.6910, 3.6004],\n",
      "        [3.4457, 3.5033, 3.7274, 3.6289, 3.4863],\n",
      "        [3.7733, 3.8787, 4.0903, 4.0207, 3.7426],\n",
      "        [3.4125, 3.6225, 3.7988, 3.6028, 3.5265],\n",
      "        [3.5633, 4.0458, 4.0687, 3.7488, 3.6719],\n",
      "        [3.6665, 3.8032, 4.0134, 3.7646, 3.5944],\n",
      "        [3.9887, 3.8489, 4.1887, 4.4428, 4.2581],\n",
      "        [3.4744, 3.6057, 3.8318, 3.6801, 3.5956],\n",
      "        [3.5315, 3.5828, 3.7539, 3.6160, 3.6278],\n",
      "        [3.5733, 3.8120, 3.8030, 3.6970, 3.6327],\n",
      "        [3.6701, 3.7065, 3.9280, 3.7187, 3.5812],\n",
      "        [3.4166, 3.6142, 3.7014, 3.5571, 3.5167],\n",
      "        [3.4853, 3.5318, 3.7654, 3.6361, 3.4885],\n",
      "        [3.5362, 3.6341, 3.8649, 3.7114, 3.6189],\n",
      "        [3.6860, 4.0539, 4.0488, 3.9139, 3.9486],\n",
      "        [3.5667, 3.7350, 3.7497, 3.7547, 3.6121],\n",
      "        [3.8998, 3.7730, 3.9359, 3.9269, 3.8582],\n",
      "        [3.4095, 3.5669, 3.7674, 3.5876, 3.4929],\n",
      "        [3.4770, 3.6601, 3.7140, 3.6309, 3.5536],\n",
      "        [3.4548, 3.7321, 3.7032, 3.6816, 3.5113],\n",
      "        [3.7373, 4.0231, 4.0262, 3.9868, 3.8591],\n",
      "        [3.5162, 3.6966, 3.7293, 3.6774, 3.5883],\n",
      "        [3.5612, 3.8084, 3.9529, 3.7589, 3.6004],\n",
      "        [3.4082, 3.5969, 3.7795, 3.5872, 3.5021],\n",
      "        [3.7036, 3.7276, 4.0366, 3.9905, 3.6896],\n",
      "        [3.5215, 3.7608, 3.8477, 3.7466, 3.6750],\n",
      "        [3.5135, 3.6941, 3.7361, 3.6817, 3.5844],\n",
      "        [3.5271, 3.6348, 3.9861, 3.5510, 3.7630]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5424, 3.7034, 3.8109, 3.6749, 3.6248],\n",
      "        [3.6179, 3.8894, 3.9125, 3.8134, 3.8117],\n",
      "        [3.6269, 3.9248, 3.8900, 3.6290, 3.7270],\n",
      "        [3.4497, 3.9097, 3.8106, 3.6247, 3.7001],\n",
      "        [3.5608, 3.8702, 3.8170, 3.8425, 3.6909],\n",
      "        [3.4971, 3.7328, 3.9231, 3.8024, 3.5625],\n",
      "        [3.4889, 3.6619, 3.7547, 3.6515, 3.5934],\n",
      "        [3.5984, 3.6632, 3.9354, 3.7514, 3.6756],\n",
      "        [3.5952, 3.8581, 3.9439, 3.8307, 3.6521],\n",
      "        [3.6507, 3.6792, 3.9095, 3.6883, 3.5899],\n",
      "        [3.6417, 3.5178, 3.9987, 3.7717, 3.6456],\n",
      "        [3.4641, 3.6190, 3.7010, 3.6463, 3.4900],\n",
      "        [3.6557, 3.8663, 3.9123, 3.7231, 3.7500],\n",
      "        [3.6796, 3.8724, 3.9399, 3.8010, 3.8239],\n",
      "        [3.5331, 3.6336, 3.8511, 3.6937, 3.6023],\n",
      "        [3.9804, 3.9959, 4.0847, 4.1005, 4.0144],\n",
      "        [3.3604, 3.5661, 3.6744, 3.4887, 3.4730],\n",
      "        [3.6726, 3.8400, 4.0611, 3.8821, 3.7996],\n",
      "        [3.3449, 3.5470, 3.6632, 3.4722, 3.4622],\n",
      "        [3.5648, 3.7015, 3.7854, 3.7688, 3.6284],\n",
      "        [3.7117, 3.8632, 4.0755, 3.8163, 3.6188],\n",
      "        [3.7389, 3.9392, 4.0306, 3.8770, 3.7402],\n",
      "        [3.6973, 3.9027, 4.0276, 3.8911, 3.7811],\n",
      "        [3.3739, 3.4897, 3.7131, 3.5337, 3.4150],\n",
      "        [3.3978, 3.6011, 3.6938, 3.5349, 3.5040],\n",
      "        [3.4542, 3.5505, 3.6535, 3.6544, 3.4568],\n",
      "        [3.4856, 3.5730, 3.8680, 3.6699, 3.5700],\n",
      "        [3.6647, 3.6808, 4.0346, 3.8611, 3.6851],\n",
      "        [3.5803, 3.6666, 3.9365, 3.6664, 3.7739],\n",
      "        [3.5196, 3.6252, 3.8677, 3.7165, 3.6864],\n",
      "        [3.9662, 4.0446, 4.1933, 4.2435, 3.9896],\n",
      "        [3.4647, 3.8716, 4.0024, 3.7331, 3.7991],\n",
      "        [3.6296, 3.8595, 3.9245, 3.8356, 3.6870],\n",
      "        [3.6935, 3.9085, 3.9282, 3.9695, 3.7930],\n",
      "        [3.4756, 3.6579, 3.7153, 3.6267, 3.5618],\n",
      "        [3.4448, 3.6558, 3.8449, 3.6448, 3.5407],\n",
      "        [3.8306, 3.9277, 4.0834, 3.9641, 4.0454],\n",
      "        [3.5478, 3.6166, 3.8565, 3.6923, 3.6071],\n",
      "        [3.4627, 3.6997, 3.9220, 3.7245, 3.7034],\n",
      "        [3.9574, 4.1370, 4.0348, 3.8956, 3.8022],\n",
      "        [3.7006, 3.8611, 4.0669, 3.9110, 3.8545],\n",
      "        [3.4958, 3.6034, 3.8367, 3.6546, 3.5765],\n",
      "        [3.7727, 3.8802, 4.0897, 4.0204, 3.7406],\n",
      "        [3.6786, 4.0260, 4.0678, 3.8858, 3.8640],\n",
      "        [3.5410, 3.7625, 3.7789, 3.8166, 3.5666],\n",
      "        [4.0399, 4.1635, 3.9251, 3.9427, 3.7308],\n",
      "        [3.6872, 3.8119, 3.8631, 3.8491, 3.7494],\n",
      "        [3.7012, 3.7638, 3.9547, 3.7529, 3.8215],\n",
      "        [3.9347, 3.7860, 4.0851, 4.0583, 3.8585],\n",
      "        [3.5356, 3.6175, 3.8450, 3.6835, 3.5986],\n",
      "        [3.5129, 3.7077, 4.0143, 3.7422, 3.7477],\n",
      "        [3.5554, 3.6292, 3.8701, 3.6986, 3.6171],\n",
      "        [3.8324, 3.8774, 4.0541, 4.0608, 4.0285],\n",
      "        [3.7112, 3.7258, 3.8585, 3.9680, 3.7790],\n",
      "        [3.5569, 3.6359, 3.8843, 3.6665, 3.6046],\n",
      "        [3.5369, 3.5681, 3.8807, 3.5730, 3.6544],\n",
      "        [3.7862, 3.9398, 4.1153, 3.8720, 3.6706],\n",
      "        [3.6506, 3.6794, 3.8894, 3.6588, 3.4828],\n",
      "        [3.6915, 3.9061, 3.9267, 3.9681, 3.7895],\n",
      "        [3.7260, 3.8468, 3.9868, 3.8566, 3.8555],\n",
      "        [3.4987, 3.6138, 3.8576, 3.6893, 3.5979],\n",
      "        [3.3521, 3.5535, 3.6718, 3.4725, 3.4649],\n",
      "        [3.7368, 3.8479, 4.0333, 3.9024, 3.6731],\n",
      "        [3.5823, 3.6533, 3.8863, 3.7426, 3.6542]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.9208, 3.9541, 4.1546, 4.1325, 3.9085],\n",
      "        [3.3524, 3.5524, 3.6676, 3.4782, 3.4661],\n",
      "        [3.7451, 3.9228, 4.0102, 3.7574, 3.7695],\n",
      "        [3.6670, 3.7415, 3.7465, 3.8188, 3.7595],\n",
      "        [3.5048, 3.6593, 3.7524, 3.6124, 3.5533],\n",
      "        [3.6957, 3.8895, 3.9229, 3.8398, 3.7144],\n",
      "        [3.9888, 4.0848, 4.1763, 4.2291, 3.9690],\n",
      "        [3.9238, 3.9999, 4.0886, 4.1519, 3.9470],\n",
      "        [3.9556, 3.8981, 4.0462, 4.0339, 3.9165],\n",
      "        [3.8963, 3.9528, 4.1282, 4.0821, 3.8960],\n",
      "        [3.4545, 3.5210, 3.7419, 3.6277, 3.4816],\n",
      "        [3.5077, 3.5305, 3.8281, 3.6784, 3.6300],\n",
      "        [3.8263, 3.9442, 4.1402, 3.9077, 3.6817],\n",
      "        [3.9671, 4.1222, 3.9450, 3.9038, 3.7603],\n",
      "        [3.4703, 3.6630, 3.8806, 3.6653, 3.6230],\n",
      "        [3.3710, 3.5770, 3.6795, 3.5083, 3.4820],\n",
      "        [3.6867, 3.9447, 4.0318, 3.8905, 3.8438],\n",
      "        [3.4532, 3.6421, 3.7086, 3.6045, 3.5340],\n",
      "        [3.6864, 3.8131, 3.8622, 3.8486, 3.7473],\n",
      "        [3.7197, 3.9403, 4.0223, 3.8741, 3.7357],\n",
      "        [3.5493, 3.6754, 3.8862, 3.7355, 3.6352],\n",
      "        [3.6129, 3.6067, 3.8533, 3.7339, 3.5719],\n",
      "        [3.7620, 3.9624, 4.1005, 3.8591, 3.5766],\n",
      "        [3.5304, 3.7096, 3.7363, 3.7148, 3.5917],\n",
      "        [3.6287, 3.8607, 3.9240, 3.8350, 3.6849],\n",
      "        [3.5493, 3.7759, 3.9059, 3.7263, 3.6498],\n",
      "        [3.7561, 3.6151, 3.9285, 4.0094, 3.9298],\n",
      "        [3.6685, 3.7089, 3.9260, 3.7179, 3.5771],\n",
      "        [3.8663, 3.7447, 3.9542, 4.2060, 3.9523],\n",
      "        [3.6775, 3.7015, 3.9075, 3.6583, 3.5069],\n",
      "        [3.5538, 3.7069, 3.7809, 3.7101, 3.6361],\n",
      "        [3.5429, 3.7276, 3.7461, 3.7253, 3.6089],\n",
      "        [3.5352, 3.6486, 3.8608, 3.7066, 3.6067],\n",
      "        [3.5411, 3.6509, 3.8652, 3.7042, 3.6083],\n",
      "        [3.6933, 4.0771, 4.0835, 3.9224, 3.9012],\n",
      "        [3.5507, 3.6660, 3.9767, 3.8172, 3.6831],\n",
      "        [3.9625, 3.9705, 4.0274, 4.0714, 4.0130],\n",
      "        [3.8544, 3.8931, 4.0756, 4.0327, 3.8396],\n",
      "        [3.5356, 3.7166, 3.7360, 3.7166, 3.5968],\n",
      "        [3.5957, 3.8360, 3.8531, 3.7135, 3.6634],\n",
      "        [3.6027, 3.6837, 3.9550, 3.7671, 3.6905],\n",
      "        [3.5628, 3.8047, 3.9698, 3.7628, 3.5897],\n",
      "        [3.5069, 3.8691, 3.9953, 3.6933, 3.8603],\n",
      "        [3.5437, 3.6383, 3.8613, 3.7068, 3.6048],\n",
      "        [3.5293, 3.6116, 3.7935, 3.7302, 3.5336],\n",
      "        [4.0386, 4.2077, 4.0811, 3.9704, 3.8379],\n",
      "        [3.6993, 3.9180, 4.0070, 3.9747, 3.7550],\n",
      "        [3.8065, 4.0484, 4.0009, 3.9772, 4.0448],\n",
      "        [3.6659, 3.8798, 3.8948, 3.9284, 3.7434],\n",
      "        [3.6925, 3.9096, 3.9272, 3.9689, 3.7908],\n",
      "        [3.7071, 3.7864, 3.7919, 3.8581, 3.8001],\n",
      "        [3.3595, 3.5671, 3.6734, 3.4882, 3.4709],\n",
      "        [3.5237, 3.6275, 3.9696, 3.5515, 3.7484],\n",
      "        [3.4193, 3.5531, 3.7199, 3.5797, 3.5028],\n",
      "        [3.5244, 3.7026, 3.7389, 3.6968, 3.5961],\n",
      "        [3.4670, 3.6803, 3.7375, 3.6243, 3.5923],\n",
      "        [3.5393, 3.8525, 3.9372, 3.6326, 3.7129],\n",
      "        [3.6611, 3.8982, 3.9358, 3.7451, 3.7436],\n",
      "        [3.5300, 3.7517, 3.7678, 3.8112, 3.5516],\n",
      "        [3.7448, 4.0884, 4.0847, 4.0538, 3.9428],\n",
      "        [3.5483, 3.6034, 3.7699, 3.7590, 3.5344],\n",
      "        [3.4371, 3.5124, 3.7337, 3.6176, 3.4705],\n",
      "        [3.6400, 3.9696, 3.9831, 3.8592, 3.8523],\n",
      "        [3.7425, 3.5695, 3.7772, 3.7114, 3.7089]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8244, 3.9119, 4.1312, 3.9776, 3.9832],\n",
      "        [3.7148, 3.9534, 3.9613, 3.8441, 3.7946],\n",
      "        [3.4618, 3.4722, 3.8264, 3.4429, 3.6075],\n",
      "        [3.9855, 3.8530, 4.1855, 4.4427, 4.2521],\n",
      "        [3.4857, 3.5033, 3.7064, 3.6222, 3.4557],\n",
      "        [4.0381, 4.1664, 3.9227, 3.9423, 3.7268],\n",
      "        [3.6746, 3.8730, 3.9379, 3.7944, 3.8198],\n",
      "        [3.8695, 3.9356, 3.9784, 3.9699, 3.9315],\n",
      "        [3.6719, 3.8781, 3.9369, 3.7962, 3.8251],\n",
      "        [3.5827, 3.6926, 3.8827, 3.6355, 3.4549],\n",
      "        [3.9167, 3.9517, 4.1525, 4.1310, 3.8994],\n",
      "        [3.7346, 4.0238, 3.9651, 3.9002, 3.9679],\n",
      "        [3.5446, 3.6258, 3.8602, 3.6940, 3.6034],\n",
      "        [3.4624, 3.6363, 3.8432, 3.6625, 3.5102],\n",
      "        [3.5342, 3.8489, 3.9314, 3.6496, 3.6870],\n",
      "        [3.5679, 3.6476, 3.9322, 3.7326, 3.6657],\n",
      "        [3.5542, 3.8697, 3.8098, 3.8413, 3.6871],\n",
      "        [3.6982, 3.8637, 4.0641, 3.9105, 3.8501],\n",
      "        [3.5609, 3.6098, 3.8821, 3.6443, 3.6483],\n",
      "        [3.7556, 3.8799, 4.0734, 3.9388, 3.9473],\n",
      "        [3.4194, 3.5711, 3.7686, 3.6017, 3.5034],\n",
      "        [3.5523, 3.7081, 3.7797, 3.7101, 3.6341],\n",
      "        [3.6909, 3.9109, 3.9260, 3.9688, 3.7886],\n",
      "        [3.7281, 3.7765, 4.0339, 3.9779, 3.6414],\n",
      "        [3.5929, 3.6334, 3.9073, 3.7219, 3.6620],\n",
      "        [3.9839, 3.9231, 4.1751, 4.1643, 3.9299],\n",
      "        [3.6319, 3.6443, 4.1153, 3.8097, 3.7575],\n",
      "        [3.8036, 4.0141, 4.1124, 3.9981, 3.9051],\n",
      "        [3.6578, 4.0576, 3.9903, 3.9745, 3.8563],\n",
      "        [3.7748, 3.8635, 4.0529, 3.8088, 3.5657],\n",
      "        [3.4369, 3.5715, 3.7775, 3.6190, 3.5122],\n",
      "        [3.7479, 3.9031, 4.0424, 3.8432, 3.6238],\n",
      "        [3.5510, 3.8361, 3.8530, 3.6741, 3.6673],\n",
      "        [3.8463, 3.9471, 4.0952, 3.9778, 4.0503],\n",
      "        [3.7091, 3.7336, 3.8657, 3.9790, 3.7892],\n",
      "        [3.5410, 3.7934, 3.9134, 3.7377, 3.6321],\n",
      "        [3.5455, 3.7738, 3.8980, 3.7198, 3.6905],\n",
      "        [3.6014, 3.7538, 3.9003, 3.8059, 3.7304],\n",
      "        [3.9949, 4.1365, 4.1191, 4.1557, 4.1566],\n",
      "        [3.9150, 4.0484, 4.0942, 4.0054, 3.9973],\n",
      "        [3.3722, 3.5629, 3.6149, 3.5228, 3.4269],\n",
      "        [3.5311, 3.9488, 3.9394, 3.8292, 3.8189],\n",
      "        [3.6668, 3.7788, 3.8470, 3.7666, 3.6519],\n",
      "        [3.4903, 3.6130, 3.8103, 3.6860, 3.5229],\n",
      "        [3.3706, 3.7316, 3.9537, 3.5915, 3.6263],\n",
      "        [3.5842, 3.6517, 3.9201, 3.7520, 3.6717],\n",
      "        [3.5715, 3.6301, 3.8091, 3.6695, 3.6601],\n",
      "        [3.6975, 3.7498, 3.9368, 3.7573, 3.5617],\n",
      "        [3.4793, 3.6966, 3.7605, 3.6463, 3.6018],\n",
      "        [3.6587, 3.9927, 3.9728, 3.8656, 3.7693],\n",
      "        [3.5608, 3.5742, 3.8361, 3.7066, 3.7028],\n",
      "        [3.7073, 3.8801, 4.0076, 3.9622, 3.7239],\n",
      "        [3.5499, 3.6688, 3.8749, 3.7337, 3.6192],\n",
      "        [3.5451, 3.6768, 3.8139, 3.7629, 3.6382],\n",
      "        [3.7319, 3.8530, 4.0415, 3.9268, 3.9151],\n",
      "        [3.6831, 3.7094, 3.9534, 3.8211, 3.6658],\n",
      "        [3.4357, 3.5197, 3.7383, 3.6105, 3.4734],\n",
      "        [3.6788, 3.9085, 3.9699, 3.9446, 3.7476],\n",
      "        [3.4134, 3.8250, 3.8431, 3.5262, 3.6837],\n",
      "        [3.6456, 3.7383, 3.8824, 3.7552, 3.6575],\n",
      "        [3.4922, 3.6175, 3.8348, 3.6661, 3.5929],\n",
      "        [4.0308, 4.1572, 3.9179, 3.9257, 3.7306],\n",
      "        [3.5362, 3.7698, 3.8897, 3.7132, 3.6709],\n",
      "        [4.0445, 4.1268, 4.2110, 4.3166, 3.9007]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[4.1003, 4.2787, 4.1498, 4.0312, 3.8998],\n",
      "        [3.9253, 4.0037, 4.1262, 4.1807, 3.8148],\n",
      "        [3.5202, 3.6310, 3.9540, 3.5667, 3.7416],\n",
      "        [3.7077, 3.9060, 4.0360, 3.8079, 3.6275],\n",
      "        [3.6128, 3.5214, 3.9741, 3.7871, 3.7029],\n",
      "        [3.7228, 3.8245, 4.1778, 3.7676, 3.6154],\n",
      "        [3.6685, 3.7789, 3.9829, 3.8007, 3.7021],\n",
      "        [3.5289, 3.6142, 3.8433, 3.6834, 3.5891],\n",
      "        [3.3498, 3.5591, 3.6663, 3.4790, 3.4666],\n",
      "        [3.4979, 3.7307, 3.9284, 3.7514, 3.5526],\n",
      "        [3.6469, 3.6374, 3.8479, 3.7030, 3.6789],\n",
      "        [3.8136, 3.9025, 4.1373, 4.0609, 3.7617],\n",
      "        [3.5223, 3.6457, 3.8567, 3.7101, 3.5998],\n",
      "        [3.7431, 4.0916, 4.0484, 3.8845, 4.0494],\n",
      "        [3.9698, 3.9102, 4.0462, 4.0432, 3.9384],\n",
      "        [3.3681, 3.5792, 3.6768, 3.5094, 3.4780],\n",
      "        [3.8089, 3.9747, 4.1496, 4.1204, 4.1166],\n",
      "        [3.3816, 3.6568, 3.9352, 3.6019, 3.6726],\n",
      "        [3.7254, 3.8830, 4.0309, 3.9828, 3.7239],\n",
      "        [3.5718, 3.7514, 3.9041, 3.8463, 3.6514],\n",
      "        [3.7872, 3.6805, 3.8854, 3.8015, 3.7468],\n",
      "        [3.5362, 3.7658, 3.8767, 3.7714, 3.6648],\n",
      "        [3.8377, 3.8914, 4.0684, 4.0262, 3.8140],\n",
      "        [3.4071, 3.5856, 3.7684, 3.5890, 3.4908],\n",
      "        [3.5747, 3.6421, 3.8787, 3.7370, 3.6701],\n",
      "        [3.3935, 3.7186, 3.9362, 3.6242, 3.6110],\n",
      "        [3.5461, 3.8122, 3.9548, 3.7615, 3.5947],\n",
      "        [3.5254, 3.7048, 3.7280, 3.7001, 3.5902],\n",
      "        [3.8236, 3.8516, 3.8768, 3.8902, 3.8480],\n",
      "        [3.5513, 3.6806, 3.8794, 3.7392, 3.6362],\n",
      "        [3.4475, 3.6304, 3.6818, 3.6267, 3.4783],\n",
      "        [3.6803, 3.8635, 3.9890, 3.8221, 3.6030],\n",
      "        [3.8320, 3.9753, 4.0496, 3.9278, 3.8730],\n",
      "        [3.6072, 3.7499, 3.8875, 3.7364, 3.7506],\n",
      "        [3.7816, 3.8795, 4.0835, 3.9332, 3.9475],\n",
      "        [3.6536, 3.8569, 3.8886, 3.8227, 3.7384],\n",
      "        [3.6898, 3.9102, 3.9252, 3.9652, 3.7852],\n",
      "        [3.4271, 3.6117, 3.7834, 3.6065, 3.5302],\n",
      "        [3.6564, 3.7289, 3.8827, 3.7681, 3.6313],\n",
      "        [3.6762, 3.9855, 4.0522, 3.8858, 3.9089],\n",
      "        [3.5304, 3.7391, 3.9154, 3.9001, 3.5682],\n",
      "        [3.3908, 3.6042, 3.6935, 3.5408, 3.5003],\n",
      "        [3.4478, 3.8960, 3.7890, 3.6323, 3.6928],\n",
      "        [3.7470, 3.8093, 4.0771, 3.8653, 3.5950],\n",
      "        [3.3681, 3.5792, 3.6768, 3.5094, 3.4780],\n",
      "        [3.5996, 3.6860, 3.9522, 3.7683, 3.6863],\n",
      "        [3.4704, 3.6508, 3.7502, 3.6370, 3.5619],\n",
      "        [3.5453, 3.6056, 3.7672, 3.7602, 3.5303],\n",
      "        [3.5528, 3.7426, 3.7404, 3.7528, 3.6121],\n",
      "        [3.7098, 3.9424, 3.9574, 3.8773, 3.7627],\n",
      "        [3.6680, 3.7556, 3.9161, 3.8144, 3.7614],\n",
      "        [3.6892, 3.9118, 3.9246, 3.9700, 3.7865],\n",
      "        [3.5420, 3.5973, 3.8658, 3.6771, 3.5924],\n",
      "        [3.5621, 3.7087, 3.8365, 3.6582, 3.5286],\n",
      "        [3.7991, 3.8639, 4.1036, 4.1086, 3.7807],\n",
      "        [3.5487, 3.6278, 3.8651, 3.6969, 3.6029],\n",
      "        [3.5397, 3.7297, 3.7435, 3.7264, 3.6048],\n",
      "        [3.3762, 3.7306, 3.9517, 3.5883, 3.6296],\n",
      "        [3.7403, 3.8146, 4.0240, 3.9052, 3.6154],\n",
      "        [3.4396, 3.6088, 3.8115, 3.6326, 3.5022],\n",
      "        [3.6359, 3.9904, 3.9928, 3.8605, 3.8447],\n",
      "        [3.4885, 3.7436, 3.9219, 3.8085, 3.5479],\n",
      "        [3.4930, 3.7365, 3.9211, 3.8032, 3.5564],\n",
      "        [3.5865, 3.8329, 3.8528, 3.7001, 3.6673]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.9235, 4.0044, 4.1250, 4.1818, 3.8125],\n",
      "        [3.9260, 3.9549, 4.1104, 4.1099, 3.9237],\n",
      "        [3.4299, 3.6306, 3.8150, 3.6370, 3.5073],\n",
      "        [3.5073, 3.6400, 3.7843, 3.6197, 3.5820],\n",
      "        [3.8789, 3.7863, 4.0461, 4.0343, 3.7972],\n",
      "        [3.4102, 3.8266, 3.8398, 3.5282, 3.6793],\n",
      "        [3.5250, 3.7006, 3.8657, 3.7428, 3.6727],\n",
      "        [3.7065, 3.8331, 4.0388, 3.8004, 3.5468],\n",
      "        [3.6875, 3.9124, 3.9228, 3.9709, 3.7842],\n",
      "        [3.7821, 3.8582, 4.0338, 3.9461, 3.6886],\n",
      "        [3.7202, 3.9995, 4.1231, 3.9147, 3.6578],\n",
      "        [4.2439, 4.4383, 4.2280, 4.1608, 3.9238],\n",
      "        [3.6049, 3.6861, 3.8738, 3.7760, 3.6434],\n",
      "        [3.6561, 3.8474, 3.9575, 3.8154, 3.8313],\n",
      "        [3.9079, 3.7699, 3.9787, 4.2834, 4.0155],\n",
      "        [3.5503, 3.5624, 3.7902, 3.6769, 3.6879],\n",
      "        [3.7051, 3.9183, 3.9880, 3.8943, 3.7411],\n",
      "        [3.6572, 3.6983, 3.9102, 3.6922, 3.5898],\n",
      "        [3.3551, 3.5699, 3.6689, 3.4900, 3.4648],\n",
      "        [3.4392, 3.6596, 3.8391, 3.6462, 3.5322],\n",
      "        [3.5554, 3.5639, 3.8053, 3.6916, 3.6942],\n",
      "        [3.3545, 3.5641, 3.6692, 3.4881, 3.4619],\n",
      "        [3.5652, 3.7640, 3.8941, 3.7170, 3.7408],\n",
      "        [3.6057, 3.7505, 3.8858, 3.7372, 3.7483],\n",
      "        [3.4441, 3.6364, 3.6841, 3.6603, 3.5212],\n",
      "        [3.4898, 3.6073, 3.8309, 3.6560, 3.5678],\n",
      "        [3.5235, 3.5746, 3.8489, 3.6712, 3.5622],\n",
      "        [3.7052, 3.8617, 3.9195, 3.7190, 3.6957],\n",
      "        [3.5410, 3.7426, 3.9282, 3.9014, 3.5824],\n",
      "        [3.4852, 4.0271, 3.8846, 3.6906, 3.7745],\n",
      "        [3.7202, 4.0086, 3.9438, 3.8869, 3.9472],\n",
      "        [3.7831, 3.6174, 3.9314, 4.0603, 3.9444],\n",
      "        [3.7035, 3.8649, 3.9234, 3.7403, 3.6964],\n",
      "        [3.3652, 3.4844, 3.7024, 3.5237, 3.4069],\n",
      "        [3.7837, 3.6926, 3.9155, 4.1239, 3.8700],\n",
      "        [3.4596, 3.5998, 3.8035, 3.6686, 3.4936],\n",
      "        [3.6975, 3.9135, 3.9416, 3.8684, 3.7461],\n",
      "        [4.0067, 4.1653, 4.0427, 3.9357, 3.7839],\n",
      "        [3.6398, 4.1446, 4.0435, 3.9050, 3.9433],\n",
      "        [3.5988, 3.4926, 3.9542, 3.7479, 3.6174],\n",
      "        [3.4710, 3.6153, 3.7847, 3.6009, 3.5430],\n",
      "        [3.7453, 3.8257, 4.0493, 3.8858, 3.6246],\n",
      "        [3.4019, 3.6021, 3.7730, 3.5882, 3.4917],\n",
      "        [3.8501, 3.8962, 4.0713, 4.0353, 3.8332],\n",
      "        [3.7405, 3.9258, 4.0058, 3.7594, 3.7629],\n",
      "        [3.7896, 3.9655, 4.1367, 4.0904, 4.1037],\n",
      "        [3.3690, 3.6067, 3.7118, 3.5757, 3.4893],\n",
      "        [3.5419, 3.6783, 3.8107, 3.7650, 3.6339],\n",
      "        [3.5511, 3.7432, 3.7387, 3.7536, 3.6099],\n",
      "        [3.3319, 3.5353, 3.6462, 3.4687, 3.4450],\n",
      "        [3.4337, 3.5730, 3.7743, 3.6209, 3.5079],\n",
      "        [3.8931, 3.7971, 4.0593, 3.9911, 3.8225],\n",
      "        [3.7953, 4.0171, 4.1023, 3.9906, 3.8917],\n",
      "        [3.5661, 3.7158, 3.6996, 3.7488, 3.5175],\n",
      "        [3.7855, 4.0875, 4.0585, 4.0173, 3.9490],\n",
      "        [3.7054, 3.9686, 3.9401, 3.8037, 3.7463],\n",
      "        [3.2320, 3.4878, 3.6998, 3.4588, 3.4337],\n",
      "        [3.6574, 3.6453, 4.0924, 3.8359, 3.7609],\n",
      "        [3.5377, 3.7951, 3.9105, 3.7400, 3.6277],\n",
      "        [3.5083, 3.6084, 3.7880, 3.7220, 3.5312],\n",
      "        [3.7196, 3.8684, 4.0294, 3.9054, 3.6927],\n",
      "        [3.3805, 3.5491, 3.6255, 3.6091, 3.4283],\n",
      "        [3.6454, 3.6380, 3.8461, 3.7037, 3.6767],\n",
      "        [3.4446, 3.6269, 3.8453, 3.7163, 3.5927]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8338, 4.0325, 3.9194, 3.8372, 3.7379],\n",
      "        [3.4719, 3.6135, 3.8105, 3.6742, 3.5062],\n",
      "        [3.7388, 3.8861, 4.0478, 3.9996, 3.7225],\n",
      "        [3.7790, 4.0135, 4.1259, 3.9049, 3.6407],\n",
      "        [3.4330, 3.6405, 3.7042, 3.5867, 3.5279],\n",
      "        [3.5385, 3.6513, 3.8551, 3.7114, 3.6022],\n",
      "        [3.5795, 3.6454, 3.8834, 3.7181, 3.6553],\n",
      "        [3.5127, 3.7170, 3.7294, 3.7001, 3.5830],\n",
      "        [3.5494, 3.8723, 3.8048, 3.8436, 3.6806],\n",
      "        [3.9308, 3.8616, 4.1061, 4.0987, 3.8664],\n",
      "        [3.7955, 3.8659, 4.1012, 4.1103, 3.7761],\n",
      "        [3.4774, 3.8889, 3.8947, 3.6527, 3.5053],\n",
      "        [3.4399, 3.6466, 3.8508, 3.6629, 3.4988],\n",
      "        [3.5911, 3.6683, 3.9278, 3.7535, 3.6648],\n",
      "        [3.6024, 3.6111, 3.8592, 3.7286, 3.5703],\n",
      "        [3.3945, 3.6619, 3.7896, 3.5879, 3.5062],\n",
      "        [3.6425, 3.7319, 3.8734, 3.7614, 3.6291],\n",
      "        [3.4445, 3.6863, 3.7016, 3.6751, 3.5332],\n",
      "        [3.5239, 3.7133, 3.7303, 3.7170, 3.5833],\n",
      "        [3.8376, 3.8714, 4.1361, 4.1061, 3.7594],\n",
      "        [3.6093, 3.6303, 4.0984, 3.7909, 3.7233],\n",
      "        [3.7571, 4.0519, 4.0506, 4.0239, 3.8690],\n",
      "        [3.5419, 3.5889, 3.8761, 3.6118, 3.6399],\n",
      "        [3.7865, 4.0239, 4.1317, 3.9140, 3.6471],\n",
      "        [3.5219, 3.5756, 3.8471, 3.6716, 3.5601],\n",
      "        [3.6536, 3.8662, 3.9626, 3.7933, 3.5801],\n",
      "        [3.6135, 3.7048, 3.9772, 3.7922, 3.6920],\n",
      "        [3.3512, 3.5678, 3.5775, 3.5859, 3.4275],\n",
      "        [3.9597, 3.8374, 4.1116, 4.4147, 4.1583],\n",
      "        [3.5259, 3.6250, 3.8360, 3.6873, 3.5870],\n",
      "        [3.9141, 3.9906, 4.0739, 4.1291, 3.9188],\n",
      "        [3.5432, 3.7286, 3.7264, 3.7354, 3.5861],\n",
      "        [3.5555, 3.7468, 3.7544, 3.7573, 3.6152],\n",
      "        [3.6746, 4.0272, 4.0598, 3.8923, 3.8589],\n",
      "        [3.5211, 3.7033, 3.7264, 3.6864, 3.5892],\n",
      "        [3.5559, 3.8093, 3.9428, 3.7604, 3.5990],\n",
      "        [3.6227, 3.7016, 3.9763, 3.8023, 3.6982],\n",
      "        [3.7290, 3.9770, 3.9315, 3.8085, 3.7394],\n",
      "        [3.5296, 3.7066, 3.9008, 3.7468, 3.6807],\n",
      "        [3.5501, 3.8204, 3.8795, 3.6791, 3.6786],\n",
      "        [3.8343, 4.0936, 4.0379, 4.0273, 4.0153],\n",
      "        [3.4138, 3.6440, 3.8231, 3.6181, 3.5197],\n",
      "        [3.5363, 3.6103, 3.8569, 3.6908, 3.5809],\n",
      "        [3.5972, 3.8878, 3.9739, 3.8516, 3.6428],\n",
      "        [3.4087, 3.7478, 3.9686, 3.6831, 3.6487],\n",
      "        [3.4855, 3.6155, 3.8052, 3.6883, 3.5164],\n",
      "        [3.5610, 3.7070, 3.8770, 3.8595, 3.6563],\n",
      "        [3.5684, 3.7214, 3.8282, 3.6755, 3.6260],\n",
      "        [4.0022, 4.2437, 3.9544, 3.9249, 3.7255],\n",
      "        [3.7195, 3.7861, 4.0553, 3.8190, 3.5415],\n",
      "        [3.5912, 3.5817, 3.9321, 3.8907, 3.5539],\n",
      "        [3.3947, 3.6936, 3.8015, 3.5912, 3.5215],\n",
      "        [3.4320, 3.5740, 3.7725, 3.6213, 3.5057],\n",
      "        [3.4835, 3.6176, 3.7860, 3.6046, 3.5634],\n",
      "        [3.5277, 3.6933, 3.8563, 3.7274, 3.6901],\n",
      "        [3.3874, 3.5954, 3.6862, 3.5351, 3.5052],\n",
      "        [3.5671, 3.6325, 3.8037, 3.6715, 3.6535],\n",
      "        [3.8020, 3.8512, 4.1232, 4.0812, 3.7068],\n",
      "        [3.4323, 3.5033, 3.7211, 3.6224, 3.4514],\n",
      "        [3.5387, 3.5989, 3.8623, 3.6784, 3.5881],\n",
      "        [3.3726, 3.7323, 3.9479, 3.5896, 3.6249],\n",
      "        [3.5416, 3.6160, 3.8772, 3.6918, 3.5915],\n",
      "        [3.7731, 3.9557, 3.9715, 3.8837, 3.8715],\n",
      "        [3.3908, 3.6059, 3.6865, 3.5366, 3.4936]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6932, 3.7732, 3.9149, 3.7639, 3.4938],\n",
      "        [3.5524, 3.7455, 3.7499, 3.7583, 3.6077],\n",
      "        [3.9215, 3.9554, 4.1318, 4.1281, 3.8971],\n",
      "        [3.6799, 3.8699, 4.0382, 3.8721, 3.7341],\n",
      "        [3.5261, 3.6388, 3.8424, 3.6961, 3.5893],\n",
      "        [3.4502, 3.5782, 3.6493, 3.6621, 3.4796],\n",
      "        [3.5694, 3.8247, 3.8862, 3.7063, 3.6885],\n",
      "        [3.6806, 3.8619, 4.0214, 3.8249, 3.7142],\n",
      "        [3.7039, 3.9198, 3.9849, 3.8954, 3.7366],\n",
      "        [3.5343, 3.6271, 3.8447, 3.6890, 3.5910],\n",
      "        [3.4689, 3.6630, 3.7070, 3.6290, 3.5493],\n",
      "        [3.4344, 3.5297, 3.7368, 3.6142, 3.4682],\n",
      "        [3.8746, 4.0269, 4.0609, 3.9826, 3.9496],\n",
      "        [3.5059, 3.7133, 4.0050, 3.7451, 3.7346],\n",
      "        [3.4374, 3.5749, 3.6715, 3.6579, 3.4201],\n",
      "        [3.6136, 4.0031, 3.9364, 3.9143, 3.7947],\n",
      "        [3.6698, 3.7897, 4.0073, 3.7876, 3.5696],\n",
      "        [3.4862, 3.6323, 3.7496, 3.6445, 3.6276],\n",
      "        [3.5586, 3.6624, 3.9346, 3.6437, 3.7601],\n",
      "        [3.6322, 3.7493, 3.9591, 3.7898, 3.6735],\n",
      "        [3.6107, 3.6963, 3.9574, 3.8091, 3.6255],\n",
      "        [3.4255, 3.5454, 3.7467, 3.6150, 3.4777],\n",
      "        [3.3994, 3.5287, 3.6976, 3.5567, 3.4718],\n",
      "        [3.5063, 3.6283, 3.8074, 3.7122, 3.5346],\n",
      "        [3.4988, 3.6936, 3.7212, 3.6702, 3.5667],\n",
      "        [3.4025, 3.7285, 3.6592, 3.6665, 3.4715],\n",
      "        [3.7663, 3.8857, 4.0812, 4.0233, 3.7274],\n",
      "        [3.7864, 3.8588, 4.0280, 3.9219, 3.8865],\n",
      "        [3.4768, 3.5069, 3.7912, 3.6464, 3.5993],\n",
      "        [3.3907, 3.6424, 3.7822, 3.5892, 3.4919],\n",
      "        [3.5509, 3.8114, 3.9323, 3.7567, 3.5970],\n",
      "        [3.6887, 3.9620, 4.0300, 3.8938, 3.8583],\n",
      "        [3.5242, 3.7105, 3.7228, 3.7204, 3.5828],\n",
      "        [3.4150, 3.5740, 3.7622, 3.6046, 3.4949],\n",
      "        [3.4710, 3.9208, 3.9110, 3.7670, 3.7970],\n",
      "        [3.8417, 3.8930, 4.0639, 4.0342, 3.8192],\n",
      "        [3.4176, 3.6282, 3.6989, 3.5673, 3.5180],\n",
      "        [3.4338, 3.7203, 3.8821, 3.7787, 3.4953],\n",
      "        [3.9184, 4.1430, 4.0614, 3.8954, 3.8299],\n",
      "        [3.3003, 3.5416, 3.7268, 3.5178, 3.4926],\n",
      "        [3.8723, 3.9261, 4.0925, 4.0612, 3.7553],\n",
      "        [3.7560, 3.6280, 3.9317, 4.0161, 3.9201],\n",
      "        [3.6331, 3.7772, 3.9157, 3.7611, 3.7761],\n",
      "        [3.3878, 3.5958, 3.6849, 3.5357, 3.5031],\n",
      "        [3.6718, 4.0323, 4.0591, 3.8883, 3.8507],\n",
      "        [3.5540, 3.5546, 3.7975, 3.5897, 3.5007],\n",
      "        [3.4578, 3.6179, 3.8150, 3.7018, 3.5619],\n",
      "        [3.4531, 3.6209, 3.8155, 3.7099, 3.5637],\n",
      "        [3.6071, 3.6917, 3.9575, 3.7930, 3.6879],\n",
      "        [3.3338, 3.5459, 3.6449, 3.4695, 3.4373],\n",
      "        [3.6776, 3.8656, 3.9843, 3.8240, 3.5963],\n",
      "        [3.5376, 3.6495, 3.9532, 3.6060, 3.7407],\n",
      "        [3.3538, 3.5539, 3.5962, 3.5085, 3.4061],\n",
      "        [3.5182, 3.7521, 3.9870, 3.6892, 3.6290],\n",
      "        [3.6050, 3.7387, 3.8605, 3.7297, 3.6425],\n",
      "        [3.6368, 3.9180, 3.9134, 3.9214, 3.7320],\n",
      "        [3.7399, 3.9157, 3.9134, 3.9147, 3.8286],\n",
      "        [3.5365, 3.6106, 3.8512, 3.6875, 3.5799],\n",
      "        [3.6513, 3.7798, 3.9552, 3.7772, 3.6923],\n",
      "        [3.5329, 3.7188, 3.7322, 3.7271, 3.5923],\n",
      "        [3.8476, 3.8006, 4.0315, 3.9871, 3.7910],\n",
      "        [3.7231, 3.7584, 3.9896, 3.9320, 3.6417],\n",
      "        [3.5201, 3.7049, 3.7150, 3.7088, 3.5637],\n",
      "        [3.5066, 3.9650, 3.8282, 3.6795, 3.7594]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5652, 4.0167, 4.0714, 3.8064, 3.6647],\n",
      "        [3.6565, 3.6467, 4.0882, 3.8374, 3.7551],\n",
      "        [3.4142, 3.7216, 3.8210, 3.6214, 3.5552],\n",
      "        [3.6008, 3.7020, 3.8760, 3.7084, 3.8207],\n",
      "        [3.5297, 3.6937, 3.7531, 3.6946, 3.6027],\n",
      "        [3.6875, 3.8489, 3.8987, 3.7053, 3.6761],\n",
      "        [3.5301, 3.6273, 3.8366, 3.6901, 3.5859],\n",
      "        [3.4477, 3.5558, 3.6445, 3.6573, 3.4433],\n",
      "        [3.4247, 3.6332, 3.6962, 3.5848, 3.5110],\n",
      "        [3.5191, 3.7580, 3.8782, 3.7843, 3.6534],\n",
      "        [3.7647, 3.6680, 3.8840, 3.7904, 3.7042],\n",
      "        [3.9088, 3.9508, 4.1376, 4.1224, 3.8859],\n",
      "        [3.7287, 3.8523, 4.0255, 3.9055, 3.6583],\n",
      "        [3.5303, 3.7897, 3.8810, 3.7281, 3.6264],\n",
      "        [3.9776, 4.2194, 3.9218, 3.8826, 3.7401],\n",
      "        [3.7439, 3.7845, 4.0544, 4.0070, 3.6389],\n",
      "        [3.7796, 3.7065, 3.9076, 4.1071, 3.8602],\n",
      "        [3.6843, 3.9108, 3.9128, 3.9626, 3.7668],\n",
      "        [3.5947, 3.7677, 3.9060, 3.8420, 3.6881],\n",
      "        [3.5316, 3.6808, 3.8034, 3.6878, 3.6657],\n",
      "        [3.4015, 3.7297, 3.6550, 3.6687, 3.4717],\n",
      "        [3.4691, 3.6631, 3.7061, 3.6293, 3.5481],\n",
      "        [3.5371, 3.7318, 3.7380, 3.7284, 3.5972],\n",
      "        [3.5061, 3.7007, 3.7264, 3.6839, 3.5687],\n",
      "        [3.6354, 3.9473, 4.0209, 3.8116, 3.7630],\n",
      "        [3.4161, 3.5656, 3.7542, 3.5955, 3.4806],\n",
      "        [3.5580, 3.7070, 3.7760, 3.7719, 3.6143],\n",
      "        [3.8066, 3.9771, 4.1436, 4.1232, 4.1085],\n",
      "        [3.6865, 3.9140, 3.9188, 3.9722, 3.7784],\n",
      "        [3.5893, 3.9803, 4.0435, 3.8805, 3.8648],\n",
      "        [3.7187, 3.6885, 3.8615, 4.0465, 3.7912],\n",
      "        [3.6562, 3.6865, 3.8826, 3.6748, 3.4803],\n",
      "        [3.5788, 3.6575, 3.8872, 3.7508, 3.6419],\n",
      "        [3.7050, 3.8847, 3.9240, 3.8000, 3.7038],\n",
      "        [3.5508, 3.5612, 3.7982, 3.6866, 3.6859],\n",
      "        [3.6865, 3.9140, 3.9188, 3.9722, 3.7784],\n",
      "        [4.0616, 4.3303, 4.0206, 4.0076, 3.7907],\n",
      "        [3.6881, 3.8956, 3.9357, 3.8242, 3.8065],\n",
      "        [3.6049, 3.7520, 3.8819, 3.7386, 3.7426],\n",
      "        [3.4780, 3.5384, 3.7551, 3.6385, 3.4727],\n",
      "        [3.6744, 3.9925, 3.9096, 3.8544, 3.9007],\n",
      "        [3.7382, 3.5735, 3.7688, 3.7150, 3.6979],\n",
      "        [3.8876, 3.9469, 4.1351, 4.1424, 3.9110],\n",
      "        [3.7243, 3.9007, 4.0198, 3.8292, 3.6016],\n",
      "        [3.5468, 3.8393, 3.8463, 3.6780, 3.6571],\n",
      "        [3.6212, 3.6363, 4.1018, 3.8087, 3.7352],\n",
      "        [3.6938, 3.8671, 4.0560, 3.9143, 3.8397],\n",
      "        [3.4991, 3.8997, 3.9556, 3.7951, 3.7562],\n",
      "        [3.4842, 4.0286, 3.8804, 3.6923, 3.7687],\n",
      "        [3.5222, 3.5793, 3.8439, 3.6745, 3.5581],\n",
      "        [3.5226, 3.5761, 3.8449, 3.6727, 3.5569],\n",
      "        [3.6788, 3.7126, 3.9460, 3.8247, 3.6559],\n",
      "        [3.4452, 3.5514, 3.6386, 3.6547, 3.4219],\n",
      "        [3.6626, 4.0015, 3.9722, 3.8568, 3.7661],\n",
      "        [3.6334, 3.7773, 3.9147, 3.7615, 3.7749],\n",
      "        [3.7732, 3.8425, 4.0083, 3.9074, 3.8818],\n",
      "        [3.8338, 3.9293, 4.0354, 4.0449, 3.7854],\n",
      "        [3.9413, 3.8318, 4.1183, 4.4159, 4.1849],\n",
      "        [3.9385, 4.0438, 4.1338, 4.2225, 3.9782],\n",
      "        [3.6707, 3.7086, 3.9249, 3.8012, 3.6398],\n",
      "        [3.4127, 3.6785, 3.8011, 3.6160, 3.5349],\n",
      "        [3.6757, 3.7059, 3.8622, 3.9265, 3.7231],\n",
      "        [3.5502, 3.7446, 3.7348, 3.7549, 3.6044],\n",
      "        [3.9160, 3.9566, 4.1451, 4.1296, 3.8916]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5305, 3.6449, 3.8487, 3.5778, 3.3937],\n",
      "        [3.7428, 3.6220, 3.7771, 3.7124, 3.7379],\n",
      "        [3.5580, 3.7069, 3.7750, 3.7726, 3.6131],\n",
      "        [3.6399, 3.9156, 3.9115, 3.9241, 3.7299],\n",
      "        [3.4297, 3.5383, 3.7360, 3.6122, 3.4721],\n",
      "        [3.5373, 3.5451, 3.7528, 3.6470, 3.6647],\n",
      "        [4.0185, 3.9156, 4.1618, 4.1960, 3.9585],\n",
      "        [3.5581, 3.7583, 3.7461, 3.7692, 3.6106],\n",
      "        [3.5056, 3.9057, 3.9214, 3.6964, 3.5160],\n",
      "        [3.8778, 3.7825, 4.0368, 4.0337, 3.7853],\n",
      "        [3.5218, 3.7036, 3.7232, 3.6880, 3.5847],\n",
      "        [3.4311, 3.6295, 3.6954, 3.5872, 3.5095],\n",
      "        [3.5605, 3.7549, 3.7428, 3.7687, 3.6103],\n",
      "        [3.5509, 3.8208, 3.8763, 3.6809, 3.6739],\n",
      "        [3.5177, 3.6318, 3.9592, 3.5553, 3.7347],\n",
      "        [3.4369, 3.6699, 3.7262, 3.6800, 3.5176],\n",
      "        [3.5062, 3.7133, 4.0029, 3.7464, 3.7321],\n",
      "        [3.7958, 4.0092, 4.1030, 3.9987, 3.8986],\n",
      "        [3.5486, 3.6826, 3.8725, 3.7422, 3.6270],\n",
      "        [3.5061, 3.7005, 3.7253, 3.6846, 3.5675],\n",
      "        [3.6004, 3.7304, 3.8510, 3.7006, 3.6450],\n",
      "        [3.7945, 4.0154, 4.0993, 3.9949, 3.8901],\n",
      "        [3.5256, 3.6321, 3.8355, 3.6923, 3.5840],\n",
      "        [3.5315, 3.7574, 3.9329, 3.7765, 3.5873],\n",
      "        [3.6961, 3.7682, 4.0423, 3.7941, 3.4809],\n",
      "        [3.4240, 3.7945, 3.7283, 3.4721, 3.5994],\n",
      "        [3.5801, 3.6457, 3.8799, 3.7198, 3.6509],\n",
      "        [3.3459, 3.5587, 3.6614, 3.4757, 3.4502],\n",
      "        [3.7366, 3.7760, 4.0373, 3.9805, 3.6390],\n",
      "        [3.5847, 3.6787, 3.9570, 3.9016, 3.8485],\n",
      "        [3.9955, 3.8948, 4.1386, 4.1671, 3.9141],\n",
      "        [3.5422, 3.7840, 3.7805, 3.8409, 3.5584],\n",
      "        [3.5414, 3.7766, 3.8892, 3.7237, 3.6789],\n",
      "        [3.7998, 4.0181, 4.1043, 4.0026, 3.8934],\n",
      "        [3.5550, 3.8803, 3.9562, 3.8809, 3.6196],\n",
      "        [3.4867, 3.7274, 3.9194, 3.7548, 3.5369],\n",
      "        [3.5061, 3.6945, 3.7180, 3.6622, 3.5674],\n",
      "        [3.6631, 3.8574, 4.0098, 3.8340, 3.7147],\n",
      "        [3.4546, 3.6984, 3.9122, 3.6900, 3.6589],\n",
      "        [3.5344, 3.6474, 3.8505, 3.7060, 3.5990],\n",
      "        [3.4763, 3.5128, 3.7117, 3.6263, 3.4531],\n",
      "        [3.7262, 3.6738, 3.8664, 4.0811, 3.8037],\n",
      "        [3.3698, 3.5901, 3.6790, 3.5203, 3.4771],\n",
      "        [4.0305, 4.0114, 4.2300, 4.2326, 4.0286],\n",
      "        [3.4147, 3.5885, 3.7634, 3.6011, 3.4971],\n",
      "        [3.6898, 3.7901, 3.7919, 3.8532, 3.7685],\n",
      "        [4.0410, 4.1308, 4.2053, 4.3223, 3.8888],\n",
      "        [3.7328, 3.9066, 4.0388, 3.8925, 3.9190],\n",
      "        [3.5769, 3.6329, 3.9038, 3.7349, 3.6072],\n",
      "        [3.5370, 3.7316, 3.7369, 3.7291, 3.5960],\n",
      "        [3.8894, 3.8099, 4.0696, 4.0610, 3.8147],\n",
      "        [3.5602, 3.6865, 3.8569, 3.7082, 3.7507],\n",
      "        [3.4391, 3.5147, 3.7225, 3.6248, 3.4588],\n",
      "        [3.7905, 3.9527, 3.9834, 3.8928, 3.8686],\n",
      "        [3.4950, 3.6835, 3.7196, 3.6783, 3.5634],\n",
      "        [3.6074, 3.6111, 3.8440, 3.7383, 3.5593],\n",
      "        [3.5276, 3.6471, 3.9864, 3.5599, 3.7512],\n",
      "        [3.6460, 3.9291, 4.0488, 3.8548, 3.6641],\n",
      "        [3.4406, 3.6471, 3.8475, 3.6645, 3.4942],\n",
      "        [3.5645, 3.6080, 3.8867, 3.7446, 3.7071],\n",
      "        [3.6640, 3.7486, 3.9161, 3.7423, 3.7750],\n",
      "        [3.5371, 3.6107, 3.8536, 3.6926, 3.5765],\n",
      "        [3.9042, 3.8174, 3.9681, 3.9580, 3.8766],\n",
      "        [3.7035, 3.8832, 3.9992, 3.9668, 3.7127]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8868, 3.8511, 3.9569, 3.9386, 3.8253],\n",
      "        [3.7147, 3.8860, 4.0204, 3.9011, 3.7130],\n",
      "        [3.4139, 3.7211, 3.8186, 3.6223, 3.5527],\n",
      "        [3.6161, 3.8560, 3.8745, 3.7326, 3.7002],\n",
      "        [3.9677, 3.9116, 4.0379, 4.0469, 3.9287],\n",
      "        [3.5118, 3.6395, 3.7544, 3.7220, 3.5456],\n",
      "        [3.6054, 3.6864, 3.9429, 3.7786, 3.6757],\n",
      "        [3.6963, 3.8946, 3.9195, 3.8788, 3.7303],\n",
      "        [3.5460, 3.9716, 3.9085, 3.7750, 3.9201],\n",
      "        [3.6785, 3.7121, 3.9434, 3.8259, 3.6535],\n",
      "        [3.6395, 3.7225, 3.8158, 3.8373, 3.6725],\n",
      "        [3.6258, 3.9532, 3.9530, 3.8488, 3.8255],\n",
      "        [3.4732, 3.8991, 3.8689, 3.7720, 3.7309],\n",
      "        [3.6862, 3.9134, 3.9162, 3.9732, 3.7759],\n",
      "        [3.7074, 3.8657, 3.9169, 3.7461, 3.6901],\n",
      "        [3.4775, 3.6730, 3.7110, 3.6279, 3.5508],\n",
      "        [3.6668, 3.9649, 4.0900, 3.8876, 3.6887],\n",
      "        [3.4336, 3.5000, 3.7112, 3.6161, 3.4484],\n",
      "        [3.5215, 3.7032, 3.7218, 3.6882, 3.5834],\n",
      "        [3.4117, 3.5661, 3.7502, 3.5939, 3.4764],\n",
      "        [3.6670, 3.7868, 3.8051, 3.7779, 3.7504],\n",
      "        [3.8349, 4.0939, 4.0330, 4.0299, 4.0091],\n",
      "        [3.6897, 3.9894, 3.9481, 3.8750, 3.7510],\n",
      "        [3.4141, 3.6441, 3.8186, 3.6200, 3.5138],\n",
      "        [3.8106, 3.8995, 4.1289, 4.0628, 3.7468],\n",
      "        [3.7654, 3.8781, 4.0923, 3.9524, 3.9365],\n",
      "        [3.4071, 3.5573, 3.7096, 3.5740, 3.4805],\n",
      "        [3.7920, 3.9461, 4.0747, 3.9458, 3.9716],\n",
      "        [3.5224, 3.5756, 3.8424, 3.6738, 3.5546],\n",
      "        [3.4314, 3.6545, 3.8262, 3.6416, 3.5173],\n",
      "        [3.5602, 3.7545, 3.7414, 3.7689, 3.6091],\n",
      "        [3.7998, 3.7126, 3.9143, 4.1468, 3.8815],\n",
      "        [3.8921, 3.9512, 4.1245, 4.0939, 3.8870],\n",
      "        [3.5565, 3.6802, 3.9502, 3.8521, 3.8120],\n",
      "        [3.8940, 3.9681, 4.0008, 4.0048, 3.9480],\n",
      "        [3.5600, 3.6861, 3.8554, 3.7084, 3.7494],\n",
      "        [3.5502, 3.6899, 3.7958, 3.6396, 3.6025],\n",
      "        [3.7111, 3.8961, 3.8938, 3.9157, 3.8754],\n",
      "        [3.6395, 3.9888, 3.9887, 3.8674, 3.8415],\n",
      "        [3.5238, 3.8684, 3.9449, 3.6375, 3.7064],\n",
      "        [3.4918, 3.6752, 3.7034, 3.6715, 3.5353],\n",
      "        [3.5314, 3.7571, 3.9318, 3.7769, 3.5860],\n",
      "        [3.5384, 3.6169, 3.8508, 3.6955, 3.5814],\n",
      "        [3.5107, 3.7040, 3.8743, 3.7269, 3.7259],\n",
      "        [3.7262, 4.1163, 4.0224, 4.0352, 3.9060],\n",
      "        [3.3671, 3.4790, 3.6860, 3.5182, 3.3971],\n",
      "        [3.7740, 3.9561, 3.9674, 3.8865, 3.8656],\n",
      "        [3.9826, 4.1165, 4.1708, 4.2665, 4.0176],\n",
      "        [3.5724, 3.6351, 3.8477, 3.7049, 3.6463],\n",
      "        [3.5263, 3.5324, 3.7338, 3.6277, 3.6549],\n",
      "        [3.5498, 3.7622, 3.9277, 3.8822, 3.6052],\n",
      "        [3.4165, 3.7261, 3.8278, 3.6251, 3.5545],\n",
      "        [3.6413, 3.8963, 3.8724, 3.7847, 3.6895],\n",
      "        [3.4668, 3.6724, 3.7169, 3.6348, 3.5436],\n",
      "        [3.6021, 3.8528, 3.8813, 3.7316, 3.6981],\n",
      "        [3.9809, 3.9257, 4.1653, 4.1707, 3.9176],\n",
      "        [3.4774, 3.6644, 3.6960, 3.6444, 3.5284],\n",
      "        [3.4334, 3.6405, 3.6997, 3.5886, 3.5222],\n",
      "        [3.5348, 3.7271, 3.7285, 3.7335, 3.5892],\n",
      "        [3.5264, 3.6249, 3.8313, 3.6894, 3.5813],\n",
      "        [3.5755, 4.0009, 4.0291, 3.7864, 3.6098],\n",
      "        [3.4059, 3.5699, 3.7226, 3.6249, 3.4732],\n",
      "        [3.7053, 3.7775, 3.9289, 3.7787, 3.5261],\n",
      "        [3.4408, 3.8546, 3.8636, 3.5619, 3.7005]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.9110, 3.9497, 4.1344, 4.1245, 3.8819],\n",
      "        [4.1824, 4.4382, 4.1247, 4.1139, 3.8759],\n",
      "        [3.4132, 3.5809, 3.7612, 3.5972, 3.4815],\n",
      "        [3.3921, 3.7195, 3.9260, 3.6284, 3.5989],\n",
      "        [3.6578, 4.0046, 3.9666, 3.8608, 3.7551],\n",
      "        [3.6279, 3.7345, 3.8813, 3.8476, 3.6504],\n",
      "        [3.4478, 3.5557, 3.7593, 3.6260, 3.4623],\n",
      "        [3.7319, 3.9769, 3.9263, 3.8117, 3.7321],\n",
      "        [3.4467, 3.6340, 3.6919, 3.6001, 3.5114],\n",
      "        [3.3898, 3.6051, 3.6842, 3.5443, 3.4891],\n",
      "        [3.4029, 3.7285, 3.6515, 3.6705, 3.4681],\n",
      "        [3.4466, 3.6465, 3.8590, 3.7313, 3.6040],\n",
      "        [3.9255, 3.8910, 3.9923, 4.0067, 3.8977],\n",
      "        [3.7523, 3.6183, 3.9159, 4.0156, 3.9149],\n",
      "        [3.4296, 3.5027, 3.7124, 3.6188, 3.4469],\n",
      "        [3.5525, 3.8197, 3.8735, 3.6818, 3.6712],\n",
      "        [3.4176, 3.5644, 3.7504, 3.5970, 3.4769],\n",
      "        [3.5517, 3.7433, 3.7308, 3.7565, 3.6007],\n",
      "        [3.4640, 3.6601, 3.7069, 3.6108, 3.5421],\n",
      "        [3.5671, 4.0158, 4.0679, 3.8083, 3.6606],\n",
      "        [3.4239, 3.4860, 3.7012, 3.6077, 3.4361],\n",
      "        [3.5407, 4.0455, 4.0565, 3.7412, 3.6419],\n",
      "        [3.4556, 3.6294, 3.7025, 3.6546, 3.5006],\n",
      "        [3.6894, 3.9085, 3.9068, 3.9633, 3.7603],\n",
      "        [3.6027, 3.8586, 4.0273, 3.8985, 3.7336],\n",
      "        [3.4464, 3.7124, 4.0073, 3.6875, 3.7372],\n",
      "        [3.8619, 3.9479, 4.0809, 3.9979, 4.0489],\n",
      "        [3.4857, 4.0272, 3.8764, 3.6941, 3.7647],\n",
      "        [3.4342, 3.5732, 3.7665, 3.6238, 3.4986],\n",
      "        [3.4448, 3.6270, 3.8370, 3.7194, 3.5830],\n",
      "        [3.4087, 3.6120, 3.6891, 3.5614, 3.5138],\n",
      "        [3.5557, 3.5535, 3.7923, 3.5920, 3.4959],\n",
      "        [3.7947, 3.8693, 3.9991, 3.9536, 3.9181],\n",
      "        [3.4521, 3.5347, 3.7372, 3.6445, 3.4829],\n",
      "        [3.4913, 3.6075, 3.7871, 3.7033, 3.5063],\n",
      "        [3.6181, 3.8553, 3.8731, 3.7332, 3.6989],\n",
      "        [3.7422, 4.0348, 4.0245, 4.0087, 3.8435],\n",
      "        [3.6645, 3.6993, 3.9090, 3.7877, 3.6267],\n",
      "        [3.5275, 3.7113, 3.7228, 3.7104, 3.5799],\n",
      "        [3.3671, 3.5801, 3.6676, 3.5129, 3.4669],\n",
      "        [3.5016, 3.5247, 3.8515, 3.5109, 3.6267],\n",
      "        [3.6610, 3.8872, 3.8859, 3.9375, 3.7322],\n",
      "        [3.6945, 4.0176, 4.0771, 3.8929, 3.8361],\n",
      "        [3.5083, 3.9638, 3.8233, 3.6818, 3.7542],\n",
      "        [3.5257, 3.7549, 3.7555, 3.8163, 3.5362],\n",
      "        [3.6860, 3.9642, 3.8852, 3.6726, 3.6762],\n",
      "        [3.4395, 3.6583, 3.8627, 3.6590, 3.4997],\n",
      "        [3.5455, 3.6259, 3.8479, 3.6965, 3.5908],\n",
      "        [4.0664, 4.2519, 4.1183, 4.0041, 3.8705],\n",
      "        [3.5312, 3.6889, 3.9436, 3.8234, 3.7718],\n",
      "        [3.5699, 3.6501, 3.8585, 3.7282, 3.6244],\n",
      "        [3.8416, 3.8712, 4.1319, 4.1097, 3.7520],\n",
      "        [3.5006, 3.6293, 3.7748, 3.6205, 3.5648],\n",
      "        [3.5305, 3.6926, 3.8507, 3.7301, 3.6829],\n",
      "        [3.5384, 3.6095, 3.8463, 3.6897, 3.5751],\n",
      "        [3.9592, 3.9749, 4.0156, 4.0775, 3.9969],\n",
      "        [3.4785, 3.6694, 3.7073, 3.6444, 3.5488],\n",
      "        [3.7412, 3.8128, 4.0793, 3.8557, 3.5387],\n",
      "        [3.9257, 4.0054, 4.1195, 4.1860, 3.8027],\n",
      "        [3.5280, 3.7028, 3.7893, 3.6685, 3.5957],\n",
      "        [3.7261, 3.7333, 3.8993, 4.0646, 3.8312],\n",
      "        [3.3949, 3.6216, 3.7668, 3.5883, 3.4865],\n",
      "        [3.4157, 3.7204, 3.8172, 3.6230, 3.5514],\n",
      "        [3.6379, 3.7507, 3.8095, 3.8159, 3.6739]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7362, 3.5596, 3.7509, 3.7321, 3.6567],\n",
      "        [3.6442, 3.9137, 3.9070, 3.9261, 3.7259],\n",
      "        [3.5497, 3.6680, 3.7890, 3.7642, 3.5864],\n",
      "        [3.5285, 3.7084, 3.7163, 3.7232, 3.5766],\n",
      "        [3.7858, 3.8575, 4.0242, 3.9509, 3.6775],\n",
      "        [3.4195, 3.5932, 3.6416, 3.5983, 3.4259],\n",
      "        [3.5246, 3.5716, 3.8351, 3.6723, 3.5565],\n",
      "        [3.6921, 3.9075, 3.9051, 3.9643, 3.7589],\n",
      "        [3.5449, 3.6579, 3.8631, 3.7301, 3.6186],\n",
      "        [3.7354, 3.9808, 3.9275, 3.8144, 3.7328],\n",
      "        [3.7520, 4.0419, 4.0204, 4.0040, 3.8536],\n",
      "        [3.4742, 3.9308, 3.7914, 3.6455, 3.7095],\n",
      "        [3.6242, 3.9285, 3.8745, 3.6348, 3.7071],\n",
      "        [3.6784, 3.9905, 3.9039, 3.8573, 3.8953],\n",
      "        [4.0492, 4.1661, 3.9275, 3.9502, 3.7187],\n",
      "        [3.5031, 3.6634, 3.7284, 3.6696, 3.5698],\n",
      "        [3.7712, 3.8836, 4.0744, 4.0268, 3.7210],\n",
      "        [3.5336, 3.6506, 3.8467, 3.7126, 3.5893],\n",
      "        [3.3574, 3.5636, 3.6603, 3.4918, 3.4517],\n",
      "        [3.5512, 3.8373, 3.8410, 3.6807, 3.6518],\n",
      "        [3.9295, 3.8661, 4.0274, 4.0100, 3.8687],\n",
      "        [3.9564, 3.9001, 4.0319, 4.0408, 3.9003],\n",
      "        [3.5954, 3.8359, 3.8272, 3.7273, 3.6363],\n",
      "        [3.3738, 3.5883, 3.6748, 3.5221, 3.4733],\n",
      "        [4.0000, 3.8928, 4.1342, 4.1699, 3.9102],\n",
      "        [3.5885, 3.8333, 3.8429, 3.7057, 3.6540],\n",
      "        [3.5305, 3.7019, 3.7877, 3.6695, 3.5944],\n",
      "        [3.5644, 4.0064, 3.8987, 3.9128, 3.7748],\n",
      "        [3.4296, 3.5697, 3.7177, 3.6006, 3.4911],\n",
      "        [3.8846, 3.9661, 4.0370, 4.1098, 3.8776],\n",
      "        [3.6958, 3.8565, 4.0484, 3.8055, 3.5965],\n",
      "        [3.5493, 3.7378, 3.9147, 3.9057, 3.5874],\n",
      "        [3.4817, 3.6628, 3.6930, 3.6460, 3.5258],\n",
      "        [3.9065, 3.7398, 3.9569, 4.2894, 3.9858],\n",
      "        [3.6627, 3.8664, 3.9579, 3.7987, 3.5735],\n",
      "        [3.4854, 3.6636, 3.6982, 3.6497, 3.5287],\n",
      "        [3.7941, 4.1002, 4.0185, 3.9960, 3.9734],\n",
      "        [3.6749, 3.7064, 3.9191, 3.8040, 3.6347],\n",
      "        [3.5113, 3.6957, 3.7100, 3.6993, 3.5558],\n",
      "        [3.5293, 3.7546, 3.9250, 3.8281, 3.5771],\n",
      "        [3.6160, 3.6115, 3.9452, 3.9024, 3.5535],\n",
      "        [3.4488, 3.8326, 3.8402, 3.5354, 3.6570],\n",
      "        [3.6950, 3.8241, 4.0028, 3.8886, 3.8423],\n",
      "        [3.4203, 3.6202, 3.6933, 3.5593, 3.5242],\n",
      "        [3.4811, 3.7445, 3.7112, 3.7237, 3.5076],\n",
      "        [3.4852, 3.6629, 3.7299, 3.6978, 3.5196],\n",
      "        [3.5337, 3.6285, 3.8327, 3.6956, 3.5817],\n",
      "        [3.5974, 3.6292, 3.8811, 3.7241, 3.6475],\n",
      "        [3.7840, 3.7045, 3.9020, 4.1104, 3.8553],\n",
      "        [3.4675, 3.6973, 3.7330, 3.7370, 3.5199],\n",
      "        [3.4091, 3.6272, 3.7830, 3.6077, 3.5055],\n",
      "        [3.7100, 3.9059, 4.0247, 3.8127, 3.6141],\n",
      "        [3.7064, 3.7868, 4.1075, 3.7928, 3.5544],\n",
      "        [3.7056, 3.7897, 3.7776, 3.8646, 3.7831],\n",
      "        [3.8028, 3.8858, 4.0525, 4.0265, 3.9968],\n",
      "        [3.4257, 3.6312, 3.6933, 3.5877, 3.5063],\n",
      "        [3.9746, 3.8869, 4.1070, 4.1356, 3.9136],\n",
      "        [4.1021, 4.2797, 4.1375, 4.0371, 3.8864],\n",
      "        [3.6317, 3.7403, 3.8690, 3.7450, 3.6474],\n",
      "        [3.4249, 3.6124, 3.7716, 3.6039, 3.5090],\n",
      "        [3.3992, 3.6922, 3.7940, 3.5947, 3.5130],\n",
      "        [3.7173, 3.8196, 3.8152, 3.8836, 3.7803],\n",
      "        [3.4654, 3.6447, 3.6937, 3.6192, 3.5172],\n",
      "        [3.5999, 3.6734, 3.9232, 3.7818, 3.6686]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3770, 3.5918, 3.6853, 3.5174, 3.4835],\n",
      "        [3.4491, 3.6356, 3.6741, 3.6650, 3.5099],\n",
      "        [3.4247, 3.6236, 3.6904, 3.5689, 3.5119],\n",
      "        [3.7720, 3.8260, 4.0672, 4.0427, 3.6710],\n",
      "        [3.6156, 3.6901, 3.9420, 3.7865, 3.6835],\n",
      "        [3.3714, 3.5790, 3.6650, 3.5144, 3.4648],\n",
      "        [3.7349, 3.8547, 4.0298, 3.9365, 3.8984],\n",
      "        [3.5700, 3.6481, 3.9176, 3.7394, 3.6500],\n",
      "        [3.8850, 3.7854, 4.0361, 4.0413, 3.7862],\n",
      "        [3.6984, 3.8005, 3.9613, 3.8491, 3.8143],\n",
      "        [3.7575, 3.8833, 4.0525, 4.0133, 3.7156],\n",
      "        [3.5339, 3.7161, 3.7172, 3.7325, 3.5780],\n",
      "        [3.8953, 4.1072, 4.0547, 4.0808, 4.0611],\n",
      "        [3.5051, 3.6631, 3.7273, 3.6701, 3.5689],\n",
      "        [3.6163, 3.6250, 4.0979, 3.7978, 3.7211],\n",
      "        [3.6180, 3.8938, 3.8973, 3.8201, 3.7916],\n",
      "        [3.6632, 3.6914, 3.9094, 3.6819, 3.6286],\n",
      "        [3.4673, 3.6332, 3.6989, 3.6819, 3.4739],\n",
      "        [3.9739, 3.9807, 4.0056, 4.0894, 4.0077],\n",
      "        [3.4235, 3.6453, 3.7011, 3.5837, 3.5189],\n",
      "        [3.4220, 3.5632, 3.7477, 3.5985, 3.4746],\n",
      "        [3.5566, 3.6880, 3.7915, 3.6416, 3.5989],\n",
      "        [3.5197, 3.7015, 3.7147, 3.6980, 3.5668],\n",
      "        [3.5348, 3.7777, 3.8393, 3.7496, 3.6565],\n",
      "        [3.9367, 3.7893, 4.0695, 4.0674, 3.8393],\n",
      "        [3.9977, 4.0746, 4.2080, 4.2697, 3.9915],\n",
      "        [3.9201, 4.0388, 4.2015, 4.2081, 4.1703],\n",
      "        [3.4317, 3.6578, 3.7289, 3.6834, 3.5090],\n",
      "        [3.5756, 3.6776, 3.9176, 3.6698, 3.7509],\n",
      "        [3.9814, 4.0005, 4.0700, 4.1079, 3.9936],\n",
      "        [3.4937, 3.5986, 3.8509, 3.6853, 3.5659],\n",
      "        [3.7511, 3.9033, 4.0282, 3.8497, 3.6075],\n",
      "        [3.8259, 3.9608, 4.0066, 3.9405, 3.8798],\n",
      "        [3.7217, 3.9558, 4.0143, 3.8946, 3.7383],\n",
      "        [3.4286, 3.6032, 3.6514, 3.6002, 3.4444],\n",
      "        [3.5521, 3.9968, 3.8911, 3.9159, 3.7533],\n",
      "        [3.4625, 3.6057, 3.6989, 3.6524, 3.4938],\n",
      "        [3.6929, 3.9112, 3.9118, 3.9755, 3.7721],\n",
      "        [3.4961, 3.6828, 3.9327, 3.7254, 3.6770],\n",
      "        [3.5045, 3.6897, 3.7094, 3.6853, 3.5499],\n",
      "        [3.8444, 3.7203, 3.8959, 3.8542, 3.7934],\n",
      "        [3.5225, 3.6564, 3.7745, 3.6762, 3.6432],\n",
      "        [3.7253, 3.6861, 3.8548, 4.0502, 3.7854],\n",
      "        [3.5860, 3.6941, 3.8698, 3.6413, 3.4392],\n",
      "        [3.8065, 3.7108, 3.9101, 4.1494, 3.8781],\n",
      "        [3.4641, 3.6371, 3.8292, 3.6688, 3.4944],\n",
      "        [3.5318, 3.7543, 3.9241, 3.8287, 3.5761],\n",
      "        [3.4325, 3.6149, 3.7949, 3.6320, 3.4850],\n",
      "        [3.4549, 3.5227, 3.7270, 3.6340, 3.4638],\n",
      "        [3.3251, 3.5244, 3.6305, 3.4520, 3.4112],\n",
      "        [3.5704, 3.7627, 3.8825, 3.7211, 3.7288],\n",
      "        [3.8279, 3.9477, 4.1254, 3.9140, 3.6627],\n",
      "        [3.9140, 3.7695, 3.9681, 4.2895, 4.0045],\n",
      "        [3.7152, 3.7184, 3.8643, 4.0223, 3.7930],\n",
      "        [3.7054, 3.7665, 4.0335, 3.7939, 3.4953],\n",
      "        [3.6165, 3.6278, 4.0893, 3.7951, 3.7133],\n",
      "        [3.5543, 3.7084, 3.7661, 3.7164, 3.6185],\n",
      "        [3.4930, 3.5220, 3.7371, 3.6575, 3.4644],\n",
      "        [3.6228, 4.0467, 3.9380, 3.9582, 3.8131],\n",
      "        [3.9577, 4.0119, 4.1749, 4.2083, 3.7701],\n",
      "        [3.7050, 3.7339, 4.0271, 3.9980, 3.6674],\n",
      "        [3.7030, 3.8931, 3.9156, 3.8809, 3.7266],\n",
      "        [3.7884, 4.0154, 4.1156, 3.9121, 3.6215],\n",
      "        [3.7001, 3.7500, 3.9224, 3.7639, 3.5458]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6669, 3.8336, 3.8783, 3.8234, 3.7571],\n",
      "        [3.9681, 3.9784, 3.9792, 4.0700, 4.0169],\n",
      "        [3.5461, 3.6338, 3.8379, 3.6961, 3.5842],\n",
      "        [3.4799, 3.6583, 3.6918, 3.6329, 3.5219],\n",
      "        [3.4856, 3.5963, 3.8343, 3.6940, 3.6442],\n",
      "        [3.8153, 3.9746, 4.1349, 4.1276, 4.1010],\n",
      "        [3.5406, 3.6790, 3.7970, 3.6914, 3.6583],\n",
      "        [3.5515, 3.7351, 3.7259, 3.7473, 3.5890],\n",
      "        [3.8464, 3.7201, 3.8944, 3.8547, 3.7925],\n",
      "        [3.6108, 3.6954, 3.8705, 3.7121, 3.8141],\n",
      "        [3.5507, 3.7348, 3.7314, 3.7439, 3.5965],\n",
      "        [3.6797, 3.8570, 3.9011, 3.8499, 3.7659],\n",
      "        [4.0104, 4.2425, 3.9437, 3.9304, 3.7153],\n",
      "        [3.9790, 3.7979, 4.0516, 4.3413, 4.1606],\n",
      "        [3.5542, 3.9696, 3.9027, 3.7775, 3.9149],\n",
      "        [3.6711, 3.6979, 3.9047, 3.7896, 3.6234],\n",
      "        [3.5080, 3.7376, 3.7984, 3.5839, 3.5137],\n",
      "        [3.6819, 3.8772, 3.9260, 3.8086, 3.8018],\n",
      "        [3.8416, 4.0348, 3.9094, 3.8404, 3.7280],\n",
      "        [3.5520, 3.6246, 3.8436, 3.6983, 3.5874],\n",
      "        [3.7235, 3.9557, 4.0128, 3.8948, 3.7371],\n",
      "        [3.5812, 3.6880, 3.8520, 3.7057, 3.7671],\n",
      "        [3.5045, 3.5448, 3.8083, 3.6496, 3.5265],\n",
      "        [3.6689, 3.5771, 4.0026, 3.8050, 3.6671],\n",
      "        [3.5256, 3.6302, 3.9391, 3.5721, 3.7265],\n",
      "        [3.6343, 3.9515, 3.9478, 3.8513, 3.8208],\n",
      "        [3.5508, 3.5865, 3.8655, 3.6161, 3.6296],\n",
      "        [3.7600, 3.9832, 3.9041, 3.8039, 3.7195],\n",
      "        [3.5493, 3.6892, 3.8453, 3.7235, 3.7028],\n",
      "        [3.5777, 3.6361, 3.8883, 3.7435, 3.6263],\n",
      "        [3.4553, 3.6437, 3.6925, 3.6108, 3.5156],\n",
      "        [3.4068, 3.5894, 3.6299, 3.5703, 3.4332],\n",
      "        [4.2001, 4.4131, 4.1325, 4.0918, 3.9001],\n",
      "        [3.7800, 3.8871, 4.0645, 3.9481, 3.9266],\n",
      "        [3.4974, 4.0311, 3.8795, 3.6967, 3.7641],\n",
      "        [3.6666, 3.6836, 4.0170, 3.8675, 3.6633],\n",
      "        [3.6897, 3.8603, 4.0129, 3.8286, 3.7056],\n",
      "        [3.7649, 3.8701, 4.0325, 3.8722, 3.8178],\n",
      "        [3.5927, 3.6762, 3.9498, 3.9049, 3.8428],\n",
      "        [3.7701, 3.9183, 4.0735, 3.9554, 3.9179],\n",
      "        [3.5376, 3.8488, 3.9140, 3.6556, 3.6689],\n",
      "        [3.6365, 3.7555, 3.7850, 3.7831, 3.6447],\n",
      "        [3.5796, 3.6424, 3.9074, 3.7329, 3.6460],\n",
      "        [3.7892, 4.0125, 4.1159, 3.9089, 3.6295],\n",
      "        [3.4333, 3.9115, 3.9424, 3.7178, 3.7804],\n",
      "        [3.7328, 3.7319, 3.8950, 4.0666, 3.8279],\n",
      "        [3.4116, 3.5599, 3.7164, 3.6322, 3.4702],\n",
      "        [3.7384, 4.0250, 3.9491, 3.9080, 3.9501],\n",
      "        [3.4448, 3.6084, 3.7979, 3.6381, 3.4875],\n",
      "        [3.7829, 3.9547, 4.0834, 3.9518, 3.9475],\n",
      "        [3.8405, 3.8744, 4.0898, 4.1138, 3.7483],\n",
      "        [3.6948, 3.9111, 3.9102, 3.9757, 3.7710],\n",
      "        [4.0231, 4.1556, 3.9197, 3.9370, 3.7211],\n",
      "        [3.5999, 3.8357, 3.8251, 3.7282, 3.6342],\n",
      "        [3.7139, 3.7753, 3.9232, 3.7811, 3.5215],\n",
      "        [3.4615, 3.6184, 3.8066, 3.7137, 3.5552],\n",
      "        [3.5882, 3.6431, 3.8726, 3.7225, 3.6450],\n",
      "        [3.3434, 3.5448, 3.6445, 3.4713, 3.4315],\n",
      "        [3.9594, 4.1415, 4.0163, 3.9029, 3.7806],\n",
      "        [3.4090, 3.6352, 3.7731, 3.5984, 3.5003],\n",
      "        [3.5068, 3.6280, 3.7706, 3.6222, 3.5617],\n",
      "        [3.5625, 3.5625, 3.7927, 3.6961, 3.6817],\n",
      "        [3.6338, 3.6295, 3.8519, 3.7194, 3.6608],\n",
      "        [3.4634, 3.6092, 3.8164, 3.6937, 3.5697]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5426, 3.8533, 3.9166, 3.6386, 3.6911],\n",
      "        [3.9708, 3.8350, 4.0989, 4.4211, 4.1469],\n",
      "        [3.6330, 4.0152, 3.8833, 3.7967, 3.8659],\n",
      "        [3.7066, 3.9128, 3.9287, 3.8736, 3.7318],\n",
      "        [3.8104, 3.8607, 4.0175, 4.0425, 3.9947],\n",
      "        [3.6236, 4.0005, 3.9253, 3.9182, 3.7845],\n",
      "        [3.9122, 3.7991, 4.0741, 4.3782, 4.1477],\n",
      "        [3.4386, 3.6412, 3.6903, 3.5917, 3.5156],\n",
      "        [3.3996, 3.6183, 3.7649, 3.5893, 3.4788],\n",
      "        [4.0433, 4.2542, 4.3519, 4.2797, 4.2899],\n",
      "        [3.7708, 3.8168, 3.9634, 3.8621, 3.8554],\n",
      "        [3.7484, 3.8136, 4.0086, 3.9117, 3.5990],\n",
      "        [3.4704, 3.6326, 3.6956, 3.6821, 3.4715],\n",
      "        [3.4580, 3.5221, 3.7239, 3.6343, 3.4615],\n",
      "        [3.4306, 3.6090, 3.7890, 3.6260, 3.4762],\n",
      "        [3.4421, 3.5006, 3.7095, 3.6268, 3.4398],\n",
      "        [3.6757, 3.7006, 3.8930, 3.7866, 3.6149],\n",
      "        [3.8526, 3.9479, 4.0781, 3.9870, 4.0315],\n",
      "        [3.4585, 3.5579, 3.7593, 3.6305, 3.4609],\n",
      "        [3.3972, 3.6033, 3.6786, 3.5460, 3.4849],\n",
      "        [3.6879, 3.8619, 4.0222, 3.7810, 3.5800],\n",
      "        [4.0537, 4.1286, 4.1982, 4.3257, 3.8808],\n",
      "        [3.5059, 3.5443, 3.8066, 3.6497, 3.5253],\n",
      "        [3.4040, 3.6010, 3.7539, 3.5891, 3.4778],\n",
      "        [3.5991, 3.6454, 3.9311, 3.8072, 3.7295],\n",
      "        [3.6665, 3.8474, 3.9462, 3.8213, 3.8163],\n",
      "        [3.4871, 3.5958, 3.8326, 3.6941, 3.6429],\n",
      "        [3.4526, 3.6251, 3.8307, 3.7212, 3.5780],\n",
      "        [3.8737, 3.7721, 3.9134, 3.8991, 3.8394],\n",
      "        [3.6435, 3.7740, 3.9048, 3.7649, 3.7661],\n",
      "        [3.7154, 3.7747, 3.9214, 3.7812, 3.5202],\n",
      "        [3.5474, 3.6471, 3.8471, 3.7191, 3.5875],\n",
      "        [3.5891, 3.6437, 3.8991, 3.7163, 3.6119],\n",
      "        [3.4556, 3.6048, 3.6998, 3.6372, 3.4883],\n",
      "        [3.6520, 3.8689, 3.8676, 3.9285, 3.7141],\n",
      "        [3.6197, 3.7534, 3.8858, 3.7617, 3.7404],\n",
      "        [3.5538, 3.9759, 3.8590, 3.7614, 3.8137],\n",
      "        [3.6084, 3.7544, 3.8852, 3.8133, 3.7116],\n",
      "        [3.6024, 3.6696, 3.9135, 3.7473, 3.6582],\n",
      "        [3.4483, 3.5116, 3.7140, 3.6275, 3.4517],\n",
      "        [3.9759, 4.0649, 4.1540, 4.2197, 3.9140],\n",
      "        [3.5390, 3.6496, 3.8424, 3.7135, 3.5858],\n",
      "        [3.5362, 3.6223, 3.8239, 3.6920, 3.5753],\n",
      "        [3.5487, 3.7891, 3.9006, 3.7483, 3.6071],\n",
      "        [3.6942, 3.9074, 3.9024, 3.9661, 3.7579],\n",
      "        [3.5630, 3.6956, 3.8042, 3.7098, 3.6758],\n",
      "        [3.5353, 3.7044, 3.7072, 3.7125, 3.5572],\n",
      "        [3.7866, 3.9258, 4.0597, 3.8793, 3.6279],\n",
      "        [3.5117, 3.6406, 3.7549, 3.6613, 3.6284],\n",
      "        [3.4514, 3.6139, 3.8038, 3.6363, 3.4993],\n",
      "        [3.7801, 3.6769, 3.8852, 3.8008, 3.7037],\n",
      "        [3.9279, 4.1404, 4.0502, 3.8998, 3.8198],\n",
      "        [3.3351, 3.5167, 3.6067, 3.5161, 3.4099],\n",
      "        [3.3653, 3.5575, 3.5899, 3.5205, 3.3984],\n",
      "        [3.4539, 3.6294, 3.6666, 3.6320, 3.4624],\n",
      "        [3.6931, 3.9245, 4.0148, 3.9030, 3.7896],\n",
      "        [3.6287, 3.9115, 3.8774, 3.9118, 3.7154],\n",
      "        [3.5932, 3.6824, 3.8641, 3.6294, 3.4386],\n",
      "        [3.5893, 3.6936, 3.8666, 3.6415, 3.4368],\n",
      "        [4.1155, 4.2826, 4.0622, 4.0021, 3.7849],\n",
      "        [3.8515, 3.9032, 4.0665, 4.0408, 3.8125],\n",
      "        [3.5541, 3.8332, 3.8902, 3.6648, 3.6805],\n",
      "        [3.5216, 3.9636, 3.8429, 3.7249, 3.7821],\n",
      "        [3.7136, 3.8442, 3.9952, 3.7994, 3.7160]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4964, 3.5032, 3.8325, 3.4839, 3.6127],\n",
      "        [3.4752, 3.6085, 3.8080, 3.6961, 3.5539],\n",
      "        [3.4722, 3.6576, 3.6991, 3.6123, 3.5364],\n",
      "        [3.7358, 3.9531, 4.0482, 3.9274, 3.7301],\n",
      "        [3.6376, 3.8952, 4.0751, 3.9499, 3.7572],\n",
      "        [3.5101, 3.5220, 3.8434, 3.5124, 3.6207],\n",
      "        [3.5490, 3.7240, 3.7216, 3.7341, 3.5838],\n",
      "        [3.6242, 3.9999, 3.9233, 3.9179, 3.7830],\n",
      "        [4.1907, 4.4358, 4.1164, 4.1160, 3.8699],\n",
      "        [3.9320, 3.7905, 4.0537, 4.0250, 3.8321],\n",
      "        [3.5172, 3.6940, 3.7036, 3.6999, 3.5512],\n",
      "        [3.5967, 3.6387, 3.9116, 3.8012, 3.6338],\n",
      "        [3.4797, 3.9291, 3.7854, 3.6462, 3.7047],\n",
      "        [3.7589, 3.9661, 4.1098, 3.9649, 3.9390],\n",
      "        [3.4654, 3.6080, 3.8126, 3.6935, 3.5668],\n",
      "        [3.5613, 3.8172, 3.8657, 3.6834, 3.6648],\n",
      "        [3.5229, 3.6590, 3.7709, 3.6770, 3.6405],\n",
      "        [3.6338, 3.6982, 3.9614, 3.8070, 3.6853],\n",
      "        [3.4616, 3.6218, 3.6940, 3.6533, 3.5000],\n",
      "        [3.5467, 3.7188, 3.8264, 3.7503, 3.6950],\n",
      "        [3.6309, 3.6761, 3.8630, 3.6393, 3.4417],\n",
      "        [3.4342, 3.6102, 3.7661, 3.6117, 3.5129],\n",
      "        [3.4984, 3.6048, 3.8144, 3.6609, 3.5521],\n",
      "        [3.8453, 4.0909, 4.0233, 4.0324, 4.0014],\n",
      "        [3.6117, 3.6260, 3.8608, 3.7514, 3.6067],\n",
      "        [3.6601, 3.8676, 3.8897, 3.7281, 3.7250],\n",
      "        [3.6059, 3.8372, 3.8297, 3.7281, 3.6369],\n",
      "        [3.4710, 3.6865, 3.8931, 3.7112, 3.6700],\n",
      "        [3.7624, 3.9823, 3.9007, 3.8038, 3.7166],\n",
      "        [3.5873, 3.6394, 3.8428, 3.7111, 3.6465],\n",
      "        [3.9257, 3.9524, 4.1370, 4.1397, 3.8788],\n",
      "        [3.3973, 3.7161, 3.9023, 3.6227, 3.6281],\n",
      "        [3.7179, 3.9418, 3.9408, 3.8831, 3.7445],\n",
      "        [3.6983, 3.9056, 3.8984, 3.9649, 3.7539],\n",
      "        [3.6733, 3.7091, 3.9046, 3.7248, 3.5552],\n",
      "        [3.6568, 3.8957, 3.8656, 3.8036, 3.6918],\n",
      "        [3.7911, 3.9433, 4.0942, 3.8775, 3.6454],\n",
      "        [3.5610, 3.5570, 3.7861, 3.6897, 3.6762],\n",
      "        [3.8065, 3.9653, 4.1304, 4.1148, 4.0907],\n",
      "        [3.7780, 3.8819, 4.0680, 4.0277, 3.7160],\n",
      "        [3.5866, 3.7636, 3.8602, 3.7602, 3.6774],\n",
      "        [3.7764, 3.6640, 3.8722, 3.7944, 3.6951],\n",
      "        [4.0157, 4.1133, 4.1905, 4.2838, 4.0086],\n",
      "        [3.5430, 3.6579, 3.8485, 3.7222, 3.5907],\n",
      "        [3.5778, 3.6286, 3.7891, 3.6754, 3.6404],\n",
      "        [3.7161, 3.7740, 3.9194, 3.7810, 3.5187],\n",
      "        [3.5525, 3.6557, 3.8496, 3.7137, 3.5962],\n",
      "        [3.5270, 3.6558, 3.7703, 3.6763, 3.6392],\n",
      "        [3.6970, 3.9097, 3.9063, 3.9755, 3.7681],\n",
      "        [3.9375, 3.8462, 4.0807, 4.1021, 3.8387],\n",
      "        [3.3831, 3.7289, 3.9333, 3.5939, 3.6111],\n",
      "        [3.3701, 3.5023, 3.6594, 3.5095, 3.4297],\n",
      "        [3.4892, 3.6986, 3.9012, 3.7584, 3.7100],\n",
      "        [3.5782, 3.8803, 3.9175, 3.7448, 3.5181],\n",
      "        [3.3928, 3.5107, 3.6768, 3.5420, 3.4466],\n",
      "        [3.4047, 3.6588, 3.7758, 3.5919, 3.4936],\n",
      "        [3.4198, 3.5771, 3.7480, 3.5955, 3.4737],\n",
      "        [3.6219, 3.6202, 4.0814, 3.7914, 3.7039],\n",
      "        [3.6489, 4.1421, 4.0269, 3.9101, 3.9264],\n",
      "        [3.3768, 3.4760, 3.6769, 3.5203, 3.3904],\n",
      "        [3.5455, 3.6349, 3.8321, 3.6975, 3.5801],\n",
      "        [3.7554, 3.9019, 4.0229, 3.8498, 3.6034],\n",
      "        [3.5802, 3.6299, 3.8074, 3.6866, 3.6448],\n",
      "        [3.4046, 3.6003, 3.7520, 3.5888, 3.4765]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6616, 3.9016, 3.9144, 3.9355, 3.7197],\n",
      "        [3.9262, 3.8154, 3.9440, 3.9406, 3.8222],\n",
      "        [3.9286, 4.0599, 4.0884, 4.0295, 3.9768],\n",
      "        [3.4874, 3.6408, 3.7140, 3.6723, 3.5460],\n",
      "        [3.4919, 3.6218, 3.6040, 3.7195, 3.4433],\n",
      "        [3.4426, 3.6216, 3.6583, 3.6222, 3.4488],\n",
      "        [3.5162, 3.7087, 3.9901, 3.7487, 3.7214],\n",
      "        [3.5928, 3.6536, 3.8948, 3.7620, 3.6388],\n",
      "        [3.6224, 3.6190, 4.0795, 3.7908, 3.7023],\n",
      "        [3.8443, 3.8729, 4.0852, 4.1132, 3.7437],\n",
      "        [3.4882, 3.5335, 3.7417, 3.6411, 3.4616],\n",
      "        [3.6943, 3.9228, 4.0111, 3.9022, 3.7866],\n",
      "        [3.5440, 3.7459, 3.9168, 3.8275, 3.5869],\n",
      "        [3.4581, 3.5427, 3.7390, 3.6406, 3.4847],\n",
      "        [3.9530, 4.0400, 4.1223, 4.2261, 3.9657],\n",
      "        [3.7002, 3.8919, 3.9238, 3.8274, 3.7944],\n",
      "        [3.7122, 3.9845, 4.0331, 3.9296, 3.8635],\n",
      "        [3.5650, 4.0070, 4.0510, 3.8069, 3.6412],\n",
      "        [3.7859, 3.9527, 4.0780, 3.9512, 3.9428],\n",
      "        [3.9696, 4.1236, 4.0717, 4.1288, 4.1108],\n",
      "        [3.5618, 3.7335, 3.8346, 3.7649, 3.6978],\n",
      "        [3.5644, 3.6942, 3.8009, 3.7090, 3.6727],\n",
      "        [3.8181, 3.8486, 4.1113, 4.0861, 3.6911],\n",
      "        [3.9719, 3.8332, 4.0949, 4.4205, 4.1440],\n",
      "        [3.5517, 3.6613, 3.8534, 3.7283, 3.6077],\n",
      "        [3.4227, 3.6738, 3.7876, 3.6184, 3.5240],\n",
      "        [3.9083, 4.0848, 4.0227, 4.0637, 4.0389],\n",
      "        [3.4479, 3.6548, 3.8527, 3.6598, 3.4925],\n",
      "        [3.6673, 3.6837, 3.8689, 3.6786, 3.4692],\n",
      "        [3.5200, 3.5551, 3.8164, 3.6632, 3.5398],\n",
      "        [3.4721, 3.6791, 3.7142, 3.6289, 3.5688],\n",
      "        [3.4028, 3.6374, 3.7384, 3.6364, 3.4689],\n",
      "        [4.0452, 4.1659, 3.9019, 3.9498, 3.7066],\n",
      "        [3.7502, 3.5682, 3.7554, 3.7187, 3.6879],\n",
      "        [3.4214, 3.7025, 3.7978, 3.6204, 3.5252],\n",
      "        [3.4961, 3.7219, 3.7406, 3.7638, 3.5243],\n",
      "        [3.6540, 3.7271, 3.8568, 3.7649, 3.6144],\n",
      "        [3.5857, 3.6394, 3.8729, 3.7210, 3.6362],\n",
      "        [3.6383, 3.8942, 4.0734, 3.9494, 3.7554],\n",
      "        [3.6732, 3.9956, 4.0330, 3.8891, 3.9067],\n",
      "        [3.6214, 3.7981, 4.0101, 3.8279, 3.7355],\n",
      "        [3.5216, 3.6993, 3.8626, 3.7284, 3.7165],\n",
      "        [3.6815, 3.7035, 3.9106, 3.8041, 3.6285],\n",
      "        [3.9264, 3.9514, 4.1353, 4.1391, 3.8771],\n",
      "        [3.9400, 4.0028, 4.1192, 4.1950, 3.7936],\n",
      "        [3.8200, 3.8507, 4.1150, 4.0890, 3.6928],\n",
      "        [3.4791, 3.5996, 3.7831, 3.6933, 3.4850],\n",
      "        [3.5536, 3.6126, 3.8499, 3.7014, 3.5821],\n",
      "        [3.4542, 3.5095, 3.7146, 3.6429, 3.4666],\n",
      "        [3.5322, 3.6987, 3.7107, 3.6899, 3.5747],\n",
      "        [3.6091, 3.9880, 4.0251, 3.8221, 3.6296],\n",
      "        [3.6255, 3.6893, 3.9443, 3.7940, 3.6732],\n",
      "        [3.4753, 3.6208, 3.8186, 3.7036, 3.5778],\n",
      "        [3.7423, 3.8488, 4.0106, 3.9089, 3.6472],\n",
      "        [3.6469, 3.7012, 3.9683, 3.8458, 3.6303],\n",
      "        [3.4831, 3.7432, 3.8955, 3.8171, 3.5128],\n",
      "        [3.6582, 3.7657, 3.8841, 3.9109, 3.6477],\n",
      "        [3.9996, 4.1300, 4.1666, 4.2923, 4.0208],\n",
      "        [3.4299, 3.4842, 3.6912, 3.6108, 3.4291],\n",
      "        [3.6668, 3.6947, 3.8915, 3.6968, 3.5727],\n",
      "        [3.4735, 3.6946, 3.7250, 3.7371, 3.5142],\n",
      "        [3.7942, 3.6897, 3.8976, 4.1293, 3.8537],\n",
      "        [3.5130, 3.5301, 3.8063, 3.6850, 3.6079],\n",
      "        [3.5651, 3.5600, 3.7871, 3.6953, 3.6774]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5299, 3.6350, 3.9577, 3.5553, 3.7338],\n",
      "        [3.5373, 3.6101, 3.8219, 3.6883, 3.5695],\n",
      "        [4.0070, 3.8889, 4.1255, 4.1708, 3.9037],\n",
      "        [3.9300, 3.9513, 4.1315, 4.1331, 3.8787],\n",
      "        [3.5235, 3.6707, 3.7300, 3.6808, 3.5794],\n",
      "        [3.6670, 3.7395, 3.9893, 3.8534, 3.6428],\n",
      "        [3.4164, 3.6018, 3.6700, 3.5573, 3.4804],\n",
      "        [3.5451, 3.7106, 3.7156, 3.7095, 3.5854],\n",
      "        [3.4358, 3.6267, 3.6802, 3.5819, 3.4975],\n",
      "        [3.4461, 3.5536, 3.7549, 3.6183, 3.4476],\n",
      "        [3.7115, 3.7309, 4.0298, 3.9966, 3.6565],\n",
      "        [4.0454, 4.1648, 3.8999, 3.9496, 3.7061],\n",
      "        [3.9312, 3.8481, 4.0274, 3.9995, 3.8766],\n",
      "        [3.5248, 3.7050, 3.7067, 3.7015, 3.5620],\n",
      "        [3.7821, 3.7437, 3.8888, 3.7534, 3.5827],\n",
      "        [3.4123, 3.6794, 3.7472, 3.6576, 3.4900],\n",
      "        [3.5671, 4.0495, 4.0459, 3.7542, 3.6406],\n",
      "        [3.5775, 3.7085, 3.8390, 3.7029, 3.4993],\n",
      "        [3.5619, 3.8149, 3.8619, 3.6826, 3.6624],\n",
      "        [3.7161, 3.8795, 3.9089, 3.8027, 3.6918],\n",
      "        [3.6209, 3.6235, 4.0800, 3.7942, 3.7068],\n",
      "        [3.8213, 3.6950, 3.8732, 3.8361, 3.7565],\n",
      "        [3.4347, 3.6079, 3.7623, 3.6109, 3.5108],\n",
      "        [3.7300, 3.6825, 3.8457, 4.0497, 3.7797],\n",
      "        [3.7510, 3.7718, 4.0260, 3.9830, 3.6276],\n",
      "        [3.5825, 3.6308, 3.8207, 3.6973, 3.6428],\n",
      "        [3.7470, 3.6260, 3.7538, 3.7123, 3.7246],\n",
      "        [3.4098, 3.5229, 3.6819, 3.5594, 3.4596],\n",
      "        [3.5481, 3.6227, 3.8329, 3.6987, 3.5802],\n",
      "        [3.9606, 4.0343, 4.1448, 4.1916, 3.8557],\n",
      "        [3.2558, 3.4874, 3.6791, 3.4803, 3.4438],\n",
      "        [3.5424, 3.6887, 3.7470, 3.6949, 3.5970],\n",
      "        [3.5800, 3.6769, 3.9525, 3.7848, 3.6629],\n",
      "        [3.4333, 3.7272, 3.8147, 3.6287, 3.5562],\n",
      "        [3.9528, 3.9024, 4.0119, 4.0420, 3.9254],\n",
      "        [3.5571, 3.5380, 3.7664, 3.5794, 3.4769],\n",
      "        [3.5401, 3.7747, 3.8312, 3.7490, 3.6501],\n",
      "        [3.4301, 3.4830, 3.6893, 3.6106, 3.4285],\n",
      "        [3.5956, 3.7258, 3.8249, 3.7006, 3.6215],\n",
      "        [3.7606, 3.9188, 3.9070, 3.9284, 3.8065],\n",
      "        [3.7156, 3.8214, 3.9885, 3.8185, 3.7129],\n",
      "        [3.4242, 3.7157, 3.8054, 3.6235, 3.5438],\n",
      "        [3.5525, 3.6859, 3.8380, 3.7225, 3.6977],\n",
      "        [3.4194, 3.7426, 3.9503, 3.6874, 3.6328],\n",
      "        [3.6346, 3.6058, 3.8065, 3.6966, 3.6426],\n",
      "        [3.4931, 3.6609, 3.7301, 3.6564, 3.5682],\n",
      "        [3.4439, 3.6350, 3.6869, 3.5899, 3.5134],\n",
      "        [4.0713, 4.0624, 4.2347, 4.3243, 4.0501],\n",
      "        [3.3781, 3.5602, 3.5935, 3.5282, 3.4062],\n",
      "        [3.5166, 3.6944, 3.7108, 3.6863, 3.5570],\n",
      "        [3.7028, 3.8208, 3.9936, 3.8891, 3.8348],\n",
      "        [3.5571, 3.6237, 3.8436, 3.7019, 3.5835],\n",
      "        [3.5333, 3.7005, 3.7069, 3.7045, 3.5707],\n",
      "        [4.0064, 4.1843, 4.0648, 3.9445, 3.8366],\n",
      "        [3.4395, 3.5284, 3.7223, 3.6101, 3.4596],\n",
      "        [3.4753, 3.6196, 3.8166, 3.7034, 3.5771],\n",
      "        [3.5410, 3.9251, 3.9613, 3.8221, 3.8064],\n",
      "        [3.4255, 3.5537, 3.7357, 3.6021, 3.4668],\n",
      "        [3.5089, 3.6859, 3.7004, 3.6846, 3.5441],\n",
      "        [3.7944, 3.6885, 3.8956, 4.1291, 3.8532],\n",
      "        [3.6573, 3.8937, 3.8618, 3.8028, 3.6896],\n",
      "        [3.5131, 3.5784, 3.7985, 3.6402, 3.5259],\n",
      "        [3.5754, 3.6017, 3.8715, 3.7466, 3.6967],\n",
      "        [3.7548, 3.8892, 4.0748, 3.9683, 3.9206]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4347, 3.6060, 3.7602, 3.6103, 3.5100],\n",
      "        [3.5082, 3.8488, 3.8742, 3.6894, 3.5418],\n",
      "        [3.6026, 3.8342, 3.8312, 3.7206, 3.6377],\n",
      "        [3.9654, 3.8937, 4.0194, 4.0411, 3.8936],\n",
      "        [3.4401, 3.5304, 3.7197, 3.6133, 3.4607],\n",
      "        [3.8404, 3.9763, 3.9869, 3.9470, 3.8997],\n",
      "        [3.4193, 3.5792, 3.7458, 3.6080, 3.4776],\n",
      "        [3.4398, 3.6036, 3.7399, 3.5999, 3.5040],\n",
      "        [3.5096, 3.6556, 3.7265, 3.6172, 3.5295],\n",
      "        [3.9397, 3.9488, 4.1079, 4.1303, 3.8928],\n",
      "        [3.5807, 3.6305, 3.8784, 3.7419, 3.6207],\n",
      "        [3.4312, 3.6066, 3.7594, 3.6030, 3.5017],\n",
      "        [3.6894, 3.8571, 4.0140, 3.7792, 3.5753],\n",
      "        [3.5450, 3.6899, 3.7390, 3.6918, 3.5986],\n",
      "        [3.5488, 3.6421, 3.8392, 3.7176, 3.5828],\n",
      "        [3.4170, 3.5827, 3.6214, 3.5738, 3.4250],\n",
      "        [3.4170, 3.5827, 3.6214, 3.5738, 3.4250],\n",
      "        [3.5711, 4.0021, 3.8866, 3.9121, 3.7667],\n",
      "        [4.2393, 4.4210, 4.1678, 4.1279, 3.8917],\n",
      "        [3.7205, 3.8863, 4.0314, 3.9010, 3.7844],\n",
      "        [3.5554, 3.7726, 3.8805, 3.7318, 3.6239],\n",
      "        [3.3958, 3.5758, 3.6108, 3.5611, 3.4111],\n",
      "        [4.0079, 3.9474, 4.1104, 4.1263, 3.9959],\n",
      "        [3.8675, 3.8011, 4.0326, 4.0008, 3.7655],\n",
      "        [3.3459, 3.5397, 3.6352, 3.4696, 3.4265],\n",
      "        [3.5068, 3.6743, 3.6930, 3.6644, 3.5500],\n",
      "        [3.5811, 3.8063, 3.7821, 3.7060, 3.5999],\n",
      "        [3.6609, 3.6862, 3.8890, 3.6936, 3.5585],\n",
      "        [3.5929, 4.0014, 3.9372, 3.8988, 3.8146],\n",
      "        [3.5459, 3.6447, 3.8383, 3.5860, 3.3854],\n",
      "        [3.5569, 3.7275, 3.7118, 3.7464, 3.5816],\n",
      "        [3.7589, 3.7785, 4.0406, 4.0102, 3.6253],\n",
      "        [3.4865, 3.5048, 3.6952, 3.6274, 3.4417],\n",
      "        [3.4369, 3.6094, 3.7837, 3.6305, 3.4787],\n",
      "        [3.4035, 3.6150, 3.7531, 3.5883, 3.4780],\n",
      "        [3.6778, 3.9659, 4.0227, 3.8672, 3.6885],\n",
      "        [3.5688, 3.7500, 3.7291, 3.7703, 3.5990],\n",
      "        [3.8847, 3.8560, 3.9639, 3.9402, 3.8300],\n",
      "        [3.4644, 3.6141, 3.6612, 3.6443, 3.4576],\n",
      "        [3.4173, 3.6734, 3.7854, 3.6119, 3.5139],\n",
      "        [3.7835, 3.8821, 4.0553, 3.9472, 3.9201],\n",
      "        [3.5462, 3.6306, 3.8262, 3.6962, 3.5770],\n",
      "        [3.6347, 3.6038, 3.8042, 3.6959, 3.6418],\n",
      "        [3.5399, 3.6422, 3.8338, 3.7107, 3.5794],\n",
      "        [3.6174, 3.7516, 3.8682, 3.7756, 3.7228],\n",
      "        [3.6953, 3.7308, 3.9931, 3.9816, 3.6490],\n",
      "        [3.6739, 3.6921, 3.8946, 3.7880, 3.6177],\n",
      "        [3.5046, 3.7328, 3.9031, 3.8090, 3.5353],\n",
      "        [3.7685, 3.9607, 4.0746, 3.8635, 3.5505],\n",
      "        [3.4708, 3.7966, 3.8508, 3.7290, 3.7613],\n",
      "        [3.9307, 4.1054, 4.0458, 4.0947, 4.0703],\n",
      "        [3.6676, 3.5658, 3.9939, 3.8014, 3.6589],\n",
      "        [3.7073, 3.7662, 3.8981, 3.7687, 3.4809],\n",
      "        [3.6721, 3.9601, 4.0199, 3.8645, 3.6775],\n",
      "        [3.5550, 3.5912, 3.7363, 3.7683, 3.4972],\n",
      "        [3.6457, 3.6266, 4.0649, 3.8105, 3.7254],\n",
      "        [3.7081, 3.9085, 3.9211, 3.8721, 3.7272],\n",
      "        [3.7602, 3.6932, 3.8748, 4.0399, 3.7960],\n",
      "        [4.0731, 4.3094, 3.9912, 3.9767, 3.8015],\n",
      "        [3.5454, 3.6241, 3.8243, 3.7050, 3.5769],\n",
      "        [3.6214, 3.7948, 4.0057, 3.8271, 3.7338],\n",
      "        [3.8450, 3.8700, 4.0817, 4.1129, 3.7420],\n",
      "        [3.6548, 3.8630, 4.0364, 3.9207, 3.7566],\n",
      "        [3.5934, 3.8500, 3.9160, 3.8398, 3.6187]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6976, 3.9045, 3.8976, 3.9731, 3.7638],\n",
      "        [3.4994, 3.8305, 3.8681, 3.7497, 3.7672],\n",
      "        [3.5450, 3.5607, 3.7869, 3.6178, 3.5022],\n",
      "        [3.5579, 3.6772, 3.8328, 3.7107, 3.7145],\n",
      "        [3.4784, 3.7073, 3.7731, 3.5588, 3.4872],\n",
      "        [3.6319, 3.6262, 4.0809, 3.8094, 3.7201],\n",
      "        [3.7174, 3.8992, 4.0099, 3.8109, 3.6047],\n",
      "        [3.4828, 3.6056, 3.7883, 3.6758, 3.4896],\n",
      "        [3.7133, 3.7798, 4.0923, 3.7905, 3.5429],\n",
      "        [3.4897, 3.6938, 3.8927, 3.7560, 3.7059],\n",
      "        [3.4758, 3.7538, 3.6897, 3.6878, 3.4880],\n",
      "        [3.8608, 3.8899, 4.0487, 4.0403, 3.8137],\n",
      "        [3.3708, 3.5633, 3.6473, 3.5012, 3.4548],\n",
      "        [3.6568, 3.6773, 3.8613, 3.6618, 3.4551],\n",
      "        [3.5301, 3.6967, 3.7041, 3.6813, 3.5646],\n",
      "        [3.3573, 3.5532, 3.6416, 3.4815, 3.4466],\n",
      "        [3.9810, 3.8889, 4.0994, 4.1878, 3.9496],\n",
      "        [3.9509, 3.9571, 3.9451, 4.0639, 4.0157],\n",
      "        [3.5329, 3.6477, 3.7379, 3.6252, 3.5605],\n",
      "        [3.7261, 3.8108, 3.8023, 3.8814, 3.7718],\n",
      "        [3.9377, 3.8829, 3.9760, 4.0073, 3.8891],\n",
      "        [3.5232, 3.7070, 3.8595, 3.7745, 3.5989],\n",
      "        [3.5201, 3.5513, 3.8100, 3.6615, 3.5375],\n",
      "        [3.2920, 3.5150, 3.6990, 3.4988, 3.4623],\n",
      "        [3.7421, 3.9707, 3.9116, 3.8114, 3.7212],\n",
      "        [3.8407, 3.8806, 4.0506, 4.0019, 3.8038],\n",
      "        [3.5940, 3.8994, 3.9903, 3.9176, 3.6201],\n",
      "        [3.5441, 3.7687, 3.8703, 3.7297, 3.6332],\n",
      "        [3.4876, 3.6371, 3.7076, 3.6705, 3.5437],\n",
      "        [3.4602, 3.6303, 3.7969, 3.5752, 3.6410],\n",
      "        [3.9659, 3.8731, 4.0748, 4.0534, 3.9235],\n",
      "        [3.7146, 3.9834, 3.9135, 3.7041, 3.7273],\n",
      "        [3.5973, 3.6338, 3.9032, 3.7989, 3.6299],\n",
      "        [3.6318, 3.8716, 4.0392, 3.9237, 3.7419],\n",
      "        [3.4047, 3.6670, 3.7773, 3.5925, 3.4985],\n",
      "        [3.4279, 3.6200, 3.6786, 3.5682, 3.5039],\n",
      "        [3.6137, 3.6889, 3.8578, 3.7092, 3.8070],\n",
      "        [3.6942, 3.9573, 3.8689, 3.6719, 3.6656],\n",
      "        [3.5568, 3.7269, 3.7095, 3.7453, 3.5806],\n",
      "        [3.6092, 3.6679, 3.9000, 3.7467, 3.6648],\n",
      "        [3.7017, 3.7087, 3.9314, 3.8351, 3.6400],\n",
      "        [3.6584, 3.6714, 3.8791, 3.6859, 3.5971],\n",
      "        [3.6482, 3.9100, 3.8921, 3.9228, 3.7166],\n",
      "        [3.5495, 3.7190, 3.7133, 3.7317, 3.5797],\n",
      "        [3.5175, 3.8989, 3.9043, 3.6964, 3.5020],\n",
      "        [3.7165, 3.7282, 3.8379, 3.9838, 3.7659],\n",
      "        [3.6989, 3.9004, 3.8898, 3.9625, 3.7496],\n",
      "        [3.4153, 3.6209, 3.7685, 3.6057, 3.4972],\n",
      "        [3.5320, 3.6741, 3.7783, 3.6619, 3.5686],\n",
      "        [4.0731, 4.3091, 3.9889, 3.9756, 3.8004],\n",
      "        [3.8931, 3.7408, 3.9404, 4.2521, 3.9590],\n",
      "        [3.4938, 3.9178, 3.8840, 3.7877, 3.7622],\n",
      "        [3.3292, 3.5187, 3.6176, 3.4495, 3.4045],\n",
      "        [3.4137, 3.7229, 3.9306, 3.6136, 3.5821],\n",
      "        [3.5654, 3.5562, 3.7805, 3.6934, 3.6751],\n",
      "        [3.4825, 3.6619, 3.6873, 3.6411, 3.5277],\n",
      "        [4.0045, 3.9932, 4.1642, 4.2383, 3.9790],\n",
      "        [3.6161, 3.7297, 3.8386, 3.7304, 3.6274],\n",
      "        [3.9538, 4.0366, 4.1164, 4.2249, 3.9629],\n",
      "        [3.5622, 3.7302, 3.8289, 3.7635, 3.6950],\n",
      "        [3.5628, 3.8757, 3.7909, 3.5742, 3.6297],\n",
      "        [3.5447, 3.6586, 3.8410, 3.7222, 3.5884],\n",
      "        [3.9647, 4.0070, 4.1635, 4.2068, 3.7612],\n",
      "        [3.5473, 3.6016, 3.8359, 3.6867, 3.5639]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4360, 3.5516, 3.7329, 3.6071, 3.4682],\n",
      "        [3.6128, 3.6801, 3.9324, 3.7762, 3.6615],\n",
      "        [3.5242, 3.8949, 3.9074, 3.7098, 3.5050],\n",
      "        [3.7221, 3.7332, 3.9688, 3.8737, 3.6791],\n",
      "        [3.7644, 3.8021, 3.9159, 3.9170, 3.8387],\n",
      "        [3.4046, 3.6167, 3.7519, 3.5852, 3.4761],\n",
      "        [3.7152, 4.0799, 4.0447, 3.9411, 3.9052],\n",
      "        [3.6782, 3.7476, 3.8879, 3.8175, 3.7398],\n",
      "        [3.7641, 3.8755, 4.0472, 3.9469, 3.9207],\n",
      "        [3.5163, 3.6910, 3.7047, 3.6842, 3.5544],\n",
      "        [3.6973, 3.9036, 3.8959, 3.9726, 3.7630],\n",
      "        [3.5618, 3.8118, 3.8557, 3.6805, 3.6597],\n",
      "        [3.4699, 3.6198, 3.8040, 3.6666, 3.4834],\n",
      "        [3.5086, 3.6826, 3.6944, 3.6825, 3.5416],\n",
      "        [3.7447, 3.8981, 4.0190, 3.8936, 3.9046],\n",
      "        [3.4107, 3.5219, 3.6734, 3.6283, 3.4512],\n",
      "        [3.4253, 3.5649, 3.7400, 3.6052, 3.4795],\n",
      "        [3.7362, 4.0711, 4.0371, 4.0506, 3.8992],\n",
      "        [3.4129, 3.5299, 3.6890, 3.6198, 3.4514],\n",
      "        [3.7630, 3.9774, 3.8914, 3.8014, 3.7116],\n",
      "        [4.1166, 4.2770, 4.0498, 3.9992, 3.7789],\n",
      "        [3.8234, 3.8904, 4.1089, 4.0631, 3.7341],\n",
      "        [3.4613, 3.6255, 3.6880, 3.6622, 3.4875],\n",
      "        [3.8343, 3.5957, 3.8907, 4.1338, 3.9798],\n",
      "        [3.6406, 3.6978, 3.9161, 3.7867, 3.7546],\n",
      "        [3.7158, 3.7077, 3.8745, 3.6894, 3.5182],\n",
      "        [3.4225, 3.6694, 3.7794, 3.6159, 3.5211],\n",
      "        [3.4922, 3.7168, 3.7310, 3.7635, 3.5237],\n",
      "        [3.4686, 3.6487, 3.6804, 3.6198, 3.5211],\n",
      "        [3.5088, 3.7261, 3.9068, 3.7571, 3.5295],\n",
      "        [3.6128, 3.6222, 3.8580, 3.7386, 3.6123],\n",
      "        [3.7020, 3.9974, 3.9305, 3.8772, 3.7330],\n",
      "        [3.5188, 3.6109, 3.8427, 3.7153, 3.6580],\n",
      "        [3.5163, 3.9557, 3.8058, 3.6807, 3.7431],\n",
      "        [3.5709, 3.6298, 3.8398, 3.7199, 3.6117],\n",
      "        [3.6991, 4.0742, 4.0531, 3.9261, 3.8736],\n",
      "        [3.4032, 3.5151, 3.7048, 3.5670, 3.4290],\n",
      "        [3.5536, 3.6080, 3.8418, 3.6993, 3.5791],\n",
      "        [3.6953, 3.9012, 3.8944, 3.9712, 3.7595],\n",
      "        [3.7160, 3.7259, 3.9541, 3.8681, 3.6657],\n",
      "        [3.4299, 3.4798, 3.6834, 3.6087, 3.4260],\n",
      "        [3.6004, 3.8250, 3.8185, 3.7139, 3.6303],\n",
      "        [3.4712, 3.5540, 3.7445, 3.6296, 3.4686],\n",
      "        [3.9086, 3.7695, 3.9038, 3.9322, 3.8307],\n",
      "        [3.4144, 3.5786, 3.7413, 3.5912, 3.4692],\n",
      "        [3.4857, 3.6894, 3.7300, 3.6485, 3.5772],\n",
      "        [3.7943, 3.6853, 3.8893, 4.1273, 3.8508],\n",
      "        [3.6871, 3.8486, 3.9008, 3.8528, 3.7601],\n",
      "        [3.5276, 3.5424, 3.8451, 3.5438, 3.6232],\n",
      "        [3.6950, 3.7623, 3.8846, 3.7516, 3.4645],\n",
      "        [3.5720, 3.5969, 3.8636, 3.7406, 3.6901],\n",
      "        [3.5451, 3.6228, 3.8204, 3.7035, 3.5751],\n",
      "        [3.6508, 3.9068, 3.8905, 3.9239, 3.7163],\n",
      "        [3.4006, 3.7114, 3.9074, 3.6268, 3.5877],\n",
      "        [3.5367, 3.6937, 3.8423, 3.7452, 3.6520],\n",
      "        [3.6504, 3.7077, 3.8311, 3.8536, 3.6587],\n",
      "        [3.7057, 3.8478, 3.8848, 3.7159, 3.6656],\n",
      "        [3.4844, 3.6281, 3.8099, 3.7305, 3.5557],\n",
      "        [4.0047, 4.0688, 4.1943, 4.2678, 3.9819],\n",
      "        [3.5108, 3.5956, 3.8067, 3.6503, 3.5431],\n",
      "        [3.3774, 3.4862, 3.6823, 3.5360, 3.3883],\n",
      "        [3.6940, 3.7211, 3.8138, 3.9260, 3.7248],\n",
      "        [3.6673, 3.6356, 4.0656, 3.8377, 3.7393],\n",
      "        [3.6697, 3.9763, 4.0125, 3.8819, 3.8881]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6945, 3.9596, 3.9332, 3.8208, 3.7279],\n",
      "        [3.4661, 3.5986, 3.6823, 3.6503, 3.4850],\n",
      "        [3.5874, 3.8840, 3.8088, 3.8743, 3.6824],\n",
      "        [3.6464, 3.6961, 3.9584, 3.8444, 3.6261],\n",
      "        [3.6275, 3.8658, 3.9274, 3.7827, 3.5403],\n",
      "        [3.4523, 3.6167, 3.6564, 3.6659, 3.4993],\n",
      "        [3.4897, 3.8147, 3.8577, 3.7451, 3.7725],\n",
      "        [3.5735, 3.6515, 3.9123, 3.7478, 3.6477],\n",
      "        [3.7148, 4.0799, 4.0429, 3.9420, 3.9043],\n",
      "        [3.3566, 3.5524, 3.6384, 3.4817, 3.4452],\n",
      "        [3.7951, 4.0818, 4.0312, 4.0208, 3.9265],\n",
      "        [3.6691, 3.8273, 3.8637, 3.8217, 3.7486],\n",
      "        [3.5482, 3.6392, 3.9270, 3.6072, 3.7240],\n",
      "        [3.2402, 3.4801, 3.6730, 3.4611, 3.4131],\n",
      "        [3.4796, 3.6076, 3.7575, 3.6028, 3.5232],\n",
      "        [3.9713, 3.8286, 4.0844, 4.4195, 4.1401],\n",
      "        [3.5367, 3.7691, 3.8649, 3.7277, 3.6098],\n",
      "        [3.5672, 3.7477, 3.7283, 3.7667, 3.6041],\n",
      "        [3.5075, 3.8478, 3.8688, 3.6890, 3.5389],\n",
      "        [3.5733, 3.6282, 3.8491, 3.7283, 3.6105],\n",
      "        [3.5997, 3.6386, 3.9169, 3.8051, 3.7226],\n",
      "        [3.6922, 3.8540, 3.9976, 3.8262, 3.6971],\n",
      "        [3.3865, 3.5012, 3.6946, 3.5587, 3.3999],\n",
      "        [3.5366, 3.6066, 3.8141, 3.6872, 3.5660],\n",
      "        [3.8169, 3.9676, 4.1187, 4.1259, 4.0924],\n",
      "        [3.8216, 3.8612, 3.9794, 3.9714, 3.9072],\n",
      "        [3.6292, 3.9054, 3.8634, 3.9095, 3.7083],\n",
      "        [3.3608, 3.5592, 3.5541, 3.5887, 3.4112],\n",
      "        [3.5731, 3.6624, 3.9254, 3.7630, 3.6507],\n",
      "        [3.7991, 3.9577, 4.1077, 4.0949, 4.0819],\n",
      "        [3.6374, 3.8467, 3.8681, 3.7391, 3.6896],\n",
      "        [3.9680, 3.9691, 3.9791, 4.0757, 3.9943],\n",
      "        [3.5409, 3.7343, 3.8965, 3.8259, 3.5863],\n",
      "        [3.8462, 3.8850, 4.0409, 4.0328, 3.7913],\n",
      "        [3.9952, 4.0800, 4.1447, 4.2375, 3.9412],\n",
      "        [3.5787, 3.6414, 3.8383, 3.7277, 3.6131],\n",
      "        [3.7679, 3.9594, 4.0687, 3.8627, 3.5477],\n",
      "        [3.6867, 3.8485, 3.8991, 3.8538, 3.7593],\n",
      "        [3.7585, 4.0369, 4.0027, 4.0030, 3.8427],\n",
      "        [3.3829, 3.5804, 3.6545, 3.5264, 3.4683],\n",
      "        [3.4009, 3.5972, 3.6618, 3.5383, 3.4762],\n",
      "        [3.8649, 3.8890, 4.0606, 4.0220, 3.6786],\n",
      "        [3.6340, 3.7974, 4.0074, 3.8309, 3.7197],\n",
      "        [3.7870, 3.9918, 4.1099, 3.9383, 3.6582],\n",
      "        [3.5789, 3.6688, 3.9341, 3.7696, 3.6546],\n",
      "        [3.4394, 3.5290, 3.7141, 3.6127, 3.4582],\n",
      "        [3.7094, 3.7591, 4.0164, 3.7918, 3.4836],\n",
      "        [3.4914, 3.6174, 3.5946, 3.7180, 3.4400],\n",
      "        [3.7944, 3.7907, 4.0004, 3.9491, 3.7162],\n",
      "        [3.4212, 3.5728, 3.7419, 3.5965, 3.4703],\n",
      "        [3.7984, 3.6725, 3.8560, 3.8067, 3.7259],\n",
      "        [3.5600, 3.8643, 3.7792, 3.8456, 3.6619],\n",
      "        [3.6374, 3.6360, 4.0833, 3.8143, 3.7302],\n",
      "        [3.5457, 3.7603, 3.8514, 3.7760, 3.6406],\n",
      "        [4.0598, 4.0924, 4.2144, 4.2815, 3.9445],\n",
      "        [3.7374, 3.9004, 3.8840, 3.9115, 3.7931],\n",
      "        [3.4177, 3.8192, 3.8124, 3.5308, 3.6569],\n",
      "        [3.8103, 3.8545, 4.0035, 4.0408, 3.9878],\n",
      "        [3.4574, 3.7767, 3.8427, 3.7155, 3.7422],\n",
      "        [3.5436, 3.7586, 3.7459, 3.8210, 3.5385],\n",
      "        [3.5547, 3.8267, 3.8759, 3.6623, 3.6729],\n",
      "        [3.9266, 3.9469, 4.1262, 4.1387, 3.8725],\n",
      "        [3.5483, 3.6268, 3.8225, 3.6941, 3.5757],\n",
      "        [3.6726, 3.9913, 4.0230, 3.8878, 3.9026]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8067, 3.8878, 4.0860, 4.0477, 3.7254],\n",
      "        [3.7905, 3.9376, 4.0802, 3.8764, 3.6392],\n",
      "        [3.9675, 3.9690, 3.9772, 4.0768, 3.9943],\n",
      "        [4.0112, 4.1727, 4.0273, 3.9442, 3.7922],\n",
      "        [3.8462, 3.7281, 3.9067, 4.1746, 3.8937],\n",
      "        [3.9876, 3.8620, 4.0927, 4.1565, 3.9229],\n",
      "        [3.4034, 3.6660, 3.7721, 3.5937, 3.4970],\n",
      "        [3.9049, 3.8215, 3.9491, 3.9440, 3.8625],\n",
      "        [3.7580, 3.9234, 3.8962, 3.9428, 3.9102],\n",
      "        [3.6763, 3.7784, 3.7828, 3.7796, 3.7372],\n",
      "        [3.3561, 3.5522, 3.6366, 3.4826, 3.4451],\n",
      "        [3.3397, 3.5279, 3.6184, 3.4714, 3.4258],\n",
      "        [3.6727, 3.7029, 3.8905, 3.7239, 3.5494],\n",
      "        [3.5642, 3.7048, 3.7553, 3.7865, 3.6100],\n",
      "        [3.7374, 3.7396, 3.8657, 4.0359, 3.8014],\n",
      "        [3.5728, 3.6280, 3.8472, 3.7293, 3.6104],\n",
      "        [3.6808, 3.7962, 3.9185, 3.9411, 3.6737],\n",
      "        [3.5190, 3.5502, 3.8048, 3.6629, 3.5360],\n",
      "        [3.6334, 3.7972, 4.0054, 3.8319, 3.7195],\n",
      "        [3.4053, 3.6212, 3.6861, 3.6079, 3.4723],\n",
      "        [3.6261, 4.0420, 3.9194, 3.9575, 3.8030],\n",
      "        [3.5416, 3.6500, 3.8328, 3.7281, 3.5868],\n",
      "        [3.5233, 3.8948, 3.9040, 3.7120, 3.5040],\n",
      "        [3.6095, 3.7442, 3.8613, 3.7679, 3.7173],\n",
      "        [3.6999, 3.8864, 3.8903, 3.8460, 3.6871],\n",
      "        [3.4375, 3.6257, 3.6722, 3.5949, 3.5026],\n",
      "        [3.9365, 3.7815, 4.0438, 4.3986, 4.1250],\n",
      "        [3.4070, 3.5811, 3.7342, 3.5868, 3.4666],\n",
      "        [3.7362, 3.9506, 3.9383, 3.8557, 3.7828],\n",
      "        [3.5425, 3.6518, 3.8349, 3.7214, 3.5846],\n",
      "        [3.4036, 3.6164, 3.7484, 3.5868, 3.4752],\n",
      "        [3.6080, 3.6666, 3.8944, 3.7481, 3.6631],\n",
      "        [3.7949, 4.0054, 4.1036, 3.9041, 3.6251],\n",
      "        [3.7818, 3.7400, 3.8790, 3.7536, 3.5798],\n",
      "        [3.7991, 4.0930, 3.9978, 3.9957, 3.9626],\n",
      "        [3.6345, 3.9052, 3.8918, 3.8335, 3.7979],\n",
      "        [3.6818, 3.8690, 3.9096, 3.8027, 3.7926],\n",
      "        [3.4022, 3.6134, 3.7456, 3.5885, 3.4754],\n",
      "        [3.9381, 3.9481, 4.0840, 4.1160, 3.9016],\n",
      "        [3.5597, 3.9520, 3.9013, 3.8661, 3.7872],\n",
      "        [3.6198, 3.7933, 3.9975, 3.8274, 3.7308],\n",
      "        [3.5928, 3.6326, 3.9081, 3.7883, 3.7185],\n",
      "        [3.3630, 3.5623, 3.6410, 3.4928, 3.4454],\n",
      "        [3.5550, 3.7283, 3.8386, 3.8003, 3.6803],\n",
      "        [3.8643, 3.8888, 4.0587, 4.0231, 3.6785],\n",
      "        [4.2382, 4.4202, 4.1596, 4.1284, 3.8893],\n",
      "        [3.4928, 4.0187, 3.8547, 3.6949, 3.7520],\n",
      "        [3.4639, 3.7855, 3.8389, 3.7206, 3.7447],\n",
      "        [3.5307, 3.6729, 3.7732, 3.6631, 3.5670],\n",
      "        [3.8902, 3.9585, 4.0179, 4.1105, 3.8672],\n",
      "        [3.3885, 3.5413, 3.5987, 3.6135, 3.4099],\n",
      "        [3.9491, 4.0533, 4.0901, 4.1960, 3.9067],\n",
      "        [3.4432, 3.4909, 3.6891, 3.6175, 3.4355],\n",
      "        [3.7526, 3.6788, 3.8512, 4.0936, 3.8023],\n",
      "        [3.7323, 3.8827, 4.0021, 3.9058, 3.7058],\n",
      "        [3.5352, 3.6746, 3.7529, 3.7279, 3.5590],\n",
      "        [3.4519, 3.9054, 3.7758, 3.6305, 3.6697],\n",
      "        [3.6339, 3.6665, 3.9457, 3.9385, 3.8729],\n",
      "        [3.7265, 4.0161, 3.9874, 3.9775, 3.8208],\n",
      "        [3.4466, 3.6749, 3.6703, 3.6750, 3.5113],\n",
      "        [3.6026, 3.8300, 3.8101, 3.7288, 3.6255],\n",
      "        [3.5176, 3.6824, 3.6936, 3.6704, 3.5608],\n",
      "        [3.4280, 3.6592, 3.7729, 3.6115, 3.5217],\n",
      "        [3.7128, 3.9486, 3.9281, 3.8686, 3.7335]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4483, 3.7148, 3.8611, 3.7850, 3.4780],\n",
      "        [3.9555, 3.8940, 4.0135, 4.1188, 3.8550],\n",
      "        [3.8218, 3.8620, 3.9762, 3.9733, 3.9068],\n",
      "        [3.5597, 3.5993, 3.7404, 3.6450, 3.6104],\n",
      "        [3.4612, 3.6168, 3.6795, 3.6527, 3.4941],\n",
      "        [3.7955, 4.0807, 4.0276, 4.0229, 3.9215],\n",
      "        [3.5449, 3.7108, 3.7001, 3.7304, 3.5680],\n",
      "        [3.4293, 3.4803, 3.6787, 3.6113, 3.4246],\n",
      "        [3.7265, 3.9333, 3.9868, 3.9026, 3.7301],\n",
      "        [3.4519, 3.5301, 3.7170, 3.6226, 3.4621],\n",
      "        [3.5435, 3.6743, 3.7809, 3.6924, 3.6490],\n",
      "        [3.5710, 3.7087, 3.7651, 3.7804, 3.6066],\n",
      "        [3.5219, 3.6315, 3.7310, 3.7242, 3.5327],\n",
      "        [3.6002, 3.8698, 3.9118, 3.7623, 3.5220],\n",
      "        [4.0163, 4.1084, 4.1760, 4.2845, 4.0034],\n",
      "        [3.6124, 3.8818, 3.9499, 3.8584, 3.6224],\n",
      "        [3.6910, 3.8974, 3.8844, 3.9663, 3.7518],\n",
      "        [3.7090, 3.7194, 3.9374, 3.9113, 3.5887],\n",
      "        [3.5863, 3.8837, 3.9111, 3.7508, 3.5147],\n",
      "        [3.9123, 3.9413, 4.1174, 4.1546, 3.8954],\n",
      "        [3.6178, 3.9577, 4.0430, 3.9072, 3.8229],\n",
      "        [3.9782, 4.0400, 4.1379, 4.2341, 3.9595],\n",
      "        [3.9899, 3.8437, 4.1449, 4.4504, 4.2164],\n",
      "        [3.7953, 4.0065, 4.1023, 3.9049, 3.6246],\n",
      "        [3.5852, 3.6353, 3.8594, 3.7212, 3.6317],\n",
      "        [3.4995, 3.7211, 3.8985, 3.7602, 3.5217],\n",
      "        [3.6338, 3.7983, 4.0039, 3.8326, 3.7190],\n",
      "        [3.6176, 3.6025, 3.8186, 3.7410, 3.5455],\n",
      "        [3.4351, 3.5631, 3.6972, 3.6005, 3.4811],\n",
      "        [3.7226, 3.8137, 3.7943, 3.8841, 3.7699],\n",
      "        [3.7239, 3.9361, 3.9847, 3.8800, 3.7063],\n",
      "        [3.5577, 3.8313, 3.8203, 3.6816, 3.6402],\n",
      "        [3.4638, 3.6162, 3.8110, 3.7114, 3.5810],\n",
      "        [3.7116, 3.9811, 4.0199, 3.9302, 3.8590],\n",
      "        [4.0255, 4.1508, 3.9015, 3.9370, 3.7135],\n",
      "        [3.9926, 3.9178, 4.1430, 4.1749, 3.9059],\n",
      "        [3.5448, 3.6684, 3.7767, 3.6809, 3.5901],\n",
      "        [3.6526, 3.7593, 3.9424, 3.8088, 3.6389],\n",
      "        [3.6872, 3.8577, 4.0009, 3.8288, 3.7042],\n",
      "        [3.7042, 3.7433, 3.9019, 3.7637, 3.5358],\n",
      "        [3.9406, 3.9483, 4.0652, 4.1061, 3.9068],\n",
      "        [3.9749, 4.0444, 4.1632, 4.2536, 3.9577],\n",
      "        [3.5632, 3.7943, 3.8368, 3.7589, 3.6656],\n",
      "        [3.3906, 3.5494, 3.6159, 3.6253, 3.4018],\n",
      "        [3.4152, 3.5618, 3.6987, 3.6266, 3.4601],\n",
      "        [3.9128, 3.7937, 4.0566, 4.3785, 4.1407],\n",
      "        [3.4188, 3.6124, 3.6657, 3.5617, 3.4863],\n",
      "        [3.7476, 3.7733, 3.9810, 3.9475, 3.6333],\n",
      "        [3.6161, 3.6234, 3.8539, 3.7248, 3.6432],\n",
      "        [3.4908, 3.6641, 3.6880, 3.6369, 3.5462],\n",
      "        [3.8168, 3.9686, 4.1153, 4.1278, 4.0921],\n",
      "        [3.4137, 3.5793, 3.7365, 3.5936, 3.4677],\n",
      "        [3.4030, 3.6392, 3.7575, 3.5932, 3.4819],\n",
      "        [3.5348, 3.7090, 3.7061, 3.7123, 3.5710],\n",
      "        [3.8092, 3.9604, 4.1060, 4.1056, 4.0925],\n",
      "        [3.5417, 3.6114, 3.8215, 3.7008, 3.5756],\n",
      "        [3.7824, 3.9182, 3.9500, 3.8959, 3.8147],\n",
      "        [3.4317, 3.5392, 3.7090, 3.5962, 3.4513],\n",
      "        [3.6030, 3.6637, 3.8960, 3.7468, 3.6507],\n",
      "        [3.5612, 3.5519, 3.7708, 3.6891, 3.6703],\n",
      "        [3.7168, 3.8991, 4.0031, 3.8132, 3.6026],\n",
      "        [3.5914, 3.6129, 3.8880, 3.7759, 3.7037],\n",
      "        [3.3791, 3.5820, 3.6546, 3.5218, 3.4637],\n",
      "        [3.3401, 3.5289, 3.6173, 3.4719, 3.4253]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7815, 3.9642, 4.0748, 3.9607, 3.9440],\n",
      "        [3.7281, 3.7105, 3.8641, 3.7043, 3.5345],\n",
      "        [3.6284, 3.5947, 3.7780, 3.6869, 3.6277],\n",
      "        [3.6947, 3.9023, 3.8880, 3.9759, 3.7574],\n",
      "        [3.4628, 3.5384, 3.8051, 3.6433, 3.5225],\n",
      "        [3.4560, 3.5998, 3.6820, 3.6382, 3.4806],\n",
      "        [3.8492, 3.6086, 3.8951, 4.1441, 3.9932],\n",
      "        [3.4255, 3.5577, 3.7266, 3.5999, 3.4645],\n",
      "        [3.8359, 3.8763, 4.0151, 4.0710, 3.9981],\n",
      "        [3.5299, 3.6393, 3.8226, 3.7174, 3.5746],\n",
      "        [3.5294, 3.8995, 3.9507, 3.8116, 3.7665],\n",
      "        [3.5454, 3.6304, 3.8157, 3.6992, 3.5733],\n",
      "        [3.4092, 3.5675, 3.7011, 3.6332, 3.4606],\n",
      "        [3.6451, 3.7439, 3.7910, 3.8211, 3.6633],\n",
      "        [3.9307, 3.9569, 4.1294, 4.1537, 3.8842],\n",
      "        [3.6632, 3.8531, 3.8584, 3.8320, 3.7140],\n",
      "        [3.7401, 4.0202, 3.9282, 3.9094, 3.9405],\n",
      "        [3.9572, 3.7659, 4.0081, 4.3426, 4.1300],\n",
      "        [3.6262, 4.0264, 3.9377, 3.9442, 3.8170],\n",
      "        [3.5413, 3.7820, 3.8533, 3.7333, 3.6090],\n",
      "        [3.5675, 3.7461, 3.9146, 3.7756, 3.6652],\n",
      "        [3.4957, 3.6726, 3.6828, 3.6625, 3.5336],\n",
      "        [3.8896, 3.7753, 4.0126, 4.0401, 3.7727],\n",
      "        [4.2388, 4.4228, 4.1565, 4.1310, 3.8884],\n",
      "        [3.4548, 3.5435, 3.6123, 3.6596, 3.4068],\n",
      "        [3.5276, 3.6526, 3.7561, 3.6796, 3.6323],\n",
      "        [3.4541, 3.6245, 3.6488, 3.6330, 3.4545],\n",
      "        [3.7914, 4.0075, 4.0952, 3.9102, 3.6193],\n",
      "        [3.4387, 3.5264, 3.7101, 3.6124, 3.4551],\n",
      "        [3.4741, 3.6174, 3.8037, 3.7057, 3.5721],\n",
      "        [3.8118, 3.9119, 4.0146, 3.9229, 3.8662],\n",
      "        [3.5688, 3.7326, 3.7119, 3.7618, 3.5796],\n",
      "        [3.5294, 3.6990, 3.7007, 3.7144, 3.5641],\n",
      "        [3.7354, 3.9589, 3.8849, 3.7117, 3.6328],\n",
      "        [3.5784, 3.8767, 3.9017, 3.7468, 3.5111],\n",
      "        [3.5241, 3.8325, 3.8845, 3.6922, 3.6930],\n",
      "        [3.3402, 3.5296, 3.6160, 3.4737, 3.4248],\n",
      "        [3.7559, 3.8972, 4.0059, 3.8515, 3.5966],\n",
      "        [3.6238, 3.9961, 3.9061, 3.9192, 3.7759],\n",
      "        [3.4321, 3.4791, 3.6779, 3.6109, 3.4236],\n",
      "        [3.4236, 3.6368, 3.7930, 3.6232, 3.5004],\n",
      "        [3.5385, 3.6997, 3.8692, 3.7529, 3.6600],\n",
      "        [3.4057, 3.6229, 3.6834, 3.6103, 3.4713],\n",
      "        [3.6307, 3.6136, 3.8241, 3.7178, 3.6462],\n",
      "        [3.5810, 3.8070, 3.7732, 3.7107, 3.5967],\n",
      "        [3.7122, 3.7588, 3.9061, 3.7719, 3.5240],\n",
      "        [3.5804, 3.8983, 3.9219, 3.7626, 3.5148],\n",
      "        [3.8520, 3.8772, 4.0352, 3.9969, 3.6769],\n",
      "        [3.4265, 3.6183, 3.6717, 3.5675, 3.4950],\n",
      "        [3.4291, 3.9084, 3.9074, 3.7077, 3.7701],\n",
      "        [3.8321, 3.9427, 4.1033, 3.9156, 3.6514],\n",
      "        [3.5442, 3.6895, 3.7292, 3.6947, 3.5950],\n",
      "        [3.7165, 3.7694, 3.9028, 3.7824, 3.5122],\n",
      "        [3.5867, 3.9952, 4.0042, 3.7911, 3.5948],\n",
      "        [3.7348, 3.8772, 3.9962, 3.9912, 3.6993],\n",
      "        [3.4248, 3.5875, 3.6198, 3.6000, 3.4150],\n",
      "        [3.5650, 3.5594, 3.7950, 3.7090, 3.6703],\n",
      "        [3.5255, 3.6737, 3.7197, 3.6829, 3.5753],\n",
      "        [3.4306, 3.5651, 3.7315, 3.6080, 3.4795],\n",
      "        [3.4946, 3.7165, 3.7661, 3.7559, 3.5443],\n",
      "        [3.4449, 3.5632, 3.6422, 3.6618, 3.4129],\n",
      "        [3.5029, 3.5889, 3.7930, 3.6499, 3.5336],\n",
      "        [3.5311, 3.6746, 3.7707, 3.6656, 3.5661],\n",
      "        [3.6523, 3.8632, 3.8489, 3.9300, 3.7055]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7194, 3.8905, 3.8652, 3.9204, 3.8605],\n",
      "        [3.8136, 3.8062, 4.0048, 3.9580, 3.7311],\n",
      "        [3.9686, 3.9707, 3.9903, 4.0826, 3.9837],\n",
      "        [3.4839, 3.7420, 3.8825, 3.8229, 3.5076],\n",
      "        [3.5399, 3.7742, 3.8185, 3.7535, 3.6450],\n",
      "        [3.6192, 3.6200, 3.8475, 3.7447, 3.5934],\n",
      "        [3.8343, 3.8823, 4.0248, 4.0663, 3.9977],\n",
      "        [3.5453, 3.7155, 3.6977, 3.7302, 3.5629],\n",
      "        [3.5441, 3.7093, 3.7026, 3.7132, 3.5802],\n",
      "        [3.4920, 3.6650, 3.6791, 3.6514, 3.5375],\n",
      "        [3.6014, 3.7536, 3.8725, 3.8306, 3.6707],\n",
      "        [3.9814, 3.7936, 4.0296, 4.3449, 4.1513],\n",
      "        [3.5353, 3.6173, 3.8379, 3.7272, 3.6528],\n",
      "        [3.4889, 3.5710, 3.8295, 3.6791, 3.5403],\n",
      "        [3.7951, 3.7935, 3.9949, 3.9539, 3.7154],\n",
      "        [3.6914, 3.8646, 4.0087, 3.8786, 3.7154],\n",
      "        [3.4819, 3.6072, 3.7796, 3.6808, 3.4864],\n",
      "        [3.8064, 3.9324, 4.0436, 3.9591, 3.9605],\n",
      "        [3.5377, 3.5921, 3.8017, 3.6436, 3.5309],\n",
      "        [3.4163, 3.6746, 3.7743, 3.6156, 3.5097],\n",
      "        [3.3998, 3.7138, 3.8998, 3.6325, 3.5848],\n",
      "        [3.5971, 3.6649, 3.8349, 3.7469, 3.6190],\n",
      "        [3.5274, 3.6252, 3.9168, 3.5742, 3.7158],\n",
      "        [3.5896, 3.6395, 3.8795, 3.7189, 3.6035],\n",
      "        [3.5472, 3.6035, 3.8255, 3.6981, 3.5611],\n",
      "        [3.5642, 3.8895, 3.9006, 3.7348, 3.5036],\n",
      "        [4.0008, 4.1352, 4.0798, 4.1665, 4.1284],\n",
      "        [3.7355, 4.0743, 4.0296, 4.0563, 3.8967],\n",
      "        [3.7761, 3.8439, 3.9759, 3.9448, 3.8564],\n",
      "        [3.5210, 4.0043, 3.8772, 3.7543, 3.8502],\n",
      "        [3.7853, 3.9513, 3.9422, 3.8937, 3.8509],\n",
      "        [3.9143, 3.8009, 4.0530, 4.3882, 4.1388],\n",
      "        [3.8946, 3.9368, 4.0416, 4.1066, 3.8197],\n",
      "        [3.4675, 3.6463, 3.6785, 3.6275, 3.5282],\n",
      "        [3.9295, 3.9534, 4.1222, 4.1462, 3.8783],\n",
      "        [3.5613, 3.6488, 3.9143, 3.6342, 3.7304],\n",
      "        [3.3401, 3.5306, 3.6152, 3.4749, 3.4242],\n",
      "        [3.4559, 3.6007, 3.6812, 3.6394, 3.4800],\n",
      "        [3.5806, 4.0308, 3.8933, 3.9375, 3.7715],\n",
      "        [4.0291, 3.9616, 4.1589, 4.1918, 3.9770],\n",
      "        [3.4540, 3.7071, 3.9811, 3.6921, 3.7231],\n",
      "        [3.7022, 3.8604, 4.0243, 3.9206, 3.8210],\n",
      "        [3.5605, 3.8023, 3.9339, 3.7708, 3.5553],\n",
      "        [3.7729, 3.9947, 3.8999, 3.8297, 3.7236],\n",
      "        [3.6763, 3.6963, 3.8729, 3.7890, 3.6062],\n",
      "        [3.6133, 3.8372, 3.8414, 3.7428, 3.6820],\n",
      "        [3.6965, 3.9056, 3.8886, 3.9787, 3.7602],\n",
      "        [3.7104, 3.7857, 3.7539, 3.8677, 3.7718],\n",
      "        [3.5392, 3.6544, 3.8307, 3.7288, 3.5894],\n",
      "        [3.6133, 3.6045, 3.8279, 3.7361, 3.5511],\n",
      "        [3.5205, 4.0274, 4.0274, 3.7567, 3.6094],\n",
      "        [3.6611, 3.8998, 3.8984, 3.9389, 3.7141],\n",
      "        [3.5045, 3.6062, 3.8186, 3.7019, 3.5663],\n",
      "        [3.7020, 3.8523, 4.0245, 3.8090, 3.5838],\n",
      "        [3.7165, 3.7703, 3.9017, 3.7836, 3.5116],\n",
      "        [3.9899, 3.9164, 4.1392, 4.1764, 3.9033],\n",
      "        [3.5312, 3.6328, 3.9246, 3.5841, 3.7134],\n",
      "        [3.6090, 3.9828, 3.8404, 3.7902, 3.8256],\n",
      "        [3.4890, 3.7551, 3.8799, 3.6814, 3.6572],\n",
      "        [3.5269, 3.5446, 3.8377, 3.5491, 3.6204],\n",
      "        [3.5288, 3.5686, 3.8143, 3.6779, 3.5417],\n",
      "        [3.4569, 3.6392, 3.6723, 3.6131, 3.5061],\n",
      "        [3.9265, 3.9843, 4.0431, 4.1389, 3.8984],\n",
      "        [3.5416, 3.6441, 3.7334, 3.7398, 3.5427]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5402, 3.7492, 3.9230, 3.7921, 3.5576],\n",
      "        [3.4933, 4.0219, 3.8492, 3.6995, 3.7492],\n",
      "        [3.4135, 3.6921, 3.7755, 3.6074, 3.5129],\n",
      "        [3.8106, 3.7076, 3.8860, 4.1537, 3.8668],\n",
      "        [3.5309, 3.6335, 3.9232, 3.5849, 3.7124],\n",
      "        [3.7295, 3.8410, 3.9984, 3.9372, 3.8769],\n",
      "        [3.8083, 3.8826, 4.0270, 4.0322, 3.9842],\n",
      "        [3.6440, 3.8818, 3.9255, 3.8624, 3.6683],\n",
      "        [3.5773, 3.9891, 3.9041, 3.8987, 3.7808],\n",
      "        [3.4705, 3.6401, 3.6698, 3.6233, 3.5048],\n",
      "        [3.4979, 3.6153, 3.8120, 3.7027, 3.5661],\n",
      "        [3.6975, 3.9021, 3.8795, 3.9691, 3.7451],\n",
      "        [3.9331, 3.7954, 4.0422, 4.0376, 3.8260],\n",
      "        [3.4068, 3.5433, 3.6850, 3.6239, 3.4485],\n",
      "        [3.4903, 3.8797, 3.8659, 3.6646, 3.4726],\n",
      "        [3.6498, 3.9853, 3.8709, 3.8248, 3.8489],\n",
      "        [3.8735, 3.9712, 3.9715, 3.9801, 3.9080],\n",
      "        [3.5639, 3.8706, 3.7771, 3.8516, 3.6590],\n",
      "        [3.4317, 3.7888, 3.6993, 3.4780, 3.5815],\n",
      "        [3.4569, 3.5493, 3.6159, 3.6644, 3.4266],\n",
      "        [3.7120, 3.7815, 4.0811, 3.7971, 3.5366],\n",
      "        [3.6745, 3.7345, 3.8517, 3.7882, 3.6233],\n",
      "        [3.4255, 3.7207, 3.8001, 3.6303, 3.5395],\n",
      "        [3.9002, 3.9481, 4.0650, 4.1129, 3.8047],\n",
      "        [3.5465, 3.6040, 3.8197, 3.6950, 3.5613],\n",
      "        [3.5864, 3.6517, 3.8446, 3.7518, 3.6224],\n",
      "        [3.9306, 3.9985, 4.0501, 4.1658, 3.9173],\n",
      "        [3.7925, 3.6126, 3.8965, 4.0706, 3.9225],\n",
      "        [3.4676, 3.6514, 3.6724, 3.6262, 3.5176],\n",
      "        [3.4170, 3.6142, 3.6629, 3.5705, 3.4862],\n",
      "        [3.9408, 4.0023, 4.1043, 4.2022, 3.7876],\n",
      "        [3.7277, 3.9287, 3.9727, 3.9041, 3.7252],\n",
      "        [3.4480, 3.5029, 3.6876, 3.6380, 3.4528],\n",
      "        [3.7921, 4.0120, 4.0912, 3.9159, 3.6084],\n",
      "        [3.4887, 3.5716, 3.8282, 3.6799, 3.5393],\n",
      "        [3.7376, 3.7430, 3.8605, 4.0404, 3.7989],\n",
      "        [3.5603, 3.8029, 3.9328, 3.7719, 3.5544],\n",
      "        [3.4409, 3.5158, 3.7015, 3.6204, 3.4459],\n",
      "        [3.6367, 3.6387, 4.0762, 3.8203, 3.7271],\n",
      "        [3.5893, 3.6402, 3.8782, 3.7197, 3.6025],\n",
      "        [3.4960, 3.6684, 3.6741, 3.6719, 3.5215],\n",
      "        [3.5594, 3.7371, 3.7047, 3.7620, 3.5862],\n",
      "        [3.8094, 3.9718, 3.9631, 3.9334, 3.8773],\n",
      "        [3.7922, 3.8532, 3.9996, 3.9558, 3.6633],\n",
      "        [3.4136, 3.7051, 3.7846, 3.6070, 3.5173],\n",
      "        [3.5443, 3.9410, 3.8671, 3.8457, 3.7386],\n",
      "        [3.5815, 3.7725, 3.8633, 3.7300, 3.7387],\n",
      "        [3.7851, 3.9520, 3.9410, 3.8947, 3.8500],\n",
      "        [3.5678, 3.6604, 3.9079, 3.6236, 3.7446],\n",
      "        [3.5442, 3.6254, 3.8115, 3.7101, 3.5716],\n",
      "        [3.5708, 3.6154, 3.7501, 3.6618, 3.6244],\n",
      "        [3.9507, 4.0570, 4.0849, 4.2007, 3.9048],\n",
      "        [3.5484, 3.7911, 3.8782, 3.7502, 3.6033],\n",
      "        [3.8577, 3.7183, 3.8738, 3.8624, 3.7769],\n",
      "        [3.6488, 3.6693, 3.8627, 3.6890, 3.5612],\n",
      "        [3.6581, 3.6701, 3.9833, 3.8746, 3.6079],\n",
      "        [3.5787, 3.6761, 3.9371, 3.7891, 3.6568],\n",
      "        [3.8350, 3.6114, 3.8917, 4.1347, 3.9733],\n",
      "        [3.5641, 3.6933, 3.7857, 3.7150, 3.6659],\n",
      "        [3.6837, 3.9871, 3.8783, 3.8617, 3.8821],\n",
      "        [3.5291, 3.9011, 3.9482, 3.8137, 3.7650],\n",
      "        [3.5005, 3.7257, 3.8999, 3.7767, 3.5312],\n",
      "        [3.4486, 3.6323, 3.8108, 3.6626, 3.4724],\n",
      "        [3.4000, 3.5608, 3.6866, 3.6274, 3.4477]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5886, 3.8905, 4.0521, 3.9224, 3.6863],\n",
      "        [3.4198, 3.7016, 3.7798, 3.6253, 3.5172],\n",
      "        [3.7907, 4.0093, 4.0913, 3.9139, 3.6161],\n",
      "        [3.5692, 3.7435, 3.7062, 3.7712, 3.5837],\n",
      "        [3.3350, 3.5316, 3.6125, 3.4623, 3.4082],\n",
      "        [3.4416, 3.5681, 3.7389, 3.6302, 3.4833],\n",
      "        [3.5517, 3.8117, 3.9470, 3.7785, 3.5473],\n",
      "        [3.5831, 3.6405, 3.8817, 3.7751, 3.6461],\n",
      "        [3.4225, 3.7160, 3.7895, 3.6288, 3.5363],\n",
      "        [3.3873, 3.6534, 3.8965, 3.6127, 3.6446],\n",
      "        [3.4036, 3.6886, 3.7680, 3.5995, 3.4994],\n",
      "        [3.8169, 4.0116, 3.9055, 3.7835, 3.6662],\n",
      "        [3.4019, 3.7140, 3.8959, 3.6277, 3.5754],\n",
      "        [3.6825, 3.8732, 3.8777, 3.8834, 3.7015],\n",
      "        [3.5785, 3.8163, 3.7704, 3.7130, 3.5979],\n",
      "        [3.8464, 3.7319, 3.8999, 4.1804, 3.8900],\n",
      "        [3.4167, 3.6144, 3.6615, 3.5718, 3.4848],\n",
      "        [3.5371, 3.5929, 3.7988, 3.6457, 3.5284],\n",
      "        [3.6932, 3.7234, 3.8930, 3.7436, 3.5434],\n",
      "        [3.4383, 3.6050, 3.7261, 3.6060, 3.4973],\n",
      "        [3.4967, 3.5945, 3.8255, 3.6901, 3.5529],\n",
      "        [3.3628, 3.5658, 3.6351, 3.4984, 3.4415],\n",
      "        [3.4521, 3.6369, 3.8247, 3.7372, 3.5899],\n",
      "        [3.9658, 3.9685, 3.9381, 4.0687, 4.0015],\n",
      "        [3.7311, 3.9125, 4.0431, 3.9113, 3.8886],\n",
      "        [3.5263, 3.7639, 3.8115, 3.7596, 3.6388],\n",
      "        [3.7162, 3.7772, 3.8968, 3.7863, 3.4968],\n",
      "        [3.5592, 3.7375, 3.7058, 3.7485, 3.5884],\n",
      "        [3.4902, 3.6665, 3.6832, 3.6422, 3.5427],\n",
      "        [3.6687, 3.8312, 3.8554, 3.8289, 3.7452],\n",
      "        [3.4930, 3.7343, 3.8843, 3.8151, 3.5195],\n",
      "        [3.6939, 3.9039, 3.8843, 3.9797, 3.7542],\n",
      "        [3.8518, 3.8937, 4.0395, 4.0535, 3.7972],\n",
      "        [3.3503, 3.5473, 3.6233, 3.4839, 3.4298],\n",
      "        [3.4634, 3.6924, 3.8803, 3.6974, 3.6402],\n",
      "        [3.3785, 3.5845, 3.6498, 3.5269, 3.4603],\n",
      "        [3.5464, 3.7221, 3.7010, 3.7489, 3.5719],\n",
      "        [3.5282, 3.7031, 3.8411, 3.7697, 3.6180],\n",
      "        [3.5742, 3.7122, 3.6662, 3.7591, 3.4953],\n",
      "        [3.4447, 3.5534, 3.7391, 3.6238, 3.4403],\n",
      "        [3.9610, 4.1405, 3.9913, 3.9078, 3.7686],\n",
      "        [3.3628, 3.5658, 3.6351, 3.4984, 3.4415],\n",
      "        [3.5573, 3.7037, 3.7416, 3.7217, 3.6052],\n",
      "        [3.6854, 3.6998, 3.8294, 3.9346, 3.7037],\n",
      "        [3.9225, 3.9456, 4.1087, 4.1343, 3.8657],\n",
      "        [3.4095, 3.5977, 3.7379, 3.5971, 3.4674],\n",
      "        [3.4291, 3.5975, 3.7244, 3.5959, 3.4920],\n",
      "        [3.7132, 3.8617, 3.8889, 3.7505, 3.6724],\n",
      "        [3.6376, 3.9977, 3.9738, 3.8698, 3.8142],\n",
      "        [3.7922, 3.6129, 3.8948, 4.0718, 3.9211],\n",
      "        [3.5794, 3.8116, 3.8228, 3.7365, 3.6648],\n",
      "        [3.8112, 3.9142, 4.0102, 3.9261, 3.8631],\n",
      "        [3.5477, 3.5897, 3.7151, 3.6340, 3.5965],\n",
      "        [3.5968, 3.9128, 3.7792, 3.7782, 3.6152],\n",
      "        [3.7499, 3.9218, 3.9699, 3.7697, 3.7375],\n",
      "        [3.6299, 3.7911, 3.8199, 3.7911, 3.7069],\n",
      "        [3.8217, 3.8647, 3.9706, 3.9788, 3.9034],\n",
      "        [3.8576, 3.7185, 3.8722, 3.8637, 3.7756],\n",
      "        [3.9223, 3.9441, 4.1102, 4.1400, 3.8630],\n",
      "        [3.6834, 3.9874, 3.8766, 3.8629, 3.8807],\n",
      "        [3.4437, 3.5232, 3.7047, 3.6225, 3.4478],\n",
      "        [3.5662, 3.7504, 3.7203, 3.7739, 3.6000],\n",
      "        [3.7349, 3.9614, 3.8808, 3.7149, 3.6298],\n",
      "        [3.8625, 3.9099, 4.1480, 4.1494, 3.7451]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5465, 3.9112, 3.9081, 3.8439, 3.7833],\n",
      "        [3.5383, 3.6837, 3.9130, 3.8310, 3.7549],\n",
      "        [3.7724, 3.9151, 4.0487, 3.9655, 3.9035],\n",
      "        [3.6557, 3.9242, 4.0163, 3.8630, 3.6433],\n",
      "        [3.4571, 3.5465, 3.6144, 3.6658, 3.3813],\n",
      "        [3.6954, 3.9059, 3.8841, 3.9820, 3.7563],\n",
      "        [3.6954, 3.7153, 3.9129, 3.8387, 3.6421],\n",
      "        [3.4310, 3.7887, 3.6959, 3.4800, 3.5785],\n",
      "        [3.4528, 3.6405, 3.8280, 3.7386, 3.5852],\n",
      "        [3.5545, 3.9658, 3.8755, 3.7833, 3.8992],\n",
      "        [3.5548, 3.7316, 3.8303, 3.8076, 3.6752],\n",
      "        [3.5947, 3.8300, 3.8161, 3.7139, 3.6377],\n",
      "        [3.4097, 3.7241, 3.6238, 3.6777, 3.4536],\n",
      "        [3.8929, 3.8673, 3.9472, 3.9540, 3.8382],\n",
      "        [3.9505, 4.0571, 4.0814, 4.2028, 3.9021],\n",
      "        [3.6112, 4.0261, 3.9068, 3.9553, 3.7880],\n",
      "        [3.4964, 3.6660, 3.7348, 3.5594, 3.5142],\n",
      "        [3.8649, 3.9131, 4.0641, 4.0154, 3.7985],\n",
      "        [3.5633, 3.8901, 3.8960, 3.7380, 3.4997],\n",
      "        [3.4108, 3.6687, 3.7643, 3.6022, 3.4887],\n",
      "        [3.8403, 3.8836, 4.0370, 4.0103, 3.7988],\n",
      "        [3.9870, 4.2177, 3.8876, 3.8921, 3.7203],\n",
      "        [3.6098, 3.8960, 3.8259, 3.9038, 3.6905],\n",
      "        [3.7012, 3.8614, 4.0190, 3.9234, 3.8169],\n",
      "        [3.9937, 3.9205, 4.1358, 4.1808, 3.9020],\n",
      "        [3.7782, 3.8793, 4.0451, 4.0346, 3.7051],\n",
      "        [3.6035, 3.8772, 3.7926, 3.5984, 3.5892],\n",
      "        [3.5707, 3.6801, 3.8234, 3.7161, 3.7303],\n",
      "        [4.0253, 4.1552, 3.8942, 3.9426, 3.7091],\n",
      "        [3.6104, 3.9593, 4.0293, 3.9038, 3.8183],\n",
      "        [3.8483, 3.6103, 3.8894, 4.1480, 3.9891],\n",
      "        [3.5399, 3.6880, 3.8218, 3.7382, 3.6655],\n",
      "        [3.3853, 3.5830, 3.6484, 3.5242, 3.4593],\n",
      "        [3.6912, 3.8574, 3.9874, 3.8345, 3.6917],\n",
      "        [3.5790, 3.8113, 3.8210, 3.7373, 3.6634],\n",
      "        [3.9319, 3.8476, 4.0089, 4.0073, 3.8695],\n",
      "        [3.7508, 3.5664, 3.7358, 3.7255, 3.6810],\n",
      "        [3.3960, 3.5864, 3.6468, 3.5414, 3.4615],\n",
      "        [3.8051, 4.0142, 4.0644, 4.0020, 3.8642],\n",
      "        [3.5624, 3.8061, 3.9001, 3.7686, 3.5743],\n",
      "        [3.4383, 3.5316, 3.7041, 3.6202, 3.4529],\n",
      "        [3.5515, 3.7180, 3.6940, 3.7453, 3.5633],\n",
      "        [3.5017, 3.5903, 3.7872, 3.6540, 3.5291],\n",
      "        [3.4284, 3.4820, 3.6717, 3.6170, 3.4199],\n",
      "        [3.6874, 3.8587, 3.9980, 3.7870, 3.5669],\n",
      "        [3.8268, 3.8875, 4.0317, 4.0687, 3.9936],\n",
      "        [3.5388, 3.7453, 3.9047, 3.8361, 3.5594],\n",
      "        [3.9678, 3.9719, 3.9856, 4.0857, 3.9800],\n",
      "        [3.4915, 3.5212, 3.7049, 3.6604, 3.4389],\n",
      "        [3.4433, 3.5229, 3.7029, 3.6232, 3.4465],\n",
      "        [3.4109, 3.7230, 3.6272, 3.6760, 3.4521],\n",
      "        [3.6846, 3.7694, 3.7470, 3.8571, 3.7438],\n",
      "        [3.7775, 3.6611, 3.8504, 3.8010, 3.6860],\n",
      "        [3.9067, 4.0852, 4.0011, 4.0701, 4.0294],\n",
      "        [3.9605, 4.0347, 4.1283, 4.2018, 3.8474],\n",
      "        [3.8216, 3.6945, 3.8552, 3.8434, 3.7496],\n",
      "        [3.7160, 3.8451, 3.9551, 3.7837, 3.7132],\n",
      "        [3.8118, 3.8629, 4.0714, 4.1252, 3.7517],\n",
      "        [3.4142, 3.6512, 3.7287, 3.6659, 3.4702],\n",
      "        [3.4669, 3.5950, 3.7665, 3.6784, 3.4680],\n",
      "        [3.7441, 3.7157, 3.8626, 3.7240, 3.5432],\n",
      "        [3.6375, 3.8930, 4.0548, 3.9607, 3.7456],\n",
      "        [3.9674, 3.9737, 3.9684, 4.0837, 3.9892],\n",
      "        [3.6439, 3.8640, 3.9201, 3.7960, 3.5441]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4075, 3.5683, 3.6945, 3.6383, 3.4557],\n",
      "        [3.4858, 3.4915, 3.6622, 3.6292, 3.4180],\n",
      "        [3.7152, 3.8955, 3.9978, 3.8837, 3.7512],\n",
      "        [3.4689, 3.6834, 3.8692, 3.7177, 3.6582],\n",
      "        [3.4104, 3.7226, 3.6261, 3.6769, 3.4517],\n",
      "        [3.7047, 3.9010, 3.9820, 3.9006, 3.7461],\n",
      "        [3.6761, 3.9597, 4.0573, 3.8967, 3.6687],\n",
      "        [3.6489, 3.9095, 3.8769, 3.9333, 3.7096],\n",
      "        [3.7339, 4.0748, 4.0237, 4.0606, 3.8923],\n",
      "        [3.6859, 3.8596, 3.9926, 3.8361, 3.6988],\n",
      "        [3.9352, 3.9621, 4.1228, 4.1540, 3.8852],\n",
      "        [3.4855, 3.6572, 3.6648, 3.6533, 3.5099],\n",
      "        [3.4084, 3.6504, 3.7547, 3.6008, 3.4800],\n",
      "        [3.4414, 3.5016, 3.6866, 3.6396, 3.4406],\n",
      "        [3.8223, 3.8928, 4.0948, 4.0738, 3.7277],\n",
      "        [3.4024, 3.6192, 3.7394, 3.5943, 3.4693],\n",
      "        [3.9894, 3.8653, 4.0831, 4.1640, 3.9188],\n",
      "        [3.7222, 3.9472, 3.9869, 3.9019, 3.7232],\n",
      "        [3.4667, 3.7773, 3.6950, 3.4846, 3.5417],\n",
      "        [3.5221, 3.8976, 3.8946, 3.7206, 3.4984],\n",
      "        [3.9698, 3.8316, 4.0722, 4.4282, 4.1344],\n",
      "        [3.5702, 3.6796, 3.8222, 3.7171, 3.7298],\n",
      "        [3.9692, 3.9765, 3.9516, 4.0768, 4.0032],\n",
      "        [3.5808, 3.6147, 3.8739, 3.7759, 3.6950],\n",
      "        [3.5545, 3.7280, 3.6970, 3.7700, 3.5781],\n",
      "        [3.6513, 3.7610, 3.9342, 3.8158, 3.6333],\n",
      "        [3.4095, 3.6351, 3.7521, 3.6128, 3.4923],\n",
      "        [3.4447, 3.7501, 3.9559, 3.7062, 3.6563],\n",
      "        [3.6809, 3.8539, 3.8755, 3.8578, 3.7522],\n",
      "        [3.4900, 3.7195, 3.7184, 3.7727, 3.5169],\n",
      "        [3.5219, 3.7088, 3.8454, 3.7852, 3.5920],\n",
      "        [3.9396, 3.9504, 4.0570, 4.1142, 3.9017],\n",
      "        [3.6414, 3.7420, 3.9234, 3.8003, 3.6505],\n",
      "        [3.5306, 3.6491, 3.7244, 3.6341, 3.5532],\n",
      "        [3.6557, 3.6840, 3.8617, 3.7072, 3.5389],\n",
      "        [3.9947, 3.9842, 4.1160, 4.2239, 3.9654],\n",
      "        [3.4922, 3.7334, 3.8817, 3.8175, 3.5178],\n",
      "        [3.6302, 3.9682, 3.9995, 3.8453, 3.6352],\n",
      "        [3.5025, 3.5994, 3.8162, 3.6998, 3.5580],\n",
      "        [3.4515, 3.9079, 3.7657, 3.6378, 3.6636],\n",
      "        [3.8042, 4.0099, 4.0650, 4.0049, 3.8692],\n",
      "        [3.4801, 3.6534, 3.6661, 3.6392, 3.5081],\n",
      "        [3.7852, 3.9945, 4.0981, 3.9479, 3.6519],\n",
      "        [3.4612, 3.5393, 3.7982, 3.6480, 3.5179],\n",
      "        [3.3767, 3.4580, 3.6646, 3.6306, 3.4228],\n",
      "        [3.4659, 3.4675, 3.7837, 3.4547, 3.5764],\n",
      "        [3.7268, 3.8471, 3.9384, 3.8699, 3.8191],\n",
      "        [3.7212, 3.8969, 3.9872, 3.9067, 3.7261],\n",
      "        [4.0327, 4.2715, 3.9376, 3.9630, 3.7176],\n",
      "        [3.7276, 4.0050, 3.9032, 3.8990, 3.9194],\n",
      "        [3.5205, 3.6332, 3.7232, 3.7315, 3.5274],\n",
      "        [3.6653, 3.8950, 3.8890, 3.7563, 3.7082],\n",
      "        [3.4624, 3.9303, 3.9494, 3.7652, 3.7804],\n",
      "        [3.5428, 3.6310, 3.8126, 3.7099, 3.5736],\n",
      "        [4.0107, 4.1782, 4.0169, 3.9516, 3.7867],\n",
      "        [3.9016, 3.8041, 4.0385, 4.0723, 3.7984],\n",
      "        [3.4042, 3.6982, 3.7764, 3.6039, 3.5077],\n",
      "        [3.7109, 3.7598, 3.8989, 3.7767, 3.5192],\n",
      "        [3.4525, 3.6254, 3.6425, 3.6381, 3.4497],\n",
      "        [3.6282, 3.5942, 3.7674, 3.6868, 3.6226],\n",
      "        [3.5722, 3.6429, 3.8881, 3.7458, 3.6347],\n",
      "        [3.5650, 3.8102, 3.9132, 3.7756, 3.5624],\n",
      "        [3.6955, 3.9037, 3.8836, 3.9782, 3.7545],\n",
      "        [4.0170, 4.1105, 4.1673, 4.2916, 3.9990]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4364, 3.6238, 3.7884, 3.6473, 3.4904],\n",
      "        [4.1753, 4.4030, 4.1207, 4.1242, 3.8570],\n",
      "        [3.4586, 3.5706, 3.6145, 3.6745, 3.4573],\n",
      "        [3.8101, 4.0120, 4.0692, 4.0146, 3.8719],\n",
      "        [3.4418, 3.5009, 3.6859, 3.6414, 3.4399],\n",
      "        [3.5471, 3.5371, 3.7172, 3.6565, 3.6441],\n",
      "        [3.5929, 3.6781, 3.8390, 3.6380, 3.4252],\n",
      "        [3.5559, 3.6291, 3.8811, 3.7586, 3.6139],\n",
      "        [3.5162, 3.6944, 3.8810, 3.7993, 3.7336],\n",
      "        [3.6024, 3.6231, 3.8497, 3.7325, 3.6307],\n",
      "        [3.6166, 3.7523, 3.8502, 3.7863, 3.7137],\n",
      "        [3.4904, 3.7189, 3.7178, 3.7746, 3.5162],\n",
      "        [3.4447, 3.5685, 3.6356, 3.6684, 3.3969],\n",
      "        [3.5980, 3.8238, 3.8246, 3.7493, 3.6677],\n",
      "        [3.9002, 3.9469, 4.0595, 4.1178, 3.8009],\n",
      "        [3.9356, 3.9614, 4.1221, 4.1561, 3.8846],\n",
      "        [3.7118, 3.7310, 4.0029, 4.0114, 3.6522],\n",
      "        [3.8542, 3.8671, 4.1043, 4.1247, 3.7339],\n",
      "        [3.9261, 3.9487, 4.1145, 4.1520, 3.8666],\n",
      "        [3.5433, 3.7188, 3.6961, 3.7447, 3.5695],\n",
      "        [3.6924, 3.8422, 3.8696, 3.8176, 3.7447],\n",
      "        [3.5782, 3.7000, 3.8370, 3.8524, 3.6466],\n",
      "        [3.6031, 3.8294, 3.9708, 3.8937, 3.7239],\n",
      "        [3.6573, 3.6688, 3.9780, 3.8796, 3.6037],\n",
      "        [3.4079, 3.5677, 3.6939, 3.6402, 3.4550],\n",
      "        [3.5608, 3.7365, 3.7138, 3.7709, 3.5842],\n",
      "        [3.4106, 3.6781, 3.7387, 3.6654, 3.4856],\n",
      "        [3.7178, 3.8600, 3.8851, 3.7573, 3.6718],\n",
      "        [3.5840, 3.6884, 3.9454, 3.8016, 3.6613],\n",
      "        [3.7609, 3.9650, 4.0579, 3.8733, 3.5520],\n",
      "        [3.6163, 3.6036, 3.8094, 3.7494, 3.5398],\n",
      "        [3.5328, 3.7050, 3.6933, 3.7300, 3.5580],\n",
      "        [3.5763, 3.6656, 3.8316, 3.6208, 3.4088],\n",
      "        [3.4707, 3.6589, 3.6771, 3.6396, 3.5220],\n",
      "        [3.4945, 3.6084, 3.7682, 3.7007, 3.4918],\n",
      "        [3.4667, 3.6502, 3.6675, 3.6311, 3.5137],\n",
      "        [3.6090, 3.7497, 3.8497, 3.7745, 3.7196],\n",
      "        [3.9338, 3.7946, 4.0370, 4.0422, 3.8233],\n",
      "        [3.4600, 3.6177, 3.6711, 3.6616, 3.4880],\n",
      "        [3.6561, 3.6724, 3.8622, 3.6963, 3.5884],\n",
      "        [3.4894, 3.4978, 3.6639, 3.6370, 3.4243],\n",
      "        [3.6448, 3.9414, 3.9855, 3.8238, 3.7406],\n",
      "        [3.5736, 3.5660, 3.7794, 3.6221, 3.4972],\n",
      "        [3.9380, 3.9506, 4.0739, 4.1273, 3.8956],\n",
      "        [3.4561, 3.5481, 3.6110, 3.6692, 3.4227],\n",
      "        [3.9490, 3.9062, 3.9952, 4.0345, 3.9117],\n",
      "        [3.4967, 3.6172, 3.8081, 3.7076, 3.5622],\n",
      "        [3.4950, 3.6670, 3.6692, 3.6769, 3.5175],\n",
      "        [3.5455, 3.8340, 3.8708, 3.6607, 3.6657],\n",
      "        [3.4146, 3.6999, 3.7797, 3.6210, 3.5227],\n",
      "        [3.9463, 3.8639, 4.0107, 4.0201, 3.8628],\n",
      "        [3.7434, 3.9003, 4.0051, 3.9080, 3.8976],\n",
      "        [3.5669, 3.5749, 3.8061, 3.7219, 3.6698],\n",
      "        [3.6357, 3.6374, 4.0708, 3.8255, 3.7225],\n",
      "        [4.0084, 3.9477, 4.0916, 4.1377, 3.9882],\n",
      "        [3.5326, 3.5903, 3.8129, 3.6985, 3.5512],\n",
      "        [3.9274, 4.1387, 4.0226, 3.9082, 3.8058],\n",
      "        [3.4379, 3.6266, 3.6657, 3.5917, 3.4942],\n",
      "        [3.5298, 3.6749, 3.7641, 3.6727, 3.5605],\n",
      "        [3.5591, 3.6004, 3.7309, 3.6529, 3.6043],\n",
      "        [3.6056, 3.6800, 3.9086, 3.7826, 3.6566],\n",
      "        [3.5306, 3.6319, 3.8067, 3.7120, 3.5642],\n",
      "        [3.5517, 3.6095, 3.8275, 3.7103, 3.5718],\n",
      "        [3.9404, 4.0010, 4.0993, 4.2089, 3.7839]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3783, 3.4565, 3.6635, 3.6345, 3.4211],\n",
      "        [3.4559, 3.5484, 3.7281, 3.6380, 3.4437],\n",
      "        [3.5621, 3.7982, 3.8213, 3.7519, 3.6488],\n",
      "        [3.6492, 3.6666, 3.8577, 3.6910, 3.5693],\n",
      "        [3.5549, 3.9710, 3.8321, 3.7718, 3.7987],\n",
      "        [3.5823, 3.6284, 3.7993, 3.7077, 3.6319],\n",
      "        [3.4583, 3.5416, 3.7150, 3.6487, 3.4718],\n",
      "        [3.5468, 3.5970, 3.8159, 3.7078, 3.5505],\n",
      "        [3.4823, 3.6465, 3.6959, 3.7088, 3.4941],\n",
      "        [3.6443, 3.9863, 3.9515, 3.8772, 3.8133],\n",
      "        [3.4683, 3.6089, 3.7781, 3.7163, 3.5374],\n",
      "        [3.6385, 3.9956, 3.9697, 3.8759, 3.8107],\n",
      "        [3.9693, 4.1228, 4.0473, 4.1404, 4.0994],\n",
      "        [3.4102, 3.5956, 3.7342, 3.6027, 3.4639],\n",
      "        [3.6069, 3.6792, 3.9081, 3.7847, 3.6556],\n",
      "        [3.4906, 3.4970, 3.6635, 3.6390, 3.4234],\n",
      "        [3.6295, 3.9069, 3.8506, 3.9221, 3.7008],\n",
      "        [3.5564, 3.6210, 3.8228, 3.7132, 3.5726],\n",
      "        [3.7048, 3.7940, 3.9310, 3.8609, 3.7983],\n",
      "        [3.6732, 3.9932, 4.0100, 3.9010, 3.8951],\n",
      "        [3.5482, 3.6331, 3.8161, 3.7244, 3.5690],\n",
      "        [3.4212, 3.5737, 3.7300, 3.6089, 3.4627],\n",
      "        [3.4545, 3.8443, 3.8320, 3.5701, 3.6698],\n",
      "        [3.3634, 3.5885, 3.6868, 3.5993, 3.4851],\n",
      "        [3.7308, 3.9946, 4.0827, 3.9305, 3.6271],\n",
      "        [3.7605, 3.7788, 4.0245, 4.0264, 3.6165],\n",
      "        [3.8665, 3.7505, 3.9115, 4.2277, 3.9177],\n",
      "        [3.4092, 3.5206, 3.6630, 3.5703, 3.4491],\n",
      "        [3.4417, 3.6179, 3.6370, 3.6332, 3.4372],\n",
      "        [4.1588, 4.3258, 4.1296, 4.0959, 3.8906],\n",
      "        [3.5652, 3.5590, 3.7866, 3.7175, 3.6638],\n",
      "        [3.7424, 3.9368, 3.9822, 3.8935, 3.7009],\n",
      "        [3.4636, 3.6230, 3.6587, 3.6719, 3.4500],\n",
      "        [3.4094, 3.8847, 3.8840, 3.7011, 3.7496],\n",
      "        [3.8007, 3.8498, 3.9896, 3.9380, 3.8637],\n",
      "        [3.4360, 3.4832, 3.6731, 3.6230, 3.4203],\n",
      "        [3.4094, 3.6240, 3.7139, 3.6475, 3.4588],\n",
      "        [3.4772, 3.6105, 3.7864, 3.7177, 3.5409],\n",
      "        [3.6730, 3.7449, 3.9741, 3.8592, 3.6452],\n",
      "        [3.9789, 3.9774, 3.9755, 4.1008, 3.9914],\n",
      "        [3.6973, 3.8064, 3.9553, 3.9011, 3.8433],\n",
      "        [3.5365, 3.9448, 3.8951, 3.8474, 3.7851],\n",
      "        [3.6395, 3.6197, 3.8055, 3.7191, 3.6431],\n",
      "        [3.8855, 3.7923, 3.8970, 3.9226, 3.8454],\n",
      "        [3.3792, 3.5825, 3.6463, 3.5325, 3.4569],\n",
      "        [3.9316, 3.9562, 4.1216, 4.1651, 3.8779],\n",
      "        [3.6164, 3.6236, 3.8438, 3.7350, 3.6360],\n",
      "        [3.5017, 3.6730, 3.6754, 3.6702, 3.5315],\n",
      "        [3.7479, 3.9096, 3.8733, 3.9287, 3.8038],\n",
      "        [3.6944, 3.8862, 3.8837, 3.8552, 3.6790],\n",
      "        [3.7861, 3.9505, 3.9353, 3.9025, 3.8456],\n",
      "        [3.6029, 3.8342, 3.8141, 3.7356, 3.6282],\n",
      "        [3.5364, 3.6865, 3.7246, 3.7306, 3.5427],\n",
      "        [3.7390, 3.5462, 3.7195, 3.7379, 3.6515],\n",
      "        [3.7435, 3.8453, 3.9876, 3.9211, 3.6362],\n",
      "        [3.3403, 3.5295, 3.6092, 3.4824, 3.4185],\n",
      "        [3.6698, 3.8293, 3.8514, 3.8350, 3.7422],\n",
      "        [3.5542, 3.6703, 3.8405, 3.7444, 3.6021],\n",
      "        [3.6023, 3.7521, 3.8656, 3.8395, 3.6650],\n",
      "        [3.6081, 3.5898, 3.8130, 3.7354, 3.5359],\n",
      "        [3.5646, 3.8880, 3.8936, 3.7436, 3.4978],\n",
      "        [3.4421, 3.5090, 3.6903, 3.6327, 3.4368],\n",
      "        [3.7677, 3.9605, 4.0560, 3.8766, 3.5398],\n",
      "        [3.7923, 3.8748, 4.0439, 3.9577, 3.9147]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3268, 3.5000, 3.5604, 3.5315, 3.3747],\n",
      "        [3.5304, 3.7005, 3.8363, 3.7780, 3.6155],\n",
      "        [3.3781, 3.5997, 3.6723, 3.5923, 3.4622],\n",
      "        [3.5585, 3.5485, 3.7350, 3.6795, 3.6549],\n",
      "        [3.7686, 3.9604, 4.0552, 3.8785, 3.5406],\n",
      "        [3.6948, 3.7221, 3.7986, 3.9408, 3.7170],\n",
      "        [3.5606, 3.7344, 3.6986, 3.7712, 3.5820],\n",
      "        [3.5874, 3.8128, 3.8141, 3.7533, 3.6554],\n",
      "        [3.4397, 3.5253, 3.7017, 3.6230, 3.4496],\n",
      "        [3.8398, 3.8853, 4.1082, 4.1380, 3.7260],\n",
      "        [3.9721, 3.9753, 3.9496, 4.0827, 4.0028],\n",
      "        [3.6813, 3.6974, 3.8614, 3.6720, 3.4679],\n",
      "        [3.8342, 3.8441, 3.9459, 3.9073, 3.8160],\n",
      "        [3.6455, 3.7633, 3.9342, 3.8136, 3.6717],\n",
      "        [3.5904, 3.6484, 3.8487, 3.7658, 3.6203],\n",
      "        [3.5677, 3.7476, 3.7158, 3.7817, 3.5972],\n",
      "        [3.4485, 3.6764, 3.6602, 3.6883, 3.5051],\n",
      "        [3.4440, 3.4997, 3.6847, 3.6452, 3.4398],\n",
      "        [3.8169, 3.8052, 3.9971, 3.9675, 3.7278],\n",
      "        [3.5182, 3.8994, 3.8879, 3.7134, 3.4941],\n",
      "        [3.7381, 3.9029, 3.8695, 3.9254, 3.7866],\n",
      "        [3.6759, 3.7322, 3.8448, 3.7967, 3.6192],\n",
      "        [3.5938, 3.8176, 3.7831, 3.7339, 3.6048],\n",
      "        [3.4822, 3.5571, 3.8140, 3.6761, 3.5270],\n",
      "        [3.5680, 3.7260, 3.8198, 3.7440, 3.6358],\n",
      "        [3.6147, 3.8355, 3.8334, 3.7526, 3.6768],\n",
      "        [3.4398, 3.6356, 3.6650, 3.6034, 3.5024],\n",
      "        [3.7205, 3.8901, 3.8568, 3.9297, 3.8559],\n",
      "        [3.5570, 3.7261, 3.6953, 3.7759, 3.5772],\n",
      "        [3.8394, 3.9702, 4.0026, 3.9461, 3.8418],\n",
      "        [3.5536, 3.6087, 3.7390, 3.7665, 3.5135],\n",
      "        [3.3991, 3.5653, 3.6871, 3.6310, 3.4422],\n",
      "        [3.9550, 3.8860, 3.9962, 4.1262, 3.8518],\n",
      "        [3.5523, 3.6186, 3.8258, 3.7358, 3.6420],\n",
      "        [3.5930, 4.0012, 3.9174, 3.9129, 3.8048],\n",
      "        [3.5134, 3.5261, 3.7829, 3.6976, 3.5980],\n",
      "        [3.7850, 3.8815, 4.0364, 3.9666, 3.9109],\n",
      "        [3.8314, 3.8481, 3.8326, 3.9077, 3.8202],\n",
      "        [3.6065, 4.0170, 3.9216, 3.9456, 3.7942],\n",
      "        [3.6577, 3.6811, 3.8687, 3.6949, 3.5822],\n",
      "        [3.5073, 3.5386, 3.7795, 3.6611, 3.5125],\n",
      "        [3.6710, 3.8291, 3.8506, 3.8368, 3.7431],\n",
      "        [3.3809, 3.4916, 3.6731, 3.5622, 3.3867],\n",
      "        [3.6470, 3.8837, 3.9195, 3.8804, 3.6563],\n",
      "        [3.9065, 3.9445, 4.0907, 4.1106, 3.8703],\n",
      "        [3.4674, 3.8702, 3.9546, 3.7534, 3.7610],\n",
      "        [3.4652, 3.6898, 3.8754, 3.7049, 3.6374],\n",
      "        [3.5120, 3.9457, 3.9577, 3.8351, 3.8050],\n",
      "        [3.7167, 3.8747, 3.9623, 3.9830, 3.6919],\n",
      "        [3.6389, 3.8475, 3.8539, 3.7533, 3.6823],\n",
      "        [3.5650, 3.8037, 3.8970, 3.7762, 3.5731],\n",
      "        [3.8945, 3.7753, 4.0041, 4.0503, 3.7696],\n",
      "        [3.9647, 3.9669, 4.0350, 4.1127, 3.9396],\n",
      "        [3.4957, 3.7316, 3.8798, 3.8243, 3.5172],\n",
      "        [3.5454, 3.7358, 3.8821, 3.9246, 3.5391],\n",
      "        [3.7981, 3.9573, 3.9438, 3.9054, 3.8504],\n",
      "        [3.5861, 3.6353, 3.8486, 3.7333, 3.6255],\n",
      "        [4.0901, 4.1410, 4.1937, 4.3727, 3.8764],\n",
      "        [3.5963, 3.7232, 3.8025, 3.7125, 3.6110],\n",
      "        [3.4244, 3.5488, 3.6771, 3.5980, 3.4703],\n",
      "        [3.4240, 3.7138, 3.7853, 3.6363, 3.5335],\n",
      "        [3.4579, 3.6375, 3.6654, 3.6227, 3.5011],\n",
      "        [3.5756, 3.7560, 3.8500, 3.7326, 3.7117],\n",
      "        [3.4422, 3.5133, 3.6952, 3.6289, 3.4420]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5310, 3.9663, 3.8178, 3.7434, 3.7786],\n",
      "        [3.8053, 3.8484, 3.9916, 4.0129, 3.7495],\n",
      "        [3.4991, 3.7597, 3.8832, 3.7028, 3.6637],\n",
      "        [3.4445, 3.6319, 3.6663, 3.6037, 3.5040],\n",
      "        [3.4089, 3.5816, 3.7224, 3.6009, 3.4605],\n",
      "        [3.4711, 3.8689, 3.8396, 3.6496, 3.4617],\n",
      "        [3.6149, 3.6025, 3.8188, 3.7464, 3.5470],\n",
      "        [3.8962, 3.7951, 3.9083, 3.9358, 3.8478],\n",
      "        [4.0624, 4.1348, 4.2273, 4.3844, 4.0423],\n",
      "        [3.6932, 3.9271, 3.9856, 3.9116, 3.7932],\n",
      "        [3.4724, 3.7955, 3.8306, 3.7444, 3.7526],\n",
      "        [3.4337, 3.7860, 3.6917, 3.4878, 3.5775],\n",
      "        [3.8726, 3.8012, 4.0129, 4.0157, 3.7604],\n",
      "        [3.5616, 3.5989, 3.7286, 3.6574, 3.6049],\n",
      "        [3.5612, 3.7339, 3.6976, 3.7723, 3.5825],\n",
      "        [3.9663, 4.1111, 3.8836, 3.9055, 3.7185],\n",
      "        [3.8193, 3.9693, 4.1029, 4.1421, 4.0873],\n",
      "        [3.8965, 3.7800, 4.0073, 4.0554, 3.7758],\n",
      "        [4.0229, 4.1084, 4.1641, 4.2984, 4.0000],\n",
      "        [3.5443, 3.7345, 3.8829, 3.8441, 3.5811],\n",
      "        [3.4722, 3.5539, 3.7291, 3.6457, 3.4616],\n",
      "        [3.5587, 3.6276, 3.8787, 3.7634, 3.6144],\n",
      "        [3.4553, 3.5044, 3.6907, 3.6567, 3.4568],\n",
      "        [3.4319, 3.5264, 3.6993, 3.6222, 3.4466],\n",
      "        [3.7784, 3.8417, 3.9666, 3.9558, 3.8525],\n",
      "        [3.5784, 3.7001, 3.8415, 3.8812, 3.6316],\n",
      "        [3.5405, 3.8469, 3.8795, 3.6684, 3.6555],\n",
      "        [3.7193, 3.8425, 3.9511, 3.7916, 3.7127],\n",
      "        [3.4976, 3.4975, 3.8060, 3.4963, 3.6005],\n",
      "        [3.4558, 3.7049, 3.9717, 3.7025, 3.7180],\n",
      "        [3.8684, 3.8893, 4.0455, 4.0382, 3.6718],\n",
      "        [3.6330, 3.9184, 3.8908, 3.8535, 3.8005],\n",
      "        [3.6981, 3.9028, 3.8800, 3.9904, 3.7554],\n",
      "        [3.7017, 3.7254, 3.8851, 3.7545, 3.5540],\n",
      "        [3.8733, 3.9421, 4.0456, 4.0151, 4.0326],\n",
      "        [3.9633, 3.8945, 4.0045, 4.1261, 3.8536],\n",
      "        [3.4375, 3.6085, 3.7648, 3.6451, 3.4698],\n",
      "        [3.5805, 3.6418, 3.8231, 3.7423, 3.6071],\n",
      "        [3.5236, 3.5338, 3.7909, 3.6991, 3.5963],\n",
      "        [3.5570, 3.6249, 3.8175, 3.7164, 3.5800],\n",
      "        [3.4285, 3.6388, 3.6717, 3.5966, 3.5041],\n",
      "        [3.5736, 3.6773, 3.8189, 3.7239, 3.7296],\n",
      "        [3.6392, 3.8586, 3.8836, 3.8603, 3.6517],\n",
      "        [3.4080, 3.6494, 3.7544, 3.6186, 3.4932],\n",
      "        [3.7162, 3.8590, 3.8833, 3.7591, 3.6709],\n",
      "        [3.7669, 3.8024, 3.8992, 3.9340, 3.8327],\n",
      "        [3.3675, 3.5523, 3.5644, 3.5331, 3.3861],\n",
      "        [3.5834, 3.7698, 3.8551, 3.7393, 3.7350],\n",
      "        [3.6135, 3.6802, 3.9152, 3.7923, 3.6543],\n",
      "        [3.4581, 3.5458, 3.6086, 3.6737, 3.4225],\n",
      "        [3.5812, 3.7445, 3.8268, 3.7565, 3.6539],\n",
      "        [3.4161, 3.6179, 3.6721, 3.5748, 3.4960],\n",
      "        [3.5842, 3.6346, 3.8343, 3.7565, 3.6412],\n",
      "        [3.6508, 3.8393, 3.8438, 3.8325, 3.6814],\n",
      "        [3.6750, 3.7035, 3.8770, 3.7375, 3.5433],\n",
      "        [3.4445, 3.6319, 3.6663, 3.6037, 3.5040],\n",
      "        [3.6961, 3.9004, 3.8784, 3.9890, 3.7519],\n",
      "        [3.3282, 3.6035, 3.8358, 3.5641, 3.5674],\n",
      "        [3.4906, 3.5688, 3.8204, 3.6891, 3.5360],\n",
      "        [3.6867, 3.9807, 4.0084, 3.9063, 3.8791],\n",
      "        [3.5862, 3.6230, 3.8685, 3.7439, 3.6301],\n",
      "        [3.3649, 3.5632, 3.6302, 3.5066, 3.4395],\n",
      "        [3.9775, 4.1162, 4.0396, 4.1428, 4.0924],\n",
      "        [3.5991, 3.9105, 3.7735, 3.7874, 3.6130]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5734, 3.7077, 3.7535, 3.7960, 3.6010],\n",
      "        [3.7814, 3.8695, 4.0566, 3.9768, 3.9166],\n",
      "        [3.9533, 3.8967, 4.0240, 4.1249, 3.8862],\n",
      "        [3.4323, 3.5258, 3.6980, 3.6234, 3.4468],\n",
      "        [3.3823, 3.5811, 3.6462, 3.5309, 3.4627],\n",
      "        [3.5599, 3.6998, 3.7350, 3.7317, 3.6033],\n",
      "        [3.6951, 3.8811, 3.9881, 3.8760, 3.6721],\n",
      "        [3.6973, 3.9185, 3.9849, 3.9184, 3.7773],\n",
      "        [3.4394, 3.6218, 3.7855, 3.6535, 3.4909],\n",
      "        [3.8257, 3.8468, 4.0920, 4.1106, 3.6840],\n",
      "        [3.5505, 3.6128, 3.8623, 3.7557, 3.6067],\n",
      "        [3.5857, 3.6840, 3.8476, 3.6465, 3.4198],\n",
      "        [3.4588, 3.6364, 3.6634, 3.6250, 3.5018],\n",
      "        [3.4542, 3.4955, 3.6840, 3.6414, 3.4357],\n",
      "        [3.3945, 3.5049, 3.6516, 3.5560, 3.4357],\n",
      "        [3.9278, 3.8149, 4.0436, 4.3996, 4.1333],\n",
      "        [3.5843, 3.6312, 3.8369, 3.7025, 3.6239],\n",
      "        [3.5475, 3.6281, 3.8041, 3.7123, 3.5684],\n",
      "        [3.4835, 3.6506, 3.6624, 3.6473, 3.5079],\n",
      "        [3.4746, 3.9002, 3.9227, 3.7902, 3.7609],\n",
      "        [3.5418, 3.6419, 3.8122, 3.7283, 3.5724],\n",
      "        [3.5629, 3.6803, 3.7577, 3.6545, 3.5834],\n",
      "        [3.4413, 3.5281, 3.6988, 3.6289, 3.4525],\n",
      "        [3.6447, 3.7562, 3.7781, 3.8128, 3.6541],\n",
      "        [3.5916, 3.8954, 3.8020, 3.8966, 3.6813],\n",
      "        [4.1191, 4.2816, 4.0312, 4.0164, 3.7732],\n",
      "        [3.8312, 3.9554, 3.9713, 3.9543, 3.8648],\n",
      "        [3.6027, 3.6197, 3.8582, 3.7453, 3.6298],\n",
      "        [3.9825, 4.0388, 4.1255, 4.2535, 3.9551],\n",
      "        [3.3325, 3.5293, 3.6089, 3.4706, 3.4075],\n",
      "        [3.6670, 3.7775, 3.8702, 3.9465, 3.6446],\n",
      "        [3.6076, 4.0159, 3.9192, 3.9481, 3.7949],\n",
      "        [3.5502, 3.6394, 3.8169, 3.7340, 3.5740],\n",
      "        [3.6239, 3.7467, 3.8555, 3.7765, 3.7274],\n",
      "        [3.5816, 3.8252, 3.8240, 3.7088, 3.6487],\n",
      "        [3.5300, 3.6960, 3.6928, 3.7181, 3.5631],\n",
      "        [3.4163, 3.6199, 3.7504, 3.6224, 3.4897],\n",
      "        [3.4648, 3.5365, 3.7938, 3.6554, 3.5179],\n",
      "        [3.4952, 3.6083, 3.7468, 3.6226, 3.5397],\n",
      "        [3.5985, 3.6325, 3.8837, 3.8156, 3.6227],\n",
      "        [3.5145, 3.5250, 3.7806, 3.6998, 3.5988],\n",
      "        [3.4565, 3.8429, 3.8287, 3.5744, 3.6711],\n",
      "        [3.5423, 3.5627, 3.8310, 3.5928, 3.6186],\n",
      "        [3.5605, 3.5960, 3.7270, 3.6588, 3.6019],\n",
      "        [3.4559, 3.6688, 3.7027, 3.7276, 3.4964],\n",
      "        [3.6966, 3.8998, 3.8772, 3.9904, 3.7521],\n",
      "        [3.5303, 3.6310, 3.9325, 3.5700, 3.7229],\n",
      "        [3.7929, 3.6979, 3.8679, 4.1261, 3.8400],\n",
      "        [3.8876, 3.7908, 3.8938, 3.9267, 3.8481],\n",
      "        [3.5221, 3.8588, 3.7776, 3.5754, 3.6522],\n",
      "        [3.5676, 3.6746, 3.9148, 3.8733, 3.7947],\n",
      "        [3.4514, 3.8456, 3.8261, 3.5792, 3.6793],\n",
      "        [3.5720, 3.7003, 3.7893, 3.6757, 3.4993],\n",
      "        [3.6547, 3.7323, 3.8302, 3.7805, 3.6242],\n",
      "        [3.4450, 3.4986, 3.6823, 3.6474, 3.4407],\n",
      "        [3.3781, 3.5726, 3.6350, 3.5262, 3.4515],\n",
      "        [4.0031, 4.1037, 4.1401, 4.2734, 3.9793],\n",
      "        [3.6177, 3.7285, 3.8183, 3.7464, 3.6197],\n",
      "        [3.4665, 3.6011, 3.7843, 3.7081, 3.5542],\n",
      "        [3.9523, 3.9038, 3.9916, 4.0408, 3.9136],\n",
      "        [3.5727, 3.6293, 3.8215, 3.7364, 3.6050],\n",
      "        [3.5603, 3.8301, 3.8075, 3.6977, 3.6349],\n",
      "        [3.5708, 3.7057, 3.7938, 3.6835, 3.4994],\n",
      "        [3.3977, 3.5694, 3.6823, 3.6372, 3.4427]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6894, 3.8564, 3.9869, 3.8458, 3.6996],\n",
      "        [3.4365, 3.6502, 3.6962, 3.6985, 3.4949],\n",
      "        [3.4326, 3.6019, 3.7597, 3.6409, 3.4642],\n",
      "        [3.4340, 3.5651, 3.7397, 3.6345, 3.4461],\n",
      "        [3.6982, 3.9013, 3.8772, 3.9928, 3.7565],\n",
      "        [3.9333, 3.9494, 4.1109, 4.1622, 3.8752],\n",
      "        [3.5858, 3.8998, 3.7607, 3.7602, 3.6028],\n",
      "        [3.7813, 3.8687, 4.0551, 3.9779, 3.9175],\n",
      "        [3.6426, 3.6964, 3.8964, 3.8052, 3.7496],\n",
      "        [3.7496, 3.9078, 3.8684, 3.9334, 3.8064],\n",
      "        [3.7408, 3.5439, 3.7152, 3.7426, 3.6554],\n",
      "        [3.7037, 3.9969, 3.9114, 3.8964, 3.7268],\n",
      "        [3.5298, 3.6952, 3.6909, 3.7209, 3.5631],\n",
      "        [3.6356, 3.7968, 3.9883, 3.8480, 3.7137],\n",
      "        [3.5865, 3.6758, 3.8188, 3.7207, 3.7530],\n",
      "        [3.5436, 3.5743, 3.7768, 3.6500, 3.5109],\n",
      "        [3.9267, 3.9408, 4.1001, 4.1475, 3.8649],\n",
      "        [3.4947, 3.6397, 3.7994, 3.7474, 3.5519],\n",
      "        [3.6043, 3.8313, 3.8130, 3.7362, 3.6352],\n",
      "        [3.5463, 3.6271, 3.8065, 3.7188, 3.5746],\n",
      "        [3.7031, 3.8864, 3.8759, 3.8631, 3.6828],\n",
      "        [3.5449, 3.5594, 3.8297, 3.5951, 3.6198],\n",
      "        [3.5970, 3.6683, 3.9166, 3.9201, 3.8303],\n",
      "        [3.5459, 3.6555, 3.8194, 3.7406, 3.5816],\n",
      "        [3.4735, 3.7029, 3.8744, 3.7076, 3.6454],\n",
      "        [3.6711, 3.8760, 3.8488, 3.9562, 3.7142],\n",
      "        [3.8138, 4.0456, 3.9547, 3.9964, 4.0059],\n",
      "        [3.7434, 3.8474, 3.9970, 3.9591, 3.8834],\n",
      "        [3.7057, 3.9720, 3.9343, 3.8766, 3.7445],\n",
      "        [3.7659, 3.8749, 4.0168, 4.0308, 3.7018],\n",
      "        [3.4339, 3.4758, 3.6654, 3.6244, 3.4200],\n",
      "        [3.8172, 3.8587, 4.0647, 4.1380, 3.7526],\n",
      "        [3.5969, 3.7213, 3.7984, 3.7155, 3.6128],\n",
      "        [3.5529, 3.6546, 3.8254, 3.7448, 3.5983],\n",
      "        [3.9267, 3.9408, 4.1001, 4.1475, 3.8649],\n",
      "        [3.9644, 3.8931, 4.0017, 4.1282, 3.8552],\n",
      "        [3.4354, 3.6035, 3.7382, 3.6268, 3.5024],\n",
      "        [3.7727, 4.0496, 4.0080, 4.0431, 3.8467],\n",
      "        [3.4557, 3.9040, 3.7600, 3.6465, 3.6644],\n",
      "        [3.5422, 3.6358, 3.8108, 3.5961, 3.3743],\n",
      "        [3.7659, 3.9779, 3.8727, 3.8217, 3.7063],\n",
      "        [3.7963, 3.6847, 3.8701, 4.1454, 3.8453],\n",
      "        [3.7087, 3.9041, 3.8944, 3.8977, 3.7150],\n",
      "        [3.8079, 3.9598, 3.9449, 3.9385, 3.8688],\n",
      "        [3.4908, 3.5673, 3.8177, 3.6910, 3.5370],\n",
      "        [3.8231, 3.8837, 4.0176, 4.0779, 3.9976],\n",
      "        [3.6851, 4.0241, 4.0175, 3.9087, 3.8284],\n",
      "        [3.5125, 3.7244, 3.8898, 3.7810, 3.5245],\n",
      "        [3.5486, 3.7173, 3.6929, 3.7599, 3.5707],\n",
      "        [3.5363, 3.7065, 3.6931, 3.7286, 3.5664],\n",
      "        [3.4478, 3.5258, 3.6964, 3.6356, 3.4505],\n",
      "        [3.4622, 3.6239, 3.6705, 3.6805, 3.4813],\n",
      "        [3.4670, 3.6587, 3.8271, 3.6874, 3.4998],\n",
      "        [3.5425, 3.9207, 3.9357, 3.8393, 3.7976],\n",
      "        [3.6756, 3.6929, 3.8593, 3.6569, 3.4678],\n",
      "        [3.7010, 3.7822, 3.7522, 3.8708, 3.7508],\n",
      "        [3.6791, 4.0028, 3.9420, 3.9024, 3.7526],\n",
      "        [3.7916, 3.7455, 3.8767, 3.7897, 3.6048],\n",
      "        [4.0033, 4.1029, 4.1386, 4.2742, 3.9804],\n",
      "        [3.5752, 3.7343, 3.9773, 3.8201, 3.7403],\n",
      "        [3.7248, 3.8138, 4.0123, 3.8382, 3.5757],\n",
      "        [3.5095, 3.6808, 3.6769, 3.7012, 3.5355],\n",
      "        [3.4365, 3.5441, 3.7131, 3.6221, 3.4594],\n",
      "        [3.8324, 3.8466, 3.8287, 3.9104, 3.8222]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5494, 3.9060, 3.9001, 3.8544, 3.7844],\n",
      "        [3.5430, 3.6081, 3.8054, 3.7165, 3.5719],\n",
      "        [3.6723, 3.7418, 3.8792, 3.7794, 3.7409],\n",
      "        [3.7366, 3.9457, 3.9722, 3.9057, 3.7116],\n",
      "        [3.5569, 3.7230, 3.6886, 3.7644, 3.5743],\n",
      "        [3.5656, 3.6754, 3.8382, 3.7712, 3.6144],\n",
      "        [3.4854, 3.6250, 3.7888, 3.7494, 3.5504],\n",
      "        [3.5486, 3.6099, 3.7990, 3.7120, 3.5718],\n",
      "        [3.7604, 3.9154, 3.8781, 3.9443, 3.7989],\n",
      "        [3.6391, 3.7304, 3.8304, 3.7603, 3.6326],\n",
      "        [3.9408, 3.8797, 3.9537, 4.0272, 3.8869],\n",
      "        [3.4072, 3.5971, 3.7265, 3.6029, 3.4669],\n",
      "        [3.6735, 4.0795, 3.9553, 4.0117, 3.8462],\n",
      "        [3.5639, 3.6021, 3.7313, 3.6679, 3.6185],\n",
      "        [3.5486, 3.7581, 3.8334, 3.7965, 3.6367],\n",
      "        [3.4901, 3.8071, 3.8294, 3.7665, 3.7216],\n",
      "        [3.5495, 3.6298, 3.8096, 3.7296, 3.5722],\n",
      "        [3.7375, 3.8735, 3.9812, 4.0064, 3.6966],\n",
      "        [3.9706, 3.9696, 3.9596, 4.0943, 3.9910],\n",
      "        [3.4490, 3.6503, 3.7945, 3.6662, 3.5069],\n",
      "        [3.7334, 3.8585, 3.9827, 3.9279, 3.6681],\n",
      "        [3.4402, 3.5993, 3.7161, 3.6165, 3.4970],\n",
      "        [3.5358, 3.7815, 3.8727, 3.7319, 3.6180],\n",
      "        [3.5477, 3.7189, 3.6969, 3.7481, 3.5772],\n",
      "        [3.7086, 3.8964, 3.9744, 3.9101, 3.7481],\n",
      "        [3.4970, 3.6046, 3.7622, 3.7080, 3.4939],\n",
      "        [3.4731, 3.6498, 3.6707, 3.6279, 3.5266],\n",
      "        [3.9304, 3.9444, 4.1080, 4.1613, 3.8689],\n",
      "        [3.7176, 3.7258, 3.8155, 4.0017, 3.7599],\n",
      "        [3.5493, 3.5332, 3.7103, 3.6633, 3.6467],\n",
      "        [3.8381, 3.9248, 4.0307, 3.9907, 4.0130],\n",
      "        [3.7292, 3.8752, 3.9801, 3.9206, 3.6965],\n",
      "        [4.0740, 4.3253, 3.9761, 4.0264, 3.7731],\n",
      "        [3.4552, 3.6210, 3.6360, 3.6474, 3.4509],\n",
      "        [3.9490, 3.8597, 4.0040, 4.0280, 3.8671],\n",
      "        [3.5763, 3.5621, 3.7727, 3.6288, 3.4995],\n",
      "        [3.4541, 3.6272, 3.6410, 3.6808, 3.4969],\n",
      "        [3.9527, 3.9574, 3.9219, 4.0821, 4.0111],\n",
      "        [3.8871, 3.7890, 3.8908, 3.9281, 3.8506],\n",
      "        [3.5791, 3.9840, 3.8921, 3.9114, 3.7786],\n",
      "        [3.6068, 4.0141, 3.9161, 3.9493, 3.7963],\n",
      "        [3.5610, 3.7318, 3.6961, 3.7600, 3.5879],\n",
      "        [3.5715, 3.5681, 3.7805, 3.7186, 3.6800],\n",
      "        [3.7426, 3.5917, 3.7182, 3.7221, 3.7031],\n",
      "        [4.2769, 4.4559, 4.1765, 4.1717, 3.9160],\n",
      "        [3.7093, 3.8876, 3.8817, 3.8987, 3.7130],\n",
      "        [3.5386, 3.5210, 3.6928, 3.6437, 3.6382],\n",
      "        [3.5125, 3.9428, 3.9523, 3.8387, 3.8073],\n",
      "        [3.5230, 3.9994, 3.8630, 3.7678, 3.8467],\n",
      "        [3.5883, 3.8810, 3.8953, 3.7685, 3.5109],\n",
      "        [3.4936, 3.6551, 3.7056, 3.6730, 3.5604],\n",
      "        [3.4364, 3.5550, 3.7232, 3.6422, 3.4703],\n",
      "        [4.1935, 4.4343, 4.0834, 4.1309, 3.8618],\n",
      "        [3.4167, 3.6848, 3.7690, 3.6277, 3.5177],\n",
      "        [3.4551, 3.6672, 3.6999, 3.7287, 3.4977],\n",
      "        [3.5720, 3.6276, 3.8184, 3.7375, 3.6068],\n",
      "        [3.4052, 3.6838, 3.7589, 3.6102, 3.4987],\n",
      "        [3.3541, 3.6321, 3.5472, 3.6232, 3.3917],\n",
      "        [3.5796, 3.6065, 3.8567, 3.7757, 3.6967],\n",
      "        [3.4867, 3.5007, 3.6712, 3.6441, 3.4348],\n",
      "        [3.5950, 3.8148, 3.7782, 3.7383, 3.6072],\n",
      "        [3.5407, 3.6490, 3.8167, 3.7421, 3.5866],\n",
      "        [3.5540, 3.6058, 3.7338, 3.7700, 3.5158],\n",
      "        [3.5110, 3.5138, 3.8126, 3.5271, 3.6102]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7080, 3.8950, 3.9734, 3.9110, 3.7494],\n",
      "        [3.3901, 3.4979, 3.6433, 3.5499, 3.4346],\n",
      "        [3.5630, 3.7961, 3.9206, 3.7877, 3.5540],\n",
      "        [3.3833, 3.5776, 3.6372, 3.5443, 3.4649],\n",
      "        [3.4068, 3.6458, 3.7495, 3.6218, 3.4958],\n",
      "        [3.3635, 3.6046, 3.6589, 3.5914, 3.4653],\n",
      "        [3.6613, 3.7664, 3.8062, 3.7756, 3.6211],\n",
      "        [3.9706, 3.9663, 3.9757, 4.0975, 3.9830],\n",
      "        [3.5620, 3.5477, 3.7533, 3.7049, 3.6681],\n",
      "        [3.4300, 3.4753, 3.6621, 3.6276, 3.4223],\n",
      "        [4.0133, 4.1738, 4.0081, 3.9613, 3.7902],\n",
      "        [3.5427, 3.6457, 3.8139, 3.7460, 3.5837],\n",
      "        [3.5577, 3.6238, 3.8733, 3.7666, 3.6174],\n",
      "        [3.4498, 3.6353, 3.8066, 3.6828, 3.4770],\n",
      "        [3.7469, 3.5516, 3.7199, 3.7386, 3.6654],\n",
      "        [3.5654, 3.5970, 3.8286, 3.6633, 3.6204],\n",
      "        [3.6929, 3.8076, 3.8125, 3.8737, 3.7178],\n",
      "        [3.4605, 3.5655, 3.6078, 3.6827, 3.4602],\n",
      "        [3.4837, 3.6001, 3.7857, 3.7124, 3.5522],\n",
      "        [3.6091, 3.8288, 3.8010, 3.7499, 3.6289],\n",
      "        [3.6473, 3.8752, 3.9132, 3.8784, 3.6681],\n",
      "        [3.8125, 4.0070, 4.0615, 4.0237, 3.8754],\n",
      "        [3.8578, 3.8822, 4.0212, 4.0572, 3.8037],\n",
      "        [3.6729, 3.7072, 3.8151, 3.9148, 3.7006],\n",
      "        [3.5675, 3.5987, 3.8309, 3.6671, 3.6195],\n",
      "        [3.4260, 3.5526, 3.7121, 3.6147, 3.4623],\n",
      "        [3.4916, 3.4757, 3.6448, 3.6393, 3.4234],\n",
      "        [3.4609, 3.5355, 3.7175, 3.6491, 3.4467],\n",
      "        [3.4790, 3.5916, 3.7548, 3.7103, 3.4779],\n",
      "        [3.6505, 3.5439, 3.9405, 3.8105, 3.6411],\n",
      "        [3.5160, 3.7009, 3.9586, 3.7659, 3.7128],\n",
      "        [3.5958, 3.7190, 3.7958, 3.7167, 3.6148],\n",
      "        [3.6801, 3.9971, 4.0120, 3.9204, 3.9064],\n",
      "        [3.8588, 3.9703, 3.9605, 3.9850, 3.8875],\n",
      "        [3.5564, 3.7678, 3.8545, 3.7513, 3.6180],\n",
      "        [3.5516, 3.7721, 3.7400, 3.8600, 3.5415],\n",
      "        [3.6040, 3.9698, 4.0046, 3.9038, 3.8458],\n",
      "        [4.0073, 3.9889, 4.1418, 4.2637, 3.9754],\n",
      "        [3.7078, 3.7611, 3.8717, 3.7860, 3.4760],\n",
      "        [3.4731, 3.6873, 3.6969, 3.7539, 3.5067],\n",
      "        [3.5742, 3.6368, 3.8793, 3.7553, 3.6374],\n",
      "        [3.4276, 3.6160, 3.6577, 3.5867, 3.4990],\n",
      "        [3.6149, 3.6732, 3.8261, 3.7979, 3.6191],\n",
      "        [3.6269, 4.0216, 3.9223, 3.9599, 3.8143],\n",
      "        [3.8597, 3.8468, 3.9448, 3.9411, 3.8301],\n",
      "        [3.5511, 4.0360, 4.0172, 3.7631, 3.6244],\n",
      "        [4.2762, 4.4546, 4.1754, 4.1725, 3.9174],\n",
      "        [3.4958, 3.6275, 3.7043, 3.7496, 3.5456],\n",
      "        [3.6643, 3.5330, 3.9625, 3.8197, 3.6402],\n",
      "        [3.8326, 3.9381, 4.0877, 3.9326, 3.6487],\n",
      "        [4.0733, 4.2428, 3.9978, 3.9956, 3.7539],\n",
      "        [3.4031, 3.5120, 3.6858, 3.5857, 3.4248],\n",
      "        [3.7167, 3.7257, 3.9959, 4.0223, 3.6559],\n",
      "        [3.8874, 3.8510, 3.9383, 3.9600, 3.8282],\n",
      "        [3.7497, 4.0843, 4.0330, 4.0802, 3.9104],\n",
      "        [3.3361, 3.5080, 3.5763, 3.5314, 3.4003],\n",
      "        [3.5905, 3.6342, 3.8468, 3.7418, 3.6345],\n",
      "        [3.3290, 3.5154, 3.5975, 3.4671, 3.3997],\n",
      "        [3.9817, 4.0355, 4.1216, 4.2563, 3.9581],\n",
      "        [3.3776, 3.5644, 3.5418, 3.6140, 3.4137],\n",
      "        [3.4046, 3.5916, 3.7220, 3.6048, 3.4677],\n",
      "        [3.7126, 3.8843, 3.9500, 3.9855, 3.7076],\n",
      "        [3.8374, 3.8732, 3.9989, 4.0862, 3.9973],\n",
      "        [3.9287, 4.0541, 4.0554, 4.0456, 3.9704]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4384, 3.4888, 3.6727, 3.6372, 3.4343],\n",
      "        [3.5647, 3.7691, 3.7309, 3.8717, 3.5455],\n",
      "        [3.6203, 3.6136, 4.0506, 3.8135, 3.6998],\n",
      "        [3.7881, 3.8269, 3.9620, 3.9301, 3.8679],\n",
      "        [3.6192, 3.9516, 4.0252, 3.9256, 3.8224],\n",
      "        [3.6597, 3.6620, 3.9695, 3.8886, 3.6087],\n",
      "        [4.0455, 4.2428, 4.3127, 4.2994, 4.2818],\n",
      "        [3.7390, 3.7352, 3.8463, 4.0538, 3.8002],\n",
      "        [3.6170, 3.6670, 3.9182, 3.9132, 3.8379],\n",
      "        [3.4885, 3.5836, 3.7971, 3.7112, 3.6344],\n",
      "        [3.9426, 3.9425, 4.0820, 4.1537, 3.8895],\n",
      "        [3.5262, 3.6492, 3.7418, 3.6991, 3.6332],\n",
      "        [3.7579, 3.6069, 3.7346, 3.7335, 3.7292],\n",
      "        [3.6218, 3.6078, 4.0481, 3.8098, 3.6945],\n",
      "        [3.5875, 3.6438, 3.8300, 3.7648, 3.6242],\n",
      "        [3.5391, 3.8416, 3.8724, 3.6720, 3.6605],\n",
      "        [3.4135, 3.6456, 3.7472, 3.6180, 3.4986],\n",
      "        [3.8850, 4.0151, 4.0109, 4.0027, 3.9322],\n",
      "        [3.6307, 3.8628, 3.9031, 3.8035, 3.5415],\n",
      "        [3.7147, 3.9451, 3.9096, 3.8880, 3.7321],\n",
      "        [3.5816, 3.9072, 3.9267, 3.8862, 3.8205],\n",
      "        [3.8102, 3.8826, 4.0651, 4.0676, 3.7256],\n",
      "        [3.5334, 3.5615, 3.8001, 3.6923, 3.5411],\n",
      "        [3.5542, 3.7788, 3.8106, 3.7797, 3.6558],\n",
      "        [3.7090, 3.9044, 3.8954, 3.8923, 3.7234],\n",
      "        [3.6971, 3.8973, 3.8734, 3.9946, 3.7601],\n",
      "        [3.6375, 3.6303, 4.0619, 3.8349, 3.7271],\n",
      "        [3.7363, 3.7206, 3.8578, 4.0836, 3.8185],\n",
      "        [3.4093, 3.5953, 3.6922, 3.6447, 3.4554],\n",
      "        [3.5346, 3.6981, 3.6851, 3.7390, 3.5630],\n",
      "        [3.4161, 3.6820, 3.7670, 3.6289, 3.5205],\n",
      "        [3.5804, 3.8205, 3.8188, 3.7116, 3.6534],\n",
      "        [3.9966, 4.0612, 4.0561, 4.2870, 3.9782],\n",
      "        [3.4818, 3.9071, 3.8657, 3.7889, 3.7788],\n",
      "        [3.4328, 3.7793, 3.8477, 3.6296, 3.6546],\n",
      "        [3.7569, 3.8905, 3.9882, 3.8676, 3.5969],\n",
      "        [3.7244, 3.9398, 3.9772, 3.9127, 3.7277],\n",
      "        [3.7266, 3.8682, 3.8760, 3.8056, 3.6938],\n",
      "        [3.9210, 4.1055, 3.9675, 3.8934, 3.7591],\n",
      "        [3.7170, 3.8131, 3.9599, 3.8370, 3.7082],\n",
      "        [3.7601, 4.0337, 3.9820, 4.0245, 3.8414],\n",
      "        [3.5686, 3.6926, 3.7335, 3.7929, 3.5975],\n",
      "        [3.8123, 3.7001, 3.8717, 4.1671, 3.8684],\n",
      "        [3.6041, 3.9682, 4.0036, 3.9043, 3.8481],\n",
      "        [3.3965, 3.5862, 3.6400, 3.5546, 3.4729],\n",
      "        [3.4542, 3.4971, 3.6817, 3.6358, 3.4525],\n",
      "        [3.5851, 3.8886, 3.9317, 3.8720, 3.8184],\n",
      "        [3.7963, 4.0783, 4.0100, 4.0424, 3.9252],\n",
      "        [3.6692, 3.8555, 3.8963, 3.8243, 3.7971],\n",
      "        [3.4046, 3.5053, 3.6435, 3.6423, 3.4382],\n",
      "        [3.6043, 3.8258, 3.8036, 3.7512, 3.6361],\n",
      "        [3.5475, 3.5581, 3.6872, 3.7871, 3.4769],\n",
      "        [3.6159, 3.6073, 3.8225, 3.7578, 3.5671],\n",
      "        [3.5947, 3.8120, 3.7763, 3.7399, 3.6102],\n",
      "        [3.5550, 3.8033, 3.9354, 3.7937, 3.5501],\n",
      "        [3.3485, 3.4564, 3.6146, 3.4987, 3.3922],\n",
      "        [3.5305, 3.6319, 3.8054, 3.7332, 3.5743],\n",
      "        [3.4361, 3.9001, 3.9058, 3.7359, 3.7702],\n",
      "        [3.4014, 3.5928, 3.6434, 3.5568, 3.4744],\n",
      "        [3.8169, 3.8548, 4.0612, 4.1403, 3.7563],\n",
      "        [3.5905, 3.6830, 3.8330, 3.6595, 3.4288],\n",
      "        [3.5286, 3.6914, 3.6879, 3.7207, 3.5675],\n",
      "        [3.6927, 3.9217, 3.9789, 3.9155, 3.7983],\n",
      "        [3.5653, 3.5838, 3.7061, 3.7903, 3.5033]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3479, 3.5386, 3.6119, 3.4936, 3.4353],\n",
      "        [3.5396, 3.6772, 3.7092, 3.7155, 3.5886],\n",
      "        [3.4161, 3.5757, 3.5956, 3.5922, 3.4227],\n",
      "        [3.5511, 3.6643, 3.7625, 3.7883, 3.6140],\n",
      "        [3.9205, 4.0386, 4.0347, 4.0294, 3.9730],\n",
      "        [3.4961, 3.4910, 3.7978, 3.4999, 3.6072],\n",
      "        [3.3480, 3.4553, 3.6131, 3.4990, 3.3943],\n",
      "        [3.6017, 3.8905, 4.0449, 3.9289, 3.6920],\n",
      "        [3.5164, 3.6188, 3.7254, 3.6333, 3.5697],\n",
      "        [3.4764, 3.6468, 3.6687, 3.6377, 3.5412],\n",
      "        [3.6126, 3.6158, 3.8332, 3.7584, 3.6128],\n",
      "        [3.9128, 3.7867, 4.0266, 4.3986, 4.1335],\n",
      "        [3.4293, 3.4728, 3.6593, 3.6284, 3.4265],\n",
      "        [3.6569, 3.6743, 3.8590, 3.6994, 3.5900],\n",
      "        [3.7621, 3.9578, 4.0472, 3.8833, 3.5590],\n",
      "        [3.5647, 3.7875, 3.8178, 3.7787, 3.6675],\n",
      "        [3.8759, 3.9635, 3.9554, 3.9937, 3.9132],\n",
      "        [3.9774, 3.9714, 4.0023, 4.1212, 3.9840],\n",
      "        [3.5452, 3.7066, 3.6818, 3.7456, 3.5652],\n",
      "        [3.5056, 3.6805, 3.6946, 3.7322, 3.5324],\n",
      "        [3.4389, 3.6291, 3.6567, 3.6084, 3.5096],\n",
      "        [3.5115, 3.7197, 3.8851, 3.7836, 3.5304],\n",
      "        [3.6141, 3.8288, 3.8239, 3.7581, 3.6850],\n",
      "        [3.6519, 3.7252, 3.8264, 3.7779, 3.6334],\n",
      "        [3.5156, 3.6784, 3.6751, 3.6824, 3.5541],\n",
      "        [3.8572, 3.8922, 4.0306, 4.0589, 3.8110],\n",
      "        [3.9706, 3.9637, 3.9729, 4.0982, 3.9874],\n",
      "        [3.6127, 4.0179, 3.8948, 3.9688, 3.7942],\n",
      "        [3.5154, 3.6984, 3.9557, 3.7666, 3.7171],\n",
      "        [3.8428, 3.8990, 4.0453, 4.1000, 3.7272],\n",
      "        [3.4526, 3.5063, 3.6839, 3.6465, 3.4536],\n",
      "        [3.7541, 3.6735, 3.8303, 4.1117, 3.8036],\n",
      "        [3.6882, 3.7395, 3.9694, 3.7837, 3.4515],\n",
      "        [3.3973, 3.5816, 3.6416, 3.5555, 3.4882],\n",
      "        [3.4155, 3.5929, 3.6423, 3.5748, 3.4777],\n",
      "        [3.6941, 3.7140, 3.8780, 3.7556, 3.5489],\n",
      "        [3.6307, 3.6180, 4.0545, 3.8306, 3.7176],\n",
      "        [3.5557, 3.7190, 3.6849, 3.7661, 3.5796],\n",
      "        [3.6438, 3.7335, 3.9126, 3.8113, 3.6576],\n",
      "        [3.4913, 3.6123, 3.5746, 3.7365, 3.4406],\n",
      "        [3.5448, 3.6109, 3.7969, 3.7100, 3.5755],\n",
      "        [3.5480, 3.6335, 3.8097, 3.7368, 3.5811],\n",
      "        [3.5524, 3.7087, 3.6823, 3.7577, 3.5694],\n",
      "        [3.6212, 3.6065, 4.0465, 3.8101, 3.6969],\n",
      "        [3.4656, 3.7798, 3.8191, 3.7394, 3.7471],\n",
      "        [3.6999, 3.7773, 3.7468, 3.8725, 3.7570],\n",
      "        [3.7132, 3.9746, 3.9998, 3.9486, 3.8613],\n",
      "        [3.7813, 3.9719, 3.9834, 3.9948, 3.9835],\n",
      "        [3.4001, 3.7051, 3.8824, 3.6470, 3.5867],\n",
      "        [3.3733, 3.6484, 3.5484, 3.6457, 3.4018],\n",
      "        [3.8120, 3.9636, 3.9474, 3.9484, 3.8822],\n",
      "        [3.7020, 3.9525, 3.9143, 3.8684, 3.7473],\n",
      "        [3.5465, 3.8261, 3.8598, 3.6696, 3.6736],\n",
      "        [3.5354, 3.6909, 3.6726, 3.7304, 3.5508],\n",
      "        [3.4323, 3.5603, 3.7346, 3.6363, 3.4517],\n",
      "        [3.4254, 3.5501, 3.7094, 3.6154, 3.4664],\n",
      "        [3.5822, 3.6213, 3.7890, 3.7143, 3.6413],\n",
      "        [3.7262, 3.8072, 4.1138, 3.7924, 3.5766],\n",
      "        [3.6376, 3.9404, 3.9104, 3.8692, 3.8141],\n",
      "        [3.4524, 3.6269, 3.8100, 3.7497, 3.5944],\n",
      "        [3.5475, 3.7034, 3.6764, 3.7482, 3.5636],\n",
      "        [3.6069, 3.6719, 3.8978, 3.7911, 3.6642],\n",
      "        [3.5418, 3.6040, 3.8015, 3.7180, 3.5772],\n",
      "        [3.5405, 3.7426, 3.8887, 3.8515, 3.5681]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6863, 3.8954, 3.9168, 3.9707, 3.7255],\n",
      "        [3.4513, 3.6779, 3.8613, 3.7053, 3.6416],\n",
      "        [3.4175, 3.5706, 3.7197, 3.6269, 3.4775],\n",
      "        [3.4206, 3.5500, 3.7090, 3.6135, 3.4665],\n",
      "        [3.5208, 4.0181, 4.0115, 3.7745, 3.6136],\n",
      "        [3.9924, 3.8397, 4.1300, 4.4714, 4.2311],\n",
      "        [3.5222, 3.6998, 3.6842, 3.7229, 3.5670],\n",
      "        [3.4033, 3.6469, 3.7445, 3.6090, 3.4901],\n",
      "        [3.9675, 3.9595, 3.9247, 4.0819, 4.0096],\n",
      "        [3.8044, 3.9362, 4.0629, 3.9693, 3.9938],\n",
      "        [3.8953, 3.9519, 3.9976, 4.1294, 3.8725],\n",
      "        [3.7905, 3.9993, 4.0780, 3.9287, 3.6223],\n",
      "        [3.4428, 3.4831, 3.6696, 3.6361, 3.4388],\n",
      "        [3.8730, 3.7343, 3.9006, 4.2334, 3.9302],\n",
      "        [3.4510, 3.6007, 3.7704, 3.6537, 3.4945],\n",
      "        [3.7067, 3.7574, 3.8700, 3.7875, 3.4825],\n",
      "        [3.5299, 3.6927, 3.8291, 3.7848, 3.6255],\n",
      "        [3.4627, 3.6136, 3.6634, 3.6740, 3.4915],\n",
      "        [3.6948, 3.8829, 3.8549, 3.8184, 3.7036],\n",
      "        [3.8176, 3.9615, 4.0953, 4.1473, 4.0974],\n",
      "        [3.9008, 3.7811, 4.0082, 4.0614, 3.7907],\n",
      "        [3.6330, 3.6520, 3.9167, 3.8491, 3.6734],\n",
      "        [3.8049, 3.9311, 4.0324, 3.9717, 3.9621],\n",
      "        [3.6809, 3.7754, 3.9625, 3.8103, 3.5548],\n",
      "        [3.5435, 3.5523, 3.7614, 3.6369, 3.5032],\n",
      "        [3.6213, 3.6787, 3.9124, 3.8313, 3.6109],\n",
      "        [3.6042, 3.6531, 3.8913, 3.7989, 3.6650],\n",
      "        [3.5589, 3.7262, 3.6911, 3.7773, 3.5913],\n",
      "        [3.8128, 3.6628, 3.8301, 3.8320, 3.7449],\n",
      "        [3.5569, 3.5407, 3.7265, 3.6852, 3.6656],\n",
      "        [3.4724, 3.6522, 3.8250, 3.6894, 3.5969],\n",
      "        [3.5096, 3.8589, 3.9409, 3.7205, 3.8349],\n",
      "        [3.7182, 3.9090, 3.9511, 3.9213, 3.7266],\n",
      "        [3.5313, 3.6397, 3.7159, 3.6456, 3.5615],\n",
      "        [3.9333, 3.8368, 3.9977, 4.0213, 3.8819],\n",
      "        [3.7351, 3.7183, 3.8574, 4.0845, 3.8227],\n",
      "        [3.4757, 3.6561, 3.6768, 3.6549, 3.5335],\n",
      "        [3.5802, 3.6204, 3.8251, 3.7355, 3.6311],\n",
      "        [3.4106, 3.6741, 3.7610, 3.6285, 3.5152],\n",
      "        [3.5038, 3.5012, 3.8057, 3.5271, 3.6105],\n",
      "        [3.5284, 3.6880, 3.6811, 3.7023, 3.5654],\n",
      "        [3.4566, 3.5303, 3.7082, 3.6589, 3.4838],\n",
      "        [3.4140, 3.6108, 3.6660, 3.5793, 3.5042],\n",
      "        [3.7544, 4.0663, 4.0725, 3.9792, 3.8853],\n",
      "        [3.6568, 3.6632, 3.8521, 3.7050, 3.5979],\n",
      "        [3.5021, 3.6337, 3.7058, 3.7394, 3.5556],\n",
      "        [3.4139, 3.6221, 3.7384, 3.6218, 3.5029],\n",
      "        [3.5772, 3.9789, 3.8899, 3.9138, 3.7865],\n",
      "        [3.4470, 3.4987, 3.6824, 3.6460, 3.4517],\n",
      "        [3.5558, 3.6125, 3.8138, 3.7203, 3.5829],\n",
      "        [3.4405, 3.6391, 3.7856, 3.6615, 3.5067],\n",
      "        [3.7693, 4.0403, 4.0046, 4.0500, 3.8521],\n",
      "        [3.9897, 3.9880, 4.1011, 4.2525, 3.9951],\n",
      "        [3.5706, 3.6053, 3.7349, 3.6755, 3.6312],\n",
      "        [3.5356, 3.7112, 3.8545, 3.8196, 3.6068],\n",
      "        [3.5562, 3.8827, 3.8880, 3.7455, 3.5050],\n",
      "        [3.9119, 3.9579, 3.9529, 4.0104, 3.9458],\n",
      "        [3.7723, 3.8004, 3.9251, 3.8797, 3.8518],\n",
      "        [3.6752, 3.6885, 3.8503, 3.7959, 3.6159],\n",
      "        [3.5382, 3.6230, 3.8085, 3.7357, 3.5896],\n",
      "        [3.5546, 3.8717, 3.7839, 3.5991, 3.6685],\n",
      "        [3.8478, 4.0211, 3.8744, 3.8619, 3.7232],\n",
      "        [3.4017, 3.6069, 3.7276, 3.6070, 3.4775],\n",
      "        [3.4668, 3.4577, 3.7737, 3.4653, 3.5844]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4535, 3.6707, 3.6596, 3.6988, 3.5201],\n",
      "        [3.4300, 3.4693, 3.6619, 3.6279, 3.4292],\n",
      "        [3.4959, 3.5831, 3.8133, 3.7034, 3.5607],\n",
      "        [3.8117, 3.6622, 3.8309, 3.8332, 3.7466],\n",
      "        [3.4019, 3.6094, 3.7311, 3.6064, 3.4785],\n",
      "        [3.8557, 3.8905, 4.0328, 4.0607, 3.8144],\n",
      "        [4.2657, 4.4431, 4.1694, 4.1618, 3.9264],\n",
      "        [3.4901, 3.6040, 3.5559, 3.7423, 3.4227],\n",
      "        [3.5421, 3.6987, 3.6889, 3.7302, 3.5857],\n",
      "        [3.5419, 3.6486, 3.8157, 3.7443, 3.5911],\n",
      "        [3.2532, 3.4764, 3.6517, 3.4989, 3.4436],\n",
      "        [3.5459, 3.7526, 3.8328, 3.8003, 3.6456],\n",
      "        [3.5263, 3.6230, 3.9271, 3.5740, 3.7325],\n",
      "        [3.4178, 3.7031, 3.7822, 3.6278, 3.5282],\n",
      "        [3.6315, 3.6838, 3.9273, 3.8257, 3.6833],\n",
      "        [3.8067, 3.8143, 3.9414, 3.9129, 3.8795],\n",
      "        [3.4163, 3.5701, 3.7205, 3.6279, 3.4789],\n",
      "        [3.7046, 3.9055, 3.9533, 4.0023, 3.7324],\n",
      "        [3.5163, 3.6849, 3.6774, 3.7024, 3.5611],\n",
      "        [3.7240, 3.9415, 3.9754, 3.9140, 3.7328],\n",
      "        [3.8036, 3.8285, 4.0487, 3.9554, 3.6108],\n",
      "        [3.2385, 3.4722, 3.6533, 3.4811, 3.4163],\n",
      "        [3.4391, 3.4986, 3.6821, 3.6426, 3.4480],\n",
      "        [3.4891, 3.8755, 3.8533, 3.6793, 3.4890],\n",
      "        [3.7687, 3.9471, 4.0670, 3.9847, 3.9311],\n",
      "        [3.9969, 3.9734, 4.1086, 4.2404, 3.9769],\n",
      "        [3.3491, 3.5372, 3.6131, 3.4973, 3.4370],\n",
      "        [3.5136, 3.6243, 3.7389, 3.6428, 3.5657],\n",
      "        [3.5879, 3.6290, 3.8640, 3.7344, 3.6092],\n",
      "        [3.6321, 3.9582, 3.9907, 3.8588, 3.6462],\n",
      "        [3.4333, 3.5544, 3.7357, 3.6407, 3.4527],\n",
      "        [3.6496, 3.8834, 3.8323, 3.8072, 3.6805],\n",
      "        [3.4021, 3.6464, 3.7452, 3.6100, 3.4914],\n",
      "        [3.7300, 3.8298, 3.9860, 3.9569, 3.8842],\n",
      "        [3.5591, 3.6731, 3.7523, 3.6590, 3.5945],\n",
      "        [3.4474, 3.6312, 3.8058, 3.6852, 3.4840],\n",
      "        [3.8405, 3.9692, 3.9609, 3.9692, 3.9035],\n",
      "        [3.3845, 3.5730, 3.6397, 3.5370, 3.4680],\n",
      "        [3.5346, 3.6779, 3.7175, 3.7394, 3.5539],\n",
      "        [3.5879, 3.6397, 3.8412, 3.7724, 3.6318],\n",
      "        [3.4942, 3.6574, 3.6618, 3.6877, 3.5278],\n",
      "        [3.4521, 3.8975, 3.7566, 3.6502, 3.6742],\n",
      "        [3.7166, 3.8344, 3.9453, 3.7975, 3.7236],\n",
      "        [3.5026, 3.5006, 3.8064, 3.5280, 3.6118],\n",
      "        [3.5213, 3.9495, 3.8080, 3.7438, 3.7794],\n",
      "        [3.3456, 3.5599, 3.6737, 3.5968, 3.4823],\n",
      "        [3.9590, 3.9580, 4.0492, 4.1383, 3.9386],\n",
      "        [3.4567, 3.7695, 3.8236, 3.7373, 3.7493],\n",
      "        [3.9024, 3.9371, 4.0507, 4.1286, 3.8129],\n",
      "        [3.8907, 4.0525, 3.8816, 3.8788, 3.7295],\n",
      "        [3.5811, 3.6255, 3.8508, 3.7660, 3.6338],\n",
      "        [3.4409, 3.4912, 3.6773, 3.6518, 3.4509],\n",
      "        [3.4693, 3.6819, 3.8307, 3.6098, 3.6774],\n",
      "        [3.8234, 3.8391, 4.0894, 4.1167, 3.6943],\n",
      "        [3.8132, 3.8355, 4.0415, 3.9770, 3.6368],\n",
      "        [3.6184, 3.5739, 3.7436, 3.6905, 3.6204],\n",
      "        [3.7506, 3.7948, 3.9027, 3.9370, 3.8556],\n",
      "        [3.6101, 3.7408, 3.8523, 3.8351, 3.7099],\n",
      "        [3.6860, 3.7566, 3.7363, 3.8621, 3.7373],\n",
      "        [3.4095, 3.6694, 3.7205, 3.6769, 3.4895],\n",
      "        [4.0057, 4.1777, 4.0342, 3.9643, 3.8390],\n",
      "        [3.5661, 3.6899, 3.7341, 3.7949, 3.6029],\n",
      "        [3.6136, 3.6041, 3.8195, 3.7651, 3.5691],\n",
      "        [3.7834, 3.8726, 4.0303, 3.9753, 3.9224]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6607, 3.5273, 3.9636, 3.8230, 3.6487],\n",
      "        [3.5760, 3.6639, 3.9243, 3.8042, 3.6639],\n",
      "        [3.8054, 3.9217, 4.0305, 3.9787, 3.9690],\n",
      "        [3.7799, 3.9147, 4.0125, 3.9536, 3.9373],\n",
      "        [3.4540, 3.6379, 3.6695, 3.6333, 3.5265],\n",
      "        [3.5485, 3.7162, 3.8134, 3.8143, 3.6886],\n",
      "        [3.5941, 3.6531, 3.8214, 3.7639, 3.6256],\n",
      "        [3.4023, 3.6617, 3.7550, 3.6123, 3.5009],\n",
      "        [3.9355, 3.9381, 4.0935, 4.1589, 3.8859],\n",
      "        [3.4483, 3.8926, 3.7535, 3.6474, 3.6715],\n",
      "        [3.4774, 3.5401, 3.7206, 3.6668, 3.4688],\n",
      "        [3.7957, 3.9482, 3.9391, 3.9136, 3.8632],\n",
      "        [3.7363, 3.9431, 3.9232, 3.8807, 3.7898],\n",
      "        [3.6073, 3.7512, 3.8686, 3.8699, 3.6788],\n",
      "        [3.6753, 3.7713, 3.7661, 3.8006, 3.7437],\n",
      "        [4.2084, 4.4157, 4.1002, 4.1204, 3.9082],\n",
      "        [3.5623, 3.5369, 3.7505, 3.6197, 3.4902],\n",
      "        [3.7784, 3.8125, 3.9549, 3.9473, 3.8873],\n",
      "        [3.3597, 3.5996, 3.6595, 3.5943, 3.4737],\n",
      "        [3.3534, 3.5405, 3.6207, 3.5023, 3.4449],\n",
      "        [3.5506, 3.6741, 3.8111, 3.7445, 3.7007],\n",
      "        [3.5503, 3.9154, 3.9454, 3.8538, 3.8190],\n",
      "        [3.6889, 3.6894, 3.8460, 3.6847, 3.4985],\n",
      "        [3.9873, 3.9865, 4.1048, 4.2550, 3.9978],\n",
      "        [3.4217, 3.5780, 3.6074, 3.6182, 3.4203],\n",
      "        [3.9083, 3.7603, 3.8836, 3.9570, 3.8418],\n",
      "        [3.4321, 3.5537, 3.7373, 3.6412, 3.4536],\n",
      "        [3.9547, 4.1580, 4.2355, 4.2295, 4.2002],\n",
      "        [3.9873, 3.8720, 4.0721, 4.1570, 3.9151],\n",
      "        [3.3256, 3.5107, 3.5983, 3.4698, 3.4072],\n",
      "        [3.7091, 3.9226, 3.9117, 3.9140, 3.7398],\n",
      "        [3.6991, 3.8802, 3.8975, 3.8525, 3.7955],\n",
      "        [3.5498, 3.5887, 3.7206, 3.7856, 3.5135],\n",
      "        [3.5694, 3.8643, 3.9232, 3.9117, 3.6105],\n",
      "        [3.5447, 3.6231, 3.8092, 3.7336, 3.5821],\n",
      "        [3.6572, 3.6760, 3.8624, 3.7135, 3.5612],\n",
      "        [3.4968, 3.6568, 3.7260, 3.5737, 3.5321],\n",
      "        [3.7640, 3.6695, 3.8427, 4.1559, 3.8272],\n",
      "        [3.5295, 3.8166, 3.8701, 3.7132, 3.6968],\n",
      "        [3.5710, 3.7071, 3.8065, 3.7171, 3.5173],\n",
      "        [3.7136, 3.7194, 3.8155, 4.0056, 3.7697],\n",
      "        [3.6958, 3.7966, 3.9505, 3.9125, 3.8564],\n",
      "        [3.7237, 3.9244, 3.9707, 3.9232, 3.7360],\n",
      "        [3.9298, 3.9388, 4.1079, 4.1604, 3.8816],\n",
      "        [3.8568, 3.8415, 3.9458, 3.9451, 3.8403],\n",
      "        [3.5778, 3.7999, 3.8128, 3.7527, 3.6749],\n",
      "        [3.4172, 3.6906, 3.7706, 3.6397, 3.5252],\n",
      "        [3.6862, 3.8183, 3.8445, 3.7160, 3.6531],\n",
      "        [3.6673, 3.9685, 3.9914, 3.9055, 3.8932],\n",
      "        [3.5778, 3.6190, 3.8275, 3.7371, 3.6337],\n",
      "        [3.7086, 3.7761, 3.7403, 3.8836, 3.7800],\n",
      "        [3.5249, 3.6878, 3.6896, 3.7253, 3.5731],\n",
      "        [3.7440, 3.8790, 3.8823, 3.8660, 3.8042],\n",
      "        [3.4581, 3.6075, 3.6653, 3.6727, 3.4991],\n",
      "        [3.4879, 3.6294, 3.7986, 3.7612, 3.5723],\n",
      "        [3.5452, 3.7087, 3.6926, 3.7547, 3.5829],\n",
      "        [3.4788, 3.5965, 3.7674, 3.6976, 3.4928],\n",
      "        [3.6296, 3.9201, 3.8959, 3.8628, 3.8130],\n",
      "        [3.9866, 3.8804, 4.0773, 4.2096, 3.9593],\n",
      "        [3.8094, 3.9029, 3.9981, 3.9402, 3.8734],\n",
      "        [3.6357, 3.7404, 3.7504, 3.8017, 3.6417],\n",
      "        [3.5093, 3.9232, 3.7767, 3.6846, 3.7290],\n",
      "        [3.5017, 3.5947, 3.8050, 3.7182, 3.5729],\n",
      "        [3.4106, 3.6813, 3.7648, 3.6229, 3.5195]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4580, 3.6352, 3.6719, 3.6282, 3.5204],\n",
      "        [3.4917, 3.6557, 3.6653, 3.6892, 3.5295],\n",
      "        [3.5630, 3.7359, 3.9007, 3.7937, 3.6720],\n",
      "        [3.5485, 3.5969, 3.8340, 3.7160, 3.5792],\n",
      "        [3.7631, 3.9506, 4.0516, 3.8875, 3.5525],\n",
      "        [3.7482, 3.7929, 3.9067, 3.9386, 3.8577],\n",
      "        [3.3314, 3.5024, 3.5790, 3.5349, 3.4085],\n",
      "        [3.8080, 3.9601, 3.9538, 3.9520, 3.8876],\n",
      "        [3.6080, 4.0144, 3.9008, 3.9732, 3.7993],\n",
      "        [3.9541, 3.7548, 3.9951, 4.3618, 4.1381],\n",
      "        [3.6200, 3.6809, 3.9233, 3.8039, 3.6796],\n",
      "        [3.3522, 3.5391, 3.5589, 3.5450, 3.3884],\n",
      "        [3.6971, 3.8408, 4.0132, 3.8290, 3.5907],\n",
      "        [3.6239, 3.9129, 3.8384, 3.6564, 3.7016],\n",
      "        [3.7607, 3.8512, 4.1207, 3.8420, 3.5680],\n",
      "        [3.6898, 3.8900, 3.8764, 3.9970, 3.7644],\n",
      "        [3.7485, 3.7122, 3.8583, 3.7498, 3.5715],\n",
      "        [3.4007, 3.6273, 3.7424, 3.6095, 3.4865],\n",
      "        [3.4153, 3.7015, 3.7856, 3.6291, 3.5297],\n",
      "        [3.8687, 3.9090, 4.0330, 4.0826, 3.7785],\n",
      "        [3.6083, 3.5668, 3.9026, 3.9249, 3.5431],\n",
      "        [3.4876, 3.6531, 3.6691, 3.6694, 3.5446],\n",
      "        [4.1946, 4.4387, 4.0922, 4.1672, 3.8863],\n",
      "        [3.5493, 3.7744, 3.8159, 3.7840, 3.6637],\n",
      "        [3.7733, 3.8312, 3.9642, 3.9640, 3.8671],\n",
      "        [3.5372, 3.6749, 3.7244, 3.7169, 3.5991],\n",
      "        [3.5639, 3.7983, 3.9095, 3.7922, 3.5748],\n",
      "        [3.6621, 3.6744, 3.8722, 3.7011, 3.6241],\n",
      "        [3.4808, 3.4933, 3.6726, 3.6486, 3.4451],\n",
      "        [3.8074, 3.8469, 3.9852, 4.0637, 3.9964],\n",
      "        [3.6688, 3.7636, 3.7986, 3.7923, 3.6327],\n",
      "        [3.5281, 3.8156, 3.8719, 3.7141, 3.6975],\n",
      "        [3.5565, 3.6510, 3.8269, 3.7575, 3.6183],\n",
      "        [3.3692, 3.6453, 3.5538, 3.6486, 3.4062],\n",
      "        [3.4741, 3.6441, 3.6680, 3.6529, 3.5386],\n",
      "        [3.4212, 3.7090, 3.7912, 3.6468, 3.5467],\n",
      "        [3.4186, 3.7041, 3.7821, 3.6440, 3.5449],\n",
      "        [3.8615, 3.8807, 4.0286, 4.0638, 3.8232],\n",
      "        [3.4274, 3.4675, 3.6652, 3.6294, 3.4311],\n",
      "        [4.0598, 4.0822, 4.2009, 4.3132, 3.9537],\n",
      "        [3.7126, 3.7187, 4.0121, 4.0273, 3.6608],\n",
      "        [3.6939, 3.7062, 3.8976, 3.8517, 3.6433],\n",
      "        [3.7117, 3.8522, 4.0259, 3.8447, 3.5931],\n",
      "        [3.5342, 3.6299, 3.8100, 3.7332, 3.5829],\n",
      "        [3.4480, 3.5028, 3.6891, 3.6496, 3.4587],\n",
      "        [3.6153, 3.7142, 3.8157, 3.7509, 3.6363],\n",
      "        [3.5403, 3.6072, 3.8025, 3.7131, 3.5804],\n",
      "        [3.4028, 3.5721, 3.7199, 3.6077, 3.4719],\n",
      "        [3.4873, 3.8677, 3.8577, 3.6843, 3.4806],\n",
      "        [3.4437, 3.5574, 3.6348, 3.6823, 3.4105],\n",
      "        [3.4940, 3.6022, 3.8016, 3.7192, 3.5744],\n",
      "        [3.7125, 3.8640, 3.9589, 3.9921, 3.7060],\n",
      "        [3.5514, 3.7157, 3.6922, 3.7846, 3.5897],\n",
      "        [3.3776, 3.7133, 3.9031, 3.6139, 3.6094],\n",
      "        [3.8948, 3.7706, 4.0053, 4.0620, 3.7900],\n",
      "        [3.8369, 3.8746, 4.1080, 4.1496, 3.7391],\n",
      "        [3.4260, 3.6696, 3.7681, 3.6348, 3.5357],\n",
      "        [3.5488, 3.7086, 3.6853, 3.7611, 3.5729],\n",
      "        [3.9566, 3.9562, 4.0533, 4.1402, 3.9405],\n",
      "        [3.4527, 3.5280, 3.7123, 3.6614, 3.4870],\n",
      "        [3.6325, 3.9377, 3.9146, 3.8696, 3.8190],\n",
      "        [3.4900, 3.7060, 3.7547, 3.7748, 3.5502],\n",
      "        [3.6193, 3.8795, 3.8651, 3.8412, 3.7897],\n",
      "        [4.0555, 4.1557, 3.8923, 3.9700, 3.7188]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3253, 3.5199, 3.6107, 3.4776, 3.4194],\n",
      "        [3.8123, 3.9576, 4.1027, 4.1523, 4.1027],\n",
      "        [3.4348, 3.6101, 3.6614, 3.6112, 3.5027],\n",
      "        [3.8204, 3.6608, 3.7632, 3.8151, 3.7671],\n",
      "        [3.5639, 3.6362, 3.8932, 3.7688, 3.6503],\n",
      "        [3.2853, 3.5036, 3.6819, 3.5224, 3.4671],\n",
      "        [3.8993, 3.8306, 3.9225, 3.9676, 3.8281],\n",
      "        [3.5479, 3.6721, 3.8160, 3.7476, 3.7033],\n",
      "        [3.4040, 3.5106, 3.6574, 3.6530, 3.4578],\n",
      "        [3.8617, 3.7390, 3.9103, 4.2399, 3.9331],\n",
      "        [3.8814, 3.9056, 4.0535, 4.0897, 3.7454],\n",
      "        [3.5413, 3.5851, 3.8143, 3.7190, 3.5651],\n",
      "        [3.8481, 3.8625, 4.0264, 4.0344, 3.8102],\n",
      "        [3.4967, 3.5764, 3.7826, 3.6700, 3.5416],\n",
      "        [3.5383, 3.6173, 3.8092, 3.7259, 3.5873],\n",
      "        [3.6443, 3.5361, 3.9463, 3.8166, 3.6519],\n",
      "        [3.4612, 3.6204, 3.7993, 3.6905, 3.4921],\n",
      "        [3.9628, 3.8607, 4.0574, 4.0819, 3.9364],\n",
      "        [3.6508, 3.8826, 3.8409, 3.8279, 3.6935],\n",
      "        [3.5108, 3.6769, 3.6795, 3.7230, 3.5526],\n",
      "        [3.6964, 3.8479, 4.0140, 3.9398, 3.8306],\n",
      "        [3.5397, 3.6456, 3.8251, 3.7495, 3.5973],\n",
      "        [3.5498, 3.7220, 3.8246, 3.7954, 3.6907],\n",
      "        [3.5862, 3.6325, 3.8296, 3.7401, 3.6337],\n",
      "        [3.4097, 3.6766, 3.7734, 3.6338, 3.5286],\n",
      "        [3.5323, 3.8359, 3.8784, 3.6774, 3.6704],\n",
      "        [3.4466, 3.7512, 3.8457, 3.6277, 3.6353],\n",
      "        [3.4015, 3.6331, 3.7160, 3.6684, 3.4808],\n",
      "        [3.6873, 3.8002, 3.8187, 3.8799, 3.7292],\n",
      "        [3.4970, 3.6306, 3.7129, 3.7438, 3.5601],\n",
      "        [3.6308, 3.6116, 3.8202, 3.7403, 3.6613],\n",
      "        [4.0562, 4.1229, 4.2306, 4.3978, 4.0581],\n",
      "        [3.6693, 3.7279, 3.8760, 3.7668, 3.7691],\n",
      "        [3.6435, 3.6555, 3.8541, 3.7065, 3.5712],\n",
      "        [3.8244, 3.6076, 3.8954, 4.1284, 3.9766],\n",
      "        [3.7431, 3.7760, 3.9755, 3.9361, 3.5794],\n",
      "        [3.9905, 4.0552, 4.1630, 4.2858, 3.9893],\n",
      "        [3.5332, 3.6017, 3.7971, 3.7122, 3.5767],\n",
      "        [3.4215, 3.6091, 3.6632, 3.5922, 3.5089],\n",
      "        [3.6615, 3.7246, 3.9679, 3.8773, 3.6469],\n",
      "        [3.6564, 3.8480, 3.9926, 3.9415, 3.7880],\n",
      "        [3.4428, 3.4939, 3.6862, 3.6494, 3.4529],\n",
      "        [3.6991, 3.7318, 3.8896, 3.7858, 3.5449],\n",
      "        [3.4482, 3.6128, 3.6407, 3.6540, 3.4621],\n",
      "        [3.5424, 3.7066, 3.6972, 3.7575, 3.5852],\n",
      "        [3.3938, 3.6022, 3.7382, 3.6103, 3.4785],\n",
      "        [3.6455, 3.9722, 3.8631, 3.8439, 3.8601],\n",
      "        [3.8210, 3.8831, 4.0919, 4.0938, 3.7480],\n",
      "        [3.4693, 3.5913, 3.7819, 3.7185, 3.5557],\n",
      "        [3.5020, 3.7212, 3.8884, 3.8395, 3.5418],\n",
      "        [3.6063, 3.7380, 3.8592, 3.8391, 3.7138],\n",
      "        [3.4889, 3.6615, 3.6756, 3.6901, 3.5384],\n",
      "        [3.5422, 3.6152, 3.8076, 3.7184, 3.5833],\n",
      "        [3.9650, 4.1115, 4.0450, 4.1525, 4.1155],\n",
      "        [3.6481, 3.6638, 3.8584, 3.7160, 3.5675],\n",
      "        [3.7260, 3.8270, 3.9931, 3.9611, 3.8880],\n",
      "        [3.5886, 3.8067, 3.7851, 3.7469, 3.6199],\n",
      "        [3.8264, 3.8373, 3.8307, 3.9165, 3.8355],\n",
      "        [4.1894, 4.4261, 4.0876, 4.1371, 3.8751],\n",
      "        [3.6132, 3.6042, 4.0662, 3.8218, 3.7166],\n",
      "        [4.0362, 4.0848, 4.1182, 4.3408, 4.0280],\n",
      "        [3.9844, 3.9844, 4.1103, 4.2591, 4.0007],\n",
      "        [3.7123, 3.8772, 3.9838, 3.9223, 3.7362],\n",
      "        [3.7246, 3.9924, 3.9001, 3.9150, 3.9340]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7004, 3.7320, 3.8917, 3.7878, 3.5462],\n",
      "        [3.5241, 3.7506, 3.8103, 3.7829, 3.6526],\n",
      "        [3.5404, 3.7023, 3.6924, 3.7528, 3.5729],\n",
      "        [3.8078, 3.9593, 3.9588, 3.9565, 3.8908],\n",
      "        [3.7472, 3.7775, 3.8930, 3.9377, 3.8400],\n",
      "        [3.4558, 3.6150, 3.6757, 3.6894, 3.4944],\n",
      "        [3.7943, 3.9465, 3.9463, 3.9193, 3.8672],\n",
      "        [3.5491, 3.7737, 3.8211, 3.7885, 3.6670],\n",
      "        [3.7032, 3.7541, 3.8791, 3.7941, 3.4890],\n",
      "        [3.4270, 3.5287, 3.7019, 3.6203, 3.4597],\n",
      "        [3.9406, 3.9882, 4.1035, 4.2312, 3.8016],\n",
      "        [3.5069, 3.7156, 3.8980, 3.7925, 3.5389],\n",
      "        [3.7971, 4.0848, 3.9864, 4.0216, 3.9726],\n",
      "        [3.7968, 3.6617, 3.8448, 3.8349, 3.7403],\n",
      "        [3.8276, 3.8376, 3.8328, 3.9185, 3.8367],\n",
      "        [3.6998, 3.9629, 3.9421, 3.8887, 3.7596],\n",
      "        [3.5866, 3.6340, 3.8755, 3.7826, 3.6560],\n",
      "        [3.4823, 3.6447, 3.6650, 3.6712, 3.5238],\n",
      "        [3.4507, 3.8783, 3.7476, 3.6625, 3.6786],\n",
      "        [3.5828, 3.6382, 3.8389, 3.7721, 3.6349],\n",
      "        [3.6421, 3.7320, 3.8555, 3.9068, 3.6496],\n",
      "        [3.9604, 3.8840, 4.0055, 4.1429, 3.8697],\n",
      "        [3.5773, 3.6242, 3.8783, 3.7559, 3.6463],\n",
      "        [3.9332, 3.7713, 4.0330, 4.4246, 4.1348],\n",
      "        [3.4624, 3.5956, 3.6752, 3.6761, 3.4933],\n",
      "        [3.7453, 3.9356, 3.9235, 3.8978, 3.8075],\n",
      "        [4.2527, 4.4276, 4.1846, 4.1917, 3.9140],\n",
      "        [3.9451, 3.9443, 4.0658, 4.1427, 3.9259],\n",
      "        [3.4830, 3.7290, 3.6846, 3.7484, 3.5075],\n",
      "        [3.9845, 3.9852, 4.0424, 4.1367, 3.9949],\n",
      "        [3.2985, 3.5209, 3.6850, 3.5405, 3.4572],\n",
      "        [3.4466, 3.8909, 3.7604, 3.6523, 3.6754],\n",
      "        [3.7104, 4.0708, 4.0312, 3.9707, 3.9136],\n",
      "        [3.6145, 3.6072, 4.0597, 3.8213, 3.7101],\n",
      "        [3.9243, 4.0467, 4.0626, 4.0532, 3.9834],\n",
      "        [3.4923, 3.6530, 3.7316, 3.5773, 3.5293],\n",
      "        [3.5520, 3.5242, 3.7457, 3.6023, 3.4819],\n",
      "        [3.7165, 3.9056, 3.9656, 3.9415, 3.7340],\n",
      "        [3.5746, 3.6619, 3.9314, 3.8088, 3.6672],\n",
      "        [3.4732, 3.6331, 3.7116, 3.6661, 3.5477],\n",
      "        [4.0075, 3.9673, 4.0615, 4.1590, 3.9977],\n",
      "        [3.5452, 3.5219, 3.7164, 3.6712, 3.6615],\n",
      "        [3.5813, 3.7472, 3.8383, 3.7853, 3.6801],\n",
      "        [3.4110, 3.8086, 3.7997, 3.5584, 3.6647],\n",
      "        [3.4077, 3.5347, 3.7107, 3.6155, 3.4632],\n",
      "        [3.5790, 3.6746, 3.8512, 3.6569, 3.4342],\n",
      "        [3.7083, 3.7468, 3.8975, 3.7944, 3.5352],\n",
      "        [3.6751, 3.7366, 3.8741, 3.8461, 3.7505],\n",
      "        [3.5318, 3.6756, 3.7260, 3.7448, 3.5582],\n",
      "        [3.3389, 3.5285, 3.6120, 3.4951, 3.4295],\n",
      "        [3.5925, 3.6512, 3.8283, 3.7687, 3.6290],\n",
      "        [3.3911, 3.5657, 3.5951, 3.5788, 3.4268],\n",
      "        [3.4337, 3.5143, 3.7025, 3.6349, 3.4651],\n",
      "        [3.6442, 3.7129, 3.8420, 3.8081, 3.7260],\n",
      "        [3.5440, 3.7056, 3.7044, 3.7641, 3.5867],\n",
      "        [3.4655, 3.6516, 3.8204, 3.5913, 3.6474],\n",
      "        [3.8289, 4.0383, 3.9470, 3.8323, 3.7155],\n",
      "        [3.9523, 4.0251, 4.1049, 4.2620, 3.9732],\n",
      "        [3.5104, 3.6944, 3.9666, 3.7738, 3.7252],\n",
      "        [3.4271, 3.4667, 3.6698, 3.6333, 3.4340],\n",
      "        [3.4485, 3.6195, 3.6477, 3.6890, 3.5090],\n",
      "        [3.6017, 3.8171, 3.9737, 3.9141, 3.7402],\n",
      "        [3.4170, 3.6600, 3.7668, 3.6424, 3.5275],\n",
      "        [3.6962, 3.9436, 3.9938, 3.9238, 3.8516]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6777, 3.8643, 3.9030, 3.8383, 3.8095],\n",
      "        [3.9892, 3.9168, 4.0471, 4.1172, 3.9622],\n",
      "        [3.7836, 3.9377, 4.0591, 3.9858, 3.9514],\n",
      "        [3.5171, 3.9907, 3.8718, 3.7796, 3.8630],\n",
      "        [3.8027, 3.9972, 4.0668, 4.0268, 3.8864],\n",
      "        [3.4017, 3.6861, 3.7782, 3.6231, 3.5223],\n",
      "        [3.3726, 3.5632, 3.6404, 3.5373, 3.4664],\n",
      "        [3.4441, 3.4888, 3.6834, 3.6609, 3.4666],\n",
      "        [3.4486, 3.8325, 3.8341, 3.5875, 3.6880],\n",
      "        [3.9373, 3.7833, 4.0398, 4.0602, 3.8439],\n",
      "        [3.6624, 3.6227, 4.0536, 3.8694, 3.7475],\n",
      "        [3.5344, 3.8306, 3.8837, 3.6806, 3.6704],\n",
      "        [3.9540, 3.8874, 3.9947, 4.0736, 3.9408],\n",
      "        [3.5973, 3.8827, 3.9604, 3.9551, 3.6376],\n",
      "        [3.5313, 3.6915, 3.6944, 3.7396, 3.5783],\n",
      "        [3.5634, 3.5812, 3.8468, 3.7451, 3.6720],\n",
      "        [3.3999, 3.6068, 3.7408, 3.6135, 3.4845],\n",
      "        [3.5837, 3.6379, 3.8407, 3.7743, 3.6367],\n",
      "        [3.7780, 3.8647, 4.0453, 4.0582, 3.7238],\n",
      "        [3.9997, 4.0977, 4.1413, 4.2987, 4.0215],\n",
      "        [3.4883, 3.6016, 3.5656, 3.7496, 3.4288],\n",
      "        [3.5303, 3.7439, 3.8354, 3.7366, 3.6480],\n",
      "        [3.5486, 3.5973, 3.7419, 3.7810, 3.5306],\n",
      "        [3.4345, 3.5141, 3.7041, 3.6371, 3.4668],\n",
      "        [3.6499, 3.7476, 3.9360, 3.8363, 3.6504],\n",
      "        [3.6921, 3.8913, 3.8847, 4.0051, 3.7727],\n",
      "        [3.4515, 3.8781, 3.7493, 3.6648, 3.6805],\n",
      "        [3.9464, 3.8507, 4.0140, 4.0410, 3.8857],\n",
      "        [3.5032, 3.5270, 3.7829, 3.6744, 3.5286],\n",
      "        [3.5523, 3.7607, 3.8646, 3.7625, 3.6330],\n",
      "        [3.6736, 3.9935, 3.9494, 3.9153, 3.7689],\n",
      "        [3.9259, 3.9355, 4.1196, 4.1759, 3.8857],\n",
      "        [3.9992, 4.0701, 4.1349, 4.2674, 3.9564],\n",
      "        [3.8387, 3.8795, 4.1071, 4.1600, 3.7693],\n",
      "        [3.6033, 3.6669, 3.9104, 3.8003, 3.6733],\n",
      "        [3.6702, 3.6838, 3.8662, 3.6690, 3.4838],\n",
      "        [3.3962, 3.6483, 3.7615, 3.6271, 3.5022],\n",
      "        [3.5515, 3.9595, 3.8342, 3.7883, 3.8180],\n",
      "        [3.6814, 3.9698, 4.0133, 3.9205, 3.8968],\n",
      "        [3.5933, 3.6509, 3.8300, 3.7710, 3.6308],\n",
      "        [3.9251, 4.0465, 4.0643, 4.0554, 3.9853],\n",
      "        [3.6143, 3.7320, 3.8479, 3.7703, 3.7396],\n",
      "        [3.5313, 3.6864, 3.6848, 3.7399, 3.5602],\n",
      "        [3.5385, 3.7699, 3.8478, 3.7606, 3.6216],\n",
      "        [3.4392, 3.6216, 3.6707, 3.6166, 3.5196],\n",
      "        [3.4325, 3.5180, 3.7053, 3.6358, 3.4656],\n",
      "        [3.5880, 3.9900, 3.9213, 3.9285, 3.8244],\n",
      "        [3.6855, 4.0441, 4.0048, 3.9486, 3.9269],\n",
      "        [3.5688, 3.6664, 3.8230, 3.7383, 3.7484],\n",
      "        [3.3723, 3.5614, 3.6420, 3.5332, 3.4741],\n",
      "        [3.5650, 3.5685, 3.8374, 3.7512, 3.6913],\n",
      "        [3.5002, 3.6628, 3.6884, 3.7076, 3.5592],\n",
      "        [3.3897, 3.5670, 3.6944, 3.6438, 3.4569],\n",
      "        [3.5233, 4.0248, 4.0215, 3.7964, 3.6299],\n",
      "        [3.7483, 3.7772, 3.8950, 3.9401, 3.8419],\n",
      "        [3.5578, 3.7238, 3.7163, 3.7900, 3.6011],\n",
      "        [3.3599, 3.5533, 3.6345, 3.5189, 3.4545],\n",
      "        [3.4543, 3.5044, 3.6998, 3.6604, 3.4656],\n",
      "        [3.6811, 3.7384, 3.8595, 3.7724, 3.4660],\n",
      "        [3.5405, 3.6988, 3.6942, 3.7585, 3.5786],\n",
      "        [3.3053, 3.5219, 3.6926, 3.5467, 3.4855],\n",
      "        [3.7800, 3.5636, 3.7176, 3.7339, 3.7332],\n",
      "        [3.7345, 3.6546, 3.8337, 4.1111, 3.8009],\n",
      "        [3.9095, 3.9546, 3.9639, 4.0191, 3.9542]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7359, 3.9417, 3.9337, 3.8923, 3.7975],\n",
      "        [3.7796, 3.9130, 4.0231, 3.9645, 3.9449],\n",
      "        [3.6580, 3.8515, 3.8667, 3.7572, 3.7324],\n",
      "        [3.7219, 3.8023, 4.1287, 3.8050, 3.5880],\n",
      "        [3.8734, 3.9593, 3.9693, 4.0059, 3.9250],\n",
      "        [3.4053, 3.5559, 3.6970, 3.6600, 3.4726],\n",
      "        [3.6022, 3.8206, 3.8069, 3.7662, 3.6403],\n",
      "        [3.7710, 3.8559, 4.0378, 3.9691, 3.9200],\n",
      "        [3.5089, 3.9216, 3.7867, 3.6942, 3.7363],\n",
      "        [3.5067, 3.5050, 3.8227, 3.5394, 3.6252],\n",
      "        [3.6165, 3.6068, 3.8442, 3.7703, 3.6069],\n",
      "        [3.9561, 3.8758, 4.0020, 4.1428, 3.8736],\n",
      "        [3.4713, 3.5401, 3.8129, 3.6835, 3.5448],\n",
      "        [3.5265, 3.6902, 3.6901, 3.7491, 3.5683],\n",
      "        [3.6629, 3.6228, 4.0550, 3.8718, 3.7489],\n",
      "        [3.7480, 3.6119, 3.7384, 3.7433, 3.7408],\n",
      "        [3.6985, 3.9487, 3.9304, 3.8836, 3.7598],\n",
      "        [3.5391, 3.7702, 3.8492, 3.7631, 3.6231],\n",
      "        [3.4590, 3.6345, 3.6796, 3.6363, 3.5261],\n",
      "        [3.5274, 3.9000, 3.9295, 3.8353, 3.8113],\n",
      "        [3.5872, 3.7366, 3.8448, 3.7889, 3.6884],\n",
      "        [3.5469, 3.5790, 3.8276, 3.7106, 3.5815],\n",
      "        [3.6702, 3.9819, 4.0143, 3.9205, 3.9158],\n",
      "        [3.4084, 3.7123, 3.6265, 3.6999, 3.4697],\n",
      "        [3.4277, 3.5932, 3.7676, 3.6536, 3.4797],\n",
      "        [3.4661, 3.8591, 3.8471, 3.6678, 3.4794],\n",
      "        [3.4507, 3.6960, 3.8914, 3.6983, 3.6401],\n",
      "        [3.6430, 3.9300, 3.9892, 3.8452, 3.7592],\n",
      "        [3.4006, 3.6441, 3.7562, 3.6193, 3.4985],\n",
      "        [3.4175, 3.5626, 3.7333, 3.6267, 3.4816],\n",
      "        [3.5662, 3.6957, 3.7999, 3.6974, 3.5183],\n",
      "        [3.5447, 3.6153, 3.8128, 3.7251, 3.5877],\n",
      "        [3.6151, 3.5912, 3.8130, 3.7690, 3.5578],\n",
      "        [3.3438, 3.5575, 3.6847, 3.6063, 3.4898],\n",
      "        [3.7578, 3.9498, 4.0918, 4.0038, 3.9472],\n",
      "        [3.5597, 3.7873, 3.8261, 3.7728, 3.6698],\n",
      "        [3.5918, 3.6701, 3.8274, 3.7299, 3.7927],\n",
      "        [3.5483, 3.7729, 3.8803, 3.7819, 3.6130],\n",
      "        [3.8778, 3.7545, 3.8922, 3.9313, 3.8538],\n",
      "        [3.4383, 3.4975, 3.6930, 3.6509, 3.4565],\n",
      "        [3.3237, 3.5480, 3.6938, 3.5738, 3.4873],\n",
      "        [3.6087, 3.7342, 3.8544, 3.8003, 3.7317],\n",
      "        [4.0095, 3.9344, 4.0965, 4.1616, 4.0133],\n",
      "        [3.7159, 3.8795, 3.9803, 3.8572, 3.5988],\n",
      "        [3.5442, 3.5902, 3.8219, 3.7235, 3.5742],\n",
      "        [3.4497, 3.6197, 3.6507, 3.6934, 3.5121],\n",
      "        [3.5980, 3.6093, 3.8647, 3.7591, 3.6478],\n",
      "        [3.4884, 3.6083, 3.5875, 3.7474, 3.4508],\n",
      "        [3.7817, 3.7295, 3.8725, 3.7849, 3.5956],\n",
      "        [3.8889, 3.9636, 3.9765, 4.0118, 3.9366],\n",
      "        [3.6248, 3.9120, 3.8464, 3.6653, 3.7079],\n",
      "        [3.5435, 3.5897, 3.8233, 3.7170, 3.5739],\n",
      "        [3.4177, 3.5469, 3.7207, 3.6241, 3.4754],\n",
      "        [3.6659, 3.8621, 3.8541, 3.9667, 3.7267],\n",
      "        [3.6705, 3.8271, 4.0138, 3.9174, 3.7801],\n",
      "        [3.5413, 3.7576, 3.8576, 3.7633, 3.6447],\n",
      "        [3.5952, 3.7041, 3.8027, 3.7233, 3.6309],\n",
      "        [3.5821, 3.6665, 3.8270, 3.7351, 3.7719],\n",
      "        [3.8290, 3.8377, 3.8358, 3.9229, 3.8398],\n",
      "        [3.4863, 3.5578, 3.8261, 3.7035, 3.5528],\n",
      "        [3.6188, 3.6864, 3.8397, 3.8417, 3.6375],\n",
      "        [3.4537, 3.6363, 3.6791, 3.6423, 3.5328],\n",
      "        [3.5728, 3.7326, 3.8810, 3.9043, 3.6203],\n",
      "        [3.9404, 3.9375, 4.0619, 4.1415, 3.9216]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.9173, 3.7535, 3.9434, 4.3224, 4.0096],\n",
      "        [3.9910, 3.9330, 4.0205, 4.1084, 3.9512],\n",
      "        [3.8862, 3.7805, 3.9029, 3.9451, 3.8725],\n",
      "        [3.5785, 3.8037, 3.7747, 3.7458, 3.6171],\n",
      "        [3.3871, 3.5327, 3.5948, 3.6440, 3.4220],\n",
      "        [4.0447, 4.1998, 4.0383, 4.0088, 3.8263],\n",
      "        [3.9041, 3.9521, 3.9706, 4.0374, 3.9514],\n",
      "        [3.5339, 3.5689, 3.7092, 3.6492, 3.6121],\n",
      "        [3.4688, 3.7447, 3.8575, 3.6354, 3.6471],\n",
      "        [3.4577, 3.8572, 3.9552, 3.7681, 3.7814],\n",
      "        [3.5560, 3.7231, 3.8302, 3.8084, 3.7162],\n",
      "        [3.4789, 3.7337, 3.8973, 3.8646, 3.5408],\n",
      "        [3.6731, 3.9609, 3.8618, 3.8752, 3.8855],\n",
      "        [3.5342, 3.6356, 3.8228, 3.7522, 3.5970],\n",
      "        [3.3631, 3.5428, 3.5711, 3.5495, 3.4032],\n",
      "        [3.4424, 3.6975, 3.8568, 3.6184, 3.7073],\n",
      "        [3.6058, 3.5781, 3.8181, 3.7545, 3.5557],\n",
      "        [3.9121, 3.9296, 4.1162, 4.1947, 3.9117],\n",
      "        [3.4524, 3.5328, 3.6104, 3.6880, 3.4194],\n",
      "        [3.6957, 3.9548, 4.0257, 3.9352, 3.7089],\n",
      "        [3.7150, 3.7631, 3.8963, 3.8120, 3.5155],\n",
      "        [3.7546, 3.8918, 3.9874, 3.8238, 3.7564],\n",
      "        [3.5923, 3.6589, 3.9258, 3.9352, 3.8482],\n",
      "        [3.5624, 3.5352, 3.7614, 3.6299, 3.4974],\n",
      "        [3.4459, 3.6289, 3.8178, 3.6961, 3.4923],\n",
      "        [3.7926, 4.0706, 4.0235, 4.0599, 3.9361],\n",
      "        [3.6087, 3.7100, 3.8180, 3.7320, 3.6450],\n",
      "        [3.5313, 3.6974, 3.7024, 3.7440, 3.5839],\n",
      "        [3.4551, 3.5046, 3.7019, 3.6643, 3.4680],\n",
      "        [4.0488, 3.8165, 4.0980, 4.4629, 4.2345],\n",
      "        [3.5277, 3.9320, 3.8766, 3.8749, 3.7767],\n",
      "        [3.6689, 3.7332, 3.8901, 3.7952, 3.7600],\n",
      "        [3.4105, 3.5685, 3.7319, 3.6235, 3.4803],\n",
      "        [3.6189, 3.5966, 3.9589, 3.8579, 3.6441],\n",
      "        [3.7394, 3.9255, 3.9865, 3.9137, 3.7223],\n",
      "        [3.6959, 4.0651, 4.0436, 3.9621, 3.8863],\n",
      "        [4.0143, 4.2320, 3.9186, 3.9588, 3.7230],\n",
      "        [3.5830, 3.7626, 3.8678, 3.7583, 3.7621],\n",
      "        [3.5699, 3.6666, 3.8255, 3.7424, 3.7509],\n",
      "        [3.6543, 3.6600, 3.8657, 3.7169, 3.6075],\n",
      "        [3.4060, 3.6549, 3.7659, 3.6369, 3.5148],\n",
      "        [3.5407, 3.6962, 3.7012, 3.7418, 3.5943],\n",
      "        [3.6973, 3.7729, 3.7611, 3.8858, 3.7695],\n",
      "        [3.7763, 4.0116, 3.9384, 3.7809, 3.7420],\n",
      "        [3.5385, 3.6741, 3.7331, 3.7268, 3.6059],\n",
      "        [3.5828, 3.6237, 3.8538, 3.7511, 3.6454],\n",
      "        [3.6823, 3.7385, 3.8618, 3.7763, 3.4684],\n",
      "        [3.9784, 4.0220, 4.1111, 4.2695, 3.8122],\n",
      "        [3.6928, 3.8916, 3.8871, 4.0092, 3.7752],\n",
      "        [3.5486, 3.7729, 3.8813, 3.7838, 3.6142],\n",
      "        [3.6928, 3.8916, 3.8871, 4.0092, 3.7752],\n",
      "        [3.6657, 3.8664, 3.8586, 3.9726, 3.7327],\n",
      "        [3.4164, 3.5949, 3.7528, 3.6406, 3.5052],\n",
      "        [3.5561, 3.7231, 3.7044, 3.7902, 3.6014],\n",
      "        [3.5077, 3.9362, 3.9648, 3.8547, 3.8308],\n",
      "        [3.7859, 3.9074, 4.0358, 3.9113, 3.6354],\n",
      "        [3.6480, 3.8812, 3.8447, 3.8204, 3.6896],\n",
      "        [3.4582, 3.7488, 3.9092, 3.6926, 3.6667],\n",
      "        [3.4086, 3.6666, 3.7713, 3.6296, 3.5180],\n",
      "        [3.7626, 3.9346, 3.9278, 3.9130, 3.8314],\n",
      "        [3.5553, 3.6206, 3.8404, 3.7027, 3.5867],\n",
      "        [3.5479, 3.6607, 3.7772, 3.8015, 3.6258],\n",
      "        [3.5780, 3.6181, 3.8639, 3.7729, 3.6316],\n",
      "        [3.8590, 3.7041, 3.8738, 3.8915, 3.7984]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5959, 3.7043, 3.8041, 3.7262, 3.6346],\n",
      "        [3.5562, 3.7236, 3.8307, 3.8100, 3.7189],\n",
      "        [3.5991, 3.8159, 3.8126, 3.7563, 3.6476],\n",
      "        [3.8024, 3.8263, 4.0625, 3.9692, 3.6227],\n",
      "        [3.7089, 3.7747, 3.7513, 3.8959, 3.7905],\n",
      "        [3.4569, 3.5156, 3.7098, 3.6779, 3.4874],\n",
      "        [3.7067, 3.9628, 4.0131, 3.9524, 3.8772],\n",
      "        [3.6143, 3.6122, 3.8483, 3.7557, 3.6600],\n",
      "        [3.7924, 3.7702, 3.9690, 3.9642, 3.7250],\n",
      "        [3.6303, 3.8612, 4.0331, 3.9702, 3.7582],\n",
      "        [3.6447, 3.8734, 3.9289, 3.9051, 3.6802],\n",
      "        [3.6752, 3.7609, 3.9474, 3.8394, 3.6950],\n",
      "        [3.6764, 3.9909, 4.0253, 3.9367, 3.9264],\n",
      "        [3.5573, 3.6909, 3.7893, 3.6788, 3.5127],\n",
      "        [4.0005, 4.0713, 4.1382, 4.2731, 3.9618],\n",
      "        [3.4952, 3.6311, 3.7048, 3.6400, 3.5312],\n",
      "        [3.5495, 3.5682, 3.8380, 3.6428, 3.6365],\n",
      "        [3.5048, 3.7225, 3.8960, 3.8517, 3.5509],\n",
      "        [3.7799, 3.9135, 4.0247, 3.9680, 3.9488],\n",
      "        [3.5391, 3.6984, 3.7014, 3.7633, 3.5906],\n",
      "        [3.6712, 4.0364, 4.0332, 3.9456, 3.9133],\n",
      "        [3.8565, 3.9640, 3.9733, 4.0014, 3.9075],\n",
      "        [3.5750, 3.6947, 3.8218, 3.7335, 3.5120],\n",
      "        [4.1616, 4.3521, 4.1059, 4.1134, 3.8549],\n",
      "        [3.6928, 3.8920, 3.8876, 4.0107, 3.7778],\n",
      "        [3.4290, 3.7155, 3.8002, 3.6598, 3.5664],\n",
      "        [3.6727, 3.6785, 3.8830, 3.8179, 3.6373],\n",
      "        [3.5480, 3.6612, 3.7776, 3.8028, 3.6284],\n",
      "        [3.6563, 3.6557, 3.9833, 3.9039, 3.6263],\n",
      "        [3.6507, 3.7263, 3.9463, 3.8529, 3.6701],\n",
      "        [3.6088, 3.7379, 3.8551, 3.8005, 3.7443],\n",
      "        [3.4442, 3.8357, 3.8341, 3.5979, 3.7013],\n",
      "        [3.5424, 3.6460, 3.8315, 3.7596, 3.6055],\n",
      "        [3.6012, 3.8240, 3.8216, 3.7618, 3.6533],\n",
      "        [3.7055, 3.7541, 3.8836, 3.8016, 3.4959],\n",
      "        [3.7158, 3.9288, 3.9230, 3.9198, 3.7555],\n",
      "        [3.6815, 3.8420, 3.8811, 3.8861, 3.7753],\n",
      "        [3.6537, 3.6190, 3.8082, 3.7384, 3.6732],\n",
      "        [3.5457, 3.5112, 3.7351, 3.6054, 3.4756],\n",
      "        [3.5442, 3.6994, 3.6914, 3.7630, 3.5779],\n",
      "        [3.5259, 3.6854, 3.6946, 3.7162, 3.5779],\n",
      "        [3.4733, 3.7453, 3.6809, 3.7211, 3.5022],\n",
      "        [3.7764, 4.0120, 3.9388, 3.7823, 3.7447],\n",
      "        [3.5532, 3.5593, 3.7073, 3.8056, 3.4992],\n",
      "        [4.1631, 4.3927, 4.0486, 4.0781, 3.8883],\n",
      "        [3.7139, 3.8077, 3.9742, 3.8524, 3.7262],\n",
      "        [3.4077, 3.7036, 3.6266, 3.7130, 3.4737],\n",
      "        [3.4602, 3.6004, 3.7832, 3.7465, 3.5624],\n",
      "        [3.7631, 3.9168, 4.0568, 3.9705, 3.9303],\n",
      "        [3.6476, 3.8296, 3.8531, 3.8541, 3.7044],\n",
      "        [3.4378, 3.5025, 3.7000, 3.6482, 3.4642],\n",
      "        [3.7387, 3.7047, 3.8588, 3.7450, 3.5698],\n",
      "        [3.7804, 3.8108, 3.9684, 3.9607, 3.8986],\n",
      "        [3.6073, 3.9710, 3.8378, 3.8198, 3.8442],\n",
      "        [3.6096, 3.6813, 3.8411, 3.7426, 3.8222],\n",
      "        [3.6638, 3.8471, 3.9292, 3.8324, 3.5772],\n",
      "        [3.6784, 3.6881, 3.8920, 3.8362, 3.6400],\n",
      "        [3.5385, 3.5654, 3.7859, 3.6655, 3.5307],\n",
      "        [3.8650, 3.8789, 4.0532, 4.0581, 3.6944],\n",
      "        [3.4761, 3.6461, 3.6789, 3.6773, 3.5388],\n",
      "        [3.9687, 3.9599, 3.9891, 4.1146, 4.0031],\n",
      "        [3.5559, 3.5377, 3.7399, 3.6989, 3.6793],\n",
      "        [3.9568, 3.8765, 4.0037, 4.1459, 3.8774],\n",
      "        [3.8024, 3.9335, 4.0779, 3.9853, 4.0079]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7512, 3.7931, 3.9184, 3.9518, 3.8703],\n",
      "        [3.5906, 3.8090, 3.7926, 3.7604, 3.6311],\n",
      "        [3.9101, 3.9560, 3.9666, 4.0252, 3.9614],\n",
      "        [3.5747, 3.6914, 3.8519, 3.9056, 3.6574],\n",
      "        [3.4784, 3.5467, 3.8203, 3.6949, 3.5496],\n",
      "        [3.5932, 3.8758, 3.8126, 3.8224, 3.6710],\n",
      "        [3.9960, 3.9064, 4.1393, 4.2069, 3.9285],\n",
      "        [3.6451, 4.1262, 4.0060, 3.9457, 3.9395],\n",
      "        [3.4672, 3.7879, 3.8395, 3.7653, 3.7831],\n",
      "        [3.6893, 3.8463, 3.9905, 3.8634, 3.7145],\n",
      "        [3.5771, 3.9045, 3.9416, 3.9034, 3.8454],\n",
      "        [3.4991, 3.6326, 3.7195, 3.7539, 3.5701],\n",
      "        [4.1090, 4.2691, 4.1097, 4.0711, 3.8972],\n",
      "        [3.5597, 3.7885, 3.8279, 3.7772, 3.6759],\n",
      "        [3.5969, 3.6755, 3.9072, 3.7946, 3.7467],\n",
      "        [3.8838, 3.9950, 4.0368, 4.0113, 3.9160],\n",
      "        [3.8089, 3.9021, 4.0094, 3.9534, 3.8864],\n",
      "        [3.6326, 3.6239, 4.0755, 3.8514, 3.7466],\n",
      "        [3.3731, 3.5647, 3.6429, 3.5428, 3.4731],\n",
      "        [3.3406, 3.5087, 3.5841, 3.5710, 3.4177],\n",
      "        [3.6903, 3.8904, 3.8861, 4.0102, 3.7766],\n",
      "        [3.4973, 3.6169, 3.8088, 3.5986, 3.6405],\n",
      "        [3.6834, 3.7581, 3.7491, 3.8834, 3.7681],\n",
      "        [3.7336, 3.8928, 3.8740, 3.9453, 3.8117],\n",
      "        [3.9623, 3.8860, 4.0110, 4.1517, 3.8792],\n",
      "        [3.4533, 3.5371, 3.6158, 3.6924, 3.4447],\n",
      "        [3.3826, 3.4932, 3.6889, 3.5917, 3.4162],\n",
      "        [3.8089, 3.9609, 3.9637, 3.9661, 3.9001],\n",
      "        [3.7297, 3.9000, 4.0464, 3.9456, 3.9129],\n",
      "        [3.5355, 3.6848, 3.8351, 3.7856, 3.6713],\n",
      "        [3.4008, 3.5115, 3.6921, 3.6000, 3.4391],\n",
      "        [3.4728, 3.6543, 3.6902, 3.6693, 3.5478],\n",
      "        [3.7104, 3.9410, 3.9235, 3.9066, 3.7523],\n",
      "        [3.8734, 3.9605, 3.9708, 4.0099, 3.9309],\n",
      "        [3.5531, 3.5253, 3.7502, 3.6100, 3.4902],\n",
      "        [3.8645, 3.8797, 4.0533, 4.0590, 3.6966],\n",
      "        [4.0037, 3.9834, 4.1587, 4.2871, 3.9996],\n",
      "        [3.4871, 3.6466, 3.6744, 3.6830, 3.5353],\n",
      "        [3.5100, 3.5157, 3.7895, 3.7173, 3.6217],\n",
      "        [3.6552, 3.8847, 3.8548, 3.8255, 3.7059],\n",
      "        [3.5397, 3.7503, 3.7394, 3.8549, 3.5545],\n",
      "        [4.0734, 4.3188, 3.9870, 4.0427, 3.7965],\n",
      "        [3.6912, 3.7123, 3.8046, 3.9612, 3.7418],\n",
      "        [3.8353, 3.9601, 4.0073, 3.9660, 3.8678],\n",
      "        [3.5283, 3.6872, 3.6930, 3.7389, 3.5843],\n",
      "        [3.5496, 3.5969, 3.8438, 3.7281, 3.5904],\n",
      "        [3.8658, 3.8922, 4.1527, 4.1903, 3.7734],\n",
      "        [3.6441, 3.8742, 3.9291, 3.9064, 3.6825],\n",
      "        [3.6050, 3.4720, 3.9205, 3.7859, 3.6126],\n",
      "        [3.6916, 3.8769, 3.8900, 3.8801, 3.7050],\n",
      "        [3.4352, 3.6147, 3.7810, 3.6728, 3.5027],\n",
      "        [3.5388, 3.7338, 3.9115, 3.8700, 3.5845],\n",
      "        [3.8088, 3.6959, 3.8859, 4.1833, 3.8873],\n",
      "        [3.6089, 3.6698, 3.9226, 3.8111, 3.6772],\n",
      "        [3.6821, 3.7394, 3.8623, 3.7786, 3.4734],\n",
      "        [3.4102, 3.6941, 3.7847, 3.6346, 3.5354],\n",
      "        [3.5829, 3.7379, 3.8769, 3.8942, 3.6484],\n",
      "        [3.4300, 3.5958, 3.7472, 3.6434, 3.5244],\n",
      "        [4.2662, 4.4418, 4.1834, 4.1764, 3.9413],\n",
      "        [3.4049, 3.5748, 3.6093, 3.6020, 3.4414],\n",
      "        [3.5864, 3.6212, 3.8973, 3.8026, 3.6898],\n",
      "        [3.5564, 3.9438, 3.8964, 3.9018, 3.8084],\n",
      "        [3.6370, 3.7476, 3.7834, 3.8328, 3.6832],\n",
      "        [3.9915, 3.9341, 4.0214, 4.1111, 3.9570]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6008, 4.0091, 3.9293, 3.9683, 3.8234],\n",
      "        [3.4074, 3.5223, 3.6806, 3.6549, 3.4699],\n",
      "        [3.7130, 3.7154, 3.8187, 4.0078, 3.7706],\n",
      "        [3.9112, 3.7910, 4.0525, 4.4198, 4.1616],\n",
      "        [3.6770, 3.8684, 3.9078, 3.8467, 3.8196],\n",
      "        [3.4707, 3.6085, 3.7590, 3.6283, 3.5427],\n",
      "        [3.5882, 3.8175, 3.8290, 3.7405, 3.6705],\n",
      "        [3.5247, 3.6880, 3.6958, 3.7175, 3.5825],\n",
      "        [3.4877, 3.6554, 3.6793, 3.6818, 3.5584],\n",
      "        [3.6968, 3.8016, 3.9720, 3.9361, 3.8757],\n",
      "        [3.6517, 3.8860, 3.8485, 3.8405, 3.7064],\n",
      "        [3.3045, 3.5251, 3.6960, 3.5530, 3.4949],\n",
      "        [3.7646, 3.7941, 3.9101, 3.9559, 3.8625],\n",
      "        [3.4481, 3.5048, 3.6990, 3.6623, 3.4730],\n",
      "        [3.4916, 3.5448, 3.7419, 3.5524, 3.5741],\n",
      "        [3.8904, 3.7337, 3.9313, 4.2891, 3.9789],\n",
      "        [3.7259, 3.9876, 4.0887, 3.9551, 3.6542],\n",
      "        [3.6896, 3.8923, 3.8873, 4.0107, 3.7792],\n",
      "        [3.7211, 3.9440, 3.9318, 3.8968, 3.7914],\n",
      "        [3.4429, 3.7552, 3.8532, 3.6356, 3.6521],\n",
      "        [3.7139, 3.7599, 3.9000, 3.8139, 3.5355],\n",
      "        [3.6915, 3.8947, 3.8888, 4.0121, 3.7827],\n",
      "        [3.5585, 3.7931, 3.9369, 3.8083, 3.5792],\n",
      "        [3.5381, 3.6356, 3.7340, 3.7707, 3.5638],\n",
      "        [3.9417, 3.8498, 4.0051, 4.0500, 3.8890],\n",
      "        [3.9095, 3.9579, 3.9677, 4.0257, 3.9640],\n",
      "        [3.8693, 3.9344, 4.0541, 4.0371, 4.0619],\n",
      "        [3.8978, 3.9621, 3.9709, 4.0160, 3.9570],\n",
      "        [3.4446, 3.6321, 3.8192, 3.6985, 3.4993],\n",
      "        [3.5967, 3.8620, 3.9092, 3.7997, 3.5437],\n",
      "        [3.9942, 4.0601, 4.0731, 4.3046, 4.0025],\n",
      "        [3.7507, 3.7142, 3.8694, 3.7631, 3.5868],\n",
      "        [3.6444, 3.9023, 3.8826, 3.9599, 3.7370],\n",
      "        [3.4589, 3.6150, 3.6651, 3.6946, 3.4767],\n",
      "        [3.6584, 3.8902, 3.8983, 3.9712, 3.7378],\n",
      "        [3.8181, 3.8771, 4.0285, 4.0974, 4.0249],\n",
      "        [3.4074, 3.7145, 3.9193, 3.6495, 3.5993],\n",
      "        [3.6145, 3.6062, 4.0738, 3.8332, 3.7296],\n",
      "        [3.3226, 3.5510, 3.6961, 3.5779, 3.4953],\n",
      "        [3.6270, 3.6640, 3.8460, 3.6749, 3.4564],\n",
      "        [3.3725, 3.5666, 3.6440, 3.5431, 3.4756],\n",
      "        [3.5407, 3.7606, 3.8605, 3.7679, 3.6535],\n",
      "        [3.4155, 3.7041, 3.7955, 3.6407, 3.5432],\n",
      "        [3.5384, 3.7732, 3.8520, 3.7678, 3.6317],\n",
      "        [3.6627, 3.8497, 3.9305, 3.8339, 3.5822],\n",
      "        [3.9261, 4.1305, 4.0282, 3.9337, 3.8349],\n",
      "        [3.3987, 3.6321, 3.7547, 3.6253, 3.5009],\n",
      "        [3.7476, 4.0234, 4.0000, 4.0514, 3.8527],\n",
      "        [3.6460, 3.7006, 3.8228, 3.8889, 3.6787],\n",
      "        [3.4663, 3.5465, 3.7366, 3.6649, 3.4872],\n",
      "        [3.4900, 3.7083, 3.7648, 3.7871, 3.5641],\n",
      "        [3.6773, 3.6907, 3.8933, 3.8374, 3.6448],\n",
      "        [3.9203, 3.7991, 3.9411, 3.9994, 3.8951],\n",
      "        [3.9869, 4.0296, 4.1154, 4.2811, 3.8253],\n",
      "        [3.5398, 3.6203, 3.8169, 3.7372, 3.6001],\n",
      "        [3.7851, 3.9102, 4.0376, 3.9142, 3.6434],\n",
      "        [3.4668, 3.6966, 3.8846, 3.7253, 3.6702],\n",
      "        [3.6135, 3.6735, 3.9250, 3.8296, 3.6907],\n",
      "        [3.4017, 3.5923, 3.7379, 3.6193, 3.4904],\n",
      "        [3.5349, 3.6047, 3.8049, 3.7233, 3.5893],\n",
      "        [3.6257, 3.6146, 4.0706, 3.8472, 3.7372],\n",
      "        [3.7096, 3.7494, 3.9033, 3.8032, 3.5470],\n",
      "        [3.5858, 3.6231, 3.8985, 3.8031, 3.6924],\n",
      "        [3.7607, 3.7170, 3.8668, 3.7736, 3.6007]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8256, 3.6129, 3.9044, 4.1395, 3.9914],\n",
      "        [3.5544, 3.5424, 3.7420, 3.7001, 3.6866],\n",
      "        [3.8685, 3.9366, 4.0549, 4.0372, 4.0641],\n",
      "        [3.7258, 3.7038, 3.8638, 3.7380, 3.5611],\n",
      "        [3.6811, 3.8679, 3.9101, 3.8510, 3.8162],\n",
      "        [4.0434, 4.2050, 4.0406, 4.0114, 3.8361],\n",
      "        [3.6294, 4.0049, 3.8628, 3.8307, 3.8829],\n",
      "        [3.5310, 3.6226, 3.8111, 3.7341, 3.5949],\n",
      "        [3.3929, 3.5931, 3.6612, 3.5769, 3.4990],\n",
      "        [3.5411, 3.7158, 3.7100, 3.7659, 3.6035],\n",
      "        [3.6772, 3.8643, 4.0079, 3.8878, 3.7118],\n",
      "        [3.6589, 3.8267, 3.9086, 3.8455, 3.8123],\n",
      "        [3.4273, 3.7523, 3.9563, 3.7487, 3.6648],\n",
      "        [3.5247, 3.6953, 3.6933, 3.7534, 3.5786],\n",
      "        [3.5767, 3.7923, 3.7622, 3.9107, 3.5830],\n",
      "        [3.5811, 3.6215, 3.8331, 3.7457, 3.6544],\n",
      "        [3.5440, 3.7100, 3.8150, 3.7924, 3.7128],\n",
      "        [3.4108, 3.5772, 3.6117, 3.6076, 3.4429],\n",
      "        [3.5512, 3.5641, 3.7091, 3.8070, 3.5061],\n",
      "        [3.5116, 3.8950, 3.8978, 3.7386, 3.5230],\n",
      "        [3.8307, 3.5903, 3.8834, 4.1691, 4.0023],\n",
      "        [3.4850, 3.4906, 3.6691, 3.6609, 3.4531],\n",
      "        [3.7306, 3.9430, 3.9851, 3.9230, 3.7397],\n",
      "        [3.5688, 3.6454, 3.9061, 3.7815, 3.6689],\n",
      "        [3.9273, 3.9460, 4.1267, 4.1870, 3.9057],\n",
      "        [3.5780, 3.7638, 3.8634, 3.7594, 3.7669],\n",
      "        [3.8946, 3.9302, 4.0421, 4.1385, 3.8464],\n",
      "        [3.6962, 3.8459, 4.0240, 3.8423, 3.6070],\n",
      "        [3.3990, 3.6495, 3.7591, 3.6230, 3.5085],\n",
      "        [3.7131, 3.9699, 3.9399, 3.9134, 3.7701],\n",
      "        [3.3714, 3.4671, 3.6615, 3.5508, 3.4063],\n",
      "        [3.8361, 3.8804, 4.1219, 4.1679, 3.7579],\n",
      "        [3.6640, 3.8674, 3.8574, 3.9713, 3.7374],\n",
      "        [3.4125, 3.6948, 3.7840, 3.6477, 3.5472],\n",
      "        [3.7613, 3.8705, 4.0299, 4.0515, 3.7322],\n",
      "        [3.5436, 3.6076, 3.8725, 3.7742, 3.6347],\n",
      "        [3.6195, 3.6891, 3.9440, 3.8296, 3.6946],\n",
      "        [3.4962, 3.6604, 3.6783, 3.7072, 3.5439],\n",
      "        [3.5074, 3.6210, 3.5924, 3.7738, 3.4519],\n",
      "        [3.7085, 3.9792, 3.9030, 3.7407, 3.7489],\n",
      "        [3.5382, 3.7065, 3.7066, 3.7662, 3.5976],\n",
      "        [3.7939, 3.6161, 3.9068, 4.1018, 3.9585],\n",
      "        [3.4066, 3.6616, 3.7689, 3.6282, 3.5145],\n",
      "        [3.4528, 3.5353, 3.7208, 3.6712, 3.5020],\n",
      "        [3.5642, 3.7345, 3.7097, 3.8008, 3.6097],\n",
      "        [3.7905, 3.6809, 3.8825, 4.1637, 3.8726],\n",
      "        [3.9998, 4.1002, 4.1523, 4.2934, 4.0109],\n",
      "        [3.6249, 3.9009, 3.8582, 3.9459, 3.7322],\n",
      "        [3.9048, 4.0785, 4.0049, 4.0986, 4.0588],\n",
      "        [3.5501, 3.6554, 3.8367, 3.7754, 3.6160],\n",
      "        [3.8134, 3.9628, 4.1116, 4.1646, 4.1186],\n",
      "        [3.5630, 3.7251, 3.7118, 3.7949, 3.6025],\n",
      "        [3.5943, 3.7091, 3.8060, 3.7274, 3.6419],\n",
      "        [3.5247, 3.6953, 3.6933, 3.7534, 3.5786],\n",
      "        [3.3217, 3.5532, 3.6967, 3.5778, 3.4973],\n",
      "        [3.4714, 3.6481, 3.6850, 3.6529, 3.5617],\n",
      "        [3.5040, 3.5896, 3.7981, 3.6853, 3.5636],\n",
      "        [3.7337, 3.6602, 3.8387, 4.1179, 3.8127],\n",
      "        [3.8374, 3.8864, 4.1133, 4.1699, 3.7824],\n",
      "        [3.5506, 3.6568, 3.7671, 3.7992, 3.5981],\n",
      "        [3.9602, 4.0271, 4.1388, 4.2413, 3.8802],\n",
      "        [3.9661, 4.1175, 4.0535, 4.1640, 4.1309],\n",
      "        [3.4628, 3.4593, 3.7904, 3.4791, 3.6024],\n",
      "        [3.8217, 3.8555, 3.9765, 4.0099, 3.9348]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5423, 4.0385, 4.0335, 3.7835, 3.6518],\n",
      "        [3.5425, 3.7132, 3.7109, 3.7727, 3.6018],\n",
      "        [3.5925, 3.6487, 3.8797, 3.7676, 3.6691],\n",
      "        [3.4178, 3.5464, 3.6850, 3.6172, 3.4991],\n",
      "        [3.4305, 3.4739, 3.6812, 3.6506, 3.4490],\n",
      "        [3.5761, 3.6245, 3.8415, 3.7499, 3.6527],\n",
      "        [3.6958, 3.7513, 3.9039, 3.7938, 3.8131],\n",
      "        [3.5345, 3.6355, 3.8219, 3.6139, 3.4022],\n",
      "        [3.7247, 3.6179, 3.8969, 4.0030, 3.9031],\n",
      "        [3.5093, 3.6878, 3.6989, 3.7204, 3.5767],\n",
      "        [3.4662, 3.6126, 3.8016, 3.7369, 3.5966],\n",
      "        [3.5229, 3.6945, 3.7009, 3.7464, 3.5884],\n",
      "        [3.3989, 3.6267, 3.7544, 3.6312, 3.5123],\n",
      "        [3.5259, 3.6938, 3.6949, 3.7390, 3.5906],\n",
      "        [3.5176, 3.8942, 3.9025, 3.7517, 3.5284],\n",
      "        [3.6065, 3.7177, 3.8206, 3.7341, 3.6568],\n",
      "        [3.5855, 3.9988, 3.9262, 3.9354, 3.8391],\n",
      "        [3.8870, 3.8514, 3.9557, 3.9789, 3.8608],\n",
      "        [3.6100, 3.6090, 3.8354, 3.7787, 3.5884],\n",
      "        [4.0466, 4.1651, 3.8862, 3.9810, 3.7313],\n",
      "        [3.3992, 3.6191, 3.6828, 3.6410, 3.4944],\n",
      "        [3.5372, 3.7090, 3.7068, 3.7658, 3.5993],\n",
      "        [3.7634, 3.8409, 3.9664, 3.9188, 3.8622],\n",
      "        [3.4639, 3.6588, 3.8266, 3.5990, 3.6622],\n",
      "        [3.5798, 3.6195, 3.8775, 3.7625, 3.6601],\n",
      "        [3.5872, 3.6353, 3.8596, 3.7786, 3.6431],\n",
      "        [3.6065, 3.6764, 3.9249, 3.8112, 3.6835],\n",
      "        [3.4077, 3.6879, 3.7773, 3.6348, 3.5372],\n",
      "        [3.7447, 4.0699, 4.0831, 3.9878, 3.9088],\n",
      "        [3.7595, 3.9777, 3.8868, 3.8422, 3.7360],\n",
      "        [3.5242, 3.6359, 3.8744, 3.7507, 3.6239],\n",
      "        [3.7515, 3.5601, 3.7426, 3.7538, 3.7173],\n",
      "        [3.5531, 3.7308, 3.7069, 3.7925, 3.6124],\n",
      "        [3.7293, 4.1871, 4.0963, 4.0071, 4.0368],\n",
      "        [3.6842, 3.8249, 3.8584, 3.7298, 3.6724],\n",
      "        [3.5783, 3.6339, 3.8849, 3.8029, 3.6743],\n",
      "        [3.4000, 3.5971, 3.7387, 3.6188, 3.4941],\n",
      "        [3.7556, 3.9622, 4.0640, 3.8997, 3.5814],\n",
      "        [3.6984, 3.8983, 3.9905, 3.9337, 3.7781],\n",
      "        [4.0390, 4.1559, 3.8815, 3.9649, 3.7349],\n",
      "        [3.8581, 3.7116, 3.8772, 3.8944, 3.8117],\n",
      "        [3.6944, 3.7808, 3.7633, 3.8881, 3.7805],\n",
      "        [3.8607, 3.7926, 4.0051, 4.0270, 3.8050],\n",
      "        [3.7158, 3.8773, 3.9770, 3.8583, 3.5989],\n",
      "        [3.9678, 3.9728, 3.9579, 4.1048, 4.0354],\n",
      "        [3.7185, 3.8120, 3.7917, 3.9177, 3.7965],\n",
      "        [3.3380, 3.5365, 3.6179, 3.5023, 3.4439],\n",
      "        [3.4012, 3.5793, 3.7306, 3.6193, 3.4895],\n",
      "        [3.8218, 3.8869, 4.1021, 4.1044, 3.7621],\n",
      "        [3.3513, 3.5515, 3.6345, 3.5138, 3.4669],\n",
      "        [3.7238, 3.7375, 4.0345, 4.0625, 3.6897],\n",
      "        [3.7872, 3.8720, 4.0540, 3.9868, 3.9493],\n",
      "        [4.0201, 4.1071, 4.1754, 4.3194, 4.0341],\n",
      "        [3.8223, 3.8914, 4.1019, 4.1066, 3.7664],\n",
      "        [3.5555, 3.7317, 3.7211, 3.7963, 3.6145],\n",
      "        [3.9275, 3.9534, 4.1333, 4.1960, 3.9128],\n",
      "        [3.5319, 3.8343, 3.8902, 3.6613, 3.6986],\n",
      "        [3.5591, 3.7333, 3.7243, 3.7959, 3.6200],\n",
      "        [3.3803, 3.4999, 3.6908, 3.5916, 3.4223],\n",
      "        [3.5064, 3.5908, 3.7829, 3.5931, 3.6207],\n",
      "        [3.5355, 4.0145, 4.0297, 3.8190, 3.6446],\n",
      "        [3.4835, 3.8823, 3.8694, 3.6965, 3.5089],\n",
      "        [3.6617, 3.6774, 3.8544, 3.7146, 3.4898],\n",
      "        [3.7462, 3.5567, 3.7378, 3.7630, 3.6989]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5381, 3.7166, 3.8592, 3.8099, 3.6654],\n",
      "        [3.6092, 3.8460, 3.8769, 3.8741, 3.6681],\n",
      "        [3.4269, 3.9077, 3.9222, 3.7525, 3.8036],\n",
      "        [3.5271, 3.5872, 3.8200, 3.7216, 3.5819],\n",
      "        [3.4717, 3.6396, 3.8137, 3.5928, 3.6436],\n",
      "        [3.6176, 3.6828, 3.9283, 3.8261, 3.6933],\n",
      "        [3.3983, 3.5596, 3.7217, 3.6193, 3.4814],\n",
      "        [3.4689, 3.7549, 3.6827, 3.7214, 3.5118],\n",
      "        [3.5003, 3.7328, 3.8989, 3.8537, 3.5610],\n",
      "        [3.7869, 4.0830, 4.0264, 4.0631, 3.9536],\n",
      "        [3.8493, 3.8942, 4.1388, 4.1784, 3.7698],\n",
      "        [3.6367, 3.7383, 3.9302, 3.8267, 3.6826],\n",
      "        [3.4744, 3.7447, 3.9010, 3.8687, 3.5536],\n",
      "        [3.5558, 3.6764, 3.8509, 3.7891, 3.6452],\n",
      "        [3.6580, 3.7199, 3.8457, 3.8047, 3.6342],\n",
      "        [3.3968, 3.5870, 3.6595, 3.5730, 3.4934],\n",
      "        [3.5256, 3.7470, 3.7311, 3.8491, 3.5489],\n",
      "        [3.4044, 3.7221, 3.6296, 3.7029, 3.4827],\n",
      "        [3.4624, 3.6607, 3.8265, 3.5983, 3.6633],\n",
      "        [3.4927, 3.6269, 3.7303, 3.6909, 3.6365],\n",
      "        [3.5719, 4.0290, 3.8939, 3.9736, 3.7988],\n",
      "        [3.7470, 3.8808, 3.9925, 3.8381, 3.7658],\n",
      "        [3.5866, 3.8183, 3.7949, 3.7612, 3.6389],\n",
      "        [3.5431, 3.5884, 3.8315, 3.7138, 3.5944],\n",
      "        [3.5215, 3.6946, 3.6966, 3.7165, 3.5875],\n",
      "        [3.8747, 3.9414, 4.0697, 4.2195, 3.8957],\n",
      "        [3.5474, 3.6823, 3.8256, 3.7589, 3.7224],\n",
      "        [3.7108, 3.9646, 3.9163, 3.8426, 3.7548],\n",
      "        [3.4201, 3.8309, 3.8182, 3.5785, 3.6868],\n",
      "        [3.5304, 3.6985, 3.8660, 3.7819, 3.6858],\n",
      "        [3.5178, 3.8912, 3.8983, 3.7452, 3.5184],\n",
      "        [4.0131, 3.9531, 4.1483, 4.2454, 3.9845],\n",
      "        [3.6748, 3.8693, 4.0080, 3.8869, 3.7146],\n",
      "        [3.7378, 3.5436, 3.7285, 3.7612, 3.6914],\n",
      "        [3.5891, 3.8997, 3.9889, 3.9673, 3.6474],\n",
      "        [3.5469, 3.7337, 3.9915, 3.8197, 3.7683],\n",
      "        [3.6532, 3.6836, 3.8762, 3.7255, 3.5809],\n",
      "        [3.6881, 3.9017, 3.8896, 4.0111, 3.7880],\n",
      "        [3.9465, 3.9593, 3.9353, 4.0994, 4.0419],\n",
      "        [3.3702, 3.5681, 3.5555, 3.6285, 3.4404],\n",
      "        [3.6995, 3.7615, 3.8838, 3.7995, 3.5054],\n",
      "        [3.4824, 3.5673, 3.8299, 3.7065, 3.5654],\n",
      "        [3.6254, 3.9298, 3.9100, 3.8760, 3.8336],\n",
      "        [3.4142, 3.6701, 3.7727, 3.6493, 3.5434],\n",
      "        [3.6480, 3.8350, 3.9138, 3.8449, 3.8296],\n",
      "        [3.4287, 3.6085, 3.7731, 3.6626, 3.4991],\n",
      "        [3.5320, 3.9619, 3.8504, 3.9197, 3.7389],\n",
      "        [3.9254, 3.9485, 4.1238, 4.1791, 3.9042],\n",
      "        [3.7332, 4.0249, 3.9894, 4.0337, 3.8532],\n",
      "        [3.6639, 4.0814, 3.9693, 4.0300, 3.8781],\n",
      "        [3.7755, 3.8750, 4.0510, 4.0653, 3.7400],\n",
      "        [3.5401, 3.9102, 3.9151, 3.8727, 3.8211],\n",
      "        [3.4957, 3.7235, 3.9068, 3.8149, 3.5609],\n",
      "        [3.8975, 3.9455, 4.0670, 4.1432, 3.8353],\n",
      "        [3.7410, 3.7119, 3.8682, 3.7525, 3.5777],\n",
      "        [3.4303, 3.6224, 3.7950, 3.6697, 3.5200],\n",
      "        [3.5374, 3.6433, 3.8262, 3.7445, 3.6060],\n",
      "        [3.4291, 3.7143, 3.8976, 3.6817, 3.6336],\n",
      "        [3.4043, 3.6662, 3.7690, 3.6271, 3.5173],\n",
      "        [3.5776, 3.7125, 3.8216, 3.7279, 3.5299],\n",
      "        [3.6615, 3.8721, 3.8576, 3.9703, 3.7404],\n",
      "        [3.5725, 3.6058, 3.8706, 3.7886, 3.7230],\n",
      "        [3.8869, 4.0603, 3.8977, 3.8936, 3.7513],\n",
      "        [3.9717, 4.1235, 3.9090, 3.9449, 3.7624]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.9577, 3.8967, 4.0137, 4.1507, 3.8882],\n",
      "        [3.6424, 3.8617, 3.8492, 3.9624, 3.7330],\n",
      "        [3.5373, 3.7217, 3.7103, 3.7640, 3.6073],\n",
      "        [3.9819, 4.0393, 4.1172, 4.2806, 3.8319],\n",
      "        [3.4142, 3.7152, 3.7928, 3.6534, 3.5640],\n",
      "        [3.7370, 3.9002, 4.0139, 3.9362, 3.9332],\n",
      "        [3.7612, 4.0519, 4.0207, 4.0657, 3.8796],\n",
      "        [3.4875, 3.5152, 3.7147, 3.6884, 3.4813],\n",
      "        [3.4473, 3.5997, 3.6824, 3.6671, 3.5060],\n",
      "        [3.6307, 3.8926, 4.0647, 3.9969, 3.7798],\n",
      "        [3.5231, 3.8254, 3.8830, 3.7249, 3.7178],\n",
      "        [3.4320, 3.5070, 3.6962, 3.6550, 3.4702],\n",
      "        [3.8097, 3.6701, 3.8480, 3.8472, 3.7726],\n",
      "        [3.5392, 3.7180, 3.7058, 3.7666, 3.6037],\n",
      "        [4.0173, 4.1109, 4.1756, 4.3181, 4.0364],\n",
      "        [3.5385, 3.7442, 3.9075, 3.8692, 3.6118],\n",
      "        [3.7853, 3.7469, 3.8897, 3.8077, 3.6402],\n",
      "        [3.5491, 3.8084, 3.9277, 3.8084, 3.5991],\n",
      "        [3.4054, 3.6217, 3.7599, 3.6380, 3.5205],\n",
      "        [3.4740, 3.6469, 3.8195, 3.5971, 3.6495],\n",
      "        [3.7135, 3.8729, 3.8957, 3.8273, 3.7128],\n",
      "        [3.5014, 3.5159, 3.8273, 3.5412, 3.6388],\n",
      "        [3.4928, 3.6356, 3.8123, 3.6068, 3.6533],\n",
      "        [3.4451, 3.5434, 3.7215, 3.6667, 3.5125],\n",
      "        [3.4820, 3.6644, 3.6870, 3.6683, 3.5717],\n",
      "        [3.5804, 3.6859, 3.8632, 3.6489, 3.7070],\n",
      "        [3.7541, 3.6118, 3.7521, 3.7494, 3.7620],\n",
      "        [3.4633, 3.6531, 3.6837, 3.6428, 3.5559],\n",
      "        [3.4872, 3.6660, 3.6764, 3.6998, 3.5491],\n",
      "        [3.5956, 3.7532, 3.8761, 3.8656, 3.7019],\n",
      "        [3.7891, 4.0193, 4.0993, 3.9523, 3.6517],\n",
      "        [3.7386, 4.0889, 4.0477, 4.1005, 3.9416],\n",
      "        [3.5300, 3.8414, 3.8888, 3.6847, 3.6867],\n",
      "        [4.0429, 3.8281, 4.1011, 4.4643, 4.2483],\n",
      "        [3.5719, 3.6306, 3.8885, 3.7657, 3.6651],\n",
      "        [3.5302, 3.6128, 3.8060, 3.7216, 3.5953],\n",
      "        [3.5349, 3.5602, 3.7772, 3.6492, 3.5255],\n",
      "        [3.6452, 3.6751, 3.8676, 3.7243, 3.5858],\n",
      "        [3.5190, 3.6972, 3.7027, 3.7370, 3.5937],\n",
      "        [3.5334, 3.8466, 3.8933, 3.6681, 3.7099],\n",
      "        [3.8645, 3.9207, 4.0455, 4.0947, 3.7996],\n",
      "        [3.6866, 3.9032, 3.8898, 4.0102, 3.7889],\n",
      "        [3.5182, 3.7447, 3.9547, 3.7248, 3.6367],\n",
      "        [4.0131, 4.1651, 4.0080, 3.9719, 3.7929],\n",
      "        [3.9451, 3.9608, 3.9354, 4.0986, 4.0428],\n",
      "        [3.4267, 3.5639, 3.6961, 3.6311, 3.5061],\n",
      "        [3.7625, 3.9708, 4.0600, 3.9013, 3.5812],\n",
      "        [3.6923, 3.7078, 3.9224, 3.8685, 3.6641],\n",
      "        [3.5800, 3.6489, 3.8464, 3.7787, 3.6529],\n",
      "        [3.5117, 3.5505, 3.8021, 3.6932, 3.5607],\n",
      "        [3.4312, 3.7284, 3.7999, 3.6535, 3.5823],\n",
      "        [3.6491, 3.6818, 3.8673, 3.7306, 3.5712],\n",
      "        [3.7501, 3.9179, 3.8899, 3.9593, 3.8300],\n",
      "        [3.5360, 3.6686, 3.7761, 3.7123, 3.6159],\n",
      "        [3.6880, 3.8992, 3.8820, 3.9996, 3.7747],\n",
      "        [3.9597, 4.0092, 4.1624, 4.2562, 3.7912],\n",
      "        [3.6252, 3.6597, 3.9334, 3.8626, 3.6968],\n",
      "        [3.4444, 3.6389, 3.6729, 3.6358, 3.5383],\n",
      "        [3.5184, 3.5421, 3.8390, 3.5760, 3.6462],\n",
      "        [3.4300, 3.6251, 3.7828, 3.6710, 3.5108],\n",
      "        [3.9112, 3.9550, 4.1281, 4.2085, 3.9335],\n",
      "        [3.5727, 3.7124, 3.7942, 3.7085, 3.6358],\n",
      "        [3.9363, 4.0019, 4.1128, 4.2436, 3.8215],\n",
      "        [3.5900, 3.9750, 4.0155, 3.9189, 3.8828]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7062, 3.7264, 3.9468, 3.9026, 3.6909],\n",
      "        [3.7145, 3.9379, 3.9814, 3.9119, 3.7341],\n",
      "        [3.6206, 3.9078, 3.8585, 3.9447, 3.7367],\n",
      "        [3.6646, 4.0499, 4.0352, 3.9456, 3.9247],\n",
      "        [3.6994, 3.8511, 3.8798, 3.7516, 3.6940],\n",
      "        [3.8071, 3.8640, 4.0830, 4.1634, 3.7871],\n",
      "        [3.3990, 3.5679, 3.6999, 3.6624, 3.4868],\n",
      "        [3.3840, 3.5794, 3.6986, 3.6483, 3.4723],\n",
      "        [3.5307, 3.9264, 3.9495, 3.8577, 3.8372],\n",
      "        [3.9447, 3.9614, 3.9353, 4.0990, 4.0433],\n",
      "        [3.5012, 3.6967, 3.6992, 3.7189, 3.5776],\n",
      "        [3.4414, 3.6866, 3.8764, 3.7193, 3.6649],\n",
      "        [3.7883, 3.8496, 4.0102, 4.0212, 3.7903],\n",
      "        [3.6574, 3.6909, 3.8745, 3.7273, 3.5951],\n",
      "        [3.7027, 3.9789, 3.9567, 3.9043, 3.7864],\n",
      "        [3.9194, 4.0583, 4.0683, 4.0601, 4.0019],\n",
      "        [3.5622, 3.8770, 3.9395, 3.9310, 3.6340],\n",
      "        [3.5349, 3.7107, 3.6989, 3.7637, 3.5945],\n",
      "        [3.6877, 3.7130, 3.9180, 3.8644, 3.6740],\n",
      "        [3.7785, 3.9525, 3.9440, 3.9282, 3.8820],\n",
      "        [3.6378, 3.8863, 3.9317, 3.9071, 3.6917],\n",
      "        [3.5702, 3.6092, 3.8711, 3.7914, 3.7273],\n",
      "        [3.7559, 3.7993, 3.9912, 3.9615, 3.6056],\n",
      "        [3.4546, 3.5376, 3.8048, 3.6709, 3.5480],\n",
      "        [3.3613, 3.4999, 3.6440, 3.5388, 3.4488],\n",
      "        [3.7401, 3.9490, 3.9307, 3.9084, 3.8262],\n",
      "        [3.7082, 3.7245, 3.8198, 4.0063, 3.7771],\n",
      "        [3.5384, 3.6017, 3.8258, 3.7265, 3.5886],\n",
      "        [3.4444, 3.6251, 3.6489, 3.6631, 3.4807],\n",
      "        [3.4529, 3.6870, 3.8454, 3.6116, 3.6897],\n",
      "        [3.4328, 3.7958, 3.8738, 3.6571, 3.6941],\n",
      "        [3.3888, 3.5998, 3.6613, 3.5753, 3.5031],\n",
      "        [3.5352, 3.6251, 3.8160, 3.7328, 3.6051],\n",
      "        [3.5217, 3.6950, 3.6967, 3.7229, 3.5965],\n",
      "        [3.5332, 3.8408, 3.8863, 3.6751, 3.7053],\n",
      "        [3.6882, 3.7625, 3.8764, 3.7859, 3.4933],\n",
      "        [3.6211, 3.6109, 3.9344, 3.9499, 3.5738],\n",
      "        [3.4430, 3.5136, 3.6997, 3.6610, 3.4795],\n",
      "        [3.4983, 3.5385, 3.7885, 3.6793, 3.5438],\n",
      "        [3.7388, 3.8263, 3.9970, 3.9532, 3.6478],\n",
      "        [3.7805, 3.9193, 4.0535, 3.9708, 3.9927],\n",
      "        [3.4933, 3.6438, 3.7214, 3.7529, 3.5789],\n",
      "        [3.5313, 3.5638, 3.8425, 3.6087, 3.6495],\n",
      "        [3.8692, 3.9639, 3.9648, 4.0015, 3.9415],\n",
      "        [3.7105, 3.8914, 3.9841, 3.8607, 3.6146],\n",
      "        [3.5453, 3.9721, 3.8389, 3.7937, 3.8348],\n",
      "        [3.9432, 3.8245, 4.0880, 4.4549, 4.1979],\n",
      "        [3.7644, 3.9820, 3.9803, 3.7989, 3.8012],\n",
      "        [3.4330, 3.4946, 3.6897, 3.6582, 3.4603],\n",
      "        [3.5512, 3.6619, 3.8384, 3.7697, 3.6395],\n",
      "        [3.7865, 3.7824, 3.9714, 3.9648, 3.7362],\n",
      "        [3.4043, 3.5243, 3.6749, 3.6585, 3.4778],\n",
      "        [3.5394, 3.6421, 3.8226, 3.7489, 3.6102],\n",
      "        [3.5662, 3.6290, 3.8436, 3.7608, 3.6388],\n",
      "        [3.7369, 3.8460, 3.9964, 3.9451, 3.6737],\n",
      "        [3.6647, 3.6915, 3.8827, 3.8205, 3.6422],\n",
      "        [3.4247, 3.9102, 3.9227, 3.7521, 3.8053],\n",
      "        [3.9291, 3.9503, 4.1095, 4.1773, 3.9099],\n",
      "        [3.8834, 3.9753, 3.9796, 4.0149, 3.9517],\n",
      "        [3.5373, 3.8334, 3.8767, 3.6847, 3.7007],\n",
      "        [3.4955, 3.6045, 3.8187, 3.7304, 3.5937],\n",
      "        [3.5205, 3.7018, 3.6934, 3.7520, 3.5828],\n",
      "        [3.4437, 3.6320, 3.6539, 3.6959, 3.5260],\n",
      "        [3.6797, 4.0584, 4.0098, 3.9542, 3.9434]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7819, 4.0148, 4.0912, 3.9477, 3.6366],\n",
      "        [4.0310, 3.9128, 4.1378, 4.2349, 3.9798],\n",
      "        [3.4403, 3.8465, 3.8383, 3.5941, 3.7047],\n",
      "        [3.8325, 3.9810, 3.9760, 3.9850, 3.9273],\n",
      "        [3.7552, 3.8011, 3.9909, 3.9623, 3.6059],\n",
      "        [3.7054, 3.7282, 3.9465, 3.9034, 3.6911],\n",
      "        [3.5569, 3.7615, 3.9116, 3.9304, 3.6222],\n",
      "        [3.4604, 3.7074, 3.8848, 3.7246, 3.6766],\n",
      "        [3.6438, 3.7612, 3.9406, 3.8424, 3.6670],\n",
      "        [3.5067, 3.8625, 3.7869, 3.5944, 3.6860],\n",
      "        [3.5159, 3.7113, 3.8551, 3.8179, 3.6275],\n",
      "        [3.5005, 3.6986, 3.6988, 3.7195, 3.5778],\n",
      "        [3.5906, 3.8734, 3.9100, 3.7996, 3.5505],\n",
      "        [3.3669, 3.4910, 3.6762, 3.5688, 3.4127],\n",
      "        [3.7531, 3.8648, 4.1328, 3.8552, 3.5895],\n",
      "        [3.5306, 3.5656, 3.8421, 3.6094, 3.6498],\n",
      "        [3.6749, 3.9888, 3.8785, 3.8912, 3.9135],\n",
      "        [3.6466, 3.6832, 3.8761, 3.7134, 3.6151],\n",
      "        [3.4975, 3.7375, 3.8991, 3.8549, 3.5627],\n",
      "        [3.5371, 3.6918, 3.8494, 3.6462, 3.6698],\n",
      "        [3.7451, 3.9471, 4.0646, 3.8797, 3.5641],\n",
      "        [3.3461, 3.5550, 3.6357, 3.5072, 3.4618],\n",
      "        [3.4433, 3.6414, 3.6723, 3.6368, 3.5391],\n",
      "        [3.6392, 3.6691, 3.8628, 3.7157, 3.5900],\n",
      "        [3.6470, 3.6735, 3.8681, 3.7182, 3.6209],\n",
      "        [3.9640, 3.9788, 3.9574, 4.1046, 4.0384],\n",
      "        [3.7451, 3.8800, 4.0162, 4.0420, 3.7345],\n",
      "        [3.6641, 3.6933, 3.8823, 3.8212, 3.6425],\n",
      "        [3.6854, 3.9058, 3.8893, 4.0115, 3.7897],\n",
      "        [3.3388, 3.5488, 3.6271, 3.5068, 3.4592],\n",
      "        [3.4469, 3.5408, 3.7227, 3.6735, 3.5082],\n",
      "        [3.6912, 3.7277, 3.8936, 3.7732, 3.5881],\n",
      "        [3.8123, 3.8874, 4.0288, 4.0970, 4.0320],\n",
      "        [3.5541, 3.7775, 3.7450, 3.8862, 3.5726],\n",
      "        [3.7917, 4.0992, 3.9925, 4.0301, 3.9914],\n",
      "        [3.5366, 3.8352, 3.8764, 3.6853, 3.7010],\n",
      "        [3.8027, 4.0509, 3.9600, 4.0186, 4.0452],\n",
      "        [3.5338, 3.6310, 3.8175, 3.7368, 3.6069],\n",
      "        [3.4913, 3.6687, 3.6780, 3.7064, 3.5484],\n",
      "        [3.8284, 3.9726, 4.0084, 3.9654, 3.8774],\n",
      "        [3.4820, 3.6660, 3.6797, 3.6810, 3.5650],\n",
      "        [3.3924, 3.6181, 3.7418, 3.6201, 3.5005],\n",
      "        [3.9164, 3.8096, 3.9429, 3.9994, 3.9048],\n",
      "        [3.5552, 3.6781, 3.9245, 3.8913, 3.8272],\n",
      "        [3.4529, 3.6923, 3.8819, 3.7249, 3.6701],\n",
      "        [3.9470, 3.9521, 3.9340, 4.0782, 4.0242],\n",
      "        [3.7259, 3.8873, 3.9993, 3.9424, 3.7363],\n",
      "        [3.9153, 3.9474, 4.1165, 4.1731, 3.9003],\n",
      "        [3.6404, 3.7116, 3.8234, 3.8880, 3.6858],\n",
      "        [3.5183, 3.7419, 3.7941, 3.6340, 3.5492],\n",
      "        [3.5909, 3.8262, 3.8320, 3.7762, 3.7041],\n",
      "        [3.6386, 3.7196, 3.8459, 3.8161, 3.7399],\n",
      "        [3.9875, 3.9467, 4.0249, 4.1119, 3.9703],\n",
      "        [3.6189, 3.6962, 3.9453, 3.8300, 3.7015],\n",
      "        [3.5201, 3.7591, 3.8413, 3.7448, 3.6512],\n",
      "        [3.7303, 4.0290, 3.9891, 4.0346, 3.8549],\n",
      "        [3.7376, 3.5961, 3.7333, 3.7407, 3.7411],\n",
      "        [3.4779, 3.6400, 3.7001, 3.7048, 3.5681],\n",
      "        [3.8853, 3.9511, 3.9493, 4.0200, 3.9438],\n",
      "        [3.6266, 3.9126, 3.8895, 3.8681, 3.8266],\n",
      "        [3.6371, 3.8883, 3.9315, 3.9081, 3.6920],\n",
      "        [3.5324, 3.7514, 3.9294, 3.8307, 3.5891],\n",
      "        [4.0416, 3.8307, 4.1006, 4.4658, 4.2491],\n",
      "        [3.5399, 3.6586, 3.8363, 3.7631, 3.6312]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3187, 3.5246, 3.6093, 3.4809, 3.4281],\n",
      "        [3.9745, 4.0657, 4.1360, 4.2553, 3.9405],\n",
      "        [3.5158, 3.7056, 3.7005, 3.7386, 3.5921],\n",
      "        [3.4033, 3.6259, 3.7586, 3.6393, 3.5221],\n",
      "        [3.9982, 4.0135, 4.1596, 4.2506, 3.8961],\n",
      "        [3.5755, 3.7533, 3.8791, 3.8962, 3.6592],\n",
      "        [3.7196, 3.8371, 4.0051, 3.9373, 3.9106],\n",
      "        [3.5803, 3.6938, 3.8467, 3.6759, 3.4579],\n",
      "        [3.5594, 3.5677, 3.8048, 3.7464, 3.7030],\n",
      "        [3.4920, 3.7308, 3.8905, 3.6711, 3.7477],\n",
      "        [3.7207, 3.9618, 3.9360, 3.9015, 3.8028],\n",
      "        [3.8138, 3.8550, 4.1082, 4.1389, 3.7206],\n",
      "        [3.7009, 3.9825, 3.9559, 3.9058, 3.7876],\n",
      "        [3.8974, 3.9510, 4.0989, 4.1340, 3.9080],\n",
      "        [3.6091, 3.6216, 3.8473, 3.7742, 3.6226],\n",
      "        [3.6790, 3.9006, 3.8820, 4.0026, 3.7810],\n",
      "        [3.6378, 3.7210, 3.8453, 3.8164, 3.7411],\n",
      "        [3.3690, 3.7279, 3.9122, 3.6261, 3.6305],\n",
      "        [3.4652, 3.7605, 3.6816, 3.7219, 3.5144],\n",
      "        [3.4433, 3.6230, 3.6736, 3.6821, 3.5086],\n",
      "        [3.4764, 3.5333, 3.7251, 3.6736, 3.4852],\n",
      "        [3.5560, 3.7631, 3.9111, 3.9309, 3.6232],\n",
      "        [3.6845, 3.9072, 3.8886, 4.0118, 3.7906],\n",
      "        [3.5129, 3.6951, 3.8433, 3.6431, 3.6448],\n",
      "        [3.5251, 3.6994, 3.7651, 3.7026, 3.6115],\n",
      "        [3.4908, 3.7272, 3.9016, 3.8047, 3.5523],\n",
      "        [3.7556, 3.8805, 4.0293, 4.0516, 3.7385],\n",
      "        [3.4460, 3.5514, 3.6166, 3.6923, 3.4544],\n",
      "        [3.5310, 3.6890, 3.7345, 3.7290, 3.6205],\n",
      "        [3.5438, 3.8314, 3.8682, 3.6982, 3.7018],\n",
      "        [3.7278, 3.9620, 4.0115, 3.9274, 3.7546],\n",
      "        [3.4310, 3.5697, 3.7400, 3.6575, 3.5151],\n",
      "        [3.7208, 3.7471, 4.0495, 4.0838, 3.6995],\n",
      "        [3.5582, 3.7003, 3.8210, 3.7289, 3.5250],\n",
      "        [3.4283, 3.6404, 3.6718, 3.6227, 3.5352],\n",
      "        [3.5474, 3.8359, 3.8180, 3.7192, 3.6708],\n",
      "        [3.4049, 3.5872, 3.6107, 3.6070, 3.4481],\n",
      "        [3.5375, 3.7204, 3.7097, 3.7726, 3.6056],\n",
      "        [3.6142, 3.7476, 3.8570, 3.7799, 3.7506],\n",
      "        [3.4472, 3.5195, 3.7031, 3.6666, 3.4831],\n",
      "        [3.4979, 3.6590, 3.7164, 3.6504, 3.5535],\n",
      "        [3.5164, 3.5460, 3.8380, 3.5773, 3.6477],\n",
      "        [3.7152, 3.8734, 3.8955, 3.8103, 3.7156],\n",
      "        [3.8676, 3.9670, 3.9637, 4.0025, 3.9426],\n",
      "        [3.3980, 3.6868, 3.7758, 3.6298, 3.5308],\n",
      "        [3.8929, 3.9452, 4.1130, 4.1938, 3.9267],\n",
      "        [3.4973, 3.6261, 3.7503, 3.6538, 3.5806],\n",
      "        [3.5935, 4.0220, 3.9291, 3.9681, 3.8314],\n",
      "        [3.5400, 3.5393, 3.7224, 3.6797, 3.6823],\n",
      "        [3.5397, 3.5935, 3.8307, 3.7144, 3.5968],\n",
      "        [3.9868, 3.9322, 4.0536, 4.1257, 3.9856],\n",
      "        [3.3654, 3.6038, 3.6783, 3.6120, 3.4944],\n",
      "        [3.7974, 4.0389, 4.1371, 3.9901, 3.6889],\n",
      "        [3.9817, 3.8874, 4.0874, 4.1717, 3.9396],\n",
      "        [3.4004, 3.5693, 3.7271, 3.6242, 3.4890],\n",
      "        [3.7943, 3.9486, 4.0791, 3.9872, 4.0211],\n",
      "        [3.5210, 3.7010, 3.6938, 3.7389, 3.5943],\n",
      "        [3.5890, 3.7188, 3.8055, 3.7265, 3.6481],\n",
      "        [3.5224, 3.7044, 3.6930, 3.7576, 3.5933],\n",
      "        [3.5456, 3.5389, 3.7513, 3.6097, 3.4998],\n",
      "        [3.4482, 3.5499, 3.6190, 3.6918, 3.4124],\n",
      "        [3.5649, 3.6018, 3.8571, 3.7795, 3.7212],\n",
      "        [3.4772, 3.6707, 3.6810, 3.6821, 3.5584],\n",
      "        [3.2789, 3.5188, 3.6882, 3.5322, 3.4864]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4276, 3.7768, 3.8544, 3.6376, 3.6728],\n",
      "        [3.7577, 4.0579, 4.0192, 4.0685, 3.8819],\n",
      "        [3.3516, 3.5541, 3.5683, 3.5435, 3.4162],\n",
      "        [3.7532, 3.9528, 3.9294, 3.9178, 3.8471],\n",
      "        [3.8666, 3.9687, 3.9634, 4.0032, 3.9432],\n",
      "        [3.6344, 3.9497, 3.9912, 3.8497, 3.7754],\n",
      "        [3.9821, 4.2231, 3.8906, 3.9192, 3.7564],\n",
      "        [3.4217, 3.9159, 3.9217, 3.7535, 3.8074],\n",
      "        [3.7142, 3.8753, 3.8952, 3.8110, 3.7161],\n",
      "        [3.5316, 3.5658, 3.7756, 3.6511, 3.5275],\n",
      "        [3.4413, 3.5108, 3.6970, 3.6681, 3.4866],\n",
      "        [3.7121, 3.9521, 3.9914, 3.9295, 3.7592],\n",
      "        [3.9356, 3.8395, 4.0742, 4.4423, 4.1740],\n",
      "        [3.5027, 3.6901, 3.6894, 3.7250, 3.5820],\n",
      "        [3.6895, 4.0055, 3.9220, 3.9169, 3.7617],\n",
      "        [3.3894, 3.6415, 3.7219, 3.6680, 3.4907],\n",
      "        [3.7056, 3.9820, 3.9387, 3.9142, 3.7764],\n",
      "        [3.6221, 3.6654, 3.9318, 3.8648, 3.6991],\n",
      "        [3.4590, 3.6440, 3.6705, 3.6523, 3.5343],\n",
      "        [3.4754, 3.7468, 3.6893, 3.7570, 3.5271],\n",
      "        [4.0073, 4.2476, 3.9194, 3.9610, 3.7386],\n",
      "        [3.4016, 3.5295, 3.6735, 3.6599, 3.4795],\n",
      "        [3.9200, 3.9906, 4.0429, 4.1716, 3.9322],\n",
      "        [3.6549, 3.8702, 3.9151, 3.8470, 3.8280],\n",
      "        [3.5830, 3.6849, 3.8438, 3.6644, 3.4597],\n",
      "        [3.4263, 3.6333, 3.6684, 3.6279, 3.5293],\n",
      "        [3.4320, 3.5262, 3.7052, 3.6505, 3.4806],\n",
      "        [3.5752, 3.6672, 3.8964, 3.7055, 3.7744],\n",
      "        [3.5510, 3.5595, 3.7543, 3.7124, 3.6991],\n",
      "        [3.3863, 3.6050, 3.6598, 3.5767, 3.5047],\n",
      "        [3.4752, 3.5951, 3.8115, 3.7284, 3.6646],\n",
      "        [3.3905, 3.6215, 3.7406, 3.6208, 3.5019],\n",
      "        [3.9407, 3.7927, 4.0504, 4.1027, 3.8669],\n",
      "        [3.4202, 3.7330, 3.8001, 3.6604, 3.5785],\n",
      "        [3.7735, 4.0789, 4.0069, 4.0546, 3.9365],\n",
      "        [3.5535, 3.6996, 3.7906, 3.7530, 3.6980],\n",
      "        [3.6810, 3.9650, 3.8572, 3.7082, 3.6933],\n",
      "        [3.3919, 3.6245, 3.7434, 3.6192, 3.5016],\n",
      "        [4.1901, 4.4543, 4.1024, 4.1797, 3.9100],\n",
      "        [3.7709, 3.8822, 4.0498, 4.0669, 3.7438],\n",
      "        [3.5061, 3.6993, 3.6905, 3.7166, 3.5849],\n",
      "        [3.8874, 3.9428, 4.0412, 4.1390, 3.8526],\n",
      "        [4.0725, 4.1354, 4.2251, 4.3547, 3.8988],\n",
      "        [3.6834, 3.9092, 3.8882, 4.0124, 3.7912],\n",
      "        [3.6201, 3.6788, 3.8453, 3.6754, 3.4646],\n",
      "        [3.7026, 3.7242, 3.9355, 3.9493, 3.6229],\n",
      "        [3.5818, 3.6442, 3.8586, 3.7789, 3.6478],\n",
      "        [3.5063, 3.6233, 3.7984, 3.6073, 3.6542],\n",
      "        [3.4747, 3.4951, 3.6654, 3.6548, 3.4522],\n",
      "        [3.6010, 3.9822, 3.8530, 3.8249, 3.8537],\n",
      "        [3.7248, 3.9080, 3.8735, 3.9454, 3.8218],\n",
      "        [3.5307, 3.6629, 3.8291, 3.7599, 3.6162],\n",
      "        [3.5240, 3.7616, 3.9190, 3.8250, 3.6034],\n",
      "        [3.5446, 3.6257, 3.8288, 3.7360, 3.6080],\n",
      "        [3.5566, 4.0105, 3.8747, 3.9541, 3.7926],\n",
      "        [3.4579, 3.6323, 3.6759, 3.7150, 3.4915],\n",
      "        [3.5741, 3.6284, 3.8762, 3.7628, 3.6645],\n",
      "        [3.7976, 4.0099, 3.8901, 3.8635, 3.7453],\n",
      "        [3.9439, 3.8677, 4.0206, 4.0498, 3.9094],\n",
      "        [4.0664, 4.3335, 3.9874, 4.0428, 3.8075],\n",
      "        [3.7431, 3.7947, 3.9019, 3.9478, 3.8624],\n",
      "        [3.5433, 3.6305, 3.8251, 3.7369, 3.6143],\n",
      "        [3.9079, 3.9618, 4.1270, 4.2117, 3.9360],\n",
      "        [3.6132, 4.0330, 3.9360, 3.9786, 3.8491]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4358, 3.6264, 3.8074, 3.7546, 3.5995],\n",
      "        [3.5893, 3.6278, 3.8668, 3.7633, 3.6667],\n",
      "        [3.6891, 3.8616, 4.0217, 3.8429, 3.6148],\n",
      "        [3.5281, 3.6352, 3.8127, 3.7431, 3.6139],\n",
      "        [3.5560, 3.5847, 3.8302, 3.7523, 3.7116],\n",
      "        [3.4563, 3.6695, 3.8244, 3.5995, 3.6683],\n",
      "        [3.9915, 4.1153, 4.1515, 4.2945, 4.0194],\n",
      "        [3.9570, 3.9758, 3.9390, 4.0989, 4.0384],\n",
      "        [3.5421, 3.6327, 3.8246, 3.7373, 3.6164],\n",
      "        [3.5690, 3.6367, 3.8653, 3.7758, 3.6496],\n",
      "        [3.4435, 3.6495, 3.6727, 3.6503, 3.5404],\n",
      "        [3.9396, 3.7948, 4.0502, 4.1032, 3.8690],\n",
      "        [3.5414, 3.5975, 3.7236, 3.8038, 3.5260],\n",
      "        [3.3772, 3.5112, 3.6544, 3.5652, 3.4658],\n",
      "        [3.6449, 3.6864, 3.8513, 3.7006, 3.4850],\n",
      "        [3.4814, 3.6418, 3.7089, 3.6409, 3.5375],\n",
      "        [3.7023, 3.7336, 3.9447, 3.9047, 3.6947],\n",
      "        [3.4333, 3.4963, 3.6805, 3.6572, 3.4728],\n",
      "        [3.9185, 3.9519, 3.9043, 4.0752, 4.0350],\n",
      "        [3.7610, 3.9231, 4.0549, 4.0030, 3.9429],\n",
      "        [3.4486, 3.6100, 3.7915, 3.7267, 3.5899],\n",
      "        [3.5741, 3.6693, 3.8960, 3.7059, 3.7766],\n",
      "        [3.3666, 3.7320, 3.9111, 3.6268, 3.6330],\n",
      "        [3.4325, 3.5598, 3.7397, 3.6512, 3.4731],\n",
      "        [3.6269, 3.7582, 3.7617, 3.8151, 3.6679],\n",
      "        [3.5023, 3.6990, 3.6968, 3.7212, 3.5830],\n",
      "        [3.9648, 4.1254, 4.0455, 4.1639, 4.1301],\n",
      "        [3.5502, 3.6063, 3.7358, 3.6770, 3.6456],\n",
      "        [3.5233, 3.6269, 3.8152, 3.7441, 3.6096],\n",
      "        [3.7671, 3.8886, 4.1493, 3.8886, 3.6224],\n",
      "        [3.5290, 3.7168, 3.7013, 3.7651, 3.6054],\n",
      "        [3.7100, 3.8169, 3.9977, 3.8497, 3.6149],\n",
      "        [3.5346, 3.6088, 3.8239, 3.7285, 3.5924],\n",
      "        [3.8738, 3.9267, 4.0614, 4.1025, 3.7692],\n",
      "        [3.4401, 3.5125, 3.6967, 3.6773, 3.4942],\n",
      "        [3.6235, 3.9188, 3.8882, 3.8693, 3.8303],\n",
      "        [3.5106, 3.6988, 3.8424, 3.6439, 3.6474],\n",
      "        [3.9555, 4.0260, 4.0799, 4.2154, 3.9649],\n",
      "        [3.8542, 3.8989, 4.0538, 4.0604, 3.7096],\n",
      "        [3.5504, 3.6891, 3.7654, 3.6727, 3.6231],\n",
      "        [3.4264, 3.6342, 3.6707, 3.6156, 3.5293],\n",
      "        [3.3615, 3.4933, 3.6449, 3.5423, 3.4554],\n",
      "        [3.7906, 4.0175, 4.1131, 3.9737, 3.6556],\n",
      "        [3.4282, 3.6263, 3.6422, 3.6558, 3.4735],\n",
      "        [3.6118, 4.0532, 3.9149, 4.0005, 3.8346],\n",
      "        [3.9851, 3.9522, 4.0238, 4.1137, 3.9756],\n",
      "        [3.6024, 3.8445, 3.8403, 3.7761, 3.7173],\n",
      "        [3.4768, 3.6732, 3.6746, 3.6951, 3.5537],\n",
      "        [3.5681, 3.6305, 3.7692, 3.7071, 3.6694],\n",
      "        [3.5382, 3.6574, 3.8293, 3.7489, 3.6214],\n",
      "        [3.6750, 3.7658, 3.9097, 3.8191, 3.7871],\n",
      "        [3.9853, 4.0776, 4.0734, 4.3059, 4.0134],\n",
      "        [3.4790, 3.6519, 3.7203, 3.7575, 3.5805],\n",
      "        [3.4578, 3.9137, 3.9335, 3.8104, 3.8054],\n",
      "        [3.5405, 3.7435, 3.9897, 3.8211, 3.7737],\n",
      "        [3.6544, 3.8544, 3.9319, 3.8675, 3.8394],\n",
      "        [3.4509, 3.5445, 3.8029, 3.6728, 3.5516],\n",
      "        [3.4974, 3.5829, 3.7818, 3.6729, 3.5514],\n",
      "        [3.7780, 4.0180, 4.0910, 3.9455, 3.6493],\n",
      "        [3.7367, 3.8934, 4.0074, 4.0442, 3.7384],\n",
      "        [3.7047, 3.7373, 3.8275, 4.0200, 3.7954],\n",
      "        [3.5466, 3.8845, 3.7789, 3.6109, 3.6586],\n",
      "        [3.7457, 3.9250, 3.8874, 3.9614, 3.8340],\n",
      "        [3.5318, 3.6365, 3.8123, 3.7321, 3.6051]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5371, 3.6212, 3.8150, 3.7326, 3.6105],\n",
      "        [3.5530, 3.7450, 3.7879, 3.8227, 3.6775],\n",
      "        [3.4371, 3.7207, 3.6384, 3.7020, 3.5042],\n",
      "        [3.4378, 3.6022, 3.7522, 3.6063, 3.5345],\n",
      "        [3.5442, 3.7520, 3.9076, 3.9561, 3.5972],\n",
      "        [3.4455, 3.5800, 3.6188, 3.6989, 3.4947],\n",
      "        [3.5705, 3.6363, 3.8041, 3.7301, 3.6754],\n",
      "        [3.4790, 3.6673, 3.7159, 3.6903, 3.5964],\n",
      "        [3.3503, 3.5742, 3.6359, 3.5246, 3.4757],\n",
      "        [3.6057, 3.7075, 3.8399, 3.8460, 3.6587],\n",
      "        [3.5945, 3.5995, 3.9260, 3.9486, 3.5596],\n",
      "        [3.5235, 3.6611, 3.8268, 3.7615, 3.6251],\n",
      "        [3.4653, 3.6183, 3.7505, 3.6371, 3.5549],\n",
      "        [3.9575, 3.9825, 3.9711, 4.1147, 4.0303],\n",
      "        [3.5088, 3.7041, 3.8436, 3.7625, 3.7486],\n",
      "        [3.3873, 3.6085, 3.6550, 3.5717, 3.5068],\n",
      "        [3.7299, 3.7247, 3.8589, 3.7478, 3.5897],\n",
      "        [3.3226, 3.5401, 3.6132, 3.4880, 3.4420],\n",
      "        [3.6376, 3.7333, 3.8492, 3.8182, 3.7530],\n",
      "        [3.5378, 3.7244, 3.6965, 3.7745, 3.6010],\n",
      "        [3.8216, 3.6050, 3.8813, 4.1707, 4.0136],\n",
      "        [3.5014, 3.6422, 3.7502, 3.6568, 3.5938],\n",
      "        [3.6809, 3.9128, 3.8868, 4.0128, 3.7959],\n",
      "        [3.5858, 3.6474, 3.9089, 3.8408, 3.7552],\n",
      "        [3.7080, 3.8902, 3.9746, 3.8595, 3.6086],\n",
      "        [3.4019, 3.6095, 3.6555, 3.5897, 3.5079],\n",
      "        [3.4950, 3.9597, 3.9657, 3.8581, 3.8534],\n",
      "        [3.9922, 4.0066, 4.1594, 4.2920, 4.0168],\n",
      "        [3.4010, 3.6287, 3.6780, 3.5935, 3.5329],\n",
      "        [3.6396, 3.6839, 3.8647, 3.7265, 3.5925],\n",
      "        [3.5874, 3.8377, 3.8132, 3.7605, 3.6654],\n",
      "        [3.4757, 3.5775, 3.8273, 3.7081, 3.5728],\n",
      "        [3.5471, 3.7441, 3.7182, 3.7973, 3.6233],\n",
      "        [3.5354, 3.6592, 3.8357, 3.7664, 3.6417],\n",
      "        [3.4260, 3.6348, 3.6662, 3.6221, 3.5306],\n",
      "        [3.3658, 3.5927, 3.6506, 3.5534, 3.4947],\n",
      "        [3.9385, 3.7961, 4.0498, 4.1033, 3.8715],\n",
      "        [3.4314, 3.5369, 3.7042, 3.6537, 3.4887],\n",
      "        [3.7215, 3.8945, 3.9972, 3.9438, 3.7427],\n",
      "        [3.9858, 3.9270, 4.1407, 4.2088, 3.9449],\n",
      "        [3.3885, 3.5264, 3.6964, 3.6014, 3.4595],\n",
      "        [3.3630, 3.5842, 3.6417, 3.5431, 3.4877],\n",
      "        [3.8981, 3.8141, 4.0459, 4.1001, 3.8421],\n",
      "        [3.5376, 3.5955, 3.7154, 3.6612, 3.6379],\n",
      "        [3.7094, 3.8280, 4.0204, 3.8576, 3.6126],\n",
      "        [3.9349, 3.8672, 4.0054, 4.0520, 3.9068],\n",
      "        [3.8603, 3.7524, 3.9152, 4.2512, 3.9609],\n",
      "        [3.4824, 3.5061, 3.8139, 3.5145, 3.6370],\n",
      "        [3.5326, 3.6981, 3.8469, 3.6472, 3.6757],\n",
      "        [3.6331, 3.7046, 3.9512, 3.8813, 3.6596],\n",
      "        [3.5451, 3.7448, 3.8314, 3.8134, 3.7374],\n",
      "        [3.4568, 3.6254, 3.7986, 3.7375, 3.6051],\n",
      "        [3.3899, 3.6651, 3.7560, 3.6229, 3.5186],\n",
      "        [3.6979, 3.7937, 3.7499, 3.8977, 3.8075],\n",
      "        [3.3801, 3.7204, 3.8798, 3.6556, 3.6529],\n",
      "        [3.4292, 3.6424, 3.6723, 3.6228, 3.5412],\n",
      "        [3.3919, 3.5506, 3.6830, 3.6526, 3.4827],\n",
      "        [3.5239, 3.7077, 3.8040, 3.7264, 3.6473],\n",
      "        [3.5387, 3.6075, 3.7309, 3.7999, 3.5415],\n",
      "        [3.8448, 3.7213, 3.8735, 3.8937, 3.8308],\n",
      "        [3.8183, 3.9814, 3.9681, 3.9805, 3.9388],\n",
      "        [3.4105, 3.5937, 3.7161, 3.6183, 3.5231],\n",
      "        [4.0069, 4.1688, 3.9224, 3.9847, 3.7779],\n",
      "        [3.7901, 3.8477, 4.0622, 3.9714, 3.6402]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4758, 3.6520, 3.8071, 3.7671, 3.5935],\n",
      "        [3.3902, 3.7086, 3.7781, 3.6282, 3.5465],\n",
      "        [3.5965, 3.6303, 3.8403, 3.7849, 3.6369],\n",
      "        [3.9074, 4.1209, 3.9794, 3.9099, 3.7985],\n",
      "        [3.6976, 3.9620, 3.9218, 3.9087, 3.7710],\n",
      "        [3.9136, 3.9613, 4.1230, 4.1884, 3.9130],\n",
      "        [3.6776, 3.9107, 3.8798, 4.0029, 3.7872],\n",
      "        [3.7185, 4.1240, 3.9926, 4.0804, 3.9301],\n",
      "        [3.5075, 3.9096, 3.8991, 3.7531, 3.5392],\n",
      "        [3.5537, 3.7504, 3.7060, 3.8012, 3.6230],\n",
      "        [4.0015, 4.1151, 4.1365, 4.2990, 4.0312],\n",
      "        [3.3894, 3.6407, 3.7502, 3.6313, 3.5237],\n",
      "        [3.8426, 3.9117, 4.0463, 4.0778, 3.8470],\n",
      "        [3.7497, 3.8749, 4.0036, 3.9046, 3.8460],\n",
      "        [3.5026, 3.6274, 3.7960, 3.6073, 3.6615],\n",
      "        [3.4301, 3.5621, 3.7378, 3.6508, 3.4783],\n",
      "        [3.6796, 3.9138, 3.8857, 4.0125, 3.7988],\n",
      "        [3.2741, 3.5250, 3.6854, 3.5326, 3.4940],\n",
      "        [3.6072, 4.0067, 3.9015, 3.9534, 3.8136],\n",
      "        [3.4025, 3.5893, 3.7305, 3.6413, 3.5099],\n",
      "        [3.3463, 3.5718, 3.5469, 3.6219, 3.4449],\n",
      "        [3.8050, 4.0204, 3.9044, 3.8115, 3.7079],\n",
      "        [3.4459, 3.6272, 3.6744, 3.6856, 3.5285],\n",
      "        [3.4437, 3.5562, 3.6163, 3.6924, 3.4202],\n",
      "        [3.4609, 3.6202, 3.7896, 3.7415, 3.5842],\n",
      "        [3.6631, 4.0156, 4.0246, 3.9386, 3.9472],\n",
      "        [3.7509, 3.8869, 4.0268, 4.0527, 3.7469],\n",
      "        [3.4371, 3.7177, 3.8900, 3.7025, 3.6633],\n",
      "        [3.4143, 3.5781, 3.7288, 3.6411, 3.5158],\n",
      "        [3.7034, 3.9282, 3.9633, 3.9382, 3.7613],\n",
      "        [3.6773, 3.9557, 3.9924, 3.9340, 3.8547],\n",
      "        [3.6331, 3.9210, 3.8799, 3.9606, 3.7532],\n",
      "        [3.4686, 3.6737, 3.6747, 3.6827, 3.5636],\n",
      "        [3.7021, 3.9776, 3.9132, 3.8447, 3.7646],\n",
      "        [3.5940, 3.6767, 3.8870, 3.7816, 3.6990],\n",
      "        [3.7569, 3.9824, 4.0555, 3.9034, 3.5904],\n",
      "        [3.6781, 3.8958, 3.9943, 3.8962, 3.7128],\n",
      "        [3.7286, 3.9897, 3.9052, 3.8561, 3.7578],\n",
      "        [3.4766, 3.6736, 3.6762, 3.6819, 3.5737],\n",
      "        [3.5718, 3.6716, 3.8942, 3.7056, 3.7822],\n",
      "        [3.4742, 3.8917, 3.8664, 3.7011, 3.5094],\n",
      "        [3.5494, 3.8160, 3.9045, 3.8024, 3.6175],\n",
      "        [3.4793, 3.7292, 3.7217, 3.7964, 3.5541],\n",
      "        [3.5322, 3.6110, 3.8221, 3.7283, 3.5977],\n",
      "        [3.7181, 3.8728, 3.9945, 3.9482, 3.7114],\n",
      "        [3.5900, 3.6682, 3.9035, 3.8181, 3.6941],\n",
      "        [4.0272, 4.1095, 4.1267, 4.3541, 4.0586],\n",
      "        [3.6855, 3.7178, 3.9183, 3.8708, 3.6738],\n",
      "        [3.9740, 4.0086, 4.0463, 4.1491, 4.0236],\n",
      "        [3.7309, 4.1401, 3.9961, 4.1001, 3.9469],\n",
      "        [3.8119, 3.6201, 3.9072, 4.1390, 3.9935],\n",
      "        [3.6180, 3.7018, 3.9395, 3.8400, 3.7141],\n",
      "        [3.4859, 3.6763, 3.6746, 3.7073, 3.5571],\n",
      "        [3.5224, 3.8474, 3.8865, 3.6608, 3.7107],\n",
      "        [3.5618, 3.6367, 3.8497, 3.7674, 3.6899],\n",
      "        [3.7211, 3.7371, 3.8704, 4.1008, 3.8565],\n",
      "        [3.3963, 3.6887, 3.7691, 3.6313, 3.5399],\n",
      "        [4.0028, 3.9888, 4.0680, 4.1714, 4.0335],\n",
      "        [3.3862, 3.6095, 3.6540, 3.5714, 3.5096],\n",
      "        [3.5408, 3.5802, 3.7058, 3.8075, 3.5198],\n",
      "        [3.5392, 3.8376, 3.8656, 3.6987, 3.7098],\n",
      "        [3.5270, 3.6675, 3.8267, 3.7600, 3.6236],\n",
      "        [3.3858, 3.6461, 3.7194, 3.6678, 3.4979],\n",
      "        [3.6473, 3.8456, 3.9062, 3.8475, 3.8251]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4771, 3.5225, 3.6829, 3.6622, 3.4849],\n",
      "        [3.4660, 3.6148, 3.7952, 3.7291, 3.5927],\n",
      "        [3.5205, 3.7101, 3.8609, 3.7820, 3.6978],\n",
      "        [3.5195, 3.6470, 3.9521, 3.5916, 3.7712],\n",
      "        [3.6421, 3.6398, 3.8063, 3.7386, 3.6976],\n",
      "        [3.6956, 3.9961, 4.0140, 3.9655, 3.9006],\n",
      "        [3.5099, 3.7559, 3.9497, 3.7260, 3.6486],\n",
      "        [3.8646, 3.9567, 4.0660, 4.2228, 3.9092],\n",
      "        [3.4545, 3.6265, 3.7815, 3.7508, 3.5844],\n",
      "        [3.4474, 3.5471, 3.7998, 3.6720, 3.5589],\n",
      "        [3.7008, 3.8419, 3.9997, 3.8398, 3.5608],\n",
      "        [3.3943, 3.6906, 3.7292, 3.6885, 3.5216],\n",
      "        [3.3942, 3.6456, 3.7524, 3.6371, 3.5343],\n",
      "        [3.4077, 3.5766, 3.7273, 3.6396, 3.5160],\n",
      "        [3.7902, 3.9737, 3.9531, 3.9594, 3.9134],\n",
      "        [3.5194, 3.6990, 3.7272, 3.7529, 3.5873],\n",
      "        [3.4333, 3.6487, 3.8260, 3.7656, 3.6278],\n",
      "        [3.4401, 3.5492, 3.7181, 3.6737, 3.5192],\n",
      "        [3.3196, 3.5245, 3.5846, 3.5452, 3.4387],\n",
      "        [3.5131, 3.6261, 3.8307, 3.7574, 3.6802],\n",
      "        [3.4979, 3.6951, 3.6858, 3.7243, 3.5915],\n",
      "        [3.4754, 3.5296, 3.7039, 3.6867, 3.4820],\n",
      "        [3.5527, 3.7553, 3.7109, 3.8058, 3.6335],\n",
      "        [3.4547, 3.6708, 3.8350, 3.7033, 3.6312],\n",
      "        [3.3979, 3.6419, 3.7477, 3.6349, 3.5368],\n",
      "        [3.4366, 3.6811, 3.7067, 3.7445, 3.5381],\n",
      "        [3.5621, 3.6779, 3.8325, 3.6465, 3.4520],\n",
      "        [3.6818, 3.9792, 4.0244, 3.9388, 3.7335],\n",
      "        [3.4754, 3.6742, 3.6750, 3.6812, 3.5758],\n",
      "        [3.6789, 3.9332, 3.9923, 3.9384, 3.8239],\n",
      "        [3.6538, 3.8712, 3.9295, 3.8355, 3.6027],\n",
      "        [3.4234, 3.7397, 3.7942, 3.6542, 3.5938],\n",
      "        [3.9497, 3.9078, 4.0106, 4.1525, 3.9003],\n",
      "        [3.6489, 3.6437, 4.0531, 3.8760, 3.7754],\n",
      "        [3.5766, 3.8325, 3.8268, 3.7622, 3.7164],\n",
      "        [3.5414, 3.7115, 3.7406, 3.7502, 3.6464],\n",
      "        [3.5936, 3.9720, 4.0325, 3.9338, 3.8710],\n",
      "        [3.4474, 3.5471, 3.7998, 3.6720, 3.5589],\n",
      "        [3.5277, 3.6889, 3.7798, 3.7352, 3.6879],\n",
      "        [3.4491, 3.7236, 3.8327, 3.6528, 3.5989],\n",
      "        [3.5357, 3.8908, 3.7944, 3.6147, 3.7046],\n",
      "        [3.7338, 3.8370, 3.9918, 3.9483, 3.6589],\n",
      "        [3.6586, 3.8823, 3.8493, 3.8543, 3.7348],\n",
      "        [4.2282, 4.4370, 4.1497, 4.1628, 3.9323],\n",
      "        [3.4385, 3.6915, 3.6692, 3.7118, 3.5537],\n",
      "        [3.9032, 4.0546, 4.0451, 4.0438, 4.0113],\n",
      "        [3.4658, 3.6390, 3.7970, 3.7680, 3.5933],\n",
      "        [3.3603, 3.4840, 3.6564, 3.5499, 3.4216],\n",
      "        [3.3951, 3.6894, 3.7678, 3.6305, 3.5421],\n",
      "        [3.6506, 3.7462, 3.9719, 3.8881, 3.6781],\n",
      "        [3.5540, 3.5806, 3.8189, 3.7470, 3.7140],\n",
      "        [3.5483, 3.7473, 3.7192, 3.7959, 3.6338],\n",
      "        [3.5680, 3.6439, 3.8622, 3.7792, 3.6682],\n",
      "        [3.5365, 3.7782, 3.8551, 3.7590, 3.7037],\n",
      "        [3.5254, 3.7612, 3.9256, 3.8317, 3.5997],\n",
      "        [3.9062, 4.1214, 3.9782, 3.9092, 3.8006],\n",
      "        [3.5739, 3.7591, 3.8427, 3.7925, 3.7148],\n",
      "        [3.7030, 3.7841, 3.8945, 3.8142, 3.5424],\n",
      "        [3.7669, 3.8954, 4.0427, 3.9949, 3.9584],\n",
      "        [3.5170, 3.5768, 3.8116, 3.7077, 3.5788],\n",
      "        [4.0259, 4.1102, 4.1256, 4.3534, 4.0608],\n",
      "        [3.7743, 3.9532, 4.0701, 3.9133, 3.6764],\n",
      "        [3.5403, 3.6425, 3.8376, 3.7043, 3.6111],\n",
      "        [3.5415, 3.8432, 3.8143, 3.7192, 3.6808]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6320, 3.9965, 3.8654, 3.8537, 3.8934],\n",
      "        [3.7500, 3.9758, 4.0550, 3.8995, 3.5852],\n",
      "        [3.8780, 3.8664, 3.9510, 3.9794, 3.8810],\n",
      "        [3.5555, 3.6411, 3.8263, 3.7530, 3.6531],\n",
      "        [3.5367, 3.7485, 3.8294, 3.8094, 3.7231],\n",
      "        [3.7506, 3.9707, 4.0778, 4.0027, 3.9690],\n",
      "        [3.3804, 3.6109, 3.6546, 3.5750, 3.5158],\n",
      "        [3.6769, 3.9154, 3.8828, 4.0109, 3.8029],\n",
      "        [3.5261, 3.6284, 3.8094, 3.7283, 3.6136],\n",
      "        [3.3792, 3.5782, 3.6875, 3.6487, 3.4866],\n",
      "        [3.5303, 3.6251, 3.8663, 3.7731, 3.6521],\n",
      "        [3.4460, 3.5480, 3.7983, 3.6711, 3.5607],\n",
      "        [3.8409, 3.9007, 4.0319, 4.0754, 3.8480],\n",
      "        [3.8747, 3.9569, 4.0649, 4.2191, 3.9103],\n",
      "        [3.5345, 3.5906, 3.8344, 3.6423, 3.6603],\n",
      "        [3.8531, 3.9258, 4.0652, 4.0445, 3.8480],\n",
      "        [3.3925, 3.7265, 3.6221, 3.7127, 3.4978],\n",
      "        [3.3973, 3.6313, 3.6742, 3.5916, 3.5396],\n",
      "        [3.8043, 3.8632, 4.1001, 4.1363, 3.7307],\n",
      "        [3.4063, 3.5776, 3.7258, 3.6388, 3.5178],\n",
      "        [3.7604, 3.8201, 3.9387, 3.8960, 3.8948],\n",
      "        [3.4084, 3.6270, 3.6651, 3.5894, 3.5525],\n",
      "        [3.8828, 3.7893, 4.0105, 4.0708, 3.8194],\n",
      "        [3.8230, 3.8552, 3.9519, 3.9309, 3.8722],\n",
      "        [3.5713, 3.6603, 3.8402, 3.7791, 3.6671],\n",
      "        [3.5568, 3.6238, 3.7453, 3.6885, 3.6713],\n",
      "        [3.9108, 3.9634, 4.1205, 4.1871, 3.9170],\n",
      "        [3.6769, 3.9154, 3.8828, 4.0109, 3.8029],\n",
      "        [3.5097, 3.7088, 3.6960, 3.7375, 3.6072],\n",
      "        [3.5867, 3.8467, 3.8060, 3.7734, 3.6684],\n",
      "        [3.6891, 3.9264, 3.9630, 4.0175, 3.7704],\n",
      "        [3.6596, 3.7507, 3.8796, 3.7760, 3.8037],\n",
      "        [3.7394, 4.0526, 3.9920, 4.0469, 3.8846],\n",
      "        [3.5348, 3.7304, 3.6898, 3.7728, 3.6064],\n",
      "        [3.5281, 3.7533, 3.8915, 3.9554, 3.5873],\n",
      "        [3.9184, 4.0105, 4.0471, 4.1961, 3.9639],\n",
      "        [3.7523, 3.8566, 3.9613, 3.9183, 3.8805],\n",
      "        [3.5078, 3.6841, 3.7136, 3.7134, 3.6150],\n",
      "        [3.6991, 3.9887, 3.9336, 3.9131, 3.7880],\n",
      "        [3.6447, 3.8749, 3.8642, 3.7596, 3.7624],\n",
      "        [3.9305, 3.8936, 3.9656, 4.0488, 3.9436],\n",
      "        [3.5344, 3.6209, 3.7401, 3.7863, 3.5601],\n",
      "        [3.6185, 3.9235, 3.8840, 3.8675, 3.8395],\n",
      "        [3.5149, 3.7602, 3.7241, 3.8484, 3.5633],\n",
      "        [3.5262, 3.7217, 3.6923, 3.7638, 3.6074],\n",
      "        [3.6153, 3.6033, 3.7669, 3.7109, 3.6722],\n",
      "        [3.5468, 3.8179, 3.9020, 3.8009, 3.6213],\n",
      "        [3.4378, 3.5591, 3.6031, 3.6915, 3.4350],\n",
      "        [3.7720, 3.9303, 4.0322, 3.9129, 3.6649],\n",
      "        [3.5482, 3.6840, 3.9162, 3.8870, 3.8393],\n",
      "        [3.5642, 3.6815, 3.8895, 3.7013, 3.7836],\n",
      "        [3.6558, 4.0630, 4.0284, 3.9457, 3.9380],\n",
      "        [3.6689, 3.7098, 3.8263, 3.9615, 3.7491],\n",
      "        [3.5943, 3.6912, 3.9182, 3.8103, 3.6991],\n",
      "        [3.4607, 3.6559, 3.7111, 3.6728, 3.5780],\n",
      "        [3.5906, 3.6030, 3.9230, 3.9474, 3.5660],\n",
      "        [3.5219, 3.7254, 3.6982, 3.7610, 3.6104],\n",
      "        [3.4175, 3.5755, 3.7427, 3.6521, 3.4870],\n",
      "        [3.6941, 3.7957, 3.7462, 3.8958, 3.8140],\n",
      "        [3.6482, 3.8775, 3.9104, 3.8459, 3.8388],\n",
      "        [3.7920, 3.8919, 4.0216, 4.0638, 4.0305],\n",
      "        [3.3559, 3.4913, 3.6650, 3.5567, 3.4253],\n",
      "        [3.4048, 3.5643, 3.7139, 3.6298, 3.5034],\n",
      "        [3.7271, 3.9130, 4.0076, 3.9375, 3.9467]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3916, 3.5436, 3.6776, 3.6527, 3.4901],\n",
      "        [3.5759, 3.9180, 3.9881, 3.9695, 3.6627],\n",
      "        [3.3329, 3.5596, 3.6228, 3.5075, 3.4718],\n",
      "        [3.6871, 3.7552, 3.8952, 3.7948, 3.5798],\n",
      "        [3.7237, 3.9884, 3.9036, 3.8527, 3.7606],\n",
      "        [3.7185, 3.8896, 3.9930, 4.0256, 3.7459],\n",
      "        [3.6027, 3.6201, 3.9581, 3.8594, 3.6724],\n",
      "        [3.4237, 3.5037, 3.6810, 3.6498, 3.4771],\n",
      "        [3.4863, 3.6862, 3.6795, 3.6974, 3.5872],\n",
      "        [3.9233, 3.8093, 4.0441, 4.0666, 3.8750],\n",
      "        [3.5474, 3.6155, 3.8426, 3.6811, 3.6626],\n",
      "        [3.5290, 3.5339, 3.7336, 3.6046, 3.5000],\n",
      "        [3.5373, 3.6447, 3.8389, 3.7030, 3.6141],\n",
      "        [3.4419, 3.6301, 3.6744, 3.6836, 3.5337],\n",
      "        [3.5094, 3.7107, 3.6971, 3.7451, 3.6053],\n",
      "        [3.9054, 3.9602, 4.1150, 4.1736, 3.9148],\n",
      "        [3.4773, 4.0393, 3.8543, 3.7292, 3.7979],\n",
      "        [3.4688, 3.6797, 3.6783, 3.6808, 3.5714],\n",
      "        [3.5633, 3.6403, 3.8381, 3.7485, 3.6703],\n",
      "        [3.8487, 3.7647, 3.9167, 4.2514, 3.9678],\n",
      "        [3.5323, 3.6830, 3.8436, 3.7759, 3.6488],\n",
      "        [3.9584, 4.1306, 4.0437, 4.1615, 4.1407],\n",
      "        [3.5506, 3.5921, 3.8393, 3.7561, 3.7222],\n",
      "        [3.4465, 3.6284, 3.6601, 3.6827, 3.5001],\n",
      "        [3.5267, 3.7548, 3.8955, 3.9552, 3.5885],\n",
      "        [3.3915, 3.6479, 3.7535, 3.6358, 3.5373],\n",
      "        [4.0060, 4.1251, 4.1740, 4.3188, 4.0517],\n",
      "        [3.4511, 3.6292, 3.7975, 3.7351, 3.6129],\n",
      "        [3.6043, 3.9072, 3.8747, 3.8529, 3.8254],\n",
      "        [3.5189, 3.9773, 3.8471, 3.9202, 3.7546],\n",
      "        [3.5275, 3.6320, 3.8156, 3.7316, 3.6175],\n",
      "        [3.3852, 3.6355, 3.6785, 3.6393, 3.5108],\n",
      "        [3.8946, 3.9584, 4.1181, 4.2005, 3.9416],\n",
      "        [3.7309, 3.7264, 3.8651, 3.7529, 3.5953],\n",
      "        [3.3892, 3.6386, 3.7163, 3.6662, 3.5047],\n",
      "        [3.4257, 3.7634, 3.9585, 3.7311, 3.7027],\n",
      "        [3.4922, 3.6061, 3.7787, 3.5914, 3.6372],\n",
      "        [3.5104, 3.7140, 3.6898, 3.7517, 3.5971],\n",
      "        [3.5149, 3.7213, 3.7011, 3.7449, 3.6118],\n",
      "        [3.7735, 4.0967, 4.0226, 4.0641, 3.9653],\n",
      "        [3.5497, 3.7532, 3.7063, 3.7993, 3.6283],\n",
      "        [3.5740, 3.8445, 3.7966, 3.7618, 3.6589],\n",
      "        [3.3848, 3.6691, 3.7547, 3.6204, 3.5266],\n",
      "        [3.8328, 3.9892, 3.9709, 3.9971, 3.9313],\n",
      "        [3.7288, 3.6114, 3.7278, 3.7333, 3.7632],\n",
      "        [3.7633, 3.8898, 4.0481, 4.0656, 3.7570],\n",
      "        [3.5376, 3.7107, 3.7375, 3.7500, 3.6494],\n",
      "        [3.8736, 3.7996, 4.0388, 4.3981, 4.1755],\n",
      "        [3.3501, 3.4555, 3.6602, 3.6369, 3.4618],\n",
      "        [3.4106, 3.6200, 3.7443, 3.6342, 3.5389],\n",
      "        [3.4395, 3.6460, 3.7852, 3.6104, 3.6824],\n",
      "        [3.5979, 3.8087, 3.9877, 3.8592, 3.7717],\n",
      "        [3.6530, 4.0108, 4.0153, 3.9235, 3.9455],\n",
      "        [3.5387, 3.7136, 3.7420, 3.7490, 3.6495],\n",
      "        [3.7425, 3.9724, 3.9465, 3.9114, 3.8555],\n",
      "        [3.4985, 3.6301, 3.7959, 3.6054, 3.6667],\n",
      "        [3.6792, 3.7292, 3.9060, 3.8627, 3.6787],\n",
      "        [3.6608, 3.8099, 3.9110, 3.9759, 3.7162],\n",
      "        [3.5185, 3.8502, 3.8863, 3.6587, 3.7158],\n",
      "        [3.5249, 3.7770, 3.8496, 3.7524, 3.6873],\n",
      "        [3.5774, 3.6757, 3.8317, 3.7757, 3.6612],\n",
      "        [3.7088, 3.8579, 3.9382, 3.8930, 3.8671],\n",
      "        [3.4922, 3.7429, 3.7710, 3.6113, 3.5473],\n",
      "        [3.7962, 3.8795, 4.0820, 4.1653, 3.8015]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3892, 3.6642, 3.7581, 3.6225, 3.5255],\n",
      "        [3.4938, 3.6982, 3.6894, 3.7222, 3.5955],\n",
      "        [3.5346, 3.6985, 3.8260, 3.7579, 3.7397],\n",
      "        [3.9739, 4.2309, 3.8910, 3.9165, 3.7699],\n",
      "        [3.6997, 3.9858, 3.9530, 3.9028, 3.8154],\n",
      "        [3.6280, 3.6801, 3.8615, 3.7136, 3.6049],\n",
      "        [3.7032, 3.8322, 4.1403, 3.8097, 3.6270],\n",
      "        [3.4282, 3.7391, 3.8353, 3.6658, 3.5836],\n",
      "        [3.5266, 3.6711, 3.8332, 3.7616, 3.6425],\n",
      "        [3.3631, 3.5968, 3.6485, 3.5563, 3.5077],\n",
      "        [3.6429, 3.7847, 3.9262, 3.8129, 3.7182],\n",
      "        [3.6277, 3.9251, 3.8825, 3.9580, 3.7594],\n",
      "        [3.5311, 3.9783, 3.8791, 3.8106, 3.9474],\n",
      "        [3.5551, 3.6116, 3.8567, 3.7776, 3.7356],\n",
      "        [3.5539, 3.6540, 3.8924, 3.7683, 3.6817],\n",
      "        [3.7118, 4.0894, 4.0292, 4.0930, 3.9422],\n",
      "        [3.5312, 3.5489, 3.7224, 3.6776, 3.6969],\n",
      "        [3.5681, 3.9067, 4.0611, 3.9602, 3.7334],\n",
      "        [3.8381, 4.0832, 3.9791, 3.8639, 3.8216],\n",
      "        [3.6504, 3.8444, 3.8596, 3.8583, 3.7923],\n",
      "        [3.4355, 3.6137, 3.6806, 3.6660, 3.5215],\n",
      "        [3.7801, 3.8092, 3.9962, 3.9832, 3.7622],\n",
      "        [3.7101, 3.9735, 3.9378, 3.9001, 3.8164],\n",
      "        [3.5933, 3.9002, 3.9551, 3.9029, 3.6673],\n",
      "        [3.4465, 3.6208, 3.6797, 3.6813, 3.5255],\n",
      "        [3.4400, 3.6400, 3.6805, 3.6948, 3.5268],\n",
      "        [3.5612, 3.8252, 3.8271, 3.7660, 3.7135],\n",
      "        [3.5153, 3.7023, 3.7309, 3.7506, 3.5914],\n",
      "        [3.9831, 4.1263, 4.1486, 4.3043, 4.0544],\n",
      "        [3.6161, 3.9666, 3.9259, 3.8804, 3.8556],\n",
      "        [3.3950, 3.5973, 3.6102, 3.6045, 3.4617],\n",
      "        [3.3956, 3.6143, 3.6564, 3.5865, 3.5168],\n",
      "        [3.5921, 3.7638, 3.8581, 3.8003, 3.7724],\n",
      "        [3.8912, 3.8083, 4.0443, 4.4150, 4.1765],\n",
      "        [3.6903, 3.9545, 3.9181, 3.9143, 3.7750],\n",
      "        [3.4580, 3.6685, 3.6773, 3.6623, 3.5737],\n",
      "        [3.6719, 3.9735, 3.8573, 3.7054, 3.7068],\n",
      "        [3.5518, 3.6102, 3.8551, 3.7735, 3.7315],\n",
      "        [3.5235, 3.7238, 3.6976, 3.7625, 3.6097],\n",
      "        [3.4896, 3.7449, 3.9075, 3.8042, 3.5722],\n",
      "        [3.4758, 4.0404, 3.8567, 3.7283, 3.7988],\n",
      "        [3.3834, 3.6701, 3.7567, 3.6194, 3.5275],\n",
      "        [3.5901, 3.7781, 3.8856, 3.8866, 3.7178],\n",
      "        [3.3902, 3.6489, 3.7556, 3.6349, 3.5383],\n",
      "        [3.6814, 3.8995, 3.8887, 3.9196, 3.7493],\n",
      "        [3.4323, 3.5190, 3.6974, 3.6655, 3.4998],\n",
      "        [3.4068, 3.6543, 3.6786, 3.6124, 3.5504],\n",
      "        [4.0301, 3.8429, 4.1001, 4.4654, 4.2659],\n",
      "        [3.3855, 3.6653, 3.7603, 3.6337, 3.5391],\n",
      "        [3.6419, 3.8851, 3.8611, 3.9690, 3.7648],\n",
      "        [3.3440, 3.5790, 3.6367, 3.5214, 3.4846],\n",
      "        [3.5910, 3.6341, 3.8429, 3.7822, 3.6431],\n",
      "        [3.9063, 3.9608, 4.1065, 4.1708, 3.9234],\n",
      "        [3.3776, 3.6190, 3.6724, 3.5680, 3.5294],\n",
      "        [3.4612, 3.9084, 3.8425, 3.8071, 3.7634],\n",
      "        [3.3892, 3.6105, 3.7386, 3.6208, 3.5115],\n",
      "        [3.8097, 3.6326, 3.9038, 4.1386, 4.0124],\n",
      "        [3.6926, 3.9030, 3.9649, 4.0025, 3.7562],\n",
      "        [3.9456, 3.9113, 4.0149, 4.1506, 3.9042],\n",
      "        [3.3566, 3.5027, 3.6745, 3.5667, 3.4277],\n",
      "        [3.5166, 3.6660, 3.8285, 3.7584, 3.6339],\n",
      "        [3.7223, 3.9895, 3.9064, 3.8517, 3.7614],\n",
      "        [3.5503, 3.6659, 3.9033, 3.6770, 3.7868],\n",
      "        [3.6623, 3.7621, 3.8832, 3.8534, 3.7874]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.9445, 4.0197, 4.1293, 4.2193, 3.7686],\n",
      "        [3.6163, 3.6166, 3.7921, 3.7246, 3.6856],\n",
      "        [3.6413, 3.7937, 3.8810, 3.9624, 3.6943],\n",
      "        [3.7361, 3.9103, 4.0051, 3.8813, 3.6445],\n",
      "        [3.7717, 3.6244, 3.8993, 4.0977, 3.9693],\n",
      "        [3.5603, 3.6843, 3.8965, 3.6987, 3.7866],\n",
      "        [3.3686, 3.5587, 3.5976, 3.6425, 3.4513],\n",
      "        [3.5425, 3.6040, 3.7221, 3.8031, 3.5477],\n",
      "        [3.8924, 3.8562, 3.9363, 3.9784, 3.8720],\n",
      "        [3.6746, 3.7267, 3.9184, 3.8620, 3.6902],\n",
      "        [3.2855, 3.5476, 3.6963, 3.5482, 3.5159],\n",
      "        [3.7706, 4.0984, 4.0275, 4.0618, 3.9669],\n",
      "        [3.5430, 3.7099, 3.7952, 3.7494, 3.7112],\n",
      "        [3.4301, 3.5274, 3.7005, 3.6585, 3.4952],\n",
      "        [3.3781, 3.6752, 3.7649, 3.6279, 3.5331],\n",
      "        [3.7792, 4.1118, 3.9934, 4.0264, 4.0071],\n",
      "        [3.5481, 3.6615, 3.9025, 3.7750, 3.6847],\n",
      "        [3.9849, 4.0901, 4.1981, 4.3190, 4.0311],\n",
      "        [3.5864, 3.9974, 3.8407, 3.8171, 3.8717],\n",
      "        [3.9521, 3.9912, 3.9591, 4.1015, 4.0542],\n",
      "        [3.6610, 3.7626, 3.8851, 3.8520, 3.7881],\n",
      "        [3.5334, 3.7401, 3.7041, 3.7935, 3.6261],\n",
      "        [3.5585, 3.8330, 3.7825, 3.7489, 3.6463],\n",
      "        [3.3490, 3.5141, 3.6436, 3.5357, 3.4643],\n",
      "        [3.3885, 3.7294, 3.6286, 3.7101, 3.5007],\n",
      "        [3.7106, 3.8868, 3.9756, 3.8040, 3.7679],\n",
      "        [3.7683, 3.6844, 3.8695, 3.8353, 3.7513],\n",
      "        [3.5138, 3.6508, 3.9573, 3.5876, 3.7756],\n",
      "        [3.5324, 3.6042, 3.7263, 3.7995, 3.5381],\n",
      "        [3.9837, 4.0136, 4.1663, 4.2882, 4.0269],\n",
      "        [3.5562, 3.8933, 3.9040, 3.7796, 3.5548],\n",
      "        [3.3227, 3.5339, 3.5856, 3.5666, 3.4417],\n",
      "        [3.3925, 3.6458, 3.7526, 3.6312, 3.5414],\n",
      "        [3.5847, 4.0604, 3.9080, 3.9873, 3.8369],\n",
      "        [3.4167, 3.5439, 3.7084, 3.6432, 3.5007],\n",
      "        [4.0250, 4.1723, 3.8826, 3.9614, 3.7539],\n",
      "        [3.7157, 3.9706, 3.9410, 3.8962, 3.8281],\n",
      "        [3.4239, 3.6682, 3.8368, 3.6871, 3.5294],\n",
      "        [3.6845, 3.7567, 3.8992, 3.7925, 3.5814],\n",
      "        [3.4803, 3.7424, 3.9110, 3.8141, 3.5773],\n",
      "        [3.6736, 3.7140, 3.8603, 3.6961, 3.5377],\n",
      "        [3.4678, 3.5827, 3.8304, 3.7037, 3.5822],\n",
      "        [3.4414, 3.7112, 3.8811, 3.7600, 3.7150],\n",
      "        [3.4769, 3.6153, 3.7627, 3.7334, 3.5375],\n",
      "        [3.5463, 3.5694, 3.7712, 3.7234, 3.7198],\n",
      "        [3.5448, 3.7152, 3.7490, 3.8044, 3.6410],\n",
      "        [3.5039, 3.6868, 3.7205, 3.7107, 3.6179],\n",
      "        [3.3908, 3.5402, 3.7031, 3.6029, 3.4894],\n",
      "        [3.5392, 3.7493, 3.7217, 3.7927, 3.6330],\n",
      "        [3.6162, 3.9878, 3.9481, 3.8881, 3.8610],\n",
      "        [3.6857, 3.7943, 4.0840, 3.8248, 3.5779],\n",
      "        [3.7113, 3.7245, 3.8652, 3.7354, 3.5835],\n",
      "        [3.5481, 3.6647, 3.9059, 3.6761, 3.7761],\n",
      "        [3.6278, 3.9995, 3.8725, 3.8510, 3.8961],\n",
      "        [3.3144, 3.5283, 3.5893, 3.5416, 3.4432],\n",
      "        [3.4114, 3.6210, 3.7488, 3.6392, 3.5489],\n",
      "        [3.3152, 3.5454, 3.6154, 3.4834, 3.4515],\n",
      "        [3.4716, 3.7312, 3.7650, 3.7825, 3.5861],\n",
      "        [3.8831, 3.8058, 4.0299, 4.0744, 3.8320],\n",
      "        [3.5938, 3.6266, 3.8363, 3.7756, 3.6069],\n",
      "        [3.5215, 3.7019, 3.8310, 3.7664, 3.7168],\n",
      "        [3.5611, 3.6262, 3.8811, 3.7982, 3.7433],\n",
      "        [3.4925, 3.6987, 3.6912, 3.7207, 3.5961],\n",
      "        [3.5099, 3.6859, 3.9075, 3.8390, 3.7924]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5951, 3.6269, 3.8412, 3.7684, 3.6103],\n",
      "        [3.4713, 3.5334, 3.7106, 3.6815, 3.4864],\n",
      "        [3.6699, 3.8429, 3.8614, 3.7250, 3.6905],\n",
      "        [3.3878, 3.6403, 3.7212, 3.6620, 3.5060],\n",
      "        [3.5060, 3.6356, 3.9318, 3.5816, 3.7597],\n",
      "        [3.6960, 3.8336, 3.9791, 3.8482, 3.7534],\n",
      "        [3.4702, 3.6709, 3.6779, 3.6776, 3.5597],\n",
      "        [3.6971, 3.9137, 4.0064, 3.9060, 3.7993],\n",
      "        [3.4676, 3.6522, 3.7020, 3.6997, 3.5835],\n",
      "        [3.6574, 3.7537, 3.8877, 3.7718, 3.8065],\n",
      "        [3.3794, 3.6753, 3.7660, 3.6262, 3.5330],\n",
      "        [3.4892, 3.9486, 3.7925, 3.6930, 3.7672],\n",
      "        [3.5663, 3.6962, 3.8325, 3.7336, 3.8048],\n",
      "        [3.5122, 3.7632, 3.7318, 3.8439, 3.5662],\n",
      "        [3.5532, 3.6440, 3.8341, 3.7488, 3.6560],\n",
      "        [4.0340, 4.1816, 3.8885, 3.9759, 3.7503],\n",
      "        [3.5747, 3.9267, 3.7847, 3.8068, 3.6618],\n",
      "        [3.5144, 3.7173, 3.7009, 3.7404, 3.6099],\n",
      "        [3.5914, 3.9917, 3.8566, 3.8189, 3.8677],\n",
      "        [3.7015, 3.8880, 3.8986, 3.8241, 3.7290],\n",
      "        [3.5175, 3.7132, 3.8080, 3.7202, 3.6573],\n",
      "        [3.5441, 3.5600, 3.7654, 3.6263, 3.5258],\n",
      "        [3.4925, 3.7220, 3.9748, 3.7770, 3.7594],\n",
      "        [3.8912, 3.8091, 4.0478, 4.4121, 4.1773],\n",
      "        [3.5307, 3.6186, 3.8345, 3.7215, 3.6110],\n",
      "        [3.5439, 3.6989, 3.8536, 3.6398, 3.7050],\n",
      "        [3.5053, 3.7252, 3.8606, 3.8142, 3.6427],\n",
      "        [3.4573, 3.9402, 3.7702, 3.6739, 3.7429],\n",
      "        [3.9735, 3.9167, 4.0183, 4.0866, 3.9778],\n",
      "        [3.6396, 3.6990, 3.8777, 3.7205, 3.5980],\n",
      "        [3.4464, 3.6539, 3.6695, 3.6441, 3.5486],\n",
      "        [3.5090, 3.6537, 3.8761, 3.7456, 3.6419],\n",
      "        [3.6394, 3.8786, 4.0074, 3.9520, 3.8237],\n",
      "        [3.5070, 3.7116, 3.7045, 3.7331, 3.6100],\n",
      "        [3.6410, 4.0698, 3.9545, 4.0115, 3.8738],\n",
      "        [3.2993, 3.5618, 3.6928, 3.5637, 3.4991],\n",
      "        [3.6740, 3.9183, 3.8920, 4.0062, 3.8058],\n",
      "        [3.5072, 3.6714, 3.7666, 3.7158, 3.6752],\n",
      "        [4.0384, 4.1455, 4.1958, 4.3736, 3.9231],\n",
      "        [3.5173, 3.9792, 3.8531, 3.9163, 3.7560],\n",
      "        [3.4069, 3.6550, 3.6815, 3.6093, 3.5510],\n",
      "        [3.4852, 3.7091, 3.8435, 3.6366, 3.6404],\n",
      "        [3.9336, 3.9755, 3.9377, 4.0949, 4.0592],\n",
      "        [3.4724, 3.6273, 3.5714, 3.7504, 3.4609],\n",
      "        [3.7439, 3.8795, 4.0089, 3.8984, 3.8526],\n",
      "        [3.3833, 3.6114, 3.7359, 3.6140, 3.5117],\n",
      "        [4.0210, 4.2855, 3.9442, 3.9813, 3.7679],\n",
      "        [3.4684, 3.8353, 3.8580, 3.7772, 3.8240],\n",
      "        [3.4048, 3.8479, 3.8203, 3.5741, 3.7036],\n",
      "        [3.6034, 3.7095, 3.9459, 3.8240, 3.7146],\n",
      "        [3.7090, 3.7924, 4.0269, 3.8525, 3.5585],\n",
      "        [3.4877, 3.6990, 3.6945, 3.7012, 3.5919],\n",
      "        [3.5715, 3.6262, 3.8878, 3.8035, 3.7465],\n",
      "        [3.6721, 3.9159, 3.8905, 4.0048, 3.8023],\n",
      "        [3.6278, 3.9258, 3.8858, 3.9549, 3.7599],\n",
      "        [3.4249, 3.5423, 3.7089, 3.6476, 3.4979],\n",
      "        [3.5086, 3.9294, 3.9367, 3.8348, 3.8455],\n",
      "        [3.5952, 3.6267, 3.8377, 3.7739, 3.6068],\n",
      "        [3.9499, 4.1270, 3.8963, 3.9207, 3.7688],\n",
      "        [3.4949, 3.6353, 3.7795, 3.7427, 3.5608],\n",
      "        [3.5178, 3.6275, 3.8082, 3.7182, 3.6113],\n",
      "        [3.4658, 3.7607, 3.8967, 3.8618, 3.5536],\n",
      "        [3.6451, 4.0154, 3.9446, 3.8940, 3.7868],\n",
      "        [3.4825, 3.5820, 3.7634, 3.5644, 3.6089]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6528, 4.0111, 3.9477, 3.8900, 3.7946],\n",
      "        [3.7384, 3.9306, 3.8916, 3.9526, 3.8457],\n",
      "        [3.4839, 3.6227, 3.8304, 3.7209, 3.6081],\n",
      "        [3.4721, 3.6381, 3.8091, 3.7321, 3.6052],\n",
      "        [3.7761, 3.7968, 3.9764, 3.9592, 3.7518],\n",
      "        [3.8229, 3.8580, 3.9615, 3.9256, 3.8766],\n",
      "        [3.4591, 3.6690, 3.6812, 3.6574, 3.5750],\n",
      "        [3.5805, 3.6677, 3.9085, 3.8023, 3.7013],\n",
      "        [3.6263, 3.9885, 3.9507, 3.8936, 3.8688],\n",
      "        [3.5506, 3.5935, 3.8455, 3.7504, 3.7243],\n",
      "        [3.3875, 3.9042, 3.8970, 3.7172, 3.8078],\n",
      "        [3.3903, 3.6110, 3.7422, 3.6159, 3.5126],\n",
      "        [3.5385, 3.8472, 3.8233, 3.7122, 3.6855],\n",
      "        [3.6672, 4.0415, 4.0321, 3.9244, 3.8836],\n",
      "        [3.5551, 3.6926, 3.8326, 3.7381, 3.7827],\n",
      "        [3.9377, 3.9150, 4.0428, 4.1379, 3.9390],\n",
      "        [3.4903, 3.9485, 3.7933, 3.6911, 3.7676],\n",
      "        [3.4135, 3.7729, 3.9585, 3.7432, 3.6810],\n",
      "        [3.5220, 3.7658, 3.9366, 3.8251, 3.6042],\n",
      "        [3.6750, 3.9182, 3.8930, 4.0043, 3.8065],\n",
      "        [3.5451, 3.7508, 3.7274, 3.7888, 3.6391],\n",
      "        [3.9580, 4.1325, 4.0503, 4.1553, 4.1426],\n",
      "        [3.6480, 3.8927, 3.8645, 3.9677, 3.7637],\n",
      "        [3.4679, 3.6794, 3.6885, 3.6551, 3.5801],\n",
      "        [3.5182, 3.7012, 3.7724, 3.6958, 3.6360],\n",
      "        [3.4395, 3.6146, 3.7806, 3.6908, 3.5105],\n",
      "        [3.5131, 3.6623, 3.7329, 3.6526, 3.6013],\n",
      "        [3.5496, 3.7588, 3.7191, 3.7986, 3.6388],\n",
      "        [3.5292, 3.6219, 3.8272, 3.7237, 3.6111],\n",
      "        [3.5135, 3.8726, 3.9141, 3.6612, 3.7353],\n",
      "        [3.5159, 3.6347, 3.8207, 3.7313, 3.6197],\n",
      "        [3.6750, 3.9182, 3.8930, 4.0043, 3.8065],\n",
      "        [3.4334, 3.6848, 3.7137, 3.7373, 3.5433],\n",
      "        [3.4758, 3.6861, 3.6854, 3.6867, 3.5766],\n",
      "        [3.7701, 3.7546, 3.8799, 3.7843, 3.6314],\n",
      "        [3.8142, 3.6855, 3.7776, 3.8223, 3.8111],\n",
      "        [3.6991, 3.9614, 3.9348, 3.9021, 3.7870],\n",
      "        [3.6270, 3.7589, 3.7925, 3.8445, 3.7089],\n",
      "        [3.8938, 3.8092, 4.0362, 4.0266, 3.8520],\n",
      "        [3.9589, 3.9951, 4.0261, 4.1335, 4.0283],\n",
      "        [3.8585, 3.9774, 3.9685, 3.9957, 3.9575],\n",
      "        [3.6927, 4.0003, 3.9059, 3.7330, 3.7697],\n",
      "        [3.5534, 3.5994, 3.8479, 3.7534, 3.7299],\n",
      "        [3.4983, 3.7079, 3.6946, 3.7089, 3.5997],\n",
      "        [3.4085, 3.6023, 3.7171, 3.6162, 3.5301],\n",
      "        [3.4820, 3.6872, 3.6853, 3.6851, 3.5809],\n",
      "        [3.6697, 3.7171, 3.9184, 3.8539, 3.6837],\n",
      "        [3.5223, 3.5372, 3.7084, 3.6533, 3.6896],\n",
      "        [3.4738, 3.6724, 3.7209, 3.6823, 3.6067],\n",
      "        [3.6476, 3.7501, 3.9799, 3.8811, 3.6831],\n",
      "        [3.5531, 3.6107, 3.8591, 3.7686, 3.7327],\n",
      "        [3.4665, 3.7658, 3.8812, 3.7036, 3.7013],\n",
      "        [3.4443, 3.5507, 3.8072, 3.6652, 3.5639],\n",
      "        [3.7957, 3.8818, 4.0922, 4.1598, 3.8032],\n",
      "        [3.4887, 3.6366, 3.7532, 3.6469, 3.5962],\n",
      "        [3.5113, 3.7086, 3.6994, 3.7167, 3.6129],\n",
      "        [3.4315, 3.7350, 3.8751, 3.8256, 3.5233],\n",
      "        [3.5263, 3.6243, 3.8231, 3.7217, 3.6154],\n",
      "        [3.5792, 3.6661, 3.8823, 3.7605, 3.6885],\n",
      "        [3.7873, 3.8641, 4.0049, 3.9564, 3.9228],\n",
      "        [3.5676, 3.6961, 3.8333, 3.7318, 3.8054],\n",
      "        [3.9214, 3.9682, 4.0914, 4.1542, 3.9487],\n",
      "        [3.4750, 3.6871, 3.6864, 3.6930, 3.5735],\n",
      "        [3.5185, 3.6960, 3.9199, 3.8512, 3.8033]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3855, 3.6363, 3.6856, 3.6314, 3.5139],\n",
      "        [3.5197, 3.6344, 3.8129, 3.7213, 3.6153],\n",
      "        [3.9385, 3.9143, 4.0441, 4.1361, 3.9400],\n",
      "        [3.5848, 3.8761, 3.9274, 3.8761, 3.6675],\n",
      "        [3.5781, 3.6465, 3.8985, 3.8251, 3.6731],\n",
      "        [3.3829, 3.6132, 3.6605, 3.5617, 3.5181],\n",
      "        [3.3841, 3.6548, 3.7576, 3.6148, 3.5243],\n",
      "        [3.5055, 4.0551, 4.0330, 3.7952, 3.6610],\n",
      "        [3.5625, 3.7696, 3.9118, 3.9284, 3.6543],\n",
      "        [3.6994, 3.9055, 3.9989, 3.9255, 3.7745],\n",
      "        [3.5283, 3.7607, 3.9162, 3.8636, 3.6293],\n",
      "        [3.4232, 3.5076, 3.6940, 3.6505, 3.4774],\n",
      "        [3.5459, 3.7095, 3.8001, 3.7441, 3.7124],\n",
      "        [3.4449, 3.8896, 3.9696, 3.7657, 3.8200],\n",
      "        [3.5480, 3.7500, 3.7942, 3.8123, 3.6890],\n",
      "        [3.4323, 3.9216, 3.7761, 3.6555, 3.7153],\n",
      "        [3.6772, 3.7134, 3.8639, 3.6911, 3.5395],\n",
      "        [3.3584, 3.5837, 3.5588, 3.6201, 3.4595],\n",
      "        [3.3566, 3.4697, 3.6733, 3.6466, 3.4713],\n",
      "        [3.8170, 3.8943, 4.0287, 4.0902, 4.0475],\n",
      "        [3.3459, 3.5790, 3.6410, 3.5147, 3.4870],\n",
      "        [3.8019, 4.0245, 3.9120, 3.8020, 3.7159],\n",
      "        [3.5251, 3.7013, 3.8350, 3.7612, 3.7182],\n",
      "        [3.7601, 3.8952, 4.1562, 3.8779, 3.6349],\n",
      "        [3.4720, 4.0350, 3.8547, 3.7205, 3.7975],\n",
      "        [3.4732, 3.6771, 3.6836, 3.6722, 3.5822],\n",
      "        [3.5172, 3.6199, 3.8125, 3.7135, 3.6098],\n",
      "        [3.9135, 3.9749, 4.1433, 4.1898, 3.9335],\n",
      "        [3.7301, 4.1010, 4.0164, 3.9184, 4.0699],\n",
      "        [3.9306, 3.9734, 4.0820, 4.1473, 3.9631],\n",
      "        [3.5953, 3.9174, 3.8443, 3.9266, 3.7479],\n",
      "        [3.9130, 3.9675, 4.1337, 4.1733, 3.9234],\n",
      "        [3.4859, 3.5220, 3.8267, 3.5309, 3.6499],\n",
      "        [3.3877, 3.6084, 3.8388, 3.6479, 3.6265],\n",
      "        [3.9005, 4.0576, 4.0536, 4.0342, 4.0172],\n",
      "        [3.4021, 3.5722, 3.7270, 3.6185, 3.5073],\n",
      "        [3.6744, 3.7366, 3.8172, 3.9554, 3.7694],\n",
      "        [3.4649, 3.9223, 3.8719, 3.8113, 3.8048],\n",
      "        [3.6962, 3.9838, 3.9488, 3.8914, 3.7997],\n",
      "        [3.5715, 4.0177, 3.9308, 3.9266, 3.8599],\n",
      "        [3.6639, 3.8874, 3.8878, 3.9115, 3.7512],\n",
      "        [3.4968, 3.8745, 3.7912, 3.5858, 3.7027],\n",
      "        [3.4352, 3.6039, 3.6628, 3.6955, 3.5270],\n",
      "        [3.6319, 3.7232, 3.8272, 3.8796, 3.7040],\n",
      "        [3.5636, 3.6550, 3.8362, 3.7523, 3.6602],\n",
      "        [3.4301, 3.8587, 3.8428, 3.5856, 3.7213],\n",
      "        [3.4941, 3.6405, 3.5958, 3.7647, 3.4744],\n",
      "        [3.4184, 3.5079, 3.6913, 3.6444, 3.4798],\n",
      "        [3.4092, 3.6016, 3.7182, 3.6143, 3.5312],\n",
      "        [3.7369, 3.9602, 4.0688, 3.8705, 3.5804],\n",
      "        [3.4791, 3.8493, 3.8668, 3.7785, 3.8178],\n",
      "        [3.3936, 3.7369, 3.6361, 3.6927, 3.5005],\n",
      "        [3.3014, 3.5528, 3.6975, 3.5591, 3.5147],\n",
      "        [3.5286, 3.6145, 3.8299, 3.7190, 3.6060],\n",
      "        [3.3502, 3.4560, 3.6675, 3.6291, 3.4647],\n",
      "        [3.4843, 3.7477, 3.9137, 3.7994, 3.5771],\n",
      "        [3.9612, 4.0537, 4.1270, 4.2688, 3.8454],\n",
      "        [3.7883, 3.9739, 4.1159, 4.1434, 4.1342],\n",
      "        [3.3895, 3.6395, 3.7229, 3.6581, 3.5078],\n",
      "        [3.6559, 3.8858, 3.8589, 3.8457, 3.7411],\n",
      "        [3.4171, 3.6053, 3.7461, 3.6299, 3.5399],\n",
      "        [3.7186, 3.9701, 3.9459, 3.8908, 3.8293],\n",
      "        [3.7887, 3.9470, 4.0510, 3.9863, 4.0097],\n",
      "        [3.9193, 3.9792, 4.1433, 4.1835, 3.9393]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4346, 3.6447, 3.6581, 3.6854, 3.5437],\n",
      "        [4.1466, 4.3396, 4.1414, 4.1065, 3.9476],\n",
      "        [3.4504, 3.6738, 3.8299, 3.5874, 3.6824],\n",
      "        [3.9479, 4.1529, 3.9985, 3.9241, 3.8205],\n",
      "        [3.9855, 4.1253, 4.1556, 4.2953, 4.0571],\n",
      "        [3.5678, 3.8995, 3.9172, 3.7780, 3.5598],\n",
      "        [3.5668, 3.7817, 3.8679, 3.7466, 3.7910],\n",
      "        [3.4487, 3.6213, 3.7904, 3.7288, 3.5895],\n",
      "        [3.9064, 3.9607, 4.1276, 4.1640, 3.9183],\n",
      "        [3.7208, 4.0410, 3.9961, 4.0252, 3.8732],\n",
      "        [3.7372, 3.6939, 3.8534, 4.1180, 3.8487],\n",
      "        [3.5590, 3.7281, 3.8242, 3.7179, 3.5582],\n",
      "        [3.9912, 4.1544, 3.9110, 3.9519, 3.7677],\n",
      "        [3.6744, 3.9725, 3.8632, 3.6966, 3.7093],\n",
      "        [3.4777, 3.6784, 3.6807, 3.6901, 3.5679],\n",
      "        [3.5669, 3.6458, 3.8713, 3.7684, 3.6754],\n",
      "        [3.6472, 3.6459, 4.0627, 3.8649, 3.7822],\n",
      "        [3.5914, 3.6791, 3.8949, 3.7700, 3.7083],\n",
      "        [3.7245, 3.7937, 4.0259, 4.0258, 3.6627],\n",
      "        [3.5429, 3.7493, 3.7218, 3.7892, 3.6386],\n",
      "        [3.7636, 3.8415, 4.0679, 4.0825, 3.7088],\n",
      "        [3.5311, 3.7235, 3.8569, 3.7829, 3.7060],\n",
      "        [3.7146, 4.1278, 4.0029, 4.0691, 3.9394],\n",
      "        [3.5484, 3.7135, 3.7531, 3.7967, 3.6435],\n",
      "        [3.6164, 3.6043, 3.7768, 3.7014, 3.6776],\n",
      "        [3.6461, 3.5474, 3.9819, 3.8261, 3.6889],\n",
      "        [3.4133, 3.4901, 3.6809, 3.6313, 3.4697],\n",
      "        [3.8403, 3.9022, 4.0448, 4.0655, 3.8526],\n",
      "        [3.4307, 3.7376, 3.8405, 3.6569, 3.5864],\n",
      "        [3.5201, 3.8498, 3.8935, 3.6484, 3.7193],\n",
      "        [3.7320, 3.6109, 3.7358, 3.7252, 3.7686],\n",
      "        [3.6201, 3.9866, 3.9525, 3.8806, 3.8633],\n",
      "        [3.3930, 3.6965, 3.7781, 3.6297, 3.5558],\n",
      "        [3.4215, 3.7870, 3.8623, 3.6320, 3.6828],\n",
      "        [3.7299, 3.9628, 3.9396, 3.8993, 3.8433],\n",
      "        [3.6561, 3.7155, 3.8899, 3.7450, 3.5950],\n",
      "        [3.5057, 3.7075, 3.8506, 3.7502, 3.7605],\n",
      "        [3.5205, 3.7837, 3.8662, 3.7546, 3.6559],\n",
      "        [3.3569, 3.8058, 3.8509, 3.7147, 3.5069],\n",
      "        [3.5080, 3.8273, 3.8857, 3.7028, 3.7232],\n",
      "        [3.5586, 3.6393, 3.8586, 3.7559, 3.6989],\n",
      "        [3.4966, 3.9173, 3.9063, 3.7279, 3.5430],\n",
      "        [3.5882, 4.0590, 3.9129, 3.9799, 3.8392],\n",
      "        [3.7370, 3.8320, 4.0229, 3.9144, 3.6434],\n",
      "        [3.4013, 3.6263, 3.6680, 3.5820, 3.5298],\n",
      "        [3.5568, 3.6909, 3.8346, 3.7342, 3.7845],\n",
      "        [3.5215, 3.8534, 3.8916, 3.6735, 3.7055],\n",
      "        [3.7595, 3.8875, 4.0784, 3.9908, 3.9695],\n",
      "        [4.0014, 3.9718, 4.1604, 4.2378, 4.0054],\n",
      "        [3.5464, 3.6135, 3.8484, 3.6673, 3.6673],\n",
      "        [3.5236, 3.6579, 3.7394, 3.7589, 3.5883],\n",
      "        [3.5578, 3.6102, 3.8625, 3.7688, 3.7387],\n",
      "        [3.6755, 3.8996, 4.0032, 3.8843, 3.7215],\n",
      "        [3.4840, 3.7060, 3.8433, 3.6299, 3.6408],\n",
      "        [3.3119, 3.5336, 3.6131, 3.4698, 3.4450],\n",
      "        [3.9130, 3.9694, 4.1384, 4.1787, 3.9288],\n",
      "        [3.7052, 3.8308, 4.1470, 3.8001, 3.6285],\n",
      "        [3.4180, 3.4899, 3.6863, 3.6401, 3.4694],\n",
      "        [3.4892, 3.6952, 3.6929, 3.7074, 3.5847],\n",
      "        [3.4428, 3.6983, 3.8490, 3.6012, 3.7073],\n",
      "        [3.4389, 3.7461, 3.6714, 3.7089, 3.5277],\n",
      "        [3.5335, 3.7277, 3.7042, 3.7624, 3.6133],\n",
      "        [3.4137, 3.7406, 3.8040, 3.6479, 3.5953],\n",
      "        [3.9244, 3.8094, 4.0533, 4.0573, 3.8785]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.9394, 3.9622, 3.9404, 4.0659, 4.0423],\n",
      "        [3.4767, 3.7316, 3.7294, 3.7831, 3.5637],\n",
      "        [3.5616, 3.6801, 3.8434, 3.6344, 3.4588],\n",
      "        [3.9715, 4.0119, 4.0584, 4.1359, 4.0328],\n",
      "        [3.6555, 3.7247, 3.8342, 3.9186, 3.7512],\n",
      "        [3.7899, 3.8618, 4.0074, 3.9510, 3.9255],\n",
      "        [3.6583, 3.7014, 3.8903, 3.8062, 3.6676],\n",
      "        [3.4502, 3.4767, 3.7957, 3.4652, 3.6243],\n",
      "        [3.5995, 3.6936, 3.9307, 3.8166, 3.7156],\n",
      "        [3.5494, 4.0190, 3.8828, 3.9417, 3.8093],\n",
      "        [3.5156, 3.5783, 3.8216, 3.6956, 3.5860],\n",
      "        [3.6567, 3.8845, 3.8603, 3.8422, 3.7419],\n",
      "        [3.9013, 4.0560, 4.0546, 4.0305, 4.0180],\n",
      "        [3.7032, 3.9307, 3.9778, 3.9382, 3.7718],\n",
      "        [3.4168, 3.5707, 3.7402, 3.6463, 3.5194],\n",
      "        [3.5952, 3.8704, 4.0202, 3.9368, 3.7671],\n",
      "        [3.3843, 3.5045, 3.6942, 3.6191, 3.4956],\n",
      "        [3.5198, 3.9774, 3.8569, 3.9092, 3.7585],\n",
      "        [3.8039, 3.8656, 4.1189, 4.1250, 3.7353],\n",
      "        [3.4279, 3.5766, 3.6477, 3.6802, 3.4575],\n",
      "        [3.4119, 3.5394, 3.7121, 3.6289, 3.4974],\n",
      "        [3.5441, 3.8259, 3.8549, 3.7065, 3.7046],\n",
      "        [3.4015, 3.6192, 3.7589, 3.6296, 3.5369],\n",
      "        [3.4215, 3.6382, 3.7854, 3.6591, 3.5298],\n",
      "        [3.4737, 3.6359, 3.8116, 3.7267, 3.6072],\n",
      "        [3.7020, 3.9850, 3.9629, 3.8923, 3.8178],\n",
      "        [3.5096, 3.6698, 3.7718, 3.7086, 3.6772],\n",
      "        [3.4638, 3.9071, 3.8492, 3.7968, 3.7662],\n",
      "        [3.4738, 3.6569, 3.7270, 3.7439, 3.5951],\n",
      "        [3.7742, 3.6822, 3.8742, 3.8273, 3.7548],\n",
      "        [3.5883, 3.6725, 3.9132, 3.8009, 3.7075],\n",
      "        [3.6061, 3.7070, 3.9489, 3.8165, 3.7174],\n",
      "        [3.7555, 3.9939, 3.9866, 3.7868, 3.8192],\n",
      "        [3.5184, 3.7961, 3.8906, 3.7352, 3.6694],\n",
      "        [3.9542, 3.9849, 3.9988, 4.1041, 4.0333],\n",
      "        [3.5838, 3.7271, 3.8107, 3.7142, 3.6659],\n",
      "        [3.5312, 3.6625, 3.8445, 3.7529, 3.6534],\n",
      "        [3.3591, 3.4859, 3.6645, 3.5378, 3.4293],\n",
      "        [3.4342, 3.5253, 3.7052, 3.6498, 3.4976],\n",
      "        [3.7658, 3.8544, 3.9859, 3.9659, 3.9124],\n",
      "        [3.3144, 3.5444, 3.6215, 3.4738, 3.4555],\n",
      "        [3.5903, 3.6054, 3.9418, 3.9368, 3.5705],\n",
      "        [3.8139, 3.9851, 3.9782, 3.9672, 3.9502],\n",
      "        [3.5529, 3.6624, 3.9101, 3.6670, 3.7789],\n",
      "        [3.5096, 3.6343, 3.9226, 3.5886, 3.7612],\n",
      "        [3.4752, 3.6251, 3.5743, 3.7436, 3.4638],\n",
      "        [3.6766, 3.9159, 3.8955, 3.9985, 3.8088],\n",
      "        [3.9140, 3.9665, 4.1360, 4.1697, 3.9241],\n",
      "        [3.4859, 3.6863, 3.6977, 3.7008, 3.5936],\n",
      "        [3.7028, 3.7452, 3.9665, 3.8968, 3.7231],\n",
      "        [3.7653, 3.8891, 4.0582, 4.0543, 3.7610],\n",
      "        [3.4064, 3.5784, 3.7369, 3.6273, 3.5231],\n",
      "        [3.6996, 3.8788, 4.0421, 3.8449, 3.6316],\n",
      "        [3.6821, 3.9723, 4.0075, 3.9205, 3.8889],\n",
      "        [3.7644, 3.8223, 3.9533, 3.8878, 3.9052],\n",
      "        [3.8487, 3.9040, 4.0626, 4.0467, 3.7232],\n",
      "        [3.5286, 3.6449, 3.8285, 3.7354, 3.6219],\n",
      "        [3.5643, 3.8240, 3.7893, 3.7422, 3.6445],\n",
      "        [3.4946, 3.7420, 3.7780, 3.6002, 3.5512],\n",
      "        [3.5610, 3.6848, 3.9426, 3.8040, 3.7027],\n",
      "        [3.5971, 3.9422, 3.8107, 3.8140, 3.6877],\n",
      "        [3.8657, 4.0310, 4.0287, 4.0039, 3.9793],\n",
      "        [3.5594, 4.0448, 3.9003, 3.9629, 3.8187],\n",
      "        [3.8356, 3.8894, 4.0440, 4.0348, 3.8476]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6748, 3.9137, 3.8897, 3.9872, 3.7980],\n",
      "        [3.8155, 3.7037, 3.8683, 3.8628, 3.8147],\n",
      "        [3.5030, 3.9728, 3.8286, 3.7440, 3.8215],\n",
      "        [3.7012, 3.9124, 4.0062, 3.8346, 3.6516],\n",
      "        [3.3916, 3.8305, 3.8094, 3.5481, 3.6943],\n",
      "        [3.5412, 3.7473, 3.7150, 3.7633, 3.6384],\n",
      "        [3.4739, 3.6367, 3.8116, 3.7251, 3.6080],\n",
      "        [3.7416, 3.7352, 3.8763, 3.7512, 3.6164],\n",
      "        [3.6458, 3.7839, 3.9330, 3.8009, 3.7221],\n",
      "        [3.4731, 4.0344, 3.8559, 3.7153, 3.7988],\n",
      "        [3.7650, 3.8993, 4.0571, 3.9806, 3.9655],\n",
      "        [3.5437, 3.6911, 3.8313, 3.7347, 3.7622],\n",
      "        [3.6749, 3.9144, 3.8940, 3.9954, 3.8062],\n",
      "        [3.9496, 4.0279, 4.1770, 4.2462, 3.8109],\n",
      "        [3.5314, 3.6633, 3.8445, 3.7513, 3.6542],\n",
      "        [3.5854, 3.8890, 3.8016, 3.6119, 3.6398],\n",
      "        [3.5394, 3.6733, 3.9417, 3.8416, 3.7033],\n",
      "        [3.5683, 3.9003, 3.9182, 3.7749, 3.5606],\n",
      "        [3.5056, 3.5462, 3.8064, 3.7049, 3.6478],\n",
      "        [3.4967, 3.9713, 3.8035, 3.7027, 3.7891],\n",
      "        [3.7496, 3.6324, 3.9074, 4.0418, 3.9523],\n",
      "        [3.5604, 3.8925, 3.9102, 3.7690, 3.5574],\n",
      "        [3.6060, 4.0605, 3.9239, 3.9861, 3.8501],\n",
      "        [3.3529, 3.7392, 3.9174, 3.6149, 3.6420],\n",
      "        [3.5335, 3.6170, 3.8377, 3.7127, 3.6145],\n",
      "        [3.7439, 3.7075, 3.8694, 4.0612, 3.8411],\n",
      "        [3.7213, 3.9719, 4.0174, 3.9128, 3.7733],\n",
      "        [3.4712, 3.8341, 3.8615, 3.7683, 3.8271],\n",
      "        [3.6768, 3.9167, 3.8956, 3.9968, 3.8097],\n",
      "        [3.5137, 3.5765, 3.8175, 3.6907, 3.5913],\n",
      "        [3.7545, 3.8581, 3.9736, 3.9052, 3.8882],\n",
      "        [3.7392, 4.0553, 4.0059, 4.0341, 3.8907],\n",
      "        [3.6749, 3.9144, 3.8940, 3.9954, 3.8062],\n",
      "        [3.4390, 3.7962, 3.8468, 3.7386, 3.7970],\n",
      "        [3.5702, 3.6396, 3.8380, 3.7311, 3.6790],\n",
      "        [3.7083, 3.8831, 3.9031, 3.7967, 3.7335],\n",
      "        [3.6858, 4.0309, 4.0576, 3.9149, 3.8705],\n",
      "        [3.4244, 3.5070, 3.6953, 3.6455, 3.4790],\n",
      "        [3.4876, 3.8680, 3.8756, 3.7173, 3.5825],\n",
      "        [3.7449, 3.9819, 4.0691, 3.8849, 3.6021],\n",
      "        [3.3437, 3.5751, 3.5548, 3.6079, 3.4553],\n",
      "        [3.7630, 3.9919, 4.0079, 3.9986, 4.0311],\n",
      "        [3.3892, 3.7606, 3.8380, 3.6833, 3.5489],\n",
      "        [3.3793, 3.6062, 3.6578, 3.5545, 3.5186],\n",
      "        [3.3403, 3.5685, 3.6374, 3.4994, 3.4886],\n",
      "        [3.6939, 3.7770, 3.8912, 3.7892, 3.5283],\n",
      "        [3.4636, 3.6200, 3.7837, 3.6957, 3.5335],\n",
      "        [3.3788, 3.7255, 3.9025, 3.6471, 3.6300],\n",
      "        [3.8059, 3.8689, 4.1232, 4.1264, 3.7378],\n",
      "        [3.7459, 3.8939, 4.0528, 3.9813, 3.9681],\n",
      "        [3.5171, 3.7158, 3.7041, 3.7314, 3.6137],\n",
      "        [3.5373, 3.8778, 3.9893, 3.9574, 3.6672],\n",
      "        [3.5452, 3.5578, 3.7703, 3.6095, 3.5284],\n",
      "        [3.4268, 3.6166, 3.7727, 3.6427, 3.5219],\n",
      "        [3.3125, 3.5339, 3.6133, 3.4670, 3.4461],\n",
      "        [3.8319, 3.8844, 3.8643, 3.9483, 3.8756],\n",
      "        [3.9320, 3.8587, 4.0761, 4.1231, 3.8870],\n",
      "        [3.5920, 3.6795, 3.8952, 3.7669, 3.7094],\n",
      "        [4.1493, 4.3759, 4.1137, 4.0995, 3.8872],\n",
      "        [3.4177, 3.6380, 3.6725, 3.5998, 3.5386],\n",
      "        [3.6470, 3.6969, 3.8880, 3.6973, 3.6626],\n",
      "        [3.3860, 3.6322, 3.7483, 3.6042, 3.5191],\n",
      "        [3.5326, 3.6319, 3.8292, 3.7201, 3.6237],\n",
      "        [3.7192, 3.7405, 3.8794, 4.0866, 3.8674]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4331, 3.8326, 3.8847, 3.6657, 3.7136],\n",
      "        [3.3820, 3.6280, 3.7489, 3.6048, 3.5165],\n",
      "        [3.4363, 3.6037, 3.6636, 3.6902, 3.5293],\n",
      "        [3.5117, 3.9591, 3.8847, 3.8635, 3.8111],\n",
      "        [3.4142, 3.5540, 3.7108, 3.6136, 3.4975],\n",
      "        [3.4664, 3.9036, 3.8595, 3.6665, 3.5311],\n",
      "        [3.8159, 3.7041, 3.8680, 3.8625, 3.8154],\n",
      "        [3.7828, 3.8095, 4.0034, 3.9712, 3.7662],\n",
      "        [3.4452, 3.7103, 3.8850, 3.7490, 3.7186],\n",
      "        [3.5104, 3.9172, 3.9586, 3.8310, 3.8218],\n",
      "        [3.4217, 3.6500, 3.6765, 3.6083, 3.5541],\n",
      "        [3.7135, 3.9274, 4.0576, 3.9329, 3.9408],\n",
      "        [3.5512, 3.5709, 3.7982, 3.7250, 3.7207],\n",
      "        [3.5352, 3.6119, 3.7386, 3.7849, 3.5551],\n",
      "        [3.7347, 3.9341, 3.9803, 3.7838, 3.7895],\n",
      "        [3.5984, 3.6897, 3.9192, 3.7986, 3.7090],\n",
      "        [3.5886, 3.6736, 3.9127, 3.7990, 3.7090],\n",
      "        [3.4122, 3.5406, 3.7117, 3.6271, 3.4986],\n",
      "        [3.4766, 3.6122, 3.7996, 3.6774, 3.5903],\n",
      "        [3.5800, 3.9910, 4.0222, 3.9057, 3.9043],\n",
      "        [3.6236, 3.8621, 3.8666, 3.7601, 3.7390],\n",
      "        [3.7221, 3.7286, 3.8682, 3.7163, 3.5964],\n",
      "        [3.3279, 3.5820, 3.6909, 3.5949, 3.5229],\n",
      "        [3.7930, 3.9737, 4.1083, 4.1285, 4.1443],\n",
      "        [3.7522, 3.7381, 3.8733, 3.7616, 3.6315],\n",
      "        [3.5107, 3.5943, 3.7942, 3.6584, 3.5684],\n",
      "        [3.7332, 3.5569, 3.7342, 3.7515, 3.7186],\n",
      "        [3.5350, 3.7499, 3.9955, 3.8057, 3.7892],\n",
      "        [3.6941, 3.7773, 3.8908, 3.7889, 3.5288],\n",
      "        [3.3923, 3.6101, 3.7438, 3.6087, 3.5161],\n",
      "        [3.4697, 3.6755, 3.6835, 3.6599, 3.5755],\n",
      "        [3.4884, 3.8846, 3.9632, 3.7215, 3.8814],\n",
      "        [3.5683, 3.7725, 3.8482, 3.7790, 3.7196],\n",
      "        [3.9352, 3.8013, 4.0594, 4.0890, 3.8843],\n",
      "        [3.3999, 3.7153, 3.7860, 3.6316, 3.5712],\n",
      "        [3.4389, 3.6551, 3.6786, 3.6350, 3.5566],\n",
      "        [3.4436, 3.6306, 3.6822, 3.6704, 3.5395],\n",
      "        [3.5337, 3.7405, 3.7169, 3.7634, 3.6344],\n",
      "        [3.6546, 4.0128, 4.0243, 3.9102, 3.9506],\n",
      "        [3.6529, 3.8443, 3.8677, 3.8462, 3.7961],\n",
      "        [3.6427, 3.6976, 3.8800, 3.7111, 3.6019],\n",
      "        [3.7652, 3.8234, 3.9529, 3.8860, 3.9071],\n",
      "        [3.5088, 3.6982, 3.8409, 3.7277, 3.7672],\n",
      "        [3.6879, 3.9225, 3.9138, 3.9077, 3.7679],\n",
      "        [3.4838, 3.6862, 3.6872, 3.6779, 3.5845],\n",
      "        [3.4365, 3.6326, 3.6786, 3.6675, 3.5273],\n",
      "        [3.3577, 3.8065, 3.8508, 3.7113, 3.5083],\n",
      "        [4.1910, 4.3982, 4.1321, 4.1004, 3.9078],\n",
      "        [3.6283, 3.9881, 3.9532, 3.8862, 3.8721],\n",
      "        [4.0080, 4.0378, 4.1710, 4.2960, 4.0832],\n",
      "        [3.7636, 3.8217, 3.9503, 3.8835, 3.9036],\n",
      "        [3.8140, 3.9865, 3.9781, 3.9654, 3.9514],\n",
      "        [3.7965, 3.8752, 3.9839, 3.9787, 3.9636],\n",
      "        [3.5041, 3.6477, 3.7350, 3.7437, 3.5787],\n",
      "        [3.3847, 3.5248, 3.6624, 3.6427, 3.4849],\n",
      "        [3.5539, 3.8206, 3.9519, 3.8015, 3.6093],\n",
      "        [3.4395, 3.6515, 3.6771, 3.6278, 3.5529],\n",
      "        [3.3851, 3.5310, 3.7020, 3.5864, 3.4737],\n",
      "        [3.8962, 3.9605, 4.1326, 4.1876, 3.9464],\n",
      "        [3.4206, 3.5391, 3.7131, 3.6289, 3.5023],\n",
      "        [3.6233, 3.6353, 3.8333, 3.7360, 3.7021],\n",
      "        [3.7898, 3.9471, 4.0525, 3.9809, 4.0117],\n",
      "        [3.5360, 3.5482, 3.7275, 3.6658, 3.7014],\n",
      "        [3.5751, 3.8372, 3.8075, 3.7502, 3.6585]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7144, 4.1296, 4.0030, 4.0668, 3.9407],\n",
      "        [3.8954, 3.9785, 3.9728, 4.0119, 3.9899],\n",
      "        [3.4350, 3.5465, 3.7189, 3.6436, 3.5111],\n",
      "        [3.8317, 4.0450, 3.8994, 3.8664, 3.7664],\n",
      "        [3.5840, 3.7281, 3.8095, 3.7131, 3.6673],\n",
      "        [3.3578, 3.5882, 3.6470, 3.5309, 3.5008],\n",
      "        [3.5402, 3.8468, 3.8256, 3.7061, 3.6884],\n",
      "        [3.4914, 3.7462, 3.9173, 3.7944, 3.5756],\n",
      "        [3.3859, 3.6698, 3.7608, 3.6082, 3.5325],\n",
      "        [3.6191, 3.8775, 3.9072, 3.8745, 3.7042],\n",
      "        [3.4236, 3.5796, 3.7449, 3.6442, 3.5335],\n",
      "        [3.5527, 3.7611, 3.8489, 3.7281, 3.7684],\n",
      "        [3.4346, 3.6456, 3.6576, 3.6833, 3.5454],\n",
      "        [3.7892, 3.9472, 4.0521, 3.9822, 4.0117],\n",
      "        [3.5717, 3.9111, 3.8170, 3.9026, 3.7348],\n",
      "        [3.3947, 3.6662, 3.7635, 3.6183, 3.5450],\n",
      "        [3.3974, 3.7030, 3.7828, 3.6287, 3.5669],\n",
      "        [3.4962, 3.6977, 3.6947, 3.7109, 3.6005],\n",
      "        [3.6849, 3.8687, 4.0289, 3.8283, 3.6304],\n",
      "        [3.9996, 3.9045, 4.1233, 4.1934, 3.9547],\n",
      "        [3.6034, 3.7672, 3.8668, 3.8024, 3.7704],\n",
      "        [3.4093, 3.5532, 3.7192, 3.6203, 3.5033],\n",
      "        [3.4152, 3.6202, 3.7518, 3.6295, 3.5529],\n",
      "        [3.8805, 3.9517, 4.0493, 4.1250, 3.8697],\n",
      "        [3.5650, 3.6478, 3.8883, 3.7502, 3.6841],\n",
      "        [3.5580, 3.6109, 3.8617, 3.7664, 3.7407],\n",
      "        [3.8138, 3.9605, 4.1062, 3.9360, 3.6972],\n",
      "        [3.5420, 3.8803, 3.7784, 3.8677, 3.7090],\n",
      "        [3.5810, 3.6649, 3.8832, 3.7541, 3.6923],\n",
      "        [3.9215, 4.1092, 3.9137, 3.9160, 3.7807],\n",
      "        [3.7003, 3.7433, 3.8337, 4.0062, 3.8121],\n",
      "        [3.3343, 3.5603, 3.6288, 3.4958, 3.4778],\n",
      "        [3.4537, 3.7054, 3.7127, 3.7557, 3.5549],\n",
      "        [3.5442, 3.7492, 3.8351, 3.7955, 3.7395],\n",
      "        [3.7024, 3.7463, 3.9654, 3.8959, 3.7249],\n",
      "        [3.4771, 3.6851, 3.6867, 3.6804, 3.5803],\n",
      "        [3.9347, 3.8015, 4.0589, 4.0899, 3.8843],\n",
      "        [3.4048, 3.7297, 3.7937, 3.6403, 3.5846],\n",
      "        [3.5183, 3.7218, 3.7004, 3.7528, 3.6146],\n",
      "        [3.6981, 3.9833, 3.9231, 3.8372, 3.7687],\n",
      "        [3.5517, 3.5898, 3.8357, 3.7383, 3.7282],\n",
      "        [3.6824, 3.7210, 3.9261, 3.8565, 3.6850],\n",
      "        [3.7451, 3.5754, 3.7478, 3.7441, 3.7459],\n",
      "        [3.5693, 3.6473, 3.8602, 3.7397, 3.6799],\n",
      "        [3.9104, 3.9672, 4.1384, 4.1755, 3.9230],\n",
      "        [3.5054, 3.6808, 3.7221, 3.7008, 3.6220],\n",
      "        [3.4168, 3.5658, 3.7289, 3.6286, 3.5134],\n",
      "        [3.3860, 3.6361, 3.6857, 3.6272, 3.5162],\n",
      "        [3.4753, 3.6714, 3.7220, 3.6761, 3.6106],\n",
      "        [3.7363, 4.0941, 4.0940, 3.9812, 3.9304],\n",
      "        [3.4212, 3.6500, 3.6759, 3.6093, 3.5542],\n",
      "        [3.5381, 3.6411, 3.8923, 3.7697, 3.6670],\n",
      "        [3.5171, 3.6424, 3.8166, 3.7206, 3.6185],\n",
      "        [3.6750, 3.8532, 3.8771, 3.8261, 3.7973],\n",
      "        [3.8034, 3.8680, 4.1197, 4.1248, 3.7365],\n",
      "        [3.6013, 3.7426, 3.8313, 3.7505, 3.6753],\n",
      "        [3.7629, 3.9811, 4.0844, 3.9877, 3.9940],\n",
      "        [3.7488, 3.8907, 4.0365, 4.0390, 3.7578],\n",
      "        [3.5477, 3.6945, 3.7700, 3.6585, 3.6392],\n",
      "        [3.8032, 3.8813, 4.0105, 4.0767, 4.0407],\n",
      "        [3.7101, 3.7615, 4.0505, 4.0539, 3.7111],\n",
      "        [3.4969, 3.7045, 3.7028, 3.7069, 3.5994],\n",
      "        [3.5000, 3.6944, 3.6858, 3.7111, 3.5813],\n",
      "        [3.7059, 3.9516, 3.9846, 3.8984, 3.7543]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.9050, 4.0470, 4.1807, 4.2336, 4.2115],\n",
      "        [3.5902, 3.6017, 3.8249, 3.7446, 3.5891],\n",
      "        [3.6966, 3.7522, 4.0319, 4.0390, 3.7065],\n",
      "        [3.4346, 3.6522, 3.6749, 3.6243, 3.5587],\n",
      "        [3.6593, 3.7092, 3.8694, 3.7975, 3.6609],\n",
      "        [3.7621, 3.8985, 4.0546, 3.9826, 3.9648],\n",
      "        [3.5781, 3.6759, 3.8387, 3.7639, 3.6667],\n",
      "        [3.4282, 3.5825, 3.6462, 3.6800, 3.4480],\n",
      "        [3.5611, 3.8418, 3.8414, 3.7177, 3.7018],\n",
      "        [3.8385, 3.8884, 4.1318, 4.1512, 3.7890],\n",
      "        [3.3950, 3.7055, 3.7772, 3.6209, 3.5594],\n",
      "        [3.5337, 3.6226, 3.7498, 3.7747, 3.5668],\n",
      "        [3.5340, 3.5921, 3.8482, 3.6338, 3.6661],\n",
      "        [3.5288, 3.6397, 3.8204, 3.7168, 3.6216],\n",
      "        [3.5366, 3.8410, 3.8723, 3.6848, 3.7192],\n",
      "        [3.6378, 3.7744, 3.8723, 3.9337, 3.6911],\n",
      "        [3.6812, 3.9738, 4.0057, 3.9205, 3.8899],\n",
      "        [3.5258, 3.6420, 3.8183, 3.7186, 3.6202],\n",
      "        [3.4535, 3.6665, 3.6858, 3.6313, 3.5761],\n",
      "        [3.3986, 3.6197, 3.6675, 3.5808, 3.5477],\n",
      "        [3.6706, 3.7187, 3.8987, 3.8316, 3.6718],\n",
      "        [3.9007, 3.8548, 3.9393, 3.9707, 3.8782],\n",
      "        [3.4494, 3.4775, 3.7935, 3.4647, 3.6258],\n",
      "        [3.7586, 3.8891, 4.0783, 3.9904, 3.9703],\n",
      "        [3.9706, 4.0135, 4.0574, 4.1361, 4.0337],\n",
      "        [3.4944, 3.7428, 3.7755, 3.5996, 3.5521],\n",
      "        [3.4476, 3.6466, 3.8080, 3.6868, 3.5309],\n",
      "        [3.4897, 3.6874, 3.6883, 3.6956, 3.5955],\n",
      "        [3.5611, 3.6811, 3.8420, 3.6341, 3.4597],\n",
      "        [3.5422, 4.0681, 4.0418, 3.7834, 3.6783],\n",
      "        [3.7328, 3.7943, 4.0394, 4.0399, 3.6610],\n",
      "        [3.7900, 4.0507, 4.1422, 3.9764, 3.7066],\n",
      "        [3.9173, 4.0131, 4.0591, 4.1842, 3.9693],\n",
      "        [3.4455, 3.6762, 3.8380, 3.6898, 3.5506],\n",
      "        [3.3006, 3.5605, 3.6936, 3.5562, 3.5024],\n",
      "        [3.9129, 4.1225, 4.0353, 4.1165, 4.1153],\n",
      "        [3.8760, 3.7570, 3.9373, 4.2788, 4.0071],\n",
      "        [3.9130, 3.9684, 4.1359, 4.1706, 3.9248],\n",
      "        [3.4340, 3.6454, 3.6566, 3.6839, 3.5451],\n",
      "        [3.5527, 3.8208, 3.9509, 3.8038, 3.6088],\n",
      "        [3.7631, 3.8214, 3.9487, 3.8853, 3.9038],\n",
      "        [3.8213, 3.7546, 3.8979, 3.9193, 3.8687],\n",
      "        [3.7117, 3.7627, 4.0658, 4.0744, 3.7165],\n",
      "        [3.3567, 3.8062, 3.8491, 3.7128, 3.5080],\n",
      "        [3.9058, 3.9625, 4.1285, 4.1633, 3.9191],\n",
      "        [3.4270, 3.5654, 3.7434, 3.6374, 3.4888],\n",
      "        [3.7256, 3.9159, 4.0210, 3.9265, 3.9521],\n",
      "        [3.4983, 4.0459, 4.0360, 3.7801, 3.6538],\n",
      "        [3.4028, 3.6858, 3.7733, 3.6362, 3.5643],\n",
      "        [3.5499, 3.7534, 3.7136, 3.7875, 3.6339],\n",
      "        [3.3938, 3.5807, 3.7286, 3.6112, 3.5074],\n",
      "        [3.5165, 3.6422, 3.8157, 3.7213, 3.6181],\n",
      "        [3.4088, 3.6537, 3.6822, 3.6019, 3.5552],\n",
      "        [3.5146, 3.9458, 3.8976, 3.8494, 3.8385],\n",
      "        [3.5687, 3.7264, 3.8234, 3.7148, 3.5513],\n",
      "        [3.7995, 3.9816, 4.1161, 4.1525, 4.1436],\n",
      "        [3.4301, 3.8586, 3.8423, 3.5819, 3.7222],\n",
      "        [3.7544, 3.8161, 3.9175, 3.9439, 3.8937],\n",
      "        [3.5628, 3.8118, 3.7634, 3.8972, 3.6077],\n",
      "        [3.6545, 3.7571, 3.9855, 3.8694, 3.6999],\n",
      "        [3.5405, 3.8907, 3.7839, 3.5975, 3.6728],\n",
      "        [3.6015, 3.7741, 3.8766, 3.8330, 3.7640],\n",
      "        [3.7343, 3.6058, 3.7374, 3.7318, 3.7660],\n",
      "        [3.5328, 3.7283, 3.7029, 3.7606, 3.6147]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3908, 3.5751, 3.7226, 3.6070, 3.5013],\n",
      "        [3.6154, 3.8133, 3.9998, 3.8516, 3.7636],\n",
      "        [3.5159, 3.7078, 3.6988, 3.7111, 3.6157],\n",
      "        [4.0100, 4.1283, 4.1757, 4.3220, 4.0661],\n",
      "        [3.6269, 3.8623, 3.8639, 3.7617, 3.7378],\n",
      "        [3.6409, 3.6836, 3.8686, 3.7048, 3.6392],\n",
      "        [3.7404, 3.8223, 3.9951, 3.9370, 3.6420],\n",
      "        [4.0753, 4.1642, 4.2228, 4.3959, 3.9346],\n",
      "        [3.3891, 3.6699, 3.7585, 3.6089, 3.5315],\n",
      "        [3.5316, 3.7350, 3.8675, 3.8003, 3.6848],\n",
      "        [3.7206, 3.7238, 3.8671, 3.7270, 3.5874],\n",
      "        [3.6558, 3.8524, 4.0171, 3.9073, 3.8124],\n",
      "        [3.9890, 4.1273, 4.1535, 4.2938, 4.0573],\n",
      "        [3.7068, 3.9812, 3.9484, 3.8898, 3.8091],\n",
      "        [3.4414, 3.6397, 3.8134, 3.7309, 3.6193],\n",
      "        [3.6686, 4.0460, 4.0324, 3.9140, 3.8798],\n",
      "        [3.9670, 3.9934, 3.9877, 4.1131, 4.0466],\n",
      "        [3.5509, 3.6593, 3.9170, 3.6495, 3.7912],\n",
      "        [3.4542, 3.7027, 3.8456, 3.6092, 3.7175],\n",
      "        [3.6069, 3.7582, 3.8581, 3.7652, 3.7762],\n",
      "        [3.5672, 3.6455, 3.8499, 3.7070, 3.6749],\n",
      "        [3.4879, 3.7497, 3.9148, 3.7977, 3.5775],\n",
      "        [3.5387, 3.6306, 3.8868, 3.7673, 3.6504],\n",
      "        [3.6965, 3.7722, 3.9126, 3.7768, 3.8400],\n",
      "        [4.2456, 4.4530, 4.1939, 4.1870, 3.9533],\n",
      "        [3.6208, 3.7396, 3.8586, 3.8708, 3.6848],\n",
      "        [3.5022, 3.6654, 3.7143, 3.6529, 3.5748],\n",
      "        [3.6267, 3.7463, 3.8446, 3.7640, 3.6852],\n",
      "        [3.5843, 3.6943, 3.8335, 3.7204, 3.8282],\n",
      "        [3.3464, 3.5757, 3.5517, 3.6097, 3.4550],\n",
      "        [3.6746, 3.7190, 3.8976, 3.8317, 3.6712],\n",
      "        [3.9456, 3.9035, 4.0124, 4.1358, 3.9076],\n",
      "        [3.7461, 3.9749, 3.9571, 3.9011, 3.8587],\n",
      "        [3.4995, 3.9198, 3.9056, 3.7268, 3.5426],\n",
      "        [3.8984, 3.8095, 4.0364, 4.0214, 3.8539],\n",
      "        [3.7395, 3.9061, 4.0728, 4.0049, 3.9646],\n",
      "        [3.5235, 3.7242, 3.7025, 3.7440, 3.6149],\n",
      "        [3.3987, 3.6015, 3.7415, 3.6129, 3.5160],\n",
      "        [3.4552, 4.0115, 3.8302, 3.6947, 3.7739],\n",
      "        [3.4080, 3.7298, 3.7914, 3.6411, 3.5837],\n",
      "        [3.6817, 3.8250, 3.9730, 3.9204, 3.8964],\n",
      "        [3.5509, 3.5666, 3.7569, 3.6993, 3.7167],\n",
      "        [3.7137, 3.7625, 4.0497, 4.0555, 3.7099],\n",
      "        [3.6054, 3.6356, 3.8517, 3.7435, 3.6913],\n",
      "        [3.4151, 3.6208, 3.7490, 3.6229, 3.5435],\n",
      "        [3.9212, 4.0136, 4.0580, 4.1844, 3.9686],\n",
      "        [3.7124, 3.7810, 3.9160, 3.7975, 3.5840],\n",
      "        [3.4443, 3.5846, 3.6230, 3.6857, 3.5073],\n",
      "        [3.4209, 3.5778, 3.6967, 3.6198, 3.5259],\n",
      "        [3.9947, 4.1456, 4.1602, 4.3175, 4.0699],\n",
      "        [3.6970, 3.9050, 3.8981, 3.8540, 3.7382],\n",
      "        [3.9552, 3.9121, 4.0061, 4.0727, 3.9888],\n",
      "        [3.6301, 3.7718, 3.7897, 3.8177, 3.7071],\n",
      "        [3.4889, 3.6876, 3.6946, 3.7007, 3.5942],\n",
      "        [3.7789, 3.6834, 3.8712, 3.8274, 3.7562],\n",
      "        [3.8517, 3.9058, 4.0600, 4.0467, 3.7229],\n",
      "        [3.4643, 3.6703, 3.6824, 3.6653, 3.5689],\n",
      "        [3.9663, 4.0619, 4.1542, 4.2735, 4.0115],\n",
      "        [3.4278, 3.6781, 3.9035, 3.6980, 3.6928],\n",
      "        [3.5068, 3.9157, 3.9097, 3.7402, 3.5467],\n",
      "        [3.4541, 3.8156, 3.8462, 3.7536, 3.8126],\n",
      "        [3.3887, 3.6830, 3.7681, 3.6119, 3.5401],\n",
      "        [3.5022, 4.0466, 4.0350, 3.7804, 3.6529],\n",
      "        [4.0112, 4.0388, 4.1697, 4.2992, 4.0821]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5487, 3.8361, 3.8603, 3.6973, 3.7119],\n",
      "        [3.5616, 3.6096, 3.8565, 3.7636, 3.7349],\n",
      "        [3.5212, 3.7623, 3.7296, 3.8374, 3.5689],\n",
      "        [3.4779, 3.6536, 3.8142, 3.7637, 3.6113],\n",
      "        [3.5061, 3.7071, 3.6925, 3.7038, 3.6017],\n",
      "        [3.5328, 3.6672, 3.8308, 3.7538, 3.6383],\n",
      "        [3.5819, 3.7045, 3.8495, 3.6645, 3.4746],\n",
      "        [3.5487, 3.8361, 3.8603, 3.6973, 3.7119],\n",
      "        [3.4934, 3.8700, 3.8728, 3.7205, 3.5804],\n",
      "        [3.7406, 3.7956, 4.0380, 4.0414, 3.6593],\n",
      "        [3.4829, 3.6864, 3.6843, 3.6880, 3.5755],\n",
      "        [3.6974, 3.9931, 4.0177, 3.9418, 3.9070],\n",
      "        [4.0623, 4.0824, 4.2391, 4.3667, 4.0980],\n",
      "        [3.5511, 3.5582, 3.7654, 3.6112, 3.5274],\n",
      "        [3.9533, 4.0556, 4.1530, 4.2345, 3.9028],\n",
      "        [3.6954, 3.7938, 4.0852, 3.8158, 3.5766],\n",
      "        [3.4040, 3.7148, 3.7837, 3.6304, 3.5719],\n",
      "        [3.5884, 3.6515, 3.9118, 3.8279, 3.7680],\n",
      "        [3.5177, 3.9594, 3.8806, 3.8659, 3.8090],\n",
      "        [3.8400, 3.9908, 3.9770, 3.9866, 3.9341],\n",
      "        [3.4039, 3.7032, 3.7789, 3.6300, 3.5652],\n",
      "        [3.8681, 3.7631, 3.8637, 3.9078, 3.8617],\n",
      "        [3.6650, 3.7026, 3.8855, 3.8065, 3.6675],\n",
      "        [3.6059, 3.8514, 3.8440, 3.7632, 3.7309],\n",
      "        [3.6604, 3.8219, 3.9762, 3.7930, 3.6047],\n",
      "        [3.4374, 3.8591, 3.8397, 3.5826, 3.7204],\n",
      "        [3.5405, 3.8009, 3.8889, 3.7764, 3.6451],\n",
      "        [3.3076, 3.5610, 3.6910, 3.5569, 3.5009],\n",
      "        [3.5758, 3.6385, 3.8195, 3.7258, 3.6811],\n",
      "        [3.6588, 4.0981, 3.9701, 4.0185, 3.8973],\n",
      "        [3.5413, 3.6830, 3.7558, 3.7448, 3.5997],\n",
      "        [3.3925, 3.6364, 3.6821, 3.6285, 3.5143],\n",
      "        [3.4877, 3.6388, 3.8091, 3.5853, 3.6667],\n",
      "        [3.5038, 3.6990, 3.6922, 3.6854, 3.5975],\n",
      "        [3.7341, 3.9000, 3.8935, 3.8653, 3.8423],\n",
      "        [3.5667, 3.8939, 3.9068, 3.7716, 3.5555],\n",
      "        [3.3301, 3.5446, 3.6143, 3.4899, 3.4681],\n",
      "        [3.7505, 3.7081, 3.8649, 4.0631, 3.8400],\n",
      "        [3.6243, 3.7397, 3.8572, 3.8713, 3.6840],\n",
      "        [3.6812, 3.9616, 3.9978, 3.9215, 3.8633],\n",
      "        [3.4966, 3.6981, 3.6932, 3.6944, 3.5946],\n",
      "        [3.6186, 3.6306, 3.9477, 3.9439, 3.5902],\n",
      "        [3.4064, 3.5931, 3.7340, 3.6286, 3.5187],\n",
      "        [3.5410, 3.5924, 3.8412, 3.6305, 3.6657],\n",
      "        [3.5910, 3.8519, 3.8340, 3.7488, 3.6856],\n",
      "        [3.8991, 3.8780, 3.9582, 3.9763, 3.9045],\n",
      "        [3.4914, 3.7502, 3.9139, 3.7987, 3.5766],\n",
      "        [3.5352, 3.6465, 3.8244, 3.7358, 3.6211],\n",
      "        [3.5373, 3.6211, 3.8253, 3.7187, 3.6128],\n",
      "        [3.3988, 3.6447, 3.7511, 3.6164, 3.5354],\n",
      "        [3.5323, 3.7236, 3.6999, 3.7524, 3.6129],\n",
      "        [3.5028, 3.9201, 3.9045, 3.7276, 3.5416],\n",
      "        [3.4496, 3.7040, 3.8818, 3.7125, 3.6870],\n",
      "        [3.4277, 3.7882, 3.8577, 3.6306, 3.6821],\n",
      "        [3.7455, 4.0572, 4.0022, 4.0366, 3.8890],\n",
      "        [3.3235, 3.5365, 3.6125, 3.4727, 3.4495],\n",
      "        [3.5136, 3.7083, 3.8460, 3.7488, 3.7600],\n",
      "        [3.5676, 3.9323, 3.9463, 3.8920, 3.8745],\n",
      "        [3.7654, 3.8508, 3.9757, 3.8788, 3.8845],\n",
      "        [3.4699, 3.9088, 3.8449, 3.7975, 3.7653],\n",
      "        [3.5784, 3.9113, 3.8135, 3.9038, 3.7328],\n",
      "        [3.3925, 3.6364, 3.6821, 3.6285, 3.5143],\n",
      "        [3.8078, 3.8234, 4.0104, 3.9781, 3.7799],\n",
      "        [3.7426, 3.8964, 3.9944, 3.8262, 3.7851]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4073, 3.6893, 3.7709, 3.6312, 3.5530],\n",
      "        [3.8656, 3.8646, 3.9634, 3.9510, 3.8896],\n",
      "        [3.5577, 3.7152, 3.7474, 3.7961, 3.6420],\n",
      "        [3.8121, 4.0253, 3.9070, 3.7989, 3.7147],\n",
      "        [4.0656, 4.0832, 4.2379, 4.3673, 4.0965],\n",
      "        [3.5390, 3.8469, 3.8747, 3.6724, 3.7162],\n",
      "        [3.5021, 3.6063, 3.7793, 3.5799, 3.6394],\n",
      "        [3.2394, 3.4920, 3.6579, 3.4966, 3.4683],\n",
      "        [3.5438, 3.6236, 3.7458, 3.7755, 3.5640],\n",
      "        [3.5697, 3.7292, 3.8177, 3.7162, 3.5567],\n",
      "        [3.6332, 3.7468, 3.8414, 3.7644, 3.6831],\n",
      "        [3.5617, 3.8973, 3.9506, 3.9249, 3.6478],\n",
      "        [3.6423, 4.0032, 3.9633, 3.8922, 3.8723],\n",
      "        [3.5501, 3.8481, 3.8210, 3.7080, 3.6848],\n",
      "        [3.3640, 3.6708, 3.5624, 3.6489, 3.4432],\n",
      "        [3.9069, 3.7514, 3.9354, 4.3166, 4.0230],\n",
      "        [3.5184, 3.9830, 3.8261, 3.7517, 3.8284],\n",
      "        [3.5242, 3.7144, 3.6935, 3.7454, 3.6092],\n",
      "        [3.5297, 3.7128, 3.8044, 3.7134, 3.6595],\n",
      "        [3.4079, 3.7579, 3.9328, 3.7092, 3.6701],\n",
      "        [3.7101, 3.8577, 3.9615, 3.7997, 3.7633],\n",
      "        [3.9529, 3.9862, 4.0720, 4.1474, 3.9794],\n",
      "        [3.5144, 3.6768, 3.7696, 3.7121, 3.6759],\n",
      "        [3.6030, 3.6343, 3.8438, 3.7724, 3.6449],\n",
      "        [3.5884, 3.6769, 3.8346, 3.7646, 3.6639],\n",
      "        [3.4698, 3.7082, 3.7175, 3.7166, 3.5358],\n",
      "        [3.5382, 3.6264, 3.8124, 3.7178, 3.6189],\n",
      "        [3.4708, 3.6233, 3.7503, 3.6242, 3.5668],\n",
      "        [3.7092, 3.9145, 4.0045, 3.8992, 3.7998],\n",
      "        [3.5121, 3.9742, 3.8225, 3.7462, 3.8182],\n",
      "        [3.7902, 3.6364, 3.9068, 4.0915, 3.9817],\n",
      "        [3.4778, 3.7637, 3.9006, 3.8579, 3.5530],\n",
      "        [3.8964, 3.8070, 4.0297, 4.0664, 3.8325],\n",
      "        [3.3890, 3.5997, 3.6493, 3.5544, 3.5084],\n",
      "        [3.7437, 3.9350, 3.9747, 3.7861, 3.7864],\n",
      "        [4.1595, 4.4177, 4.0497, 4.0661, 3.9172],\n",
      "        [3.6861, 3.9180, 3.8895, 3.9990, 3.8071],\n",
      "        [3.9229, 4.1236, 4.0309, 4.1172, 4.1122],\n",
      "        [3.7529, 3.6245, 3.7439, 3.7393, 3.7794],\n",
      "        [3.6957, 3.9195, 3.9916, 3.9225, 3.7976],\n",
      "        [3.5149, 3.9115, 3.9030, 3.7351, 3.5331],\n",
      "        [3.9062, 3.9626, 4.1290, 4.1923, 3.9427],\n",
      "        [3.5663, 3.6537, 3.8916, 3.7582, 3.6836],\n",
      "        [3.3552, 3.5734, 3.6358, 3.5098, 3.4841],\n",
      "        [3.3953, 3.6369, 3.6805, 3.6286, 3.5130],\n",
      "        [3.7177, 3.8903, 3.8935, 3.8119, 3.7395],\n",
      "        [3.3434, 3.5609, 3.6235, 3.4970, 3.4750],\n",
      "        [3.3855, 3.5919, 3.5995, 3.5819, 3.4493],\n",
      "        [3.5228, 3.7112, 3.6942, 3.7268, 3.6103],\n",
      "        [3.5502, 3.7485, 3.7092, 3.7654, 3.6360],\n",
      "        [3.4955, 3.6782, 3.7354, 3.5729, 3.5706],\n",
      "        [3.5275, 3.6336, 3.8174, 3.7313, 3.6217],\n",
      "        [3.4048, 3.7063, 3.7727, 3.6215, 3.5568],\n",
      "        [3.9487, 4.0602, 4.1246, 4.2695, 4.0103],\n",
      "        [3.5439, 3.5928, 3.8396, 3.6305, 3.6644],\n",
      "        [3.5839, 3.8429, 3.8334, 3.7301, 3.6922],\n",
      "        [3.5491, 3.7881, 3.8715, 3.7580, 3.6657],\n",
      "        [3.4887, 3.6299, 3.8146, 3.7202, 3.6111],\n",
      "        [3.5391, 3.6407, 3.8165, 3.7176, 3.6187],\n",
      "        [3.4263, 3.5274, 3.6972, 3.6354, 3.4875],\n",
      "        [3.4595, 3.6750, 3.8235, 3.5858, 3.6806],\n",
      "        [3.4809, 3.6542, 3.8127, 3.7638, 3.6099],\n",
      "        [3.6607, 3.9989, 4.0065, 3.9081, 3.9319],\n",
      "        [3.5206, 3.9601, 3.8791, 3.8660, 3.8076]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6429, 3.7585, 3.7807, 3.8368, 3.7062],\n",
      "        [3.6226, 3.6376, 4.0681, 3.8344, 3.7588],\n",
      "        [3.5513, 3.6877, 3.8419, 3.7675, 3.6545],\n",
      "        [3.5816, 3.6480, 3.8531, 3.7406, 3.6764],\n",
      "        [3.4226, 3.6077, 3.7242, 3.6105, 3.5381],\n",
      "        [3.7240, 3.9771, 3.9425, 3.8924, 3.8155],\n",
      "        [3.6497, 3.7386, 3.8498, 3.8054, 3.7656],\n",
      "        [3.6639, 3.7526, 3.7049, 3.8436, 3.7755],\n",
      "        [3.4383, 3.7658, 3.9576, 3.7203, 3.7035],\n",
      "        [3.3794, 3.4988, 3.6685, 3.5532, 3.4374],\n",
      "        [3.3877, 3.5920, 3.5979, 3.5817, 3.4488],\n",
      "        [3.5656, 3.7618, 3.8415, 3.7286, 3.7644],\n",
      "        [3.6315, 3.9683, 3.9271, 3.8733, 3.8565],\n",
      "        [3.4334, 3.7436, 3.7935, 3.6414, 3.5996],\n",
      "        [3.4816, 3.7680, 4.0047, 3.7411, 3.7981],\n",
      "        [3.7926, 3.6366, 3.9051, 4.0913, 3.9812],\n",
      "        [3.6304, 3.9288, 3.8888, 3.8567, 3.8422],\n",
      "        [3.2902, 3.8510, 3.8266, 3.6876, 3.4520],\n",
      "        [3.2816, 3.5295, 3.6853, 3.5194, 3.4998],\n",
      "        [3.3681, 3.4998, 3.6425, 3.5293, 3.4682],\n",
      "        [3.5010, 3.6969, 3.6859, 3.7062, 3.5830],\n",
      "        [3.5623, 3.7546, 3.7080, 3.7880, 3.6307],\n",
      "        [3.5073, 3.6157, 3.7526, 3.7400, 3.5458],\n",
      "        [3.7391, 3.9007, 3.8900, 3.8649, 3.8402],\n",
      "        [3.4501, 3.6560, 3.6712, 3.6370, 3.5534],\n",
      "        [3.6124, 3.6158, 3.8152, 3.7612, 3.5892],\n",
      "        [3.5414, 3.7364, 3.8220, 3.7840, 3.7302],\n",
      "        [3.6443, 3.8765, 3.8472, 3.9511, 3.7504],\n",
      "        [3.5627, 3.7588, 3.7142, 3.7933, 3.6390],\n",
      "        [3.7237, 3.6360, 3.8948, 3.9923, 3.9233],\n",
      "        [3.5564, 3.7513, 3.8302, 3.7980, 3.7351],\n",
      "        [3.3581, 3.5794, 3.6339, 3.5115, 3.4865],\n",
      "        [3.5967, 3.6722, 3.8914, 3.7774, 3.6895],\n",
      "        [3.6886, 3.9183, 3.8878, 3.9988, 3.8065],\n",
      "        [3.7997, 3.9795, 3.9595, 3.9484, 3.9168],\n",
      "        [3.5207, 3.6346, 3.9259, 3.5733, 3.7608],\n",
      "        [3.5141, 3.5638, 3.7993, 3.6831, 3.5781],\n",
      "        [3.6936, 3.7415, 3.8927, 3.7685, 3.5816],\n",
      "        [3.8801, 3.9348, 4.0630, 4.0891, 3.7794],\n",
      "        [3.4506, 3.5531, 3.7209, 3.6616, 3.5235],\n",
      "        [3.9037, 3.8090, 3.9194, 3.9509, 3.9149],\n",
      "        [3.7805, 4.0127, 4.1012, 3.9638, 3.6983],\n",
      "        [3.3662, 3.6710, 3.5607, 3.6487, 3.4427],\n",
      "        [3.7177, 3.8350, 4.0222, 3.8440, 3.6214],\n",
      "        [3.9939, 3.9343, 4.1436, 4.1959, 3.9543],\n",
      "        [3.5471, 3.6217, 3.8325, 3.7223, 3.6204],\n",
      "        [3.9772, 3.9067, 4.0109, 4.0732, 3.9561],\n",
      "        [3.6313, 3.8797, 3.9023, 3.8769, 3.6999],\n",
      "        [3.4096, 3.6147, 3.6541, 3.5764, 3.5186],\n",
      "        [3.7264, 3.8870, 3.9730, 3.7949, 3.7679],\n",
      "        [3.6742, 3.8965, 3.8693, 3.8339, 3.7385],\n",
      "        [3.5668, 3.6757, 3.9152, 3.7835, 3.6923],\n",
      "        [3.4435, 3.7390, 3.8353, 3.6584, 3.5824],\n",
      "        [3.4519, 3.5303, 3.7024, 3.6547, 3.4972],\n",
      "        [3.9840, 3.8599, 4.1413, 4.4755, 4.2644],\n",
      "        [3.5811, 3.7688, 3.8864, 3.8874, 3.6723],\n",
      "        [3.8064, 4.0326, 4.0755, 4.0288, 3.9224],\n",
      "        [3.5165, 3.7039, 3.8387, 3.6292, 3.6591],\n",
      "        [3.5331, 3.7862, 3.8596, 3.7538, 3.6529],\n",
      "        [3.9763, 4.0637, 4.1508, 4.2753, 4.0083],\n",
      "        [3.8509, 3.9184, 4.0504, 4.0654, 3.8527],\n",
      "        [3.4149, 3.7231, 3.8890, 3.6659, 3.6411],\n",
      "        [3.9065, 3.9701, 4.0988, 4.1087, 3.9295],\n",
      "        [3.7856, 3.8957, 4.0576, 3.9787, 3.9664]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.9759, 4.1396, 3.9070, 3.9348, 3.7790],\n",
      "        [3.4028, 3.6169, 3.7002, 3.6469, 3.4973],\n",
      "        [4.0037, 4.0168, 4.1691, 4.2837, 4.0251],\n",
      "        [3.8279, 3.9615, 4.0978, 3.9382, 3.6922],\n",
      "        [3.4474, 3.7227, 3.9751, 3.7109, 3.7658],\n",
      "        [4.0507, 4.1813, 3.8821, 3.9696, 3.7503],\n",
      "        [3.4157, 3.7156, 3.7749, 3.6388, 3.5614],\n",
      "        [3.9352, 4.1104, 3.9057, 3.9183, 3.7761],\n",
      "        [3.4651, 3.6849, 3.6922, 3.6420, 3.6060],\n",
      "        [3.5274, 3.7719, 3.8386, 3.7337, 3.6650],\n",
      "        [3.5892, 3.6611, 3.8519, 3.7741, 3.6715],\n",
      "        [3.4816, 3.5035, 3.6622, 3.6426, 3.4648],\n",
      "        [3.7217, 3.8258, 3.7902, 3.9057, 3.8136],\n",
      "        [3.8489, 3.8932, 4.0354, 4.0362, 3.8438],\n",
      "        [3.7142, 3.8723, 3.8873, 3.7472, 3.7197],\n",
      "        [3.6897, 3.9035, 3.8897, 3.8705, 3.7293],\n",
      "        [3.5409, 3.7564, 3.9013, 3.8628, 3.6299],\n",
      "        [3.7127, 3.7547, 4.0382, 4.0423, 3.6973],\n",
      "        [3.4054, 3.6108, 3.7343, 3.6115, 3.5119],\n",
      "        [3.6132, 3.7054, 3.8383, 3.7305, 3.8501],\n",
      "        [3.5967, 3.6670, 3.9006, 3.7978, 3.7011],\n",
      "        [3.4923, 3.5102, 3.8111, 3.5010, 3.6468],\n",
      "        [3.3713, 3.5886, 3.6383, 3.5327, 3.4969],\n",
      "        [3.4711, 3.8846, 3.8937, 3.7850, 3.7822],\n",
      "        [3.6059, 3.6802, 3.8851, 3.7695, 3.7059],\n",
      "        [3.6907, 3.9180, 3.8860, 3.9997, 3.8057],\n",
      "        [3.5514, 3.6148, 3.8455, 3.7296, 3.6229],\n",
      "        [3.4090, 3.5945, 3.7282, 3.6134, 3.5089],\n",
      "        [3.5404, 3.6679, 3.8259, 3.7545, 3.6352],\n",
      "        [3.5125, 3.6399, 3.7363, 3.6369, 3.6113],\n",
      "        [3.4863, 3.6294, 3.8028, 3.7216, 3.6047],\n",
      "        [3.5231, 3.7112, 3.6986, 3.7248, 3.6110],\n",
      "        [3.8262, 3.9103, 4.1002, 4.0970, 3.7856],\n",
      "        [3.3887, 3.5214, 3.6552, 3.5610, 3.4817],\n",
      "        [3.5470, 3.6642, 3.8282, 3.7367, 3.6318],\n",
      "        [3.6334, 3.8334, 3.8884, 3.8562, 3.7471],\n",
      "        [4.0507, 4.1813, 3.8821, 3.9696, 3.7503],\n",
      "        [3.5270, 3.6885, 3.7655, 3.6853, 3.6099],\n",
      "        [3.5047, 3.6691, 3.7115, 3.6390, 3.5693],\n",
      "        [3.2475, 3.4992, 3.6595, 3.5000, 3.4784],\n",
      "        [3.5477, 3.7416, 3.7025, 3.7698, 3.6227],\n",
      "        [3.7128, 3.9932, 3.9378, 3.9033, 3.7895],\n",
      "        [3.7883, 4.1007, 4.0247, 4.0546, 3.9653],\n",
      "        [3.4568, 3.7046, 3.8765, 3.7131, 3.6841],\n",
      "        [3.3944, 3.7264, 3.8915, 3.6428, 3.6183],\n",
      "        [3.4776, 3.6601, 3.6984, 3.7188, 3.5430],\n",
      "        [3.8455, 3.7458, 3.9008, 4.2001, 3.9387],\n",
      "        [3.6345, 4.0162, 3.9739, 3.8879, 3.8604],\n",
      "        [3.4901, 3.6868, 3.6793, 3.6887, 3.5731],\n",
      "        [3.5447, 3.6216, 3.8203, 3.7195, 3.6101],\n",
      "        [3.5941, 3.9212, 4.0709, 3.9444, 3.7322],\n",
      "        [3.4247, 3.4936, 3.6721, 3.6330, 3.4666],\n",
      "        [3.6010, 3.6934, 3.8304, 3.7949, 3.6617],\n",
      "        [3.5477, 3.7416, 3.7025, 3.7698, 3.6227],\n",
      "        [3.4042, 3.7379, 3.9133, 3.6360, 3.6187],\n",
      "        [3.5303, 3.8717, 3.9045, 3.6557, 3.7330],\n",
      "        [3.4529, 3.5628, 3.6136, 3.6819, 3.4693],\n",
      "        [3.5480, 3.6846, 3.8441, 3.7657, 3.6484],\n",
      "        [3.3701, 3.4996, 3.6407, 3.5301, 3.4676],\n",
      "        [3.7221, 3.8904, 3.8901, 3.8125, 3.7382],\n",
      "        [3.4507, 3.5588, 3.6082, 3.6792, 3.4481],\n",
      "        [3.5882, 3.6253, 3.8809, 3.7974, 3.7471],\n",
      "        [3.5031, 3.5509, 3.7840, 3.6697, 3.5599],\n",
      "        [3.4999, 3.6179, 3.8149, 3.7203, 3.6088]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5619, 3.8842, 3.7733, 3.8706, 3.7029],\n",
      "        [3.5127, 3.7085, 3.8805, 3.8127, 3.7804],\n",
      "        [3.7617, 3.8980, 4.0440, 3.9885, 3.9617],\n",
      "        [3.4313, 3.7311, 3.8899, 3.6701, 3.6475],\n",
      "        [3.7343, 3.9019, 3.9959, 3.9326, 3.7501],\n",
      "        [3.4508, 3.6047, 3.6533, 3.6938, 3.5242],\n",
      "        [3.4677, 3.5695, 3.7304, 3.6530, 3.5079],\n",
      "        [3.6531, 3.6940, 3.8682, 3.7014, 3.6287],\n",
      "        [3.4366, 3.6407, 3.6658, 3.6036, 3.5407],\n",
      "        [3.6924, 3.9183, 3.8846, 4.0002, 3.8047],\n",
      "        [3.4675, 3.7257, 3.8314, 3.6429, 3.6034],\n",
      "        [3.5708, 3.5781, 3.7784, 3.6326, 3.5431],\n",
      "        [3.4492, 3.5112, 3.6885, 3.6491, 3.4820],\n",
      "        [3.2451, 3.4923, 3.6531, 3.4976, 3.4658],\n",
      "        [3.7164, 3.9633, 3.9277, 3.8989, 3.7841],\n",
      "        [3.7974, 3.8120, 3.9934, 3.9747, 3.7604],\n",
      "        [3.9208, 4.1263, 3.9769, 3.8980, 3.8029],\n",
      "        [3.5115, 3.5390, 3.7869, 3.7075, 3.6461],\n",
      "        [3.5647, 3.6119, 3.7300, 3.6645, 3.6565],\n",
      "        [3.5826, 4.0169, 4.0035, 3.8177, 3.6341],\n",
      "        [3.8022, 3.9583, 4.0484, 3.9820, 4.0012],\n",
      "        [3.3918, 3.5926, 3.5944, 3.5754, 3.4581],\n",
      "        [3.6642, 3.7036, 3.8668, 3.7164, 3.6091],\n",
      "        [3.5352, 3.6462, 3.8199, 3.7408, 3.6271],\n",
      "        [3.4507, 3.5195, 3.6942, 3.6659, 3.5035],\n",
      "        [3.7351, 3.7418, 3.8683, 4.0896, 3.8628],\n",
      "        [3.4866, 3.5820, 3.8237, 3.6963, 3.5813],\n",
      "        [3.6452, 3.7586, 3.7836, 3.8406, 3.7065],\n",
      "        [3.7729, 3.8594, 3.9623, 3.9086, 3.8845],\n",
      "        [3.3772, 3.5979, 3.6457, 3.5413, 3.5039],\n",
      "        [3.5664, 3.7588, 3.7111, 3.7946, 3.6373],\n",
      "        [3.7940, 3.7025, 3.8778, 4.1541, 3.8932],\n",
      "        [3.7583, 3.5643, 3.7258, 3.7613, 3.7067],\n",
      "        [3.7276, 4.0153, 4.0842, 3.9431, 3.6728],\n",
      "        [3.6540, 3.9428, 4.0157, 3.8812, 3.6867],\n",
      "        [3.5365, 4.0385, 4.0288, 3.8092, 3.6571],\n",
      "        [3.6454, 3.9096, 3.8427, 3.8136, 3.7166],\n",
      "        [3.6008, 3.8403, 3.8289, 3.7661, 3.7171],\n",
      "        [3.9956, 4.0868, 4.0727, 4.2943, 4.0230],\n",
      "        [3.5680, 3.5905, 3.8254, 3.7405, 3.7229],\n",
      "        [3.6950, 3.9862, 4.0271, 3.9285, 3.7347],\n",
      "        [3.6428, 3.7726, 3.7817, 3.8194, 3.7024],\n",
      "        [3.5855, 3.7272, 3.8138, 3.7159, 3.5460],\n",
      "        [3.4414, 3.6767, 3.6910, 3.7029, 3.5428],\n",
      "        [3.6352, 3.8802, 3.8997, 3.8786, 3.6978],\n",
      "        [3.6904, 3.8904, 3.8850, 3.9075, 3.7542],\n",
      "        [3.5249, 3.6441, 3.9364, 3.5725, 3.7682],\n",
      "        [3.3549, 3.5696, 3.6262, 3.5022, 3.4847],\n",
      "        [3.8349, 3.8905, 4.0080, 4.0940, 4.0435],\n",
      "        [3.6924, 3.9183, 3.8846, 4.0002, 3.8047],\n",
      "        [3.6778, 3.8967, 3.8662, 3.8351, 3.7367],\n",
      "        [4.0524, 4.1816, 3.8807, 3.9700, 3.7494],\n",
      "        [3.5267, 3.7153, 3.6881, 3.7419, 3.5979],\n",
      "        [3.5393, 3.6992, 3.7298, 3.7179, 3.6349],\n",
      "        [3.5271, 3.5796, 3.8094, 3.6961, 3.5837],\n",
      "        [3.5234, 3.8292, 3.8744, 3.7025, 3.7184],\n",
      "        [3.5471, 3.6524, 3.9151, 3.6280, 3.7650],\n",
      "        [3.6307, 3.7056, 3.9363, 3.8282, 3.7202],\n",
      "        [3.6533, 3.9119, 3.8523, 3.8162, 3.7284],\n",
      "        [3.5420, 3.5365, 3.6990, 3.6488, 3.6873],\n",
      "        [3.4107, 3.7064, 3.7677, 3.6223, 3.5548],\n",
      "        [3.4011, 3.6705, 3.7504, 3.6103, 3.5274],\n",
      "        [3.7059, 3.7562, 3.8922, 3.7849, 3.5794],\n",
      "        [3.4852, 3.6811, 3.6760, 3.6709, 3.5723]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8486, 3.7468, 3.8979, 4.2020, 3.9366],\n",
      "        [3.6930, 3.7378, 3.8059, 3.9550, 3.7650],\n",
      "        [3.5567, 3.7008, 3.8221, 3.7514, 3.7362],\n",
      "        [3.4570, 3.5679, 3.6077, 3.6885, 3.4579],\n",
      "        [3.5792, 3.8380, 3.7827, 3.7477, 3.6417],\n",
      "        [3.4301, 3.5555, 3.6985, 3.6180, 3.4919],\n",
      "        [4.0557, 3.8503, 4.1043, 4.4660, 4.2729],\n",
      "        [3.7604, 3.9109, 3.9973, 3.8757, 3.6410],\n",
      "        [3.4647, 3.6483, 3.7970, 3.6898, 3.5252],\n",
      "        [3.6132, 3.9190, 3.8332, 3.9259, 3.7430],\n",
      "        [3.4750, 3.6255, 3.7875, 3.7315, 3.5872],\n",
      "        [3.9970, 4.0877, 4.0712, 4.2958, 4.0217],\n",
      "        [3.5892, 3.6460, 3.8926, 3.7939, 3.7127],\n",
      "        [3.5632, 3.7515, 3.7179, 3.7863, 3.6366],\n",
      "        [3.8002, 3.9740, 4.0944, 4.1250, 4.1260],\n",
      "        [3.4740, 3.8859, 3.8908, 3.7872, 3.7799],\n",
      "        [3.7251, 3.8915, 3.8874, 3.8145, 3.7360],\n",
      "        [3.8487, 3.8964, 4.0859, 4.1594, 3.7815],\n",
      "        [3.5466, 3.7378, 3.8182, 3.7877, 3.7268],\n",
      "        [3.9758, 4.1337, 4.0396, 4.1527, 4.1385],\n",
      "        [3.4120, 3.6029, 3.7321, 3.6158, 3.5106],\n",
      "        [3.6825, 4.0480, 4.0230, 3.9175, 3.8739],\n",
      "        [3.6923, 3.9836, 3.9319, 3.8569, 3.7643],\n",
      "        [3.4259, 3.6552, 3.6717, 3.6049, 3.5496],\n",
      "        [3.6145, 3.6268, 3.8289, 3.7698, 3.6050],\n",
      "        [3.8933, 4.0787, 3.8943, 3.8862, 3.7647],\n",
      "        [3.5258, 3.6349, 3.9209, 3.5760, 3.7578],\n",
      "        [3.6622, 3.9146, 3.8928, 3.9623, 3.7576],\n",
      "        [3.4969, 3.6501, 3.7344, 3.6876, 3.6472],\n",
      "        [3.4452, 3.5842, 3.6363, 3.6835, 3.4422],\n",
      "        [3.6729, 3.7272, 3.8214, 3.9215, 3.7460],\n",
      "        [3.6338, 3.6494, 4.0692, 3.8420, 3.7676],\n",
      "        [3.6854, 3.7788, 3.7442, 3.8662, 3.7717],\n",
      "        [3.9839, 4.0800, 4.1330, 4.2459, 3.9509],\n",
      "        [3.3353, 3.5458, 3.6063, 3.4774, 3.4504],\n",
      "        [3.8240, 3.8744, 4.1159, 4.1349, 3.7302],\n",
      "        [3.5372, 3.9074, 3.8957, 3.7479, 3.5332],\n",
      "        [3.8106, 4.0648, 3.9526, 4.0089, 4.0568],\n",
      "        [4.2145, 4.4409, 4.1068, 4.1241, 3.9450],\n",
      "        [3.5362, 3.9823, 3.8454, 3.9124, 3.7525],\n",
      "        [3.8473, 3.8864, 3.8510, 3.9520, 3.8691],\n",
      "        [3.5267, 3.6997, 3.8277, 3.7319, 3.7599],\n",
      "        [3.4976, 3.6398, 3.8007, 3.5873, 3.6618],\n",
      "        [3.4506, 3.6131, 3.6502, 3.6885, 3.5254],\n",
      "        [3.5775, 3.6869, 3.9292, 3.8069, 3.6981],\n",
      "        [3.5611, 3.5594, 3.7572, 3.6134, 3.5227],\n",
      "        [3.5306, 3.7730, 3.8357, 3.7358, 3.6626],\n",
      "        [3.3399, 3.5457, 3.6065, 3.4921, 3.4641],\n",
      "        [3.5123, 3.6164, 3.7480, 3.7428, 3.5430],\n",
      "        [3.6143, 3.7691, 3.8683, 3.8453, 3.7466],\n",
      "        [3.4367, 3.6397, 3.7844, 3.6599, 3.5354],\n",
      "        [3.6186, 3.6968, 3.9098, 3.8092, 3.7141],\n",
      "        [3.5463, 3.6156, 3.8189, 3.7186, 3.6020],\n",
      "        [3.8531, 3.9642, 4.1257, 4.0483, 4.0284],\n",
      "        [3.5722, 3.6107, 3.8483, 3.7663, 3.7303],\n",
      "        [3.4765, 3.9415, 3.7608, 3.6699, 3.7380],\n",
      "        [3.7678, 3.6951, 3.8505, 4.1617, 3.8637],\n",
      "        [3.9303, 3.9598, 3.8997, 4.0646, 4.0439],\n",
      "        [3.4126, 3.6374, 3.7506, 3.6293, 3.5344],\n",
      "        [3.6791, 3.8975, 3.8647, 3.8366, 3.7355],\n",
      "        [3.6497, 4.0045, 3.9570, 3.8949, 3.8686],\n",
      "        [3.7811, 3.8802, 4.0097, 3.8408, 3.5758],\n",
      "        [4.0088, 4.1484, 4.1507, 4.3206, 4.0636],\n",
      "        [3.5386, 3.6326, 3.8007, 3.7180, 3.6092]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5460, 3.9311, 3.9085, 3.8658, 3.8344],\n",
      "        [3.6240, 3.7095, 3.9341, 3.8207, 3.7114],\n",
      "        [3.5782, 3.6266, 3.7407, 3.6802, 3.6701],\n",
      "        [3.7004, 3.9070, 3.8820, 3.8761, 3.7270],\n",
      "        [3.6245, 3.7389, 3.8169, 3.7534, 3.6706],\n",
      "        [3.7297, 3.8543, 4.0040, 3.9347, 3.9185],\n",
      "        [3.3795, 3.5986, 3.6427, 3.5436, 3.5017],\n",
      "        [3.5290, 3.9618, 3.8711, 3.8698, 3.8023],\n",
      "        [3.4157, 3.6278, 3.7355, 3.6257, 3.5341],\n",
      "        [3.4451, 3.5673, 3.7313, 3.6416, 3.4814],\n",
      "        [3.5643, 3.8851, 3.7703, 3.8730, 3.7003],\n",
      "        [3.6464, 3.7596, 3.8540, 3.9074, 3.6800],\n",
      "        [3.5307, 3.6461, 3.8053, 3.7294, 3.6084],\n",
      "        [3.8026, 3.8766, 3.9722, 3.9429, 3.9059],\n",
      "        [3.4684, 3.9247, 3.9271, 3.8016, 3.8117],\n",
      "        [3.4676, 3.6758, 3.8152, 3.5889, 3.6756],\n",
      "        [3.5739, 3.5996, 3.8356, 3.7519, 3.7260],\n",
      "        [3.5478, 3.7832, 3.8491, 3.8131, 3.6786],\n",
      "        [3.5016, 3.6246, 3.8110, 3.7198, 3.6062],\n",
      "        [3.6334, 3.5988, 3.7551, 3.6913, 3.6603],\n",
      "        [3.4665, 3.6219, 3.6718, 3.6748, 3.5231],\n",
      "        [3.8569, 3.9208, 4.1449, 4.1779, 3.7807],\n",
      "        [3.9184, 4.0591, 4.0386, 4.0337, 4.0103],\n",
      "        [3.5864, 3.7034, 3.8502, 3.6580, 3.4631],\n",
      "        [3.3858, 3.5189, 3.6793, 3.5824, 3.4386],\n",
      "        [3.9831, 4.0086, 4.0370, 4.1328, 4.0146],\n",
      "        [3.5546, 3.6777, 3.8297, 3.7671, 3.6306],\n",
      "        [3.5557, 3.6006, 3.7072, 3.6510, 3.6437],\n",
      "        [3.4585, 3.5684, 3.7301, 3.6530, 3.4916],\n",
      "        [3.5378, 3.6563, 3.8140, 3.7384, 3.6142],\n",
      "        [4.0008, 4.0077, 4.1318, 4.2620, 4.0145],\n",
      "        [3.7616, 3.9111, 3.9958, 3.8767, 3.6396],\n",
      "        [3.4423, 3.5151, 3.6838, 3.6577, 3.4844],\n",
      "        [3.4240, 3.5668, 3.7127, 3.6258, 3.5011],\n",
      "        [3.4222, 3.7311, 3.7799, 3.6448, 3.5774],\n",
      "        [3.5644, 3.5621, 3.7325, 3.6902, 3.7040],\n",
      "        [3.8863, 3.9362, 4.0567, 4.0932, 3.7742],\n",
      "        [3.5822, 3.7755, 3.9058, 3.9331, 3.6466],\n",
      "        [3.4787, 3.6591, 3.7078, 3.6651, 3.5785],\n",
      "        [3.4867, 3.5447, 3.7171, 3.6651, 3.4955],\n",
      "        [3.7069, 3.7694, 3.8934, 3.7835, 3.8280],\n",
      "        [3.5477, 3.6418, 3.8087, 3.7213, 3.6135],\n",
      "        [3.7815, 3.9947, 3.9939, 4.0049, 4.0228],\n",
      "        [3.4927, 3.6249, 3.7459, 3.6311, 3.5850],\n",
      "        [3.5395, 3.8521, 3.8778, 3.6501, 3.7113],\n",
      "        [3.6176, 3.6302, 4.0651, 3.8244, 3.7464],\n",
      "        [3.4963, 3.6945, 3.8976, 3.7488, 3.7032],\n",
      "        [3.6641, 3.7950, 3.8722, 3.9579, 3.6899],\n",
      "        [3.4912, 3.6579, 3.8041, 3.7581, 3.5944],\n",
      "        [3.8204, 4.0265, 3.8989, 3.8025, 3.7095],\n",
      "        [3.4345, 3.5738, 3.7264, 3.6502, 3.5125],\n",
      "        [3.7963, 3.6849, 3.8605, 3.8321, 3.7502],\n",
      "        [3.5474, 3.7379, 3.8582, 3.8059, 3.6769],\n",
      "        [3.6936, 3.9033, 3.9905, 3.8875, 3.7143],\n",
      "        [3.7170, 3.8965, 3.8915, 3.8317, 3.7289],\n",
      "        [3.4466, 3.6500, 3.8165, 3.7556, 3.6292],\n",
      "        [3.4927, 3.7321, 3.7545, 3.7776, 3.5824],\n",
      "        [3.7328, 4.2094, 4.0875, 3.9980, 4.0493],\n",
      "        [3.6897, 3.7204, 3.8863, 3.8359, 3.6642],\n",
      "        [3.7915, 4.0279, 4.0850, 3.9360, 3.6558],\n",
      "        [3.5150, 3.7004, 3.6830, 3.6890, 3.5918],\n",
      "        [3.4093, 3.8334, 3.7955, 3.5541, 3.6850],\n",
      "        [3.4670, 3.6244, 3.7778, 3.7313, 3.5823],\n",
      "        [3.7633, 3.6253, 3.7361, 3.7431, 3.7755]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6475, 3.8797, 3.9184, 3.8198, 3.5865],\n",
      "        [3.4476, 3.5220, 3.6885, 3.6534, 3.4850],\n",
      "        [3.6329, 3.9519, 3.9017, 3.8693, 3.8450],\n",
      "        [3.5922, 3.6591, 3.8290, 3.7420, 3.6634],\n",
      "        [3.5826, 3.9170, 3.9407, 3.8829, 3.8638],\n",
      "        [3.3861, 3.5188, 3.6782, 3.5828, 3.4373],\n",
      "        [3.6713, 3.6962, 3.8470, 3.7066, 3.5022],\n",
      "        [3.5472, 3.6273, 3.8034, 3.7220, 3.6123],\n",
      "        [3.5515, 3.7280, 3.8451, 3.7878, 3.6966],\n",
      "        [3.9243, 3.8367, 3.9402, 3.9789, 3.9210],\n",
      "        [3.4198, 3.7164, 3.7693, 3.6420, 3.5569],\n",
      "        [3.4483, 3.8435, 3.8058, 3.5625, 3.6798],\n",
      "        [3.7154, 3.9050, 3.9570, 3.9974, 3.7505],\n",
      "        [3.5687, 3.7553, 3.7009, 3.7925, 3.6252],\n",
      "        [3.5476, 3.6156, 3.8162, 3.7202, 3.5992],\n",
      "        [3.6695, 3.7951, 3.7666, 3.8018, 3.7618],\n",
      "        [3.9575, 4.0755, 4.0812, 4.2239, 3.9472],\n",
      "        [3.5632, 3.6942, 3.8425, 3.7822, 3.6551],\n",
      "        [3.4251, 3.5726, 3.7146, 3.6220, 3.5018],\n",
      "        [3.3488, 3.5614, 3.6152, 3.4984, 3.4708],\n",
      "        [4.1683, 4.4189, 4.0400, 4.0703, 3.9105],\n",
      "        [3.4968, 4.0427, 3.8474, 3.7227, 3.7907],\n",
      "        [3.9266, 3.9653, 4.1196, 4.1780, 3.9058],\n",
      "        [3.7501, 3.8428, 3.9896, 3.9481, 3.6578],\n",
      "        [4.2819, 4.4752, 4.1793, 4.1805, 3.9614],\n",
      "        [3.3615, 3.7366, 3.6931, 3.4685, 3.5521],\n",
      "        [3.6665, 3.8787, 3.8593, 3.7519, 3.7583],\n",
      "        [3.5608, 3.8382, 3.8495, 3.7020, 3.7033],\n",
      "        [3.4633, 3.6366, 3.6683, 3.6797, 3.5256],\n",
      "        [3.3366, 3.5458, 3.6037, 3.4787, 3.4479],\n",
      "        [3.5935, 3.8518, 3.8002, 3.7607, 3.6526],\n",
      "        [3.6219, 3.6272, 3.8250, 3.7422, 3.6842],\n",
      "        [3.9921, 3.9108, 4.0872, 4.2171, 3.9927],\n",
      "        [3.9705, 4.1401, 4.0423, 4.1548, 4.1443],\n",
      "        [3.7856, 3.8930, 4.0433, 4.0603, 3.7522],\n",
      "        [3.5879, 3.6414, 3.7949, 3.7205, 3.6799],\n",
      "        [3.8071, 4.0312, 4.0630, 4.0260, 3.9128],\n",
      "        [3.6120, 3.9932, 3.8442, 3.8164, 3.8601],\n",
      "        [3.4075, 3.7623, 3.8219, 3.6886, 3.5394],\n",
      "        [3.7628, 3.7371, 3.8613, 3.7578, 3.6089],\n",
      "        [3.5755, 3.7149, 3.7868, 3.6829, 3.5441],\n",
      "        [3.6294, 3.8855, 3.9162, 3.8152, 3.5767],\n",
      "        [3.4192, 3.6220, 3.7435, 3.6340, 3.5291],\n",
      "        [3.5328, 3.7153, 3.6848, 3.7496, 3.6034],\n",
      "        [3.7072, 3.9106, 3.8896, 3.9160, 3.7551],\n",
      "        [3.6899, 3.7153, 3.8637, 3.6936, 3.5197],\n",
      "        [3.3959, 3.7281, 3.8863, 3.6534, 3.6198],\n",
      "        [3.5149, 3.7061, 3.6891, 3.7123, 3.5905],\n",
      "        [3.5419, 3.5743, 3.7653, 3.6417, 3.5357],\n",
      "        [3.4425, 3.6802, 3.8908, 3.7026, 3.6837],\n",
      "        [3.4443, 3.6185, 3.7571, 3.6488, 3.5136],\n",
      "        [3.4689, 3.7701, 3.8473, 3.6277, 3.6691],\n",
      "        [3.3855, 3.4995, 3.6612, 3.5571, 3.4324],\n",
      "        [3.4133, 3.5954, 3.7226, 3.6168, 3.5042],\n",
      "        [3.4791, 3.9350, 3.8746, 3.7997, 3.8239],\n",
      "        [3.5420, 3.7710, 3.9296, 3.8298, 3.5962],\n",
      "        [3.6162, 3.7664, 3.8516, 3.7954, 3.7659],\n",
      "        [3.5236, 3.6823, 3.7082, 3.7060, 3.6135],\n",
      "        [3.5275, 3.6445, 3.9318, 3.5754, 3.7641],\n",
      "        [3.5832, 3.7209, 3.8465, 3.8797, 3.6905],\n",
      "        [3.4813, 3.9113, 3.8344, 3.8020, 3.7571],\n",
      "        [3.7260, 3.8327, 4.1323, 3.7999, 3.6131],\n",
      "        [3.9307, 3.9714, 4.1275, 4.1855, 3.9118],\n",
      "        [3.5546, 3.9127, 3.9012, 3.7581, 3.5356]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4008, 3.6496, 3.7398, 3.6130, 3.5136],\n",
      "        [3.4178, 3.6275, 3.6524, 3.5898, 3.5237],\n",
      "        [3.4140, 3.6371, 3.7465, 3.6308, 3.5302],\n",
      "        [3.7154, 3.7399, 3.9345, 3.8961, 3.7007],\n",
      "        [3.5366, 3.6210, 3.7977, 3.7149, 3.6007],\n",
      "        [3.7729, 3.6250, 3.7416, 3.7469, 3.7798],\n",
      "        [3.6670, 3.7039, 3.8608, 3.7194, 3.6034],\n",
      "        [3.8588, 3.9917, 3.9665, 3.9966, 3.9262],\n",
      "        [3.4153, 3.7157, 3.7712, 3.6342, 3.5636],\n",
      "        [3.3644, 3.5796, 3.6253, 3.5154, 3.4801],\n",
      "        [3.6927, 3.9484, 3.9863, 3.9258, 3.8365],\n",
      "        [3.6622, 4.0707, 3.9409, 4.0088, 3.8652],\n",
      "        [3.5444, 3.8607, 3.8779, 3.6589, 3.7171],\n",
      "        [3.5683, 3.6067, 3.8414, 3.7445, 3.6978],\n",
      "        [3.9909, 3.8603, 4.1320, 4.4801, 4.2570],\n",
      "        [3.4948, 3.6484, 3.6982, 3.6320, 3.5451],\n",
      "        [3.3985, 3.5747, 3.6751, 3.6467, 3.4840],\n",
      "        [3.4486, 3.7015, 3.8632, 3.7119, 3.6723],\n",
      "        [3.4325, 3.5829, 3.7369, 3.6422, 3.4855],\n",
      "        [3.4906, 3.7035, 3.7066, 3.6723, 3.6133],\n",
      "        [3.5455, 3.6178, 3.8087, 3.7243, 3.5994],\n",
      "        [3.5379, 3.6490, 3.8067, 3.7332, 3.6082],\n",
      "        [3.5469, 3.7245, 3.6830, 3.7562, 3.5987],\n",
      "        [3.7251, 3.9530, 3.9680, 3.9041, 3.7422],\n",
      "        [3.9017, 3.8007, 4.0118, 4.0685, 3.8202],\n",
      "        [3.4501, 3.7392, 3.8258, 3.6624, 3.5747],\n",
      "        [3.6887, 3.7625, 3.8729, 3.8483, 3.7831],\n",
      "        [3.8020, 3.9738, 4.0900, 4.1270, 4.1214],\n",
      "        [3.6634, 3.6432, 3.7975, 3.7301, 3.6951],\n",
      "        [4.0104, 4.2021, 4.0372, 3.9701, 3.8714],\n",
      "        [3.5383, 3.6559, 3.8114, 3.7391, 3.6110],\n",
      "        [3.4989, 3.6159, 3.7503, 3.7292, 3.5312],\n",
      "        [3.9405, 3.9841, 4.1339, 4.1903, 3.9282],\n",
      "        [3.4477, 3.5217, 3.6871, 3.6535, 3.4835],\n",
      "        [3.5659, 3.8244, 3.9021, 3.7975, 3.6147],\n",
      "        [3.5897, 3.6474, 3.8215, 3.7387, 3.6699],\n",
      "        [3.9729, 3.9887, 3.9834, 4.1103, 4.0228],\n",
      "        [3.4253, 3.5723, 3.7132, 3.6221, 3.5003],\n",
      "        [3.6534, 3.8592, 3.9135, 3.8436, 3.8349],\n",
      "        [3.6083, 3.9988, 3.8283, 3.8130, 3.8623],\n",
      "        [3.4113, 3.5805, 3.7158, 3.6160, 3.4966],\n",
      "        [3.6553, 3.6859, 3.8608, 3.7007, 3.6394],\n",
      "        [3.9842, 3.8071, 4.0190, 4.3714, 4.1932],\n",
      "        [3.7270, 3.9266, 4.0067, 3.8685, 3.6531],\n",
      "        [3.9709, 4.1283, 3.8843, 3.9186, 3.7616],\n",
      "        [3.7382, 3.7421, 3.8625, 4.0927, 3.8573],\n",
      "        [3.6468, 3.6327, 3.7989, 3.7319, 3.6897],\n",
      "        [3.5350, 3.7146, 3.8521, 3.7736, 3.6930],\n",
      "        [3.5293, 3.7837, 3.8154, 3.7907, 3.6770],\n",
      "        [3.5482, 3.6413, 3.8061, 3.7220, 3.6104],\n",
      "        [3.7397, 4.0460, 3.9816, 4.0295, 3.8626],\n",
      "        [3.4519, 3.5547, 3.6054, 3.6874, 3.4857],\n",
      "        [3.5482, 3.6413, 3.8061, 3.7220, 3.6104],\n",
      "        [3.5885, 3.6393, 3.8068, 3.7295, 3.6720],\n",
      "        [4.0092, 4.0186, 4.1633, 4.2900, 4.0177],\n",
      "        [3.5104, 3.7511, 3.9058, 3.8052, 3.5633],\n",
      "        [3.5932, 3.8446, 3.8236, 3.7357, 3.6834],\n",
      "        [3.5428, 3.7751, 3.7273, 3.8465, 3.5734],\n",
      "        [4.0255, 4.1313, 4.1619, 4.3267, 4.0552],\n",
      "        [3.4108, 3.5694, 3.6830, 3.6551, 3.4956],\n",
      "        [3.4077, 3.7619, 3.8204, 3.6887, 3.5378],\n",
      "        [3.7408, 3.8722, 4.0076, 3.9823, 3.9232],\n",
      "        [3.5966, 3.6179, 3.9291, 3.8392, 3.6400],\n",
      "        [3.7695, 4.0721, 4.0130, 4.0624, 3.8881]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8351, 3.8762, 3.9660, 4.0030, 3.9525],\n",
      "        [3.4070, 3.5972, 3.7161, 3.6103, 3.4994],\n",
      "        [3.3606, 3.6025, 3.6784, 3.6116, 3.5238],\n",
      "        [3.6996, 3.7296, 3.8958, 3.8557, 3.6720],\n",
      "        [3.5810, 3.8442, 3.8260, 3.7240, 3.6879],\n",
      "        [3.6972, 3.7371, 3.7937, 3.9535, 3.7587],\n",
      "        [3.7073, 3.9098, 3.8869, 3.9160, 3.7518],\n",
      "        [3.8027, 3.7602, 3.8770, 3.8041, 3.6537],\n",
      "        [3.5570, 3.7114, 3.7288, 3.7431, 3.6438],\n",
      "        [3.4037, 3.6700, 3.7431, 3.6129, 3.5207],\n",
      "        [3.6803, 3.8968, 3.8593, 3.8379, 3.7294],\n",
      "        [3.4681, 3.6365, 3.7818, 3.6921, 3.5164],\n",
      "        [3.5296, 3.7149, 3.6813, 3.7449, 3.5911],\n",
      "        [3.4366, 3.6244, 3.7570, 3.6541, 3.5085],\n",
      "        [3.8693, 3.7668, 3.9085, 4.2455, 3.9621],\n",
      "        [3.8654, 3.9118, 4.0324, 4.0716, 3.8500],\n",
      "        [3.5401, 3.6315, 3.7951, 3.7194, 3.6030],\n",
      "        [4.2821, 4.4740, 4.1760, 4.1803, 3.9579],\n",
      "        [3.3720, 3.4648, 3.6439, 3.6438, 3.4463],\n",
      "        [3.4212, 3.5725, 3.7102, 3.6192, 3.4969],\n",
      "        [3.5375, 3.9817, 3.8400, 3.9137, 3.7462],\n",
      "        [3.6381, 3.6050, 3.7580, 3.7029, 3.6661],\n",
      "        [3.7330, 3.8869, 3.9628, 3.7992, 3.7585],\n",
      "        [3.4572, 3.5625, 3.6054, 3.6851, 3.4615],\n",
      "        [3.4552, 3.5341, 3.6963, 3.6527, 3.4909],\n",
      "        [3.4275, 3.8021, 3.6871, 3.5008, 3.6142],\n",
      "        [3.9316, 4.1239, 4.0181, 4.1215, 4.1019],\n",
      "        [3.4037, 3.7021, 3.7544, 3.6157, 3.5359],\n",
      "        [3.5397, 3.7275, 3.6926, 3.7538, 3.6057],\n",
      "        [3.5639, 3.5587, 3.7491, 3.6225, 3.5175],\n",
      "        [3.7817, 3.9325, 3.9286, 3.9173, 3.8487],\n",
      "        [3.5270, 3.9834, 3.8139, 3.7558, 3.8177],\n",
      "        [3.6689, 3.5763, 3.9711, 3.8295, 3.6890],\n",
      "        [3.4170, 3.6201, 3.6516, 3.5849, 3.5366],\n",
      "        [3.6029, 3.6391, 3.8540, 3.7507, 3.6718],\n",
      "        [3.7529, 3.8420, 3.9859, 3.9418, 3.6537],\n",
      "        [3.7403, 3.9729, 3.9984, 3.9191, 3.7601],\n",
      "        [3.5170, 4.0494, 4.0212, 3.7872, 3.6391],\n",
      "        [3.3462, 3.5548, 3.6106, 3.4914, 3.4572],\n",
      "        [3.7424, 3.9930, 3.9003, 3.8486, 3.7506],\n",
      "        [3.6557, 3.6934, 3.8604, 3.7040, 3.6212],\n",
      "        [3.5206, 3.5630, 3.7890, 3.6872, 3.5696],\n",
      "        [3.4622, 3.6278, 3.6378, 3.6693, 3.4877],\n",
      "        [3.5276, 3.7110, 3.6904, 3.7281, 3.6033],\n",
      "        [3.5604, 3.8809, 3.7615, 3.8725, 3.6959],\n",
      "        [3.4179, 3.5934, 3.7204, 3.6323, 3.5081],\n",
      "        [3.9949, 4.2321, 3.8791, 3.9106, 3.7616],\n",
      "        [3.4704, 3.6172, 3.7756, 3.7089, 3.5931],\n",
      "        [3.7079, 3.7681, 3.8889, 3.7836, 3.8230],\n",
      "        [3.4466, 3.5831, 3.6309, 3.6849, 3.4366],\n",
      "        [3.4564, 3.6496, 3.7772, 3.6051, 3.6732],\n",
      "        [3.7397, 4.0453, 3.9802, 4.0293, 3.8608],\n",
      "        [4.0933, 4.1674, 4.2111, 4.4048, 3.9206],\n",
      "        [3.5528, 3.6236, 3.7340, 3.7795, 3.5546],\n",
      "        [3.4564, 3.5617, 3.6049, 3.6846, 3.4609],\n",
      "        [3.7628, 3.7085, 3.8512, 4.0669, 3.8294],\n",
      "        [3.4573, 3.8894, 3.9465, 3.7634, 3.8027],\n",
      "        [3.4907, 3.6235, 3.5706, 3.7413, 3.4693],\n",
      "        [3.5485, 3.8471, 3.8619, 3.6763, 3.7055],\n",
      "        [3.4134, 3.5943, 3.7197, 3.6165, 3.5010],\n",
      "        [3.5381, 3.6458, 3.8127, 3.7440, 3.6195],\n",
      "        [3.8500, 4.0470, 3.8838, 3.8732, 3.7529],\n",
      "        [3.4526, 3.5274, 3.6880, 3.6542, 3.4857],\n",
      "        [3.6716, 3.6952, 3.8442, 3.7066, 3.4990]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7015, 3.7393, 3.8765, 3.7789, 3.5695],\n",
      "        [3.5683, 3.6105, 3.7210, 3.6666, 3.6475],\n",
      "        [3.4438, 3.8619, 3.8218, 3.5920, 3.7143],\n",
      "        [3.6101, 3.9777, 4.0243, 3.9268, 3.8635],\n",
      "        [3.9925, 4.0625, 4.1188, 4.2828, 3.8353],\n",
      "        [3.7501, 3.7286, 3.8478, 3.7410, 3.5917],\n",
      "        [3.5203, 3.9738, 3.8086, 3.7503, 3.8055],\n",
      "        [3.4314, 3.5535, 3.6913, 3.6190, 3.4848],\n",
      "        [3.4073, 3.6390, 3.7035, 3.6588, 3.4963],\n",
      "        [3.5803, 3.6204, 3.8554, 3.7848, 3.7342],\n",
      "        [3.6537, 3.6867, 3.8502, 3.7161, 3.5911],\n",
      "        [3.6565, 3.7442, 3.8272, 3.7839, 3.6662],\n",
      "        [3.7049, 3.9192, 3.9780, 3.9270, 3.7855],\n",
      "        [3.5787, 3.6403, 3.8275, 3.7529, 3.6454],\n",
      "        [3.4520, 3.6229, 3.7678, 3.6583, 3.5236],\n",
      "        [4.1679, 4.3765, 4.0927, 4.1056, 3.8728],\n",
      "        [3.7110, 4.0000, 3.9543, 3.9056, 3.7878],\n",
      "        [3.4378, 3.6136, 3.7139, 3.6246, 3.5327],\n",
      "        [3.6171, 3.7335, 3.8041, 3.7243, 3.6655],\n",
      "        [3.4036, 3.6358, 3.6669, 3.6323, 3.5018],\n",
      "        [3.5548, 3.6778, 3.7530, 3.7910, 3.6082],\n",
      "        [3.7786, 3.8923, 4.0624, 4.0012, 3.9540],\n",
      "        [3.8514, 3.9913, 3.9622, 3.9916, 3.9208],\n",
      "        [3.8962, 3.9781, 4.0030, 4.1379, 3.9006],\n",
      "        [3.4083, 3.6962, 3.7591, 3.6204, 3.5362],\n",
      "        [3.7374, 3.9738, 3.9324, 3.8969, 3.8148],\n",
      "        [3.7161, 3.9284, 3.9412, 3.9274, 3.7521],\n",
      "        [3.4930, 3.5100, 3.7491, 3.6797, 3.6117],\n",
      "        [3.6388, 4.0158, 3.9639, 3.8915, 3.8501],\n",
      "        [3.7374, 3.9738, 3.9324, 3.8969, 3.8148],\n",
      "        [3.7007, 3.9751, 3.9878, 3.9258, 3.8747],\n",
      "        [3.5707, 3.6161, 3.7283, 3.6749, 3.6589],\n",
      "        [3.8366, 3.6090, 3.8698, 4.1632, 4.0157],\n",
      "        [3.6648, 3.9108, 3.8858, 3.9633, 3.7476],\n",
      "        [3.9070, 3.9651, 4.0891, 4.1269, 3.9102],\n",
      "        [3.5930, 3.6455, 3.8083, 3.7332, 3.6760],\n",
      "        [3.5344, 3.6008, 3.8059, 3.7147, 3.5892],\n",
      "        [3.5714, 3.5691, 3.7454, 3.7055, 3.7082],\n",
      "        [3.5400, 3.8499, 3.8715, 3.6501, 3.7043],\n",
      "        [3.5541, 3.6302, 3.8087, 3.7235, 3.6105],\n",
      "        [3.3676, 3.4562, 3.6497, 3.6297, 3.4515],\n",
      "        [3.5646, 3.7495, 3.7110, 3.7878, 3.6291],\n",
      "        [3.4049, 3.6852, 3.7493, 3.6144, 3.5277],\n",
      "        [3.6873, 4.0420, 4.0154, 3.9238, 3.8719],\n",
      "        [3.5130, 3.6398, 3.5778, 3.7659, 3.4639],\n",
      "        [3.9260, 3.8304, 4.0408, 4.4132, 4.1748],\n",
      "        [3.5691, 3.7575, 3.7027, 3.7977, 3.6287],\n",
      "        [3.5094, 3.9482, 3.7757, 3.6904, 3.7539],\n",
      "        [3.3962, 3.4990, 3.6701, 3.6139, 3.4825],\n",
      "        [3.6004, 3.6503, 3.8960, 3.8322, 3.7557],\n",
      "        [3.2472, 3.4911, 3.6443, 3.5003, 3.4568],\n",
      "        [3.2366, 3.4943, 3.6516, 3.4856, 3.4408],\n",
      "        [3.4571, 3.6605, 3.6670, 3.6371, 3.5541],\n",
      "        [3.9436, 3.9698, 4.0976, 4.1751, 3.9239],\n",
      "        [3.6523, 3.9223, 3.8698, 3.9537, 3.7489],\n",
      "        [3.4820, 3.7690, 3.9027, 3.8712, 3.5571],\n",
      "        [3.4473, 3.6455, 3.7945, 3.6812, 3.5072],\n",
      "        [3.8416, 3.6837, 3.7603, 3.8229, 3.8041],\n",
      "        [3.6952, 3.9169, 3.8759, 4.0034, 3.7956],\n",
      "        [3.4237, 3.5940, 3.7202, 3.6264, 3.5146],\n",
      "        [3.5381, 3.6997, 3.7547, 3.6944, 3.6273],\n",
      "        [3.4481, 3.9178, 3.7526, 3.6532, 3.6965],\n",
      "        [3.7430, 3.9969, 3.9014, 3.8505, 3.7509],\n",
      "        [3.9728, 3.9871, 3.9803, 4.1102, 4.0192]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7852, 3.8899, 4.0375, 4.0603, 3.7450],\n",
      "        [3.4121, 3.5750, 3.6793, 3.6493, 3.4888],\n",
      "        [3.5462, 3.6530, 3.8126, 3.7454, 3.6087],\n",
      "        [3.5695, 3.7510, 3.9711, 3.8288, 3.7744],\n",
      "        [3.4513, 3.6218, 3.7668, 3.6580, 3.5218],\n",
      "        [3.7072, 3.9875, 4.0238, 3.9302, 3.7350],\n",
      "        [3.5408, 3.5711, 3.7595, 3.6410, 3.5288],\n",
      "        [3.5137, 3.7412, 3.7552, 3.6024, 3.5352],\n",
      "        [3.5838, 3.6970, 3.9343, 3.8158, 3.6968],\n",
      "        [3.9005, 3.9827, 3.9568, 4.0078, 3.9659],\n",
      "        [3.6012, 3.8459, 3.8094, 3.7569, 3.6596],\n",
      "        [3.9120, 3.8068, 4.0302, 4.4093, 4.1662],\n",
      "        [3.5255, 3.7136, 3.6867, 3.7301, 3.5957],\n",
      "        [3.7228, 3.9723, 3.9275, 3.8964, 3.7978],\n",
      "        [3.4633, 3.5786, 3.6133, 3.7094, 3.5115],\n",
      "        [3.4227, 3.6001, 3.6041, 3.6218, 3.4447],\n",
      "        [3.8358, 3.6079, 3.8687, 4.1629, 4.0139],\n",
      "        [3.5222, 4.0578, 4.0166, 3.7987, 3.6433],\n",
      "        [3.5141, 3.7061, 3.8703, 3.8152, 3.7693],\n",
      "        [3.4538, 3.6388, 3.6526, 3.6243, 3.5306],\n",
      "        [3.4036, 3.6427, 3.7365, 3.6216, 3.5190],\n",
      "        [3.3971, 3.6013, 3.6402, 3.5601, 3.5177],\n",
      "        [3.4471, 3.5806, 3.6308, 3.6866, 3.4356],\n",
      "        [3.5499, 3.6307, 3.8088, 3.7260, 3.6078],\n",
      "        [3.5760, 3.6406, 3.8151, 3.7446, 3.6442],\n",
      "        [3.5018, 4.0648, 4.0420, 3.8691, 3.6783],\n",
      "        [4.0308, 3.9573, 4.0874, 4.1631, 4.0465],\n",
      "        [3.5458, 3.7770, 3.8373, 3.7452, 3.6744],\n",
      "        [3.5171, 3.6234, 3.8205, 3.7443, 3.6870],\n",
      "        [3.5275, 3.6325, 3.8999, 3.5915, 3.7467],\n",
      "        [3.9033, 3.9625, 4.0540, 4.1360, 3.8371],\n",
      "        [3.4235, 3.5782, 3.7163, 3.6311, 3.5082],\n",
      "        [3.7947, 3.7519, 3.8615, 3.7840, 3.6211],\n",
      "        [3.5421, 3.7251, 3.6793, 3.7582, 3.6011],\n",
      "        [3.4650, 3.6117, 3.6616, 3.6750, 3.5146],\n",
      "        [3.6001, 3.8927, 3.9313, 3.9037, 3.6379],\n",
      "        [3.7909, 4.0251, 4.0783, 3.9365, 3.6469],\n",
      "        [3.5851, 3.6337, 3.7533, 3.6965, 3.6694],\n",
      "        [3.5656, 3.5958, 3.8263, 3.7538, 3.7104],\n",
      "        [3.5351, 3.6412, 3.7972, 3.7259, 3.6010],\n",
      "        [3.4526, 3.5172, 3.6847, 3.6685, 3.4925],\n",
      "        [3.6126, 3.7804, 3.8787, 3.8844, 3.7034],\n",
      "        [3.4419, 3.5120, 3.6773, 3.6578, 3.4759],\n",
      "        [3.5253, 3.7584, 3.9360, 3.7180, 3.6389],\n",
      "        [3.9423, 3.8054, 4.0283, 4.0523, 3.8636],\n",
      "        [3.7670, 4.0663, 4.0094, 4.0656, 3.8796],\n",
      "        [3.4492, 3.8314, 3.8633, 3.6714, 3.6961],\n",
      "        [3.7095, 3.9236, 3.9522, 4.0068, 3.7517],\n",
      "        [3.5302, 3.6429, 3.7985, 3.7295, 3.5996],\n",
      "        [3.2966, 3.8487, 3.8132, 3.6912, 3.4388],\n",
      "        [3.5723, 3.6609, 3.8879, 3.6703, 3.7648],\n",
      "        [3.4343, 3.5254, 3.6830, 3.6389, 3.4741],\n",
      "        [3.5587, 3.8471, 3.8070, 3.7132, 3.6702],\n",
      "        [3.5713, 3.7072, 3.8038, 3.7187, 3.5274],\n",
      "        [3.6423, 3.7444, 3.8260, 3.7674, 3.6694],\n",
      "        [3.9715, 3.9873, 3.9608, 4.1064, 4.0265],\n",
      "        [3.6884, 3.7595, 3.8686, 3.8476, 3.7778],\n",
      "        [3.5006, 3.6847, 3.6675, 3.6837, 3.5693],\n",
      "        [3.3435, 3.5520, 3.6000, 3.4926, 3.4519],\n",
      "        [3.5819, 3.6469, 3.8291, 3.7688, 3.6775],\n",
      "        [3.4016, 3.5295, 3.6814, 3.5914, 3.4593],\n",
      "        [3.8506, 3.8548, 3.9430, 3.9259, 3.8671],\n",
      "        [3.6714, 3.8211, 3.9605, 3.7977, 3.5898],\n",
      "        [3.7365, 3.8999, 3.9861, 3.9358, 3.7387]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7076, 3.7524, 3.8807, 3.7864, 3.5663],\n",
      "        [3.7055, 3.9069, 3.8832, 3.9151, 3.7460],\n",
      "        [4.0495, 4.0254, 4.2066, 4.2856, 4.0460],\n",
      "        [3.6738, 3.8679, 3.9673, 3.8637, 3.7261],\n",
      "        [3.6221, 3.9086, 3.8632, 3.8459, 3.8119],\n",
      "        [3.3502, 3.5572, 3.6080, 3.4990, 3.4616],\n",
      "        [3.7466, 3.8169, 4.0386, 3.8830, 3.5437],\n",
      "        [3.5643, 3.7580, 3.7085, 3.7941, 3.6332],\n",
      "        [3.4142, 3.6109, 3.6403, 3.5790, 3.5053],\n",
      "        [3.7213, 3.7241, 3.8251, 4.0468, 3.8140],\n",
      "        [3.5508, 3.6812, 3.8316, 3.7682, 3.6336],\n",
      "        [3.8059, 4.0310, 4.0546, 4.0232, 3.8980],\n",
      "        [3.7900, 4.0239, 4.0771, 3.9357, 3.6448],\n",
      "        [3.5291, 3.7050, 3.6805, 3.7146, 3.5994],\n",
      "        [3.7204, 3.9299, 3.9557, 3.9422, 3.7535],\n",
      "        [3.5400, 3.6564, 3.7185, 3.7616, 3.5723],\n",
      "        [3.4115, 3.7158, 3.7654, 3.6231, 3.5471],\n",
      "        [3.4736, 3.6275, 3.7408, 3.6179, 3.5536],\n",
      "        [3.4912, 3.7275, 3.7463, 3.7768, 3.5723],\n",
      "        [3.8179, 3.8719, 3.9615, 3.9847, 3.9465],\n",
      "        [3.5714, 3.5742, 3.7668, 3.6340, 3.5304],\n",
      "        [3.9166, 4.0545, 4.0297, 4.0328, 3.9993],\n",
      "        [3.4096, 3.7342, 3.6154, 3.6930, 3.4859],\n",
      "        [3.6212, 3.6182, 3.9459, 3.8518, 3.6588],\n",
      "        [3.4211, 3.5636, 3.7031, 3.6213, 3.4919],\n",
      "        [3.4308, 3.5789, 3.7315, 3.6408, 3.4785],\n",
      "        [3.5416, 3.9528, 3.8532, 3.8682, 3.7700],\n",
      "        [4.0101, 3.9546, 4.0099, 4.1083, 3.9818],\n",
      "        [3.5593, 3.7456, 3.7055, 3.7872, 3.6198],\n",
      "        [3.7725, 3.6209, 3.7363, 3.7458, 3.7733],\n",
      "        [3.4291, 3.9256, 3.9078, 3.7451, 3.8051],\n",
      "        [3.5401, 3.6632, 3.8146, 3.7481, 3.6112],\n",
      "        [3.8559, 3.9173, 4.1384, 4.1793, 3.7694],\n",
      "        [3.5029, 3.8699, 3.8580, 3.7263, 3.5621],\n",
      "        [3.8264, 3.6208, 3.8942, 4.1303, 3.9885],\n",
      "        [3.7162, 3.9548, 3.9116, 3.9152, 3.7677],\n",
      "        [3.6918, 3.8691, 3.9389, 3.8554, 3.6075],\n",
      "        [3.6866, 3.7089, 3.8152, 3.9532, 3.7381],\n",
      "        [3.8706, 3.9345, 4.0310, 4.0877, 3.7982],\n",
      "        [3.9890, 3.8561, 4.1263, 4.4786, 4.2497],\n",
      "        [3.5084, 3.6022, 3.7625, 3.5813, 3.6242],\n",
      "        [3.5528, 3.9091, 3.8951, 3.7576, 3.5261],\n",
      "        [3.4568, 3.5571, 3.6037, 3.6833, 3.4139],\n",
      "        [3.4808, 3.6149, 3.7845, 3.7201, 3.5822],\n",
      "        [3.5873, 3.7234, 3.8021, 3.7168, 3.5330],\n",
      "        [3.7349, 3.9610, 3.9663, 3.9120, 3.7446],\n",
      "        [3.4538, 3.6374, 3.7938, 3.7342, 3.6005],\n",
      "        [3.4134, 3.7000, 3.7610, 3.6323, 3.5498],\n",
      "        [4.0163, 4.1894, 4.0046, 3.9680, 3.8235],\n",
      "        [3.3533, 3.5622, 3.5518, 3.5469, 3.4101],\n",
      "        [3.5278, 3.7117, 3.6776, 3.7438, 3.5857],\n",
      "        [3.6567, 3.7344, 3.8352, 3.8087, 3.7513],\n",
      "        [3.6823, 3.8926, 3.9041, 3.8478, 3.8172],\n",
      "        [3.3920, 3.5886, 3.5841, 3.5845, 3.4351],\n",
      "        [3.4077, 3.6610, 3.7409, 3.6148, 3.5131],\n",
      "        [3.5342, 3.6399, 3.7959, 3.7251, 3.5990],\n",
      "        [3.5184, 3.9715, 3.8063, 3.7493, 3.8015],\n",
      "        [3.4518, 3.5441, 3.6986, 3.6478, 3.4924],\n",
      "        [3.9053, 3.9630, 4.0868, 4.1263, 3.9062],\n",
      "        [3.6840, 3.8663, 3.9811, 3.8019, 3.5936],\n",
      "        [3.9561, 3.9145, 4.0241, 4.1364, 3.9240],\n",
      "        [3.5881, 3.6366, 3.8149, 3.7350, 3.6615],\n",
      "        [3.4877, 3.4902, 3.6411, 3.6454, 3.4537],\n",
      "        [3.5482, 3.6677, 3.8211, 3.7546, 3.6304]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3772, 3.5028, 3.6602, 3.5698, 3.4216],\n",
      "        [3.7381, 3.8870, 3.9794, 4.0180, 3.7310],\n",
      "        [3.8696, 3.9332, 4.0296, 4.0865, 3.7971],\n",
      "        [3.5797, 3.9119, 3.9331, 3.8808, 3.8535],\n",
      "        [3.4536, 3.5572, 3.5998, 3.6824, 3.4546],\n",
      "        [3.5441, 3.7744, 3.8346, 3.7432, 3.6712],\n",
      "        [3.5746, 3.5844, 3.8074, 3.7401, 3.7105],\n",
      "        [3.6511, 3.6829, 3.8462, 3.7137, 3.5861],\n",
      "        [3.3990, 3.5211, 3.6397, 3.6467, 3.4653],\n",
      "        [3.4392, 3.5757, 3.7228, 3.6470, 3.5140],\n",
      "        [3.9645, 4.0541, 4.1381, 4.2411, 3.8827],\n",
      "        [3.5569, 3.8447, 3.8044, 3.7114, 3.6671],\n",
      "        [3.5476, 3.6464, 3.9017, 3.6279, 3.7510],\n",
      "        [3.7134, 3.9247, 3.9375, 3.9252, 3.7470],\n",
      "        [3.4023, 3.7079, 3.7602, 3.6159, 3.5397],\n",
      "        [3.4197, 3.7252, 3.7703, 3.6426, 3.5666],\n",
      "        [3.6552, 3.7418, 3.8202, 3.7869, 3.6596],\n",
      "        [3.4216, 3.5611, 3.7033, 3.6237, 3.4900],\n",
      "        [3.9899, 4.0590, 4.1157, 4.2812, 3.8299],\n",
      "        [3.7596, 3.6202, 3.8733, 4.0424, 3.9342],\n",
      "        [3.5382, 3.5712, 3.8233, 3.5976, 3.6506],\n",
      "        [3.4570, 3.9472, 3.9411, 3.7840, 3.8192],\n",
      "        [3.5451, 3.6097, 3.8080, 3.7177, 3.5894],\n",
      "        [3.4460, 3.6643, 3.7848, 3.6702, 3.5381],\n",
      "        [3.6924, 3.9132, 3.8721, 4.0011, 3.7907],\n",
      "        [3.4287, 3.7369, 3.7795, 3.6479, 3.5791],\n",
      "        [3.5113, 3.9186, 3.8881, 3.7318, 3.5220],\n",
      "        [3.6924, 3.9132, 3.8721, 4.0011, 3.7907],\n",
      "        [3.3271, 3.5299, 3.5901, 3.4696, 3.4299],\n",
      "        [3.4631, 3.6428, 3.7859, 3.6885, 3.5131],\n",
      "        [3.5708, 3.5814, 3.7935, 3.7347, 3.7063],\n",
      "        [3.5057, 3.6836, 3.6675, 3.6979, 3.5777],\n",
      "        [3.5605, 3.8184, 3.9292, 3.8058, 3.5835],\n",
      "        [3.4325, 3.5228, 3.6804, 3.6369, 3.4711],\n",
      "        [3.6354, 3.6206, 3.8020, 3.7361, 3.6774],\n",
      "        [3.5937, 3.8333, 3.8157, 3.7528, 3.7033],\n",
      "        [3.4017, 3.5316, 3.6736, 3.5886, 3.4511],\n",
      "        [3.6118, 3.6109, 3.8114, 3.7555, 3.5807],\n",
      "        [3.7896, 4.0970, 4.0110, 4.0562, 3.9492],\n",
      "        [3.7522, 3.8298, 4.0005, 3.9156, 3.6215],\n",
      "        [3.8457, 4.0462, 3.8783, 3.8692, 3.7467],\n",
      "        [3.8672, 3.9243, 4.1539, 4.1911, 3.7800],\n",
      "        [3.5272, 3.8344, 3.8623, 3.7148, 3.7167],\n",
      "        [3.6755, 4.0192, 4.0110, 3.9283, 3.9366],\n",
      "        [3.5283, 3.6402, 3.7958, 3.7275, 3.5965],\n",
      "        [3.7787, 3.9279, 3.9229, 3.9150, 3.8418],\n",
      "        [3.7094, 3.9963, 3.8841, 3.7302, 3.7512],\n",
      "        [3.9666, 4.0207, 4.1219, 4.2193, 3.7495],\n",
      "        [3.4365, 3.8046, 3.8534, 3.6461, 3.6923],\n",
      "        [3.5047, 3.6920, 3.6708, 3.7081, 3.5683],\n",
      "        [3.7835, 3.8872, 4.0347, 4.0584, 3.7419],\n",
      "        [3.3493, 3.5560, 3.6066, 3.4978, 3.4607],\n",
      "        [3.5558, 3.6686, 3.9169, 3.8445, 3.6856],\n",
      "        [3.5000, 4.0620, 4.0391, 3.8670, 3.6750],\n",
      "        [3.4493, 3.5063, 3.6764, 3.6497, 3.4680],\n",
      "        [4.0532, 4.1768, 3.8682, 3.9704, 3.7362],\n",
      "        [3.6498, 3.9074, 3.8327, 3.8311, 3.7121],\n",
      "        [3.7792, 3.9802, 4.0636, 3.9970, 3.9722],\n",
      "        [3.7194, 3.9286, 3.9543, 3.9410, 3.7525],\n",
      "        [3.9099, 3.8183, 4.0333, 4.0897, 3.8360],\n",
      "        [3.6203, 4.0555, 3.8926, 3.9911, 3.8208],\n",
      "        [3.5409, 3.7266, 3.6862, 3.7596, 3.6041],\n",
      "        [3.2971, 3.5418, 3.6711, 3.5373, 3.4732],\n",
      "        [3.4693, 3.6677, 3.6658, 3.6526, 3.5562]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5012, 3.5147, 3.8021, 3.5264, 3.6329],\n",
      "        [3.3944, 3.6072, 3.6402, 3.5635, 3.5046],\n",
      "        [3.5465, 3.6449, 3.9001, 3.6262, 3.7498],\n",
      "        [3.6865, 3.7128, 3.8749, 3.8323, 3.6518],\n",
      "        [3.6883, 3.7562, 3.8449, 3.7671, 3.4832],\n",
      "        [3.8899, 3.7951, 4.0229, 4.3881, 4.1624],\n",
      "        [3.5548, 3.9659, 3.8800, 3.8911, 3.8163],\n",
      "        [4.0086, 3.9517, 4.0069, 4.1056, 3.9803],\n",
      "        [3.4464, 3.7162, 3.8721, 3.6893, 3.6514],\n",
      "        [3.3619, 3.5685, 3.5366, 3.6292, 3.4401],\n",
      "        [3.4313, 3.5449, 3.6973, 3.6387, 3.4869],\n",
      "        [4.1205, 4.2920, 4.0210, 4.0226, 3.8078],\n",
      "        [3.6010, 3.6268, 3.8466, 3.7498, 3.6628],\n",
      "        [3.5884, 3.6516, 3.8190, 3.7378, 3.6523],\n",
      "        [3.6535, 3.7693, 3.8493, 3.9353, 3.6703],\n",
      "        [3.7088, 3.9968, 4.0002, 3.9544, 3.8870],\n",
      "        [3.6252, 3.9305, 3.8791, 3.8580, 3.8285],\n",
      "        [3.9323, 4.0099, 4.0360, 4.1857, 3.9474],\n",
      "        [3.8012, 4.0094, 3.9962, 3.8097, 3.8322],\n",
      "        [3.5981, 3.6885, 3.8105, 3.7199, 3.8072],\n",
      "        [3.6815, 3.7746, 3.7315, 3.8706, 3.7752],\n",
      "        [3.6191, 3.7708, 3.8558, 3.8359, 3.7421],\n",
      "        [3.7571, 3.8717, 4.1142, 3.8433, 3.5801],\n",
      "        [3.5532, 3.5423, 3.7022, 3.6665, 3.6807],\n",
      "        [3.7889, 4.0241, 4.0727, 3.9364, 3.6331],\n",
      "        [3.3957, 3.6686, 3.7428, 3.6188, 3.5181],\n",
      "        [3.5717, 3.6469, 3.8719, 3.7581, 3.6665],\n",
      "        [3.4637, 3.6684, 3.8037, 3.5849, 3.6631],\n",
      "        [3.3944, 3.6072, 3.6402, 3.5635, 3.5046],\n",
      "        [3.7540, 3.5509, 3.7103, 3.7547, 3.7028],\n",
      "        [3.5702, 3.6032, 3.8354, 3.7639, 3.7168],\n",
      "        [3.9512, 3.8690, 4.0645, 4.1294, 3.8821],\n",
      "        [3.6913, 3.9117, 3.8706, 3.9995, 3.7895],\n",
      "        [3.4483, 3.6179, 3.7626, 3.6545, 3.5178],\n",
      "        [3.4238, 3.6289, 3.6505, 3.5890, 3.5286],\n",
      "        [3.5634, 3.6096, 3.8259, 3.6695, 3.6482],\n",
      "        [3.4009, 3.5499, 3.6653, 3.6393, 3.4752],\n",
      "        [3.5698, 3.5770, 3.8026, 3.7348, 3.7029],\n",
      "        [3.4707, 3.6109, 3.7724, 3.7177, 3.5729],\n",
      "        [3.4483, 3.6784, 3.6903, 3.7323, 3.5270],\n",
      "        [3.4372, 3.5217, 3.6830, 3.6374, 3.4740],\n",
      "        [3.6958, 3.7082, 3.8418, 3.6893, 3.5225],\n",
      "        [3.4854, 3.5753, 3.8098, 3.6952, 3.5669],\n",
      "        [3.4482, 3.5049, 3.6750, 3.6483, 3.4669],\n",
      "        [3.5554, 3.6324, 3.8123, 3.7266, 3.6132],\n",
      "        [3.7696, 3.9905, 3.9619, 3.7875, 3.7994],\n",
      "        [3.8439, 3.7488, 3.8752, 3.9216, 3.8518],\n",
      "        [3.6109, 3.6814, 3.9132, 3.9181, 3.8662],\n",
      "        [3.5040, 3.5444, 3.7688, 3.6691, 3.5449],\n",
      "        [3.4062, 3.6390, 3.7306, 3.6160, 3.5175],\n",
      "        [3.7269, 3.8903, 3.9778, 3.9298, 3.7285],\n",
      "        [3.9144, 4.0517, 4.0265, 4.0300, 3.9970],\n",
      "        [3.8203, 3.8669, 4.1022, 4.1324, 3.7134],\n",
      "        [3.6502, 3.7455, 3.9299, 3.8418, 3.6802],\n",
      "        [3.4430, 3.6869, 3.6484, 3.6967, 3.5384],\n",
      "        [3.5066, 3.7040, 3.6798, 3.7078, 3.5786],\n",
      "        [3.5629, 3.7558, 3.7007, 3.7943, 3.6233],\n",
      "        [3.8162, 3.9395, 4.0488, 3.9895, 3.7826],\n",
      "        [3.5647, 3.6888, 3.7450, 3.6584, 3.6182],\n",
      "        [3.5565, 3.8105, 3.8176, 3.7812, 3.6845],\n",
      "        [3.4895, 3.6207, 3.5504, 3.7444, 3.4469],\n",
      "        [3.5608, 3.6870, 3.8072, 3.7372, 3.7407],\n",
      "        [3.3607, 3.5730, 3.6172, 3.5111, 3.4714],\n",
      "        [3.7960, 3.8400, 3.9627, 3.9371, 3.9046]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8972, 3.9774, 3.9510, 4.0038, 3.9614],\n",
      "        [3.5027, 3.9055, 3.9097, 3.8227, 3.7722],\n",
      "        [3.4105, 3.5906, 3.5903, 3.5937, 3.4467],\n",
      "        [3.5060, 3.6624, 3.6856, 3.6896, 3.5867],\n",
      "        [3.5631, 3.6080, 3.8242, 3.6685, 3.6478],\n",
      "        [3.6811, 3.7732, 3.7299, 3.8698, 3.7748],\n",
      "        [3.5551, 3.6928, 3.8086, 3.7485, 3.7212],\n",
      "        [3.4994, 3.7468, 3.8964, 3.8045, 3.5561],\n",
      "        [3.7822, 3.8842, 4.0315, 4.0562, 3.7404],\n",
      "        [3.3982, 3.6475, 3.7314, 3.6104, 3.5069],\n",
      "        [4.1949, 4.4437, 4.0722, 4.1326, 3.8945],\n",
      "        [3.5936, 3.9867, 3.9967, 3.9089, 3.8816],\n",
      "        [3.5376, 3.7153, 3.6826, 3.7512, 3.6021],\n",
      "        [3.5172, 3.9115, 3.8891, 3.7428, 3.5243],\n",
      "        [3.2429, 3.4846, 3.6376, 3.4956, 3.4501],\n",
      "        [3.7589, 3.9022, 3.9827, 3.8724, 3.6262],\n",
      "        [3.6784, 3.7955, 3.9585, 3.8138, 3.5750],\n",
      "        [3.4070, 3.7301, 3.6110, 3.6895, 3.4834],\n",
      "        [3.7821, 3.9625, 4.0485, 3.9884, 3.9642],\n",
      "        [3.6328, 3.9622, 3.9075, 3.8704, 3.8385],\n",
      "        [3.4247, 3.5996, 3.7057, 3.6099, 3.5211],\n",
      "        [3.6816, 3.8622, 3.9768, 3.7983, 3.5908],\n",
      "        [3.5547, 3.7404, 3.6869, 3.7798, 3.6153],\n",
      "        [3.6717, 3.7814, 3.7880, 3.7907, 3.6526],\n",
      "        [3.4510, 3.5542, 3.5888, 3.6805, 3.4223],\n",
      "        [3.5964, 3.6434, 3.8889, 3.8274, 3.7495],\n",
      "        [3.5733, 3.6330, 3.8329, 3.7545, 3.6795],\n",
      "        [3.4480, 3.5996, 3.7316, 3.5918, 3.5306],\n",
      "        [3.5610, 3.5965, 3.7016, 3.7947, 3.5311],\n",
      "        [3.4369, 3.5140, 3.6762, 3.6440, 3.4687],\n",
      "        [3.8032, 3.9303, 4.0268, 3.9822, 4.0148],\n",
      "        [3.5131, 3.6581, 3.6913, 3.6522, 3.5571],\n",
      "        [3.7602, 3.7980, 4.0343, 4.0557, 3.6484],\n",
      "        [3.5229, 3.7013, 3.8229, 3.7473, 3.7396],\n",
      "        [3.4491, 3.6454, 3.6510, 3.6238, 3.5397],\n",
      "        [3.5221, 3.6787, 3.6991, 3.7013, 3.6032],\n",
      "        [3.4942, 3.6309, 3.7859, 3.5831, 3.6475],\n",
      "        [3.8539, 3.9005, 4.0204, 4.0658, 3.8320],\n",
      "        [3.5805, 3.8202, 3.8099, 3.7570, 3.6947],\n",
      "        [3.5002, 3.8661, 3.8541, 3.7231, 3.5590],\n",
      "        [3.9902, 3.9260, 4.1172, 4.2079, 3.9426],\n",
      "        [3.5465, 3.5951, 3.8103, 3.7022, 3.5958],\n",
      "        [3.5457, 3.6569, 3.8184, 3.7529, 3.6320],\n",
      "        [3.5442, 3.6195, 3.8519, 3.7614, 3.6383],\n",
      "        [3.4307, 3.5651, 3.7141, 3.6458, 3.4997],\n",
      "        [3.4065, 3.6900, 3.7508, 3.6272, 3.5379],\n",
      "        [3.6204, 3.7619, 3.8431, 3.8045, 3.7477],\n",
      "        [3.8218, 3.8675, 4.1045, 4.1347, 3.7146],\n",
      "        [3.5658, 3.6881, 3.8081, 3.7387, 3.7432],\n",
      "        [3.8917, 3.7508, 3.9130, 4.2790, 3.9876],\n",
      "        [3.3444, 3.4700, 3.6061, 3.4994, 3.4185],\n",
      "        [3.6195, 3.9045, 3.8590, 3.8425, 3.8093],\n",
      "        [3.6199, 3.5183, 3.9212, 3.8149, 3.7049],\n",
      "        [3.5344, 3.7173, 3.6799, 3.7439, 3.5960],\n",
      "        [3.6437, 3.6708, 3.8393, 3.6965, 3.6009],\n",
      "        [3.5232, 3.6349, 3.9194, 3.5694, 3.7522],\n",
      "        [3.7104, 3.7646, 3.8871, 3.7751, 3.8186],\n",
      "        [3.7423, 3.8530, 3.9789, 3.9353, 3.6715],\n",
      "        [3.6100, 3.5969, 3.9154, 3.9417, 3.5618],\n",
      "        [3.7739, 4.0309, 3.9181, 3.7705, 3.7528],\n",
      "        [3.3815, 3.4912, 3.6501, 3.5519, 3.4220],\n",
      "        [3.8033, 4.0268, 4.0503, 4.0195, 3.8952],\n",
      "        [3.4704, 3.7646, 3.6611, 3.7101, 3.5147],\n",
      "        [3.8910, 3.9584, 4.0672, 4.2147, 3.8925]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.9168, 3.7723, 3.9305, 4.3140, 4.0249],\n",
      "        [3.7737, 3.8845, 4.0601, 3.9970, 3.9463],\n",
      "        [3.4381, 3.5048, 3.6751, 3.6522, 3.4710],\n",
      "        [3.6656, 3.8378, 3.8481, 3.8486, 3.7736],\n",
      "        [3.7026, 3.9203, 3.8980, 3.9016, 3.7502],\n",
      "        [3.3990, 3.6798, 3.7448, 3.6078, 3.5211],\n",
      "        [3.4246, 3.4844, 3.6592, 3.6305, 3.4497],\n",
      "        [3.5186, 3.7064, 3.6777, 3.7217, 3.5844],\n",
      "        [3.5542, 3.7387, 3.6904, 3.7785, 3.6149],\n",
      "        [3.6692, 3.9790, 3.8458, 3.8637, 3.8955],\n",
      "        [3.4002, 3.6770, 3.7458, 3.6082, 3.5210],\n",
      "        [3.5637, 3.7731, 3.9101, 3.9256, 3.6167],\n",
      "        [3.5532, 3.5902, 3.6976, 3.6447, 3.6306],\n",
      "        [3.5605, 3.6046, 3.8253, 3.6634, 3.6481],\n",
      "        [3.5467, 4.0051, 3.8542, 3.9424, 3.7673],\n",
      "        [3.5425, 3.6376, 3.8062, 3.7341, 3.6001],\n",
      "        [3.4080, 3.5679, 3.6769, 3.6436, 3.4837],\n",
      "        [3.5226, 3.6330, 3.9228, 3.5679, 3.7517],\n",
      "        [3.6959, 3.8973, 3.8736, 3.8707, 3.7135],\n",
      "        [3.5691, 3.5737, 3.8043, 3.7326, 3.7022],\n",
      "        [3.5691, 3.5767, 3.7937, 3.7309, 3.7045],\n",
      "        [3.7907, 4.0177, 4.0820, 3.9274, 3.6461],\n",
      "        [3.5842, 3.7615, 3.8749, 3.8890, 3.6533],\n",
      "        [3.5485, 3.5826, 3.8266, 3.6315, 3.6453],\n",
      "        [3.5448, 3.6121, 3.8034, 3.7137, 3.5951],\n",
      "        [3.4538, 3.6053, 3.7588, 3.6833, 3.4941],\n",
      "        [3.8525, 3.9507, 4.0430, 4.0142, 4.0541],\n",
      "        [3.4441, 3.5103, 3.6780, 3.6465, 3.4695],\n",
      "        [3.5434, 3.6311, 3.7996, 3.7157, 3.5999],\n",
      "        [3.4965, 3.6709, 3.6612, 3.6925, 3.5483],\n",
      "        [3.7898, 3.6147, 3.8808, 4.0878, 3.9537],\n",
      "        [3.4304, 3.5573, 3.7072, 3.6276, 3.4920],\n",
      "        [3.5479, 3.7235, 3.6799, 3.7596, 3.5932],\n",
      "        [3.3999, 3.6434, 3.7322, 3.6051, 3.5058],\n",
      "        [3.5243, 3.9227, 3.9184, 3.8276, 3.8263],\n",
      "        [3.5989, 4.0249, 3.9126, 3.9542, 3.8267],\n",
      "        [3.9625, 4.0496, 4.1402, 4.2379, 3.8804],\n",
      "        [3.4474, 3.6147, 3.7643, 3.6523, 3.5169],\n",
      "        [3.5869, 3.6646, 3.8780, 3.6898, 3.7734],\n",
      "        [3.9465, 3.9678, 4.0661, 4.1476, 3.9415],\n",
      "        [3.9355, 4.1020, 3.8929, 3.9167, 3.7592],\n",
      "        [3.4111, 3.7493, 3.9147, 3.7073, 3.6510],\n",
      "        [3.5810, 3.6451, 3.8127, 3.7460, 3.6419],\n",
      "        [3.4814, 3.6664, 3.6660, 3.6641, 3.5633],\n",
      "        [3.9971, 3.9981, 4.1257, 4.2593, 3.9998],\n",
      "        [3.5541, 3.8196, 3.9182, 3.8026, 3.5950],\n",
      "        [3.9116, 3.9552, 4.1161, 4.1954, 3.9223],\n",
      "        [3.8005, 3.8609, 3.9876, 4.0220, 3.7810],\n",
      "        [3.4345, 3.6414, 3.6542, 3.6081, 3.5347],\n",
      "        [3.5286, 3.9393, 3.8772, 3.8491, 3.8162],\n",
      "        [3.6071, 3.9002, 3.8141, 3.9182, 3.7218],\n",
      "        [3.4060, 3.8266, 3.7885, 3.5547, 3.6772],\n",
      "        [3.6322, 3.9605, 3.9110, 3.8692, 3.8380],\n",
      "        [3.5052, 3.5962, 3.7609, 3.5762, 3.6213],\n",
      "        [3.6086, 3.8688, 4.0036, 3.9454, 3.7438],\n",
      "        [3.4635, 3.6213, 3.7820, 3.7212, 3.5943],\n",
      "        [3.5917, 3.6523, 3.8595, 3.7799, 3.6621],\n",
      "        [3.3817, 3.5089, 3.6703, 3.5764, 3.4265],\n",
      "        [3.8059, 3.8864, 4.0117, 4.0532, 4.0144],\n",
      "        [3.4511, 3.5540, 3.7152, 3.6447, 3.4755],\n",
      "        [3.2932, 3.8415, 3.8106, 3.6853, 3.4338],\n",
      "        [3.5777, 3.9075, 3.9338, 3.8773, 3.8514],\n",
      "        [3.4748, 3.6488, 3.6989, 3.6593, 3.5662],\n",
      "        [3.7194, 3.8266, 4.0080, 3.8431, 3.6030]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5722, 3.6314, 3.8151, 3.7372, 3.6388],\n",
      "        [3.5863, 3.6626, 3.8808, 3.6882, 3.7728],\n",
      "        [3.5142, 3.9637, 3.8082, 3.7432, 3.7974],\n",
      "        [3.8838, 3.7448, 3.9203, 4.2823, 3.9795],\n",
      "        [3.5419, 3.6149, 3.7984, 3.7143, 3.5996],\n",
      "        [3.4024, 3.7499, 3.8161, 3.6802, 3.5265],\n",
      "        [3.5649, 3.6846, 3.8146, 3.7359, 3.7421],\n",
      "        [3.9289, 3.9611, 4.1238, 4.1743, 3.9003],\n",
      "        [3.8122, 3.8767, 4.0866, 4.1587, 3.7812],\n",
      "        [3.7646, 3.8807, 4.0174, 4.0387, 3.7347],\n",
      "        [3.4620, 3.6633, 3.8080, 3.5811, 3.6616],\n",
      "        [3.5583, 3.6792, 3.9087, 3.8765, 3.8252],\n",
      "        [3.4756, 3.6102, 3.7630, 3.6938, 3.5131],\n",
      "        [3.6775, 3.7007, 3.8780, 3.8209, 3.6500],\n",
      "        [3.4835, 3.6410, 3.6853, 3.6894, 3.5677],\n",
      "        [3.5482, 3.6194, 3.8698, 3.7641, 3.6297],\n",
      "        [3.6091, 3.9353, 3.7913, 3.8104, 3.6660],\n",
      "        [3.7153, 3.8787, 3.9581, 3.9929, 3.7261],\n",
      "        [3.7558, 3.9675, 3.9441, 3.9032, 3.8354],\n",
      "        [3.3904, 3.5699, 3.6775, 3.6336, 3.4713],\n",
      "        [3.5658, 3.8896, 3.9432, 3.9271, 3.6263],\n",
      "        [3.5917, 3.6402, 3.8427, 3.7619, 3.6454],\n",
      "        [3.5097, 3.7320, 3.7548, 3.5949, 3.5295],\n",
      "        [3.7179, 3.8185, 3.7793, 3.9028, 3.7957],\n",
      "        [3.6056, 3.6684, 3.8736, 3.7651, 3.6886],\n",
      "        [3.4861, 3.6915, 3.7022, 3.6638, 3.6023],\n",
      "        [3.5399, 3.7830, 3.8541, 3.7618, 3.6325],\n",
      "        [3.5034, 3.7467, 3.9006, 3.8487, 3.5565],\n",
      "        [3.6870, 3.9367, 3.9832, 3.9184, 3.8250],\n",
      "        [3.6558, 3.8448, 3.9074, 3.8372, 3.8082],\n",
      "        [3.4225, 3.5906, 3.6995, 3.6076, 3.5114],\n",
      "        [3.4645, 3.7137, 3.8208, 3.6370, 3.5863],\n",
      "        [3.2309, 3.4843, 3.6511, 3.4782, 3.4329],\n",
      "        [3.5308, 3.6231, 3.8036, 3.7229, 3.6002],\n",
      "        [3.5498, 3.7952, 3.8229, 3.7887, 3.6802],\n",
      "        [3.8535, 4.0734, 3.9643, 3.8508, 3.8016],\n",
      "        [3.7116, 3.9830, 3.9281, 3.8997, 3.7710],\n",
      "        [3.4656, 3.6950, 3.6931, 3.7531, 3.5335],\n",
      "        [3.5952, 3.6535, 3.8628, 3.7515, 3.6707],\n",
      "        [3.4534, 3.5563, 3.7238, 3.6459, 3.4778],\n",
      "        [3.6878, 3.8733, 3.9960, 3.8956, 3.7398],\n",
      "        [3.6168, 3.7008, 3.8288, 3.8300, 3.6502],\n",
      "        [3.3592, 3.5589, 3.5575, 3.5356, 3.4147],\n",
      "        [3.7493, 4.0848, 4.0753, 3.9796, 3.9068],\n",
      "        [3.4092, 3.5872, 3.5965, 3.5909, 3.4455],\n",
      "        [3.5636, 3.6837, 3.7492, 3.6546, 3.6169],\n",
      "        [4.0578, 4.0079, 4.1985, 4.2724, 4.0350],\n",
      "        [3.4739, 3.6612, 3.6617, 3.6524, 3.5482],\n",
      "        [3.7048, 3.7872, 3.7386, 3.8805, 3.7982],\n",
      "        [3.6782, 3.7414, 3.8685, 3.7599, 3.7868],\n",
      "        [3.5922, 3.8372, 3.8160, 3.7362, 3.6664],\n",
      "        [3.4866, 3.6666, 3.6652, 3.6654, 3.5642],\n",
      "        [3.4761, 3.6648, 3.6650, 3.6602, 3.5512],\n",
      "        [3.4195, 3.7237, 3.7825, 3.6402, 3.5656],\n",
      "        [3.5411, 3.7472, 3.8947, 3.8619, 3.6111],\n",
      "        [3.6469, 3.7120, 3.8077, 3.8724, 3.6844],\n",
      "        [3.6828, 3.8581, 3.8890, 3.8819, 3.7836],\n",
      "        [3.5778, 3.7651, 3.9038, 3.9290, 3.6316],\n",
      "        [3.5275, 3.7614, 3.8281, 3.7301, 3.6463],\n",
      "        [3.8526, 3.8971, 4.0272, 4.0636, 3.8308],\n",
      "        [3.5132, 4.0631, 4.0447, 3.8687, 3.6845],\n",
      "        [3.5243, 3.7041, 3.6796, 3.7374, 3.5822],\n",
      "        [3.7847, 3.5854, 3.7252, 3.7334, 3.7542],\n",
      "        [3.3762, 3.8188, 3.8423, 3.7107, 3.4907]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4872, 3.6110, 3.7419, 3.6220, 3.5713],\n",
      "        [3.9027, 4.0870, 3.9911, 4.0806, 4.0577],\n",
      "        [3.7995, 3.9486, 4.0716, 3.9750, 4.0149],\n",
      "        [3.6246, 3.9091, 3.8466, 3.9288, 3.7329],\n",
      "        [3.4633, 3.6040, 3.7753, 3.6994, 3.5821],\n",
      "        [3.4811, 3.5908, 3.8014, 3.7113, 3.6582],\n",
      "        [3.8942, 3.7997, 4.0205, 4.0528, 3.8133],\n",
      "        [3.5274, 3.7047, 3.6889, 3.7376, 3.5891],\n",
      "        [3.7851, 4.0909, 4.0181, 4.0492, 3.9497],\n",
      "        [3.8362, 3.6909, 3.8502, 3.8612, 3.7974],\n",
      "        [3.4721, 3.6947, 3.7048, 3.7106, 3.5171],\n",
      "        [3.4394, 3.6356, 3.8122, 3.7464, 3.6127],\n",
      "        [3.5159, 3.6896, 3.8263, 3.6225, 3.6391],\n",
      "        [3.3869, 3.5085, 3.6470, 3.5549, 3.4646],\n",
      "        [3.5506, 3.6204, 3.8181, 3.7186, 3.6031],\n",
      "        [3.4866, 3.6000, 3.7810, 3.6740, 3.5659],\n",
      "        [3.4129, 3.5741, 3.7168, 3.6090, 3.4911],\n",
      "        [3.5953, 3.8760, 3.9035, 3.7851, 3.5435],\n",
      "        [3.4305, 3.7718, 3.8405, 3.6181, 3.6657],\n",
      "        [3.6286, 3.6352, 4.0637, 3.8341, 3.7500],\n",
      "        [3.5793, 3.6272, 3.8265, 3.7317, 3.6537],\n",
      "        [3.3989, 3.5971, 3.8208, 3.6400, 3.6046],\n",
      "        [3.5535, 3.8364, 3.8106, 3.7048, 3.6631],\n",
      "        [3.4612, 3.6613, 3.8101, 3.5795, 3.6606],\n",
      "        [3.3674, 3.4814, 3.6560, 3.5396, 3.4124],\n",
      "        [3.9524, 3.8441, 4.0063, 4.0266, 3.9214],\n",
      "        [4.2038, 4.3861, 4.1129, 4.0976, 3.8842],\n",
      "        [3.7310, 3.9625, 3.9368, 3.8894, 3.8054],\n",
      "        [3.8351, 3.9826, 3.9687, 3.9716, 3.9216],\n",
      "        [3.4244, 3.5999, 3.6177, 3.6144, 3.4577],\n",
      "        [3.6462, 3.7100, 3.8098, 3.8707, 3.6835],\n",
      "        [3.5449, 3.9334, 3.9501, 3.8532, 3.8412],\n",
      "        [3.8006, 4.0172, 4.0611, 4.0168, 3.8984],\n",
      "        [3.6658, 3.6840, 3.8447, 3.6996, 3.4894],\n",
      "        [3.5100, 3.6165, 3.7831, 3.5871, 3.6489],\n",
      "        [3.7107, 3.9810, 3.9305, 3.8981, 3.7701],\n",
      "        [3.7485, 4.0828, 4.0777, 3.9779, 3.9058],\n",
      "        [3.4250, 3.7286, 3.7846, 3.6408, 3.5754],\n",
      "        [3.6021, 3.6848, 3.8970, 3.7768, 3.7579],\n",
      "        [3.4621, 3.4637, 3.7766, 3.4583, 3.6041],\n",
      "        [3.6877, 3.8898, 3.9876, 3.8793, 3.6986],\n",
      "        [3.5450, 4.0014, 3.8598, 3.9392, 3.7655],\n",
      "        [3.5590, 3.6737, 3.9089, 3.8710, 3.8232],\n",
      "        [3.8443, 3.7329, 3.8928, 4.1943, 3.9210],\n",
      "        [3.3353, 3.5322, 3.6008, 3.4839, 3.4492],\n",
      "        [3.5394, 3.6038, 3.8074, 3.7148, 3.5876],\n",
      "        [3.3578, 3.5605, 3.6240, 3.5038, 3.4663],\n",
      "        [3.8057, 4.0508, 3.9524, 3.9972, 4.0337],\n",
      "        [3.5531, 3.6252, 3.8194, 3.7212, 3.6107],\n",
      "        [3.4878, 3.7589, 3.8766, 3.7036, 3.6913],\n",
      "        [3.7772, 3.8916, 4.0442, 3.9874, 3.9395],\n",
      "        [3.7366, 3.8921, 3.9773, 3.8513, 3.6114],\n",
      "        [3.7050, 3.9452, 3.9102, 3.9009, 3.7551],\n",
      "        [3.7205, 3.8461, 3.9255, 3.8762, 3.8475],\n",
      "        [3.5493, 3.6255, 3.8148, 3.7195, 3.6086],\n",
      "        [3.5310, 3.6828, 3.9032, 3.8410, 3.7833],\n",
      "        [3.6048, 3.9791, 3.8414, 3.8075, 3.8457],\n",
      "        [3.3584, 3.5571, 3.5597, 3.5341, 3.4138],\n",
      "        [3.5628, 3.5536, 3.7406, 3.6934, 3.6950],\n",
      "        [3.7548, 3.5930, 3.7212, 3.7285, 3.7488],\n",
      "        [3.5882, 3.6319, 3.8908, 3.8048, 3.7435],\n",
      "        [3.4504, 3.6428, 3.6614, 3.6317, 3.5355],\n",
      "        [3.6321, 3.9769, 3.9366, 3.8750, 3.8410],\n",
      "        [3.3538, 3.5895, 3.6783, 3.6023, 3.5132]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4971, 3.6224, 3.7474, 3.6364, 3.5754],\n",
      "        [3.3700, 3.4885, 3.6625, 3.5490, 3.4113],\n",
      "        [3.9334, 4.0964, 3.9003, 3.9119, 3.7564],\n",
      "        [3.4995, 3.9544, 3.9590, 3.8393, 3.8402],\n",
      "        [3.7987, 3.9466, 4.0736, 3.9732, 4.0136],\n",
      "        [3.5255, 3.7371, 3.7779, 3.6124, 3.5439],\n",
      "        [3.4491, 3.5989, 3.6704, 3.6488, 3.5037],\n",
      "        [3.6882, 3.9024, 3.8800, 3.9919, 3.7858],\n",
      "        [3.5018, 3.7428, 3.9059, 3.8454, 3.5543],\n",
      "        [3.4323, 3.6357, 3.6608, 3.6031, 3.5320],\n",
      "        [3.3731, 3.5828, 3.6403, 3.5327, 3.4867],\n",
      "        [3.9200, 3.9511, 4.1218, 4.1637, 3.8923],\n",
      "        [3.4383, 3.6179, 3.7970, 3.7329, 3.5873],\n",
      "        [3.5338, 3.6827, 3.7151, 3.7114, 3.6117],\n",
      "        [3.5964, 3.8400, 3.8268, 3.7460, 3.6611],\n",
      "        [3.3899, 3.5922, 3.6412, 3.5488, 3.4973],\n",
      "        [3.5291, 3.7624, 3.9219, 3.8145, 3.5935],\n",
      "        [3.4440, 3.7082, 3.9675, 3.7032, 3.7454],\n",
      "        [3.9011, 4.1032, 4.0175, 4.0858, 4.0742],\n",
      "        [3.5408, 3.5631, 3.6931, 3.7854, 3.5016],\n",
      "        [3.5739, 3.6102, 3.7372, 3.6689, 3.6545],\n",
      "        [3.9310, 3.7822, 4.0303, 4.4175, 4.1518],\n",
      "        [3.5773, 3.6323, 3.8713, 3.7438, 3.6605],\n",
      "        [3.7302, 3.9605, 3.9391, 3.8876, 3.8041],\n",
      "        [3.9000, 3.9624, 3.9615, 4.0212, 3.9604],\n",
      "        [3.3936, 3.6340, 3.7397, 3.6014, 3.5008],\n",
      "        [3.3922, 3.6136, 3.7323, 3.5993, 3.4934],\n",
      "        [3.9834, 3.8437, 4.1327, 4.4684, 4.2440],\n",
      "        [3.6812, 3.8543, 3.8937, 3.8786, 3.7814],\n",
      "        [3.6299, 3.9546, 3.9181, 3.8642, 3.8351],\n",
      "        [3.6011, 3.7578, 3.8756, 3.8532, 3.6955],\n",
      "        [3.7794, 3.9558, 3.9415, 3.9158, 3.8744],\n",
      "        [3.4825, 4.0209, 3.8389, 3.7108, 3.7717],\n",
      "        [3.5659, 3.5624, 3.7719, 3.6239, 3.5246],\n",
      "        [3.4311, 3.6236, 3.7801, 3.6499, 3.5184],\n",
      "        [3.7658, 3.8752, 4.0410, 3.9669, 3.9268],\n",
      "        [3.4309, 3.4936, 3.6775, 3.6345, 3.4573],\n",
      "        [3.4106, 3.5497, 3.6726, 3.5877, 3.4910],\n",
      "        [3.6415, 3.6638, 3.8481, 3.6949, 3.5847],\n",
      "        [3.7191, 3.8987, 3.9862, 3.9180, 3.7563],\n",
      "        [3.6372, 3.7390, 3.9204, 3.8079, 3.6789],\n",
      "        [3.5320, 3.6975, 3.7943, 3.7058, 3.6404],\n",
      "        [3.4255, 3.5673, 3.7369, 3.6308, 3.4727],\n",
      "        [3.6881, 3.7215, 3.8021, 3.9451, 3.7475],\n",
      "        [3.7001, 3.8958, 3.8903, 3.9055, 3.7400],\n",
      "        [3.7483, 3.8948, 4.0642, 4.0063, 3.9384],\n",
      "        [3.4228, 3.5425, 3.7058, 3.6143, 3.4834],\n",
      "        [3.3963, 3.6218, 3.6703, 3.6212, 3.4918],\n",
      "        [3.5520, 3.7330, 3.6974, 3.7734, 3.6122],\n",
      "        [3.5625, 3.7435, 3.7066, 3.7866, 3.6195],\n",
      "        [3.4981, 3.6917, 3.8264, 3.6199, 3.6191],\n",
      "        [3.5826, 3.6250, 3.7927, 3.7087, 3.6656],\n",
      "        [3.5205, 3.6935, 3.8327, 3.7408, 3.7363],\n",
      "        [3.5883, 3.6333, 3.8372, 3.7337, 3.6616],\n",
      "        [3.7883, 4.0118, 4.0895, 3.9222, 3.6430],\n",
      "        [3.3979, 3.6976, 3.7668, 3.6070, 3.5349],\n",
      "        [3.5356, 4.0501, 4.0314, 3.7681, 3.6407],\n",
      "        [3.7712, 3.8799, 4.1418, 3.8677, 3.6049],\n",
      "        [3.4616, 3.6604, 3.8260, 3.6843, 3.6127],\n",
      "        [3.5252, 3.6262, 3.9113, 3.5894, 3.7362],\n",
      "        [3.7239, 3.8811, 3.9870, 3.9228, 3.7248],\n",
      "        [3.7152, 3.9180, 3.9619, 3.9321, 3.7474],\n",
      "        [3.4820, 3.6371, 3.6892, 3.6859, 3.5657],\n",
      "        [3.5495, 3.6260, 3.8773, 3.7639, 3.6431]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6941, 3.9830, 3.9573, 3.8914, 3.7684],\n",
      "        [3.4471, 3.6242, 3.6582, 3.6117, 3.5228],\n",
      "        [3.4351, 3.5331, 3.7074, 3.6253, 3.4827],\n",
      "        [3.5150, 3.8971, 3.8988, 3.7287, 3.5087],\n",
      "        [3.4026, 3.6321, 3.7453, 3.6154, 3.5192],\n",
      "        [3.5666, 3.7439, 3.8322, 3.7185, 3.7424],\n",
      "        [3.4067, 3.5814, 3.6016, 3.5855, 3.4429],\n",
      "        [3.7601, 3.6161, 3.8924, 4.0348, 3.9294],\n",
      "        [3.4781, 3.8915, 3.8713, 3.6801, 3.4993],\n",
      "        [3.7468, 3.9128, 3.8773, 3.9373, 3.8219],\n",
      "        [3.3157, 3.5563, 3.6850, 3.5554, 3.4945],\n",
      "        [4.0343, 4.2687, 3.9303, 3.9653, 3.7478],\n",
      "        [3.4408, 3.6519, 3.7927, 3.6593, 3.5327],\n",
      "        [3.4777, 3.6911, 3.8711, 3.7695, 3.7239],\n",
      "        [3.6495, 3.7577, 3.8599, 3.9260, 3.6660],\n",
      "        [3.9010, 4.0829, 3.9942, 4.0768, 4.0558],\n",
      "        [3.4830, 3.6535, 3.6669, 3.6617, 3.5412],\n",
      "        [3.5051, 3.9561, 3.7883, 3.6966, 3.7621],\n",
      "        [3.4199, 3.6182, 3.6600, 3.5799, 3.5246],\n",
      "        [3.8350, 3.9016, 4.1257, 4.1597, 3.7775],\n",
      "        [3.6852, 3.8918, 3.8637, 3.8159, 3.7220],\n",
      "        [3.6852, 3.8748, 3.8834, 3.8984, 3.7344],\n",
      "        [3.4577, 3.7081, 3.8234, 3.6292, 3.5814],\n",
      "        [3.5528, 3.6584, 3.8304, 3.7499, 3.6324],\n",
      "        [3.6243, 3.6182, 3.9480, 3.9411, 3.5659],\n",
      "        [3.4093, 3.6036, 3.6545, 3.5719, 3.5254],\n",
      "        [3.5500, 3.6697, 3.8351, 3.7589, 3.6316],\n",
      "        [3.5678, 3.6355, 3.8813, 3.7487, 3.6624],\n",
      "        [3.4538, 3.6938, 3.8691, 3.7421, 3.6924],\n",
      "        [3.5404, 3.6230, 3.8080, 3.7086, 3.5964],\n",
      "        [3.9830, 3.9986, 4.0482, 4.1310, 4.0074],\n",
      "        [3.6519, 3.8667, 4.0049, 3.9456, 3.7991],\n",
      "        [3.8673, 3.9406, 4.0478, 4.0197, 4.0640],\n",
      "        [3.4074, 3.6169, 3.6692, 3.5710, 3.5243],\n",
      "        [3.5441, 3.7122, 3.6910, 3.7524, 3.5916],\n",
      "        [3.4643, 3.6555, 3.6742, 3.6419, 3.5512],\n",
      "        [3.7163, 3.7637, 3.8902, 3.7923, 3.5384],\n",
      "        [3.7832, 4.0868, 4.0217, 4.0454, 3.9478],\n",
      "        [3.4621, 3.7075, 3.8255, 3.6314, 3.5836],\n",
      "        [3.5578, 3.6983, 3.7390, 3.7872, 3.6206],\n",
      "        [3.4388, 3.5666, 3.6345, 3.6724, 3.4253],\n",
      "        [3.4047, 3.5645, 3.7154, 3.6025, 3.4835],\n",
      "        [4.0571, 4.1435, 4.2528, 4.4048, 4.0728],\n",
      "        [3.8673, 3.8064, 4.0184, 4.0192, 3.7892],\n",
      "        [3.6428, 3.9869, 3.9556, 3.8836, 3.8498],\n",
      "        [3.8446, 3.6042, 3.8854, 4.1568, 4.0216],\n",
      "        [3.4219, 3.5404, 3.7071, 3.6124, 3.4829],\n",
      "        [3.9854, 3.8672, 4.0605, 4.0783, 3.9691],\n",
      "        [3.4815, 4.0188, 3.8402, 3.7089, 3.7710],\n",
      "        [3.5206, 3.6164, 3.9048, 3.5775, 3.7382],\n",
      "        [3.7491, 3.6781, 3.8391, 4.1078, 3.8268],\n",
      "        [3.6647, 3.6786, 3.8485, 3.6942, 3.4873],\n",
      "        [3.7073, 3.7211, 3.9360, 3.8823, 3.6870],\n",
      "        [3.6817, 3.9017, 3.9254, 3.9673, 3.7457],\n",
      "        [3.5439, 3.7341, 3.9792, 3.7990, 3.7627],\n",
      "        [3.4014, 3.6774, 3.7208, 3.6664, 3.5066],\n",
      "        [3.5369, 3.8423, 3.8776, 3.6445, 3.7021],\n",
      "        [3.3567, 3.5532, 3.5626, 3.5304, 3.4121],\n",
      "        [3.9191, 3.9490, 4.1238, 4.1618, 3.8917],\n",
      "        [3.7231, 3.8790, 3.9884, 3.9209, 3.7242],\n",
      "        [3.4747, 3.6256, 3.7948, 3.7468, 3.5745],\n",
      "        [3.7473, 3.8927, 4.0660, 4.0045, 3.9377],\n",
      "        [3.7112, 3.8561, 3.8829, 3.7382, 3.6999],\n",
      "        [3.7737, 3.9677, 4.0746, 3.9873, 3.9659]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5650, 3.5494, 3.7592, 3.7026, 3.6986],\n",
      "        [3.3950, 3.6743, 3.7592, 3.6082, 3.5230],\n",
      "        [3.7015, 3.7368, 3.8879, 3.7724, 3.5594],\n",
      "        [3.4834, 3.6592, 3.6713, 3.6579, 3.5610],\n",
      "        [3.9741, 3.9760, 3.9784, 4.1040, 4.0209],\n",
      "        [3.7113, 3.7249, 3.8205, 3.9962, 3.7865],\n",
      "        [3.6932, 3.9817, 3.9588, 3.8893, 3.7674],\n",
      "        [3.5659, 3.7422, 3.8328, 3.7163, 3.7414],\n",
      "        [3.3514, 3.7177, 3.6941, 3.4541, 3.5354],\n",
      "        [3.5395, 3.7660, 3.8543, 3.7450, 3.6520],\n",
      "        [3.8930, 3.7777, 4.0103, 4.0523, 3.8009],\n",
      "        [3.6635, 3.6785, 3.8488, 3.6938, 3.4869],\n",
      "        [3.3815, 3.4992, 3.6457, 3.5410, 3.4585],\n",
      "        [3.6863, 3.8987, 3.8823, 3.9876, 3.7845],\n",
      "        [3.6042, 3.6169, 3.8435, 3.7512, 3.6333],\n",
      "        [3.9311, 3.9522, 4.1168, 4.1642, 3.9008],\n",
      "        [3.5574, 4.0057, 3.8713, 3.9311, 3.7829],\n",
      "        [3.3940, 3.5135, 3.6873, 3.5766, 3.4509],\n",
      "        [3.8383, 3.6010, 3.8984, 4.1412, 3.9984],\n",
      "        [3.4046, 3.5833, 3.7300, 3.6018, 3.4920],\n",
      "        [3.6863, 3.8987, 3.8823, 3.9876, 3.7845],\n",
      "        [3.6443, 3.6911, 3.9018, 3.8003, 3.7843],\n",
      "        [3.4590, 3.6411, 3.6699, 3.6332, 3.5515],\n",
      "        [3.5740, 3.8138, 3.7875, 3.7407, 3.6178],\n",
      "        [3.9871, 4.2143, 3.8830, 3.8963, 3.7490],\n",
      "        [3.6451, 3.8692, 4.0350, 3.9563, 3.7722],\n",
      "        [3.7000, 3.9757, 4.0088, 3.9314, 3.8815],\n",
      "        [3.5632, 3.8043, 3.9163, 3.7883, 3.5991],\n",
      "        [3.4806, 3.5626, 3.8203, 3.6839, 3.5621],\n",
      "        [3.7315, 3.8540, 4.0141, 3.9705, 3.9070],\n",
      "        [3.4991, 3.5700, 3.7725, 3.6473, 3.5402],\n",
      "        [3.5720, 3.8213, 3.7882, 3.7389, 3.6215],\n",
      "        [3.7248, 3.6766, 3.8242, 4.0612, 3.7998],\n",
      "        [3.5641, 3.5588, 3.7739, 3.6198, 3.5232],\n",
      "        [3.4956, 3.5987, 3.8105, 3.7083, 3.5877],\n",
      "        [3.8123, 4.0073, 3.8984, 3.7885, 3.6918],\n",
      "        [3.7368, 3.7453, 3.9570, 3.9549, 3.6517],\n",
      "        [3.7879, 3.6527, 3.8493, 3.8122, 3.7286],\n",
      "        [4.0482, 3.8296, 4.1029, 4.4521, 4.2542],\n",
      "        [3.4204, 3.5885, 3.7177, 3.5996, 3.5165],\n",
      "        [3.7496, 3.7088, 3.8605, 3.7333, 3.5795],\n",
      "        [3.4005, 3.6758, 3.7215, 3.6643, 3.5058],\n",
      "        [3.5375, 3.6956, 3.7636, 3.6895, 3.6202],\n",
      "        [3.9921, 3.9175, 4.1375, 4.1876, 3.9322],\n",
      "        [3.6820, 3.8709, 3.8765, 3.8962, 3.7249],\n",
      "        [3.7782, 3.8727, 4.0449, 4.0460, 3.7358],\n",
      "        [3.5431, 3.7228, 3.7044, 3.7548, 3.6103],\n",
      "        [3.4357, 3.5163, 3.6984, 3.6271, 3.4723],\n",
      "        [3.5080, 3.5976, 3.7463, 3.7360, 3.5330],\n",
      "        [3.5275, 3.6153, 3.8098, 3.7153, 3.5965],\n",
      "        [3.4432, 3.5941, 3.6490, 3.6749, 3.5071],\n",
      "        [3.9117, 3.8583, 3.9484, 3.9666, 3.8853],\n",
      "        [3.9182, 3.9477, 4.1252, 4.1597, 3.8907],\n",
      "        [3.7297, 3.7224, 3.8650, 4.0769, 3.8430],\n",
      "        [3.9936, 4.1328, 4.0682, 4.1740, 4.1501],\n",
      "        [3.6556, 3.7744, 3.8726, 3.9433, 3.6719],\n",
      "        [3.4432, 3.6659, 3.7008, 3.7210, 3.5217],\n",
      "        [3.4211, 3.5636, 3.7228, 3.6170, 3.5008],\n",
      "        [3.7822, 4.0854, 4.0227, 4.0432, 3.9468],\n",
      "        [3.4142, 3.5483, 3.7107, 3.6073, 3.4847],\n",
      "        [3.4383, 3.5994, 3.7651, 3.6449, 3.4995],\n",
      "        [3.4166, 3.5530, 3.7154, 3.6066, 3.4859],\n",
      "        [3.5641, 3.5588, 3.7739, 3.6198, 3.5232],\n",
      "        [3.3896, 3.6008, 3.6632, 3.5466, 3.5112]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.9067, 3.7321, 3.9288, 4.3037, 4.0006],\n",
      "        [4.0155, 4.1114, 4.1654, 4.3116, 4.0388],\n",
      "        [3.4285, 3.6224, 3.6602, 3.6015, 3.5232],\n",
      "        [3.6927, 3.7202, 3.8815, 3.7614, 3.5574],\n",
      "        [3.7262, 3.9558, 3.8737, 3.7181, 3.6524],\n",
      "        [3.5201, 3.6958, 3.6863, 3.7275, 3.5779],\n",
      "        [3.4007, 3.6296, 3.7464, 3.6110, 3.5172],\n",
      "        [3.5428, 3.7222, 3.6994, 3.7558, 3.6017],\n",
      "        [3.6339, 3.7524, 3.7761, 3.8067, 3.6857],\n",
      "        [3.5083, 3.6055, 3.8280, 3.7271, 3.6763],\n",
      "        [3.4580, 3.6402, 3.6703, 3.6310, 3.5504],\n",
      "        [3.9238, 3.9556, 4.1370, 4.1721, 3.8997],\n",
      "        [3.5839, 3.8337, 3.8085, 3.7470, 3.6341],\n",
      "        [3.7448, 3.9100, 3.8785, 3.9329, 3.8197],\n",
      "        [3.5910, 3.8766, 3.9445, 3.8886, 3.6262],\n",
      "        [3.4064, 3.5952, 3.6482, 3.5629, 3.4975],\n",
      "        [3.4051, 3.6838, 3.7685, 3.6158, 3.5414],\n",
      "        [4.0551, 4.1414, 4.2556, 4.4003, 4.0705],\n",
      "        [3.3575, 3.4380, 3.6554, 3.6125, 3.4389],\n",
      "        [3.5193, 3.7100, 3.8605, 3.7994, 3.6171],\n",
      "        [4.0250, 3.9646, 4.1764, 4.2203, 4.0013],\n",
      "        [3.4432, 3.6198, 3.6401, 3.6380, 3.4748],\n",
      "        [3.4338, 3.6280, 3.6655, 3.5961, 3.5305],\n",
      "        [3.4444, 3.5385, 3.7131, 3.6428, 3.5054],\n",
      "        [3.3481, 3.5502, 3.6229, 3.4874, 3.4653],\n",
      "        [3.6833, 3.8648, 4.0030, 3.8858, 3.7349],\n",
      "        [3.8060, 3.8423, 3.9930, 3.9383, 3.9035],\n",
      "        [3.6346, 3.6172, 4.0449, 3.8220, 3.7388],\n",
      "        [3.8186, 3.6044, 3.9026, 4.1144, 3.9808],\n",
      "        [3.7073, 3.8572, 3.8882, 3.7556, 3.6985],\n",
      "        [3.9457, 3.8560, 4.0760, 4.1186, 3.8761],\n",
      "        [3.4924, 3.7305, 3.9162, 3.8032, 3.5510],\n",
      "        [3.5385, 3.6205, 3.8093, 3.7042, 3.5944],\n",
      "        [3.4669, 3.6592, 3.6832, 3.6434, 3.5519],\n",
      "        [3.7139, 3.8068, 3.9946, 3.8243, 3.6019],\n",
      "        [3.7735, 3.8299, 3.9659, 3.8659, 3.8622],\n",
      "        [3.5345, 3.7047, 3.6918, 3.7392, 3.5893],\n",
      "        [3.5846, 3.6252, 3.8951, 3.7965, 3.7399],\n",
      "        [3.4845, 3.6526, 3.7095, 3.6637, 3.5863],\n",
      "        [3.6813, 3.7410, 3.8755, 3.8301, 3.7686],\n",
      "        [3.7473, 4.0406, 3.9958, 4.0244, 3.8623],\n",
      "        [3.6044, 3.7639, 3.8897, 3.8687, 3.6923],\n",
      "        [3.6699, 3.8783, 3.8646, 3.8210, 3.7149],\n",
      "        [3.3959, 3.5561, 3.7118, 3.5938, 3.4761],\n",
      "        [3.6510, 3.8368, 3.9168, 3.8275, 3.8026],\n",
      "        [3.4985, 3.9297, 3.7816, 3.6739, 3.7408],\n",
      "        [3.7349, 3.8810, 3.8821, 3.8519, 3.8164],\n",
      "        [3.4483, 3.5968, 3.7833, 3.6986, 3.5754],\n",
      "        [3.9119, 3.7923, 4.0435, 4.3966, 4.1626],\n",
      "        [3.8475, 3.9019, 4.1538, 4.1641, 3.7596],\n",
      "        [3.6454, 3.6732, 3.8634, 3.6858, 3.6068],\n",
      "        [3.3521, 3.5447, 3.5604, 3.5178, 3.4086],\n",
      "        [3.3992, 3.6811, 3.7671, 3.6133, 3.5369],\n",
      "        [3.5399, 3.6017, 3.8129, 3.7023, 3.5897],\n",
      "        [3.4556, 3.6105, 3.6552, 3.6579, 3.4802],\n",
      "        [3.5329, 3.6795, 3.7277, 3.7036, 3.6151],\n",
      "        [3.9118, 3.7620, 3.9407, 4.3028, 4.0198],\n",
      "        [3.6821, 3.8345, 3.8621, 3.8139, 3.7695],\n",
      "        [3.5289, 3.6373, 3.8154, 3.7225, 3.5959],\n",
      "        [3.9994, 3.9987, 4.1737, 4.2741, 4.0002],\n",
      "        [3.7968, 4.0105, 4.0658, 4.0084, 3.8942],\n",
      "        [3.3661, 3.5695, 3.6339, 3.5183, 3.4767],\n",
      "        [3.4596, 3.6214, 3.6687, 3.6881, 3.4840],\n",
      "        [3.5396, 3.6014, 3.8164, 3.7054, 3.5880]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3071, 3.5407, 3.6815, 3.5424, 3.4748],\n",
      "        [3.5332, 3.7106, 3.6966, 3.7435, 3.5970],\n",
      "        [3.3920, 3.5112, 3.6877, 3.5735, 3.4496],\n",
      "        [3.9339, 4.0061, 4.1221, 4.2216, 3.8114],\n",
      "        [3.7158, 3.8380, 3.9292, 3.8672, 3.8431],\n",
      "        [4.0495, 4.0343, 4.1810, 4.2856, 4.0684],\n",
      "        [3.6260, 3.9488, 3.9209, 3.8571, 3.8320],\n",
      "        [3.6136, 3.9183, 3.8406, 3.6440, 3.7120],\n",
      "        [3.6495, 3.7159, 3.8435, 3.7911, 3.7439],\n",
      "        [3.6629, 3.9673, 3.8554, 3.8518, 3.8892],\n",
      "        [3.7090, 3.8865, 3.9882, 3.9098, 3.7482],\n",
      "        [3.5162, 3.5736, 3.7793, 3.6454, 3.5407],\n",
      "        [3.7572, 3.6123, 3.8938, 4.0297, 3.9271],\n",
      "        [3.4793, 3.7116, 3.7133, 3.7709, 3.5411],\n",
      "        [3.5121, 3.7013, 3.6921, 3.7111, 3.5855],\n",
      "        [3.4596, 3.5483, 3.7275, 3.6377, 3.4867],\n",
      "        [3.5421, 3.5479, 3.7636, 3.6183, 3.5139],\n",
      "        [3.4496, 3.5200, 3.7047, 3.6532, 3.4906],\n",
      "        [3.6562, 3.6816, 3.8623, 3.7003, 3.5872],\n",
      "        [3.6013, 3.6125, 3.8368, 3.7582, 3.6214],\n",
      "        [3.7262, 3.9552, 3.9436, 3.8807, 3.8006],\n",
      "        [3.5483, 3.7272, 3.7003, 3.7661, 3.6096],\n",
      "        [3.6723, 3.9810, 3.8701, 3.8656, 3.9028],\n",
      "        [3.9141, 4.0267, 4.1689, 4.2215, 4.1824],\n",
      "        [3.9290, 3.9502, 4.1185, 4.1612, 3.8990],\n",
      "        [3.6726, 4.0265, 4.0232, 3.9007, 3.8524],\n",
      "        [3.4443, 3.6205, 3.6596, 3.6064, 3.5206],\n",
      "        [3.7635, 3.9944, 3.9044, 3.8427, 3.7411],\n",
      "        [3.4403, 3.8851, 3.7457, 3.6460, 3.6863],\n",
      "        [3.7844, 3.7803, 3.9679, 3.9436, 3.7273],\n",
      "        [3.7573, 3.5428, 3.7226, 3.7478, 3.6909],\n",
      "        [3.4803, 3.6040, 3.7856, 3.6771, 3.5816],\n",
      "        [3.8652, 3.7379, 3.9118, 4.2260, 3.9503],\n",
      "        [3.4421, 3.5065, 3.6926, 3.6362, 3.4713],\n",
      "        [3.7050, 3.7504, 3.8988, 3.7611, 3.8123],\n",
      "        [3.7863, 3.9572, 3.9547, 3.9100, 3.8749],\n",
      "        [3.6116, 3.6791, 3.9210, 3.8203, 3.6272],\n",
      "        [3.7298, 3.7034, 3.8575, 3.7148, 3.5639],\n",
      "        [3.4188, 3.6744, 3.7665, 3.6180, 3.5494],\n",
      "        [3.6915, 3.8840, 3.8873, 3.8977, 3.7253],\n",
      "        [3.4979, 3.6155, 3.7414, 3.6272, 3.5759],\n",
      "        [3.7093, 3.7226, 3.8211, 3.9931, 3.7850],\n",
      "        [3.4191, 3.6004, 3.7380, 3.6087, 3.5178],\n",
      "        [3.5525, 3.8033, 3.9428, 3.7913, 3.5749],\n",
      "        [3.5926, 4.0130, 3.9227, 3.9417, 3.8204],\n",
      "        [3.4636, 3.5424, 3.8075, 3.6609, 3.5530],\n",
      "        [3.6718, 3.7822, 3.9726, 3.8004, 3.5683],\n",
      "        [3.6085, 3.5939, 3.8099, 3.7472, 3.5671],\n",
      "        [3.6061, 3.6679, 3.9045, 3.7862, 3.6829],\n",
      "        [3.4280, 3.5190, 3.7003, 3.6169, 3.4752],\n",
      "        [3.6443, 3.6718, 3.8634, 3.6850, 3.6065],\n",
      "        [3.4527, 3.5284, 3.7954, 3.6459, 3.5426],\n",
      "        [3.6319, 3.7431, 3.7543, 3.7875, 3.6566],\n",
      "        [3.4054, 3.5938, 3.6483, 3.5620, 3.4972],\n",
      "        [3.6381, 3.7369, 3.7808, 3.8248, 3.6847],\n",
      "        [3.5170, 3.6905, 3.6954, 3.7098, 3.5898],\n",
      "        [3.7617, 3.5545, 3.7348, 3.7331, 3.7256],\n",
      "        [3.5552, 4.0040, 3.8722, 3.9279, 3.7812],\n",
      "        [3.4132, 3.9415, 3.9332, 3.7726, 3.6408],\n",
      "        [3.5356, 3.7123, 3.6982, 3.7515, 3.5967],\n",
      "        [3.5304, 3.5521, 3.7657, 3.6228, 3.5180],\n",
      "        [3.5511, 3.5372, 3.7546, 3.5961, 3.5027],\n",
      "        [3.4023, 3.6448, 3.7215, 3.6635, 3.4933],\n",
      "        [3.6830, 3.7412, 3.8555, 3.7532, 3.4773]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3368, 3.4563, 3.6181, 3.4850, 3.4121],\n",
      "        [3.3983, 3.5993, 3.6546, 3.5516, 3.5112],\n",
      "        [3.6905, 3.8370, 3.8675, 3.7165, 3.6832],\n",
      "        [3.4444, 3.5407, 3.6098, 3.6657, 3.4464],\n",
      "        [3.4272, 3.7213, 3.7861, 3.6251, 3.5765],\n",
      "        [3.5283, 3.6094, 3.8000, 3.6999, 3.5875],\n",
      "        [3.5035, 3.6838, 3.6912, 3.6927, 3.5734],\n",
      "        [3.7097, 3.9648, 3.9472, 3.8818, 3.7787],\n",
      "        [3.4101, 3.7081, 3.7789, 3.6250, 3.5582],\n",
      "        [3.4321, 3.4836, 3.6777, 3.6244, 3.4539],\n",
      "        [3.5268, 3.6352, 3.8155, 3.7204, 3.5948],\n",
      "        [3.8816, 3.7790, 4.0351, 4.3728, 4.1556],\n",
      "        [3.5666, 3.8751, 3.9020, 3.7582, 3.5267],\n",
      "        [4.1572, 4.3969, 4.0510, 4.0717, 3.9000],\n",
      "        [3.4642, 3.9193, 3.7593, 3.6530, 3.7154],\n",
      "        [3.4735, 3.7353, 3.6819, 3.7304, 3.5204],\n",
      "        [3.8461, 3.8869, 4.0348, 4.0534, 3.8247],\n",
      "        [4.0516, 4.0407, 4.2394, 4.3061, 4.0530],\n",
      "        [3.5074, 3.5389, 3.7877, 3.6636, 3.5530],\n",
      "        [3.6453, 3.7531, 3.8614, 3.9194, 3.6630],\n",
      "        [3.3404, 3.5395, 3.6153, 3.4809, 3.4529],\n",
      "        [3.5341, 3.7142, 3.7031, 3.7378, 3.6020],\n",
      "        [3.3890, 3.7178, 3.7727, 3.6727, 3.7042],\n",
      "        [3.7414, 3.8786, 4.0032, 4.0180, 3.7261],\n",
      "        [3.5307, 3.8369, 3.8710, 3.6554, 3.6794],\n",
      "        [3.5539, 3.7290, 3.7819, 3.7939, 3.6640],\n",
      "        [3.9189, 3.9497, 4.1367, 4.1687, 3.8916],\n",
      "        [3.5041, 3.6077, 3.7865, 3.5769, 3.6441],\n",
      "        [3.6830, 3.8956, 3.8831, 3.9831, 3.7824],\n",
      "        [3.4029, 3.6817, 3.7684, 3.6136, 3.5405],\n",
      "        [3.4648, 3.6469, 3.6760, 3.6244, 3.5603],\n",
      "        [3.7047, 3.7557, 3.8765, 3.7757, 3.5014],\n",
      "        [3.4896, 3.6375, 3.7131, 3.7268, 3.5716],\n",
      "        [3.9579, 4.0126, 4.1785, 4.2403, 3.7791],\n",
      "        [3.5065, 3.6737, 3.6744, 3.6970, 3.5553],\n",
      "        [3.6401, 3.8386, 3.9233, 3.8254, 3.8152],\n",
      "        [3.5026, 3.6769, 3.6826, 3.6965, 3.5746],\n",
      "        [3.4363, 3.5618, 3.6384, 3.6682, 3.4248],\n",
      "        [3.5149, 3.6943, 3.6943, 3.7109, 3.5851],\n",
      "        [3.9596, 3.8233, 4.0712, 4.4304, 4.1634],\n",
      "        [3.7498, 3.5353, 3.7206, 3.7405, 3.6991],\n",
      "        [3.9204, 3.9373, 3.8991, 4.0474, 4.0225],\n",
      "        [3.4314, 3.5665, 3.7399, 3.6286, 3.4737],\n",
      "        [3.5964, 3.5927, 3.9360, 3.9156, 3.5388],\n",
      "        [3.8210, 3.8880, 4.0969, 4.0828, 3.7615],\n",
      "        [3.4907, 4.0438, 4.0491, 3.8480, 3.6655],\n",
      "        [3.5259, 3.6260, 3.8102, 3.7133, 3.5905],\n",
      "        [3.4719, 3.6972, 3.7468, 3.5606, 3.5039],\n",
      "        [3.4489, 3.6186, 3.6731, 3.6689, 3.5057],\n",
      "        [3.5837, 3.6842, 3.8428, 3.6502, 3.4494],\n",
      "        [3.5718, 3.9975, 4.0047, 3.8035, 3.6086],\n",
      "        [3.4006, 3.5388, 3.7071, 3.5956, 3.4730],\n",
      "        [3.6055, 3.6101, 4.0569, 3.8022, 3.7172],\n",
      "        [3.5630, 3.7390, 3.8329, 3.7119, 3.7393],\n",
      "        [3.9313, 3.7936, 4.0418, 4.0457, 3.8524],\n",
      "        [3.7051, 3.8318, 3.9707, 3.8056, 3.7285],\n",
      "        [3.4356, 3.6341, 3.8061, 3.6682, 3.5001],\n",
      "        [3.4181, 3.7540, 3.9441, 3.7214, 3.6587],\n",
      "        [3.5088, 3.8219, 3.8707, 3.6944, 3.7099],\n",
      "        [3.5515, 3.5368, 3.7522, 3.6030, 3.5029],\n",
      "        [3.5262, 3.6443, 3.8232, 3.7330, 3.6074],\n",
      "        [3.6542, 3.5273, 3.9694, 3.8098, 3.6620],\n",
      "        [3.4776, 3.4718, 3.6490, 3.6272, 3.4442],\n",
      "        [3.4801, 3.5115, 3.7002, 3.6597, 3.4627]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4547, 3.6376, 3.6701, 3.6275, 3.5508],\n",
      "        [3.5482, 3.7269, 3.7143, 3.7673, 3.6123],\n",
      "        [3.7372, 4.0707, 4.0764, 3.9586, 3.9033],\n",
      "        [3.7022, 3.9654, 3.9177, 3.8259, 3.7385],\n",
      "        [3.4284, 3.4994, 3.6885, 3.6281, 3.4631],\n",
      "        [3.7451, 3.7777, 3.9015, 3.9065, 3.8624],\n",
      "        [3.6230, 3.7170, 3.8482, 3.8545, 3.6589],\n",
      "        [3.5035, 3.6803, 3.6803, 3.7044, 3.5669],\n",
      "        [3.5576, 3.6369, 3.8904, 3.7491, 3.6632],\n",
      "        [3.4989, 3.7008, 3.9618, 3.7538, 3.7345],\n",
      "        [3.5626, 3.6300, 3.8820, 3.7409, 3.6608],\n",
      "        [3.7094, 3.8914, 3.9928, 3.8202, 3.6235],\n",
      "        [3.3853, 3.5915, 3.6504, 3.5466, 3.4992],\n",
      "        [3.9770, 3.8363, 4.1353, 4.4590, 4.2418],\n",
      "        [3.7796, 3.5742, 3.7309, 3.7211, 3.7519],\n",
      "        [3.3774, 3.7642, 3.8279, 3.6758, 3.5009],\n",
      "        [3.5168, 3.6932, 3.6862, 3.7240, 3.5783],\n",
      "        [3.4581, 3.6080, 3.7804, 3.7218, 3.5641],\n",
      "        [3.8376, 3.7238, 3.8971, 4.1834, 3.9178],\n",
      "        [3.6806, 3.8806, 3.9923, 3.8676, 3.6946],\n",
      "        [3.9305, 3.9491, 4.1100, 4.1558, 3.9108],\n",
      "        [4.0311, 4.2406, 4.3227, 4.2898, 4.3050],\n",
      "        [3.6717, 3.9648, 3.8777, 3.6880, 3.7317],\n",
      "        [3.5848, 3.6235, 3.8859, 3.8048, 3.6503],\n",
      "        [3.3685, 3.5802, 3.6534, 3.5177, 3.4959],\n",
      "        [3.5843, 3.9028, 4.0750, 3.9337, 3.7069],\n",
      "        [3.7604, 3.9142, 4.0602, 3.9832, 3.9276],\n",
      "        [3.5748, 3.6138, 3.8673, 3.7412, 3.6137],\n",
      "        [3.4497, 3.6380, 3.6734, 3.6104, 3.5360],\n",
      "        [3.9538, 4.0375, 4.1568, 4.2233, 3.8745],\n",
      "        [3.5655, 3.6623, 3.9265, 3.7871, 3.6787],\n",
      "        [3.5678, 3.8985, 3.7654, 3.7527, 3.6267],\n",
      "        [3.5223, 3.6138, 3.7997, 3.7001, 3.5878],\n",
      "        [3.5188, 3.6893, 3.6874, 3.7099, 3.5885],\n",
      "        [3.5222, 3.6069, 3.8306, 3.7296, 3.6743],\n",
      "        [3.6900, 3.7512, 4.0077, 3.8018, 3.4717],\n",
      "        [3.4186, 3.5971, 3.7576, 3.6267, 3.4886],\n",
      "        [3.8356, 3.8632, 3.8479, 3.9338, 3.8495],\n",
      "        [3.4262, 3.5217, 3.6994, 3.6181, 3.4778],\n",
      "        [3.7434, 3.7768, 4.0384, 4.0133, 3.6432],\n",
      "        [3.8433, 3.8917, 4.0414, 4.0603, 3.8228],\n",
      "        [3.5044, 3.6179, 3.7320, 3.6192, 3.5914],\n",
      "        [3.4663, 3.6651, 3.6829, 3.6282, 3.5864],\n",
      "        [3.5875, 3.6280, 3.9017, 3.8110, 3.7444],\n",
      "        [3.3915, 3.5808, 3.6485, 3.5438, 3.4909],\n",
      "        [3.6799, 3.8927, 3.8812, 3.9802, 3.7803],\n",
      "        [3.6737, 4.0206, 4.0226, 3.9028, 3.8591],\n",
      "        [3.7417, 3.8883, 4.0688, 3.9968, 3.9356],\n",
      "        [3.3905, 3.6668, 3.7530, 3.5928, 3.5161],\n",
      "        [3.5596, 3.5482, 3.7826, 3.7095, 3.6951],\n",
      "        [3.3847, 3.5520, 3.6772, 3.6254, 3.4686],\n",
      "        [3.7549, 3.9582, 4.0559, 3.8716, 3.5626],\n",
      "        [3.6987, 3.8856, 3.8892, 3.8385, 3.7127],\n",
      "        [3.8395, 3.5992, 3.8864, 4.1498, 4.0202],\n",
      "        [3.7411, 3.8119, 4.0110, 3.8975, 3.6130],\n",
      "        [3.2733, 3.5073, 3.6783, 3.5026, 3.4761],\n",
      "        [3.4633, 3.6021, 3.7868, 3.7120, 3.5667],\n",
      "        [3.5500, 3.6096, 3.8307, 3.7070, 3.6034],\n",
      "        [3.5355, 3.5137, 3.6938, 3.6301, 3.6668],\n",
      "        [3.6971, 3.7754, 3.7451, 3.8679, 3.7936],\n",
      "        [3.6627, 3.6810, 3.8722, 3.7918, 3.6367],\n",
      "        [3.8198, 3.8875, 4.0967, 4.0814, 3.7629],\n",
      "        [3.6819, 3.7494, 3.9010, 3.7880, 3.7751],\n",
      "        [3.5202, 3.6925, 3.6867, 3.7285, 3.5875]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5284, 3.6772, 3.7936, 3.7119, 3.6661],\n",
      "        [3.9285, 3.7923, 4.0418, 4.0437, 3.8545],\n",
      "        [3.5339, 3.9565, 3.8725, 3.7819, 3.9205],\n",
      "        [3.6970, 3.9795, 4.0122, 3.9361, 3.8813],\n",
      "        [3.7262, 3.7014, 3.8573, 3.7109, 3.5655],\n",
      "        [3.5450, 3.5761, 3.7050, 3.6285, 3.6267],\n",
      "        [3.4997, 3.6757, 3.6825, 3.6936, 3.5768],\n",
      "        [3.5892, 3.7130, 3.7965, 3.7000, 3.6419],\n",
      "        [3.4362, 3.8832, 3.7454, 3.6422, 3.6875],\n",
      "        [3.2734, 3.8037, 3.7955, 3.6957, 3.4739],\n",
      "        [3.6207, 3.6666, 3.8430, 3.6468, 3.4567],\n",
      "        [3.4436, 3.5446, 3.6072, 3.6681, 3.4399],\n",
      "        [3.4533, 3.9896, 3.8187, 3.6777, 3.7459],\n",
      "        [3.4528, 3.9020, 3.9289, 3.7805, 3.7928],\n",
      "        [3.7936, 4.0290, 4.1323, 3.9590, 3.6783],\n",
      "        [3.7476, 3.6018, 3.8831, 4.0231, 3.9284],\n",
      "        [3.9529, 4.0123, 4.0774, 4.1873, 3.9517],\n",
      "        [3.7151, 4.1839, 4.0880, 3.9750, 4.0282],\n",
      "        [3.5118, 3.6635, 3.7118, 3.6837, 3.5992],\n",
      "        [3.7521, 4.0477, 4.0193, 4.0437, 3.8694],\n",
      "        [3.9701, 4.0566, 4.1323, 4.2284, 3.9304],\n",
      "        [3.9439, 3.8954, 4.0324, 4.1200, 3.9172],\n",
      "        [3.5297, 3.6769, 3.8341, 3.6120, 3.6618],\n",
      "        [3.5753, 3.7582, 3.8496, 3.7241, 3.7653],\n",
      "        [3.4298, 3.5120, 3.6987, 3.6200, 3.4721],\n",
      "        [3.5894, 3.8603, 3.9296, 3.8621, 3.6401],\n",
      "        [3.5821, 3.8291, 3.8327, 3.7144, 3.6711],\n",
      "        [3.5602, 3.5563, 3.7872, 3.7133, 3.7025],\n",
      "        [3.5947, 3.6105, 3.8439, 3.7243, 3.6603],\n",
      "        [3.5076, 3.8922, 3.9018, 3.7192, 3.5071],\n",
      "        [3.5183, 3.7527, 3.8644, 3.8056, 3.6555],\n",
      "        [4.1006, 4.2700, 4.1012, 4.0402, 3.9008],\n",
      "        [3.6430, 3.7213, 3.8318, 3.7611, 3.6553],\n",
      "        [3.9523, 3.9641, 4.0484, 4.1136, 3.9678],\n",
      "        [3.6781, 3.8920, 3.8814, 3.9786, 3.7811],\n",
      "        [3.4939, 3.6136, 3.7411, 3.6231, 3.5775],\n",
      "        [3.4788, 3.7104, 3.7145, 3.7649, 3.5404],\n",
      "        [3.5993, 3.6678, 3.8326, 3.7832, 3.6432],\n",
      "        [3.6767, 3.7373, 3.8753, 3.8249, 3.7702],\n",
      "        [3.3898, 3.5801, 3.6487, 3.5423, 3.4917],\n",
      "        [3.6303, 3.7542, 3.9353, 3.8044, 3.6992],\n",
      "        [3.9628, 3.8935, 3.9988, 4.0388, 3.9652],\n",
      "        [3.6539, 3.7107, 3.8349, 3.7737, 3.6307],\n",
      "        [3.3924, 3.8100, 3.7960, 3.5329, 3.6655],\n",
      "        [3.4197, 3.6168, 3.6595, 3.5881, 3.5181],\n",
      "        [3.6807, 3.8928, 3.8838, 3.9752, 3.7835],\n",
      "        [3.7088, 3.8033, 3.9950, 3.8193, 3.6028],\n",
      "        [3.6086, 3.6119, 3.8384, 3.7248, 3.6671],\n",
      "        [4.0349, 4.1496, 3.8732, 3.9364, 3.7341],\n",
      "        [3.5399, 3.5245, 3.7402, 3.5785, 3.4934],\n",
      "        [3.9648, 3.9736, 4.0205, 4.1132, 4.0041],\n",
      "        [3.6799, 3.8943, 3.8830, 3.9800, 3.7846],\n",
      "        [3.7422, 3.6722, 3.8403, 4.0989, 3.8260],\n",
      "        [3.7723, 3.8683, 4.0456, 4.0390, 3.7359],\n",
      "        [3.4109, 3.6335, 3.7854, 3.6263, 3.5257],\n",
      "        [3.6441, 3.7122, 3.8289, 3.7655, 3.6333],\n",
      "        [3.5297, 3.6769, 3.8341, 3.6120, 3.6618],\n",
      "        [3.6882, 4.0102, 4.0454, 3.8989, 3.8436],\n",
      "        [3.6656, 3.6891, 3.8662, 3.6477, 3.4953],\n",
      "        [3.7444, 3.7044, 3.8609, 3.7265, 3.5799],\n",
      "        [3.4508, 3.6247, 3.7944, 3.6681, 3.5070],\n",
      "        [3.3844, 3.6277, 3.7111, 3.6355, 3.4836],\n",
      "        [3.4392, 3.4963, 3.6919, 3.6469, 3.4832],\n",
      "        [3.7492, 3.9262, 4.0607, 3.9508, 3.9315]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3048, 3.8214, 3.8221, 3.6659, 3.4413],\n",
      "        [3.5318, 3.6315, 3.8158, 3.7179, 3.6024],\n",
      "        [3.8966, 3.7997, 4.0430, 4.0735, 3.8306],\n",
      "        [3.7473, 3.8849, 3.9953, 3.8531, 3.6220],\n",
      "        [3.7023, 3.8497, 3.8843, 3.7278, 3.6996],\n",
      "        [3.6215, 3.6883, 3.9387, 3.8112, 3.7040],\n",
      "        [3.5653, 3.6008, 3.7383, 3.6560, 3.6535],\n",
      "        [3.4514, 3.4523, 3.7800, 3.4429, 3.6022],\n",
      "        [3.6630, 3.6824, 3.8621, 3.7853, 3.6309],\n",
      "        [3.6037, 3.8367, 3.8456, 3.7351, 3.7068],\n",
      "        [3.5141, 3.6848, 3.6889, 3.6915, 3.5933],\n",
      "        [3.4975, 3.9947, 3.8682, 3.7540, 3.8686],\n",
      "        [3.7830, 3.7903, 3.9918, 3.9577, 3.7404],\n",
      "        [3.5083, 3.9597, 3.8180, 3.7329, 3.8038],\n",
      "        [3.7042, 3.8656, 3.9651, 3.9767, 3.7230],\n",
      "        [3.4845, 3.6355, 3.7129, 3.7222, 3.5743],\n",
      "        [3.5240, 3.5489, 3.7650, 3.6172, 3.5199],\n",
      "        [3.6080, 3.6719, 3.9174, 3.7942, 3.6909],\n",
      "        [3.5536, 3.6706, 3.7538, 3.6382, 3.6138],\n",
      "        [3.5265, 3.7714, 3.8253, 3.7627, 3.6659],\n",
      "        [3.8240, 3.8902, 4.1399, 4.1465, 3.7526],\n",
      "        [3.3743, 3.5699, 3.6873, 3.6158, 3.4668],\n",
      "        [3.4200, 3.5199, 3.7010, 3.6099, 3.4759],\n",
      "        [3.7104, 3.9412, 3.9811, 3.8956, 3.7499],\n",
      "        [3.4698, 3.7447, 3.9969, 3.7215, 3.7753],\n",
      "        [3.3932, 3.5448, 3.6852, 3.6305, 3.4812],\n",
      "        [3.4807, 3.6295, 3.7422, 3.6690, 3.6270],\n",
      "        [3.5377, 3.8109, 3.9619, 3.7929, 3.5712],\n",
      "        [3.5735, 3.6156, 3.7941, 3.6958, 3.6647],\n",
      "        [3.5269, 3.6185, 3.8111, 3.7053, 3.5991],\n",
      "        [3.7195, 3.9390, 3.9738, 3.8879, 3.7370],\n",
      "        [3.4773, 4.0175, 3.8484, 3.6990, 3.7729],\n",
      "        [3.8291, 3.9105, 4.0861, 4.1028, 3.7479],\n",
      "        [3.4420, 3.5434, 3.7296, 3.6293, 3.4749],\n",
      "        [3.4214, 3.7850, 3.8618, 3.6238, 3.6858],\n",
      "        [3.4499, 3.6955, 3.8740, 3.6918, 3.6682],\n",
      "        [3.7886, 3.9572, 3.9576, 3.9324, 3.8938],\n",
      "        [3.4850, 3.5989, 3.8113, 3.6961, 3.5892],\n",
      "        [3.4503, 3.5990, 3.7788, 3.7075, 3.5643],\n",
      "        [3.5133, 3.5545, 3.8064, 3.6751, 3.5655],\n",
      "        [3.5320, 3.5119, 3.6936, 3.6270, 3.6680],\n",
      "        [3.4061, 3.5430, 3.7107, 3.5984, 3.4851],\n",
      "        [3.6981, 3.9638, 3.9182, 3.8226, 3.7399],\n",
      "        [3.8954, 3.7843, 4.0379, 4.3864, 4.1580],\n",
      "        [3.5352, 3.6598, 3.8404, 3.7448, 3.6259],\n",
      "        [3.4889, 3.6638, 3.6751, 3.6664, 3.5699],\n",
      "        [3.7769, 3.6909, 3.8715, 4.1153, 3.8700],\n",
      "        [3.5765, 3.8213, 3.8295, 3.7126, 3.6677],\n",
      "        [3.5991, 3.9555, 4.0374, 3.9124, 3.8516],\n",
      "        [3.6284, 3.8387, 3.8517, 3.7412, 3.7120],\n",
      "        [3.6973, 3.9678, 3.9506, 3.8772, 3.7723],\n",
      "        [3.5883, 3.6684, 3.8262, 3.7738, 3.6410],\n",
      "        [3.3789, 3.4764, 3.6754, 3.5899, 3.4715],\n",
      "        [3.7042, 3.7159, 3.9286, 3.9247, 3.6200],\n",
      "        [3.7257, 3.8958, 3.8665, 3.9159, 3.8291],\n",
      "        [3.4245, 3.5038, 3.6937, 3.6175, 3.4692],\n",
      "        [3.8359, 3.7303, 3.8858, 3.9026, 3.8511],\n",
      "        [3.9591, 3.8498, 4.0139, 4.0219, 3.9157],\n",
      "        [3.8214, 3.5986, 3.8853, 4.1353, 4.0028],\n",
      "        [3.5287, 3.5926, 3.8116, 3.7001, 3.5855],\n",
      "        [3.5644, 3.5949, 3.8604, 3.7573, 3.7214],\n",
      "        [3.7744, 3.8743, 4.0579, 3.9656, 3.9418],\n",
      "        [3.4998, 3.5924, 3.7464, 3.7271, 3.5335],\n",
      "        [3.3914, 3.6572, 3.7550, 3.6045, 3.5238]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8380, 3.8897, 4.0439, 4.0560, 3.8243],\n",
      "        [3.3852, 3.6461, 3.7481, 3.5865, 3.5089],\n",
      "        [3.5160, 3.9404, 3.9000, 3.8391, 3.8184],\n",
      "        [3.5512, 3.7347, 3.7116, 3.7715, 3.6192],\n",
      "        [3.5881, 3.9854, 4.0139, 3.8310, 3.6421],\n",
      "        [3.9083, 3.9428, 4.1312, 4.1490, 3.8917],\n",
      "        [3.7486, 3.7918, 3.9170, 3.9192, 3.8828],\n",
      "        [3.3888, 3.5770, 3.6038, 3.5676, 3.4457],\n",
      "        [4.0187, 4.1449, 3.8934, 3.9370, 3.7408],\n",
      "        [3.5372, 3.7834, 3.8348, 3.7706, 3.6768],\n",
      "        [3.4454, 3.9950, 3.9998, 3.7940, 3.6147],\n",
      "        [3.6537, 3.9602, 4.0120, 3.8739, 3.6944],\n",
      "        [3.7726, 3.9621, 3.9996, 3.7828, 3.8034],\n",
      "        [3.7113, 3.9565, 3.9478, 3.8762, 3.7916],\n",
      "        [3.4640, 3.7495, 3.9213, 3.8484, 3.5459],\n",
      "        [3.8773, 4.0546, 3.8979, 3.8640, 3.7461],\n",
      "        [3.5450, 3.8009, 3.9463, 3.7839, 3.5772],\n",
      "        [3.4457, 3.8720, 3.8593, 3.6439, 3.4804],\n",
      "        [3.4200, 3.5902, 3.7211, 3.5990, 3.5224],\n",
      "        [3.7672, 3.9460, 4.0675, 3.9679, 3.9592],\n",
      "        [3.2810, 3.5226, 3.6823, 3.5138, 3.4668],\n",
      "        [3.5006, 3.9507, 3.8164, 3.7256, 3.7937],\n",
      "        [3.5236, 3.7495, 3.9413, 3.8081, 3.5794],\n",
      "        [3.4739, 3.5090, 3.7019, 3.6532, 3.4655],\n",
      "        [3.7627, 3.8798, 4.0530, 3.9702, 3.9364],\n",
      "        [3.4184, 3.6005, 3.7621, 3.6278, 3.4967],\n",
      "        [3.3952, 3.5704, 3.7252, 3.5905, 3.4890],\n",
      "        [3.3874, 3.6414, 3.7521, 3.6009, 3.5202],\n",
      "        [3.5354, 3.5950, 3.8398, 3.6948, 3.5956],\n",
      "        [3.5117, 3.6914, 3.6884, 3.7189, 3.5799],\n",
      "        [3.3436, 3.5408, 3.5622, 3.5094, 3.4106],\n",
      "        [3.6457, 3.7687, 3.8752, 3.9323, 3.6727],\n",
      "        [3.7518, 3.5393, 3.7239, 3.7410, 3.6937],\n",
      "        [3.3750, 3.5624, 3.6827, 3.6189, 3.4685],\n",
      "        [3.5653, 3.6931, 3.8125, 3.6975, 3.5187],\n",
      "        [4.1815, 4.4256, 4.0862, 4.1121, 3.8905],\n",
      "        [3.5720, 3.8880, 3.8069, 3.8820, 3.7090],\n",
      "        [3.5149, 3.7517, 3.8672, 3.8021, 3.6563],\n",
      "        [3.4896, 3.6730, 3.6827, 3.6844, 3.5635],\n",
      "        [3.9384, 3.7989, 3.9269, 3.9519, 3.8681],\n",
      "        [3.4681, 3.6519, 3.6773, 3.6442, 3.5603],\n",
      "        [3.4740, 3.6539, 3.6736, 3.6471, 3.5619],\n",
      "        [3.6722, 3.6936, 3.8878, 3.8098, 3.6476],\n",
      "        [3.7896, 3.9258, 4.0455, 3.9673, 3.9842],\n",
      "        [3.7816, 3.7294, 3.8700, 3.7596, 3.6153],\n",
      "        [3.4511, 3.6171, 3.6706, 3.6793, 3.4860],\n",
      "        [3.4089, 3.7742, 3.8522, 3.6089, 3.6741],\n",
      "        [3.3852, 3.6461, 3.7481, 3.5865, 3.5089],\n",
      "        [3.5096, 3.6874, 3.6972, 3.7021, 3.5921],\n",
      "        [3.4858, 3.6642, 3.6866, 3.6791, 3.5721],\n",
      "        [3.5121, 3.5542, 3.8085, 3.6733, 3.5657],\n",
      "        [3.9637, 4.1159, 3.9062, 3.9144, 3.7590],\n",
      "        [3.9283, 4.0035, 4.1349, 4.2216, 3.8132],\n",
      "        [3.4164, 3.6158, 3.6613, 3.5846, 3.5188],\n",
      "        [3.5718, 3.6120, 3.7785, 3.6822, 3.6653],\n",
      "        [3.5264, 3.6140, 3.8112, 3.7003, 3.5982],\n",
      "        [3.9690, 3.8596, 4.0094, 4.0373, 3.9248],\n",
      "        [4.0318, 4.1480, 3.8751, 3.9331, 3.7348],\n",
      "        [3.7770, 3.8445, 4.0085, 3.9927, 3.7830],\n",
      "        [3.4789, 3.8293, 3.8588, 3.7561, 3.7933],\n",
      "        [3.5602, 3.7461, 3.9008, 3.8867, 3.6271],\n",
      "        [3.3758, 3.5696, 3.5937, 3.5525, 3.4397],\n",
      "        [3.7232, 3.9703, 3.9121, 3.8240, 3.7368],\n",
      "        [3.4970, 3.5137, 3.7865, 3.6851, 3.6282]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3372, 3.5666, 3.6568, 3.5633, 3.4762],\n",
      "        [3.4849, 3.6517, 3.7269, 3.5475, 3.5423],\n",
      "        [3.9480, 4.0112, 4.0825, 4.1831, 3.9532],\n",
      "        [3.5173, 3.5957, 3.8057, 3.6876, 3.5875],\n",
      "        [3.6979, 3.8734, 3.8984, 3.8062, 3.7128],\n",
      "        [3.4390, 3.5439, 3.6120, 3.6634, 3.4415],\n",
      "        [3.5186, 3.6304, 3.8198, 3.7115, 3.5966],\n",
      "        [3.6347, 3.8909, 3.8560, 3.7924, 3.7088],\n",
      "        [3.3882, 3.5125, 3.6616, 3.6278, 3.4711],\n",
      "        [3.4111, 3.5898, 3.6265, 3.5964, 3.4568],\n",
      "        [4.0725, 4.1449, 4.2338, 4.3790, 3.9076],\n",
      "        [3.4367, 3.5904, 3.6774, 3.6327, 3.5041],\n",
      "        [3.3583, 3.5659, 3.6375, 3.5065, 3.4804],\n",
      "        [3.4088, 3.5777, 3.7100, 3.5883, 3.5093],\n",
      "        [3.5087, 3.6087, 3.9102, 3.5623, 3.7390],\n",
      "        [3.6341, 3.6626, 3.8590, 3.6886, 3.5811],\n",
      "        [3.6910, 3.7426, 3.8954, 3.7552, 3.8109],\n",
      "        [3.5286, 3.9556, 3.8776, 3.7770, 3.9218],\n",
      "        [3.9569, 4.1079, 4.0433, 4.1275, 4.1192],\n",
      "        [3.5211, 4.0426, 4.0425, 3.7513, 3.6393],\n",
      "        [3.7405, 3.7033, 3.8657, 3.7219, 3.5817],\n",
      "        [4.0054, 4.1068, 4.1706, 4.3045, 4.0413],\n",
      "        [3.3717, 3.5700, 3.6920, 3.6128, 3.4678],\n",
      "        [3.5879, 3.6461, 3.9016, 3.7815, 3.6825],\n",
      "        [3.3852, 3.6888, 3.7731, 3.5905, 3.5352],\n",
      "        [3.6649, 3.9630, 3.8827, 3.6818, 3.7338],\n",
      "        [3.3909, 3.6254, 3.7506, 3.6011, 3.5199],\n",
      "        [3.6695, 3.6876, 3.8278, 3.9272, 3.7326],\n",
      "        [3.3898, 3.6406, 3.7526, 3.5884, 3.5074],\n",
      "        [3.4944, 3.6180, 3.5885, 3.7398, 3.4557],\n",
      "        [3.5222, 3.6417, 3.8284, 3.7217, 3.6044],\n",
      "        [3.4724, 3.6134, 3.8041, 3.7039, 3.5834],\n",
      "        [3.7805, 3.7903, 3.9970, 3.9551, 3.7413],\n",
      "        [3.8391, 4.0601, 3.9755, 3.8315, 3.7989],\n",
      "        [3.5247, 3.7006, 3.6968, 3.7293, 3.5922],\n",
      "        [3.8011, 3.9634, 4.1163, 4.1288, 4.1267],\n",
      "        [3.6491, 3.7705, 3.7758, 3.7760, 3.7461],\n",
      "        [3.4037, 3.5430, 3.7155, 3.5954, 3.4861],\n",
      "        [3.7969, 3.8791, 4.0831, 4.0551, 3.7531],\n",
      "        [3.4165, 3.7608, 3.8485, 3.5999, 3.6640],\n",
      "        [3.9791, 4.0702, 4.1967, 4.2785, 4.0047],\n",
      "        [3.6808, 3.8844, 3.8890, 3.8504, 3.7107],\n",
      "        [3.5225, 3.6994, 3.7005, 3.7286, 3.5995],\n",
      "        [4.0612, 4.2371, 4.0076, 3.9775, 3.7816],\n",
      "        [3.5903, 3.6093, 3.8485, 3.7196, 3.6617],\n",
      "        [3.4082, 3.6310, 3.6747, 3.5789, 3.5338],\n",
      "        [3.4701, 3.4694, 3.6533, 3.6196, 3.4476],\n",
      "        [3.4700, 3.6298, 3.8113, 3.7403, 3.5869],\n",
      "        [3.4105, 3.5584, 3.7276, 3.6050, 3.5022],\n",
      "        [3.4751, 3.6484, 3.7140, 3.6540, 3.5892],\n",
      "        [3.6609, 3.6844, 3.8607, 3.7741, 3.6373],\n",
      "        [3.9069, 3.9418, 4.1363, 4.1536, 3.8900],\n",
      "        [3.3791, 3.5958, 3.6679, 3.5347, 3.5130],\n",
      "        [3.5837, 3.8334, 3.8371, 3.7470, 3.6581],\n",
      "        [3.4779, 3.5799, 3.8250, 3.6820, 3.5784],\n",
      "        [3.6606, 3.6823, 3.8670, 3.7822, 3.6319],\n",
      "        [3.6631, 3.7791, 3.9780, 3.7917, 3.5710],\n",
      "        [3.6014, 3.8367, 3.8506, 3.7320, 3.7077],\n",
      "        [3.3520, 3.5561, 3.6330, 3.4976, 3.4763],\n",
      "        [3.2797, 3.5228, 3.6850, 3.5126, 3.4676],\n",
      "        [3.8123, 3.6087, 3.9016, 4.1077, 3.9959],\n",
      "        [3.8730, 3.7386, 3.8594, 3.8877, 3.8469],\n",
      "        [3.4166, 3.5819, 3.7375, 3.6034, 3.5182],\n",
      "        [3.7996, 3.8034, 4.0082, 3.9601, 3.7569]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7867, 4.0098, 4.0726, 3.9954, 3.8918],\n",
      "        [3.3671, 3.4950, 3.6849, 3.5540, 3.4249],\n",
      "        [3.9773, 4.2081, 3.8904, 3.8838, 3.7509],\n",
      "        [3.7633, 3.8277, 4.0826, 4.0653, 3.6833],\n",
      "        [3.4329, 3.4868, 3.6930, 3.6241, 3.4635],\n",
      "        [3.4264, 3.8365, 3.8379, 3.5591, 3.6952],\n",
      "        [3.7482, 3.6092, 3.9009, 4.0203, 3.9306],\n",
      "        [3.6765, 3.8068, 3.9787, 3.9056, 3.8707],\n",
      "        [3.2793, 3.5228, 3.6873, 3.5111, 3.4680],\n",
      "        [3.7380, 3.8939, 3.9908, 3.7893, 3.7655],\n",
      "        [3.7526, 3.5993, 3.7422, 3.7173, 3.7661],\n",
      "        [3.7509, 3.8674, 4.0324, 4.0182, 3.7333],\n",
      "        [3.6860, 3.7503, 3.8738, 3.7514, 3.4908],\n",
      "        [3.6339, 3.6596, 3.8682, 3.6706, 3.6258],\n",
      "        [3.4602, 3.6345, 3.8123, 3.5596, 3.6449],\n",
      "        [3.6726, 3.8905, 3.8850, 3.9640, 3.7751],\n",
      "        [3.6332, 3.6982, 3.8205, 3.8512, 3.6829],\n",
      "        [3.7617, 3.9203, 4.0349, 3.9410, 3.9532],\n",
      "        [3.5259, 3.7709, 3.8694, 3.7411, 3.6303],\n",
      "        [3.6746, 3.8934, 3.8907, 3.9735, 3.7867],\n",
      "        [3.3543, 3.5907, 3.6766, 3.5749, 3.4885],\n",
      "        [3.3999, 3.6042, 3.6611, 3.5560, 3.5104],\n",
      "        [3.8264, 3.6793, 3.8614, 3.8429, 3.7991],\n",
      "        [3.6430, 3.6705, 3.8563, 3.6657, 3.4780],\n",
      "        [3.5601, 3.9924, 3.8610, 3.7800, 3.8593],\n",
      "        [3.4981, 3.6739, 3.6903, 3.6676, 3.5850],\n",
      "        [3.5329, 3.5669, 3.8383, 3.6043, 3.6443],\n",
      "        [3.7497, 3.7898, 3.9942, 3.9296, 3.6016],\n",
      "        [3.3902, 3.5449, 3.6922, 3.6260, 3.4825],\n",
      "        [3.4440, 3.9196, 3.9265, 3.7896, 3.6680],\n",
      "        [3.6008, 3.8286, 3.8428, 3.7386, 3.7073],\n",
      "        [3.5076, 3.5295, 3.8357, 3.5375, 3.6437],\n",
      "        [4.0308, 4.1478, 3.8803, 3.9307, 3.7361],\n",
      "        [3.8499, 3.7430, 3.9215, 4.2186, 3.9521],\n",
      "        [3.4458, 3.6239, 3.8011, 3.6617, 3.5090],\n",
      "        [3.7769, 3.9544, 3.9635, 3.9004, 3.8783],\n",
      "        [3.8580, 3.9543, 3.9665, 3.9696, 3.9358],\n",
      "        [3.6919, 3.8844, 3.8969, 3.8311, 3.7155],\n",
      "        [3.3383, 3.5414, 3.6277, 3.4764, 3.4640],\n",
      "        [3.3835, 3.6785, 3.7640, 3.5863, 3.5255],\n",
      "        [3.4296, 3.7036, 3.6384, 3.6662, 3.4973],\n",
      "        [3.6889, 3.8943, 3.9915, 3.8945, 3.7764],\n",
      "        [3.5434, 3.8016, 3.9523, 3.7815, 3.5784],\n",
      "        [3.3474, 3.7159, 3.9083, 3.5912, 3.6148],\n",
      "        [3.4695, 3.5566, 3.8277, 3.6709, 3.5642],\n",
      "        [3.5037, 3.6922, 3.6946, 3.6990, 3.5827],\n",
      "        [3.5364, 3.5895, 3.8487, 3.7046, 3.6045],\n",
      "        [3.7098, 3.9182, 3.9730, 3.8980, 3.7508],\n",
      "        [3.7120, 3.8886, 3.8709, 3.9064, 3.8119],\n",
      "        [3.6161, 3.7151, 3.8556, 3.8466, 3.6618],\n",
      "        [3.9493, 4.0113, 4.1901, 4.2316, 3.7839],\n",
      "        [3.4665, 3.6522, 3.6824, 3.6415, 3.5616],\n",
      "        [3.4602, 3.6630, 3.6893, 3.6204, 3.5890],\n",
      "        [3.9643, 3.7815, 4.0296, 4.3437, 4.1816],\n",
      "        [3.7055, 3.7560, 3.8979, 3.7771, 3.5395],\n",
      "        [3.4942, 3.9947, 3.8758, 3.7494, 3.8699],\n",
      "        [3.3832, 3.5086, 3.6939, 3.5632, 3.4532],\n",
      "        [3.5841, 3.8599, 3.9391, 3.8564, 3.6422],\n",
      "        [3.5534, 3.6494, 3.9147, 3.7587, 3.6728],\n",
      "        [3.4694, 3.5167, 3.7192, 3.6425, 3.4786],\n",
      "        [3.5153, 3.6934, 3.6989, 3.7088, 3.5924],\n",
      "        [3.4598, 3.6474, 3.6794, 3.6411, 3.5483],\n",
      "        [3.9989, 3.8839, 4.1186, 4.1762, 3.9307],\n",
      "        [3.5239, 3.6979, 3.7035, 3.7073, 3.6060]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6906, 3.7426, 3.8994, 3.7519, 3.8116],\n",
      "        [3.4664, 3.7452, 4.0061, 3.7154, 3.7766],\n",
      "        [3.5250, 3.6185, 3.8163, 3.6933, 3.5958],\n",
      "        [3.8446, 3.8896, 4.0483, 4.0465, 3.8382],\n",
      "        [3.7379, 3.9616, 4.1103, 3.9817, 3.9540],\n",
      "        [3.5218, 3.7530, 3.9321, 3.8444, 3.5884],\n",
      "        [3.6029, 3.8887, 3.8818, 3.8181, 3.8062],\n",
      "        [3.3402, 3.5541, 3.5503, 3.5853, 3.4348],\n",
      "        [3.9693, 3.8348, 4.1453, 4.4503, 4.2449],\n",
      "        [3.3789, 3.6274, 3.7195, 3.6275, 3.4857],\n",
      "        [3.4359, 3.5908, 3.6813, 3.6296, 3.5047],\n",
      "        [3.5243, 3.6144, 3.8183, 3.6962, 3.5996],\n",
      "        [3.7732, 3.7982, 3.9481, 3.8632, 3.8889],\n",
      "        [3.9345, 3.8541, 4.0844, 4.1140, 3.8766],\n",
      "        [3.4220, 3.5566, 3.7407, 3.6193, 3.5097],\n",
      "        [3.6156, 3.7156, 3.8574, 3.8449, 3.6619],\n",
      "        [3.4230, 3.4847, 3.6913, 3.6220, 3.4552],\n",
      "        [3.5506, 3.6349, 3.8993, 3.7398, 3.6661],\n",
      "        [3.5736, 3.9080, 3.7848, 3.7732, 3.6409],\n",
      "        [3.7604, 3.8814, 4.0614, 3.9663, 3.9377],\n",
      "        [3.5277, 3.7089, 3.7078, 3.7296, 3.6025],\n",
      "        [3.3952, 3.6656, 3.7702, 3.6038, 3.5336],\n",
      "        [3.7903, 3.8715, 4.0315, 4.0305, 4.0117],\n",
      "        [3.4350, 3.6181, 3.6679, 3.5945, 3.5243],\n",
      "        [3.6130, 3.5702, 3.7542, 3.6644, 3.6421],\n",
      "        [3.7315, 3.8179, 4.0017, 3.9195, 3.6437],\n",
      "        [3.7117, 3.8888, 3.8726, 3.9048, 3.8119],\n",
      "        [3.6477, 3.9760, 4.0096, 3.8829, 3.9092],\n",
      "        [3.4951, 3.5140, 3.7936, 3.6810, 3.6297],\n",
      "        [3.5487, 3.7312, 3.7125, 3.7620, 3.6122],\n",
      "        [3.5318, 3.7062, 3.7016, 3.7351, 3.5932],\n",
      "        [3.8005, 3.9636, 4.1207, 4.1259, 4.1273],\n",
      "        [3.8314, 3.9687, 3.9795, 3.9641, 3.9112],\n",
      "        [3.3971, 3.5975, 3.6638, 3.5547, 3.5269],\n",
      "        [3.6035, 4.0194, 3.9392, 3.9397, 3.8409],\n",
      "        [3.5452, 3.6330, 3.9130, 3.6212, 3.7568],\n",
      "        [3.9258, 3.9790, 4.1228, 4.1513, 3.7386],\n",
      "        [3.5742, 3.7608, 3.8649, 3.7171, 3.7727],\n",
      "        [3.4193, 3.6276, 3.6717, 3.5840, 3.5331],\n",
      "        [3.3888, 3.7071, 3.6278, 3.6775, 3.4836],\n",
      "        [3.4701, 3.6012, 3.7939, 3.6649, 3.5846],\n",
      "        [3.4113, 3.9277, 3.9358, 3.7671, 3.6716],\n",
      "        [3.6048, 3.6720, 3.9267, 3.7881, 3.6925],\n",
      "        [3.8093, 3.8755, 4.0387, 4.0639, 4.0240],\n",
      "        [3.3784, 3.5903, 3.6589, 3.5373, 3.5022],\n",
      "        [3.5278, 3.5900, 3.8269, 3.6901, 3.5855],\n",
      "        [3.4828, 3.7346, 3.9265, 3.7814, 3.5528],\n",
      "        [3.4548, 3.8630, 3.9008, 3.7597, 3.7623],\n",
      "        [3.5386, 3.6913, 3.7470, 3.7118, 3.6344],\n",
      "        [3.5033, 3.6926, 3.6963, 3.6974, 3.5829],\n",
      "        [3.5481, 3.7029, 3.7642, 3.7751, 3.6293],\n",
      "        [3.6103, 4.0033, 3.8634, 3.7934, 3.8796],\n",
      "        [3.5557, 3.6281, 3.8908, 3.7316, 3.6637],\n",
      "        [3.8618, 4.0069, 4.0192, 3.9775, 3.9548],\n",
      "        [3.5830, 3.8333, 3.8420, 3.7273, 3.6614],\n",
      "        [3.5243, 3.6351, 3.8289, 3.7071, 3.6008],\n",
      "        [3.5322, 3.7185, 3.7086, 3.7429, 3.6052],\n",
      "        [4.0322, 4.2003, 4.0395, 3.9732, 3.8371],\n",
      "        [3.8262, 3.6797, 3.8632, 3.8413, 3.7994],\n",
      "        [3.4155, 3.5037, 3.6984, 3.6095, 3.4668],\n",
      "        [3.3541, 3.7145, 3.9097, 3.5849, 3.6204],\n",
      "        [3.5694, 3.9957, 3.9288, 3.8978, 3.8359],\n",
      "        [3.3926, 3.6958, 3.7806, 3.5932, 3.5421],\n",
      "        [3.9645, 4.0558, 4.1419, 4.2216, 3.9323]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5363, 3.8196, 3.8694, 3.6575, 3.6927],\n",
      "        [3.7187, 4.0137, 3.9277, 3.9028, 3.9627],\n",
      "        [3.9104, 4.0998, 4.0335, 4.0907, 4.0894],\n",
      "        [3.5260, 3.5643, 3.8194, 3.6744, 3.5920],\n",
      "        [3.6784, 3.7730, 3.7673, 3.8500, 3.7774],\n",
      "        [3.4383, 3.5446, 3.7395, 3.6219, 3.4763],\n",
      "        [3.7986, 3.8046, 4.0139, 3.9567, 3.7573],\n",
      "        [3.4367, 3.5299, 3.7252, 3.6348, 3.5032],\n",
      "        [3.5385, 3.7263, 3.7133, 3.7379, 3.6171],\n",
      "        [3.5553, 3.7371, 3.8422, 3.6995, 3.7432],\n",
      "        [3.8260, 3.6804, 3.8647, 3.8402, 3.7995],\n",
      "        [4.0386, 4.1573, 3.8875, 3.9442, 3.7330],\n",
      "        [3.4277, 3.5613, 3.6486, 3.6568, 3.4294],\n",
      "        [3.5482, 3.7305, 3.9877, 3.7978, 3.7657],\n",
      "        [3.8381, 3.9685, 3.9823, 3.9681, 3.9127],\n",
      "        [3.4188, 3.6171, 3.7792, 3.6313, 3.5092],\n",
      "        [3.6168, 3.8134, 3.9030, 3.8325, 3.7263],\n",
      "        [3.5714, 3.6823, 3.9605, 3.7845, 3.6978],\n",
      "        [3.5067, 3.5306, 3.8390, 3.5346, 3.6436],\n",
      "        [3.4806, 3.6372, 3.7234, 3.7150, 3.5759],\n",
      "        [3.4190, 3.6183, 3.6729, 3.5749, 3.5243],\n",
      "        [3.7917, 3.8469, 4.0000, 4.0417, 4.0135],\n",
      "        [3.6380, 3.8640, 4.0216, 3.9281, 3.7997],\n",
      "        [3.8871, 4.0943, 4.0308, 4.0657, 4.0739],\n",
      "        [3.5609, 3.5958, 3.8711, 3.7501, 3.7229],\n",
      "        [3.6767, 3.7011, 3.9189, 3.8254, 3.6714],\n",
      "        [3.5318, 3.5457, 3.7729, 3.6055, 3.5170],\n",
      "        [3.7372, 3.8952, 3.9942, 3.7866, 3.7655],\n",
      "        [3.5712, 3.6224, 3.8327, 3.7067, 3.6578],\n",
      "        [3.5346, 3.5815, 3.7287, 3.7649, 3.5193],\n",
      "        [3.3813, 3.5913, 3.6569, 3.5309, 3.4997],\n",
      "        [3.8188, 3.9204, 4.0515, 3.9765, 4.0423],\n",
      "        [3.6718, 3.8879, 3.8759, 3.7983, 3.7228],\n",
      "        [3.4072, 3.6128, 3.6708, 3.5616, 3.5260],\n",
      "        [3.7225, 4.0880, 4.0550, 4.0646, 3.9360],\n",
      "        [3.3903, 3.7161, 3.6335, 3.6642, 3.4813],\n",
      "        [3.3450, 3.5532, 3.5574, 3.6032, 3.4377],\n",
      "        [3.9633, 3.9852, 4.0540, 4.1040, 3.9980],\n",
      "        [3.3948, 3.6115, 3.6799, 3.5527, 3.5257],\n",
      "        [3.4575, 3.6850, 3.7180, 3.6883, 3.5169],\n",
      "        [3.5253, 3.6602, 3.7752, 3.6737, 3.6168],\n",
      "        [3.5096, 3.6630, 3.9072, 3.8038, 3.7719],\n",
      "        [3.4808, 3.6580, 3.6809, 3.6671, 3.5466],\n",
      "        [3.7608, 3.9222, 4.0387, 3.9385, 3.9531],\n",
      "        [3.6041, 3.6797, 3.9356, 3.7763, 3.6972],\n",
      "        [3.4658, 3.8096, 3.8504, 3.7487, 3.7538],\n",
      "        [3.9133, 3.9585, 4.1591, 4.1678, 3.9089],\n",
      "        [3.5522, 3.5659, 3.8317, 3.7120, 3.7055],\n",
      "        [3.3508, 3.5572, 3.6381, 3.4934, 3.4768],\n",
      "        [3.5551, 3.5527, 3.8048, 3.7067, 3.6996],\n",
      "        [4.0481, 4.1552, 3.9057, 3.9454, 3.7386],\n",
      "        [3.4356, 3.7788, 3.8463, 3.7166, 3.7725],\n",
      "        [3.5552, 3.6288, 3.8923, 3.7305, 3.6636],\n",
      "        [3.5596, 3.8206, 3.8044, 3.7239, 3.6235],\n",
      "        [3.5267, 3.5901, 3.8296, 3.6823, 3.5854],\n",
      "        [3.6595, 3.6832, 3.8725, 3.7780, 3.6324],\n",
      "        [3.8178, 3.5996, 3.8960, 4.1287, 4.0044],\n",
      "        [3.6749, 3.7131, 3.8149, 3.9251, 3.7480],\n",
      "        [3.5424, 3.6087, 3.8414, 3.6967, 3.6062],\n",
      "        [3.8825, 3.9413, 4.0734, 4.1078, 3.8285],\n",
      "        [3.8819, 3.7735, 4.0212, 4.0408, 3.8028],\n",
      "        [3.7241, 3.8762, 3.8914, 3.8388, 3.8188],\n",
      "        [3.5837, 4.0447, 3.9149, 3.9524, 3.8143],\n",
      "        [3.5298, 3.7680, 3.7515, 3.8350, 3.5685]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3628, 3.5761, 3.6498, 3.5181, 3.4916],\n",
      "        [3.7687, 3.9147, 4.0634, 3.9384, 3.9861],\n",
      "        [3.5493, 3.6459, 3.9092, 3.6078, 3.7708],\n",
      "        [3.6925, 3.9727, 3.9652, 3.8700, 3.7734],\n",
      "        [3.4441, 3.7025, 3.8339, 3.6097, 3.5815],\n",
      "        [3.3593, 3.4869, 3.6786, 3.5404, 3.4180],\n",
      "        [3.5639, 3.6734, 3.8566, 3.6053, 3.7006],\n",
      "        [3.7593, 3.9655, 4.0912, 3.9690, 3.9661],\n",
      "        [3.5443, 3.6350, 3.9153, 3.6193, 3.7564],\n",
      "        [3.4577, 3.9135, 3.8893, 3.7685, 3.8087],\n",
      "        [3.5322, 3.6236, 3.8421, 3.6624, 3.5933],\n",
      "        [3.7328, 3.9053, 3.8892, 3.9188, 3.8214],\n",
      "        [4.0216, 4.2410, 4.3358, 4.2785, 4.3074],\n",
      "        [3.3822, 3.6488, 3.7566, 3.5803, 3.5098],\n",
      "        [3.4287, 3.7154, 3.8367, 3.6287, 3.5608],\n",
      "        [3.4806, 3.6011, 3.8229, 3.6884, 3.5902],\n",
      "        [3.6003, 3.9899, 3.9087, 3.9123, 3.7969],\n",
      "        [3.3638, 3.6482, 3.8993, 3.6016, 3.6686],\n",
      "        [3.6259, 3.6556, 3.8614, 3.6688, 3.5972],\n",
      "        [3.9306, 3.9347, 3.9317, 4.0305, 4.0101],\n",
      "        [3.5171, 3.6350, 3.8269, 3.7079, 3.5983],\n",
      "        [3.5926, 3.6693, 3.8440, 3.7734, 3.6448],\n",
      "        [3.4757, 3.7411, 3.9237, 3.8259, 3.5444],\n",
      "        [3.5591, 3.9006, 3.7770, 3.7418, 3.6290],\n",
      "        [3.5761, 3.6389, 3.8795, 3.7537, 3.6600],\n",
      "        [3.5383, 3.6505, 3.9367, 3.8142, 3.6817],\n",
      "        [3.4770, 3.9139, 3.8898, 3.7811, 3.8091],\n",
      "        [3.8650, 3.8407, 3.9672, 3.9244, 3.8753],\n",
      "        [3.6811, 3.6927, 3.8651, 3.6620, 3.5203],\n",
      "        [3.2649, 3.8264, 3.8214, 3.6516, 3.4250],\n",
      "        [3.7014, 3.8917, 4.0048, 3.8091, 3.6259],\n",
      "        [3.4986, 3.9002, 3.9197, 3.7159, 3.5194],\n",
      "        [3.3164, 3.5242, 3.6141, 3.4467, 3.4351],\n",
      "        [3.5698, 3.7587, 3.8599, 3.7139, 3.7668],\n",
      "        [3.6815, 3.8373, 3.8789, 3.7049, 3.6869],\n",
      "        [3.5804, 3.6247, 3.7970, 3.6833, 3.6768],\n",
      "        [3.5750, 3.6378, 3.8570, 3.7448, 3.6528],\n",
      "        [3.5573, 3.8924, 3.8162, 3.7798, 3.6616],\n",
      "        [3.9587, 3.9752, 4.0337, 4.1040, 4.0058],\n",
      "        [3.6749, 3.8517, 4.0199, 3.9085, 3.8409],\n",
      "        [3.9589, 3.8945, 4.0108, 4.0294, 3.9687],\n",
      "        [3.5269, 3.6182, 3.8207, 3.6898, 3.5970],\n",
      "        [3.6027, 3.6851, 3.9451, 3.7885, 3.6959],\n",
      "        [3.7043, 3.7581, 3.9019, 3.7738, 3.5393],\n",
      "        [3.5724, 3.6731, 3.8318, 3.6975, 3.7828],\n",
      "        [3.4139, 3.5509, 3.7371, 3.6186, 3.4965],\n",
      "        [3.7328, 3.8915, 4.0836, 3.9862, 3.9381],\n",
      "        [3.3389, 3.5960, 3.6728, 3.5641, 3.4935],\n",
      "        [3.5362, 3.6650, 3.8480, 3.7397, 3.6318],\n",
      "        [3.7063, 3.8739, 3.9821, 3.8197, 3.5966],\n",
      "        [3.6615, 4.0257, 4.0355, 3.8869, 3.8554],\n",
      "        [3.5505, 3.5412, 3.7667, 3.6797, 3.6975],\n",
      "        [3.7052, 3.8362, 3.9393, 3.8541, 3.8455],\n",
      "        [3.3559, 3.4673, 3.6590, 3.5095, 3.4101],\n",
      "        [3.5138, 3.6245, 3.9551, 3.5453, 3.7552],\n",
      "        [3.3823, 3.6677, 3.7634, 3.5813, 3.5186],\n",
      "        [3.5375, 3.6935, 3.7493, 3.7101, 3.6340],\n",
      "        [3.6960, 3.8115, 3.9811, 3.8134, 3.7325],\n",
      "        [3.3848, 3.5608, 3.7002, 3.6222, 3.4817],\n",
      "        [3.3759, 3.6724, 3.7653, 3.5806, 3.5206],\n",
      "        [3.3358, 3.9668, 3.9356, 3.7364, 3.5529],\n",
      "        [3.8846, 3.7558, 3.9014, 3.9038, 3.8844],\n",
      "        [3.6334, 3.6705, 3.8736, 3.6712, 3.6091],\n",
      "        [3.6746, 3.7495, 3.9124, 3.7767, 3.7775]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8598, 4.0089, 4.0217, 3.9753, 3.9534],\n",
      "        [3.4892, 3.9525, 3.8007, 3.6779, 3.7614],\n",
      "        [3.4333, 3.7282, 3.6692, 3.6810, 3.5076],\n",
      "        [3.7265, 4.0344, 4.0120, 4.0151, 3.8525],\n",
      "        [3.3863, 3.6743, 3.7323, 3.6462, 3.5069],\n",
      "        [3.3766, 3.6303, 3.7219, 3.6250, 3.4846],\n",
      "        [3.3521, 3.4795, 3.6470, 3.5007, 3.4494],\n",
      "        [3.5713, 3.6736, 3.8323, 3.6968, 3.7821],\n",
      "        [3.4564, 3.6485, 3.6814, 3.6236, 3.5563],\n",
      "        [3.5277, 3.5137, 3.7044, 3.6184, 3.6686],\n",
      "        [3.5732, 3.6239, 3.8238, 3.7002, 3.6665],\n",
      "        [3.4694, 3.6038, 3.5855, 3.7097, 3.4594],\n",
      "        [3.5061, 3.6306, 3.8261, 3.7095, 3.5950],\n",
      "        [3.6876, 3.8080, 4.0070, 3.7958, 3.5542],\n",
      "        [3.7603, 3.8332, 4.0899, 4.0619, 3.6824],\n",
      "        [3.5167, 3.6921, 3.8077, 3.6838, 3.6410],\n",
      "        [3.5825, 3.7141, 3.8070, 3.6895, 3.6429],\n",
      "        [3.5216, 3.7040, 3.7037, 3.7237, 3.5918],\n",
      "        [3.9243, 3.8275, 4.0806, 4.4037, 4.1714],\n",
      "        [3.3880, 3.6004, 3.6653, 3.5384, 3.5145],\n",
      "        [3.6838, 3.7528, 3.8783, 3.7474, 3.4900],\n",
      "        [3.4243, 3.6797, 3.8768, 3.6786, 3.6570],\n",
      "        [3.7852, 3.9304, 4.0568, 3.9610, 3.9843],\n",
      "        [3.4343, 3.6355, 3.6767, 3.6082, 3.5345],\n",
      "        [3.4598, 4.0254, 4.0085, 3.8280, 3.6366],\n",
      "        [3.5299, 3.7216, 3.7115, 3.7404, 3.6041],\n",
      "        [3.9015, 4.0260, 4.1813, 4.2080, 4.1846],\n",
      "        [3.4584, 3.8915, 3.8703, 3.6447, 3.5011],\n",
      "        [3.7358, 3.8562, 4.1402, 3.8123, 3.5731],\n",
      "        [3.3902, 3.5203, 3.7027, 3.5654, 3.4723],\n",
      "        [3.5687, 3.7592, 3.8603, 3.7131, 3.7662],\n",
      "        [3.7776, 3.7935, 4.0041, 3.9507, 3.7407],\n",
      "        [3.6051, 3.7932, 3.9980, 3.8232, 3.7362],\n",
      "        [4.0002, 4.2331, 3.9205, 3.9208, 3.7321],\n",
      "        [3.5329, 3.7196, 3.7084, 3.7561, 3.6075],\n",
      "        [3.4714, 3.6126, 3.5916, 3.7113, 3.4642],\n",
      "        [3.5195, 3.6025, 3.8234, 3.6938, 3.5973],\n",
      "        [3.6312, 3.7519, 3.9453, 3.8022, 3.6605],\n",
      "        [3.3553, 3.7848, 3.8461, 3.6828, 3.4825],\n",
      "        [3.4743, 3.4871, 3.8173, 3.4692, 3.6272],\n",
      "        [3.5548, 3.6190, 3.8584, 3.7265, 3.6758],\n",
      "        [3.4131, 3.5574, 3.7491, 3.6118, 3.4704],\n",
      "        [3.5247, 3.7218, 3.8401, 3.7605, 3.7068],\n",
      "        [3.6946, 3.8945, 4.0115, 3.8716, 3.7767],\n",
      "        [3.5603, 3.8152, 3.8672, 3.7091, 3.6906],\n",
      "        [3.6955, 3.8741, 3.8967, 3.8023, 3.7145],\n",
      "        [3.7210, 3.9301, 3.9900, 3.8727, 3.7296],\n",
      "        [3.4500, 3.6471, 3.6855, 3.6030, 3.5540],\n",
      "        [3.9389, 3.8856, 4.0143, 4.1155, 3.8839],\n",
      "        [3.5738, 3.6263, 3.8505, 3.7120, 3.6613],\n",
      "        [3.4930, 3.6076, 3.7964, 3.5638, 3.6465],\n",
      "        [3.5534, 3.5575, 3.7983, 3.7030, 3.7036],\n",
      "        [3.5494, 3.6747, 3.8339, 3.7110, 3.7392],\n",
      "        [3.7196, 3.9796, 3.9267, 3.8195, 3.7391],\n",
      "        [3.5284, 3.6111, 3.8390, 3.7168, 3.6704],\n",
      "        [3.6922, 3.9684, 3.9332, 3.8145, 3.7402],\n",
      "        [3.5068, 3.7112, 3.8766, 3.7851, 3.6193],\n",
      "        [3.4447, 3.6007, 3.6832, 3.6425, 3.5079],\n",
      "        [3.8739, 4.0578, 3.9088, 3.8579, 3.7464],\n",
      "        [3.6634, 3.8488, 4.0041, 3.7699, 3.5861],\n",
      "        [3.4519, 3.5957, 3.7961, 3.6891, 3.5683],\n",
      "        [3.3686, 3.5733, 3.6983, 3.6071, 3.4673],\n",
      "        [3.6963, 3.9752, 3.9768, 3.8733, 3.7903],\n",
      "        [3.5637, 3.6196, 3.8676, 3.7333, 3.6429]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3407, 3.5519, 3.5748, 3.5110, 3.4145],\n",
      "        [3.5692, 3.8288, 3.8234, 3.7335, 3.6338],\n",
      "        [3.3902, 3.6258, 3.7522, 3.5931, 3.5240],\n",
      "        [3.7746, 3.9360, 3.9484, 3.8845, 3.8767],\n",
      "        [3.4327, 3.7819, 3.8479, 3.7151, 3.7737],\n",
      "        [3.3971, 3.5686, 3.7372, 3.5885, 3.4935],\n",
      "        [3.4693, 3.5422, 3.7382, 3.5084, 3.5769],\n",
      "        [3.6696, 3.8831, 4.0057, 3.8555, 3.6984],\n",
      "        [3.6101, 3.6278, 4.0803, 3.8096, 3.7498],\n",
      "        [3.5930, 3.6085, 4.0779, 3.7911, 3.7301],\n",
      "        [3.7780, 3.9521, 4.1059, 4.0959, 4.1092],\n",
      "        [3.6747, 3.8958, 3.9354, 3.8353, 3.8094],\n",
      "        [3.4781, 3.6027, 3.8237, 3.6875, 3.5918],\n",
      "        [3.6979, 3.8700, 3.9781, 3.9683, 3.7258],\n",
      "        [3.4899, 4.0335, 4.0454, 3.7549, 3.6255],\n",
      "        [3.8615, 3.9152, 4.0711, 4.0631, 3.7572],\n",
      "        [3.3525, 3.5695, 3.6444, 3.5029, 3.4812],\n",
      "        [3.7501, 3.6030, 3.7469, 3.7132, 3.7683],\n",
      "        [3.6651, 3.8917, 3.8894, 3.9600, 3.7786],\n",
      "        [3.5882, 3.6131, 3.8491, 3.7437, 3.6262],\n",
      "        [3.5039, 3.9010, 3.9598, 3.8062, 3.7977],\n",
      "        [3.5230, 3.6344, 3.8324, 3.7126, 3.6015],\n",
      "        [3.8808, 3.9460, 4.1428, 4.1628, 3.9205],\n",
      "        [3.5870, 3.6574, 3.9007, 3.7728, 3.6852],\n",
      "        [3.7695, 3.8341, 3.9843, 3.9372, 3.8966],\n",
      "        [3.3687, 3.5479, 3.6191, 3.6195, 3.4280],\n",
      "        [3.6093, 3.6835, 3.9449, 3.7976, 3.7038],\n",
      "        [3.5440, 3.7207, 3.8288, 3.7223, 3.6705],\n",
      "        [3.4725, 3.6610, 3.6803, 3.6602, 3.5494],\n",
      "        [3.4932, 3.7218, 3.7692, 3.5691, 3.5288],\n",
      "        [3.9609, 4.0598, 4.1452, 4.2200, 3.9333],\n",
      "        [4.0590, 4.2402, 4.0146, 3.9721, 3.7833],\n",
      "        [3.9339, 4.1616, 4.2570, 4.2055, 4.2201],\n",
      "        [3.5211, 3.6107, 3.8191, 3.6855, 3.5974],\n",
      "        [3.4465, 3.8839, 3.9040, 3.8003, 3.7107],\n",
      "        [3.4250, 3.7023, 3.8945, 3.6598, 3.6480],\n",
      "        [3.8235, 3.5997, 3.9108, 4.1252, 4.0021],\n",
      "        [3.8631, 3.8423, 3.9680, 3.9234, 3.8771],\n",
      "        [3.5493, 3.5896, 3.7351, 3.6337, 3.6402],\n",
      "        [3.8602, 3.9956, 4.0358, 3.9684, 3.9190],\n",
      "        [3.6425, 3.5284, 3.9816, 3.7965, 3.6671],\n",
      "        [3.5641, 3.6158, 3.8798, 3.7292, 3.6178],\n",
      "        [3.4330, 3.6366, 3.6768, 3.6081, 3.5366],\n",
      "        [3.5297, 3.5933, 3.7377, 3.7591, 3.5336],\n",
      "        [3.6479, 3.9656, 4.0234, 3.8680, 3.6964],\n",
      "        [3.6785, 3.7538, 4.0212, 3.7894, 3.4750],\n",
      "        [3.5949, 3.6055, 4.0666, 3.7846, 3.7170],\n",
      "        [3.4279, 3.7285, 3.9009, 3.8034, 3.5013],\n",
      "        [3.4278, 3.6651, 3.7121, 3.7034, 3.5251],\n",
      "        [3.3859, 3.5910, 3.7403, 3.5814, 3.4946],\n",
      "        [3.3940, 3.5455, 3.6861, 3.5660, 3.4933],\n",
      "        [3.5877, 3.8644, 4.0348, 3.9202, 3.7418],\n",
      "        [3.6198, 3.7430, 3.7656, 3.7727, 3.6613],\n",
      "        [3.3820, 3.7177, 3.9194, 3.6053, 3.5975],\n",
      "        [3.5508, 3.6411, 3.9058, 3.6356, 3.7596],\n",
      "        [3.5286, 3.7227, 3.7117, 3.7401, 3.6064],\n",
      "        [3.3982, 3.7103, 3.7893, 3.6111, 3.5636],\n",
      "        [3.7849, 3.9537, 4.1161, 4.1140, 4.1126],\n",
      "        [3.7211, 3.8785, 3.8926, 3.8375, 3.8198],\n",
      "        [3.6534, 3.8829, 3.9331, 3.8129, 3.8169],\n",
      "        [3.5972, 4.0444, 3.9177, 3.9609, 3.8166],\n",
      "        [3.4314, 3.5403, 3.6166, 3.6506, 3.4315],\n",
      "        [3.4120, 3.5074, 3.7011, 3.6069, 3.4678],\n",
      "        [3.5692, 3.6525, 3.8987, 3.6615, 3.7734]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6933, 3.8581, 3.9004, 3.7408, 3.7045],\n",
      "        [3.5110, 3.6167, 3.8118, 3.6877, 3.5933],\n",
      "        [3.5248, 3.7662, 3.8670, 3.7267, 3.6565],\n",
      "        [3.5202, 3.6398, 3.8318, 3.7039, 3.6035],\n",
      "        [3.3306, 3.5486, 3.5704, 3.5157, 3.4079],\n",
      "        [3.4349, 3.6854, 3.8825, 3.6829, 3.6659],\n",
      "        [3.5097, 3.7540, 3.8467, 3.7043, 3.6470],\n",
      "        [3.9598, 3.7865, 4.0345, 4.3393, 4.1851],\n",
      "        [3.6094, 3.6631, 3.9433, 3.9326, 3.9007],\n",
      "        [3.3794, 3.6512, 3.7567, 3.5791, 3.5130],\n",
      "        [3.7878, 3.8421, 4.0650, 3.9519, 3.6520],\n",
      "        [3.5171, 3.6219, 3.8198, 3.7012, 3.6070],\n",
      "        [3.5092, 3.6029, 3.7596, 3.7288, 3.5341],\n",
      "        [3.5237, 3.7138, 3.7106, 3.7264, 3.6054],\n",
      "        [3.2690, 3.8326, 3.8285, 3.6522, 3.4359],\n",
      "        [3.5503, 4.0346, 3.9021, 3.9340, 3.7966],\n",
      "        [3.5885, 3.6722, 3.9261, 3.7691, 3.6867],\n",
      "        [3.4542, 3.6886, 3.7189, 3.6865, 3.5201],\n",
      "        [3.5407, 3.5940, 3.8462, 3.6351, 3.6488],\n",
      "        [3.5511, 3.9853, 3.9112, 3.8893, 3.8092],\n",
      "        [3.7292, 3.8152, 4.0242, 3.8854, 3.6181],\n",
      "        [3.3779, 3.5949, 3.6579, 3.5292, 3.5027],\n",
      "        [3.9095, 3.9384, 3.9113, 4.0345, 4.0291],\n",
      "        [3.3532, 3.4695, 3.6592, 3.5084, 3.4133],\n",
      "        [3.5195, 3.7534, 3.9415, 3.8404, 3.5892],\n",
      "        [3.4297, 3.6777, 3.6768, 3.6726, 3.5440],\n",
      "        [3.4599, 3.4983, 3.6847, 3.6189, 3.4637],\n",
      "        [3.5724, 3.6399, 3.8574, 3.7433, 3.6561],\n",
      "        [3.6795, 3.8512, 4.0318, 3.8009, 3.6079],\n",
      "        [3.6255, 3.7375, 3.7919, 3.8097, 3.6912],\n",
      "        [3.5269, 3.9275, 3.9672, 3.8291, 3.8431],\n",
      "        [3.6509, 3.8524, 3.9899, 3.8318, 3.7227],\n",
      "        [3.4222, 3.5025, 3.7023, 3.6193, 3.4762],\n",
      "        [3.5188, 3.7080, 3.7115, 3.7241, 3.6033],\n",
      "        [4.0005, 4.1009, 4.1717, 4.2689, 4.0120],\n",
      "        [3.8351, 4.0644, 3.9824, 3.8254, 3.8022],\n",
      "        [3.4120, 3.5597, 3.6971, 3.5909, 3.5083],\n",
      "        [3.5347, 3.7299, 3.7123, 3.7509, 3.6163],\n",
      "        [3.5216, 3.5972, 3.8238, 3.6909, 3.5899],\n",
      "        [3.4180, 3.7023, 3.8574, 3.5771, 3.7177],\n",
      "        [3.5654, 4.0002, 3.9317, 3.8947, 3.8387],\n",
      "        [3.7891, 3.9121, 4.0584, 3.9558, 3.7655],\n",
      "        [3.9160, 3.7621, 3.9051, 3.9381, 3.8848],\n",
      "        [3.5383, 3.7386, 3.8477, 3.7732, 3.7155],\n",
      "        [3.6583, 3.7839, 3.9854, 3.7856, 3.5742],\n",
      "        [3.5777, 3.8340, 3.8370, 3.7262, 3.6542],\n",
      "        [4.0216, 4.2634, 3.9419, 3.9467, 3.7517],\n",
      "        [3.6197, 3.6173, 4.0571, 3.8056, 3.7446],\n",
      "        [3.6985, 3.8942, 4.0054, 3.8077, 3.6295],\n",
      "        [3.5020, 3.5753, 3.7898, 3.6303, 3.5465],\n",
      "        [3.4180, 3.5611, 3.7432, 3.6162, 3.5124],\n",
      "        [3.4223, 3.5229, 3.7102, 3.6120, 3.4803],\n",
      "        [3.4160, 3.8444, 3.8400, 3.5594, 3.7060],\n",
      "        [3.6590, 3.6914, 3.8960, 3.7946, 3.6516],\n",
      "        [3.5361, 3.6562, 3.8439, 3.7294, 3.6360],\n",
      "        [3.7877, 4.0435, 3.9685, 3.9737, 4.0349],\n",
      "        [3.5553, 3.9972, 3.8654, 3.7756, 3.8618],\n",
      "        [3.9794, 4.1062, 4.1609, 4.2582, 4.0116],\n",
      "        [3.6766, 3.9981, 3.9303, 3.8762, 3.7568],\n",
      "        [3.5130, 3.6909, 3.7667, 3.6606, 3.6144],\n",
      "        [3.5394, 3.6185, 3.8411, 3.6973, 3.6142],\n",
      "        [3.5596, 3.6040, 3.7489, 3.6467, 3.6580],\n",
      "        [3.7057, 4.1176, 4.0067, 4.0398, 3.9172],\n",
      "        [3.9561, 3.9779, 4.0348, 4.1028, 4.0091]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5900, 3.9659, 4.0482, 3.8967, 3.8614],\n",
      "        [3.5136, 3.6824, 3.7706, 3.6601, 3.6242],\n",
      "        [3.6031, 3.7168, 3.8252, 3.7187, 3.6594],\n",
      "        [3.4070, 3.6483, 3.7061, 3.6725, 3.5252],\n",
      "        [3.4718, 3.6388, 3.7589, 3.6600, 3.6322],\n",
      "        [3.3809, 3.7455, 3.8285, 3.6446, 3.5252],\n",
      "        [3.5629, 3.6168, 3.8793, 3.7280, 3.6208],\n",
      "        [3.5230, 3.6210, 3.8209, 3.6876, 3.6015],\n",
      "        [3.4903, 3.6874, 3.7024, 3.6781, 3.5819],\n",
      "        [3.7301, 3.9151, 3.8888, 3.9313, 3.9346],\n",
      "        [3.7517, 3.5556, 3.7454, 3.7186, 3.7353],\n",
      "        [3.4771, 4.0461, 4.0604, 3.8315, 3.6750],\n",
      "        [3.4139, 3.5210, 3.7106, 3.6013, 3.4824],\n",
      "        [3.4114, 3.4780, 3.6830, 3.6045, 3.4535],\n",
      "        [3.5086, 3.5630, 3.8186, 3.6682, 3.5713],\n",
      "        [3.6921, 3.8344, 3.9824, 3.7912, 3.7368],\n",
      "        [3.7212, 3.8013, 4.0606, 3.8494, 3.5402],\n",
      "        [3.5347, 3.8327, 3.8285, 3.6799, 3.6659],\n",
      "        [3.5397, 3.7329, 3.7295, 3.7534, 3.6253],\n",
      "        [3.6667, 3.9290, 4.0027, 3.8927, 3.8271],\n",
      "        [3.4538, 3.6507, 3.6810, 3.6223, 3.5615],\n",
      "        [3.3797, 3.6341, 3.7505, 3.5769, 3.5077],\n",
      "        [3.4621, 3.5249, 3.7275, 3.6317, 3.4841],\n",
      "        [3.5286, 3.7111, 3.8642, 3.7554, 3.6856],\n",
      "        [3.4685, 3.6818, 3.7166, 3.6368, 3.6048],\n",
      "        [3.8984, 3.7885, 3.9248, 3.9244, 3.9075],\n",
      "        [3.6453, 3.8286, 3.8735, 3.8228, 3.7746],\n",
      "        [3.6964, 3.8892, 4.0274, 3.8964, 3.8075],\n",
      "        [3.7186, 3.7901, 4.0494, 4.0045, 3.6418],\n",
      "        [3.8965, 3.7632, 3.9536, 4.2879, 4.0279],\n",
      "        [3.6292, 3.7322, 3.9532, 3.8120, 3.6811],\n",
      "        [3.4357, 3.6924, 3.8808, 3.7212, 3.6972],\n",
      "        [4.0250, 4.0147, 4.2422, 4.2533, 4.0457],\n",
      "        [3.8623, 3.8433, 3.9676, 3.9222, 3.8803],\n",
      "        [3.5602, 3.6310, 3.8883, 3.7614, 3.6787],\n",
      "        [3.5360, 3.7313, 3.7262, 3.7539, 3.6197],\n",
      "        [3.3833, 3.6625, 3.7651, 3.5945, 3.5294],\n",
      "        [3.8076, 3.8389, 3.8360, 3.8858, 3.8536],\n",
      "        [3.9140, 3.9560, 4.1366, 4.1462, 3.9078],\n",
      "        [3.5361, 3.6822, 3.8352, 3.7196, 3.7223],\n",
      "        [4.1892, 4.4076, 4.1116, 4.0831, 3.9232],\n",
      "        [3.4005, 3.6383, 3.7954, 3.6145, 3.5319],\n",
      "        [3.6012, 3.7520, 3.8713, 3.7759, 3.7489],\n",
      "        [3.7955, 3.9682, 4.1232, 4.1224, 4.1316],\n",
      "        [3.4048, 3.6026, 3.7480, 3.5929, 3.5253],\n",
      "        [3.6472, 3.9951, 3.9512, 3.8562, 3.7765],\n",
      "        [3.5023, 3.5345, 3.8399, 3.5316, 3.6477],\n",
      "        [3.5181, 3.7096, 3.6986, 3.7243, 3.5991],\n",
      "        [3.3492, 3.4762, 3.6690, 3.5153, 3.4165],\n",
      "        [3.9894, 4.1361, 3.9106, 3.9240, 3.7508],\n",
      "        [4.0382, 4.1479, 4.2768, 4.3838, 4.0794],\n",
      "        [3.6689, 3.8996, 3.8953, 3.9677, 3.7914],\n",
      "        [3.7294, 3.9067, 3.8889, 3.9168, 3.8258],\n",
      "        [3.4106, 3.5085, 3.7005, 3.6057, 3.4706],\n",
      "        [3.5810, 3.6554, 3.8938, 3.7361, 3.6795],\n",
      "        [3.3905, 3.9504, 3.9560, 3.7545, 3.5534],\n",
      "        [3.6405, 3.9993, 3.9489, 3.8582, 3.7693],\n",
      "        [3.5607, 3.9029, 4.0863, 3.9314, 3.7128],\n",
      "        [3.3570, 3.5794, 3.6544, 3.5047, 3.4963],\n",
      "        [3.4581, 3.9066, 3.8731, 3.7799, 3.7856],\n",
      "        [3.5079, 3.5845, 3.8000, 3.6283, 3.5563],\n",
      "        [3.6203, 3.7257, 3.8418, 3.7331, 3.6666],\n",
      "        [3.5543, 3.9975, 3.8650, 3.7749, 3.8630],\n",
      "        [3.3774, 3.6364, 3.7531, 3.5809, 3.5084]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5517, 3.6167, 3.8458, 3.6702, 3.6520],\n",
      "        [3.7565, 3.8378, 4.0911, 4.0604, 3.6887],\n",
      "        [3.6680, 3.8994, 3.8946, 3.9673, 3.7925],\n",
      "        [4.0344, 4.1380, 4.2252, 4.3441, 3.9047],\n",
      "        [3.5312, 3.8735, 3.7819, 3.5694, 3.6518],\n",
      "        [3.9992, 4.1118, 4.1769, 4.2995, 4.0467],\n",
      "        [4.0019, 4.0285, 4.1896, 4.2763, 4.0632],\n",
      "        [3.6478, 3.7383, 3.9848, 3.8395, 3.6809],\n",
      "        [3.6195, 3.7253, 3.8409, 3.7326, 3.6676],\n",
      "        [3.6197, 3.8935, 3.9581, 3.8751, 3.6882],\n",
      "        [3.7358, 3.9651, 4.0695, 3.8568, 3.5814],\n",
      "        [3.4559, 3.6239, 3.8076, 3.7252, 3.5803],\n",
      "        [3.9840, 4.1297, 4.1618, 4.2955, 4.0501],\n",
      "        [3.6435, 3.7136, 3.8449, 3.7614, 3.6380],\n",
      "        [3.6771, 3.9383, 4.0056, 3.9013, 3.8330],\n",
      "        [3.5423, 3.6375, 3.9145, 3.6163, 3.7743],\n",
      "        [3.3790, 3.6675, 3.7630, 3.5795, 3.5241],\n",
      "        [3.4147, 3.6213, 3.6690, 3.5785, 3.5285],\n",
      "        [3.5389, 3.6977, 3.7508, 3.7660, 3.6271],\n",
      "        [3.5061, 3.6699, 3.7708, 3.6538, 3.5987],\n",
      "        [3.5033, 3.9132, 3.9396, 3.7993, 3.8289],\n",
      "        [3.5393, 3.7327, 3.7922, 3.7791, 3.6735],\n",
      "        [3.6458, 3.9669, 4.0225, 3.8667, 3.7003],\n",
      "        [3.5997, 3.6046, 3.8337, 3.7072, 3.6757],\n",
      "        [3.5249, 3.6130, 3.8271, 3.6919, 3.6056],\n",
      "        [3.5568, 3.7644, 3.9329, 3.9043, 3.6348],\n",
      "        [3.4848, 3.6922, 3.7015, 3.6771, 3.5816],\n",
      "        [3.5127, 3.7070, 3.7039, 3.7140, 3.5993],\n",
      "        [3.5983, 3.7216, 3.8249, 3.7196, 3.6567],\n",
      "        [3.5590, 3.6751, 3.8549, 3.6024, 3.7061],\n",
      "        [3.5503, 3.5587, 3.7969, 3.7011, 3.7097],\n",
      "        [3.6529, 3.8812, 3.8756, 3.8049, 3.7230],\n",
      "        [3.3776, 3.6513, 3.7553, 3.5780, 3.5153],\n",
      "        [3.4773, 3.6020, 3.8302, 3.6855, 3.5935],\n",
      "        [3.5462, 3.5579, 3.7834, 3.6007, 3.5299],\n",
      "        [3.7263, 3.7989, 4.0486, 3.8636, 3.5867],\n",
      "        [3.5566, 4.0027, 4.0188, 3.7891, 3.6171],\n",
      "        [3.6366, 3.6767, 3.8797, 3.6663, 3.6433],\n",
      "        [3.4173, 3.4949, 3.6944, 3.6243, 3.4733],\n",
      "        [3.5462, 3.5875, 3.7330, 3.6321, 3.6408],\n",
      "        [3.6295, 3.6896, 3.9132, 3.7804, 3.7931],\n",
      "        [3.5030, 3.6322, 3.8757, 3.7080, 3.6285],\n",
      "        [3.7975, 4.0054, 3.9088, 3.7704, 3.6985],\n",
      "        [4.0694, 4.1565, 4.2578, 4.3733, 3.9256],\n",
      "        [3.3717, 3.5557, 3.6868, 3.6118, 3.4763],\n",
      "        [3.7287, 3.9060, 3.8880, 3.9164, 3.8268],\n",
      "        [3.5478, 3.7045, 3.7906, 3.6432, 3.5284],\n",
      "        [3.3830, 3.6818, 3.7757, 3.5959, 3.5453],\n",
      "        [3.7818, 3.8541, 3.9837, 3.9073, 3.8986],\n",
      "        [3.6742, 3.8901, 3.8951, 3.8436, 3.7163],\n",
      "        [3.4280, 3.6780, 3.6756, 3.6717, 3.5463],\n",
      "        [3.5312, 3.6678, 3.8475, 3.7370, 3.6373],\n",
      "        [3.9134, 3.9696, 4.1622, 4.1585, 3.9203],\n",
      "        [3.5007, 3.6213, 3.9414, 3.5363, 3.7543],\n",
      "        [3.7214, 3.7457, 3.9702, 3.9366, 3.6591],\n",
      "        [3.5329, 3.6964, 3.7487, 3.7076, 3.6398],\n",
      "        [3.6975, 3.8072, 4.0067, 3.8073, 3.6098],\n",
      "        [3.6700, 3.7164, 3.8150, 3.9221, 3.7536],\n",
      "        [3.4302, 3.5956, 3.6826, 3.6256, 3.5098],\n",
      "        [3.6290, 3.7086, 3.7896, 3.8288, 3.6895],\n",
      "        [3.5112, 3.6910, 3.7655, 3.6595, 3.6168],\n",
      "        [3.4232, 3.5004, 3.6974, 3.6186, 3.4717],\n",
      "        [3.5312, 3.8233, 3.8693, 3.6541, 3.6979],\n",
      "        [3.7683, 3.6956, 3.8829, 4.1056, 3.8773]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4254, 3.6052, 3.7816, 3.6236, 3.5207],\n",
      "        [3.6032, 3.9736, 4.0196, 3.8383, 3.6648],\n",
      "        [3.3722, 3.6322, 3.7197, 3.6235, 3.4915],\n",
      "        [3.5013, 3.6326, 3.8245, 3.7077, 3.6018],\n",
      "        [3.7968, 4.0051, 3.9083, 3.7705, 3.6992],\n",
      "        [3.4478, 3.5431, 3.8174, 3.6453, 3.5623],\n",
      "        [3.5167, 3.8321, 3.8795, 3.6379, 3.6862],\n",
      "        [3.4059, 3.7338, 3.8318, 3.6372, 3.5520],\n",
      "        [3.8194, 4.0837, 4.0042, 4.0239, 4.0227],\n",
      "        [3.5400, 3.6739, 3.8299, 3.7069, 3.7431],\n",
      "        [3.5852, 3.6138, 3.8474, 3.7421, 3.6309],\n",
      "        [3.7072, 3.6754, 3.8350, 4.0429, 3.8085],\n",
      "        [3.4206, 3.9041, 3.7723, 3.6243, 3.6951],\n",
      "        [3.4006, 3.6572, 3.7661, 3.5998, 3.5496],\n",
      "        [3.5423, 3.8904, 3.9740, 3.9026, 3.6300],\n",
      "        [3.5551, 3.6256, 3.8491, 3.6756, 3.6581],\n",
      "        [3.6652, 3.8970, 3.8926, 3.9659, 3.7898],\n",
      "        [3.9305, 4.1621, 4.2551, 4.2041, 4.2253],\n",
      "        [3.5816, 3.6529, 3.9081, 3.7700, 3.6927],\n",
      "        [3.5626, 4.0000, 3.9300, 3.8937, 3.8417],\n",
      "        [3.4340, 3.6218, 3.6826, 3.6540, 3.5159],\n",
      "        [3.5983, 3.6765, 3.9279, 3.7835, 3.6985],\n",
      "        [3.5559, 3.8177, 3.8658, 3.7074, 3.6976],\n",
      "        [3.7614, 3.8731, 4.0574, 4.0273, 3.7440],\n",
      "        [3.4539, 3.6027, 3.7777, 3.6670, 3.5178],\n",
      "        [3.5774, 3.8438, 3.8376, 3.7421, 3.6537],\n",
      "        [3.5239, 3.6297, 3.9201, 3.5930, 3.7529],\n",
      "        [3.5722, 3.6759, 3.8518, 3.6231, 3.4596],\n",
      "        [3.3826, 3.6453, 3.7567, 3.5812, 3.5138],\n",
      "        [3.6634, 3.8747, 3.8896, 3.8781, 3.7324],\n",
      "        [3.4620, 3.8201, 3.8605, 3.7430, 3.8083],\n",
      "        [3.5303, 3.8231, 3.8687, 3.6542, 3.6987],\n",
      "        [3.7364, 3.9343, 4.0747, 3.9395, 3.9391],\n",
      "        [3.5239, 3.5143, 3.7021, 3.6167, 3.6753],\n",
      "        [3.5552, 3.8209, 3.8065, 3.7233, 3.6256],\n",
      "        [3.6626, 3.6949, 3.8751, 3.6546, 3.5071],\n",
      "        [3.5257, 3.7150, 3.7003, 3.7309, 3.5978],\n",
      "        [3.5081, 3.5819, 3.8224, 3.6805, 3.5865],\n",
      "        [3.6556, 4.0282, 4.0347, 3.8845, 3.8619],\n",
      "        [3.3977, 3.5786, 3.7189, 3.5750, 3.5180],\n",
      "        [3.8880, 3.8042, 4.0535, 4.0669, 3.8374],\n",
      "        [3.3756, 3.6360, 3.7517, 3.5806, 3.5101],\n",
      "        [3.9181, 3.9542, 4.0879, 4.1137, 3.9375],\n",
      "        [3.6537, 3.6864, 3.8720, 3.7747, 3.6384],\n",
      "        [3.4477, 3.7548, 3.6836, 3.6824, 3.5190],\n",
      "        [3.4959, 3.6165, 3.8322, 3.7149, 3.6847],\n",
      "        [3.3260, 3.5421, 3.6236, 3.4665, 3.4629],\n",
      "        [3.3376, 3.5528, 3.5728, 3.5099, 3.4189],\n",
      "        [3.6835, 3.9359, 3.9342, 3.8923, 3.7630],\n",
      "        [3.4842, 3.9542, 3.7988, 3.6765, 3.7677],\n",
      "        [3.5183, 3.7808, 3.8586, 3.7270, 3.6369],\n",
      "        [3.5176, 3.6111, 3.8191, 3.6870, 3.6013],\n",
      "        [3.4284, 3.6227, 3.6688, 3.5905, 3.5302],\n",
      "        [3.4627, 3.6336, 3.7012, 3.6629, 3.5728],\n",
      "        [3.5227, 3.5699, 3.7076, 3.6070, 3.6307],\n",
      "        [3.3555, 3.8093, 3.8564, 3.6824, 3.4958],\n",
      "        [3.5496, 3.5774, 3.8447, 3.7177, 3.7172],\n",
      "        [3.5185, 3.8383, 3.8855, 3.6214, 3.7084],\n",
      "        [3.5106, 3.5697, 3.7854, 3.6220, 3.5420],\n",
      "        [3.6442, 3.7294, 3.7090, 3.8154, 3.7607],\n",
      "        [3.5646, 3.6151, 3.7854, 3.6736, 3.6726],\n",
      "        [3.4842, 3.6494, 3.7719, 3.6722, 3.6445],\n",
      "        [3.5160, 3.6806, 3.7377, 3.6866, 3.6248],\n",
      "        [3.6373, 3.7659, 3.9307, 3.7730, 3.7043]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5401, 3.7079, 3.7646, 3.7711, 3.6355],\n",
      "        [3.4104, 3.6196, 3.7900, 3.6259, 3.5256],\n",
      "        [3.3444, 3.6533, 3.5636, 3.6206, 3.4311],\n",
      "        [3.7039, 3.7599, 4.0910, 4.0545, 3.6969],\n",
      "        [3.4854, 4.0354, 4.0438, 3.7532, 3.6304],\n",
      "        [3.7778, 3.6631, 3.8705, 3.8002, 3.7467],\n",
      "        [3.8727, 4.0982, 4.0293, 4.0723, 4.0789],\n",
      "        [3.4152, 3.5306, 3.7172, 3.6039, 3.4896],\n",
      "        [3.5456, 3.5685, 3.8305, 3.7085, 3.7118],\n",
      "        [3.6886, 3.9770, 3.9463, 3.8731, 3.7754],\n",
      "        [3.3375, 3.5602, 3.6353, 3.4810, 3.4751],\n",
      "        [3.5643, 3.6854, 3.9594, 3.7808, 3.7043],\n",
      "        [3.6348, 3.8724, 3.9406, 3.8098, 3.8218],\n",
      "        [3.5625, 3.7037, 3.7882, 3.6648, 3.6394],\n",
      "        [3.7279, 3.9127, 3.8866, 3.9306, 3.9365],\n",
      "        [3.6774, 3.9107, 3.9157, 3.8818, 3.7491],\n",
      "        [3.7800, 3.8536, 3.9826, 3.9072, 3.8998],\n",
      "        [3.4153, 3.4945, 3.6933, 3.6241, 3.4743],\n",
      "        [3.4274, 3.5410, 3.6142, 3.6493, 3.4364],\n",
      "        [3.4022, 3.8805, 3.8833, 3.7778, 3.7074],\n",
      "        [3.5534, 3.8275, 3.8432, 3.6902, 3.6815],\n",
      "        [3.6616, 3.6910, 3.8321, 3.9198, 3.7400],\n",
      "        [3.3852, 3.6866, 3.7711, 3.5896, 3.5439],\n",
      "        [3.8811, 4.0966, 4.0295, 4.0627, 4.0800],\n",
      "        [3.5406, 3.7341, 3.9863, 3.7946, 3.7719],\n",
      "        [4.0672, 4.1574, 4.2576, 4.3735, 3.9267],\n",
      "        [3.5926, 3.6744, 3.9170, 3.7750, 3.7040],\n",
      "        [3.5226, 3.9676, 3.8394, 3.7541, 3.8321],\n",
      "        [3.5781, 3.9780, 3.8400, 3.7798, 3.8536],\n",
      "        [3.4259, 3.5278, 3.7156, 3.6146, 3.4928],\n",
      "        [3.4344, 3.9202, 3.9353, 3.7832, 3.6766],\n",
      "        [3.6907, 3.9799, 3.9764, 3.8717, 3.7977],\n",
      "        [3.8373, 3.8942, 4.0494, 4.0440, 3.8439],\n",
      "        [3.4494, 3.5923, 3.7660, 3.6827, 3.5111],\n",
      "        [3.6608, 3.8599, 4.0044, 3.8232, 3.7312],\n",
      "        [3.5288, 3.6136, 3.8324, 3.6932, 3.6087],\n",
      "        [3.5570, 3.6742, 3.8534, 3.6020, 3.7072],\n",
      "        [3.3530, 3.5709, 3.6402, 3.5040, 3.4852],\n",
      "        [3.6649, 3.8315, 3.8695, 3.7978, 3.7777],\n",
      "        [3.7296, 3.9706, 4.1134, 3.9777, 3.9599],\n",
      "        [3.7534, 3.9730, 4.0055, 3.9722, 4.0126],\n",
      "        [3.5096, 3.5693, 3.7848, 3.6217, 3.5423],\n",
      "        [3.9125, 4.0837, 3.9059, 3.8725, 3.7559],\n",
      "        [3.4119, 3.6206, 3.7775, 3.6283, 3.5155],\n",
      "        [3.4745, 3.7449, 3.9311, 3.7779, 3.5586],\n",
      "        [3.5285, 3.5940, 3.8514, 3.6984, 3.6109],\n",
      "        [3.6713, 3.9831, 3.9279, 3.8732, 3.7657],\n",
      "        [3.6939, 3.7858, 3.9424, 3.8445, 3.8493],\n",
      "        [3.6458, 3.5613, 3.9843, 3.7967, 3.6862],\n",
      "        [3.5150, 3.6803, 3.7372, 3.6864, 3.6252],\n",
      "        [3.5517, 3.5675, 3.8250, 3.7077, 3.7131],\n",
      "        [3.4542, 3.6475, 3.6733, 3.6221, 3.5443],\n",
      "        [3.5916, 4.0397, 3.9053, 3.9501, 3.8080],\n",
      "        [3.6955, 3.8068, 4.0057, 3.8071, 3.6109],\n",
      "        [3.5235, 3.6646, 3.8503, 3.7340, 3.6334],\n",
      "        [3.4382, 3.5952, 3.6771, 3.6409, 3.5144],\n",
      "        [3.5143, 3.6861, 3.8093, 3.7006, 3.6737],\n",
      "        [3.6835, 3.9060, 3.9704, 3.9733, 3.7505],\n",
      "        [3.6389, 3.8740, 3.8652, 3.9308, 3.7509],\n",
      "        [3.9941, 3.9646, 4.1796, 4.2146, 3.9880],\n",
      "        [3.3032, 3.5157, 3.6062, 3.4383, 3.4324],\n",
      "        [3.4762, 3.4981, 3.7769, 3.6565, 3.6149],\n",
      "        [3.5482, 3.5460, 3.7672, 3.6832, 3.7068],\n",
      "        [3.4988, 3.6975, 3.7040, 3.6956, 3.5958]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8364, 3.8943, 4.0486, 4.0445, 3.8437],\n",
      "        [3.5238, 3.7148, 3.6990, 3.7308, 3.5981],\n",
      "        [3.5075, 3.6099, 3.8061, 3.6831, 3.5954],\n",
      "        [3.3904, 3.6016, 3.7518, 3.5992, 3.5211],\n",
      "        [3.8241, 3.6017, 3.8954, 4.1376, 4.0301],\n",
      "        [3.7918, 3.9669, 4.1204, 4.1223, 4.1338],\n",
      "        [3.2885, 3.5345, 3.6907, 3.5256, 3.4977],\n",
      "        [3.5831, 3.6586, 3.8880, 3.7376, 3.6935],\n",
      "        [3.5892, 3.7527, 3.8831, 3.8145, 3.7345],\n",
      "        [3.5767, 3.7143, 3.8029, 3.6876, 3.6502],\n",
      "        [3.5946, 4.0233, 3.9388, 3.9355, 3.8469],\n",
      "        [3.5230, 3.6649, 3.8494, 3.7255, 3.6359],\n",
      "        [3.8638, 3.7815, 4.0446, 4.3593, 4.1673],\n",
      "        [3.3298, 3.5503, 3.6297, 3.4708, 3.4746],\n",
      "        [3.5035, 3.6201, 3.9214, 3.5636, 3.7429],\n",
      "        [3.8073, 3.9608, 4.0026, 3.9219, 3.8758],\n",
      "        [3.7261, 3.8234, 4.0016, 3.9093, 3.6488],\n",
      "        [3.3448, 3.7192, 3.9084, 3.5805, 3.6261],\n",
      "        [3.5313, 3.6519, 3.9337, 3.8114, 3.6886],\n",
      "        [3.5761, 3.6722, 3.8278, 3.6884, 3.8100],\n",
      "        [3.5287, 3.7618, 3.8571, 3.7147, 3.6916],\n",
      "        [3.4558, 3.8888, 3.8887, 3.6623, 3.4949],\n",
      "        [3.3871, 3.6074, 3.7423, 3.5914, 3.5249],\n",
      "        [3.3822, 3.6734, 3.7670, 3.5866, 3.5349],\n",
      "        [3.7612, 3.9390, 4.0802, 3.8703, 3.6644],\n",
      "        [3.5633, 3.6854, 3.9586, 3.7809, 3.7041],\n",
      "        [3.9752, 4.1295, 4.0774, 4.1552, 4.1574],\n",
      "        [3.5423, 3.6385, 3.8987, 3.7351, 3.6722],\n",
      "        [3.5540, 3.8178, 3.8645, 3.7074, 3.6977],\n",
      "        [3.3294, 3.7176, 3.7024, 3.4359, 3.5421],\n",
      "        [3.3878, 3.5956, 3.6557, 3.5461, 3.5069],\n",
      "        [3.3117, 3.5691, 3.6922, 3.5550, 3.5098],\n",
      "        [3.6930, 3.7152, 3.9438, 3.9115, 3.6239],\n",
      "        [3.4300, 3.6853, 3.8791, 3.6817, 3.6691],\n",
      "        [3.5562, 3.6624, 3.9150, 3.7170, 3.7515],\n",
      "        [3.5141, 3.6804, 3.7364, 3.6865, 3.6251],\n",
      "        [3.6747, 3.8511, 4.0290, 3.7996, 3.6113],\n",
      "        [3.6436, 4.0485, 4.0386, 3.9037, 3.9258],\n",
      "        [3.7537, 3.7956, 3.9154, 3.9141, 3.8810],\n",
      "        [3.3762, 3.6670, 3.7610, 3.5795, 3.5251],\n",
      "        [3.5203, 3.7663, 3.8639, 3.7256, 3.6596],\n",
      "        [3.4209, 3.7087, 3.6393, 3.6614, 3.5037],\n",
      "        [3.7198, 4.0376, 4.0096, 4.0135, 3.8595],\n",
      "        [3.7450, 3.5511, 3.7380, 3.7284, 3.7201],\n",
      "        [3.5676, 3.6243, 3.8201, 3.6983, 3.6736],\n",
      "        [3.6059, 3.6526, 3.9339, 3.8215, 3.7013],\n",
      "        [3.6081, 3.9498, 3.9325, 3.8445, 3.8416],\n",
      "        [3.4093, 3.4893, 3.6881, 3.6116, 3.4632],\n",
      "        [3.7025, 3.8775, 4.0001, 3.9005, 3.7312],\n",
      "        [3.9162, 3.9545, 4.0869, 4.1139, 3.9378],\n",
      "        [3.3748, 3.6829, 3.7642, 3.5806, 3.5317],\n",
      "        [3.5819, 3.6612, 3.9087, 3.7588, 3.6852],\n",
      "        [3.4010, 3.4743, 3.6766, 3.6028, 3.4529],\n",
      "        [3.5389, 3.7212, 3.8254, 3.7208, 3.6759],\n",
      "        [3.3705, 3.6092, 3.7415, 3.5759, 3.5001],\n",
      "        [3.6046, 3.6629, 3.9400, 3.9316, 3.9042],\n",
      "        [3.4266, 3.7535, 3.9076, 3.6482, 3.6786],\n",
      "        [3.5846, 3.7909, 3.9866, 3.8172, 3.7547],\n",
      "        [4.0348, 4.1579, 3.8854, 3.9420, 3.7391],\n",
      "        [3.6551, 3.9673, 3.8861, 3.6747, 3.7400],\n",
      "        [3.5682, 3.6391, 3.8541, 3.7421, 3.6593],\n",
      "        [3.7659, 3.6044, 3.8992, 4.0611, 3.9589],\n",
      "        [3.5432, 3.5574, 3.7813, 3.6006, 3.5308],\n",
      "        [3.5175, 3.7555, 3.9314, 3.9262, 3.5725]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5154, 3.6842, 3.7295, 3.6838, 3.6273],\n",
      "        [3.5048, 3.9689, 3.8550, 3.8796, 3.7396],\n",
      "        [3.6742, 3.7791, 4.0949, 3.7872, 3.5603],\n",
      "        [3.7756, 3.9964, 4.0160, 3.7792, 3.8346],\n",
      "        [3.7898, 3.9619, 4.1121, 4.1254, 4.1251],\n",
      "        [3.4132, 3.5314, 3.7152, 3.6039, 3.4891],\n",
      "        [3.4661, 3.6298, 3.7070, 3.5973, 3.5408],\n",
      "        [3.6927, 3.9143, 3.9724, 3.9084, 3.7541],\n",
      "        [3.4517, 3.6245, 3.8046, 3.7250, 3.5809],\n",
      "        [3.8286, 3.8905, 4.0439, 4.0425, 3.8338],\n",
      "        [3.4018, 3.9327, 3.9341, 3.7620, 3.6794],\n",
      "        [3.3691, 3.5950, 3.6569, 3.5332, 3.5079],\n",
      "        [3.7232, 3.8159, 4.0200, 3.8841, 3.6208],\n",
      "        [3.3946, 3.5463, 3.6814, 3.5746, 3.5063],\n",
      "        [3.5995, 3.8681, 3.9300, 3.7815, 3.5672],\n",
      "        [3.3792, 3.6761, 3.7380, 3.6433, 3.5188],\n",
      "        [3.4817, 3.8580, 3.7855, 3.5538, 3.6825],\n",
      "        [3.4492, 3.6508, 3.6773, 3.6218, 3.5632],\n",
      "        [3.6282, 3.8737, 4.0220, 3.9256, 3.8054],\n",
      "        [3.5146, 3.6116, 3.8166, 3.6867, 3.6012],\n",
      "        [3.5842, 3.6689, 3.9312, 3.8888, 3.8693],\n",
      "        [3.5051, 3.6174, 3.8077, 3.6863, 3.5961],\n",
      "        [3.4247, 3.6120, 3.8033, 3.6988, 3.6043],\n",
      "        [3.3484, 3.5707, 3.6391, 3.4995, 3.4867],\n",
      "        [3.5169, 3.7276, 3.8388, 3.7588, 3.7130],\n",
      "        [3.8231, 3.6023, 3.8942, 4.1375, 4.0299],\n",
      "        [3.5451, 3.6430, 3.9014, 3.7371, 3.6761],\n",
      "        [3.5931, 3.8939, 3.8810, 3.8145, 3.8116],\n",
      "        [3.6990, 4.0791, 4.0354, 4.0537, 3.9258],\n",
      "        [3.6012, 3.9027, 3.8589, 3.9041, 3.7376],\n",
      "        [3.7117, 3.6617, 3.8392, 4.0774, 3.8226],\n",
      "        [3.7605, 3.8866, 4.0707, 3.9560, 3.9488],\n",
      "        [3.7002, 3.9195, 4.0631, 3.9141, 3.9185],\n",
      "        [3.6454, 3.9618, 4.0661, 3.8819, 3.6987],\n",
      "        [4.0035, 3.9729, 4.1946, 4.2040, 4.0123],\n",
      "        [3.3754, 3.5183, 3.6880, 3.5568, 3.4538],\n",
      "        [3.7015, 3.8782, 3.9990, 3.9004, 3.7308],\n",
      "        [3.6684, 4.0786, 4.0485, 3.9216, 3.9014],\n",
      "        [3.5853, 3.5958, 3.8300, 3.7233, 3.5830],\n",
      "        [3.5323, 3.7414, 3.8453, 3.7721, 3.7180],\n",
      "        [3.4271, 3.6378, 3.6725, 3.6065, 3.5413],\n",
      "        [3.4171, 3.6283, 3.8047, 3.6460, 3.5046],\n",
      "        [3.5867, 3.6060, 3.8401, 3.7312, 3.5983],\n",
      "        [3.6805, 3.9370, 3.9319, 3.8922, 3.7629],\n",
      "        [3.5605, 3.8924, 3.8125, 3.8738, 3.7158],\n",
      "        [3.5823, 3.6142, 3.8449, 3.7418, 3.6308],\n",
      "        [3.7828, 4.0431, 3.9639, 3.9726, 4.0375],\n",
      "        [3.4106, 3.6157, 3.6424, 3.6116, 3.4728],\n",
      "        [3.6639, 3.9000, 3.8918, 3.9670, 3.7933],\n",
      "        [3.5677, 3.8344, 3.8356, 3.7101, 3.6699],\n",
      "        [3.4163, 3.5615, 3.6431, 3.6525, 3.4434],\n",
      "        [3.5802, 3.6071, 3.9653, 3.9185, 3.5523],\n",
      "        [3.4066, 3.4783, 3.6792, 3.6039, 3.4550],\n",
      "        [3.4994, 3.7714, 3.8365, 3.7587, 3.6683],\n",
      "        [3.6130, 3.9888, 3.9617, 3.8580, 3.8482],\n",
      "        [3.4687, 3.5971, 3.7592, 3.6944, 3.5250],\n",
      "        [3.6327, 3.8741, 3.9392, 3.8099, 3.8212],\n",
      "        [3.4761, 3.6697, 3.6829, 3.6559, 3.5775],\n",
      "        [3.5149, 3.7100, 3.6998, 3.7183, 3.5951],\n",
      "        [3.7824, 4.0617, 3.9643, 3.9867, 3.9571],\n",
      "        [3.4723, 4.0461, 4.0559, 3.8307, 3.6777],\n",
      "        [4.0570, 4.3073, 3.9762, 3.9691, 3.8312],\n",
      "        [3.3949, 3.5790, 3.7163, 3.5748, 3.5179],\n",
      "        [3.7930, 3.8618, 4.0058, 4.0513, 4.0216]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3681, 3.5961, 3.6556, 3.5328, 3.5073],\n",
      "        [3.5404, 3.6402, 3.8961, 3.7344, 3.6712],\n",
      "        [4.0597, 4.1596, 4.2435, 4.3726, 3.9138],\n",
      "        [3.4781, 3.5320, 3.7864, 3.6383, 3.5478],\n",
      "        [3.5945, 3.6779, 3.9238, 3.7826, 3.6978],\n",
      "        [3.5635, 3.6760, 3.8261, 3.6943, 3.7882],\n",
      "        [3.5842, 3.9671, 4.0427, 3.8959, 3.8624],\n",
      "        [3.6739, 3.9032, 3.9926, 3.8936, 3.7807],\n",
      "        [3.5124, 3.7111, 3.6939, 3.7231, 3.6004],\n",
      "        [3.5415, 3.6781, 3.8284, 3.7086, 3.7452],\n",
      "        [3.5509, 3.6021, 3.8672, 3.7492, 3.7311],\n",
      "        [3.3996, 3.5615, 3.7256, 3.5950, 3.5077],\n",
      "        [3.8223, 3.9744, 3.9773, 3.9605, 3.9159],\n",
      "        [3.5133, 3.7078, 3.6986, 3.7212, 3.5983],\n",
      "        [3.4090, 3.8648, 3.8851, 3.8004, 3.7187],\n",
      "        [3.6293, 3.7263, 3.8335, 3.7535, 3.6610],\n",
      "        [3.4297, 3.6937, 3.8752, 3.7202, 3.6982],\n",
      "        [3.5921, 3.8953, 3.8797, 3.8141, 3.8109],\n",
      "        [3.5209, 3.6669, 3.8468, 3.7249, 3.6349],\n",
      "        [3.3256, 3.5730, 3.6573, 3.5552, 3.4812],\n",
      "        [3.6564, 3.7571, 3.7489, 3.8418, 3.7760],\n",
      "        [3.8291, 4.0654, 3.9763, 3.8238, 3.8043],\n",
      "        [3.4349, 3.6790, 3.8687, 3.7002, 3.6887],\n",
      "        [3.3782, 3.6831, 3.7710, 3.5954, 3.5453],\n",
      "        [3.6576, 3.7559, 3.7505, 3.8353, 3.7589],\n",
      "        [3.3763, 3.5797, 3.7246, 3.5752, 3.4937],\n",
      "        [3.3935, 3.9441, 3.9385, 3.7539, 3.6517],\n",
      "        [3.7341, 3.9864, 3.8998, 3.8051, 3.7352],\n",
      "        [3.3264, 3.9707, 3.9295, 3.7326, 3.5607],\n",
      "        [3.9909, 3.9680, 4.1773, 4.2147, 3.9870],\n",
      "        [3.5062, 3.6281, 3.8241, 3.7085, 3.6126],\n",
      "        [3.5737, 3.6520, 3.8900, 3.7457, 3.6755],\n",
      "        [3.3687, 3.6570, 3.7572, 3.5873, 3.5202],\n",
      "        [3.4967, 3.5355, 3.8347, 3.5302, 3.6484],\n",
      "        [3.5934, 3.6890, 3.9399, 3.7848, 3.7016],\n",
      "        [3.4905, 3.6820, 3.8322, 3.5952, 3.6429],\n",
      "        [3.7245, 3.9049, 3.8830, 3.9159, 3.8264],\n",
      "        [3.7253, 3.7865, 3.9888, 3.9100, 3.6013],\n",
      "        [3.6443, 3.9631, 4.0648, 3.8814, 3.6980],\n",
      "        [3.3074, 3.5276, 3.6085, 3.4442, 3.4405],\n",
      "        [3.5040, 3.6186, 3.8063, 3.6858, 3.5954],\n",
      "        [3.4608, 4.0244, 3.8538, 3.6884, 3.7786],\n",
      "        [3.4616, 3.6068, 3.5798, 3.7080, 3.4660],\n",
      "        [3.8011, 3.8167, 3.9584, 3.8890, 3.9196],\n",
      "        [3.6962, 3.8754, 3.8946, 3.7830, 3.7243],\n",
      "        [3.4604, 3.6618, 3.6840, 3.6264, 3.5761],\n",
      "        [3.7411, 3.8749, 4.0324, 4.0121, 3.7385],\n",
      "        [3.6252, 3.6908, 3.9087, 3.7798, 3.7932],\n",
      "        [3.4346, 3.9955, 3.8239, 3.6654, 3.7520],\n",
      "        [3.6860, 3.8982, 4.0063, 3.8695, 3.7830],\n",
      "        [4.1853, 4.3774, 4.1226, 4.0723, 3.8888],\n",
      "        [3.8223, 3.8789, 4.0404, 4.0126, 3.8281],\n",
      "        [3.4323, 3.6597, 3.8276, 3.6578, 3.5343],\n",
      "        [3.6628, 3.9012, 3.8904, 3.9666, 3.7927],\n",
      "        [3.5415, 3.5458, 3.7480, 3.6677, 3.6995],\n",
      "        [3.5647, 3.6417, 3.8400, 3.7356, 3.6569],\n",
      "        [3.4711, 3.6705, 3.6811, 3.6491, 3.5684],\n",
      "        [3.3989, 3.4761, 3.6741, 3.6022, 3.4519],\n",
      "        [3.6344, 3.7661, 3.8158, 3.7474, 3.6533],\n",
      "        [3.3742, 3.6949, 3.7728, 3.5827, 3.5409],\n",
      "        [3.6702, 3.7016, 3.9191, 3.8258, 3.6671],\n",
      "        [3.4555, 3.7612, 3.9220, 3.8359, 3.5357],\n",
      "        [3.4502, 3.6671, 3.6863, 3.6137, 3.5944],\n",
      "        [3.2864, 3.5362, 3.6881, 3.5251, 3.4968]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5020, 3.6963, 3.8561, 3.7389, 3.6824],\n",
      "        [3.3701, 3.7234, 3.7774, 3.6574, 3.7124],\n",
      "        [3.5791, 3.6148, 3.8472, 3.7107, 3.6667],\n",
      "        [3.7986, 3.9458, 4.1015, 3.9058, 3.6754],\n",
      "        [3.5457, 3.8836, 3.9104, 3.7425, 3.5351],\n",
      "        [3.3386, 3.4495, 3.6514, 3.6084, 3.4387],\n",
      "        [3.4271, 3.5511, 3.7331, 3.6177, 3.4806],\n",
      "        [3.5515, 3.6244, 3.8800, 3.7222, 3.6672],\n",
      "        [3.5113, 3.7122, 3.6925, 3.7224, 3.5997],\n",
      "        [3.3926, 3.5492, 3.7160, 3.5906, 3.4898],\n",
      "        [4.1790, 4.4407, 4.0955, 4.1355, 3.9090],\n",
      "        [3.4074, 3.7266, 3.7884, 3.6086, 3.5852],\n",
      "        [3.6597, 3.9320, 3.9960, 3.8914, 3.8271],\n",
      "        [3.5038, 3.6171, 3.8153, 3.6996, 3.6040],\n",
      "        [3.9347, 3.8393, 4.0162, 4.0010, 3.9306],\n",
      "        [3.9533, 3.9771, 3.9859, 4.0848, 4.0267],\n",
      "        [3.8155, 3.6030, 3.9035, 4.1227, 4.0063],\n",
      "        [3.5612, 3.6687, 3.9226, 3.8962, 3.8640],\n",
      "        [3.5727, 3.6767, 3.8311, 3.7617, 3.6467],\n",
      "        [3.7227, 3.8845, 4.0090, 4.0024, 3.7346],\n",
      "        [3.7571, 4.0908, 4.0303, 4.0232, 3.9480],\n",
      "        [3.5055, 3.5722, 3.7796, 3.6205, 3.5404],\n",
      "        [3.5142, 3.6665, 3.7692, 3.6696, 3.6219],\n",
      "        [3.4080, 3.6246, 3.6670, 3.5709, 3.5289],\n",
      "        [3.5968, 3.6889, 3.9396, 3.7853, 3.7036],\n",
      "        [3.3707, 3.6210, 3.6766, 3.5970, 3.4967],\n",
      "        [4.2565, 4.4529, 4.1841, 4.1446, 3.9511],\n",
      "        [3.7160, 3.8450, 3.9990, 3.9059, 3.6730],\n",
      "        [3.5718, 3.8480, 3.8410, 3.7299, 3.6611],\n",
      "        [3.4639, 3.6705, 3.6797, 3.6499, 3.5635],\n",
      "        [3.5689, 3.8756, 3.9169, 3.7591, 3.5467],\n",
      "        [3.3860, 3.5489, 3.6788, 3.5636, 3.4964],\n",
      "        [3.7619, 4.0107, 4.0987, 3.8964, 3.6474],\n",
      "        [3.3213, 3.5445, 3.6181, 3.4654, 3.4614],\n",
      "        [3.5191, 3.6320, 3.9143, 3.5912, 3.7511],\n",
      "        [3.6334, 3.7672, 3.8142, 3.7467, 3.6526],\n",
      "        [3.6338, 3.8949, 3.8976, 3.9286, 3.7423],\n",
      "        [3.5615, 3.8322, 3.8366, 3.7015, 3.6733],\n",
      "        [3.9432, 3.9719, 3.9764, 4.0729, 4.0227],\n",
      "        [3.3849, 3.6992, 3.7730, 3.6009, 3.5536],\n",
      "        [3.4952, 4.0673, 4.0667, 3.8380, 3.6940],\n",
      "        [3.6669, 3.9603, 4.0005, 3.8912, 3.8686],\n",
      "        [3.2181, 3.4835, 3.6578, 3.4684, 3.4621],\n",
      "        [3.7923, 3.6678, 3.8501, 3.8075, 3.7753],\n",
      "        [3.5007, 3.5868, 3.7928, 3.6264, 3.5564],\n",
      "        [3.9111, 4.0204, 4.1397, 4.2064, 3.8202],\n",
      "        [3.7883, 3.9310, 4.0681, 3.9640, 3.7824],\n",
      "        [3.4334, 3.9967, 3.8223, 3.6648, 3.7512],\n",
      "        [3.9755, 4.0104, 4.1899, 4.2572, 4.0099],\n",
      "        [3.9598, 3.8668, 4.0131, 4.0282, 3.9335],\n",
      "        [3.6945, 3.7622, 3.8947, 3.7702, 3.5451],\n",
      "        [3.5480, 3.8336, 3.8036, 3.7207, 3.6277],\n",
      "        [3.6418, 3.8606, 3.9357, 3.7935, 3.5900],\n",
      "        [3.4041, 3.5894, 3.7364, 3.5950, 3.5229],\n",
      "        [3.5847, 3.6083, 3.8372, 3.7300, 3.5969],\n",
      "        [3.4145, 3.6845, 3.8689, 3.6756, 3.6624],\n",
      "        [3.4840, 3.5200, 3.7843, 3.6677, 3.6208],\n",
      "        [3.5331, 3.8667, 3.7756, 3.8387, 3.6883],\n",
      "        [3.5873, 4.0439, 3.9007, 3.9491, 3.8060],\n",
      "        [3.6638, 3.9237, 3.9969, 3.8971, 3.8110],\n",
      "        [3.6903, 3.7888, 3.9374, 3.8435, 3.8475],\n",
      "        [3.7315, 4.0140, 3.9161, 3.9169, 3.9783],\n",
      "        [3.5359, 3.7111, 3.7597, 3.7702, 3.6336],\n",
      "        [3.6037, 3.9144, 3.8902, 3.8275, 3.8254]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5321, 3.7368, 3.7847, 3.7779, 3.6718],\n",
      "        [3.6619, 3.8098, 4.0074, 3.7879, 3.6267],\n",
      "        [3.6164, 3.8493, 3.8692, 3.8206, 3.7111],\n",
      "        [3.7422, 4.0037, 3.9127, 3.8261, 3.7475],\n",
      "        [3.5932, 3.6077, 3.8255, 3.7056, 3.6739],\n",
      "        [3.2984, 3.5198, 3.5998, 3.4372, 3.4297],\n",
      "        [3.5565, 3.6179, 3.8673, 3.7171, 3.6634],\n",
      "        [3.5879, 3.7164, 3.8087, 3.6878, 3.6601],\n",
      "        [3.6054, 3.9808, 4.0086, 3.8377, 3.6694],\n",
      "        [3.3721, 3.6712, 3.7551, 3.5781, 3.5224],\n",
      "        [3.4083, 3.5127, 3.6962, 3.6058, 3.4738],\n",
      "        [3.7254, 3.9029, 3.9869, 3.7821, 3.7690],\n",
      "        [4.0543, 4.2429, 4.0051, 3.9694, 3.7854],\n",
      "        [3.4345, 3.6392, 3.6621, 3.6054, 3.5355],\n",
      "        [3.4372, 3.6158, 3.7843, 3.7066, 3.5701],\n",
      "        [3.6661, 3.9884, 3.9216, 3.8720, 3.7628],\n",
      "        [3.4749, 3.7535, 3.9244, 3.8231, 3.5580],\n",
      "        [3.2938, 3.5026, 3.5587, 3.5065, 3.4070],\n",
      "        [3.4527, 3.7552, 3.9993, 3.7097, 3.7798],\n",
      "        [3.5149, 3.7183, 3.7025, 3.7237, 3.6063],\n",
      "        [3.6188, 3.6133, 3.8004, 3.6953, 3.6809],\n",
      "        [3.5805, 3.6136, 3.8346, 3.7261, 3.6157],\n",
      "        [3.5597, 3.8482, 3.8213, 3.7305, 3.6405],\n",
      "        [3.9478, 4.0555, 4.1482, 4.2432, 3.8238],\n",
      "        [3.4074, 3.6194, 3.6380, 3.6104, 3.4705],\n",
      "        [3.8565, 3.7418, 3.9319, 4.2563, 3.9833],\n",
      "        [3.4534, 3.6616, 3.6784, 3.6343, 3.5654],\n",
      "        [3.3953, 3.6204, 3.6632, 3.5574, 3.5296],\n",
      "        [3.5193, 3.7281, 3.7035, 3.7369, 3.6091],\n",
      "        [3.7919, 4.0085, 3.9009, 3.7692, 3.6966],\n",
      "        [3.5519, 3.6064, 3.7391, 3.6441, 3.6583],\n",
      "        [3.6671, 3.8950, 3.8880, 3.8424, 3.7145],\n",
      "        [3.6650, 4.0829, 4.0439, 3.9203, 3.8989],\n",
      "        [3.6947, 3.7695, 3.8914, 3.7713, 3.5323],\n",
      "        [3.5896, 3.9246, 3.8426, 3.6268, 3.7178],\n",
      "        [3.4599, 3.5453, 3.7280, 3.5048, 3.5789],\n",
      "        [3.6147, 3.6168, 3.8179, 3.7048, 3.6823],\n",
      "        [3.4578, 3.5982, 3.7864, 3.6464, 3.5676],\n",
      "        [3.4533, 3.7648, 3.9198, 3.8351, 3.5340],\n",
      "        [3.5822, 3.5994, 3.8256, 3.7219, 3.5806],\n",
      "        [3.6545, 3.7589, 3.7457, 3.8410, 3.7742],\n",
      "        [3.7096, 3.9883, 3.9205, 3.8164, 3.7432],\n",
      "        [3.3278, 3.5631, 3.5443, 3.5809, 3.4383],\n",
      "        [3.4981, 3.6945, 3.6926, 3.6797, 3.5987],\n",
      "        [3.5681, 3.6346, 3.9051, 3.7952, 3.7509],\n",
      "        [3.7125, 3.8058, 4.0522, 3.8472, 3.5391],\n",
      "        [3.7494, 3.8927, 3.9966, 3.9133, 3.9463],\n",
      "        [3.4620, 3.6729, 3.6791, 3.6560, 3.5595],\n",
      "        [3.7246, 3.6797, 3.8437, 4.0861, 3.8327],\n",
      "        [3.9654, 4.0728, 4.0741, 4.2710, 4.0066],\n",
      "        [3.5046, 3.6423, 3.8187, 3.7037, 3.6019],\n",
      "        [3.6867, 3.8427, 3.9582, 3.7683, 3.7455],\n",
      "        [3.4160, 3.5046, 3.6899, 3.6171, 3.4699],\n",
      "        [3.3862, 3.6059, 3.7460, 3.5978, 3.5184],\n",
      "        [3.5729, 3.7184, 3.7967, 3.6861, 3.6474],\n",
      "        [3.3147, 3.5403, 3.6154, 3.4564, 3.4510],\n",
      "        [3.7912, 3.8590, 3.9744, 3.9491, 3.9483],\n",
      "        [3.5189, 3.7982, 3.8869, 3.7456, 3.6301],\n",
      "        [3.4194, 3.4960, 3.6887, 3.6168, 3.4666],\n",
      "        [3.4833, 3.6019, 3.7488, 3.7155, 3.5385],\n",
      "        [3.9422, 3.9733, 3.9748, 4.0727, 4.0217],\n",
      "        [3.7736, 3.9680, 3.9636, 3.9223, 3.8983],\n",
      "        [3.3395, 3.6577, 3.5573, 3.6198, 3.4285],\n",
      "        [3.4526, 3.7010, 3.7459, 3.5437, 3.5110]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5625, 3.6459, 3.8349, 3.7341, 3.6541],\n",
      "        [3.4592, 3.7586, 3.8804, 3.6744, 3.6921],\n",
      "        [4.0991, 4.2808, 4.0329, 3.9913, 3.8071],\n",
      "        [3.5960, 3.8744, 3.9241, 3.7796, 3.5638],\n",
      "        [3.5393, 3.6786, 3.7523, 3.6257, 3.6179],\n",
      "        [3.5454, 4.0032, 3.8543, 3.7728, 3.8606],\n",
      "        [3.8155, 3.8965, 4.1093, 4.1305, 3.7653],\n",
      "        [3.4509, 3.8968, 3.8825, 3.6604, 3.4909],\n",
      "        [3.5589, 3.7102, 3.8069, 3.6806, 3.5301],\n",
      "        [3.6148, 3.5986, 3.7778, 3.6825, 3.6686],\n",
      "        [3.9543, 4.1244, 3.9066, 3.9055, 3.7626],\n",
      "        [3.9695, 4.0886, 4.1381, 4.2376, 3.9685],\n",
      "        [3.9449, 3.9769, 3.9552, 4.0629, 4.0349],\n",
      "        [3.5129, 3.6339, 3.8175, 3.7032, 3.5994],\n",
      "        [3.6426, 4.0127, 3.9521, 3.8803, 3.7824],\n",
      "        [3.4943, 3.6992, 3.6971, 3.6936, 3.5956],\n",
      "        [4.0178, 3.8304, 4.0953, 4.4254, 4.2527],\n",
      "        [3.4232, 3.5502, 3.6111, 3.6496, 3.4532],\n",
      "        [3.9475, 4.0579, 4.1468, 4.2426, 3.8227],\n",
      "        [3.7299, 3.9423, 4.0669, 3.9377, 3.9351],\n",
      "        [3.3275, 3.5649, 3.5426, 3.5804, 3.4374],\n",
      "        [3.6453, 3.8882, 3.8667, 3.8031, 3.7202],\n",
      "        [3.6369, 3.8623, 3.9296, 3.7910, 3.5859],\n",
      "        [3.5683, 3.8437, 3.8291, 3.7236, 3.6535],\n",
      "        [3.3324, 3.5661, 3.6271, 3.4795, 3.4714],\n",
      "        [3.5349, 3.7409, 3.9774, 3.7926, 3.7679],\n",
      "        [3.6793, 3.7779, 3.7465, 3.8538, 3.7978],\n",
      "        [3.6564, 3.6971, 3.8236, 3.9180, 3.7365],\n",
      "        [3.5310, 3.6741, 3.9134, 3.8448, 3.8252],\n",
      "        [3.9294, 3.8932, 4.0038, 4.1147, 3.8866],\n",
      "        [3.6490, 4.0351, 4.0258, 3.8824, 3.8583],\n",
      "        [3.4067, 3.6278, 3.6637, 3.5702, 3.5270],\n",
      "        [3.6405, 3.9739, 3.8556, 3.8348, 3.8937],\n",
      "        [3.5403, 3.6594, 3.9082, 3.7501, 3.6753],\n",
      "        [3.4464, 3.6598, 3.6692, 3.6236, 3.5500],\n",
      "        [3.5487, 3.6699, 3.8364, 3.6034, 3.4387],\n",
      "        [3.9629, 3.9205, 4.1323, 4.1857, 3.9417],\n",
      "        [3.5183, 3.5191, 3.6926, 3.6147, 3.6717],\n",
      "        [3.4011, 3.8898, 3.8807, 3.7801, 3.6973],\n",
      "        [3.2561, 3.8122, 3.7953, 3.6806, 3.4807],\n",
      "        [3.5930, 3.6095, 3.8237, 3.7050, 3.6729],\n",
      "        [3.5153, 4.0076, 3.8677, 3.9121, 3.7663],\n",
      "        [3.4103, 3.5753, 3.7395, 3.6117, 3.4802],\n",
      "        [3.4602, 3.9483, 3.8917, 3.8755, 3.7198],\n",
      "        [3.3555, 3.7128, 3.8704, 3.6081, 3.6407],\n",
      "        [3.5616, 3.6766, 3.8223, 3.6929, 3.7850],\n",
      "        [3.6901, 3.8137, 3.9977, 3.8052, 3.6070],\n",
      "        [3.4227, 3.5504, 3.7240, 3.6144, 3.4756],\n",
      "        [3.3549, 3.5835, 3.6426, 3.5046, 3.4907],\n",
      "        [3.6680, 3.7615, 4.0106, 3.7851, 3.4757],\n",
      "        [3.5218, 3.6253, 3.8210, 3.6920, 3.6102],\n",
      "        [3.8631, 3.7463, 3.9296, 4.2497, 3.9894],\n",
      "        [3.3835, 3.6016, 3.6484, 3.5443, 3.5034],\n",
      "        [3.5577, 3.6318, 3.8458, 3.7074, 3.6595],\n",
      "        [3.4574, 3.6001, 3.7846, 3.6458, 3.5666],\n",
      "        [3.4574, 3.6485, 3.7152, 3.7136, 3.5763],\n",
      "        [3.6602, 3.9059, 3.8856, 3.9651, 3.7900],\n",
      "        [3.7910, 3.8609, 3.9726, 3.9485, 3.9473],\n",
      "        [3.3597, 3.5551, 3.6090, 3.6168, 3.4295],\n",
      "        [3.6786, 3.7508, 3.8898, 3.7451, 3.8138],\n",
      "        [3.5419, 3.9910, 3.9003, 3.8861, 3.8085],\n",
      "        [3.5809, 3.7770, 3.8988, 3.8510, 3.6977],\n",
      "        [3.4037, 3.6117, 3.7598, 3.6173, 3.5005],\n",
      "        [3.7103, 3.7108, 3.8593, 3.6975, 3.5715]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4989, 3.5914, 3.7876, 3.6245, 3.5532],\n",
      "        [3.6771, 3.8549, 3.8749, 3.7101, 3.6918],\n",
      "        [3.4812, 3.6242, 3.7668, 3.7026, 3.5438],\n",
      "        [3.6423, 3.7828, 3.7777, 3.7727, 3.7589],\n",
      "        [3.6334, 3.8778, 3.8520, 3.9236, 3.7411],\n",
      "        [3.6999, 3.8751, 3.9679, 3.7624, 3.7483],\n",
      "        [3.8056, 3.8756, 4.0047, 4.0632, 4.0256],\n",
      "        [3.5159, 3.7319, 3.8685, 3.7718, 3.6612],\n",
      "        [3.6195, 3.9055, 3.8511, 3.7827, 3.7101],\n",
      "        [3.8118, 3.8934, 4.0410, 4.0038, 3.8291],\n",
      "        [3.5907, 3.7695, 3.8738, 3.8037, 3.7396],\n",
      "        [3.6828, 3.7606, 4.0495, 4.0166, 3.6820],\n",
      "        [3.4954, 3.7798, 3.8298, 3.7559, 3.6635],\n",
      "        [3.5274, 3.7407, 3.7110, 3.7545, 3.6203],\n",
      "        [3.3226, 3.5788, 3.6508, 3.5527, 3.4773],\n",
      "        [3.5788, 3.9063, 3.9765, 3.8694, 3.6446],\n",
      "        [3.3659, 3.6381, 3.7384, 3.5762, 3.4992],\n",
      "        [3.3795, 3.6941, 3.7607, 3.5871, 3.5389],\n",
      "        [3.4773, 3.7383, 3.7183, 3.7789, 3.5522],\n",
      "        [3.2834, 3.5503, 3.6796, 3.5237, 3.4791],\n",
      "        [3.5464, 3.5747, 3.8147, 3.7046, 3.7080],\n",
      "        [3.8718, 3.7895, 4.0150, 4.0431, 3.8089],\n",
      "        [3.5339, 3.8083, 3.8423, 3.7568, 3.6888],\n",
      "        [3.6101, 3.6250, 4.0448, 3.8010, 3.7428],\n",
      "        [3.3855, 3.6092, 3.7425, 3.5964, 3.5162],\n",
      "        [3.6319, 3.6351, 4.0490, 3.8295, 3.7589],\n",
      "        [3.7510, 3.6102, 3.7428, 3.7131, 3.7764],\n",
      "        [3.5801, 3.6074, 3.9496, 3.9137, 3.5602],\n",
      "        [3.6844, 3.7565, 3.8952, 3.7408, 3.8167],\n",
      "        [3.3699, 3.6212, 3.7311, 3.5723, 3.4983],\n",
      "        [3.4289, 3.6268, 3.6568, 3.6476, 3.4816],\n",
      "        [3.3272, 3.5663, 3.5410, 3.5796, 3.4362],\n",
      "        [3.7366, 3.6822, 3.8497, 4.1270, 3.8501],\n",
      "        [3.6983, 3.7671, 3.9021, 3.7647, 3.5635],\n",
      "        [3.8715, 3.9627, 4.0907, 4.0918, 3.8948],\n",
      "        [3.8784, 3.9623, 4.0956, 4.0839, 3.9082],\n",
      "        [3.9228, 3.8662, 4.0752, 4.1111, 3.8771],\n",
      "        [3.8453, 3.9723, 3.9670, 3.9701, 3.9352],\n",
      "        [3.5335, 3.6816, 3.8194, 3.7038, 3.7382],\n",
      "        [3.5689, 3.8532, 3.8376, 3.7380, 3.6595],\n",
      "        [3.5326, 3.6441, 3.9028, 3.6127, 3.7576],\n",
      "        [3.4670, 3.5648, 3.7444, 3.5214, 3.5899],\n",
      "        [3.5785, 3.6211, 3.8371, 3.7388, 3.6262],\n",
      "        [3.8050, 3.6108, 3.8852, 4.1231, 4.0071],\n",
      "        [3.4086, 3.6380, 3.8143, 3.7163, 3.6120],\n",
      "        [3.6226, 3.6966, 3.9019, 3.7773, 3.7893],\n",
      "        [3.6890, 3.9217, 3.9642, 3.9055, 3.7494],\n",
      "        [3.5145, 3.6019, 3.8179, 3.6824, 3.5867],\n",
      "        [3.6360, 3.7809, 3.7720, 3.7670, 3.7469],\n",
      "        [3.5095, 3.7169, 3.6877, 3.7208, 3.5966],\n",
      "        [3.4149, 3.8947, 3.7437, 3.6282, 3.6894],\n",
      "        [3.6612, 3.8134, 4.0040, 3.7863, 3.6245],\n",
      "        [3.6836, 3.8364, 4.0011, 3.7946, 3.5443],\n",
      "        [3.7349, 3.5430, 3.7198, 3.7253, 3.7076],\n",
      "        [3.5157, 3.6088, 3.8165, 3.6852, 3.5924],\n",
      "        [3.4235, 3.8795, 3.9510, 3.7260, 3.7917],\n",
      "        [3.3823, 3.6150, 3.7330, 3.5886, 3.5200],\n",
      "        [3.5487, 3.7764, 3.9256, 3.9021, 3.6307],\n",
      "        [3.7080, 3.6688, 3.8312, 4.0747, 3.8183],\n",
      "        [3.6304, 3.9992, 3.9343, 3.8662, 3.7665],\n",
      "        [3.7317, 3.9928, 3.8940, 3.8027, 3.7310],\n",
      "        [3.9518, 3.9981, 4.0455, 4.0988, 3.9989],\n",
      "        [3.5136, 3.5673, 3.6956, 3.7599, 3.5035],\n",
      "        [3.4198, 3.5056, 3.6887, 3.6077, 3.4764]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5252, 3.6653, 3.8299, 3.7239, 3.6337],\n",
      "        [3.4687, 3.7680, 3.9251, 3.8285, 3.5469],\n",
      "        [3.5002, 3.7631, 3.8327, 3.6991, 3.6444],\n",
      "        [4.1435, 4.4037, 4.0479, 4.0536, 3.9047],\n",
      "        [3.7954, 3.9521, 3.9607, 3.9240, 3.8917],\n",
      "        [3.5939, 3.9279, 3.8900, 3.8252, 3.8252],\n",
      "        [3.5076, 3.6976, 3.8004, 3.6968, 3.6679],\n",
      "        [3.4262, 3.8790, 3.8759, 3.8218, 3.7456],\n",
      "        [3.5950, 3.8770, 3.9207, 3.7776, 3.5621],\n",
      "        [3.9390, 3.8828, 3.9630, 4.0092, 3.9426],\n",
      "        [3.5210, 3.7302, 3.6942, 3.7351, 3.6049],\n",
      "        [3.5992, 3.6719, 3.9287, 3.9277, 3.8991],\n",
      "        [3.4718, 3.6616, 3.7167, 3.5358, 3.5433],\n",
      "        [3.5410, 3.6507, 3.8913, 3.7329, 3.6709],\n",
      "        [3.5004, 3.6256, 3.7980, 3.6822, 3.5910],\n",
      "        [3.2993, 3.5351, 3.6026, 3.4403, 3.4371],\n",
      "        [3.7148, 4.0840, 4.0758, 3.9408, 3.9068],\n",
      "        [3.3806, 3.9581, 3.9373, 3.7455, 3.5477],\n",
      "        [3.3850, 3.6102, 3.7407, 3.5954, 3.5157],\n",
      "        [3.3234, 3.7266, 3.6916, 3.4320, 3.5366],\n",
      "        [3.4807, 3.6252, 3.7649, 3.7016, 3.5433],\n",
      "        [3.7791, 4.0511, 3.9481, 3.9735, 4.0377],\n",
      "        [3.4481, 3.5564, 3.8110, 3.6486, 3.5568],\n",
      "        [3.3655, 3.6638, 3.7486, 3.5841, 3.5158],\n",
      "        [3.5886, 3.9035, 3.8714, 3.8109, 3.8064],\n",
      "        [3.5657, 3.6380, 3.8451, 3.7304, 3.6449],\n",
      "        [3.5112, 3.7901, 3.8465, 3.7229, 3.6313],\n",
      "        [3.3483, 3.5870, 3.6408, 3.5009, 3.4930],\n",
      "        [3.4126, 3.4922, 3.6731, 3.6112, 3.4639],\n",
      "        [3.4955, 3.6189, 3.8268, 3.7111, 3.6648],\n",
      "        [3.5590, 3.6261, 3.8179, 3.6970, 3.6574],\n",
      "        [3.5279, 3.9039, 3.9060, 3.7271, 3.5232],\n",
      "        [3.5045, 3.7153, 3.6919, 3.7100, 3.5953],\n",
      "        [3.5335, 3.7169, 3.7528, 3.7676, 3.6299],\n",
      "        [3.5212, 3.7302, 3.6953, 3.7502, 3.6099],\n",
      "        [3.5098, 3.6860, 3.8278, 3.5943, 3.6639],\n",
      "        [3.5246, 3.7386, 3.6992, 3.7456, 3.6147],\n",
      "        [3.4151, 3.9085, 3.8424, 3.8297, 3.7309],\n",
      "        [3.5154, 3.7330, 3.8669, 3.7708, 3.6607],\n",
      "        [3.4049, 3.5331, 3.6965, 3.6008, 3.4810],\n",
      "        [3.9418, 3.9775, 3.9696, 4.0702, 4.0188],\n",
      "        [3.4469, 3.6329, 3.7949, 3.7210, 3.5758],\n",
      "        [3.6775, 3.8994, 3.8885, 3.8222, 3.7162],\n",
      "        [3.4271, 3.6162, 3.7782, 3.7012, 3.5678],\n",
      "        [3.6148, 3.5127, 3.9517, 3.7659, 3.6376],\n",
      "        [3.2553, 3.8144, 3.7917, 3.6785, 3.4792],\n",
      "        [3.5550, 3.6924, 3.8521, 3.6206, 3.4485],\n",
      "        [3.6222, 3.6975, 3.9000, 3.7762, 3.7887],\n",
      "        [3.7605, 3.7041, 3.8701, 4.1018, 3.8736],\n",
      "        [3.7477, 3.8463, 3.9574, 3.8718, 3.8704],\n",
      "        [3.4250, 3.6871, 3.8278, 3.5634, 3.6846],\n",
      "        [3.5054, 3.6540, 3.8194, 3.7166, 3.6077],\n",
      "        [3.4081, 3.6232, 3.7955, 3.7039, 3.5874],\n",
      "        [3.7769, 4.0240, 4.0706, 3.9953, 3.9015],\n",
      "        [3.4529, 3.5329, 3.7138, 3.6274, 3.4807],\n",
      "        [3.5970, 3.9106, 3.8490, 3.9003, 3.7323],\n",
      "        [3.5233, 3.7017, 3.7321, 3.7048, 3.6357],\n",
      "        [3.6979, 3.7680, 3.9003, 3.7636, 3.5630],\n",
      "        [3.5084, 3.6412, 3.8127, 3.6960, 3.6056],\n",
      "        [3.6615, 3.8285, 3.9743, 3.8968, 3.8706],\n",
      "        [3.3043, 3.5341, 3.6002, 3.4412, 3.4362],\n",
      "        [3.4144, 3.8957, 3.7418, 3.6272, 3.6888],\n",
      "        [3.6809, 3.9823, 3.9255, 3.8023, 3.7463],\n",
      "        [3.5196, 3.7212, 3.8523, 3.7512, 3.6819]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4400, 3.9697, 3.8957, 3.9017, 3.7141],\n",
      "        [3.4804, 3.7498, 3.7171, 3.7768, 3.5540],\n",
      "        [3.5093, 3.7152, 3.6887, 3.7174, 3.5934],\n",
      "        [3.5621, 3.8462, 3.8314, 3.6983, 3.6727],\n",
      "        [3.4171, 3.6380, 3.6415, 3.6514, 3.5233],\n",
      "        [3.4322, 3.7581, 3.8402, 3.5871, 3.6536],\n",
      "        [3.4869, 3.8515, 3.8739, 3.6814, 3.7188],\n",
      "        [3.4947, 3.7001, 3.6761, 3.6988, 3.5721],\n",
      "        [3.9184, 3.8533, 4.0595, 4.1016, 3.8640],\n",
      "        [3.6079, 3.9989, 3.9499, 3.8537, 3.8423],\n",
      "        [3.5060, 3.5642, 3.8280, 3.5587, 3.6459],\n",
      "        [3.5652, 3.6386, 3.8430, 3.7300, 3.6443],\n",
      "        [3.3535, 3.5864, 3.6371, 3.5024, 3.4885],\n",
      "        [3.5765, 3.6208, 3.8379, 3.7074, 3.6623],\n",
      "        [3.9924, 4.0426, 4.1782, 4.2729, 4.0580],\n",
      "        [3.6804, 3.9831, 3.9236, 3.8018, 3.7456],\n",
      "        [3.6211, 3.7722, 3.8735, 3.7516, 3.7841],\n",
      "        [3.6830, 3.8887, 3.8903, 3.7955, 3.7133],\n",
      "        [3.7420, 3.6219, 3.7299, 3.7089, 3.7717],\n",
      "        [3.3768, 3.7291, 3.6187, 3.6583, 3.4819],\n",
      "        [3.4729, 3.7596, 3.9187, 3.8202, 3.5547],\n",
      "        [3.6331, 3.8418, 3.9969, 3.8722, 3.7856],\n",
      "        [3.2690, 3.5379, 3.6794, 3.5051, 3.4942],\n",
      "        [3.5040, 3.6165, 3.7950, 3.6764, 3.5906],\n",
      "        [3.8139, 3.9007, 4.1049, 4.1281, 3.7630],\n",
      "        [3.5447, 3.6687, 3.9111, 3.7541, 3.6769],\n",
      "        [3.6997, 3.8954, 3.8573, 3.8965, 3.8108],\n",
      "        [3.6037, 3.9866, 4.0016, 3.8348, 3.6662],\n",
      "        [3.4487, 3.8890, 3.8866, 3.7560, 3.7858],\n",
      "        [3.6687, 3.8613, 4.0162, 3.7949, 3.6051],\n",
      "        [3.3644, 3.6033, 3.6453, 3.5294, 3.5024],\n",
      "        [3.5219, 3.8827, 3.7666, 3.5650, 3.6464],\n",
      "        [4.0079, 3.9466, 4.0904, 4.1253, 4.0475],\n",
      "        [3.5881, 3.9044, 3.8694, 3.8105, 3.8058],\n",
      "        [3.4814, 3.6069, 3.7415, 3.7127, 3.5353],\n",
      "        [3.7571, 3.9762, 3.9935, 3.7700, 3.8046],\n",
      "        [3.5896, 3.7714, 3.8702, 3.8022, 3.7384],\n",
      "        [3.6261, 3.7194, 3.8347, 3.7694, 3.7427],\n",
      "        [3.5777, 3.6675, 3.8746, 3.7328, 3.6873],\n",
      "        [3.3896, 3.5556, 3.7071, 3.5875, 3.4855],\n",
      "        [3.6013, 3.9616, 3.9180, 3.8374, 3.8352],\n",
      "        [3.4532, 3.6669, 3.6668, 3.6275, 3.5546],\n",
      "        [3.4759, 3.7149, 3.9566, 3.7358, 3.7368],\n",
      "        [3.4657, 3.5579, 3.7258, 3.5075, 3.5837],\n",
      "        [3.8717, 3.9587, 4.0940, 4.0960, 3.8997],\n",
      "        [3.5551, 3.6339, 3.8508, 3.7310, 3.6548],\n",
      "        [3.8690, 3.9615, 4.1311, 4.1577, 3.9197],\n",
      "        [3.4423, 3.6020, 3.7521, 3.6787, 3.5051],\n",
      "        [3.4941, 3.9511, 3.8682, 3.8319, 3.7852],\n",
      "        [3.3821, 3.6046, 3.6430, 3.5421, 3.5011],\n",
      "        [3.3499, 3.5870, 3.6340, 3.5121, 3.4921],\n",
      "        [3.5148, 3.8359, 3.8582, 3.6353, 3.6924],\n",
      "        [3.9414, 3.9782, 3.9675, 4.0698, 4.0182],\n",
      "        [3.4245, 3.6877, 3.8257, 3.5630, 3.6839],\n",
      "        [3.3374, 3.5693, 3.6229, 3.4868, 3.4770],\n",
      "        [3.5527, 3.6292, 3.8509, 3.7266, 3.6439],\n",
      "        [3.9618, 3.9238, 4.1266, 4.1838, 3.9398],\n",
      "        [3.3929, 3.5438, 3.7012, 3.5869, 3.4796],\n",
      "        [3.8461, 3.9664, 3.9554, 3.9611, 3.9356],\n",
      "        [3.6931, 3.8860, 3.9665, 3.8129, 3.5982],\n",
      "        [3.3791, 3.6263, 3.7428, 3.5917, 3.5178],\n",
      "        [3.5285, 3.6214, 3.8272, 3.6886, 3.6063],\n",
      "        [3.6471, 3.9954, 4.0092, 3.8820, 3.9063],\n",
      "        [3.3712, 3.6076, 3.6895, 3.6112, 3.4784]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4458, 3.9013, 3.8308, 3.7642, 3.7409],\n",
      "        [3.8169, 3.8850, 4.0242, 3.9862, 3.6941],\n",
      "        [3.4984, 3.6526, 3.7139, 3.6133, 3.5850],\n",
      "        [3.4739, 3.5393, 3.7742, 3.6344, 3.5420],\n",
      "        [3.6631, 3.9684, 3.9891, 3.8881, 3.8632],\n",
      "        [3.5709, 3.8328, 3.8223, 3.7306, 3.6966],\n",
      "        [3.3714, 3.5924, 3.5952, 3.5556, 3.4461],\n",
      "        [3.7078, 3.8823, 3.9849, 3.9827, 3.7259],\n",
      "        [3.4680, 3.5995, 3.7790, 3.6355, 3.5598],\n",
      "        [3.5230, 3.7700, 3.9316, 3.9208, 3.5820],\n",
      "        [3.4653, 3.5665, 3.7382, 3.5199, 3.5878],\n",
      "        [3.8192, 3.9254, 4.1633, 4.1448, 3.7624],\n",
      "        [3.6016, 3.8797, 3.9071, 3.8489, 3.6769],\n",
      "        [3.4397, 3.5517, 3.8011, 3.6406, 3.5558],\n",
      "        [3.5468, 3.7792, 3.9207, 3.9009, 3.6288],\n",
      "        [3.6852, 3.7345, 3.9458, 3.8607, 3.7007],\n",
      "        [3.7837, 3.8518, 3.9873, 3.9168, 3.9084],\n",
      "        [3.6405, 4.0167, 3.9444, 3.8781, 3.7791],\n",
      "        [3.4565, 3.7214, 3.7463, 3.7394, 3.5667],\n",
      "        [3.3304, 3.7311, 3.8924, 3.5806, 3.6133],\n",
      "        [3.4544, 3.5697, 3.8145, 3.6603, 3.5636],\n",
      "        [3.5721, 3.8573, 3.8287, 3.7361, 3.6522],\n",
      "        [3.5503, 3.6351, 3.8655, 3.7156, 3.6603],\n",
      "        [3.3857, 3.5628, 3.7066, 3.5807, 3.4851],\n",
      "        [3.4300, 3.6211, 3.6488, 3.6364, 3.4827],\n",
      "        [3.3031, 3.5351, 3.5961, 3.4410, 3.4347],\n",
      "        [3.9436, 4.0721, 4.1867, 4.2673, 3.9842],\n",
      "        [3.3943, 3.7684, 3.9358, 3.7022, 3.6613],\n",
      "        [3.4180, 3.5098, 3.6850, 3.6220, 3.4785],\n",
      "        [3.3758, 3.6829, 3.7514, 3.5826, 3.5279],\n",
      "        [3.5092, 3.7189, 3.6865, 3.7142, 3.5888],\n",
      "        [3.5220, 3.8327, 3.8512, 3.6496, 3.6914],\n",
      "        [3.8172, 4.0426, 3.8880, 3.8354, 3.7410],\n",
      "        [3.7571, 3.8594, 3.9908, 3.9425, 3.6819],\n",
      "        [3.5292, 3.6034, 3.8279, 3.6289, 3.6446],\n",
      "        [3.9717, 4.0193, 4.1805, 4.2544, 4.0045],\n",
      "        [3.4163, 3.5457, 3.6025, 3.6498, 3.4731],\n",
      "        [3.5621, 3.8448, 3.8228, 3.7061, 3.6631],\n",
      "        [4.0881, 4.2790, 4.0931, 4.0244, 3.9019],\n",
      "        [3.7223, 3.6851, 3.8342, 4.0834, 3.8287],\n",
      "        [3.5334, 3.5857, 3.8258, 3.7147, 3.7031],\n",
      "        [3.6931, 3.8625, 4.0082, 3.9418, 3.8984],\n",
      "        [3.4487, 3.9882, 3.9026, 3.9215, 3.7273],\n",
      "        [3.4944, 3.7066, 3.6811, 3.7060, 3.5812],\n",
      "        [3.5142, 3.6111, 3.8071, 3.6806, 3.5921],\n",
      "        [3.5322, 3.7179, 3.7486, 3.7673, 3.6284],\n",
      "        [3.4213, 3.9059, 3.8891, 3.7685, 3.6727],\n",
      "        [3.5552, 3.9011, 3.7984, 3.8696, 3.7090],\n",
      "        [3.8497, 3.9264, 4.0523, 4.0580, 3.7549],\n",
      "        [3.4832, 3.9169, 3.9057, 3.7093, 3.5185],\n",
      "        [3.8175, 3.8691, 3.8389, 3.9182, 3.8509],\n",
      "        [3.7114, 4.0922, 3.9987, 3.8806, 4.0428],\n",
      "        [3.6940, 4.0090, 3.8919, 3.8805, 3.9448],\n",
      "        [3.9408, 3.9783, 3.9854, 4.0737, 4.0082],\n",
      "        [3.3943, 3.6116, 3.7298, 3.5884, 3.5203],\n",
      "        [3.3939, 3.4840, 3.6619, 3.5986, 3.4462],\n",
      "        [3.5104, 3.8469, 3.8668, 3.6164, 3.7010],\n",
      "        [3.4196, 3.5245, 3.6940, 3.6145, 3.4786],\n",
      "        [3.4854, 3.6414, 3.7173, 3.7130, 3.5554],\n",
      "        [3.7035, 3.7307, 3.8589, 4.0540, 3.8457],\n",
      "        [3.5465, 3.6735, 3.8291, 3.6011, 3.4355],\n",
      "        [3.3358, 3.5046, 3.6258, 3.4938, 3.4466],\n",
      "        [3.5498, 3.6399, 3.8705, 3.7564, 3.6739],\n",
      "        [3.7945, 3.9528, 3.9561, 3.9236, 3.8903]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6937, 3.9303, 4.0482, 3.9107, 3.9114],\n",
      "        [3.6084, 3.7517, 3.7443, 3.7674, 3.6597],\n",
      "        [3.6647, 4.0089, 3.9100, 3.8713, 3.7530],\n",
      "        [3.5775, 3.6186, 3.8232, 3.7236, 3.6114],\n",
      "        [3.3117, 3.5453, 3.6039, 3.4546, 3.4468],\n",
      "        [3.5706, 3.6636, 3.8732, 3.7313, 3.6744],\n",
      "        [3.4470, 3.9075, 3.8733, 3.6554, 3.4976],\n",
      "        [3.5393, 3.6960, 3.7973, 3.6799, 3.5193],\n",
      "        [3.3482, 3.6617, 3.8786, 3.5953, 3.6679],\n",
      "        [3.4988, 3.6523, 3.8103, 3.7083, 3.6025],\n",
      "        [3.6169, 3.9081, 3.8431, 3.7819, 3.7080],\n",
      "        [3.7397, 3.5513, 3.7137, 3.7315, 3.6975],\n",
      "        [3.3696, 3.6556, 3.7397, 3.5889, 3.5207],\n",
      "        [3.8604, 3.7500, 3.9198, 4.2481, 3.9866],\n",
      "        [3.6167, 3.5493, 3.9394, 3.7816, 3.6657],\n",
      "        [3.6705, 3.9265, 3.9031, 3.8707, 3.7464],\n",
      "        [3.4867, 3.7133, 3.6842, 3.6913, 3.5889],\n",
      "        [3.4444, 3.7757, 3.9229, 3.8386, 3.5464],\n",
      "        [3.6743, 3.9197, 3.9548, 3.9737, 3.7512],\n",
      "        [3.7451, 3.9055, 4.0498, 3.9600, 3.9365],\n",
      "        [3.2807, 3.5440, 3.6731, 3.5220, 3.4908],\n",
      "        [4.0537, 4.1709, 4.2312, 4.3697, 3.9074],\n",
      "        [3.8414, 3.8146, 4.0125, 4.0015, 3.7891],\n",
      "        [3.6204, 3.6984, 3.8935, 3.7765, 3.7872],\n",
      "        [3.4928, 3.6410, 3.8565, 3.7037, 3.6225],\n",
      "        [3.3813, 3.6717, 3.7155, 3.6479, 3.5023],\n",
      "        [3.6259, 3.8855, 3.9254, 3.8060, 3.8140],\n",
      "        [3.5160, 3.7332, 3.6923, 3.7347, 3.6050],\n",
      "        [3.2456, 3.8388, 3.8017, 3.6514, 3.4267],\n",
      "        [3.5052, 3.7797, 3.8471, 3.7213, 3.6296],\n",
      "        [3.4171, 3.5075, 3.6808, 3.6069, 3.4744],\n",
      "        [3.3417, 3.5777, 3.6249, 3.4923, 3.4878],\n",
      "        [3.6866, 3.9238, 3.9558, 3.9047, 3.7473],\n",
      "        [3.5330, 3.7502, 3.7025, 3.7590, 3.6205],\n",
      "        [3.5247, 3.7405, 3.7074, 3.7496, 3.6152],\n",
      "        [3.6937, 3.6261, 3.8800, 3.9593, 3.9044],\n",
      "        [3.3747, 3.6110, 3.6450, 3.5337, 3.5147],\n",
      "        [3.7115, 3.8849, 3.8700, 3.8325, 3.8175],\n",
      "        [3.5024, 3.6914, 3.7509, 3.6564, 3.6198],\n",
      "        [3.3932, 3.6232, 3.6505, 3.5538, 3.5264],\n",
      "        [3.8405, 3.7500, 3.9044, 4.2081, 3.9550],\n",
      "        [3.5154, 3.7328, 3.6979, 3.7314, 3.6125],\n",
      "        [4.0320, 4.1648, 3.8679, 3.9391, 3.7326],\n",
      "        [3.7239, 3.8151, 3.9792, 3.9067, 3.6177],\n",
      "        [3.3937, 3.8912, 3.8654, 3.7741, 3.7008],\n",
      "        [3.3764, 3.6569, 3.7387, 3.5848, 3.5215],\n",
      "        [3.5792, 3.6043, 3.8143, 3.7193, 3.5764],\n",
      "        [3.9965, 3.9851, 4.1808, 4.2011, 4.0055],\n",
      "        [3.6380, 3.6865, 3.8437, 3.6695, 3.4879],\n",
      "        [3.6651, 3.7091, 3.9040, 3.8220, 3.6609],\n",
      "        [3.6906, 3.7685, 3.8810, 3.7677, 3.5401],\n",
      "        [3.3981, 3.8935, 3.8708, 3.7782, 3.6941],\n",
      "        [3.6722, 4.0047, 3.9696, 3.8712, 3.7760],\n",
      "        [3.5486, 3.6825, 3.8332, 3.5973, 3.6996],\n",
      "        [3.5688, 3.6594, 3.8749, 3.7420, 3.6694],\n",
      "        [3.7356, 3.9364, 4.0590, 3.9671, 3.9290],\n",
      "        [3.4984, 3.9548, 3.8891, 3.8270, 3.8186],\n",
      "        [3.5606, 4.0656, 3.9867, 4.0332, 3.8140],\n",
      "        [3.4527, 3.6155, 3.7750, 3.6561, 3.5833],\n",
      "        [3.6232, 3.7323, 3.8209, 3.7446, 3.6565],\n",
      "        [3.3301, 3.5664, 3.5389, 3.5980, 3.4373],\n",
      "        [3.5409, 3.6029, 3.7204, 3.6366, 3.6493],\n",
      "        [3.6100, 3.7336, 3.8204, 3.7286, 3.6614],\n",
      "        [4.0074, 3.9197, 4.1251, 4.2004, 3.9743]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5520, 3.7707, 3.8876, 3.8598, 3.6493],\n",
      "        [3.3739, 3.6107, 3.6427, 3.5340, 3.5144],\n",
      "        [3.7390, 3.5509, 3.7115, 3.7319, 3.6972],\n",
      "        [3.5213, 3.7701, 3.9280, 3.9218, 3.5815],\n",
      "        [3.5192, 3.5754, 3.6929, 3.7631, 3.5066],\n",
      "        [3.7723, 3.9286, 4.0327, 3.9519, 4.0102],\n",
      "        [3.2483, 3.5197, 3.6658, 3.4860, 3.4771],\n",
      "        [3.6836, 3.9240, 3.9485, 3.8918, 3.7458],\n",
      "        [3.3681, 3.5270, 3.6696, 3.5541, 3.4471],\n",
      "        [3.4582, 3.6176, 3.5508, 3.7128, 3.4449],\n",
      "        [3.3700, 3.5871, 3.7074, 3.5725, 3.4874],\n",
      "        [3.3695, 3.6308, 3.6958, 3.6207, 3.4856],\n",
      "        [3.4040, 3.5115, 3.6775, 3.6113, 3.4643],\n",
      "        [3.4683, 3.5086, 3.8013, 3.4897, 3.6279],\n",
      "        [3.9713, 4.0978, 4.2095, 4.2866, 4.0070],\n",
      "        [3.5535, 3.6389, 3.8608, 3.7015, 3.6275],\n",
      "        [3.5294, 3.6454, 3.8919, 3.6119, 3.7551],\n",
      "        [3.3867, 3.5849, 3.7134, 3.5887, 3.5041],\n",
      "        [3.5529, 3.6224, 3.8530, 3.7148, 3.6587],\n",
      "        [3.4375, 3.9701, 3.8893, 3.9027, 3.7128],\n",
      "        [3.3666, 3.6228, 3.7205, 3.5719, 3.4959],\n",
      "        [3.5112, 3.6034, 3.8077, 3.6817, 3.5843],\n",
      "        [3.4436, 3.6132, 3.7296, 3.5904, 3.5488],\n",
      "        [3.4641, 3.6919, 3.8101, 3.5901, 3.6159],\n",
      "        [3.3204, 3.9886, 3.9254, 3.7275, 3.5486],\n",
      "        [3.4899, 3.6291, 3.9185, 3.5311, 3.7468],\n",
      "        [3.4647, 3.6710, 3.6608, 3.6607, 3.5460],\n",
      "        [3.9450, 4.0680, 4.1574, 4.2490, 3.9854],\n",
      "        [3.6562, 3.9091, 3.8734, 3.9636, 3.7862],\n",
      "        [3.8153, 3.8847, 4.0196, 3.9870, 3.6938],\n",
      "        [3.8221, 3.9003, 4.0259, 4.0407, 3.8276],\n",
      "        [3.7527, 3.9497, 4.0603, 3.8665, 3.6568],\n",
      "        [3.6010, 3.8287, 3.8864, 3.8271, 3.7249],\n",
      "        [3.8150, 3.9006, 4.0245, 4.0345, 3.8157],\n",
      "        [3.4806, 3.6304, 3.7211, 3.6029, 3.5940],\n",
      "        [3.4881, 3.6777, 3.7717, 3.6836, 3.6493],\n",
      "        [3.5144, 3.6152, 3.7999, 3.6857, 3.5988],\n",
      "        [3.5161, 3.6193, 3.8661, 3.7332, 3.6270],\n",
      "        [3.3456, 3.5876, 3.6322, 3.5015, 3.4911],\n",
      "        [3.4135, 3.7467, 3.8868, 3.7997, 3.4989],\n",
      "        [3.4145, 3.5340, 3.6945, 3.6100, 3.4834],\n",
      "        [3.3227, 3.6076, 3.6504, 3.5577, 3.4922],\n",
      "        [3.6864, 3.8174, 3.9856, 3.8036, 3.6033],\n",
      "        [3.9858, 3.9305, 4.0376, 4.0875, 3.9979],\n",
      "        [3.3982, 3.5174, 3.6785, 3.6019, 3.4653],\n",
      "        [3.7039, 3.9651, 4.0228, 3.9268, 3.7471],\n",
      "        [3.5597, 4.0654, 3.9845, 4.0335, 3.8136],\n",
      "        [3.5238, 3.8125, 3.8257, 3.7481, 3.6790],\n",
      "        [3.8224, 3.7429, 3.8760, 3.8910, 3.8552],\n",
      "        [3.7098, 4.0918, 3.9940, 3.8814, 4.0424],\n",
      "        [3.8656, 4.1069, 4.0075, 4.0692, 4.0708],\n",
      "        [3.4186, 3.6314, 3.6484, 3.5873, 3.5234],\n",
      "        [3.4305, 3.6274, 3.7722, 3.6541, 3.5051],\n",
      "        [3.6332, 3.8657, 3.9174, 3.7895, 3.5823],\n",
      "        [3.6562, 3.9091, 3.8734, 3.9636, 3.7862],\n",
      "        [3.5419, 3.6729, 3.9149, 3.7688, 3.6803],\n",
      "        [3.9104, 3.7982, 4.0255, 4.0266, 3.8558],\n",
      "        [3.7936, 3.9314, 4.0997, 3.9992, 3.9747],\n",
      "        [3.5451, 4.0148, 3.9986, 3.7859, 3.6103],\n",
      "        [4.0528, 4.1708, 4.2292, 4.3701, 3.9070],\n",
      "        [3.4993, 3.6096, 3.7905, 3.6763, 3.5867],\n",
      "        [3.7580, 3.8438, 3.9610, 3.9324, 3.8949],\n",
      "        [3.4956, 3.6286, 3.9007, 3.5590, 3.7349],\n",
      "        [3.5687, 3.6256, 3.8441, 3.7120, 3.6600]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6895, 3.7827, 4.0062, 3.8118, 3.5286],\n",
      "        [3.7543, 3.9113, 4.0047, 3.8633, 3.6429],\n",
      "        [3.6570, 3.7043, 3.8552, 3.6576, 3.5056],\n",
      "        [3.5392, 3.5961, 3.8327, 3.7294, 3.7125],\n",
      "        [3.3563, 3.5835, 3.5789, 3.5499, 3.4280],\n",
      "        [3.5108, 3.5974, 3.8030, 3.6841, 3.5791],\n",
      "        [3.5071, 3.7145, 3.6801, 3.7191, 3.5915],\n",
      "        [3.7716, 3.9429, 4.0332, 3.9573, 3.9829],\n",
      "        [3.4975, 3.7788, 3.9235, 3.7907, 3.5913],\n",
      "        [3.4943, 3.5666, 3.7944, 3.6614, 3.5655],\n",
      "        [3.5719, 3.6582, 3.8833, 3.7703, 3.6812],\n",
      "        [3.8032, 3.8760, 3.9916, 4.0635, 4.0228],\n",
      "        [3.8038, 3.8639, 3.9581, 3.9654, 3.9437],\n",
      "        [3.6562, 3.9083, 3.8711, 3.9643, 3.7856],\n",
      "        [3.9145, 3.9721, 4.0746, 4.1188, 3.9374],\n",
      "        [3.3283, 3.5625, 3.6132, 3.4771, 3.4645],\n",
      "        [3.6379, 3.8625, 3.9655, 3.8277, 3.7179],\n",
      "        [3.6293, 3.8831, 3.8429, 3.9280, 3.7429],\n",
      "        [3.9260, 3.9508, 3.9150, 4.0354, 4.0165],\n",
      "        [3.6545, 3.9059, 3.8695, 3.9629, 3.7820],\n",
      "        [3.9619, 4.0775, 4.0575, 4.2706, 4.0024],\n",
      "        [3.3722, 3.6839, 3.7151, 3.6445, 3.5219],\n",
      "        [3.2853, 3.5630, 3.6714, 3.5315, 3.4933],\n",
      "        [4.2552, 4.4573, 4.1647, 4.1430, 3.9449],\n",
      "        [3.6373, 3.6855, 3.8393, 3.6705, 3.4869],\n",
      "        [3.5090, 3.8456, 3.8594, 3.6178, 3.6999],\n",
      "        [3.3811, 3.7125, 3.8665, 3.6318, 3.6163],\n",
      "        [3.8593, 3.9686, 3.9967, 4.1071, 3.8886],\n",
      "        [3.4494, 3.6656, 3.6627, 3.6332, 3.5603],\n",
      "        [3.7590, 3.8595, 3.9940, 3.9857, 3.7828],\n",
      "        [3.6115, 3.6656, 3.8339, 3.6674, 3.5831],\n",
      "        [4.0237, 4.1551, 3.8595, 3.9240, 3.7350],\n",
      "        [3.6640, 4.0080, 3.9054, 3.8723, 3.7519],\n",
      "        [3.3683, 3.6753, 3.7385, 3.5770, 3.5171],\n",
      "        [3.5295, 3.6446, 3.8896, 3.6126, 3.7545],\n",
      "        [3.8008, 3.5990, 3.8626, 4.1289, 4.0083],\n",
      "        [3.7718, 3.8626, 3.9590, 3.9049, 3.8920],\n",
      "        [3.9314, 4.0251, 4.0642, 4.1763, 3.9519],\n",
      "        [3.4953, 3.7726, 3.8602, 3.7919, 3.6549],\n",
      "        [3.5429, 3.7491, 3.8113, 3.7299, 3.6859],\n",
      "        [3.5310, 3.9047, 3.9567, 3.9005, 3.6221],\n",
      "        [3.5093, 3.6123, 3.7998, 3.6832, 3.5933],\n",
      "        [3.5091, 3.6612, 3.8147, 3.7180, 3.6180],\n",
      "        [3.5530, 3.6329, 3.8418, 3.7325, 3.6530],\n",
      "        [3.3695, 3.6301, 3.6935, 3.6214, 3.4850],\n",
      "        [3.5088, 3.7260, 3.6911, 3.7199, 3.6051],\n",
      "        [3.3907, 3.6654, 3.7422, 3.5973, 3.5419],\n",
      "        [3.2631, 3.8380, 3.8033, 3.6521, 3.4321],\n",
      "        [3.4055, 3.4977, 3.6695, 3.6150, 3.4531],\n",
      "        [3.4906, 3.7015, 3.6832, 3.6929, 3.5914],\n",
      "        [3.7965, 3.9792, 3.9580, 3.9406, 3.9239],\n",
      "        [3.7065, 3.8811, 3.9781, 3.9842, 3.7249],\n",
      "        [3.4200, 3.6454, 3.6523, 3.6042, 3.5339],\n",
      "        [4.0238, 4.2091, 4.0155, 3.9667, 3.8353],\n",
      "        [3.5047, 3.8366, 3.8564, 3.6095, 3.6909],\n",
      "        [3.5883, 3.6912, 3.9115, 3.7692, 3.6954],\n",
      "        [3.6113, 3.6206, 3.8010, 3.7034, 3.6770],\n",
      "        [3.6624, 3.9935, 3.9055, 3.8707, 3.7573],\n",
      "        [3.5599, 3.6952, 3.8316, 3.6324, 3.4520],\n",
      "        [3.6104, 3.6649, 3.8347, 3.6622, 3.5957],\n",
      "        [4.0255, 4.2425, 3.9423, 3.9283, 3.7689],\n",
      "        [3.9258, 3.8114, 3.9128, 3.9432, 3.8715],\n",
      "        [3.4491, 3.6991, 3.8090, 3.5953, 3.5993],\n",
      "        [3.5254, 3.7493, 3.8828, 3.7598, 3.6816]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5274, 3.7409, 3.7040, 3.7505, 3.6199],\n",
      "        [3.5047, 3.7129, 3.6812, 3.7188, 3.5989],\n",
      "        [3.7315, 3.7905, 3.8812, 3.9037, 3.8635],\n",
      "        [3.7181, 3.8900, 3.9887, 4.0013, 3.7284],\n",
      "        [3.5990, 3.8533, 3.8226, 3.7230, 3.7083],\n",
      "        [3.3577, 3.4896, 3.6593, 3.5772, 3.4711],\n",
      "        [3.5239, 3.6822, 3.8288, 3.7443, 3.6373],\n",
      "        [3.5090, 3.7234, 3.6842, 3.7327, 3.5993],\n",
      "        [3.3931, 3.5681, 3.7039, 3.5933, 3.5008],\n",
      "        [3.2630, 3.8377, 3.8009, 3.6524, 3.4322],\n",
      "        [3.4517, 3.6142, 3.7678, 3.6572, 3.5823],\n",
      "        [3.3685, 3.5645, 3.6947, 3.5746, 3.4773],\n",
      "        [3.3836, 3.5774, 3.7093, 3.5847, 3.4904],\n",
      "        [3.4896, 3.7059, 3.6800, 3.6934, 3.5882],\n",
      "        [3.5482, 3.6384, 3.8614, 3.7582, 3.6730],\n",
      "        [3.8172, 3.9250, 4.1555, 4.1471, 3.7614],\n",
      "        [3.7273, 3.9612, 3.9246, 3.8812, 3.8357],\n",
      "        [4.0568, 4.1717, 4.2369, 4.3721, 3.9182],\n",
      "        [4.0320, 4.1635, 3.8609, 3.9404, 3.7321],\n",
      "        [3.5729, 3.9682, 4.0158, 3.8900, 3.8517],\n",
      "        [3.4328, 3.8945, 3.8770, 3.7961, 3.7091],\n",
      "        [3.8897, 3.7955, 3.8980, 3.9244, 3.9039],\n",
      "        [3.5099, 3.7142, 3.6728, 3.7188, 3.5861],\n",
      "        [3.5642, 3.8444, 3.8138, 3.7167, 3.6543],\n",
      "        [3.6733, 3.9942, 3.9971, 3.9224, 3.8811],\n",
      "        [3.4980, 3.6227, 3.7951, 3.6981, 3.5978],\n",
      "        [3.4225, 3.5301, 3.6887, 3.6349, 3.4919],\n",
      "        [3.6608, 3.8323, 3.9700, 3.9053, 3.8709],\n",
      "        [3.4703, 3.9025, 3.9079, 3.7910, 3.7671],\n",
      "        [3.6442, 3.6937, 3.8454, 3.7716, 3.6306],\n",
      "        [3.5090, 3.6609, 3.8123, 3.7184, 3.6181],\n",
      "        [3.3677, 3.6006, 3.8073, 3.6133, 3.6010],\n",
      "        [3.4304, 3.6429, 3.6441, 3.6048, 3.5304],\n",
      "        [3.4038, 3.5106, 3.6729, 3.6124, 3.4638],\n",
      "        [3.5175, 3.5348, 3.7228, 3.5635, 3.4932],\n",
      "        [3.3741, 3.5687, 3.7012, 3.5790, 3.4823],\n",
      "        [3.5698, 3.6622, 3.8661, 3.7325, 3.6735],\n",
      "        [3.6813, 3.9585, 3.9136, 3.8665, 3.7628],\n",
      "        [3.7072, 3.9150, 4.0040, 3.9026, 3.9231],\n",
      "        [3.5183, 3.7416, 3.8232, 3.7931, 3.7031],\n",
      "        [3.7019, 3.7294, 3.8495, 4.0559, 3.8448],\n",
      "        [3.4740, 3.7389, 3.7031, 3.7796, 3.5493],\n",
      "        [3.4655, 3.7691, 3.9143, 3.8304, 3.5444],\n",
      "        [3.4904, 3.5415, 3.8128, 3.5277, 3.6412],\n",
      "        [3.5853, 3.9289, 3.8234, 3.6256, 3.7123],\n",
      "        [3.4467, 3.7531, 3.8505, 3.6631, 3.6761],\n",
      "        [3.3287, 3.5682, 3.6106, 3.4795, 3.4673],\n",
      "        [3.5098, 3.6146, 3.7901, 3.6846, 3.5961],\n",
      "        [3.6560, 3.9081, 3.8687, 3.9647, 3.7856],\n",
      "        [3.7508, 3.8375, 3.9508, 3.8470, 3.8668],\n",
      "        [3.4506, 3.6440, 3.7915, 3.7301, 3.5856],\n",
      "        [3.3561, 3.5572, 3.5929, 3.6169, 3.4256],\n",
      "        [3.8021, 3.9551, 4.0519, 3.9646, 4.0286],\n",
      "        [3.5399, 3.5717, 3.7850, 3.6997, 3.7008],\n",
      "        [3.3377, 3.4891, 3.6197, 3.4977, 3.4485],\n",
      "        [3.9070, 4.0913, 3.8818, 3.8708, 3.7482],\n",
      "        [3.6281, 3.8669, 3.8572, 3.8326, 3.7345],\n",
      "        [3.4971, 3.5701, 3.7924, 3.6646, 3.5656],\n",
      "        [3.5111, 3.6150, 3.8499, 3.7289, 3.6341],\n",
      "        [3.4239, 3.6296, 3.6577, 3.6516, 3.5085],\n",
      "        [3.6655, 3.9486, 3.9790, 3.8993, 3.8257],\n",
      "        [3.6524, 3.8664, 3.9829, 3.7715, 3.5897],\n",
      "        [3.6348, 3.9775, 3.9975, 3.8652, 3.6934],\n",
      "        [3.6159, 3.9073, 3.8362, 3.7832, 3.7070]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5487, 3.8198, 3.8087, 3.7260, 3.6892],\n",
      "        [3.5301, 3.6821, 3.8019, 3.7052, 3.7350],\n",
      "        [4.0456, 4.1553, 4.2388, 4.3200, 3.8870],\n",
      "        [3.2627, 3.8372, 3.7984, 3.6533, 3.4321],\n",
      "        [3.4806, 3.6547, 3.6846, 3.6215, 3.5545],\n",
      "        [3.7875, 3.8626, 3.9527, 3.9496, 3.9437],\n",
      "        [3.4737, 3.6589, 3.6806, 3.6589, 3.5837],\n",
      "        [3.4462, 3.8877, 3.8728, 3.7590, 3.7836],\n",
      "        [4.0039, 4.2513, 4.3036, 4.2748, 4.3060],\n",
      "        [3.6803, 3.8878, 3.8770, 3.7983, 3.7113],\n",
      "        [3.4629, 3.5562, 3.7117, 3.5098, 3.5815],\n",
      "        [3.7016, 3.9623, 3.8543, 3.7002, 3.6528],\n",
      "        [3.5095, 3.7137, 3.6705, 3.7196, 3.5859],\n",
      "        [3.4583, 3.5180, 3.6873, 3.6460, 3.4757],\n",
      "        [3.5167, 3.5938, 3.7011, 3.7607, 3.5176],\n",
      "        [3.5056, 3.7170, 3.6708, 3.7221, 3.5935],\n",
      "        [3.8639, 4.0671, 3.8811, 3.8553, 3.7455],\n",
      "        [3.4900, 3.5410, 3.8103, 3.5285, 3.6410],\n",
      "        [3.5641, 3.9853, 3.9977, 3.8794, 3.8769],\n",
      "        [3.5525, 3.6209, 3.8457, 3.7166, 3.6581],\n",
      "        [3.3369, 3.4836, 3.6397, 3.5141, 3.4109],\n",
      "        [3.6850, 3.9734, 3.9316, 3.8644, 3.7871],\n",
      "        [3.5767, 3.7801, 3.8816, 3.8517, 3.6933],\n",
      "        [3.3603, 3.6820, 3.7345, 3.5771, 3.5189],\n",
      "        [3.6481, 3.8596, 3.9751, 3.7656, 3.5852],\n",
      "        [3.4951, 3.6112, 3.7301, 3.7264, 3.5295],\n",
      "        [3.5562, 3.6251, 3.8017, 3.6993, 3.6549],\n",
      "        [3.5113, 3.6792, 3.7530, 3.7609, 3.6347],\n",
      "        [3.4853, 3.6980, 3.6698, 3.6873, 3.5805],\n",
      "        [3.4502, 3.6435, 3.7891, 3.7309, 3.5854],\n",
      "        [3.5852, 3.9039, 3.8557, 3.8134, 3.8039],\n",
      "        [3.4606, 3.6047, 3.7337, 3.6933, 3.5175],\n",
      "        [3.6798, 3.8372, 3.9837, 3.7955, 3.5409],\n",
      "        [3.7962, 3.9788, 3.9533, 3.9417, 3.9238],\n",
      "        [3.6635, 3.7634, 3.9912, 3.7849, 3.4708],\n",
      "        [3.4052, 3.5387, 3.6899, 3.6026, 3.4816],\n",
      "        [3.5449, 3.6075, 3.8427, 3.7476, 3.7240],\n",
      "        [3.5269, 3.7056, 3.7223, 3.7651, 3.6199],\n",
      "        [3.6125, 3.9072, 3.8263, 3.7982, 3.7045],\n",
      "        [3.9036, 3.8413, 3.9104, 3.9445, 3.8642],\n",
      "        [3.3651, 3.7285, 3.7552, 3.6572, 3.7062],\n",
      "        [3.7390, 3.5578, 3.7121, 3.7292, 3.7143],\n",
      "        [3.9094, 3.8039, 4.0244, 4.0368, 3.8553],\n",
      "        [3.5756, 3.9416, 3.7810, 3.7817, 3.6616],\n",
      "        [3.4065, 3.6362, 3.6472, 3.5780, 3.5321],\n",
      "        [3.3677, 3.7009, 3.7480, 3.5820, 3.5336],\n",
      "        [3.6852, 3.9026, 3.9749, 3.8050, 3.6255],\n",
      "        [3.5156, 3.6179, 3.8590, 3.7350, 3.6263],\n",
      "        [3.7719, 3.5732, 3.6986, 3.7070, 3.7636],\n",
      "        [3.4984, 3.9038, 3.8877, 3.7151, 3.5109],\n",
      "        [3.9270, 4.0612, 4.1542, 4.2105, 3.8760],\n",
      "        [3.8029, 3.8756, 3.9867, 4.0647, 4.0227],\n",
      "        [3.3816, 3.6095, 3.7248, 3.5978, 3.5131],\n",
      "        [3.6117, 3.5121, 3.9361, 3.7683, 3.6347],\n",
      "        [3.5103, 3.7218, 3.6823, 3.7236, 3.6011],\n",
      "        [3.9496, 3.9822, 3.9633, 4.0847, 4.0203],\n",
      "        [3.5700, 3.8562, 3.8186, 3.7389, 3.6509],\n",
      "        [3.3617, 3.6020, 3.6319, 3.5323, 3.5004],\n",
      "        [3.6539, 3.9052, 3.8647, 3.9641, 3.7819],\n",
      "        [3.5515, 3.7698, 3.8813, 3.8617, 3.6486],\n",
      "        [3.6304, 3.8404, 3.9821, 3.8747, 3.7834],\n",
      "        [3.5266, 3.5833, 3.6834, 3.6151, 3.6267],\n",
      "        [3.5394, 3.6386, 3.8626, 3.7247, 3.6617],\n",
      "        [3.3353, 3.6612, 3.5371, 3.6201, 3.4235]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4496, 3.7705, 3.9013, 3.8357, 3.5292],\n",
      "        [3.7347, 3.5421, 3.7005, 3.7291, 3.7068],\n",
      "        [3.5051, 3.6601, 3.8036, 3.7151, 3.6054],\n",
      "        [3.4498, 3.7466, 3.6612, 3.7166, 3.5246],\n",
      "        [3.4931, 3.9491, 3.8518, 3.8351, 3.7838],\n",
      "        [3.6090, 3.7412, 3.9028, 3.7834, 3.6782],\n",
      "        [3.5462, 3.7779, 3.9089, 3.9041, 3.6282],\n",
      "        [3.3691, 3.6405, 3.7181, 3.5756, 3.5022],\n",
      "        [3.4243, 3.5424, 3.6988, 3.6206, 3.4709],\n",
      "        [3.5098, 3.6041, 3.7921, 3.6878, 3.5858],\n",
      "        [3.5176, 3.8334, 3.9517, 3.7831, 3.5709],\n",
      "        [3.5358, 3.6449, 3.8687, 3.7330, 3.6647],\n",
      "        [3.5000, 3.6845, 3.8851, 3.8149, 3.7815],\n",
      "        [3.7425, 3.6196, 3.7140, 3.7137, 3.7717],\n",
      "        [3.5624, 3.6456, 3.8241, 3.7404, 3.6520],\n",
      "        [3.3732, 3.7461, 3.7976, 3.6501, 3.5246],\n",
      "        [3.4729, 3.6771, 3.6580, 3.6647, 3.5733],\n",
      "        [3.4278, 3.6075, 3.7625, 3.6651, 3.5744],\n",
      "        [3.6460, 3.7004, 3.8480, 3.6348, 3.4966],\n",
      "        [3.3848, 3.5763, 3.7044, 3.5859, 3.4909],\n",
      "        [3.6636, 3.7232, 3.7771, 3.9183, 3.7476],\n",
      "        [3.5437, 3.5962, 3.8270, 3.7350, 3.7172],\n",
      "        [3.4985, 3.6242, 3.7798, 3.6848, 3.5890],\n",
      "        [3.3705, 3.6289, 3.6861, 3.6229, 3.4854],\n",
      "        [3.5565, 3.6919, 3.9284, 3.7785, 3.6965],\n",
      "        [3.2882, 3.6122, 3.8118, 3.5409, 3.5922],\n",
      "        [3.6182, 3.8711, 3.9090, 3.7870, 3.5764],\n",
      "        [3.5115, 3.6439, 3.7957, 3.7059, 3.6023],\n",
      "        [3.3339, 3.4536, 3.6267, 3.6082, 3.4330],\n",
      "        [3.6835, 3.8804, 3.8275, 3.9036, 3.8803],\n",
      "        [3.7285, 3.6959, 3.8352, 4.0325, 3.8193],\n",
      "        [3.5796, 3.6018, 3.8026, 3.7215, 3.5760],\n",
      "        [3.3964, 3.6075, 3.7352, 3.6122, 3.4901],\n",
      "        [3.5955, 3.6391, 3.9499, 3.9222, 3.5660],\n",
      "        [3.6723, 4.0031, 3.9590, 3.8737, 3.7755],\n",
      "        [3.3509, 3.4874, 3.6392, 3.5224, 3.4191],\n",
      "        [3.7255, 3.9736, 4.0384, 3.8548, 3.5746],\n",
      "        [3.3776, 3.7070, 3.7490, 3.5882, 3.5406],\n",
      "        [3.4267, 3.6264, 3.6373, 3.6493, 3.4790],\n",
      "        [3.5698, 4.0412, 3.8900, 3.9473, 3.8120],\n",
      "        [3.5481, 3.6281, 3.8542, 3.7216, 3.6615],\n",
      "        [3.5886, 3.6940, 3.9127, 3.7832, 3.6949],\n",
      "        [3.6250, 3.6672, 3.9574, 3.8610, 3.6320],\n",
      "        [3.6872, 3.9217, 3.9437, 3.9072, 3.7469],\n",
      "        [3.3231, 3.5573, 3.6010, 3.4703, 3.4673],\n",
      "        [3.4345, 3.5572, 3.7055, 3.6205, 3.4888],\n",
      "        [3.4895, 3.5817, 3.7564, 3.6270, 3.5422],\n",
      "        [3.4139, 3.7225, 3.7991, 3.6199, 3.5623],\n",
      "        [3.2543, 3.8127, 3.7729, 3.6813, 3.4775],\n",
      "        [3.2873, 3.8314, 3.7991, 3.6529, 3.4440],\n",
      "        [3.6771, 3.7515, 3.8664, 3.7460, 3.8102],\n",
      "        [3.3428, 3.7923, 3.8117, 3.6787, 3.4842],\n",
      "        [3.6853, 3.8981, 3.9956, 3.8947, 3.8020],\n",
      "        [3.3775, 3.6938, 3.7402, 3.5889, 3.5362],\n",
      "        [3.4238, 3.5290, 3.6839, 3.6361, 3.4924],\n",
      "        [3.5484, 3.6842, 3.9191, 3.7783, 3.6884],\n",
      "        [3.3986, 3.5486, 3.6933, 3.5952, 3.4852],\n",
      "        [3.4992, 4.0358, 4.0158, 3.7785, 3.6323],\n",
      "        [3.7036, 3.8242, 3.9866, 3.8184, 3.6052],\n",
      "        [3.4931, 3.7807, 3.8119, 3.7576, 3.6609],\n",
      "        [3.9259, 3.9065, 4.0125, 4.1135, 3.9190],\n",
      "        [3.9440, 3.9781, 3.9333, 4.0638, 4.0312],\n",
      "        [3.6425, 3.8906, 3.8453, 3.8039, 3.7164],\n",
      "        [3.4743, 3.6611, 3.7479, 3.6710, 3.6366]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6399, 3.6834, 3.8299, 3.6729, 3.4888],\n",
      "        [3.9109, 3.7677, 3.8708, 3.9406, 3.8851],\n",
      "        [3.5636, 3.6325, 3.8142, 3.7092, 3.6625],\n",
      "        [3.4611, 3.6504, 3.7324, 3.6592, 3.6271],\n",
      "        [3.5189, 3.8326, 3.9495, 3.7839, 3.5722],\n",
      "        [3.5433, 3.5513, 3.7334, 3.6831, 3.7009],\n",
      "        [3.5215, 3.6273, 3.8574, 3.7396, 3.6437],\n",
      "        [3.7223, 3.9806, 4.0831, 3.9779, 3.9529],\n",
      "        [3.6151, 3.8523, 3.8457, 3.8217, 3.7079],\n",
      "        [4.0238, 4.0541, 4.1716, 4.2715, 4.0740],\n",
      "        [3.7529, 3.9623, 3.9281, 3.8946, 3.8745],\n",
      "        [3.4276, 3.7796, 3.6680, 3.4709, 3.5654],\n",
      "        [3.3948, 3.6201, 3.6364, 3.5571, 3.5272],\n",
      "        [3.8106, 3.9343, 4.0797, 4.0950, 3.7502],\n",
      "        [3.5086, 3.6465, 3.7970, 3.7019, 3.6005],\n",
      "        [3.7430, 3.5563, 3.7073, 3.7310, 3.7166],\n",
      "        [3.5272, 3.6786, 3.8084, 3.5960, 3.6827],\n",
      "        [3.5277, 3.7473, 3.8725, 3.7619, 3.6835],\n",
      "        [3.5235, 3.7680, 3.9180, 3.9248, 3.5827],\n",
      "        [3.3939, 3.5879, 3.6820, 3.5805, 3.5095],\n",
      "        [3.7539, 4.0976, 4.0028, 4.0242, 3.9431],\n",
      "        [3.4572, 3.9257, 3.8477, 3.7844, 3.7879],\n",
      "        [3.6555, 3.7585, 3.7216, 3.8354, 3.7540],\n",
      "        [3.5241, 3.7363, 3.6792, 3.7491, 3.6139],\n",
      "        [3.8089, 3.9837, 3.9541, 3.9487, 3.9205],\n",
      "        [3.3702, 3.5988, 3.7998, 3.6151, 3.6029],\n",
      "        [3.6696, 3.7014, 3.8324, 3.6599, 3.5219],\n",
      "        [3.8226, 3.8959, 4.1275, 4.1303, 3.7626],\n",
      "        [3.6835, 3.8198, 3.9466, 3.8103, 3.7331],\n",
      "        [3.8934, 3.9615, 4.1030, 4.1400, 3.9016],\n",
      "        [3.3977, 3.6066, 3.7326, 3.6130, 3.4915],\n",
      "        [3.4040, 3.5269, 3.6765, 3.6005, 3.4784],\n",
      "        [4.1458, 4.4003, 4.0159, 4.0365, 3.8964],\n",
      "        [3.5172, 3.6725, 3.7246, 3.7149, 3.5789],\n",
      "        [3.4174, 3.4980, 3.6633, 3.6179, 3.4634],\n",
      "        [3.4484, 4.0330, 3.9704, 3.8244, 3.6406],\n",
      "        [3.6139, 3.6959, 3.9234, 3.8373, 3.6485],\n",
      "        [3.3376, 3.5665, 3.6046, 3.4909, 3.4769],\n",
      "        [3.2990, 3.5330, 3.5824, 3.4440, 3.4364],\n",
      "        [3.5630, 3.8421, 3.8073, 3.7100, 3.6639],\n",
      "        [3.7214, 3.8306, 3.9703, 3.9093, 3.6429],\n",
      "        [3.3159, 3.5478, 3.5915, 3.4647, 3.4583],\n",
      "        [3.7049, 3.8233, 3.9841, 3.8191, 3.6064],\n",
      "        [3.7900, 3.8843, 3.9994, 4.0597, 4.0268],\n",
      "        [3.4348, 3.6286, 3.6462, 3.6700, 3.4873],\n",
      "        [3.4510, 3.7581, 3.9720, 3.7106, 3.7765],\n",
      "        [3.5487, 3.8255, 3.8336, 3.7071, 3.6914],\n",
      "        [3.5024, 3.5750, 3.7513, 3.6205, 3.5359],\n",
      "        [3.5450, 3.6654, 3.8919, 3.7574, 3.6767],\n",
      "        [3.7795, 4.0674, 3.9323, 3.9862, 3.9510],\n",
      "        [3.6578, 3.8882, 3.8668, 3.8783, 3.7348],\n",
      "        [3.5345, 3.7469, 3.6885, 3.7622, 3.6213],\n",
      "        [3.4999, 3.6820, 3.7208, 3.7211, 3.5825],\n",
      "        [3.7846, 3.8917, 4.0564, 4.0481, 3.7538],\n",
      "        [3.6689, 3.8587, 3.9976, 3.7985, 3.6048],\n",
      "        [3.7552, 4.0157, 4.0649, 3.8999, 3.6378],\n",
      "        [3.2971, 3.5218, 3.5744, 3.4388, 3.4264],\n",
      "        [3.5750, 3.6582, 3.8743, 3.7685, 3.6868],\n",
      "        [3.5715, 3.9848, 3.8062, 3.7798, 3.8471],\n",
      "        [3.5248, 4.0224, 4.0200, 3.8075, 3.6519],\n",
      "        [4.0555, 4.2478, 4.0549, 3.9965, 3.8852],\n",
      "        [3.4557, 3.6674, 3.6467, 3.6513, 3.5491],\n",
      "        [3.6624, 3.7218, 3.7808, 3.9219, 3.7492],\n",
      "        [3.4462, 3.6452, 3.6846, 3.6312, 3.5654]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5357, 3.7412, 3.9517, 3.7945, 3.7676],\n",
      "        [3.3153, 3.5420, 3.5898, 3.4585, 3.4495],\n",
      "        [3.4290, 3.8911, 3.8429, 3.6355, 3.4821],\n",
      "        [3.5885, 3.7507, 3.8348, 3.7651, 3.7444],\n",
      "        [3.5653, 3.8418, 3.8077, 3.7106, 3.6660],\n",
      "        [3.9951, 4.0405, 4.1620, 4.2790, 4.0601],\n",
      "        [3.4462, 3.6940, 3.6833, 3.6858, 3.5200],\n",
      "        [3.6030, 3.9201, 3.8627, 3.8290, 3.8234],\n",
      "        [3.3928, 3.9480, 3.9075, 3.7539, 3.6497],\n",
      "        [3.7468, 3.6184, 3.7115, 3.7156, 3.7752],\n",
      "        [3.4348, 3.6082, 3.6492, 3.6411, 3.5111],\n",
      "        [3.4537, 3.6965, 3.7985, 3.5980, 3.6032],\n",
      "        [3.8221, 3.9232, 4.1501, 4.1495, 3.7652],\n",
      "        [3.5641, 4.0624, 3.9728, 4.0369, 3.8170],\n",
      "        [3.5010, 3.7056, 3.6723, 3.7122, 3.5915],\n",
      "        [3.7197, 3.8021, 4.0371, 4.0202, 3.6373],\n",
      "        [3.5392, 3.6528, 3.8727, 3.6039, 3.7727],\n",
      "        [3.6421, 3.9691, 4.0354, 3.8814, 3.6944],\n",
      "        [3.6003, 3.7508, 3.8397, 3.7556, 3.7606],\n",
      "        [3.4776, 3.9607, 3.7646, 3.6769, 3.7635],\n",
      "        [3.3459, 3.5761, 3.6090, 3.5004, 3.4829],\n",
      "        [3.6336, 4.0069, 3.9149, 3.8581, 3.7670],\n",
      "        [3.9505, 3.9849, 4.0018, 4.1028, 4.0079],\n",
      "        [3.3764, 3.6818, 3.7065, 3.6438, 3.5148],\n",
      "        [3.4481, 3.6101, 3.7175, 3.5941, 3.5519],\n",
      "        [3.9431, 4.1381, 3.9586, 3.8944, 3.8000],\n",
      "        [3.9194, 3.9700, 4.0660, 4.1219, 3.9414],\n",
      "        [3.7892, 3.8755, 4.1164, 4.1055, 3.7117],\n",
      "        [3.3713, 3.5977, 3.6992, 3.5766, 3.4950],\n",
      "        [3.7885, 3.8481, 3.9703, 3.9223, 3.9124],\n",
      "        [3.3723, 3.6481, 3.6862, 3.6339, 3.4978],\n",
      "        [3.5898, 3.8405, 3.8127, 3.7329, 3.7096],\n",
      "        [3.4531, 3.7456, 3.6587, 3.7180, 3.5281],\n",
      "        [3.8226, 4.0362, 3.8732, 3.8418, 3.7433],\n",
      "        [3.6125, 3.9033, 3.8196, 3.7833, 3.6989],\n",
      "        [3.6490, 3.7287, 3.8168, 3.7724, 3.6530],\n",
      "        [3.6702, 3.7853, 4.0636, 3.7857, 3.5554],\n",
      "        [3.5618, 3.9263, 4.0652, 3.9213, 3.7110],\n",
      "        [3.3482, 3.4952, 3.6439, 3.5391, 3.4207],\n",
      "        [3.6855, 3.7600, 3.8500, 3.7596, 3.5089],\n",
      "        [3.4076, 3.6267, 3.7441, 3.6289, 3.5111],\n",
      "        [3.5517, 3.9163, 4.0587, 3.9314, 3.7100],\n",
      "        [3.4213, 3.6404, 3.6408, 3.5948, 3.5399],\n",
      "        [3.4282, 3.9398, 3.9276, 3.7516, 3.8168],\n",
      "        [3.6173, 3.8520, 3.8463, 3.8222, 3.7098],\n",
      "        [3.3995, 3.5423, 3.6720, 3.5857, 3.4794],\n",
      "        [3.7663, 3.9169, 4.0045, 3.8722, 3.6517],\n",
      "        [3.6048, 3.9795, 3.9194, 3.8505, 3.8420],\n",
      "        [3.6133, 3.7632, 3.9123, 3.7924, 3.7035],\n",
      "        [3.5340, 3.7500, 3.6916, 3.7631, 3.6235],\n",
      "        [3.4149, 3.6050, 3.7401, 3.6258, 3.5035],\n",
      "        [3.4594, 3.9254, 3.8477, 3.7850, 3.7901],\n",
      "        [3.5140, 3.7015, 3.7401, 3.6708, 3.6256],\n",
      "        [3.4633, 3.6502, 3.7333, 3.6597, 3.6290],\n",
      "        [3.3780, 3.6360, 3.7212, 3.5941, 3.5222],\n",
      "        [3.7337, 3.9921, 3.8735, 3.8054, 3.7318],\n",
      "        [3.3581, 3.5049, 3.6224, 3.5230, 3.4626],\n",
      "        [3.4313, 3.6231, 3.6473, 3.6449, 3.5148],\n",
      "        [3.5568, 3.7682, 3.8776, 3.8634, 3.6526],\n",
      "        [3.6518, 3.6963, 3.8603, 3.7924, 3.6505],\n",
      "        [3.5027, 3.7356, 3.7507, 3.5885, 3.5463],\n",
      "        [3.6442, 3.7106, 3.7951, 3.8883, 3.7327],\n",
      "        [3.2518, 3.8337, 3.7819, 3.6401, 3.4317],\n",
      "        [3.6124, 3.9799, 3.9197, 3.8595, 3.8493]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5936, 3.6078, 3.9327, 3.8196, 3.6585],\n",
      "        [3.5512, 4.0116, 3.9872, 3.7899, 3.6170],\n",
      "        [3.8096, 3.8734, 3.9812, 4.0675, 4.0302],\n",
      "        [3.7900, 3.9355, 4.0409, 3.9671, 3.7847],\n",
      "        [3.5326, 3.6173, 3.8086, 3.6936, 3.6114],\n",
      "        [3.6179, 3.6951, 3.9233, 3.8388, 3.6540],\n",
      "        [3.7532, 3.8430, 3.9356, 3.8780, 3.8766],\n",
      "        [3.6613, 3.8998, 3.8432, 3.7971, 3.7281],\n",
      "        [3.5281, 3.9580, 3.8680, 3.8620, 3.8183],\n",
      "        [3.3624, 3.5547, 3.5857, 3.6203, 3.4329],\n",
      "        [3.6084, 3.6976, 3.9150, 3.7998, 3.7107],\n",
      "        [3.4377, 3.6506, 3.6432, 3.6134, 3.5499],\n",
      "        [3.4556, 3.5906, 3.7832, 3.6867, 3.6625],\n",
      "        [3.4261, 3.5391, 3.6916, 3.6328, 3.5085],\n",
      "        [3.4346, 3.6347, 3.7684, 3.6574, 3.5148],\n",
      "        [3.4306, 3.6180, 3.6457, 3.6430, 3.5235],\n",
      "        [3.4132, 3.6340, 3.6420, 3.5805, 3.5393],\n",
      "        [4.0333, 4.1201, 4.2276, 4.3032, 3.9772],\n",
      "        [3.6119, 3.9961, 3.9306, 3.8590, 3.8478],\n",
      "        [3.6201, 3.9114, 3.8533, 3.9196, 3.7442],\n",
      "        [3.5900, 3.7535, 3.8338, 3.7630, 3.7568],\n",
      "        [3.3873, 3.7093, 3.8560, 3.6352, 3.6237],\n",
      "        [3.6627, 3.9052, 3.8612, 3.9681, 3.7929],\n",
      "        [3.5326, 3.7109, 3.7888, 3.7185, 3.6916],\n",
      "        [3.7938, 3.8659, 3.9743, 4.0531, 4.0215],\n",
      "        [3.6399, 3.6244, 3.7710, 3.6965, 3.6890],\n",
      "        [3.9398, 3.8322, 4.0473, 4.4176, 4.1753],\n",
      "        [3.5548, 3.6355, 3.8537, 3.7615, 3.6800],\n",
      "        [3.7104, 4.0221, 3.8918, 3.9012, 3.9675],\n",
      "        [3.4212, 3.4971, 3.6631, 3.6194, 3.4687],\n",
      "        [3.5003, 3.6957, 3.6674, 3.6822, 3.6006],\n",
      "        [3.5096, 3.7717, 3.9283, 3.8023, 3.5854],\n",
      "        [3.7232, 3.8295, 3.9713, 3.9172, 3.6492],\n",
      "        [3.5032, 3.9776, 3.8251, 3.8810, 3.7386],\n",
      "        [3.5475, 3.5623, 3.7616, 3.7021, 3.7103],\n",
      "        [3.8294, 3.9460, 4.0318, 3.9899, 4.0572],\n",
      "        [3.6407, 3.6756, 3.9674, 3.8605, 3.6818],\n",
      "        [3.7959, 3.8602, 3.9474, 3.9529, 3.9518],\n",
      "        [3.5459, 3.5929, 3.8224, 3.7330, 3.7197],\n",
      "        [3.5438, 3.5463, 3.7300, 3.6784, 3.7037],\n",
      "        [3.8129, 3.9829, 3.9542, 3.9502, 3.9260],\n",
      "        [3.5465, 3.6475, 3.8680, 3.6337, 3.7751],\n",
      "        [3.4990, 3.7025, 3.6651, 3.7112, 3.5871],\n",
      "        [3.4988, 3.6169, 3.8800, 3.5534, 3.7441],\n",
      "        [3.5035, 3.6986, 3.8269, 3.7405, 3.6833],\n",
      "        [3.7759, 3.8306, 3.9511, 3.9079, 3.9118],\n",
      "        [3.9869, 4.1101, 4.1115, 4.2659, 4.0216],\n",
      "        [3.6006, 3.8764, 3.8977, 3.7829, 3.5696],\n",
      "        [3.6627, 3.9052, 3.8612, 3.9681, 3.7929],\n",
      "        [3.6580, 3.7585, 3.7193, 3.8433, 3.7765],\n",
      "        [3.4183, 3.9062, 3.8227, 3.8345, 3.7361],\n",
      "        [3.4612, 3.9248, 3.8475, 3.7860, 3.7938],\n",
      "        [3.5067, 3.8534, 3.8651, 3.6210, 3.7164],\n",
      "        [3.5159, 3.5183, 3.6999, 3.5628, 3.4874],\n",
      "        [3.4896, 3.9085, 3.8868, 3.7082, 3.5135],\n",
      "        [3.5816, 3.6185, 3.8146, 3.7422, 3.6302],\n",
      "        [4.0313, 4.2069, 4.0049, 3.9706, 3.8432],\n",
      "        [3.5279, 3.7355, 3.6792, 3.7505, 3.6191],\n",
      "        [3.9958, 4.1169, 4.1476, 4.2878, 4.0374],\n",
      "        [3.4012, 3.9165, 3.8928, 3.7127, 3.8055],\n",
      "        [3.6737, 3.7005, 3.8323, 3.6615, 3.5272],\n",
      "        [3.5597, 3.8974, 3.7857, 3.7827, 3.6786],\n",
      "        [3.8270, 3.9097, 4.0250, 4.0457, 3.8376],\n",
      "        [3.3466, 3.4751, 3.6239, 3.5092, 3.4161]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4328, 3.7780, 3.6671, 3.4729, 3.5745],\n",
      "        [3.8739, 4.1029, 3.9936, 4.0742, 4.0817],\n",
      "        [3.7162, 3.8065, 4.0252, 3.8495, 3.5447],\n",
      "        [3.4763, 3.9352, 3.7557, 3.6599, 3.7517],\n",
      "        [3.5342, 3.7102, 3.7888, 3.7191, 3.6956],\n",
      "        [3.9979, 3.9413, 3.9951, 4.0818, 3.9970],\n",
      "        [3.3777, 3.5828, 3.6943, 3.5775, 3.4978],\n",
      "        [3.4517, 3.6290, 3.7738, 3.7264, 3.5846],\n",
      "        [3.6878, 3.9847, 3.9137, 3.8753, 3.7784],\n",
      "        [3.4582, 3.6561, 3.6406, 3.6382, 3.5492],\n",
      "        [3.7472, 4.0054, 3.8890, 3.8289, 3.7535],\n",
      "        [3.5186, 3.6253, 3.7861, 3.6882, 3.6065],\n",
      "        [3.5512, 3.9208, 3.9143, 3.8651, 3.8620],\n",
      "        [3.4225, 3.5993, 3.6265, 3.6578, 3.5184],\n",
      "        [3.9008, 3.9665, 4.1273, 4.1583, 3.9070],\n",
      "        [3.5141, 3.6448, 3.7964, 3.7040, 3.6098],\n",
      "        [3.3715, 3.6345, 3.7153, 3.5796, 3.5106],\n",
      "        [4.0331, 4.0157, 4.2014, 4.2501, 4.0451],\n",
      "        [3.4504, 3.6585, 3.6447, 3.6273, 3.5566],\n",
      "        [3.4223, 3.5295, 3.6818, 3.6151, 3.4938],\n",
      "        [3.6864, 3.7220, 3.9132, 3.8601, 3.6973],\n",
      "        [3.7510, 3.8998, 4.0355, 3.9648, 3.9463],\n",
      "        [3.6530, 3.8771, 3.9803, 3.8469, 3.7185],\n",
      "        [3.3302, 3.6031, 3.6375, 3.5626, 3.5026],\n",
      "        [3.4255, 3.7581, 3.8732, 3.6490, 3.6814],\n",
      "        [3.8084, 3.9643, 3.9665, 3.9232, 3.8792],\n",
      "        [3.4717, 3.6471, 3.6895, 3.7144, 3.5853],\n",
      "        [3.5737, 3.8518, 3.8186, 3.7431, 3.6680],\n",
      "        [3.7908, 3.8900, 4.0561, 4.0504, 3.7634],\n",
      "        [3.6386, 3.6856, 3.8347, 3.6846, 3.6000],\n",
      "        [3.8642, 3.9651, 4.0841, 4.1900, 3.8998],\n",
      "        [3.3757, 3.5229, 3.6564, 3.5592, 3.4573],\n",
      "        [3.6655, 3.7137, 3.8120, 3.8302, 3.8082],\n",
      "        [3.4361, 3.6823, 3.8375, 3.7018, 3.6929],\n",
      "        [3.5646, 3.8708, 3.9138, 3.8561, 3.6458],\n",
      "        [3.4057, 3.5363, 3.6837, 3.6101, 3.4926],\n",
      "        [3.4458, 3.7601, 3.6501, 3.6849, 3.5236],\n",
      "        [3.7379, 3.9724, 4.0704, 3.9724, 3.9557],\n",
      "        [3.6984, 3.8731, 3.8695, 3.7724, 3.7202],\n",
      "        [3.6076, 3.5760, 3.7184, 3.6624, 3.6521],\n",
      "        [4.1995, 4.4213, 4.0788, 4.0936, 3.9378],\n",
      "        [3.5383, 3.7316, 3.6838, 3.7530, 3.6147],\n",
      "        [3.3898, 3.5726, 3.6953, 3.5855, 3.4995],\n",
      "        [3.6753, 3.7610, 3.9827, 3.7857, 3.5026],\n",
      "        [3.5147, 3.6814, 3.8039, 3.5989, 3.6722],\n",
      "        [3.7189, 3.9619, 3.9208, 3.8783, 3.8276],\n",
      "        [3.3812, 3.6348, 3.7200, 3.5955, 3.5295],\n",
      "        [3.6252, 3.9314, 3.9928, 3.8507, 3.6759],\n",
      "        [3.4888, 3.6518, 3.6786, 3.6247, 3.5654],\n",
      "        [3.6368, 3.6326, 4.0250, 3.8340, 3.7669],\n",
      "        [3.4116, 3.6677, 3.8656, 3.6702, 3.6775],\n",
      "        [3.5154, 3.6159, 3.7838, 3.6848, 3.6053],\n",
      "        [3.5647, 3.6181, 3.7493, 3.6753, 3.6766],\n",
      "        [3.9722, 4.0049, 4.1339, 4.2359, 4.0091],\n",
      "        [3.3983, 3.6188, 3.6375, 3.5564, 3.5289],\n",
      "        [3.5174, 3.8371, 3.8433, 3.6304, 3.7070],\n",
      "        [3.4746, 3.6743, 3.6618, 3.6721, 3.5829],\n",
      "        [3.9779, 4.1341, 4.0425, 4.1566, 4.1603],\n",
      "        [3.9974, 4.1162, 4.1470, 4.2884, 4.0415],\n",
      "        [3.5119, 3.6574, 3.8005, 3.7180, 3.6161],\n",
      "        [3.3656, 3.5672, 3.6579, 3.6080, 3.4785],\n",
      "        [3.4620, 3.6649, 3.6548, 3.6287, 3.5801],\n",
      "        [3.5635, 3.8416, 3.7977, 3.7350, 3.6420],\n",
      "        [3.6470, 3.7798, 3.7553, 3.7769, 3.7670]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5517, 3.6649, 3.8941, 3.7593, 3.6899],\n",
      "        [3.8780, 3.9681, 3.9433, 3.9799, 3.9720],\n",
      "        [3.5700, 3.8421, 3.8114, 3.7125, 3.6781],\n",
      "        [3.6721, 3.8984, 3.8658, 3.8461, 3.7247],\n",
      "        [3.6718, 3.8033, 3.7801, 3.8491, 3.7797],\n",
      "        [3.5402, 3.7413, 3.9539, 3.7961, 3.7793],\n",
      "        [3.4749, 3.5956, 3.7644, 3.6408, 3.5739],\n",
      "        [3.5294, 4.0227, 3.9573, 3.9990, 3.7840],\n",
      "        [3.5010, 3.6371, 3.8445, 3.7085, 3.6364],\n",
      "        [3.7874, 3.7091, 3.8616, 4.1469, 3.9107],\n",
      "        [3.5549, 3.7772, 3.9131, 3.9075, 3.6435],\n",
      "        [3.4104, 3.6291, 3.6394, 3.5866, 3.5398],\n",
      "        [3.4258, 3.6845, 3.6449, 3.6745, 3.5554],\n",
      "        [3.4569, 3.4897, 3.6358, 3.6131, 3.4584],\n",
      "        [3.4912, 4.0591, 4.0270, 3.8393, 3.7013],\n",
      "        [3.5261, 4.0281, 3.9411, 3.9935, 3.7915],\n",
      "        [3.3541, 3.5893, 3.6313, 3.5068, 3.5119],\n",
      "        [3.3758, 3.6760, 3.7294, 3.5809, 3.5322],\n",
      "        [3.4165, 3.6048, 3.7348, 3.6158, 3.5134],\n",
      "        [3.4953, 3.7037, 3.6687, 3.6948, 3.5965],\n",
      "        [3.3145, 3.5321, 3.5818, 3.4617, 3.4619],\n",
      "        [3.4101, 3.6006, 3.6980, 3.5922, 3.5364],\n",
      "        [3.4477, 3.6605, 3.6534, 3.6249, 3.5640],\n",
      "        [3.6515, 3.7726, 3.9229, 3.7998, 3.7155],\n",
      "        [3.5416, 3.5818, 3.8113, 3.7203, 3.7174],\n",
      "        [3.5660, 3.8369, 3.8140, 3.7048, 3.6830],\n",
      "        [3.5309, 3.8254, 3.9201, 3.7782, 3.6058],\n",
      "        [3.5057, 3.6494, 3.6998, 3.6195, 3.5989],\n",
      "        [3.7261, 3.8301, 3.9745, 3.9180, 3.6575],\n",
      "        [3.9230, 3.8260, 4.0596, 4.4190, 4.2133],\n",
      "        [3.9583, 3.8597, 3.9944, 4.0178, 3.9370],\n",
      "        [3.3413, 3.4524, 3.6268, 3.6111, 3.4476],\n",
      "        [3.4154, 3.4919, 3.6576, 3.6116, 3.4708],\n",
      "        [3.4736, 3.6089, 3.7920, 3.6866, 3.6038],\n",
      "        [3.5706, 3.9815, 3.9898, 3.8812, 3.8940],\n",
      "        [3.9007, 4.0500, 4.0276, 4.0184, 4.0086],\n",
      "        [3.5237, 3.5540, 3.7401, 3.6027, 3.5297],\n",
      "        [3.5223, 3.8328, 3.8404, 3.6416, 3.7068],\n",
      "        [3.6631, 3.7002, 3.8852, 3.8178, 3.6778],\n",
      "        [3.3471, 3.5648, 3.5523, 3.5209, 3.4370],\n",
      "        [3.4681, 3.6677, 3.6497, 3.6603, 3.5616],\n",
      "        [3.9704, 4.0931, 4.1861, 4.2764, 4.0208],\n",
      "        [3.5069, 3.7049, 3.6730, 3.7045, 3.6061],\n",
      "        [3.8142, 3.9305, 4.0216, 3.9769, 4.0563],\n",
      "        [3.3765, 3.5987, 3.8019, 3.6172, 3.6161],\n",
      "        [3.5219, 3.9744, 3.8081, 3.7563, 3.8393],\n",
      "        [3.4765, 3.6893, 3.8012, 3.5956, 3.6325],\n",
      "        [3.8943, 3.7703, 3.9224, 4.2898, 4.0386],\n",
      "        [3.6654, 3.8962, 3.8692, 3.8434, 3.7236],\n",
      "        [3.7778, 3.8596, 3.9792, 4.0026, 3.7928],\n",
      "        [3.5261, 3.8327, 3.9549, 3.7863, 3.5861],\n",
      "        [3.4942, 3.5480, 3.7740, 3.6538, 3.5728],\n",
      "        [3.6654, 3.9058, 3.8644, 3.9688, 3.8012],\n",
      "        [3.9831, 4.1373, 4.1302, 4.2999, 4.0603],\n",
      "        [3.4023, 3.8878, 3.8543, 3.7794, 3.7168],\n",
      "        [3.4926, 3.5457, 3.7683, 3.6494, 3.5701],\n",
      "        [3.5014, 3.7799, 3.8145, 3.7608, 3.6761],\n",
      "        [3.3250, 3.5479, 3.5928, 3.4687, 3.4700],\n",
      "        [3.4266, 3.7595, 3.8766, 3.6491, 3.6856],\n",
      "        [3.4238, 3.4976, 3.6659, 3.6201, 3.4766],\n",
      "        [3.4621, 3.6672, 3.6494, 3.6534, 3.5621],\n",
      "        [3.4947, 3.7100, 3.6729, 3.6967, 3.6029],\n",
      "        [3.5350, 3.8215, 3.9348, 3.7788, 3.5920],\n",
      "        [3.4814, 3.5355, 3.7606, 3.6396, 3.5555]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5271, 3.5333, 3.7198, 3.5677, 3.5108],\n",
      "        [3.4407, 3.6628, 3.8069, 3.6636, 3.6280],\n",
      "        [3.7027, 4.0070, 3.8799, 3.8872, 3.9629],\n",
      "        [3.3059, 3.5341, 3.5865, 3.4466, 3.4525],\n",
      "        [3.4199, 3.6445, 3.7839, 3.6557, 3.5214],\n",
      "        [3.5357, 3.6900, 3.8082, 3.7222, 3.7359],\n",
      "        [3.6436, 3.7636, 3.8546, 3.7501, 3.8142],\n",
      "        [3.7288, 3.8013, 4.0442, 4.0056, 3.6642],\n",
      "        [3.3312, 3.9859, 3.9174, 3.7332, 3.5697],\n",
      "        [3.5851, 3.6181, 3.8230, 3.7141, 3.6795],\n",
      "        [3.5860, 3.6648, 3.8604, 3.7391, 3.7041],\n",
      "        [3.5339, 3.7800, 3.8497, 3.7315, 3.6606],\n",
      "        [3.4032, 3.8888, 3.8574, 3.7800, 3.7205],\n",
      "        [3.4116, 3.5315, 3.6813, 3.6072, 3.4971],\n",
      "        [3.6494, 4.0152, 3.9341, 3.8852, 3.7973],\n",
      "        [3.9265, 3.8520, 4.0465, 4.1091, 3.8824],\n",
      "        [3.8261, 3.8664, 3.8261, 3.9247, 3.8685],\n",
      "        [3.3493, 3.5768, 3.6144, 3.5044, 3.4963],\n",
      "        [3.6960, 3.8155, 3.9796, 3.8091, 3.6212],\n",
      "        [3.5038, 3.6973, 3.6731, 3.6835, 3.6117],\n",
      "        [3.6663, 3.9069, 3.8675, 3.9695, 3.8047],\n",
      "        [3.4953, 3.6236, 3.8049, 3.7171, 3.6958],\n",
      "        [3.7834, 3.8672, 4.0026, 4.0058, 3.7961],\n",
      "        [3.5739, 3.8813, 3.8973, 3.7626, 3.5600],\n",
      "        [3.4894, 3.5233, 3.7629, 3.6706, 3.6327],\n",
      "        [3.5245, 3.5549, 3.7428, 3.6033, 3.5330],\n",
      "        [3.4006, 3.6428, 3.6515, 3.5746, 3.5509],\n",
      "        [3.6224, 3.9947, 3.9408, 3.8648, 3.8680],\n",
      "        [3.8118, 3.6103, 3.8679, 4.1290, 4.0227],\n",
      "        [3.3321, 3.6054, 3.6436, 3.5635, 3.5100],\n",
      "        [3.3829, 3.7287, 3.6020, 3.6669, 3.5006],\n",
      "        [3.6975, 4.0346, 3.9691, 3.9837, 3.8597],\n",
      "        [3.5247, 3.6124, 3.7208, 3.7484, 3.5611],\n",
      "        [3.5701, 3.6461, 3.8145, 3.7384, 3.6691],\n",
      "        [3.5351, 3.7643, 3.9217, 3.9275, 3.6160],\n",
      "        [3.6009, 3.7606, 3.8455, 3.7788, 3.7626],\n",
      "        [3.4154, 3.5378, 3.6902, 3.6066, 3.5002],\n",
      "        [3.6774, 3.7020, 3.8381, 3.6630, 3.5386],\n",
      "        [3.7607, 3.9634, 3.9357, 3.8977, 3.8918],\n",
      "        [3.8282, 4.0375, 3.8801, 3.8442, 3.7584],\n",
      "        [3.8952, 3.7713, 3.9255, 4.2908, 4.0419],\n",
      "        [3.4873, 3.6239, 3.7491, 3.7082, 3.5594],\n",
      "        [3.4836, 3.5133, 3.7982, 3.4969, 3.6519],\n",
      "        [3.6072, 3.7282, 3.8311, 3.8428, 3.6787],\n",
      "        [3.5193, 3.7866, 3.8481, 3.7382, 3.6476],\n",
      "        [3.6340, 3.7249, 3.8085, 3.7596, 3.6626],\n",
      "        [3.4452, 3.6610, 3.6582, 3.6231, 3.5694],\n",
      "        [4.1537, 4.4014, 4.0212, 4.0395, 3.9141],\n",
      "        [3.5184, 3.6425, 3.8033, 3.7132, 3.6173],\n",
      "        [3.4625, 3.5667, 3.8033, 3.6661, 3.5804],\n",
      "        [3.5072, 3.5686, 3.7905, 3.6690, 3.5834],\n",
      "        [3.9166, 3.9669, 4.0876, 4.1306, 3.9438],\n",
      "        [3.6360, 3.7169, 3.8212, 3.7773, 3.7613],\n",
      "        [3.7206, 3.8824, 3.8593, 3.8382, 3.8352],\n",
      "        [3.4296, 3.6443, 3.6478, 3.6092, 3.5520],\n",
      "        [3.5660, 3.9238, 3.7590, 3.7719, 3.6573],\n",
      "        [3.9391, 4.0611, 4.1613, 4.2153, 3.8967],\n",
      "        [3.5955, 3.8416, 3.8182, 3.7354, 3.7255],\n",
      "        [3.4208, 3.5022, 3.6639, 3.6284, 3.4941],\n",
      "        [4.0238, 4.0282, 4.2235, 4.2587, 4.0605],\n",
      "        [3.5494, 3.5943, 3.7018, 3.6353, 3.6569],\n",
      "        [3.4880, 3.6942, 3.6751, 3.6800, 3.5945],\n",
      "        [4.2576, 4.4496, 4.1548, 4.1354, 3.9662],\n",
      "        [3.5710, 3.8432, 3.8148, 3.7132, 3.6817]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5259, 3.6022, 3.7112, 3.7607, 3.5520],\n",
      "        [3.4331, 3.5292, 3.6892, 3.6400, 3.5132],\n",
      "        [3.8391, 3.8969, 4.0370, 4.0220, 3.7159],\n",
      "        [3.5060, 3.7511, 3.7017, 3.8094, 3.5696],\n",
      "        [3.5163, 3.6310, 3.7970, 3.6972, 3.6201],\n",
      "        [3.7416, 3.6219, 3.8784, 4.0178, 3.9517],\n",
      "        [3.4015, 3.6240, 3.6446, 3.5616, 3.5452],\n",
      "        [3.6300, 3.7150, 3.7625, 3.8317, 3.7052],\n",
      "        [3.4892, 3.6056, 3.7302, 3.7198, 3.5548],\n",
      "        [3.7965, 3.8778, 4.1306, 4.1087, 3.7308],\n",
      "        [3.5907, 3.9689, 4.0223, 3.9052, 3.8755],\n",
      "        [3.3753, 3.6186, 3.7124, 3.5793, 3.5167],\n",
      "        [3.4350, 3.8931, 3.8538, 3.6380, 3.5000],\n",
      "        [3.9341, 3.9617, 3.9142, 4.0626, 4.0574],\n",
      "        [3.6653, 3.9389, 3.9761, 3.8956, 3.8436],\n",
      "        [3.3824, 3.5579, 3.6684, 3.6224, 3.5018],\n",
      "        [3.5572, 3.9060, 3.9285, 3.8525, 3.8710],\n",
      "        [3.6618, 3.9010, 3.8637, 3.9608, 3.7980],\n",
      "        [3.4734, 3.6448, 3.6801, 3.6012, 3.5625],\n",
      "        [3.6853, 3.9894, 3.8763, 3.7013, 3.7658],\n",
      "        [3.3925, 3.7159, 3.7624, 3.5974, 3.5669],\n",
      "        [3.4157, 3.8329, 3.7908, 3.5317, 3.6830],\n",
      "        [3.5995, 3.6830, 3.9016, 3.7846, 3.7119],\n",
      "        [3.5458, 3.8193, 3.9112, 3.7729, 3.6209],\n",
      "        [3.5368, 3.6193, 3.8167, 3.6952, 3.6255],\n",
      "        [3.7250, 3.8521, 3.9792, 3.9106, 3.6898],\n",
      "        [3.5267, 3.6646, 3.8160, 3.7351, 3.6332],\n",
      "        [3.7175, 3.8063, 4.0391, 4.0086, 3.6584],\n",
      "        [3.8012, 4.0119, 3.8819, 3.7731, 3.7135],\n",
      "        [3.7294, 3.8849, 3.9713, 3.7986, 3.7829],\n",
      "        [3.7016, 3.7662, 3.8735, 3.7747, 3.5622],\n",
      "        [3.7749, 3.8434, 4.0454, 3.9305, 3.6424],\n",
      "        [3.5844, 3.6198, 3.9578, 3.9225, 3.5670],\n",
      "        [3.5451, 3.5640, 3.7556, 3.6021, 3.5434],\n",
      "        [3.7463, 3.8038, 3.9752, 3.9276, 3.6218],\n",
      "        [3.8312, 3.9122, 4.0339, 4.0474, 3.8521],\n",
      "        [3.5916, 3.6753, 3.8878, 3.7710, 3.7060],\n",
      "        [3.5625, 3.6255, 3.8120, 3.7082, 3.6733],\n",
      "        [3.4659, 3.4966, 3.7418, 3.6432, 3.6288],\n",
      "        [3.5133, 3.5599, 3.7472, 3.6081, 3.5399],\n",
      "        [3.5270, 3.6701, 3.7455, 3.7602, 3.6194],\n",
      "        [3.8110, 3.9673, 3.9747, 3.9243, 3.8898],\n",
      "        [3.9089, 4.1403, 4.0015, 3.8936, 3.8563],\n",
      "        [3.5200, 3.7873, 3.8507, 3.7384, 3.6506],\n",
      "        [3.8918, 3.9633, 3.9425, 3.9898, 3.9855],\n",
      "        [3.4899, 3.6918, 3.6672, 3.6933, 3.5895],\n",
      "        [3.6230, 3.9076, 3.8299, 3.8032, 3.7261],\n",
      "        [3.8600, 4.0004, 4.0034, 3.9693, 3.9378],\n",
      "        [3.5537, 3.8419, 3.7940, 3.7255, 3.6438],\n",
      "        [3.6182, 3.5905, 3.7429, 3.6764, 3.6767],\n",
      "        [3.5285, 3.7213, 3.8430, 3.7584, 3.7021],\n",
      "        [3.3782, 3.5259, 3.6640, 3.5602, 3.4673],\n",
      "        [3.3866, 3.5829, 3.7059, 3.5846, 3.5096],\n",
      "        [3.4416, 4.0079, 3.9705, 3.7821, 3.6327],\n",
      "        [3.4779, 3.6908, 3.8058, 3.5965, 3.6387],\n",
      "        [3.5892, 3.6020, 3.8081, 3.7251, 3.5962],\n",
      "        [3.5021, 3.8268, 3.8525, 3.6834, 3.7304],\n",
      "        [3.3664, 3.5572, 3.5933, 3.6218, 3.4470],\n",
      "        [3.5008, 3.6404, 3.7997, 3.7102, 3.6158],\n",
      "        [3.5608, 3.6693, 3.8898, 3.7195, 3.7663],\n",
      "        [3.4100, 3.4799, 3.6596, 3.6122, 3.4656],\n",
      "        [3.7811, 3.9527, 4.0663, 3.9549, 4.0339],\n",
      "        [3.6745, 3.7153, 3.8838, 3.8217, 3.6809],\n",
      "        [3.3372, 3.5613, 3.5477, 3.5130, 3.4319]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4273, 3.6427, 3.6496, 3.5972, 3.5593],\n",
      "        [3.4945, 3.5475, 3.7750, 3.6504, 3.5783],\n",
      "        [3.8666, 3.7905, 4.0222, 4.3631, 4.1842],\n",
      "        [3.8867, 4.0867, 3.9802, 4.0587, 4.0778],\n",
      "        [3.4635, 3.5676, 3.8072, 3.6664, 3.5853],\n",
      "        [3.6918, 3.9545, 3.9124, 3.8866, 3.7840],\n",
      "        [3.7766, 4.0999, 3.9674, 3.9908, 4.0059],\n",
      "        [3.6673, 3.9080, 3.8720, 3.9698, 3.8100],\n",
      "        [3.4235, 3.7229, 3.8041, 3.6235, 3.5864],\n",
      "        [3.7208, 4.0908, 3.9918, 3.8877, 4.0673],\n",
      "        [3.9219, 3.7694, 3.8802, 3.9453, 3.9085],\n",
      "        [3.6507, 3.7126, 3.8038, 3.8910, 3.7531],\n",
      "        [3.3759, 3.6029, 3.6319, 3.5311, 3.5211],\n",
      "        [3.5034, 3.6193, 3.8889, 3.5548, 3.7610],\n",
      "        [3.2714, 3.5357, 3.6652, 3.5077, 3.4896],\n",
      "        [3.5417, 3.8115, 3.8220, 3.7418, 3.7014],\n",
      "        [3.4904, 3.5243, 3.7669, 3.6709, 3.6377],\n",
      "        [3.3894, 3.7511, 3.9059, 3.6818, 3.6697],\n",
      "        [3.3475, 3.4842, 3.6423, 3.5182, 3.4339],\n",
      "        [3.4133, 3.6403, 3.6488, 3.5829, 3.5545],\n",
      "        [3.3725, 3.6027, 3.6352, 3.5362, 3.5234],\n",
      "        [3.4159, 3.8512, 3.8167, 3.5560, 3.7168],\n",
      "        [3.4605, 3.5324, 3.7021, 3.6339, 3.5018],\n",
      "        [3.6524, 3.8013, 3.8945, 3.9371, 3.7200],\n",
      "        [3.4201, 3.6366, 3.7811, 3.6490, 3.5207],\n",
      "        [3.6748, 3.7157, 3.8855, 3.8217, 3.6832],\n",
      "        [3.3375, 3.5618, 3.5492, 3.5130, 3.4341],\n",
      "        [3.7162, 3.9598, 3.9865, 3.8861, 3.7727],\n",
      "        [3.7281, 3.9240, 3.9552, 3.7587, 3.7877],\n",
      "        [3.4408, 3.6898, 3.8143, 3.5795, 3.7148],\n",
      "        [3.6004, 3.6203, 3.8207, 3.7150, 3.6918],\n",
      "        [3.3840, 3.6383, 3.7294, 3.5964, 3.5421],\n",
      "        [3.4364, 3.6671, 3.8047, 3.6611, 3.5511],\n",
      "        [4.0290, 4.2677, 3.9136, 3.9485, 3.7718],\n",
      "        [3.4197, 3.9281, 3.8356, 3.8278, 3.7561],\n",
      "        [3.6276, 3.9116, 3.8634, 3.9230, 3.7615],\n",
      "        [3.4890, 3.6953, 3.6792, 3.6802, 3.5995],\n",
      "        [3.4841, 3.8664, 3.7635, 3.5566, 3.6988],\n",
      "        [3.8278, 3.6907, 3.8412, 3.8446, 3.8257],\n",
      "        [3.7718, 3.8085, 3.9227, 3.8621, 3.9114],\n",
      "        [3.9710, 3.9236, 4.1176, 4.1917, 3.9638],\n",
      "        [3.7893, 3.7111, 3.8688, 4.1483, 3.9191],\n",
      "        [3.3850, 3.7288, 3.6090, 3.6653, 3.5043],\n",
      "        [3.6660, 3.7050, 3.8710, 3.8025, 3.6709],\n",
      "        [3.3731, 3.6390, 3.7237, 3.5815, 3.5195],\n",
      "        [3.5357, 3.7492, 3.8807, 3.7649, 3.7055],\n",
      "        [3.7155, 4.1058, 4.0332, 4.0659, 3.9582],\n",
      "        [3.4228, 3.5741, 3.6261, 3.6576, 3.4520],\n",
      "        [3.6329, 3.6965, 3.8879, 3.7840, 3.8122],\n",
      "        [3.6364, 3.8690, 3.9479, 3.8325, 3.8461],\n",
      "        [3.7030, 3.9145, 3.9969, 3.8366, 3.6646],\n",
      "        [3.4611, 3.6595, 3.6508, 3.6393, 3.5615],\n",
      "        [3.4366, 3.5558, 3.7042, 3.6256, 3.5418],\n",
      "        [3.6183, 3.7479, 3.8418, 3.8754, 3.6863],\n",
      "        [3.5014, 3.6178, 3.9005, 3.5389, 3.7615],\n",
      "        [3.3267, 3.5501, 3.5986, 3.4695, 3.4781],\n",
      "        [3.4269, 3.5058, 3.6763, 3.6133, 3.4970],\n",
      "        [3.4434, 3.9154, 3.9144, 3.7706, 3.8195],\n",
      "        [3.6813, 3.9866, 3.9963, 3.9159, 3.9065],\n",
      "        [4.0220, 4.1533, 3.8777, 3.9333, 3.7650],\n",
      "        [3.5324, 3.7382, 3.6895, 3.7521, 3.6354],\n",
      "        [3.3756, 3.6191, 3.7138, 3.5793, 3.5190],\n",
      "        [3.5640, 3.6882, 3.8346, 3.6086, 3.7273],\n",
      "        [3.9655, 4.0672, 4.1463, 4.2560, 3.8494]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6513, 3.9841, 4.0067, 3.8724, 3.7309],\n",
      "        [3.4911, 3.6143, 3.8174, 3.7121, 3.7034],\n",
      "        [3.4717, 3.6053, 3.7390, 3.6971, 3.5430],\n",
      "        [3.3868, 3.6954, 3.7469, 3.5919, 3.5611],\n",
      "        [3.6241, 3.8547, 3.8617, 3.8247, 3.7321],\n",
      "        [3.4782, 3.6268, 3.7354, 3.6162, 3.6004],\n",
      "        [3.4274, 3.6429, 3.6513, 3.5968, 3.5611],\n",
      "        [3.5174, 3.6846, 3.8143, 3.5996, 3.6866],\n",
      "        [3.7307, 3.8901, 3.9941, 4.0066, 3.7551],\n",
      "        [3.5728, 3.9845, 3.9989, 3.8819, 3.9056],\n",
      "        [3.4087, 3.5555, 3.7030, 3.6017, 3.5130],\n",
      "        [3.3787, 3.7020, 3.7521, 3.5853, 3.5591],\n",
      "        [3.4210, 3.6076, 3.7500, 3.6276, 3.5252],\n",
      "        [3.5909, 3.6126, 3.8180, 3.7382, 3.6123],\n",
      "        [3.6593, 3.8599, 3.9826, 3.7691, 3.6108],\n",
      "        [3.4263, 3.6299, 3.6282, 3.6232, 3.5012],\n",
      "        [3.6358, 3.7840, 3.8623, 3.9260, 3.6983],\n",
      "        [3.3769, 3.6726, 3.7396, 3.5830, 3.5423],\n",
      "        [3.5413, 3.7353, 3.6965, 3.7537, 3.6289],\n",
      "        [3.4243, 3.7233, 3.8087, 3.6267, 3.5867],\n",
      "        [3.7131, 3.8252, 3.9963, 3.8217, 3.6301],\n",
      "        [3.6277, 3.6165, 3.7824, 3.6995, 3.7026],\n",
      "        [3.5379, 3.5325, 3.6938, 3.6390, 3.7032],\n",
      "        [3.7550, 3.6204, 3.7218, 3.7190, 3.7977],\n",
      "        [3.7016, 3.8766, 3.8822, 3.7733, 3.7348],\n",
      "        [3.7851, 4.0250, 4.0613, 4.0016, 3.9260],\n",
      "        [3.4326, 3.6863, 3.8161, 3.5691, 3.7068],\n",
      "        [4.0006, 4.1201, 4.1600, 4.2892, 4.0569],\n",
      "        [3.6351, 3.6683, 3.9661, 3.8647, 3.6577],\n",
      "        [3.3725, 3.5932, 3.6323, 3.5292, 3.5345],\n",
      "        [3.6932, 3.9936, 3.9661, 3.8752, 3.8169],\n",
      "        [3.5174, 3.7218, 3.6875, 3.7293, 3.6246],\n",
      "        [3.7409, 3.8969, 3.9826, 3.8460, 3.6517],\n",
      "        [3.4271, 3.5079, 3.6805, 3.6376, 3.5085],\n",
      "        [3.5692, 3.9300, 4.0832, 3.9238, 3.7346],\n",
      "        [3.3874, 3.6257, 3.7339, 3.5981, 3.5413],\n",
      "        [3.6867, 3.9650, 3.9133, 3.8712, 3.7805],\n",
      "        [3.4640, 3.6173, 3.7889, 3.6921, 3.6086],\n",
      "        [3.8331, 3.9005, 4.0267, 4.0468, 3.8536],\n",
      "        [3.5280, 3.7554, 3.8457, 3.7768, 3.7254],\n",
      "        [3.7792, 3.9541, 4.0453, 3.9589, 4.0052],\n",
      "        [3.4896, 3.6063, 3.7335, 3.7195, 3.5589],\n",
      "        [3.4183, 3.6072, 3.7427, 3.6162, 3.5237],\n",
      "        [3.7535, 3.5579, 3.7177, 3.7351, 3.7407],\n",
      "        [3.8288, 3.9813, 3.9612, 3.9639, 3.9353],\n",
      "        [3.3870, 3.5835, 3.7091, 3.5842, 3.5137],\n",
      "        [3.5267, 3.5759, 3.6815, 3.6100, 3.6502],\n",
      "        [3.7796, 3.7415, 3.8566, 3.7567, 3.6441],\n",
      "        [3.7091, 3.6835, 3.8127, 4.0459, 3.8274],\n",
      "        [3.7633, 3.9488, 4.0602, 3.8718, 3.6822],\n",
      "        [3.4696, 3.5899, 3.7654, 3.6365, 3.5767],\n",
      "        [3.4400, 3.5986, 3.7453, 3.6640, 3.5209],\n",
      "        [3.6222, 3.9889, 3.8488, 3.8162, 3.8959],\n",
      "        [3.3488, 3.5673, 3.5604, 3.5212, 3.4469],\n",
      "        [3.5325, 3.7384, 3.6914, 3.7518, 3.6372],\n",
      "        [3.3903, 3.6041, 3.6347, 3.5486, 3.5239],\n",
      "        [3.6750, 3.7158, 3.8872, 3.8213, 3.6851],\n",
      "        [3.4298, 3.6037, 3.6604, 3.6279, 3.5281],\n",
      "        [3.6983, 3.8791, 3.9559, 3.9699, 3.7492],\n",
      "        [3.5415, 3.7299, 3.8039, 3.7236, 3.6937],\n",
      "        [3.8863, 3.9646, 4.0856, 4.0900, 3.9332],\n",
      "        [3.4688, 3.6615, 3.6974, 3.6494, 3.6134],\n",
      "        [3.7256, 3.8527, 3.9830, 3.9103, 3.6942],\n",
      "        [3.3583, 3.6611, 3.8739, 3.6013, 3.6925]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6282, 3.6690, 3.8388, 3.6725, 3.6400],\n",
      "        [3.4553, 3.9007, 3.8268, 3.7702, 3.7682],\n",
      "        [3.5346, 3.8429, 3.8096, 3.6816, 3.6882],\n",
      "        [3.9556, 4.1194, 4.0261, 4.1219, 4.1444],\n",
      "        [3.3792, 3.6043, 3.7138, 3.5765, 3.5183],\n",
      "        [3.6198, 3.9070, 3.9504, 3.8779, 3.7091],\n",
      "        [3.6277, 3.9118, 3.8665, 3.9219, 3.7649],\n",
      "        [3.7304, 3.8030, 4.0560, 4.0050, 3.6732],\n",
      "        [3.5817, 3.7217, 3.7791, 3.6894, 3.6709],\n",
      "        [3.5385, 3.6016, 3.8234, 3.6342, 3.6702],\n",
      "        [3.3892, 3.6786, 3.7472, 3.6010, 3.5584],\n",
      "        [3.3670, 3.5846, 3.5807, 3.5463, 3.4650],\n",
      "        [3.3837, 3.6344, 3.7269, 3.5867, 3.5391],\n",
      "        [3.5966, 3.9052, 3.8630, 3.8165, 3.8321],\n",
      "        [3.3177, 3.5245, 3.5615, 3.5302, 3.4491],\n",
      "        [3.5202, 3.7905, 3.8393, 3.7285, 3.6573],\n",
      "        [3.2620, 3.8352, 3.7966, 3.6497, 3.4564],\n",
      "        [3.4164, 3.5390, 3.6970, 3.6057, 3.5084],\n",
      "        [3.5685, 3.6251, 3.8073, 3.7024, 3.6827],\n",
      "        [3.3460, 3.6624, 3.5437, 3.6229, 3.4507],\n",
      "        [3.4163, 3.5027, 3.6740, 3.6260, 3.4932],\n",
      "        [3.7659, 3.9276, 4.0457, 3.9389, 4.0124],\n",
      "        [3.5352, 3.7813, 3.8572, 3.7306, 3.6695],\n",
      "        [3.5076, 3.9806, 3.8392, 3.8823, 3.7586],\n",
      "        [3.6682, 3.9067, 3.8762, 3.9639, 3.8121],\n",
      "        [3.5082, 3.5695, 3.7974, 3.6682, 3.5914],\n",
      "        [3.5190, 3.6918, 3.7127, 3.6857, 3.6463],\n",
      "        [3.5725, 3.7698, 3.8381, 3.7138, 3.8002],\n",
      "        [3.8775, 3.8033, 4.0163, 4.0383, 3.8385],\n",
      "        [3.7022, 3.7666, 3.8778, 3.7736, 3.5681],\n",
      "        [3.5103, 3.6367, 3.8008, 3.6995, 3.6197],\n",
      "        [3.6191, 3.7423, 3.9130, 3.7862, 3.7053],\n",
      "        [3.4067, 3.6099, 3.7252, 3.6014, 3.5545],\n",
      "        [3.2983, 3.8288, 3.8110, 3.6646, 3.4788],\n",
      "        [3.5244, 3.8350, 3.8495, 3.6412, 3.7193],\n",
      "        [3.7209, 4.0910, 3.9951, 3.8865, 4.0707],\n",
      "        [3.6730, 3.9103, 3.9247, 3.8352, 3.8336],\n",
      "        [3.4154, 3.5693, 3.7203, 3.6166, 3.5345],\n",
      "        [3.5503, 3.7184, 3.6535, 3.7501, 3.5530],\n",
      "        [3.6655, 3.9078, 3.9177, 3.9485, 3.7724],\n",
      "        [3.5556, 3.6333, 3.8281, 3.6761, 3.6769],\n",
      "        [3.6919, 3.9547, 3.9158, 3.8857, 3.7873],\n",
      "        [3.5687, 3.6317, 3.8084, 3.7046, 3.6838],\n",
      "        [3.6750, 3.7157, 3.8884, 3.8206, 3.6864],\n",
      "        [3.6924, 3.8420, 3.9610, 3.7922, 3.7586],\n",
      "        [3.4196, 3.6900, 3.8523, 3.6778, 3.6835],\n",
      "        [3.6560, 3.8807, 3.9944, 3.8468, 3.7345],\n",
      "        [3.7215, 3.8834, 3.8655, 3.8372, 3.8434],\n",
      "        [3.7199, 3.8932, 3.9710, 3.8285, 3.6399],\n",
      "        [3.6945, 3.8467, 3.9453, 3.7712, 3.7680],\n",
      "        [3.5299, 3.5743, 3.6940, 3.7684, 3.5326],\n",
      "        [3.4126, 3.5326, 3.6881, 3.6063, 3.5053],\n",
      "        [3.8425, 3.9346, 4.1893, 4.1647, 3.8025],\n",
      "        [3.6278, 3.6164, 3.7834, 3.6987, 3.7041],\n",
      "        [3.5928, 3.6810, 3.9037, 3.7858, 3.7194],\n",
      "        [3.6999, 3.7939, 3.9213, 3.8483, 3.8712],\n",
      "        [3.9360, 3.9081, 4.0227, 4.1166, 3.9461],\n",
      "        [3.8910, 3.8037, 4.0182, 4.0050, 3.8576],\n",
      "        [3.6457, 3.9783, 4.0055, 3.8689, 3.7213],\n",
      "        [3.2582, 3.5186, 3.6653, 3.4903, 3.5032],\n",
      "        [3.6470, 4.0054, 3.9308, 3.8579, 3.7983],\n",
      "        [3.5953, 4.0002, 3.8856, 3.9114, 3.8227],\n",
      "        [3.9975, 3.9788, 4.1734, 4.2197, 4.0098],\n",
      "        [3.5436, 3.5930, 3.8352, 3.7106, 3.7110]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5192, 3.8383, 3.8523, 3.6377, 3.7080],\n",
      "        [3.8760, 4.0679, 3.8922, 3.8574, 3.7740],\n",
      "        [3.5777, 3.8528, 3.8341, 3.7249, 3.6886],\n",
      "        [3.4266, 3.6192, 3.7849, 3.6983, 3.6247],\n",
      "        [3.6661, 3.8751, 3.9959, 3.8689, 3.7643],\n",
      "        [3.8454, 3.9274, 4.0320, 4.0590, 3.8188],\n",
      "        [3.7867, 4.0149, 3.8924, 3.8260, 3.7628],\n",
      "        [3.5028, 3.6990, 3.6721, 3.7036, 3.5973],\n",
      "        [3.8512, 3.7487, 3.9042, 4.2137, 3.9817],\n",
      "        [3.4791, 3.5636, 3.7332, 3.5258, 3.6245],\n",
      "        [3.4557, 3.6557, 3.6551, 3.6228, 3.5635],\n",
      "        [3.5945, 3.6179, 3.8329, 3.7319, 3.6448],\n",
      "        [3.5493, 3.5777, 3.8209, 3.7143, 3.7319],\n",
      "        [3.7118, 4.0444, 3.9834, 3.9982, 3.8746],\n",
      "        [3.4894, 3.6894, 3.6754, 3.6554, 3.6033],\n",
      "        [3.7064, 3.8873, 3.9832, 3.9015, 3.7526],\n",
      "        [3.8035, 3.9520, 4.0880, 3.9067, 3.6971],\n",
      "        [3.7166, 3.9892, 3.9130, 3.8164, 3.7642],\n",
      "        [3.4751, 3.6700, 3.6626, 3.6644, 3.5724],\n",
      "        [3.5216, 3.7206, 3.6974, 3.7302, 3.6290],\n",
      "        [3.6925, 3.7612, 3.8623, 3.7603, 3.5345],\n",
      "        [3.3048, 3.5239, 3.5852, 3.4393, 3.4511],\n",
      "        [3.5494, 3.6491, 3.8821, 3.7364, 3.6958],\n",
      "        [3.5215, 3.5744, 3.8001, 3.6705, 3.6173],\n",
      "        [3.5779, 3.6817, 3.8170, 3.7630, 3.6683],\n",
      "        [3.9443, 3.8345, 4.0618, 4.4183, 4.1962],\n",
      "        [3.5013, 3.6174, 3.9039, 3.5365, 3.7656],\n",
      "        [3.7191, 3.9390, 3.9653, 3.8707, 3.7590],\n",
      "        [3.6574, 3.9453, 3.9850, 3.9413, 3.9078],\n",
      "        [3.5008, 3.6270, 3.9176, 3.5338, 3.7743],\n",
      "        [3.4173, 3.6367, 3.6546, 3.5798, 3.5593],\n",
      "        [3.3782, 3.6417, 3.7270, 3.5768, 3.5292],\n",
      "        [3.3820, 3.6850, 3.7073, 3.6450, 3.5340],\n",
      "        [3.5209, 3.6206, 3.8033, 3.6905, 3.6244],\n",
      "        [3.5266, 3.5788, 3.8251, 3.6009, 3.6682],\n",
      "        [3.3820, 3.6845, 3.7180, 3.6435, 3.5389],\n",
      "        [3.6931, 3.9935, 3.9696, 3.8735, 3.8193],\n",
      "        [3.6654, 3.9055, 3.8747, 3.9661, 3.8107],\n",
      "        [3.4980, 3.8165, 3.8564, 3.6694, 3.7239],\n",
      "        [4.0595, 4.1567, 4.2601, 4.3233, 3.9186],\n",
      "        [3.5458, 3.6543, 3.8847, 3.6040, 3.7976],\n",
      "        [3.3841, 3.6867, 3.7481, 3.5973, 3.5610],\n",
      "        [3.5306, 3.6210, 3.8140, 3.6931, 3.6281],\n",
      "        [3.5323, 3.7381, 3.6936, 3.7500, 3.6394],\n",
      "        [3.8285, 3.6905, 3.8450, 3.8428, 3.8303],\n",
      "        [4.0665, 4.2467, 3.9912, 3.9713, 3.8095],\n",
      "        [3.4407, 3.6105, 3.6617, 3.6413, 3.5345],\n",
      "        [3.6508, 3.7124, 3.8074, 3.8889, 3.7574],\n",
      "        [3.5581, 3.6844, 3.9290, 3.7794, 3.7152],\n",
      "        [3.4573, 3.7526, 3.8559, 3.6656, 3.7042],\n",
      "        [3.7859, 3.8618, 3.9622, 3.9093, 3.9234],\n",
      "        [3.5839, 3.6594, 3.8870, 3.7692, 3.7129],\n",
      "        [3.4232, 3.7176, 3.6206, 3.6626, 3.5248],\n",
      "        [3.4137, 3.6235, 3.6255, 3.6122, 3.4923],\n",
      "        [3.3602, 3.5079, 3.6648, 3.5495, 3.4505],\n",
      "        [3.6725, 3.8645, 3.9403, 3.8271, 3.6360],\n",
      "        [3.4382, 4.0027, 3.8063, 3.6664, 3.7737],\n",
      "        [3.5648, 3.6319, 3.8439, 3.7355, 3.6814],\n",
      "        [3.4324, 3.5564, 3.7177, 3.6193, 3.5021],\n",
      "        [3.4589, 4.0262, 3.8289, 3.6885, 3.7976],\n",
      "        [3.8428, 3.8060, 3.9942, 3.9970, 3.8296],\n",
      "        [3.4621, 3.4814, 3.6374, 3.6124, 3.4736],\n",
      "        [3.5253, 3.6133, 3.8016, 3.6895, 3.6258],\n",
      "        [3.5085, 3.6312, 3.7963, 3.6918, 3.6191]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6704, 3.7163, 3.8267, 3.8281, 3.8270],\n",
      "        [3.8689, 3.9688, 4.1096, 4.1885, 3.9194],\n",
      "        [3.6189, 3.9052, 3.8345, 3.7832, 3.7233],\n",
      "        [3.5225, 3.6586, 3.8219, 3.7199, 3.6512],\n",
      "        [3.5051, 3.6979, 3.6816, 3.6804, 3.6212],\n",
      "        [3.6949, 3.7555, 3.8822, 3.7435, 3.8448],\n",
      "        [3.8404, 3.9043, 4.0330, 4.0458, 3.8660],\n",
      "        [3.5373, 3.8269, 3.8409, 3.6659, 3.7153],\n",
      "        [3.5792, 3.8572, 3.8328, 3.7429, 3.6756],\n",
      "        [3.5145, 3.9345, 3.9355, 3.8178, 3.8624],\n",
      "        [3.4796, 3.9382, 3.7696, 3.6575, 3.7693],\n",
      "        [3.6745, 3.7234, 3.7878, 3.9191, 3.7761],\n",
      "        [3.9307, 3.8068, 3.9271, 3.9700, 3.9488],\n",
      "        [3.4595, 4.0258, 3.8293, 3.6872, 3.7981],\n",
      "        [3.6872, 3.9643, 3.9164, 3.8683, 3.7833],\n",
      "        [3.6374, 3.8638, 3.8416, 3.7276, 3.7526],\n",
      "        [3.5580, 3.6799, 3.8118, 3.7018, 3.7890],\n",
      "        [3.5317, 4.0244, 3.9717, 3.9963, 3.7981],\n",
      "        [3.7743, 3.9177, 4.0181, 3.8716, 3.6789],\n",
      "        [3.4720, 3.6046, 3.7414, 3.6940, 3.5457],\n",
      "        [3.3621, 3.5854, 3.6306, 3.5059, 3.5138],\n",
      "        [3.6061, 3.8784, 3.9142, 3.7811, 3.5921],\n",
      "        [3.5458, 4.0303, 4.0462, 3.8094, 3.6904],\n",
      "        [3.7410, 3.9701, 4.0494, 3.8557, 3.5915],\n",
      "        [3.6661, 3.9070, 3.9191, 3.9462, 3.7739],\n",
      "        [3.7148, 4.1476, 3.9926, 4.0595, 3.9581],\n",
      "        [3.7581, 3.5608, 3.7248, 3.7226, 3.7612],\n",
      "        [3.4548, 3.9244, 3.8687, 3.7660, 3.8388],\n",
      "        [3.3849, 3.5271, 3.6550, 3.6153, 3.4990],\n",
      "        [3.3825, 3.5339, 3.6609, 3.6099, 3.4971],\n",
      "        [3.9148, 3.9832, 4.1576, 4.1609, 3.9441],\n",
      "        [3.4163, 3.8506, 3.8211, 3.5526, 3.7215],\n",
      "        [3.4110, 3.8533, 3.8185, 3.5576, 3.7297],\n",
      "        [3.4298, 3.5523, 3.5936, 3.6518, 3.4468],\n",
      "        [3.9736, 3.8709, 3.9988, 4.0334, 3.9610],\n",
      "        [3.7255, 3.7166, 3.8481, 3.6917, 3.6051],\n",
      "        [3.5643, 3.8997, 3.8006, 3.7818, 3.6997],\n",
      "        [3.3877, 3.6250, 3.7362, 3.5950, 3.5440],\n",
      "        [3.4927, 3.9162, 3.9096, 3.7122, 3.5464],\n",
      "        [3.3584, 3.5859, 3.6275, 3.5155, 3.5175],\n",
      "        [3.6065, 3.7954, 3.8233, 3.7840, 3.7578],\n",
      "        [3.4037, 3.6840, 3.7525, 3.6006, 3.5791],\n",
      "        [3.3835, 3.6529, 3.7348, 3.5801, 3.5340],\n",
      "        [3.5607, 3.6322, 3.8607, 3.7184, 3.6876],\n",
      "        [3.7096, 3.6827, 3.8152, 4.0431, 3.8302],\n",
      "        [3.9013, 3.9641, 4.1420, 4.1493, 3.9199],\n",
      "        [3.9562, 4.1186, 4.0274, 4.1195, 4.1458],\n",
      "        [3.6817, 3.9261, 3.9055, 3.8751, 3.7742],\n",
      "        [3.4814, 4.0503, 4.0278, 3.8253, 3.7007],\n",
      "        [3.3863, 3.5485, 3.6958, 3.5799, 3.5031],\n",
      "        [3.5993, 3.6937, 3.9235, 3.7832, 3.7223],\n",
      "        [3.4221, 3.8218, 3.8568, 3.6344, 3.7135],\n",
      "        [3.7801, 4.0253, 4.0575, 3.9888, 3.9198],\n",
      "        [3.5259, 3.7189, 3.6862, 3.7298, 3.6196],\n",
      "        [3.5207, 3.7898, 3.8408, 3.7261, 3.6588],\n",
      "        [3.8118, 3.8951, 4.0928, 4.0664, 3.7899],\n",
      "        [3.9657, 3.8519, 4.1318, 4.4494, 4.2852],\n",
      "        [3.8339, 3.8984, 4.1542, 4.1310, 3.7915],\n",
      "        [3.4465, 3.6617, 3.6663, 3.6199, 3.5788],\n",
      "        [3.4637, 3.6450, 3.7985, 3.7227, 3.6044],\n",
      "        [3.7798, 3.9536, 4.0489, 3.9558, 4.0081],\n",
      "        [3.7776, 3.5824, 3.7217, 3.7131, 3.7871],\n",
      "        [3.9432, 4.0247, 4.0693, 4.1787, 3.9819],\n",
      "        [3.8799, 3.7902, 4.0113, 4.0400, 3.8374]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5297, 3.7542, 3.8552, 3.7733, 3.7284],\n",
      "        [3.6746, 3.9866, 3.9623, 3.8596, 3.7947],\n",
      "        [3.5511, 3.6478, 3.8866, 3.7345, 3.6964],\n",
      "        [3.3835, 3.6834, 3.7223, 3.6416, 3.5394],\n",
      "        [3.8793, 3.8019, 4.0220, 4.0357, 3.8401],\n",
      "        [3.5446, 3.6809, 3.8159, 3.7059, 3.7659],\n",
      "        [3.4457, 3.6943, 3.6918, 3.7251, 3.5598],\n",
      "        [3.4771, 3.8713, 3.8828, 3.6925, 3.5804],\n",
      "        [3.5363, 3.5433, 3.7451, 3.5776, 3.5307],\n",
      "        [3.7505, 3.8801, 4.0241, 4.0121, 3.7614],\n",
      "        [3.5098, 3.6231, 3.7964, 3.6849, 3.6171],\n",
      "        [3.6991, 3.9739, 3.9543, 3.8652, 3.8175],\n",
      "        [3.5631, 3.7518, 3.8325, 3.7051, 3.7735],\n",
      "        [3.6229, 3.6624, 3.8403, 3.6629, 3.6237],\n",
      "        [3.3612, 3.4876, 3.6515, 3.5221, 3.4460],\n",
      "        [3.9714, 3.8906, 4.0801, 4.1404, 3.9628],\n",
      "        [3.5148, 3.7166, 3.6952, 3.7175, 3.6224],\n",
      "        [3.5392, 3.8232, 3.9554, 3.7759, 3.6061],\n",
      "        [3.5278, 3.9357, 3.9504, 3.8272, 3.8704],\n",
      "        [3.8349, 3.8991, 4.0343, 4.0434, 3.8565],\n",
      "        [3.6127, 4.0071, 3.9680, 3.8555, 3.8675],\n",
      "        [3.4379, 3.6484, 3.6681, 3.5957, 3.5650],\n",
      "        [3.9234, 4.0288, 4.1576, 4.2156, 3.8447],\n",
      "        [3.4610, 3.7591, 3.9885, 3.7098, 3.8036],\n",
      "        [3.4108, 3.5934, 3.7255, 3.5947, 3.5451],\n",
      "        [3.4100, 3.5381, 3.7021, 3.6071, 3.5099],\n",
      "        [3.7091, 3.7753, 4.1011, 4.0556, 3.7196],\n",
      "        [3.5240, 3.6501, 3.8223, 3.5786, 3.4282],\n",
      "        [3.5853, 3.6559, 3.8907, 3.7712, 3.7098],\n",
      "        [3.8930, 3.7411, 3.9275, 4.2893, 4.0323],\n",
      "        [3.9793, 3.8739, 4.0832, 4.1602, 3.9812],\n",
      "        [3.5250, 3.6071, 3.8127, 3.6864, 3.6173],\n",
      "        [3.5164, 3.6590, 3.8207, 3.7152, 3.6340],\n",
      "        [3.3782, 3.6713, 3.7457, 3.5792, 3.5450],\n",
      "        [3.4101, 3.7721, 3.8350, 3.5898, 3.6897],\n",
      "        [3.7639, 4.1009, 4.0254, 4.0246, 3.9751],\n",
      "        [3.9094, 3.9736, 4.1570, 4.1577, 3.9331],\n",
      "        [3.7209, 3.8084, 4.0457, 3.8462, 3.5626],\n",
      "        [3.5119, 3.6419, 3.8115, 3.7026, 3.6240],\n",
      "        [3.3515, 3.5769, 3.6256, 3.5005, 3.5056],\n",
      "        [3.7741, 3.6898, 3.8714, 4.1236, 3.9043],\n",
      "        [3.5502, 3.5496, 3.7327, 3.6673, 3.7226],\n",
      "        [3.3873, 3.5478, 3.6999, 3.5793, 3.5032],\n",
      "        [3.4742, 3.8428, 3.8524, 3.7472, 3.8244],\n",
      "        [3.4748, 3.7266, 3.8694, 3.6239, 3.7664],\n",
      "        [3.3995, 3.5843, 3.7036, 3.5735, 3.5380],\n",
      "        [3.5392, 3.6748, 3.9062, 3.8457, 3.8497],\n",
      "        [3.4859, 3.9208, 3.9124, 3.6984, 3.5418],\n",
      "        [3.4771, 3.6757, 3.6711, 3.6483, 3.5892],\n",
      "        [3.6942, 3.7635, 4.0650, 4.0199, 3.7096],\n",
      "        [3.5185, 3.6589, 3.8237, 3.7168, 3.6366],\n",
      "        [3.5654, 4.0073, 3.9144, 3.8925, 3.8640],\n",
      "        [3.9748, 4.0766, 4.0669, 4.2727, 4.0329],\n",
      "        [3.5387, 3.7648, 3.9418, 3.9242, 3.6267],\n",
      "        [3.7813, 3.8606, 3.9959, 3.9997, 3.8063],\n",
      "        [3.9669, 3.8511, 4.1364, 4.4489, 4.2853],\n",
      "        [3.5178, 3.6387, 3.8112, 3.6987, 3.6319],\n",
      "        [3.5639, 3.6221, 3.8635, 3.7251, 3.6427],\n",
      "        [3.5575, 3.9717, 3.8710, 3.8686, 3.8065],\n",
      "        [3.6742, 3.9669, 3.9905, 3.8911, 3.8928],\n",
      "        [3.3719, 3.5627, 3.6698, 3.6100, 3.4976],\n",
      "        [3.4109, 3.6274, 3.6525, 3.5699, 3.5440],\n",
      "        [3.7505, 3.8801, 4.0241, 4.0121, 3.7614],\n",
      "        [3.9461, 3.8333, 4.0669, 4.4166, 4.1967]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8322, 3.6883, 3.8540, 3.8411, 3.8309],\n",
      "        [3.5928, 3.9039, 3.8318, 3.8922, 3.7518],\n",
      "        [3.8908, 4.0846, 3.9934, 4.0544, 4.0821],\n",
      "        [3.9365, 3.8632, 4.0766, 4.1096, 3.9074],\n",
      "        [3.7444, 3.8941, 3.9939, 3.8421, 3.6548],\n",
      "        [3.4064, 3.6825, 3.7604, 3.5997, 3.5788],\n",
      "        [3.7884, 3.6682, 3.8609, 3.8030, 3.7700],\n",
      "        [3.5529, 3.6469, 3.8906, 3.7343, 3.6960],\n",
      "        [3.7051, 3.8744, 3.8938, 3.7697, 3.7373],\n",
      "        [3.4866, 3.7587, 3.9374, 3.8244, 3.5824],\n",
      "        [3.7956, 3.8911, 4.1305, 4.1348, 3.8083],\n",
      "        [3.5302, 3.6154, 3.8768, 3.7350, 3.6540],\n",
      "        [3.5796, 3.6350, 3.9010, 3.7941, 3.7732],\n",
      "        [3.4471, 3.9140, 3.9274, 3.7662, 3.8248],\n",
      "        [3.5310, 3.5917, 3.7187, 3.7609, 3.5455],\n",
      "        [3.6975, 3.8185, 4.1380, 3.7581, 3.6204],\n",
      "        [3.4868, 3.5348, 3.7798, 3.6365, 3.5677],\n",
      "        [3.5636, 3.6305, 3.8688, 3.7176, 3.6873],\n",
      "        [3.8688, 3.7116, 3.8688, 3.8624, 3.8570],\n",
      "        [3.5589, 3.5720, 3.8122, 3.7059, 3.7338],\n",
      "        [3.4111, 3.5472, 3.7122, 3.5948, 3.5126],\n",
      "        [3.3576, 3.5774, 3.6279, 3.5028, 3.5043],\n",
      "        [3.7919, 4.0491, 3.9488, 3.9758, 4.0640],\n",
      "        [3.5406, 4.0203, 3.8763, 3.9119, 3.8105],\n",
      "        [3.4739, 3.6513, 3.7660, 3.6589, 3.6535],\n",
      "        [3.7228, 3.8051, 4.0619, 4.0052, 3.6659],\n",
      "        [3.5378, 3.7371, 3.7173, 3.7517, 3.6417],\n",
      "        [3.3376, 3.5540, 3.5582, 3.5004, 3.4367],\n",
      "        [3.8780, 3.9426, 3.9353, 3.9805, 3.9651],\n",
      "        [3.4883, 3.6613, 3.7793, 3.6713, 3.6644],\n",
      "        [3.7994, 3.9722, 4.1109, 4.1226, 4.1552],\n",
      "        [3.5879, 4.1522, 4.0643, 4.0809, 3.9249],\n",
      "        [3.9161, 3.9428, 3.8991, 4.0326, 4.0516],\n",
      "        [3.5135, 3.6340, 3.8111, 3.6965, 3.6209],\n",
      "        [3.4237, 3.6438, 3.7987, 3.6514, 3.5307],\n",
      "        [3.5870, 3.9788, 3.8424, 3.7820, 3.8702],\n",
      "        [3.3933, 3.6020, 3.6450, 3.5447, 3.5262],\n",
      "        [3.7918, 3.7449, 3.8798, 3.7735, 3.6770],\n",
      "        [3.7509, 3.9352, 4.0767, 3.9700, 3.9582],\n",
      "        [3.6707, 3.9058, 3.8860, 3.9654, 3.8144],\n",
      "        [3.6522, 3.8640, 3.9327, 3.7935, 3.6143],\n",
      "        [3.6269, 3.5104, 3.9532, 3.7688, 3.6632],\n",
      "        [3.5256, 3.5993, 3.8183, 3.6833, 3.6112],\n",
      "        [3.5049, 3.6152, 3.9125, 3.5342, 3.7657],\n",
      "        [4.0391, 4.0549, 4.2090, 4.2727, 4.1038],\n",
      "        [3.4727, 3.6355, 3.6975, 3.5963, 3.5606],\n",
      "        [3.5425, 3.5267, 3.7035, 3.6343, 3.7061],\n",
      "        [3.6483, 3.6243, 3.7902, 3.6939, 3.7111],\n",
      "        [3.7125, 3.6810, 3.8238, 4.0424, 3.8300],\n",
      "        [4.0402, 4.1521, 4.2375, 4.3456, 3.9294],\n",
      "        [3.5136, 3.6319, 3.8186, 3.7074, 3.6341],\n",
      "        [3.3838, 3.8972, 3.8861, 3.6821, 3.8146],\n",
      "        [3.5252, 3.7684, 3.9442, 3.9267, 3.5942],\n",
      "        [3.6221, 3.5884, 3.7552, 3.6722, 3.6840],\n",
      "        [3.5610, 3.6776, 3.8359, 3.5984, 3.7258],\n",
      "        [3.5291, 3.7298, 3.7020, 3.7368, 3.6314],\n",
      "        [3.4558, 3.6565, 3.6693, 3.6204, 3.5831],\n",
      "        [3.7304, 3.9495, 4.0602, 3.8341, 3.5815],\n",
      "        [3.5897, 3.6187, 3.9808, 3.9192, 3.5745],\n",
      "        [4.0267, 4.1511, 3.8905, 3.9294, 3.7696],\n",
      "        [3.4586, 3.6637, 3.6713, 3.6319, 3.5760],\n",
      "        [3.4745, 3.4926, 3.8029, 3.4635, 3.6526],\n",
      "        [3.4925, 3.6039, 3.7442, 3.7156, 3.5614],\n",
      "        [3.4282, 3.5429, 3.6085, 3.6525, 3.4998]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3888, 3.6846, 3.7596, 3.5954, 3.5606],\n",
      "        [3.5243, 3.6697, 3.7658, 3.6702, 3.6428],\n",
      "        [3.8780, 3.9411, 4.0428, 4.1010, 3.8699],\n",
      "        [3.5132, 3.6286, 3.8093, 3.6902, 3.6188],\n",
      "        [3.5634, 3.7777, 3.9463, 3.9056, 3.6572],\n",
      "        [3.4103, 3.6066, 3.7558, 3.6115, 3.5169],\n",
      "        [3.6047, 3.6874, 3.9268, 3.7699, 3.7226],\n",
      "        [3.9712, 4.1241, 3.9104, 3.9069, 3.7872],\n",
      "        [3.7090, 4.0057, 3.9005, 3.8836, 3.9720],\n",
      "        [3.9390, 3.7673, 4.0055, 4.3389, 4.1872],\n",
      "        [3.7852, 3.6558, 3.8533, 3.7971, 3.7623],\n",
      "        [3.7063, 3.9026, 3.9952, 3.8951, 3.7839],\n",
      "        [3.3685, 3.5813, 3.6867, 3.6037, 3.4936],\n",
      "        [3.5957, 3.8342, 3.8442, 3.7319, 3.7271],\n",
      "        [3.5890, 3.6568, 3.8993, 3.7673, 3.7126],\n",
      "        [3.6722, 3.9055, 3.8898, 3.9658, 3.8138],\n",
      "        [3.3435, 3.7267, 3.9002, 3.5825, 3.6405],\n",
      "        [3.9500, 3.9031, 4.0161, 4.1164, 3.9133],\n",
      "        [4.1771, 4.4010, 4.1194, 4.1056, 3.9189],\n",
      "        [3.4195, 3.6356, 3.8170, 3.7170, 3.6370],\n",
      "        [3.6787, 3.9078, 3.9419, 3.8328, 3.8343],\n",
      "        [3.7183, 3.9605, 3.8742, 3.7006, 3.6811],\n",
      "        [3.3889, 3.5251, 3.6668, 3.6148, 3.4982],\n",
      "        [3.4948, 3.6899, 3.6855, 3.6894, 3.5954],\n",
      "        [3.5922, 3.6202, 3.8488, 3.7300, 3.6609],\n",
      "        [3.4883, 3.9605, 3.7895, 3.6757, 3.7880],\n",
      "        [3.6609, 4.0365, 4.0276, 3.8829, 3.8827],\n",
      "        [3.4629, 3.9128, 3.8646, 3.7789, 3.8098],\n",
      "        [3.5517, 3.8177, 3.9326, 3.7693, 3.6278],\n",
      "        [3.4699, 3.7178, 3.7542, 3.7420, 3.5939],\n",
      "        [3.9723, 4.0649, 4.1720, 4.2530, 3.8543],\n",
      "        [3.4022, 3.5519, 3.7130, 3.5905, 3.5110],\n",
      "        [3.7172, 4.0423, 3.9975, 3.9970, 3.8743],\n",
      "        [3.3938, 3.6210, 3.6700, 3.5488, 3.5508],\n",
      "        [3.8965, 3.7399, 3.9357, 4.2897, 4.0315],\n",
      "        [3.9976, 4.1105, 4.1401, 4.2646, 4.0431],\n",
      "        [3.8998, 3.7988, 4.0483, 4.3821, 4.1942],\n",
      "        [3.5754, 3.6917, 3.8491, 3.6340, 3.4789],\n",
      "        [3.4975, 3.9143, 3.9236, 3.7121, 3.5456],\n",
      "        [3.2758, 3.5332, 3.6813, 3.5038, 3.4934],\n",
      "        [3.6014, 3.9027, 3.8763, 3.8138, 3.8329],\n",
      "        [3.6634, 3.6952, 3.8855, 3.7907, 3.6745],\n",
      "        [3.4313, 3.5030, 3.6927, 3.6096, 3.5009],\n",
      "        [3.7366, 3.8298, 3.9992, 3.9091, 3.6698],\n",
      "        [3.3429, 3.5605, 3.6261, 3.4782, 3.4908],\n",
      "        [3.3508, 3.7248, 3.8999, 3.5778, 3.6460],\n",
      "        [3.3767, 3.6386, 3.7092, 3.6216, 3.5112],\n",
      "        [3.7415, 3.8110, 3.9941, 3.9101, 3.6458],\n",
      "        [3.6451, 3.8803, 3.8616, 3.9294, 3.7708],\n",
      "        [3.3841, 3.6281, 3.7071, 3.6221, 3.5125],\n",
      "        [3.7022, 3.8785, 3.8971, 3.7888, 3.7355],\n",
      "        [3.4993, 3.6838, 3.8227, 3.5928, 3.6631],\n",
      "        [3.9772, 3.9211, 4.1350, 4.1889, 3.9681],\n",
      "        [3.6292, 4.1820, 4.0863, 4.1186, 3.9544],\n",
      "        [3.9431, 3.9486, 3.9323, 4.0374, 4.0440],\n",
      "        [3.4551, 3.6557, 3.6778, 3.6085, 3.5898],\n",
      "        [3.4311, 3.5940, 3.7412, 3.5617, 3.5543],\n",
      "        [3.5011, 3.6217, 3.8262, 3.7136, 3.7048],\n",
      "        [3.4049, 3.9469, 3.9334, 3.7517, 3.6782],\n",
      "        [3.5133, 3.7047, 3.6968, 3.7015, 3.6181],\n",
      "        [3.5307, 3.6000, 3.7292, 3.7569, 3.5581],\n",
      "        [3.4401, 3.6163, 3.6449, 3.6333, 3.5023],\n",
      "        [3.7523, 3.7209, 3.8659, 3.7267, 3.6272],\n",
      "        [3.6673, 3.7350, 3.8708, 3.7311, 3.8134]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6044, 3.6074, 3.9619, 3.8190, 3.6787],\n",
      "        [3.7510, 3.6797, 3.8563, 4.1316, 3.8745],\n",
      "        [3.6434, 3.8827, 3.9541, 3.8103, 3.8411],\n",
      "        [3.4041, 3.5572, 3.7189, 3.5874, 3.5125],\n",
      "        [3.5742, 3.6215, 3.7937, 3.6852, 3.6930],\n",
      "        [3.4715, 3.6646, 3.6779, 3.6388, 3.5879],\n",
      "        [3.3815, 3.6414, 3.7439, 3.5801, 3.5289],\n",
      "        [3.4493, 3.7060, 3.8234, 3.6073, 3.6105],\n",
      "        [3.4345, 3.6279, 3.6640, 3.5906, 3.5488],\n",
      "        [3.4927, 4.0451, 4.0495, 3.7524, 3.6493],\n",
      "        [3.3996, 3.5743, 3.7288, 3.5869, 3.5171],\n",
      "        [3.5855, 3.6540, 3.8876, 3.7452, 3.6952],\n",
      "        [3.5334, 3.5907, 3.7251, 3.7626, 3.5444],\n",
      "        [3.4405, 3.6118, 3.7884, 3.7055, 3.5926],\n",
      "        [3.6490, 4.0843, 3.9668, 3.9879, 3.8986],\n",
      "        [3.4619, 3.5515, 3.8180, 3.6517, 3.5797],\n",
      "        [3.9158, 3.9762, 4.1772, 4.1690, 3.9371],\n",
      "        [3.4787, 3.5608, 3.7450, 3.5235, 3.6117],\n",
      "        [3.6876, 3.9836, 4.0161, 3.9135, 3.9102],\n",
      "        [4.0141, 4.2357, 3.9103, 3.9198, 3.7593],\n",
      "        [3.5930, 3.6613, 3.8925, 3.7699, 3.7095],\n",
      "        [3.4768, 3.6297, 3.7966, 3.5618, 3.6721],\n",
      "        [3.6620, 4.0359, 4.0306, 3.8843, 3.8820],\n",
      "        [3.5433, 3.6880, 3.8331, 3.7201, 3.7454],\n",
      "        [3.5728, 3.9223, 3.7833, 3.7704, 3.6656],\n",
      "        [3.8337, 3.8639, 3.8477, 3.9230, 3.8763],\n",
      "        [3.7885, 3.8298, 3.9807, 3.9075, 3.9343],\n",
      "        [3.5250, 3.7659, 3.9552, 3.8415, 3.6131],\n",
      "        [3.5161, 3.6400, 3.8226, 3.7042, 3.6224],\n",
      "        [4.1632, 4.3594, 4.1030, 4.0724, 3.8914],\n",
      "        [3.7289, 4.0819, 4.0846, 3.9449, 3.9326],\n",
      "        [3.5092, 3.6720, 3.9007, 3.8012, 3.7976],\n",
      "        [3.4938, 3.6852, 3.6889, 3.6816, 3.6037],\n",
      "        [3.7731, 3.9720, 4.0051, 3.7744, 3.8306],\n",
      "        [3.5091, 3.7023, 3.6948, 3.7103, 3.6062],\n",
      "        [3.6627, 3.7485, 3.9907, 3.7558, 3.4885],\n",
      "        [3.7006, 3.7596, 3.8790, 3.7625, 3.5352],\n",
      "        [3.5819, 3.8769, 3.7910, 3.5853, 3.6391],\n",
      "        [3.4770, 3.4916, 3.8089, 3.4650, 3.6513],\n",
      "        [3.5179, 3.6197, 3.8091, 3.6878, 3.6172],\n",
      "        [3.5755, 3.8721, 3.9550, 3.8559, 3.6628],\n",
      "        [3.6978, 3.8187, 4.1449, 3.7639, 3.6217],\n",
      "        [3.5161, 3.9750, 3.9279, 3.9527, 3.8240],\n",
      "        [3.6260, 3.7622, 3.9416, 3.7927, 3.7272],\n",
      "        [3.5623, 3.6244, 3.8209, 3.7099, 3.6641],\n",
      "        [3.5614, 3.8403, 3.8234, 3.7240, 3.6499],\n",
      "        [3.7050, 3.8758, 3.9747, 3.9680, 3.7507],\n",
      "        [3.7448, 3.6936, 3.8613, 4.0348, 3.8458],\n",
      "        [3.3219, 3.5685, 3.6794, 3.5663, 3.5238],\n",
      "        [3.7224, 3.6663, 3.8375, 4.0790, 3.8427],\n",
      "        [3.4672, 3.4955, 3.6635, 3.6175, 3.4770],\n",
      "        [3.5271, 3.7192, 3.7072, 3.7253, 3.6274],\n",
      "        [3.4256, 3.5668, 3.6425, 3.6533, 3.4636],\n",
      "        [3.5022, 3.7092, 3.6993, 3.6951, 3.6142],\n",
      "        [3.9092, 4.0483, 4.0525, 4.0169, 4.0203],\n",
      "        [3.3876, 3.5314, 3.6755, 3.6107, 3.4957],\n",
      "        [3.6076, 3.6231, 4.0670, 3.8027, 3.7621],\n",
      "        [3.5203, 3.6262, 3.8152, 3.6999, 3.6292],\n",
      "        [3.5856, 3.8551, 3.8516, 3.7443, 3.6744],\n",
      "        [3.5872, 3.7183, 3.7936, 3.6878, 3.6714],\n",
      "        [3.7481, 3.6190, 3.8996, 4.0162, 3.9572],\n",
      "        [3.5340, 3.6152, 3.8220, 3.6886, 3.6260],\n",
      "        [3.4471, 3.6464, 3.6750, 3.6142, 3.5784],\n",
      "        [3.5058, 3.6755, 3.8028, 3.6879, 3.6759]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6784, 3.7440, 3.8839, 3.8145, 3.8010],\n",
      "        [3.4678, 3.6653, 3.6851, 3.6207, 3.5860],\n",
      "        [3.5506, 3.6395, 3.9084, 3.6159, 3.7938],\n",
      "        [3.5244, 3.6410, 3.8301, 3.5733, 3.4222],\n",
      "        [3.6485, 3.6843, 3.8645, 3.6840, 3.6150],\n",
      "        [3.4567, 3.6646, 3.6909, 3.6275, 3.5790],\n",
      "        [3.8723, 3.7097, 3.8776, 3.8653, 3.8553],\n",
      "        [3.3790, 3.6139, 3.7376, 3.5765, 3.5178],\n",
      "        [3.4777, 3.4907, 3.8111, 3.4660, 3.6504],\n",
      "        [3.4039, 3.5652, 3.7285, 3.5982, 3.5249],\n",
      "        [3.9294, 3.8011, 4.0520, 4.0418, 3.8821],\n",
      "        [3.4966, 3.6885, 3.6907, 3.6918, 3.5938],\n",
      "        [3.4117, 3.4762, 3.6775, 3.6020, 3.4705],\n",
      "        [3.4237, 3.6332, 3.6714, 3.5803, 3.5574],\n",
      "        [3.4334, 3.5427, 3.7198, 3.6270, 3.5324],\n",
      "        [3.9157, 3.9709, 4.1743, 4.1611, 3.9308],\n",
      "        [3.6939, 3.7368, 3.8921, 3.7547, 3.5885],\n",
      "        [3.4715, 3.5434, 3.7269, 3.5064, 3.5975],\n",
      "        [3.7059, 3.7108, 3.8407, 4.0162, 3.8354],\n",
      "        [3.3905, 3.6065, 3.6590, 3.5381, 3.5388],\n",
      "        [3.4710, 4.0278, 3.8542, 3.6902, 3.7986],\n",
      "        [3.4201, 3.6201, 3.6427, 3.6127, 3.4904],\n",
      "        [3.5776, 3.6318, 3.8545, 3.7143, 3.6871],\n",
      "        [3.3835, 3.7267, 3.7816, 3.6603, 3.7358],\n",
      "        [3.5860, 3.8527, 3.8580, 3.7335, 3.6827],\n",
      "        [4.0448, 4.1516, 3.8800, 3.9288, 3.7617],\n",
      "        [3.8937, 3.9568, 3.9699, 4.0033, 3.9848],\n",
      "        [3.8887, 3.9550, 4.1103, 4.1037, 3.9260],\n",
      "        [3.4047, 3.7206, 3.7895, 3.6132, 3.5882],\n",
      "        [3.4951, 3.7454, 3.7275, 3.7820, 3.5790],\n",
      "        [3.4245, 3.6033, 3.7613, 3.6146, 3.5240],\n",
      "        [3.5120, 3.5613, 3.8152, 3.6648, 3.5902],\n",
      "        [3.5211, 3.9315, 3.9533, 3.8198, 3.8606],\n",
      "        [3.6106, 4.0123, 3.8606, 3.7914, 3.9035],\n",
      "        [3.5171, 3.7768, 3.9575, 3.7954, 3.6188],\n",
      "        [3.4595, 3.6583, 3.6758, 3.6266, 3.5710],\n",
      "        [3.4910, 3.7108, 3.9665, 3.7414, 3.7615],\n",
      "        [3.6248, 3.7436, 3.8645, 3.8739, 3.6885],\n",
      "        [3.9851, 4.0054, 4.1822, 4.2377, 4.0265],\n",
      "        [3.5137, 3.5593, 3.8123, 3.6626, 3.5936],\n",
      "        [3.4121, 3.6052, 3.7606, 3.6136, 3.5154],\n",
      "        [4.0091, 4.1172, 4.1766, 4.3053, 4.0684],\n",
      "        [3.5850, 3.8527, 3.8609, 3.7436, 3.6843],\n",
      "        [3.7243, 3.7390, 3.8607, 4.0303, 3.8531],\n",
      "        [3.5082, 3.6133, 3.9208, 3.5367, 3.7634],\n",
      "        [3.6553, 3.9726, 3.8613, 3.8382, 3.9158],\n",
      "        [3.8216, 3.8719, 4.0138, 4.0690, 4.0492],\n",
      "        [3.7740, 3.9711, 4.0076, 3.7755, 3.8297],\n",
      "        [3.4080, 3.6210, 3.6663, 3.5599, 3.5496],\n",
      "        [3.3866, 3.5824, 3.7242, 3.5766, 3.5125],\n",
      "        [3.9076, 3.8501, 3.9581, 3.9481, 3.9064],\n",
      "        [3.3594, 3.7884, 3.8374, 3.6804, 3.5126],\n",
      "        [3.5229, 3.7125, 3.7104, 3.7240, 3.6244],\n",
      "        [3.7196, 3.8210, 4.0173, 3.8205, 3.6303],\n",
      "        [3.8172, 3.8383, 3.8278, 3.8879, 3.8731],\n",
      "        [3.7469, 3.9584, 3.9579, 3.8858, 3.8628],\n",
      "        [3.6712, 3.6987, 3.8755, 3.6566, 3.5261],\n",
      "        [3.4237, 3.6332, 3.6714, 3.5803, 3.5574],\n",
      "        [3.5067, 3.7021, 3.7046, 3.6968, 3.6134],\n",
      "        [3.9818, 4.0739, 4.0816, 4.2770, 4.0305],\n",
      "        [3.8854, 3.9501, 4.0734, 4.1090, 3.8540],\n",
      "        [3.6584, 3.6856, 3.8780, 3.7777, 3.6640],\n",
      "        [3.8995, 3.7997, 4.0379, 4.0064, 3.8568],\n",
      "        [3.6858, 3.8438, 3.8783, 3.7049, 3.7114]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4574, 3.6533, 3.6847, 3.6112, 3.5872],\n",
      "        [3.6981, 3.9789, 3.9475, 3.8146, 3.7645],\n",
      "        [4.0272, 4.1019, 4.1385, 4.3258, 4.0692],\n",
      "        [3.5287, 3.6227, 3.8211, 3.6884, 3.6203],\n",
      "        [3.8422, 3.8953, 4.0512, 4.0479, 3.8530],\n",
      "        [3.5203, 3.7129, 3.7104, 3.7205, 3.6189],\n",
      "        [3.5287, 3.7158, 3.7177, 3.7313, 3.6259],\n",
      "        [3.9661, 3.7899, 4.0334, 4.3427, 4.2069],\n",
      "        [3.4390, 3.6384, 3.7941, 3.5745, 3.6843],\n",
      "        [3.6862, 3.7200, 3.8870, 3.7461, 3.5861],\n",
      "        [3.5938, 3.6749, 3.8433, 3.7717, 3.6679],\n",
      "        [3.5559, 3.5434, 3.7596, 3.6787, 3.7226],\n",
      "        [3.6169, 3.6739, 3.8584, 3.6366, 3.4814],\n",
      "        [3.8287, 3.8904, 4.0554, 4.0108, 3.8531],\n",
      "        [3.7363, 3.9189, 3.9800, 3.7579, 3.7888],\n",
      "        [3.5169, 3.7583, 3.8456, 3.7045, 3.6690],\n",
      "        [3.3164, 3.5217, 3.6066, 3.4437, 3.4525],\n",
      "        [3.5256, 3.6134, 3.8185, 3.6849, 3.6191],\n",
      "        [3.4836, 3.7507, 3.9562, 3.7913, 3.5778],\n",
      "        [3.4147, 3.5443, 3.7227, 3.5977, 3.5095],\n",
      "        [3.4916, 3.7097, 3.9684, 3.7418, 3.7604],\n",
      "        [3.3974, 3.7225, 3.7279, 3.6772, 3.5075],\n",
      "        [3.7882, 4.0106, 4.0836, 3.9970, 3.9302],\n",
      "        [3.6481, 3.7193, 3.8536, 3.7769, 3.7753],\n",
      "        [3.3899, 3.5949, 3.7351, 3.5810, 3.5162],\n",
      "        [3.6275, 3.7530, 3.7829, 3.7908, 3.7141],\n",
      "        [3.4047, 3.5494, 3.6823, 3.5763, 3.5231],\n",
      "        [3.6343, 3.7389, 3.7815, 3.8076, 3.7112],\n",
      "        [3.4226, 3.7595, 3.8467, 3.5904, 3.6730],\n",
      "        [3.9078, 4.0292, 4.1805, 4.2107, 4.2101],\n",
      "        [3.7029, 3.8937, 4.0018, 3.8969, 3.7762],\n",
      "        [3.6820, 3.7796, 4.0929, 3.7824, 3.5693],\n",
      "        [3.6993, 3.8165, 4.1497, 3.7652, 3.6195],\n",
      "        [3.7958, 4.0101, 3.9152, 3.8277, 3.7599],\n",
      "        [3.7928, 4.0197, 4.0846, 4.0010, 3.9253],\n",
      "        [3.7034, 3.7259, 3.8303, 3.9799, 3.8135],\n",
      "        [3.6590, 3.6844, 3.8799, 3.7781, 3.6629],\n",
      "        [3.5235, 3.7114, 3.7124, 3.7244, 3.6233],\n",
      "        [3.4465, 3.5937, 3.7656, 3.6630, 3.5202],\n",
      "        [3.5197, 3.6093, 3.8106, 3.6823, 3.6135],\n",
      "        [3.4655, 3.9105, 3.8719, 3.7817, 3.8073],\n",
      "        [3.2655, 3.8298, 3.8125, 3.6407, 3.4564],\n",
      "        [3.6029, 3.9240, 3.8486, 3.6298, 3.7382],\n",
      "        [3.7468, 3.9419, 4.0864, 3.9422, 3.9570],\n",
      "        [3.6871, 3.7183, 3.8880, 3.7313, 3.6088],\n",
      "        [3.4486, 3.6590, 3.8322, 3.6628, 3.6340],\n",
      "        [3.4228, 3.4972, 3.6945, 3.6260, 3.4913],\n",
      "        [3.4227, 3.6480, 3.7912, 3.6316, 3.5501],\n",
      "        [3.4336, 3.5024, 3.7024, 3.6369, 3.5080],\n",
      "        [3.4285, 3.5702, 3.6473, 3.6545, 3.4515],\n",
      "        [3.4891, 3.6837, 3.6957, 3.6654, 3.5976],\n",
      "        [3.9235, 3.9786, 4.1834, 4.1644, 3.9408],\n",
      "        [3.5920, 3.5830, 3.8258, 3.7157, 3.5899],\n",
      "        [3.6108, 3.6876, 3.9439, 3.7867, 3.7214],\n",
      "        [3.4883, 3.6819, 3.6924, 3.6773, 3.5876],\n",
      "        [3.6309, 3.5946, 3.7806, 3.6864, 3.6914],\n",
      "        [3.8363, 3.6853, 3.8647, 3.8445, 3.8282],\n",
      "        [3.6833, 3.7014, 3.9225, 3.8264, 3.6844],\n",
      "        [3.5673, 3.7576, 3.8414, 3.7520, 3.7231],\n",
      "        [3.6991, 3.9148, 3.9599, 3.8949, 3.7674],\n",
      "        [3.3605, 3.4931, 3.6724, 3.5401, 3.4410],\n",
      "        [3.4273, 3.6412, 3.8084, 3.6542, 3.5276],\n",
      "        [3.4202, 3.6254, 3.6710, 3.5735, 3.5468],\n",
      "        [3.9101, 3.9611, 4.1664, 4.1471, 3.9193]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4566, 3.6060, 3.8013, 3.6999, 3.5918],\n",
      "        [3.7070, 4.0304, 4.0023, 3.9844, 3.8653],\n",
      "        [3.5502, 3.7425, 3.7249, 3.7645, 3.6430],\n",
      "        [3.2837, 3.5303, 3.6933, 3.5104, 3.5163],\n",
      "        [3.5941, 3.6735, 3.8448, 3.7718, 3.6671],\n",
      "        [3.6008, 3.6738, 3.9253, 3.7858, 3.7164],\n",
      "        [3.4372, 3.5468, 3.6215, 3.6533, 3.4734],\n",
      "        [3.3813, 3.6321, 3.7474, 3.5789, 3.5234],\n",
      "        [3.9416, 3.8613, 4.0892, 4.1195, 3.9013],\n",
      "        [3.8395, 3.6645, 3.7757, 3.7982, 3.8294],\n",
      "        [3.5309, 3.7645, 3.9614, 3.9307, 3.5906],\n",
      "        [3.3938, 3.6894, 3.7678, 3.5906, 3.5597],\n",
      "        [3.6722, 3.8540, 3.9246, 3.8604, 3.8040],\n",
      "        [3.3919, 3.6654, 3.7615, 3.5840, 3.5382],\n",
      "        [3.4736, 3.6072, 3.5832, 3.7108, 3.4844],\n",
      "        [3.6025, 3.6112, 3.8545, 3.7332, 3.6410],\n",
      "        [3.5400, 3.7324, 3.7177, 3.7364, 3.6396],\n",
      "        [3.6857, 3.7195, 3.8921, 3.7398, 3.5864],\n",
      "        [3.3957, 3.6867, 3.7731, 3.5994, 3.5667],\n",
      "        [3.4854, 4.0459, 4.0578, 3.8304, 3.7007],\n",
      "        [3.5852, 3.8422, 3.8535, 3.7287, 3.6753],\n",
      "        [4.0764, 4.3179, 3.9840, 4.0029, 3.8264],\n",
      "        [3.5243, 3.6535, 3.8411, 3.7200, 3.6322],\n",
      "        [3.6287, 3.7251, 3.8362, 3.7338, 3.6866],\n",
      "        [3.4830, 3.6037, 3.8242, 3.6867, 3.6124],\n",
      "        [3.4338, 3.4990, 3.7014, 3.6125, 3.4977],\n",
      "        [3.6730, 3.8986, 3.8936, 3.9594, 3.7984],\n",
      "        [3.8857, 3.7434, 3.8671, 3.8888, 3.8780],\n",
      "        [3.6720, 3.6963, 3.8790, 3.6571, 3.5243],\n",
      "        [3.3917, 3.6761, 3.7650, 3.5875, 3.5507],\n",
      "        [3.5091, 3.6106, 3.9239, 3.5371, 3.7614],\n",
      "        [3.3902, 3.5936, 3.7364, 3.5811, 3.5155],\n",
      "        [3.4073, 3.7809, 3.8580, 3.6008, 3.6961],\n",
      "        [3.7814, 3.9113, 4.0391, 3.8742, 3.6752],\n",
      "        [3.3751, 3.4828, 3.6857, 3.5810, 3.4950],\n",
      "        [3.6929, 3.9884, 4.0249, 3.9270, 3.9075],\n",
      "        [3.3991, 3.6107, 3.6633, 3.5569, 3.5341],\n",
      "        [3.3686, 3.5801, 3.6494, 3.5080, 3.5098],\n",
      "        [3.7051, 3.9810, 3.9846, 3.8718, 3.8074],\n",
      "        [3.5832, 3.8758, 3.9307, 3.7622, 3.5664],\n",
      "        [3.3577, 3.4876, 3.6690, 3.5282, 3.4345],\n",
      "        [3.5298, 3.5947, 3.8304, 3.6866, 3.6072],\n",
      "        [3.6565, 3.7394, 3.9858, 3.8413, 3.6988],\n",
      "        [3.6031, 3.9938, 3.9079, 3.9117, 3.8199],\n",
      "        [3.4859, 3.5571, 3.7520, 3.5270, 3.6204],\n",
      "        [3.4720, 3.6623, 3.6891, 3.6286, 3.5927],\n",
      "        [3.3068, 3.5015, 3.5635, 3.5094, 3.4255],\n",
      "        [3.5391, 3.8856, 4.0435, 3.9456, 3.6651],\n",
      "        [3.4504, 3.4558, 3.7885, 3.4312, 3.6237],\n",
      "        [3.7113, 3.9471, 3.9913, 3.8864, 3.7767],\n",
      "        [3.4515, 3.6894, 3.7075, 3.7281, 3.5558],\n",
      "        [3.7215, 3.7226, 3.8764, 4.0612, 3.8696],\n",
      "        [3.4927, 3.9159, 3.9321, 3.7019, 3.5374],\n",
      "        [3.5084, 3.6950, 3.7089, 3.6972, 3.6149],\n",
      "        [3.6125, 3.8463, 3.8997, 3.8244, 3.7019],\n",
      "        [3.7632, 3.6030, 3.7448, 3.7192, 3.7950],\n",
      "        [3.5379, 3.9865, 3.9514, 3.9698, 3.8333],\n",
      "        [3.5440, 3.6731, 3.9246, 3.8531, 3.8465],\n",
      "        [3.6062, 3.6042, 3.9677, 3.8207, 3.6759],\n",
      "        [3.4559, 3.6631, 3.6868, 3.6103, 3.6114],\n",
      "        [3.5775, 3.6581, 3.8387, 3.7341, 3.6652],\n",
      "        [3.9171, 3.9683, 4.1794, 4.1619, 3.9290],\n",
      "        [3.3828, 3.6202, 3.6827, 3.5994, 3.5150],\n",
      "        [3.4291, 3.8894, 3.7538, 3.6332, 3.7113]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6599, 3.8849, 3.8804, 3.8084, 3.7390],\n",
      "        [3.5679, 3.6244, 3.8809, 3.7205, 3.6826],\n",
      "        [3.8637, 3.9649, 3.9820, 3.9760, 3.9566],\n",
      "        [3.8129, 3.9424, 3.9707, 3.9296, 3.9130],\n",
      "        [3.8777, 3.8418, 3.9684, 3.9281, 3.9039],\n",
      "        [3.5729, 3.6234, 3.9047, 3.7625, 3.7177],\n",
      "        [3.5816, 3.8216, 3.8421, 3.7224, 3.7224],\n",
      "        [3.6490, 3.8924, 3.9065, 3.9320, 3.7603],\n",
      "        [3.3938, 3.6880, 3.7685, 3.5904, 3.5589],\n",
      "        [3.5521, 3.6907, 3.7793, 3.6344, 3.5444],\n",
      "        [3.5708, 3.6795, 3.8572, 3.6071, 3.7260],\n",
      "        [3.3931, 3.6484, 3.7560, 3.5891, 3.5437],\n",
      "        [3.8942, 3.7896, 4.0529, 4.3818, 4.1836],\n",
      "        [3.6302, 3.6561, 3.8559, 3.6711, 3.6060],\n",
      "        [3.9135, 3.9562, 4.1554, 4.1446, 3.9254],\n",
      "        [3.9466, 3.9001, 4.0471, 4.1195, 3.9436],\n",
      "        [3.7302, 3.8749, 3.8869, 3.8379, 3.8397],\n",
      "        [3.7098, 3.7578, 3.8998, 3.7737, 3.5654],\n",
      "        [3.4515, 3.6879, 3.7084, 3.7279, 3.5551],\n",
      "        [3.5397, 3.7304, 3.7165, 3.7511, 3.6348],\n",
      "        [3.6858, 3.7180, 3.8929, 3.7396, 3.5856],\n",
      "        [3.5982, 3.6101, 4.0775, 3.7901, 3.7506],\n",
      "        [3.4460, 3.9195, 3.9377, 3.7830, 3.6983],\n",
      "        [3.5502, 3.7410, 3.7259, 3.7643, 3.6422],\n",
      "        [3.7972, 4.0434, 3.9623, 3.9794, 4.0592],\n",
      "        [3.4420, 3.6133, 3.6797, 3.6431, 3.5393],\n",
      "        [3.4244, 3.5369, 3.7215, 3.6088, 3.5083],\n",
      "        [3.7058, 3.9147, 3.9778, 3.9102, 3.7717],\n",
      "        [3.6684, 4.0604, 4.0180, 3.9143, 3.9606],\n",
      "        [3.5401, 3.7309, 3.7186, 3.7362, 3.6387],\n",
      "        [3.6838, 3.6983, 3.9248, 3.8264, 3.6828],\n",
      "        [3.7254, 3.7349, 3.8649, 4.0309, 3.8505],\n",
      "        [3.4164, 3.5870, 3.7420, 3.5973, 3.5401],\n",
      "        [3.3415, 3.5606, 3.5527, 3.5841, 3.4574],\n",
      "        [3.6369, 3.8636, 3.9462, 3.7902, 3.6015],\n",
      "        [3.4459, 3.5268, 3.8062, 3.6305, 3.5661],\n",
      "        [3.7032, 3.7578, 4.1040, 4.0245, 3.7007],\n",
      "        [3.6741, 3.8672, 4.0187, 3.8701, 3.7598],\n",
      "        [3.6741, 3.6963, 3.8965, 3.8011, 3.6704],\n",
      "        [3.8310, 3.9202, 4.0179, 4.0496, 3.8124],\n",
      "        [3.5243, 3.6519, 3.8421, 3.7198, 3.6314],\n",
      "        [3.4048, 3.5466, 3.7222, 3.5930, 3.5070],\n",
      "        [3.5849, 3.6422, 3.8775, 3.7246, 3.6912],\n",
      "        [3.9676, 4.0553, 4.1856, 4.2497, 3.8452],\n",
      "        [3.9153, 3.9839, 4.0563, 4.1392, 3.9459],\n",
      "        [3.5553, 3.6722, 3.7562, 3.6291, 3.6397],\n",
      "        [3.7119, 3.9306, 3.9879, 3.8960, 3.7775],\n",
      "        [3.7872, 4.0139, 4.0818, 3.9931, 3.9203],\n",
      "        [3.2972, 3.5429, 3.6911, 3.5273, 3.4995],\n",
      "        [3.4274, 3.5623, 3.6491, 3.6547, 3.4604],\n",
      "        [3.4384, 3.5971, 3.7743, 3.6561, 3.5138],\n",
      "        [3.3999, 3.7092, 3.7869, 3.5954, 3.5687],\n",
      "        [3.5756, 3.6132, 3.7813, 3.6749, 3.6903],\n",
      "        [3.6433, 3.7236, 3.8351, 3.7550, 3.6789],\n",
      "        [3.9714, 3.8399, 4.1507, 4.4512, 4.2690],\n",
      "        [3.6426, 3.8490, 3.9582, 3.8125, 3.8269],\n",
      "        [3.5536, 3.6368, 3.8990, 3.7351, 3.6869],\n",
      "        [3.5608, 3.6957, 3.7922, 3.6557, 3.5534],\n",
      "        [3.5284, 3.9621, 3.8870, 3.7699, 3.9441],\n",
      "        [3.6431, 3.7754, 3.8880, 3.9252, 3.6960],\n",
      "        [3.5223, 3.7518, 3.8426, 3.7008, 3.6817],\n",
      "        [3.5243, 3.7316, 3.9127, 3.8076, 3.6494],\n",
      "        [3.5277, 3.5122, 3.7321, 3.5634, 3.5020],\n",
      "        [3.3873, 3.5175, 3.6681, 3.6213, 3.4926]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8672, 3.9190, 3.9368, 3.9719, 3.9532],\n",
      "        [3.6532, 3.8036, 3.9870, 3.7633, 3.6016],\n",
      "        [3.6069, 3.7332, 3.8512, 3.7393, 3.7620],\n",
      "        [3.7227, 4.1398, 4.0181, 4.0623, 3.9519],\n",
      "        [3.7465, 3.7053, 3.8747, 3.7187, 3.6063],\n",
      "        [3.5877, 3.9773, 3.8417, 3.7817, 3.8683],\n",
      "        [3.5131, 3.6020, 3.7603, 3.7289, 3.5520],\n",
      "        [3.2640, 3.8265, 3.8198, 3.6549, 3.4528],\n",
      "        [3.6750, 3.8981, 3.9008, 3.9682, 3.8082],\n",
      "        [3.4398, 3.9053, 3.9235, 3.7755, 3.6972],\n",
      "        [3.8977, 3.7550, 3.9027, 3.9091, 3.9125],\n",
      "        [3.4356, 3.7386, 3.9339, 3.8063, 3.5224],\n",
      "        [3.3775, 3.5546, 3.6868, 3.6120, 3.4918],\n",
      "        [3.4218, 3.6620, 3.8999, 3.6699, 3.6888],\n",
      "        [3.3839, 3.6129, 3.7408, 3.5753, 3.5174],\n",
      "        [3.6750, 3.8981, 3.9008, 3.9682, 3.8082],\n",
      "        [3.6095, 3.7105, 3.8569, 3.8322, 3.6735],\n",
      "        [3.5120, 3.6891, 3.7038, 3.6821, 3.6152],\n",
      "        [3.5223, 3.7501, 3.8432, 3.7002, 3.6807],\n",
      "        [3.4384, 3.5954, 3.7747, 3.6555, 3.5128],\n",
      "        [3.5284, 3.6036, 3.8198, 3.6880, 3.6181],\n",
      "        [3.7098, 3.7560, 3.9003, 3.7731, 3.5645],\n",
      "        [3.4474, 3.7467, 3.8541, 3.5918, 3.6726],\n",
      "        [3.5587, 3.5851, 3.8573, 3.7327, 3.7347],\n",
      "        [3.6490, 3.8906, 3.9071, 3.9315, 3.7593],\n",
      "        [3.5221, 3.6502, 3.8397, 3.7176, 3.6278],\n",
      "        [3.8963, 4.0770, 4.0076, 4.0576, 4.0763],\n",
      "        [3.8108, 4.0029, 3.9095, 3.7718, 3.7150],\n",
      "        [3.4726, 3.5046, 3.6887, 3.6200, 3.4892],\n",
      "        [3.4938, 3.7232, 3.9284, 3.6799, 3.6325],\n",
      "        [3.6279, 3.7483, 3.7855, 3.7901, 3.7116],\n",
      "        [3.5706, 3.6777, 3.8576, 3.6065, 3.7249],\n",
      "        [3.8598, 3.7391, 3.9280, 4.2158, 3.9765],\n",
      "        [3.8109, 3.6027, 3.9154, 4.1026, 4.0063],\n",
      "        [3.6356, 3.9251, 4.0318, 3.8499, 3.6869],\n",
      "        [3.3850, 3.8173, 3.8108, 3.5281, 3.6938],\n",
      "        [3.5866, 3.8471, 3.8683, 3.7436, 3.6809],\n",
      "        [3.6450, 3.6740, 3.8667, 3.6614, 3.4989],\n",
      "        [3.6017, 4.0509, 3.9249, 3.9628, 3.8357],\n",
      "        [3.3730, 3.5670, 3.6898, 3.6106, 3.4902],\n",
      "        [3.5439, 3.7619, 3.9742, 3.9284, 3.6054],\n",
      "        [3.4789, 3.5808, 3.8333, 3.6747, 3.5985],\n",
      "        [3.3937, 3.6863, 3.7689, 3.5898, 3.5579],\n",
      "        [3.6811, 3.7084, 3.8921, 3.7279, 3.5937],\n",
      "        [3.5874, 3.6471, 3.8943, 3.7460, 3.6905],\n",
      "        [3.5629, 3.7611, 3.9399, 3.8830, 3.6512],\n",
      "        [3.5427, 3.8334, 3.8357, 3.6810, 3.6841],\n",
      "        [3.4338, 3.5262, 3.7190, 3.6158, 3.5073],\n",
      "        [4.1660, 4.3928, 4.0524, 4.0386, 3.9188],\n",
      "        [3.6591, 3.6914, 3.8816, 3.7127, 3.5943],\n",
      "        [3.5120, 3.6891, 3.7038, 3.6821, 3.6152],\n",
      "        [3.8219, 3.8716, 4.0313, 4.0640, 4.0460],\n",
      "        [3.5932, 3.9599, 4.0461, 3.8939, 3.8787],\n",
      "        [3.5641, 3.8340, 3.8345, 3.7252, 3.6457],\n",
      "        [3.3445, 3.5534, 3.5741, 3.5110, 3.4329],\n",
      "        [3.5332, 3.5929, 3.7393, 3.7590, 3.5531],\n",
      "        [3.4118, 3.7221, 3.7933, 3.6150, 3.5955],\n",
      "        [3.4032, 3.5461, 3.7210, 3.5888, 3.5070],\n",
      "        [3.6949, 3.7309, 3.8966, 3.7546, 3.5851],\n",
      "        [3.5194, 3.6810, 3.7700, 3.6611, 3.6408],\n",
      "        [3.9870, 3.9994, 4.1908, 4.2380, 4.0229],\n",
      "        [3.7580, 3.8714, 4.0439, 4.0152, 3.7554],\n",
      "        [3.5467, 3.8627, 3.7828, 3.8411, 3.7048],\n",
      "        [3.6829, 3.7051, 3.9117, 3.8198, 3.6816]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7033, 3.8516, 3.9011, 3.7200, 3.7206],\n",
      "        [3.7150, 3.8756, 4.0077, 3.9017, 3.7462],\n",
      "        [3.4805, 3.7514, 3.9567, 3.8270, 3.5660],\n",
      "        [3.5543, 4.0380, 3.9083, 3.9350, 3.8128],\n",
      "        [3.7713, 3.5981, 3.7544, 3.7209, 3.7992],\n",
      "        [3.4014, 3.7818, 3.7028, 3.4681, 3.6205],\n",
      "        [3.7169, 4.1058, 4.1370, 4.1124, 3.9464],\n",
      "        [3.5292, 3.9103, 3.9248, 3.8336, 3.8414],\n",
      "        [3.4907, 3.5252, 3.7931, 3.6382, 3.5608],\n",
      "        [3.4199, 3.6294, 3.6739, 3.5801, 3.5520],\n",
      "        [3.5216, 3.6482, 3.8400, 3.7167, 3.6265],\n",
      "        [3.5879, 3.8468, 3.8632, 3.7446, 3.6690],\n",
      "        [4.0399, 4.2562, 3.9389, 3.9467, 3.7700],\n",
      "        [3.5720, 3.6557, 3.8940, 3.6564, 3.7904],\n",
      "        [3.4852, 3.5519, 3.7531, 3.5255, 3.6173],\n",
      "        [3.5413, 3.7278, 3.7318, 3.7535, 3.6346],\n",
      "        [3.6801, 3.8524, 3.9649, 3.8268, 3.6298],\n",
      "        [3.7413, 3.9725, 4.1327, 3.9793, 3.9741],\n",
      "        [3.5246, 3.6336, 3.8357, 3.5721, 3.4174],\n",
      "        [3.5178, 3.8440, 3.8950, 3.6185, 3.7319],\n",
      "        [3.6747, 3.8808, 3.9089, 3.8814, 3.7544],\n",
      "        [3.9316, 3.9925, 4.1635, 4.1519, 3.7609],\n",
      "        [3.4588, 3.6849, 3.7160, 3.6853, 3.5382],\n",
      "        [3.4119, 3.4687, 3.6827, 3.6009, 3.4658],\n",
      "        [3.6845, 3.7748, 4.1048, 3.7847, 3.5731],\n",
      "        [3.6126, 3.8918, 4.0868, 3.9453, 3.7810],\n",
      "        [4.0062, 3.8897, 4.0227, 4.0596, 3.9979],\n",
      "        [3.3719, 3.5403, 3.6026, 3.6083, 3.4560],\n",
      "        [3.7715, 3.9533, 3.9740, 3.8967, 3.8950],\n",
      "        [3.9297, 4.0185, 4.1787, 4.2116, 3.8385],\n",
      "        [3.3840, 3.6713, 3.7652, 3.5878, 3.5441],\n",
      "        [3.7607, 3.8835, 4.1077, 3.9716, 3.9632],\n",
      "        [3.8257, 3.9211, 4.0592, 3.9770, 4.0630],\n",
      "        [3.8454, 3.9684, 3.9902, 3.9680, 3.9330],\n",
      "        [3.6531, 4.0481, 4.0436, 3.9038, 3.9399],\n",
      "        [3.5977, 4.0413, 4.0407, 4.0507, 3.8670],\n",
      "        [3.5246, 3.6886, 3.8347, 3.7019, 3.6870],\n",
      "        [3.2717, 3.8010, 3.8039, 3.6815, 3.5027],\n",
      "        [3.3969, 3.6942, 3.7761, 3.6013, 3.5684],\n",
      "        [3.4802, 3.6343, 3.7062, 3.5986, 3.5621],\n",
      "        [3.4394, 3.9033, 3.9238, 3.7745, 3.6960],\n",
      "        [3.6504, 4.0758, 3.9744, 3.9880, 3.8927],\n",
      "        [3.6792, 3.7360, 3.8888, 3.8134, 3.7963],\n",
      "        [3.4593, 3.6475, 3.6827, 3.6220, 3.5763],\n",
      "        [3.8878, 3.7919, 4.0420, 4.0400, 3.8341],\n",
      "        [3.7138, 3.9682, 3.9830, 3.8712, 3.8142],\n",
      "        [3.9707, 3.7798, 4.0409, 4.3450, 4.2035],\n",
      "        [4.0317, 3.9323, 4.1080, 4.1348, 4.0738],\n",
      "        [3.4599, 3.6510, 3.6807, 3.6256, 3.5663],\n",
      "        [3.9400, 3.9321, 3.9354, 4.0300, 4.0292],\n",
      "        [3.5792, 4.0529, 4.0185, 4.0376, 3.8365],\n",
      "        [3.4979, 3.6185, 3.7433, 3.6065, 3.6140],\n",
      "        [3.3645, 3.5758, 3.6477, 3.5160, 3.5107],\n",
      "        [3.4662, 3.7379, 3.6937, 3.7182, 3.5472],\n",
      "        [3.8106, 3.9401, 4.1128, 3.9062, 3.6898],\n",
      "        [3.5758, 3.7541, 3.8517, 3.7101, 3.7896],\n",
      "        [3.5812, 3.6355, 3.8783, 3.7500, 3.6802],\n",
      "        [3.5529, 3.6421, 3.9061, 3.6031, 3.7905],\n",
      "        [3.4888, 3.6146, 3.7511, 3.6119, 3.5989],\n",
      "        [3.5174, 3.6881, 3.7659, 3.6601, 3.6310],\n",
      "        [3.5158, 3.6834, 3.7386, 3.7119, 3.5939],\n",
      "        [3.4486, 3.6425, 3.6784, 3.6122, 3.5633],\n",
      "        [3.6532, 3.6668, 4.0045, 3.8600, 3.6963],\n",
      "        [3.4225, 3.4908, 3.6977, 3.6245, 3.4877]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4969, 3.9516, 3.8258, 3.7174, 3.8136],\n",
      "        [3.8100, 3.8491, 3.9854, 3.9516, 3.9687],\n",
      "        [3.7333, 3.9388, 4.0753, 3.8345, 3.5739],\n",
      "        [3.5385, 3.7257, 3.7179, 3.7487, 3.6322],\n",
      "        [3.3902, 3.7184, 3.6318, 3.6637, 3.5045],\n",
      "        [3.5908, 3.8456, 3.8663, 3.7410, 3.6741],\n",
      "        [3.5272, 3.7779, 3.8647, 3.7258, 3.6517],\n",
      "        [3.8168, 3.9668, 3.9914, 3.9438, 3.9458],\n",
      "        [3.7815, 4.0036, 4.1268, 3.9262, 3.6626],\n",
      "        [3.4918, 3.9097, 3.9359, 3.6992, 3.5342],\n",
      "        [3.6031, 3.7401, 3.8750, 3.7644, 3.7640],\n",
      "        [3.6730, 3.8625, 4.0201, 3.8675, 3.7573],\n",
      "        [3.5259, 3.7108, 3.7154, 3.7342, 3.6193],\n",
      "        [3.4234, 3.6248, 3.6765, 3.5782, 3.5526],\n",
      "        [3.3793, 3.4836, 3.6929, 3.5877, 3.4914],\n",
      "        [3.6297, 3.6850, 3.9604, 3.8373, 3.6681],\n",
      "        [3.5275, 3.6956, 3.8665, 3.7491, 3.6958],\n",
      "        [3.5943, 3.8713, 4.0611, 3.9195, 3.7609],\n",
      "        [3.8099, 3.9390, 4.1133, 3.9050, 3.6895],\n",
      "        [3.4963, 3.6799, 3.6964, 3.6898, 3.5886],\n",
      "        [3.5315, 3.7629, 3.8696, 3.7242, 3.6747],\n",
      "        [3.8263, 3.9117, 4.1854, 4.1426, 3.8005],\n",
      "        [3.9101, 3.9531, 4.1734, 4.1449, 3.9152],\n",
      "        [3.4656, 3.7368, 3.6941, 3.7172, 3.5472],\n",
      "        [3.5123, 3.7394, 3.7286, 3.8055, 3.5699],\n",
      "        [3.6404, 3.6829, 3.9142, 3.7801, 3.8105],\n",
      "        [3.8587, 3.7361, 3.9288, 4.2142, 3.9750],\n",
      "        [3.4386, 3.6312, 3.7980, 3.5721, 3.6806],\n",
      "        [3.6028, 3.7066, 3.8126, 3.6879, 3.6783],\n",
      "        [3.4117, 3.8766, 3.8923, 3.7762, 3.7247],\n",
      "        [3.6749, 3.6907, 3.8840, 3.6600, 3.5269],\n",
      "        [3.9012, 3.8008, 4.0597, 4.0729, 3.8545],\n",
      "        [3.4088, 3.5336, 3.7195, 3.5899, 3.5028],\n",
      "        [3.8678, 4.0003, 4.0160, 3.9732, 3.9738],\n",
      "        [3.5407, 3.7266, 3.7323, 3.7525, 3.6343],\n",
      "        [3.4923, 3.5929, 3.7579, 3.7091, 3.5462],\n",
      "        [3.4890, 3.8913, 3.9385, 3.7928, 3.7920],\n",
      "        [3.5420, 3.7365, 3.9056, 3.7615, 3.7024],\n",
      "        [3.3538, 3.4776, 3.6453, 3.4983, 3.4688],\n",
      "        [3.3905, 3.6700, 3.7665, 3.5847, 3.5477],\n",
      "        [3.8540, 3.9142, 4.0581, 4.0593, 3.8119],\n",
      "        [3.4230, 3.5653, 3.7486, 3.6119, 3.4969],\n",
      "        [3.4004, 3.6306, 3.7876, 3.6065, 3.5412],\n",
      "        [3.4181, 3.6193, 3.6713, 3.5835, 3.5453],\n",
      "        [3.5868, 3.6107, 3.8643, 3.7140, 3.6809],\n",
      "        [3.5642, 3.6678, 3.8347, 3.7013, 3.7821],\n",
      "        [3.3813, 3.6069, 3.7386, 3.5750, 3.5163],\n",
      "        [3.4819, 3.5972, 3.8264, 3.6841, 3.6090],\n",
      "        [3.5320, 3.6201, 3.8410, 3.6573, 3.6119],\n",
      "        [3.4061, 3.7745, 3.8599, 3.5981, 3.6926],\n",
      "        [3.7026, 3.7524, 4.0946, 4.0223, 3.7025],\n",
      "        [3.5324, 3.5763, 3.8372, 3.6708, 3.6118],\n",
      "        [3.5686, 3.6791, 3.8707, 3.6230, 3.4660],\n",
      "        [3.8255, 3.6561, 3.8538, 3.8176, 3.8077],\n",
      "        [3.5404, 3.6664, 3.8387, 3.5947, 3.7004],\n",
      "        [3.8367, 3.8749, 4.0530, 4.0164, 3.8452],\n",
      "        [3.9605, 3.9651, 3.9905, 4.0748, 4.0379],\n",
      "        [3.7342, 3.8107, 4.0293, 3.8833, 3.6337],\n",
      "        [3.6850, 3.6899, 3.8700, 3.6600, 3.5414],\n",
      "        [3.5561, 3.6357, 3.9038, 3.7348, 3.6885],\n",
      "        [4.0187, 3.9720, 4.2274, 4.2080, 4.0289],\n",
      "        [3.6370, 3.7025, 3.7898, 3.8280, 3.7053],\n",
      "        [3.4209, 3.6093, 3.8106, 3.7057, 3.6057],\n",
      "        [3.5315, 3.6008, 3.7517, 3.7449, 3.5637]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5661, 3.8860, 3.9370, 3.7473, 3.5547],\n",
      "        [3.3098, 3.5127, 3.6053, 3.4361, 3.4453],\n",
      "        [3.5821, 3.8865, 3.9958, 3.8737, 3.6504],\n",
      "        [3.8062, 3.8736, 4.0390, 4.0600, 4.0471],\n",
      "        [3.5783, 3.6304, 3.8828, 3.7440, 3.6925],\n",
      "        [3.9404, 3.7571, 4.0173, 4.3397, 4.1810],\n",
      "        [3.5562, 3.5828, 3.7280, 3.6299, 3.6613],\n",
      "        [3.5492, 3.6698, 3.8355, 3.7048, 3.7591],\n",
      "        [3.3552, 3.5665, 3.6422, 3.4993, 3.4991],\n",
      "        [4.0065, 3.9659, 4.2118, 4.2175, 4.0045],\n",
      "        [3.7066, 3.9250, 3.9793, 3.8637, 3.7498],\n",
      "        [3.5219, 3.6711, 3.8361, 3.5945, 3.6813],\n",
      "        [3.2621, 3.8235, 3.8204, 3.6514, 3.4517],\n",
      "        [3.3889, 3.6263, 3.7544, 3.5908, 3.5399],\n",
      "        [3.7438, 3.7653, 3.9989, 3.9470, 3.6831],\n",
      "        [3.5221, 3.7052, 3.7045, 3.7216, 3.6139],\n",
      "        [3.4417, 3.6377, 3.6859, 3.5947, 3.5581],\n",
      "        [3.6394, 4.1488, 4.1005, 4.0996, 3.9344],\n",
      "        [3.3760, 3.6712, 3.7608, 3.5750, 3.5404],\n",
      "        [3.5200, 3.6166, 3.8238, 3.6974, 3.6233],\n",
      "        [3.5754, 3.8439, 3.8554, 3.7320, 3.6585],\n",
      "        [3.7094, 3.7590, 3.8996, 3.7712, 3.5518],\n",
      "        [3.3732, 3.5588, 3.6932, 3.6033, 3.4890],\n",
      "        [3.6412, 3.6699, 3.8714, 3.6783, 3.5972],\n",
      "        [3.5891, 3.7009, 3.7983, 3.6795, 3.6654],\n",
      "        [3.4440, 3.5221, 3.8073, 3.6269, 3.5639],\n",
      "        [3.9532, 3.8927, 4.0259, 4.1241, 3.9073],\n",
      "        [3.4197, 3.8387, 3.8447, 3.5512, 3.7141],\n",
      "        [3.4553, 3.5892, 3.7673, 3.6804, 3.5246],\n",
      "        [3.4083, 3.6726, 3.7732, 3.5985, 3.5724],\n",
      "        [3.5988, 4.0426, 3.9160, 3.9505, 3.8210],\n",
      "        [3.6466, 3.9974, 3.9548, 3.8564, 3.7855],\n",
      "        [3.8659, 3.9162, 3.9374, 3.9689, 3.9523],\n",
      "        [3.7126, 3.9186, 4.0838, 3.9129, 3.9329],\n",
      "        [3.4325, 3.6309, 3.6756, 3.5921, 3.5569],\n",
      "        [3.4210, 3.4899, 3.6985, 3.6222, 3.4877],\n",
      "        [3.5257, 3.8277, 3.8768, 3.6250, 3.7184],\n",
      "        [3.4336, 3.5927, 3.7941, 3.6768, 3.5967],\n",
      "        [3.4298, 3.8965, 3.8679, 3.8317, 3.7521],\n",
      "        [3.6722, 3.9426, 4.0051, 3.8911, 3.8612],\n",
      "        [3.3889, 3.6263, 3.7544, 3.5908, 3.5399],\n",
      "        [3.4414, 3.8668, 3.9007, 3.8237, 3.7674],\n",
      "        [3.5296, 3.7466, 3.9458, 3.8366, 3.6306],\n",
      "        [3.6278, 3.8908, 3.9853, 3.8686, 3.7122],\n",
      "        [3.8372, 3.9685, 3.9898, 3.9608, 3.9315],\n",
      "        [3.7928, 3.8485, 3.9861, 3.9065, 3.9175],\n",
      "        [3.8401, 3.9141, 4.2121, 4.1502, 3.7854],\n",
      "        [3.4400, 3.6089, 3.6809, 3.6393, 3.5373],\n",
      "        [3.5585, 3.9022, 3.9527, 3.7577, 3.5540],\n",
      "        [3.5749, 4.0516, 3.9848, 4.0107, 3.8529],\n",
      "        [3.4318, 3.5234, 3.7199, 3.6125, 3.5062],\n",
      "        [3.4243, 3.5183, 3.7122, 3.6086, 3.4968],\n",
      "        [3.6956, 3.8057, 4.1452, 3.7578, 3.6045],\n",
      "        [3.6569, 4.0046, 3.9687, 3.8811, 3.8004],\n",
      "        [3.6048, 3.6809, 3.9460, 3.7815, 3.7146],\n",
      "        [3.4090, 3.7561, 3.9517, 3.7043, 3.6818],\n",
      "        [3.5111, 3.5782, 3.7991, 3.6243, 3.5703],\n",
      "        [3.5602, 3.6857, 3.7884, 3.6441, 3.5513],\n",
      "        [3.6839, 3.8321, 4.0259, 3.9045, 3.8711],\n",
      "        [3.5142, 3.6048, 3.8469, 3.7136, 3.6964],\n",
      "        [3.6061, 3.6073, 3.8448, 3.7097, 3.6898],\n",
      "        [3.6710, 3.8924, 3.8964, 3.9554, 3.7951],\n",
      "        [4.1275, 4.3284, 4.0448, 4.0227, 3.8765],\n",
      "        [3.6565, 3.6998, 3.8297, 3.8861, 3.7511]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8618, 3.9612, 3.9836, 3.9711, 3.9549],\n",
      "        [3.6162, 3.9971, 3.9871, 3.8532, 3.8604],\n",
      "        [3.7144, 3.6714, 3.8380, 4.0410, 3.8234],\n",
      "        [3.5141, 3.6098, 3.8259, 3.6919, 3.6174],\n",
      "        [3.6721, 3.8959, 3.9017, 3.9634, 3.8068],\n",
      "        [3.4202, 3.4907, 3.6983, 3.6207, 3.4877],\n",
      "        [3.7748, 3.6921, 3.8867, 4.1046, 3.8926],\n",
      "        [3.5554, 3.7074, 3.6779, 3.7452, 3.5496],\n",
      "        [3.7951, 3.6993, 3.8968, 4.1440, 3.9168],\n",
      "        [3.5323, 4.0159, 3.9930, 3.9918, 3.7954],\n",
      "        [3.6927, 4.0834, 4.0465, 3.9333, 3.9482],\n",
      "        [3.3601, 3.5807, 3.6612, 3.5008, 3.5183],\n",
      "        [3.5243, 3.7118, 3.7154, 3.7315, 3.6196],\n",
      "        [3.6401, 3.7715, 3.8895, 3.9197, 3.6939],\n",
      "        [3.3967, 3.5645, 3.7305, 3.5796, 3.5099],\n",
      "        [3.6243, 3.7382, 3.7638, 3.7669, 3.6817],\n",
      "        [3.3487, 3.4928, 3.6423, 3.4937, 3.4668],\n",
      "        [3.6309, 3.8499, 3.9690, 3.8070, 3.8385],\n",
      "        [3.7072, 3.7537, 3.9007, 3.7683, 3.5634],\n",
      "        [3.4884, 3.9515, 3.8003, 3.6734, 3.7819],\n",
      "        [3.9652, 3.9759, 4.0469, 4.1006, 4.0265],\n",
      "        [3.4451, 3.6777, 3.8389, 3.5730, 3.7114],\n",
      "        [3.9312, 4.0875, 3.9244, 3.8886, 3.7780],\n",
      "        [3.4179, 3.6180, 3.7763, 3.6238, 3.5290],\n",
      "        [3.7690, 4.0082, 4.1030, 3.8992, 3.6476],\n",
      "        [3.8198, 3.8697, 4.0321, 4.0594, 4.0451],\n",
      "        [3.7066, 3.9370, 3.9956, 3.8813, 3.7744],\n",
      "        [3.3901, 3.6451, 3.7283, 3.6425, 3.5172],\n",
      "        [3.7064, 3.8010, 3.8046, 3.8755, 3.8135],\n",
      "        [3.6803, 3.8990, 3.9580, 3.8305, 3.8278],\n",
      "        [3.4191, 3.6262, 3.8277, 3.7140, 3.6302],\n",
      "        [3.6301, 4.1726, 4.1016, 4.1164, 3.9479],\n",
      "        [3.8053, 3.8568, 4.0132, 4.0504, 4.0363],\n",
      "        [3.9862, 4.0797, 4.1545, 4.2397, 3.9891],\n",
      "        [3.5251, 3.7026, 3.7039, 3.7176, 3.6063],\n",
      "        [3.4375, 3.5407, 3.6266, 3.6481, 3.4301],\n",
      "        [3.5264, 3.6470, 3.8462, 3.7169, 3.6438],\n",
      "        [3.3134, 3.5082, 3.5860, 3.4996, 3.4460],\n",
      "        [3.3800, 3.6150, 3.6846, 3.5940, 3.5127],\n",
      "        [3.4431, 4.0374, 4.0072, 3.8110, 3.6610],\n",
      "        [3.4577, 3.6494, 3.6861, 3.6316, 3.5676],\n",
      "        [3.5050, 3.5211, 3.8082, 3.6730, 3.6456],\n",
      "        [3.5069, 3.8150, 3.8803, 3.6767, 3.7292],\n",
      "        [3.8002, 4.0544, 4.1851, 4.1001, 3.9598],\n",
      "        [3.7107, 3.8527, 4.0442, 3.9437, 3.9197],\n",
      "        [4.0449, 4.1979, 4.0412, 3.9662, 3.8590],\n",
      "        [3.5943, 3.6104, 4.0054, 3.9187, 3.5684],\n",
      "        [3.9945, 4.0243, 4.2342, 4.2187, 3.9107],\n",
      "        [3.9258, 3.9567, 4.1324, 4.1262, 3.9475],\n",
      "        [3.5962, 3.5998, 3.8438, 3.7324, 3.6077],\n",
      "        [3.4610, 3.4942, 3.6849, 3.6135, 3.4803],\n",
      "        [3.3040, 3.4965, 3.5648, 3.5040, 3.4235],\n",
      "        [3.4202, 3.4907, 3.6983, 3.6207, 3.4877],\n",
      "        [3.6499, 3.5533, 3.9898, 3.7917, 3.6973],\n",
      "        [3.9693, 3.9715, 4.0002, 4.0840, 4.0425],\n",
      "        [3.4956, 3.6183, 3.7434, 3.6028, 3.6142],\n",
      "        [3.4074, 3.5989, 3.7470, 3.5883, 3.5408],\n",
      "        [3.6814, 3.8484, 4.0377, 3.7944, 3.6235],\n",
      "        [3.5179, 3.7035, 3.7194, 3.7151, 3.6225],\n",
      "        [3.6721, 3.8959, 3.9017, 3.9634, 3.8068],\n",
      "        [3.7207, 3.8634, 4.0528, 3.9504, 3.9285],\n",
      "        [3.6835, 3.6909, 3.8701, 3.6573, 3.5416],\n",
      "        [3.4192, 3.6103, 3.8105, 3.7028, 3.6060],\n",
      "        [3.4522, 3.5929, 3.8004, 3.6832, 3.5885]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6441, 3.8722, 3.8729, 3.9261, 3.7637],\n",
      "        [3.5688, 3.6566, 3.8934, 3.6514, 3.7903],\n",
      "        [3.5235, 3.6492, 3.8438, 3.7164, 3.6394],\n",
      "        [3.5282, 3.7581, 3.8551, 3.7052, 3.6874],\n",
      "        [3.4629, 3.7676, 3.9715, 3.8404, 3.5686],\n",
      "        [4.2000, 4.4345, 4.1007, 4.1325, 3.9270],\n",
      "        [3.6148, 3.5684, 3.7490, 3.6558, 3.6640],\n",
      "        [3.7024, 3.9776, 3.9901, 3.8656, 3.8046],\n",
      "        [3.5439, 3.7419, 3.7297, 3.7586, 3.6400],\n",
      "        [3.4352, 3.5660, 3.6255, 3.6524, 3.5058],\n",
      "        [3.5465, 3.7385, 3.7268, 3.7583, 3.6397],\n",
      "        [3.6896, 3.9795, 3.9043, 3.6941, 3.7658],\n",
      "        [3.6896, 3.9399, 3.9443, 3.8901, 3.7769],\n",
      "        [3.8235, 3.6582, 3.8532, 3.8141, 3.8079],\n",
      "        [3.5302, 3.5677, 3.8424, 3.5914, 3.6619],\n",
      "        [3.3759, 3.5930, 3.6590, 3.5286, 3.5215],\n",
      "        [3.9584, 3.9676, 4.0120, 4.0751, 4.0293],\n",
      "        [3.4677, 3.5562, 3.8325, 3.6594, 3.5822],\n",
      "        [3.4350, 3.5080, 3.7099, 3.6204, 3.4961],\n",
      "        [3.7939, 4.0593, 3.9686, 3.9825, 3.9709],\n",
      "        [3.5361, 3.8209, 3.8686, 3.6483, 3.7137],\n",
      "        [3.6278, 3.5025, 3.9664, 3.7659, 3.6562],\n",
      "        [3.6717, 3.8827, 3.9094, 3.8768, 3.7545],\n",
      "        [3.3759, 3.5989, 3.6711, 3.5230, 3.5330],\n",
      "        [3.7372, 3.8219, 4.0110, 3.9061, 3.6636],\n",
      "        [3.5074, 3.9408, 3.8860, 3.8321, 3.8066],\n",
      "        [3.3977, 3.6657, 3.7661, 3.5998, 3.5619],\n",
      "        [3.4206, 3.5344, 3.7221, 3.6025, 3.5063],\n",
      "        [3.5638, 3.7522, 3.8437, 3.7458, 3.7196],\n",
      "        [3.5652, 3.7092, 3.8901, 3.8458, 3.6967],\n",
      "        [3.4196, 3.8651, 3.8977, 3.8011, 3.7435],\n",
      "        [3.3900, 3.6854, 3.7681, 3.5840, 3.5575],\n",
      "        [3.7666, 3.9567, 4.0943, 3.9567, 3.9802],\n",
      "        [3.2116, 3.4745, 3.6684, 3.4464, 3.4497],\n",
      "        [3.5747, 3.6714, 3.8300, 3.6900, 3.8050],\n",
      "        [3.6393, 3.8770, 4.0473, 3.9225, 3.8201],\n",
      "        [3.3425, 3.5590, 3.6342, 3.4765, 3.4884],\n",
      "        [3.3821, 3.5823, 3.6570, 3.5258, 3.5131],\n",
      "        [3.5875, 3.7028, 3.7973, 3.6771, 3.6653],\n",
      "        [3.9357, 3.7964, 3.9495, 3.9672, 3.9435],\n",
      "        [3.5231, 3.7155, 3.7190, 3.7181, 3.6253],\n",
      "        [3.5922, 3.6053, 3.8460, 3.7224, 3.6309],\n",
      "        [3.4596, 3.5951, 3.8084, 3.6818, 3.5955],\n",
      "        [3.7117, 3.7553, 3.9128, 3.7636, 3.5843],\n",
      "        [3.5002, 3.6135, 3.8370, 3.7101, 3.6981],\n",
      "        [3.4262, 3.6486, 3.7992, 3.6318, 3.5541],\n",
      "        [4.0107, 4.0338, 4.2229, 4.2775, 4.0807],\n",
      "        [3.7495, 3.6723, 3.8637, 4.1278, 3.8689],\n",
      "        [3.5300, 3.6245, 3.9179, 3.5855, 3.7657],\n",
      "        [3.8098, 3.9398, 3.9704, 3.9234, 3.9109],\n",
      "        [3.3890, 3.5388, 3.7169, 3.5757, 3.4964],\n",
      "        [3.5703, 4.0320, 4.0099, 4.0239, 3.8447],\n",
      "        [3.5944, 3.9001, 4.0159, 3.8701, 3.6644],\n",
      "        [3.5324, 3.7196, 3.7121, 3.7345, 3.6225],\n",
      "        [3.4638, 3.5220, 3.7276, 3.6262, 3.4997],\n",
      "        [3.2260, 3.4783, 3.6643, 3.4641, 3.4773],\n",
      "        [3.6576, 3.9743, 4.0366, 3.8669, 3.7272],\n",
      "        [3.4254, 3.5650, 3.6503, 3.6485, 3.4491],\n",
      "        [3.4052, 3.6147, 3.6704, 3.5541, 3.5454],\n",
      "        [3.7179, 3.9631, 4.0592, 3.9340, 3.7693],\n",
      "        [3.4239, 3.6747, 3.6716, 3.6642, 3.5586],\n",
      "        [3.5202, 4.0206, 3.9841, 3.9879, 3.8063],\n",
      "        [3.5333, 3.7893, 3.9080, 3.7457, 3.6418],\n",
      "        [3.5260, 3.5896, 3.8330, 3.6736, 3.6039]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7190, 3.8669, 4.0519, 3.9502, 3.9278],\n",
      "        [3.5253, 3.5921, 3.8311, 3.6809, 3.6035],\n",
      "        [3.5185, 3.8267, 3.8738, 3.6066, 3.7137],\n",
      "        [3.6724, 3.8285, 3.8661, 3.7943, 3.7902],\n",
      "        [3.5276, 3.6108, 3.8300, 3.6873, 3.6187],\n",
      "        [3.5283, 3.6667, 3.7601, 3.7110, 3.5990],\n",
      "        [3.6071, 3.7135, 3.8185, 3.7137, 3.6763],\n",
      "        [3.7888, 3.9354, 4.0672, 3.9574, 4.0048],\n",
      "        [3.8063, 3.6036, 3.9145, 4.0982, 4.0047],\n",
      "        [3.4896, 3.6886, 3.8865, 3.7781, 3.7808],\n",
      "        [3.7012, 3.9140, 3.9777, 3.9046, 3.7691],\n",
      "        [3.5108, 3.6152, 3.8145, 3.6822, 3.6089],\n",
      "        [3.6374, 3.7210, 3.8370, 3.7438, 3.6779],\n",
      "        [3.6236, 3.7565, 3.9484, 3.7889, 3.7208],\n",
      "        [3.8301, 3.7270, 3.9122, 4.1705, 3.9416],\n",
      "        [3.6789, 3.7970, 3.8169, 3.8446, 3.7858],\n",
      "        [3.6194, 3.5728, 3.7546, 3.6532, 3.6668],\n",
      "        [3.8338, 3.8797, 4.0520, 4.0136, 3.8457],\n",
      "        [3.7423, 3.7059, 3.8739, 3.7139, 3.6046],\n",
      "        [3.5244, 3.7001, 3.8660, 3.7463, 3.6955],\n",
      "        [3.6684, 3.8965, 3.8987, 3.9617, 3.8026],\n",
      "        [3.5232, 3.7054, 3.7026, 3.7172, 3.6056],\n",
      "        [3.4719, 3.6290, 3.7086, 3.5938, 3.5537],\n",
      "        [3.8848, 3.7954, 4.0416, 4.0364, 3.8347],\n",
      "        [3.6701, 3.8989, 3.9003, 3.9631, 3.8062],\n",
      "        [3.4102, 3.5405, 3.7246, 3.5919, 3.5056],\n",
      "        [3.4847, 3.6171, 3.7497, 3.6078, 3.5987],\n",
      "        [3.5729, 3.8390, 3.8523, 3.7314, 3.6534],\n",
      "        [3.7088, 3.9053, 3.9602, 3.7374, 3.7663],\n",
      "        [3.3895, 3.6169, 3.7556, 3.5911, 3.5371],\n",
      "        [3.9506, 4.0300, 4.2362, 4.2268, 3.8059],\n",
      "        [3.7709, 3.8724, 4.0653, 4.0250, 3.7582],\n",
      "        [3.5910, 3.8765, 4.0614, 3.9166, 3.7607],\n",
      "        [3.4055, 3.5861, 3.7285, 3.5763, 3.5362],\n",
      "        [3.7448, 3.9543, 3.9659, 3.8813, 3.8579],\n",
      "        [3.3694, 3.5766, 3.6020, 3.5404, 3.4597],\n",
      "        [3.6312, 3.7560, 3.8760, 3.8997, 3.6864],\n",
      "        [3.2789, 3.5279, 3.6935, 3.5045, 3.5135],\n",
      "        [3.9131, 3.8546, 3.9622, 3.9490, 3.9166],\n",
      "        [3.5253, 3.5921, 3.8311, 3.6809, 3.6035],\n",
      "        [3.6990, 3.9145, 3.9728, 3.8915, 3.7680],\n",
      "        [3.8331, 3.6811, 3.8668, 3.8395, 3.8246],\n",
      "        [3.6261, 3.8994, 3.9850, 3.8742, 3.7032],\n",
      "        [3.8402, 3.9404, 4.0720, 3.9866, 4.0720],\n",
      "        [3.5244, 3.6500, 3.8448, 3.7166, 3.6431],\n",
      "        [3.6386, 3.7118, 3.8351, 3.7481, 3.6554],\n",
      "        [3.6701, 3.8989, 3.9003, 3.9631, 3.8062],\n",
      "        [3.5520, 3.5394, 3.7605, 3.6730, 3.7187],\n",
      "        [3.4664, 3.6608, 3.6816, 3.6476, 3.5672],\n",
      "        [3.7661, 4.0957, 4.0465, 4.0232, 3.9672],\n",
      "        [3.4821, 3.6688, 3.6885, 3.6520, 3.5901],\n",
      "        [4.0370, 4.2587, 3.9375, 3.9426, 3.7701],\n",
      "        [3.4820, 3.7532, 3.9594, 3.7763, 3.5725],\n",
      "        [3.8831, 3.9455, 4.0789, 4.1048, 3.8492],\n",
      "        [3.6970, 3.7468, 3.9008, 3.7394, 3.8373],\n",
      "        [3.3881, 3.7210, 3.6336, 3.6589, 3.5043],\n",
      "        [3.5842, 3.9967, 4.0370, 3.8202, 3.6627],\n",
      "        [3.9677, 3.9746, 3.9989, 4.0836, 4.0420],\n",
      "        [3.5314, 3.7212, 3.7113, 3.7351, 3.6221],\n",
      "        [3.4821, 3.4971, 3.8211, 3.4875, 3.6465],\n",
      "        [3.5337, 3.8286, 4.0009, 3.7819, 3.5930],\n",
      "        [3.3556, 3.7829, 3.8403, 3.6750, 3.5074],\n",
      "        [3.5450, 3.7359, 3.7199, 3.7535, 3.6306],\n",
      "        [3.6851, 3.9201, 3.9303, 3.8728, 3.7669]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5704, 3.8179, 3.8391, 3.7330, 3.7049],\n",
      "        [3.5271, 3.5480, 3.7686, 3.5973, 3.5334],\n",
      "        [3.4612, 3.7423, 3.6915, 3.7143, 3.5483],\n",
      "        [3.8754, 3.9677, 3.9835, 3.9759, 3.9657],\n",
      "        [3.3957, 3.6689, 3.7640, 3.6004, 3.5611],\n",
      "        [3.5343, 3.7317, 3.7177, 3.7309, 3.6351],\n",
      "        [3.7565, 3.8634, 4.0250, 3.8035, 3.5745],\n",
      "        [3.4097, 3.5482, 3.7252, 3.5951, 3.5080],\n",
      "        [3.5019, 3.6989, 3.7079, 3.6919, 3.6073],\n",
      "        [3.7515, 3.9317, 4.0951, 3.9684, 3.9498],\n",
      "        [3.3459, 3.4970, 3.6397, 3.4934, 3.4661],\n",
      "        [3.6579, 3.6939, 3.8821, 3.6324, 3.5158],\n",
      "        [3.7644, 3.7960, 3.9180, 3.9119, 3.8974],\n",
      "        [3.4812, 3.8740, 3.9638, 3.6908, 3.8747],\n",
      "        [3.4636, 3.6639, 3.6851, 3.6354, 3.5740],\n",
      "        [3.3785, 3.6525, 3.7501, 3.5730, 3.5290],\n",
      "        [3.4107, 3.5604, 3.7442, 3.6054, 3.4902],\n",
      "        [3.7835, 3.6509, 3.8617, 3.7951, 3.7555],\n",
      "        [3.4067, 3.7603, 3.9484, 3.7049, 3.6763],\n",
      "        [3.4520, 3.6615, 3.6936, 3.6224, 3.5735],\n",
      "        [3.4701, 3.6151, 3.5885, 3.7071, 3.4868],\n",
      "        [3.3360, 3.5614, 3.5514, 3.5789, 3.4562],\n",
      "        [4.0311, 4.0242, 4.2735, 4.2550, 4.0634],\n",
      "        [4.0285, 3.8256, 4.1068, 4.4275, 4.2693],\n",
      "        [3.4233, 3.8890, 3.7536, 3.6277, 3.7075],\n",
      "        [3.4509, 3.6055, 3.8015, 3.6943, 3.5874],\n",
      "        [3.6315, 3.8649, 3.9459, 3.7851, 3.5980],\n",
      "        [3.5272, 3.6685, 3.7590, 3.7112, 3.5985],\n",
      "        [3.7623, 3.8915, 4.0123, 3.9124, 3.9618],\n",
      "        [3.8315, 3.8950, 4.0524, 4.0376, 3.8383],\n",
      "        [3.5569, 3.6649, 3.8497, 3.6007, 3.4530],\n",
      "        [3.2968, 3.5556, 3.6942, 3.5296, 3.5143],\n",
      "        [3.5595, 4.0093, 4.0308, 3.7858, 3.6308],\n",
      "        [3.6000, 4.0257, 3.9410, 3.9319, 3.8602],\n",
      "        [3.6133, 3.9760, 3.9541, 3.8465, 3.8596],\n",
      "        [3.9613, 4.0675, 4.2332, 4.2725, 4.0066],\n",
      "        [3.4254, 3.7115, 3.6402, 3.6585, 3.5203],\n",
      "        [3.6644, 3.8590, 4.0133, 3.7690, 3.6085],\n",
      "        [3.8349, 3.6634, 3.7752, 3.7931, 3.8260],\n",
      "        [3.9854, 3.8631, 4.0730, 4.0590, 4.0008],\n",
      "        [3.8213, 3.9261, 4.0576, 3.9731, 4.0622],\n",
      "        [3.8593, 3.9663, 3.9812, 3.9710, 3.9538],\n",
      "        [3.4479, 3.6503, 3.6837, 3.5974, 3.5734],\n",
      "        [3.5826, 3.8778, 3.9751, 3.8508, 3.6617],\n",
      "        [3.9577, 3.8740, 3.9770, 4.0149, 3.9669],\n",
      "        [3.5901, 4.0524, 4.0164, 4.0155, 3.8601],\n",
      "        [3.5276, 3.5955, 3.7376, 3.7540, 3.5512],\n",
      "        [3.5511, 3.6781, 3.8356, 3.7058, 3.7607],\n",
      "        [3.5027, 3.6943, 3.7087, 3.6917, 3.6107],\n",
      "        [3.9470, 3.8276, 4.0841, 4.4162, 4.1883],\n",
      "        [3.4297, 4.0276, 4.0307, 3.8338, 3.6768],\n",
      "        [3.5152, 3.6475, 3.8376, 3.7102, 3.6230],\n",
      "        [3.8639, 4.0062, 4.0126, 3.9702, 3.9731],\n",
      "        [3.3588, 3.8076, 3.8512, 3.6770, 3.5122],\n",
      "        [3.6105, 3.7459, 3.8759, 3.7520, 3.7792],\n",
      "        [3.3146, 3.5702, 3.6925, 3.5504, 3.5230],\n",
      "        [3.5604, 3.6764, 3.9481, 3.7748, 3.7065],\n",
      "        [3.4048, 3.7616, 3.9486, 3.7028, 3.6807],\n",
      "        [3.8224, 3.9197, 4.1859, 4.1404, 3.7995],\n",
      "        [3.5812, 3.6245, 3.7890, 3.6766, 3.6977],\n",
      "        [3.6799, 3.9429, 4.0072, 3.8983, 3.8484],\n",
      "        [3.9131, 3.9662, 4.1810, 4.1497, 3.9199],\n",
      "        [3.7989, 3.9618, 4.1168, 4.1248, 4.1388],\n",
      "        [3.5816, 3.6445, 3.9035, 3.7606, 3.7015]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7576, 3.6143, 3.7418, 3.7148, 3.7956],\n",
      "        [3.8808, 4.0637, 3.9159, 3.8550, 3.7681],\n",
      "        [3.4593, 3.8852, 3.9028, 3.7578, 3.8093],\n",
      "        [3.5494, 3.5454, 3.7450, 3.6649, 3.7159],\n",
      "        [3.4614, 3.9467, 3.9092, 3.8580, 3.7373],\n",
      "        [3.4650, 3.6635, 3.6873, 3.6235, 3.5901],\n",
      "        [3.6701, 3.8324, 3.8636, 3.7950, 3.7907],\n",
      "        [3.3319, 3.5865, 3.6885, 3.5732, 3.5329],\n",
      "        [3.5107, 3.5708, 3.7812, 3.6174, 3.5539],\n",
      "        [3.5458, 3.5584, 3.7779, 3.5965, 3.5421],\n",
      "        [3.4256, 3.6334, 3.6551, 3.6523, 3.5435],\n",
      "        [3.5602, 3.6320, 3.8873, 3.7576, 3.6934],\n",
      "        [3.3618, 3.5811, 3.6470, 3.5027, 3.5081],\n",
      "        [3.5026, 3.8218, 3.8763, 3.6768, 3.7288],\n",
      "        [3.9655, 3.9788, 3.9968, 4.0844, 4.0425],\n",
      "        [3.5075, 3.7241, 3.8961, 3.7827, 3.6415],\n",
      "        [3.8323, 4.0381, 3.9137, 3.8377, 3.7624],\n",
      "        [3.7986, 3.9697, 4.1227, 4.1223, 4.1482],\n",
      "        [3.4267, 3.5005, 3.7005, 3.6073, 3.4945],\n",
      "        [3.6763, 3.9070, 3.9558, 3.8314, 3.8276],\n",
      "        [3.4736, 3.7226, 3.8826, 3.6218, 3.7581],\n",
      "        [3.6239, 3.9058, 3.8575, 3.7987, 3.7259],\n",
      "        [3.7799, 3.9546, 4.1048, 4.0945, 4.1287],\n",
      "        [3.5275, 3.9330, 3.9669, 3.8255, 3.8641],\n",
      "        [3.5138, 3.6496, 3.8365, 3.7107, 3.6239],\n",
      "        [3.6128, 3.9215, 4.1180, 3.9681, 3.7914],\n",
      "        [3.4653, 3.5168, 3.7080, 3.6408, 3.4864],\n",
      "        [3.7806, 4.0377, 4.1465, 3.9411, 3.6988],\n",
      "        [3.4662, 3.6626, 3.6819, 3.6352, 3.5825],\n",
      "        [3.7442, 3.9910, 3.9180, 3.8034, 3.7500],\n",
      "        [3.5821, 3.6739, 3.8233, 3.6847, 3.8256],\n",
      "        [3.8803, 3.7444, 3.8657, 3.8844, 3.8755],\n",
      "        [3.9806, 4.0065, 4.1927, 4.2345, 4.0216],\n",
      "        [3.5870, 3.6132, 3.8465, 3.7080, 3.6824],\n",
      "        [3.5581, 4.0119, 4.0298, 3.7864, 3.6321],\n",
      "        [3.5215, 3.6152, 3.8237, 3.6867, 3.6172],\n",
      "        [3.9618, 4.0612, 4.1895, 4.2458, 3.8430],\n",
      "        [3.3858, 3.7246, 3.6314, 3.6595, 3.5055],\n",
      "        [3.6685, 3.9013, 3.8990, 3.9590, 3.8053],\n",
      "        [3.4019, 3.6197, 3.6672, 3.5551, 3.5458],\n",
      "        [3.5974, 4.0655, 4.0246, 4.0430, 3.8986],\n",
      "        [3.5136, 3.6140, 3.8122, 3.6812, 3.6102],\n",
      "        [3.4172, 3.6538, 3.8236, 3.6420, 3.5328],\n",
      "        [3.6659, 3.9004, 3.8965, 3.9623, 3.8029],\n",
      "        [3.5186, 3.6968, 3.8348, 3.6990, 3.6869],\n",
      "        [3.4808, 3.6550, 3.7187, 3.5358, 3.5639],\n",
      "        [3.3842, 3.6820, 3.7643, 3.5924, 3.5555],\n",
      "        [3.4567, 3.6669, 3.6813, 3.6101, 3.6112],\n",
      "        [3.8740, 3.9645, 4.0237, 4.1094, 3.9119],\n",
      "        [3.4331, 3.5243, 3.7148, 3.6339, 3.5131],\n",
      "        [3.6725, 4.0849, 4.0514, 3.9182, 3.9162],\n",
      "        [3.5243, 3.6676, 3.8537, 3.7308, 3.6465],\n",
      "        [3.4642, 3.6368, 3.7004, 3.6596, 3.5866],\n",
      "        [3.6977, 3.7639, 4.1087, 4.0210, 3.6985],\n",
      "        [3.7023, 3.9439, 3.9919, 3.8819, 3.7744],\n",
      "        [3.3976, 3.5640, 3.7299, 3.5933, 3.5206],\n",
      "        [3.3824, 3.5534, 3.6922, 3.6156, 3.5021],\n",
      "        [3.5300, 3.7954, 3.9055, 3.7474, 3.6419],\n",
      "        [3.5032, 3.6941, 3.6924, 3.6998, 3.5902],\n",
      "        [3.5138, 3.5544, 3.7697, 3.6022, 3.5387],\n",
      "        [3.5515, 3.5897, 3.7237, 3.6289, 3.6612],\n",
      "        [3.4229, 3.6537, 3.7957, 3.6329, 3.5546],\n",
      "        [3.4560, 3.6509, 3.6741, 3.6188, 3.5571],\n",
      "        [3.6301, 3.8672, 3.9448, 3.7858, 3.5991]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7848, 4.0234, 4.0836, 3.9962, 3.9225],\n",
      "        [3.9163, 3.9692, 4.1609, 4.1477, 3.9259],\n",
      "        [3.6105, 3.5756, 3.7443, 3.6574, 3.6646],\n",
      "        [3.5079, 3.5658, 3.8161, 3.6636, 3.5860],\n",
      "        [3.4149, 3.8743, 3.8939, 3.8037, 3.7447],\n",
      "        [3.5505, 3.6347, 3.8853, 3.7223, 3.6829],\n",
      "        [3.7228, 3.8803, 3.8819, 3.8331, 3.8383],\n",
      "        [3.4766, 4.0495, 4.0543, 3.8259, 3.6983],\n",
      "        [3.5004, 3.6135, 3.9192, 3.5312, 3.7581],\n",
      "        [3.3149, 3.5689, 3.6816, 3.5627, 3.5201],\n",
      "        [3.3037, 3.5214, 3.5998, 3.4348, 3.4471],\n",
      "        [3.5762, 3.8989, 3.9938, 3.8737, 3.6509],\n",
      "        [3.3213, 3.4649, 3.6219, 3.4669, 3.4369],\n",
      "        [3.6353, 3.6789, 3.8706, 3.6610, 3.6560],\n",
      "        [3.4201, 3.5001, 3.6909, 3.6227, 3.4973],\n",
      "        [3.5896, 4.0528, 4.0378, 4.0486, 3.8685],\n",
      "        [3.5852, 3.4810, 3.9239, 3.7422, 3.6369],\n",
      "        [3.6996, 3.8766, 3.9789, 3.9651, 3.7455],\n",
      "        [3.8608, 3.9230, 4.0719, 4.0607, 3.7767],\n",
      "        [3.4208, 3.8195, 3.8738, 3.6318, 3.7058],\n",
      "        [3.7904, 3.8537, 3.9990, 4.0391, 4.0345],\n",
      "        [3.6963, 3.8239, 4.0322, 3.8106, 3.6190],\n",
      "        [3.3605, 3.5832, 3.6457, 3.5027, 3.5089],\n",
      "        [3.6866, 3.9160, 3.9749, 3.9753, 3.7733],\n",
      "        [3.6079, 3.7505, 3.8736, 3.7529, 3.7809],\n",
      "        [3.6660, 3.8919, 4.0050, 3.8498, 3.7170],\n",
      "        [3.5944, 3.5981, 3.8206, 3.7273, 3.5898],\n",
      "        [3.3876, 3.6757, 3.7632, 3.5952, 3.5546],\n",
      "        [3.5981, 3.6855, 3.8306, 3.6933, 3.8520],\n",
      "        [3.4722, 3.7248, 3.8813, 3.6219, 3.7587],\n",
      "        [3.5101, 3.9040, 3.9262, 3.7144, 3.5340],\n",
      "        [3.5481, 3.5476, 3.7437, 3.6651, 3.7165],\n",
      "        [3.5282, 4.0298, 3.9798, 3.9903, 3.8001],\n",
      "        [3.6229, 3.6163, 3.8165, 3.7030, 3.7007],\n",
      "        [3.6065, 3.6349, 4.0754, 3.8037, 3.7683],\n",
      "        [3.8026, 3.6099, 3.9110, 4.0991, 4.0058],\n",
      "        [3.6350, 3.7178, 3.8314, 3.7490, 3.6564],\n",
      "        [3.4398, 3.6404, 3.6671, 3.6034, 3.5518],\n",
      "        [3.5073, 3.6283, 3.8162, 3.6881, 3.6123],\n",
      "        [3.4575, 4.0240, 3.8476, 3.6848, 3.7914],\n",
      "        [3.8032, 3.8595, 3.9801, 3.9494, 3.9697],\n",
      "        [3.4657, 3.9267, 3.8810, 3.7821, 3.8110],\n",
      "        [3.4372, 4.0469, 4.0018, 3.8130, 3.6616],\n",
      "        [3.3968, 3.5513, 3.6802, 3.5713, 3.5214],\n",
      "        [3.4790, 3.5014, 3.7769, 3.6529, 3.6278],\n",
      "        [3.5111, 3.7123, 3.7052, 3.7106, 3.6135],\n",
      "        [3.9464, 4.0305, 4.1954, 4.1908, 3.7677],\n",
      "        [3.5969, 3.8405, 3.8456, 3.7297, 3.7299],\n",
      "        [3.7733, 3.9147, 4.0359, 3.8698, 3.6725],\n",
      "        [3.5303, 3.7206, 3.8743, 3.7537, 3.7035],\n",
      "        [3.6798, 3.9102, 3.9974, 3.8918, 3.7979],\n",
      "        [3.4648, 3.6648, 3.6806, 3.6353, 3.5831],\n",
      "        [3.4946, 3.9112, 3.9305, 3.7050, 3.5291],\n",
      "        [3.4825, 3.6559, 3.7117, 3.6048, 3.5734],\n",
      "        [3.4244, 3.5130, 3.7013, 3.6171, 3.4943],\n",
      "        [3.3766, 3.6483, 3.7132, 3.6289, 3.5176],\n",
      "        [3.5615, 3.6838, 3.8514, 3.6021, 3.7234],\n",
      "        [3.5165, 3.5563, 3.8386, 3.5597, 3.6649],\n",
      "        [3.6064, 3.6690, 3.9380, 3.9302, 3.9190],\n",
      "        [3.4376, 3.7059, 3.8219, 3.6016, 3.6025],\n",
      "        [3.5165, 3.6237, 3.8205, 3.6883, 3.6188],\n",
      "        [3.6688, 3.8347, 3.8623, 3.7951, 3.7913],\n",
      "        [3.5629, 3.9005, 3.8200, 3.7802, 3.6933],\n",
      "        [3.4321, 3.7910, 3.8470, 3.7116, 3.7975]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.8250, 4.0697, 4.1992, 4.0973, 4.0303],\n",
      "        [3.4940, 3.7111, 3.7009, 3.6923, 3.6094],\n",
      "        [3.2725, 3.8347, 3.8195, 3.6526, 3.4589],\n",
      "        [3.5244, 3.5771, 3.8406, 3.5969, 3.6617],\n",
      "        [3.3694, 3.5880, 3.6436, 3.5208, 3.5113],\n",
      "        [3.7404, 4.0752, 4.0374, 4.0296, 3.8944],\n",
      "        [3.3360, 3.5617, 3.6283, 3.4762, 3.4874],\n",
      "        [3.3990, 3.6430, 3.6735, 3.5689, 3.5553],\n",
      "        [3.4388, 3.6633, 3.8281, 3.6591, 3.6312],\n",
      "        [3.7033, 3.8578, 4.0410, 3.9060, 3.9214],\n",
      "        [3.5917, 3.6999, 3.8438, 3.7988, 3.6686],\n",
      "        [3.5375, 3.7163, 3.8363, 3.7166, 3.7075],\n",
      "        [3.9211, 3.8395, 3.9356, 3.9473, 3.8915],\n",
      "        [3.4354, 4.0023, 3.8233, 3.6635, 3.7679],\n",
      "        [3.4288, 3.8994, 3.8976, 3.7746, 3.6996],\n",
      "        [3.5744, 3.6355, 3.9081, 3.7929, 3.7665],\n",
      "        [3.8954, 3.7723, 3.9530, 4.2893, 4.0454],\n",
      "        [3.5684, 3.6934, 3.8546, 3.6324, 3.4732],\n",
      "        [3.5775, 3.6506, 3.8994, 3.7619, 3.7034],\n",
      "        [3.4416, 3.6946, 3.7025, 3.7238, 3.5558],\n",
      "        [3.6916, 3.8210, 3.9785, 3.8089, 3.7540],\n",
      "        [3.3784, 3.5220, 3.6705, 3.6330, 3.4958],\n",
      "        [3.5049, 3.6505, 3.7245, 3.6150, 3.6060],\n",
      "        [3.6469, 3.7323, 3.7051, 3.8137, 3.7755],\n",
      "        [3.5531, 3.6315, 3.8453, 3.6712, 3.6714],\n",
      "        [3.5080, 3.7629, 3.8431, 3.7008, 3.6662],\n",
      "        [3.4480, 3.6570, 3.6814, 3.6068, 3.5852],\n",
      "        [3.3847, 3.6335, 3.7424, 3.5880, 3.5441],\n",
      "        [3.3930, 3.7183, 3.7765, 3.6055, 3.5842],\n",
      "        [3.3839, 3.7075, 3.7702, 3.5849, 3.5638],\n",
      "        [3.4757, 3.5961, 3.8222, 3.6797, 3.6050],\n",
      "        [3.5374, 3.8263, 3.9754, 3.7763, 3.6005],\n",
      "        [3.5507, 3.5510, 3.7582, 3.6809, 3.7227],\n",
      "        [3.6878, 3.7233, 3.9445, 3.8556, 3.7075],\n",
      "        [3.8945, 3.8145, 4.0541, 4.0719, 3.8571],\n",
      "        [3.6324, 3.7288, 3.8317, 3.7455, 3.6793],\n",
      "        [3.5158, 3.6295, 3.8169, 3.6861, 3.6152],\n",
      "        [3.4312, 3.6995, 3.8739, 3.7179, 3.7141],\n",
      "        [3.5524, 3.5948, 3.8526, 3.7332, 3.7382],\n",
      "        [3.5631, 3.6378, 3.8208, 3.7143, 3.6620],\n",
      "        [3.5898, 3.7001, 3.8430, 3.7982, 3.6686],\n",
      "        [3.5448, 4.0330, 4.0689, 3.8091, 3.6847],\n",
      "        [3.5046, 3.7067, 3.7039, 3.7095, 3.6088],\n",
      "        [3.7123, 3.9761, 3.9777, 3.8666, 3.8266],\n",
      "        [3.5030, 3.7003, 3.6974, 3.6936, 3.6113],\n",
      "        [3.4032, 3.6077, 3.7579, 3.6092, 3.5130],\n",
      "        [3.5663, 3.6214, 3.8074, 3.6912, 3.6816],\n",
      "        [3.7566, 3.9145, 3.9293, 3.8817, 3.8567],\n",
      "        [3.3791, 3.5333, 3.6765, 3.6075, 3.4916],\n",
      "        [3.4110, 3.6281, 3.7692, 3.6246, 3.5308],\n",
      "        [3.5886, 3.9752, 4.0459, 3.8947, 3.8824],\n",
      "        [4.0236, 3.9429, 4.1017, 4.1328, 4.0749],\n",
      "        [3.5233, 3.7308, 3.7107, 3.7359, 3.6249],\n",
      "        [3.4065, 3.4841, 3.6805, 3.6015, 3.4694],\n",
      "        [3.3808, 3.6331, 3.7419, 3.5816, 3.5356],\n",
      "        [3.3727, 3.6180, 3.7315, 3.5730, 3.5186],\n",
      "        [3.4057, 3.5147, 3.6965, 3.6026, 3.4868],\n",
      "        [3.6040, 3.9869, 4.0270, 3.8377, 3.6812],\n",
      "        [3.5290, 3.5996, 3.8494, 3.6951, 3.6240],\n",
      "        [3.3555, 3.5855, 3.6410, 3.5130, 3.5131],\n",
      "        [3.8571, 3.9655, 3.9696, 3.9649, 3.9574],\n",
      "        [3.4556, 4.0325, 4.0000, 3.8220, 3.6667],\n",
      "        [3.4004, 3.6213, 3.6632, 3.5541, 3.5479],\n",
      "        [3.3168, 3.5427, 3.6057, 3.4562, 3.4670]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4830, 3.5367, 3.7853, 3.6358, 3.5625],\n",
      "        [3.3450, 3.6045, 3.6733, 3.5665, 3.5116],\n",
      "        [3.8214, 3.6088, 3.9040, 4.1251, 4.0235],\n",
      "        [3.3663, 3.5712, 3.6845, 3.6029, 3.4918],\n",
      "        [3.8886, 4.0880, 3.9995, 4.0541, 4.0775],\n",
      "        [3.5352, 3.5446, 3.7510, 3.5850, 3.5258],\n",
      "        [3.5993, 3.6828, 3.9207, 3.7792, 3.7126],\n",
      "        [3.3754, 3.8281, 3.8036, 3.5252, 3.6944],\n",
      "        [3.7656, 4.0185, 4.1019, 3.8941, 3.6636],\n",
      "        [3.5114, 3.6534, 3.8302, 3.7185, 3.6281],\n",
      "        [3.4055, 3.7390, 3.8195, 3.6339, 3.5693],\n",
      "        [3.9857, 4.0241, 4.2220, 4.2623, 4.0305],\n",
      "        [3.5309, 3.7385, 3.7101, 3.7473, 3.6338],\n",
      "        [3.4705, 3.5909, 3.8257, 3.6714, 3.5990],\n",
      "        [3.4478, 3.6134, 3.7961, 3.6960, 3.5903],\n",
      "        [3.5796, 3.8596, 3.8619, 3.7314, 3.6807],\n",
      "        [3.6637, 3.6989, 3.8248, 3.9188, 3.7567],\n",
      "        [3.4240, 3.6388, 3.6506, 3.6533, 3.5459],\n",
      "        [3.6196, 3.7580, 3.7776, 3.7871, 3.7126],\n",
      "        [3.5871, 3.6249, 3.9919, 3.9063, 3.5675],\n",
      "        [3.5665, 3.7749, 3.9247, 3.8640, 3.6745],\n",
      "        [3.6224, 3.9982, 3.9645, 3.8601, 3.8734],\n",
      "        [4.0338, 3.9519, 4.1050, 4.1370, 4.0812],\n",
      "        [3.4159, 3.5237, 3.7037, 3.6056, 3.4952],\n",
      "        [3.6951, 3.9243, 3.9661, 3.8937, 3.7708],\n",
      "        [3.5223, 3.6525, 3.8329, 3.7029, 3.6319],\n",
      "        [3.8102, 3.9816, 3.9844, 3.9430, 3.9485],\n",
      "        [3.8329, 3.6707, 3.7696, 3.7952, 3.8288],\n",
      "        [3.8284, 3.9694, 4.1597, 4.0205, 4.0312],\n",
      "        [3.5690, 3.8503, 3.8481, 3.7342, 3.6564],\n",
      "        [3.8012, 4.0808, 4.1549, 4.0873, 3.9597],\n",
      "        [3.4268, 3.5229, 3.7067, 3.6164, 3.5007],\n",
      "        [3.5760, 4.0676, 3.9178, 3.9500, 3.8358],\n",
      "        [3.3488, 3.5784, 3.6334, 3.4988, 3.5022],\n",
      "        [3.8303, 3.8910, 4.0457, 4.0157, 3.8489],\n",
      "        [3.5482, 3.5507, 3.7403, 3.6663, 3.7178],\n",
      "        [3.5463, 3.5446, 3.7265, 3.6538, 3.7125],\n",
      "        [3.3442, 3.7281, 3.9013, 3.5761, 3.6422],\n",
      "        [3.3850, 3.5836, 3.7242, 3.5788, 3.5123],\n",
      "        [3.7034, 3.7717, 3.8909, 3.7725, 3.5537],\n",
      "        [3.6959, 3.8179, 4.0051, 3.8042, 3.6251],\n",
      "        [3.4606, 3.6711, 3.6795, 3.6368, 3.5771],\n",
      "        [3.7842, 3.9753, 3.9769, 3.9238, 3.9181],\n",
      "        [3.7864, 3.9302, 4.0555, 3.9553, 4.0345],\n",
      "        [3.7049, 3.8673, 4.0380, 3.9457, 3.9217],\n",
      "        [3.5735, 3.6473, 3.8698, 3.7475, 3.6819],\n",
      "        [3.5153, 3.7177, 3.6965, 3.7214, 3.6154],\n",
      "        [3.5721, 3.6335, 3.8385, 3.7070, 3.6843],\n",
      "        [3.5181, 3.7794, 3.9595, 3.8420, 3.6118],\n",
      "        [3.9468, 4.0427, 4.2321, 4.2295, 3.8087],\n",
      "        [3.5359, 3.8284, 3.8560, 3.6646, 3.7103],\n",
      "        [3.4538, 3.9268, 3.8851, 3.7649, 3.8350],\n",
      "        [3.4872, 3.7496, 3.7236, 3.7786, 3.5786],\n",
      "        [3.5274, 3.7302, 3.7048, 3.7368, 3.6242],\n",
      "        [3.6924, 3.8906, 3.9045, 3.7995, 3.7350],\n",
      "        [3.5200, 3.7225, 3.7076, 3.7228, 3.6232],\n",
      "        [3.5176, 3.6437, 3.8290, 3.7086, 3.6211],\n",
      "        [3.4252, 3.5964, 3.6562, 3.6606, 3.5294],\n",
      "        [3.3907, 3.6170, 3.6566, 3.5525, 3.5343],\n",
      "        [3.4265, 3.6879, 3.6701, 3.6704, 3.5677],\n",
      "        [3.9256, 3.8079, 4.0513, 4.0406, 3.8822],\n",
      "        [3.6656, 3.7046, 3.8888, 3.7972, 3.6698],\n",
      "        [3.9443, 3.8104, 3.9312, 3.9489, 3.9001],\n",
      "        [4.0706, 4.3246, 3.9768, 3.9994, 3.8265]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5283, 3.5215, 3.6872, 3.6152, 3.6950],\n",
      "        [3.4232, 3.7203, 3.6326, 3.6599, 3.5265],\n",
      "        [3.7024, 3.7262, 3.9472, 3.9118, 3.6419],\n",
      "        [3.5867, 3.6203, 3.8397, 3.7093, 3.6860],\n",
      "        [3.3859, 3.5853, 3.7222, 3.5788, 3.5140],\n",
      "        [3.8968, 3.8183, 4.0506, 4.0722, 3.8598],\n",
      "        [3.4930, 3.9225, 3.9302, 3.7124, 3.5436],\n",
      "        [3.5867, 3.6203, 3.8397, 3.7093, 3.6860],\n",
      "        [3.4642, 3.5820, 3.8232, 3.6671, 3.5970],\n",
      "        [3.4246, 3.5470, 3.6126, 3.6514, 3.4984],\n",
      "        [3.6970, 3.8658, 3.8925, 3.7179, 3.7242],\n",
      "        [3.7042, 3.6268, 3.8926, 3.9630, 3.9284],\n",
      "        [3.4803, 3.5908, 3.7608, 3.5440, 3.6384],\n",
      "        [3.4144, 3.5133, 3.6926, 3.6109, 3.4889],\n",
      "        [3.5404, 3.7462, 3.9753, 3.7927, 3.7892],\n",
      "        [3.5092, 3.5675, 3.8119, 3.6625, 3.5874],\n",
      "        [3.6022, 3.6119, 3.8189, 3.7049, 3.6949],\n",
      "        [3.5794, 4.0493, 3.9199, 3.9489, 3.8372],\n",
      "        [3.4323, 3.9182, 3.9141, 3.7745, 3.7009],\n",
      "        [3.4348, 3.6209, 3.6452, 3.6319, 3.5001],\n",
      "        [3.8475, 3.8114, 4.0109, 3.9977, 3.8295],\n",
      "        [3.6231, 3.9130, 3.9788, 3.8768, 3.7076],\n",
      "        [3.5914, 3.6139, 3.8339, 3.7338, 3.6109],\n",
      "        [3.5042, 3.7005, 3.6946, 3.6787, 3.6174],\n",
      "        [3.9578, 3.9829, 3.9613, 4.0639, 4.0563],\n",
      "        [3.3778, 3.6775, 3.7491, 3.5756, 3.5433],\n",
      "        [3.4576, 3.4934, 3.6585, 3.6085, 3.4681],\n",
      "        [3.6002, 3.6846, 3.9187, 3.7792, 3.7142],\n",
      "        [3.5307, 3.6228, 3.8277, 3.6904, 3.6244],\n",
      "        [3.4382, 3.6223, 3.6584, 3.6377, 3.5059],\n",
      "        [3.6154, 3.8334, 3.9167, 3.8306, 3.7500],\n",
      "        [3.5251, 3.6776, 3.7514, 3.7126, 3.6039],\n",
      "        [3.7745, 3.9198, 4.0305, 3.8717, 3.6759],\n",
      "        [3.5140, 3.6627, 3.8310, 3.7143, 3.6294],\n",
      "        [3.5092, 3.6877, 3.9080, 3.8147, 3.8064],\n",
      "        [3.9448, 3.8377, 4.0762, 4.4178, 4.1929],\n",
      "        [3.3726, 3.4983, 3.6830, 3.5865, 3.4954],\n",
      "        [3.5372, 3.8169, 3.8512, 3.7509, 3.7056],\n",
      "        [3.4804, 3.6617, 3.7117, 3.5375, 3.5677],\n",
      "        [3.5292, 3.5762, 3.7093, 3.7644, 3.5310],\n",
      "        [3.5571, 4.0208, 4.0238, 3.7880, 3.6364],\n",
      "        [3.6236, 3.8734, 3.9332, 3.7856, 3.5974],\n",
      "        [3.4024, 3.6866, 3.7619, 3.5980, 3.5772],\n",
      "        [3.9767, 3.8727, 4.0116, 4.0334, 3.9592],\n",
      "        [3.5325, 3.6665, 3.8384, 3.7259, 3.6557],\n",
      "        [3.7684, 3.8845, 4.0569, 4.0271, 3.7621],\n",
      "        [3.5345, 3.5460, 3.7512, 3.5771, 3.5264],\n",
      "        [3.9536, 4.1427, 3.9840, 3.8927, 3.8230],\n",
      "        [3.9550, 3.9816, 4.0031, 4.0776, 4.0332],\n",
      "        [3.5666, 3.6769, 3.9198, 3.8967, 3.8837],\n",
      "        [3.4121, 3.7346, 3.7797, 3.6058, 3.6055],\n",
      "        [3.8262, 3.9448, 4.1369, 4.0978, 3.7764],\n",
      "        [3.6755, 3.9942, 3.9836, 3.8613, 3.7920],\n",
      "        [3.5141, 3.6316, 3.8139, 3.6974, 3.6263],\n",
      "        [3.8826, 3.8084, 4.0335, 4.0383, 3.8394],\n",
      "        [4.1607, 4.3648, 4.1004, 4.0706, 3.8905],\n",
      "        [3.4383, 3.6881, 3.8638, 3.6981, 3.7072],\n",
      "        [3.3823, 3.6017, 3.7274, 3.5766, 3.5173],\n",
      "        [3.5376, 3.5959, 3.7203, 3.7638, 3.5521],\n",
      "        [3.5272, 3.5960, 3.7237, 3.7599, 3.5428],\n",
      "        [3.7627, 3.9518, 4.0778, 3.8670, 3.6808],\n",
      "        [3.5244, 3.7862, 3.8827, 3.7817, 3.6855],\n",
      "        [3.8122, 4.0830, 4.1799, 4.1039, 4.0116],\n",
      "        [3.5130, 3.5616, 3.7630, 3.6034, 3.5422]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3831, 3.7485, 3.8168, 3.6501, 3.5524],\n",
      "        [3.5529, 3.8968, 3.9214, 3.7434, 3.5569],\n",
      "        [3.6523, 3.7042, 3.8716, 3.7107, 3.5976],\n",
      "        [3.4793, 3.9431, 3.7831, 3.6567, 3.7675],\n",
      "        [3.6413, 3.8447, 4.0000, 3.8747, 3.8100],\n",
      "        [3.9688, 3.9069, 4.0046, 4.0326, 4.0020],\n",
      "        [3.4692, 3.5214, 3.7084, 3.6450, 3.5021],\n",
      "        [3.7679, 3.9063, 4.0868, 3.9563, 3.9685],\n",
      "        [4.1172, 4.2869, 4.0349, 3.9923, 3.8319],\n",
      "        [3.5400, 3.8316, 3.9737, 3.7773, 3.6046],\n",
      "        [3.6993, 3.9061, 3.9992, 3.8067, 3.6547],\n",
      "        [3.9640, 3.8528, 4.1425, 4.4487, 4.2714],\n",
      "        [3.6538, 3.7781, 3.8003, 3.7591, 3.6763],\n",
      "        [3.7642, 3.8070, 3.9110, 3.9145, 3.9033],\n",
      "        [3.5866, 3.6709, 3.9011, 3.7552, 3.7019],\n",
      "        [3.7411, 4.0244, 3.9146, 3.9165, 3.9988],\n",
      "        [3.4127, 3.7359, 3.7802, 3.6061, 3.6067],\n",
      "        [3.6960, 3.9049, 4.0221, 3.8940, 3.8286],\n",
      "        [3.9259, 4.0134, 4.1620, 4.1514, 3.7659],\n",
      "        [4.2652, 4.4545, 4.1770, 4.1318, 3.9757],\n",
      "        [3.4235, 3.5776, 3.6443, 3.6530, 3.4578],\n",
      "        [3.7580, 4.0080, 4.1052, 3.9298, 3.6992],\n",
      "        [3.5107, 3.9860, 3.9319, 3.9531, 3.8252],\n",
      "        [3.8863, 3.7927, 4.0190, 4.0455, 3.8317],\n",
      "        [3.6966, 3.9275, 3.9649, 3.8944, 3.7739],\n",
      "        [3.6250, 4.1928, 4.0939, 4.1205, 3.9545],\n",
      "        [3.5332, 3.7483, 3.8576, 3.7965, 3.7316],\n",
      "        [3.6924, 4.1438, 4.1227, 4.1314, 3.9624],\n",
      "        [4.0075, 4.1815, 4.0133, 3.9351, 3.8452],\n",
      "        [3.5327, 3.8351, 3.8595, 3.6522, 3.7186],\n",
      "        [3.6125, 3.6508, 4.0070, 3.9263, 3.5942],\n",
      "        [3.6566, 4.0446, 4.0292, 3.8823, 3.8816],\n",
      "        [3.6639, 3.7408, 3.8699, 3.7309, 3.8117],\n",
      "        [3.8092, 3.8910, 4.0364, 4.0615, 4.0492],\n",
      "        [3.5204, 3.8477, 3.8676, 3.6180, 3.7281],\n",
      "        [3.6457, 3.8907, 3.8574, 3.8142, 3.7425],\n",
      "        [3.4587, 4.0306, 3.8431, 3.6863, 3.7956],\n",
      "        [3.9842, 4.1225, 4.1577, 4.2612, 4.0368],\n",
      "        [3.5097, 3.6254, 3.8170, 3.6937, 3.6214],\n",
      "        [3.5428, 3.7521, 3.7184, 3.7609, 3.6439],\n",
      "        [3.4435, 3.4646, 3.7798, 3.4266, 3.6244],\n",
      "        [3.2987, 3.8308, 3.8229, 3.6627, 3.4802],\n",
      "        [3.6673, 3.9116, 3.8925, 3.9652, 3.8111],\n",
      "        [3.5313, 3.6242, 3.8285, 3.6908, 3.6254],\n",
      "        [3.5885, 3.6817, 3.9160, 3.7639, 3.7063],\n",
      "        [3.6486, 3.9859, 4.0262, 3.8678, 3.7220],\n",
      "        [3.8976, 4.0428, 4.0308, 3.9984, 4.0174],\n",
      "        [3.9965, 4.1909, 4.0405, 3.9351, 3.8849],\n",
      "        [3.3752, 3.6224, 3.7283, 3.5736, 3.5225],\n",
      "        [3.3895, 3.6266, 3.6697, 3.5474, 3.5508],\n",
      "        [3.7381, 3.8690, 3.9908, 3.8588, 3.8533],\n",
      "        [3.4891, 3.6097, 3.7483, 3.7147, 3.5602],\n",
      "        [3.5366, 3.5477, 3.7496, 3.5853, 3.5283],\n",
      "        [3.7623, 3.8639, 4.1241, 4.0643, 3.7103],\n",
      "        [3.4277, 3.6090, 3.7840, 3.6775, 3.6012],\n",
      "        [3.4416, 3.6525, 3.6728, 3.6118, 3.5782],\n",
      "        [3.5085, 3.6348, 3.8120, 3.6895, 3.6162],\n",
      "        [3.7406, 3.9753, 4.0642, 3.8544, 3.5884],\n",
      "        [3.5539, 3.5644, 3.7931, 3.7014, 3.7246],\n",
      "        [3.5226, 3.6036, 3.8244, 3.6762, 3.6083],\n",
      "        [3.8905, 3.9722, 4.1067, 4.0893, 3.9364],\n",
      "        [3.6415, 3.9992, 4.0052, 3.8774, 3.9356],\n",
      "        [3.4030, 3.6137, 3.7373, 3.5897, 3.5461],\n",
      "        [3.6237, 3.9147, 3.9803, 3.8773, 3.7087]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3377, 3.5677, 3.5655, 3.5083, 3.4391],\n",
      "        [3.5135, 3.7229, 3.7057, 3.7176, 3.6198],\n",
      "        [3.5870, 3.4889, 3.9200, 3.7444, 3.6415],\n",
      "        [3.5383, 3.7126, 3.7451, 3.7650, 3.6490],\n",
      "        [3.6864, 3.9576, 3.9372, 3.8943, 3.7828],\n",
      "        [3.7627, 3.8506, 3.9634, 3.8767, 3.8992],\n",
      "        [3.5369, 3.6855, 3.9172, 3.8506, 3.8495],\n",
      "        [3.7796, 4.1064, 3.9852, 3.9873, 4.0092],\n",
      "        [3.5813, 3.8652, 3.8625, 3.7330, 3.6843],\n",
      "        [3.4101, 3.5373, 3.7046, 3.5981, 3.5019],\n",
      "        [3.3333, 3.9910, 3.9368, 3.7314, 3.5819],\n",
      "        [3.4020, 3.6489, 3.6708, 3.5701, 3.5598],\n",
      "        [3.6277, 3.6747, 3.8568, 3.6611, 3.6479],\n",
      "        [3.4618, 3.6491, 3.8161, 3.7320, 3.6120],\n",
      "        [3.5525, 3.5996, 3.8483, 3.7303, 3.7382],\n",
      "        [3.6753, 4.0012, 3.9283, 3.8738, 3.7858],\n",
      "        [3.6149, 3.9970, 4.0208, 3.8399, 3.6935],\n",
      "        [3.5646, 3.6301, 3.8282, 3.7043, 3.6786],\n",
      "        [3.5037, 3.6436, 3.8687, 3.7055, 3.6466],\n",
      "        [3.7842, 3.6630, 3.8555, 3.7984, 3.7617],\n",
      "        [3.6676, 3.9475, 3.9974, 3.8921, 3.8503],\n",
      "        [3.7176, 3.9649, 4.0038, 3.8825, 3.7769],\n",
      "        [3.4161, 3.5018, 3.6884, 3.6166, 3.4792],\n",
      "        [3.5634, 3.6972, 3.8627, 3.6231, 3.4712],\n",
      "        [3.6925, 3.9922, 3.9515, 3.8068, 3.7709],\n",
      "        [3.6033, 3.7791, 3.8915, 3.8084, 3.7661],\n",
      "        [3.4503, 4.0205, 3.9985, 3.7738, 3.6353],\n",
      "        [3.5951, 4.0738, 3.9276, 3.9611, 3.8495],\n",
      "        [3.5037, 3.7103, 3.6945, 3.7089, 3.6052],\n",
      "        [3.5325, 3.8120, 3.8580, 3.7637, 3.7044],\n",
      "        [3.7151, 4.1586, 4.0115, 4.0610, 3.9567],\n",
      "        [3.3921, 3.9615, 3.9445, 3.7537, 3.5829],\n",
      "        [3.5810, 3.9931, 3.8334, 3.7795, 3.8730],\n",
      "        [3.4319, 3.5236, 3.7020, 3.6238, 3.5012],\n",
      "        [3.6567, 3.8875, 4.0112, 3.8443, 3.7339],\n",
      "        [3.3756, 3.6240, 3.7286, 3.5743, 3.5232],\n",
      "        [3.6676, 3.9134, 3.8930, 3.9660, 3.8117],\n",
      "        [3.7017, 3.9429, 3.9691, 3.8655, 3.7557],\n",
      "        [3.6999, 4.2046, 4.0929, 3.9614, 4.0564],\n",
      "        [3.5336, 3.7503, 3.8584, 3.7974, 3.7323],\n",
      "        [3.6474, 3.8695, 3.8563, 3.7151, 3.7715],\n",
      "        [3.4121, 3.5335, 3.7034, 3.5994, 3.5031],\n",
      "        [3.5014, 3.5380, 3.7996, 3.6752, 3.6504],\n",
      "        [3.5186, 3.6236, 3.8159, 3.6854, 3.6191],\n",
      "        [3.6303, 3.7670, 3.9389, 3.7998, 3.6866],\n",
      "        [3.3509, 3.4986, 3.6601, 3.5249, 3.4386],\n",
      "        [3.3162, 3.5767, 3.6773, 3.5647, 3.5254],\n",
      "        [3.6676, 3.9134, 3.8930, 3.9660, 3.8117],\n",
      "        [3.7501, 3.9468, 4.0909, 3.9718, 3.9569],\n",
      "        [3.5772, 3.6413, 3.8472, 3.7329, 3.6699],\n",
      "        [3.4720, 3.4987, 3.8059, 3.4625, 3.6497],\n",
      "        [3.5286, 3.5384, 3.7381, 3.5644, 3.5171],\n",
      "        [4.0361, 4.2727, 3.9292, 3.9458, 3.7763],\n",
      "        [3.6595, 3.7504, 3.8832, 3.7534, 3.7974],\n",
      "        [3.7068, 3.9373, 3.9699, 3.8917, 3.7790],\n",
      "        [3.8625, 3.9323, 4.0682, 4.0629, 3.7814],\n",
      "        [3.6805, 3.7298, 3.8802, 3.7447, 3.5879],\n",
      "        [3.5222, 3.6333, 3.8165, 3.6856, 3.6210],\n",
      "        [3.6784, 4.0145, 4.0043, 3.8743, 3.7975],\n",
      "        [3.3770, 3.6270, 3.7312, 3.5726, 3.5229],\n",
      "        [3.2080, 3.4902, 3.6601, 3.4497, 3.4560],\n",
      "        [3.6631, 3.8720, 4.0071, 3.7720, 3.6150],\n",
      "        [3.5933, 3.6800, 3.9058, 3.7666, 3.7101],\n",
      "        [3.6702, 3.7088, 3.8759, 3.6603, 3.5321]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5387, 3.7485, 3.7857, 3.7784, 3.6957],\n",
      "        [3.8026, 4.0885, 4.1550, 4.0892, 3.9638],\n",
      "        [3.5193, 3.8437, 3.8599, 3.6363, 3.7072],\n",
      "        [3.6566, 4.0480, 4.0300, 3.8836, 3.8824],\n",
      "        [3.7691, 3.9161, 4.0218, 3.8684, 3.6740],\n",
      "        [3.3504, 3.5840, 3.6325, 3.5000, 3.5059],\n",
      "        [3.4967, 3.6311, 3.8295, 3.7142, 3.7030],\n",
      "        [3.6952, 3.8744, 3.8983, 3.7409, 3.7266],\n",
      "        [3.6787, 3.7866, 3.7636, 3.8477, 3.8026],\n",
      "        [3.7058, 4.0159, 3.9024, 3.8842, 3.9716],\n",
      "        [3.5336, 3.6323, 3.8309, 3.6945, 3.6337],\n",
      "        [4.1243, 4.3477, 4.0354, 4.0246, 3.8826],\n",
      "        [4.0251, 3.9298, 4.1424, 4.2080, 4.0051],\n",
      "        [3.7041, 3.7717, 3.8915, 3.7733, 3.5694],\n",
      "        [3.8948, 3.7706, 3.8949, 3.9087, 3.9173],\n",
      "        [3.4507, 3.6642, 3.6790, 3.6084, 3.5898],\n",
      "        [3.4044, 3.7742, 3.9417, 3.7083, 3.6829],\n",
      "        [3.7649, 3.8101, 3.9117, 3.9156, 3.9042],\n",
      "        [3.3289, 3.5851, 3.6553, 3.5538, 3.5000],\n",
      "        [3.4922, 3.5308, 3.7912, 3.6750, 3.6532],\n",
      "        [3.5327, 3.7449, 3.7120, 3.7338, 3.6413],\n",
      "        [3.8977, 4.0461, 4.0311, 3.9996, 4.0182],\n",
      "        [3.5230, 3.6076, 3.8242, 3.6839, 3.6089],\n",
      "        [3.4716, 3.6204, 3.8132, 3.6881, 3.6140],\n",
      "        [3.3240, 3.5561, 3.6127, 3.4627, 3.4845],\n",
      "        [3.6879, 3.9747, 3.9343, 3.8697, 3.7825],\n",
      "        [3.4363, 3.5620, 3.7224, 3.6217, 3.5450],\n",
      "        [3.5568, 3.9807, 3.8809, 3.8695, 3.8048],\n",
      "        [3.4099, 3.5385, 3.7048, 3.5984, 3.5021],\n",
      "        [3.3940, 3.8001, 3.6949, 3.4680, 3.6263],\n",
      "        [3.9829, 4.1017, 4.1465, 4.2426, 3.9950],\n",
      "        [3.8041, 3.6195, 3.9073, 4.1015, 4.0103],\n",
      "        [3.7318, 3.9157, 3.8767, 3.9149, 3.8461],\n",
      "        [3.5168, 3.6672, 3.8357, 3.7175, 3.6337],\n",
      "        [3.7857, 3.9824, 3.9774, 3.9255, 3.9218],\n",
      "        [3.4779, 3.7673, 3.9615, 3.7909, 3.5804],\n",
      "        [3.3901, 3.7112, 3.7657, 3.5995, 3.5759],\n",
      "        [3.5356, 3.8385, 3.9584, 3.7778, 3.6192],\n",
      "        [3.4873, 3.6196, 3.7797, 3.5595, 3.6694],\n",
      "        [3.4254, 3.6447, 3.6501, 3.6546, 3.5497],\n",
      "        [3.7223, 3.7185, 3.8643, 3.7017, 3.5954],\n",
      "        [3.8180, 3.9644, 4.0796, 3.9685, 4.0572],\n",
      "        [3.5177, 3.7205, 3.7005, 3.7208, 3.6168],\n",
      "        [3.8211, 3.9385, 4.1853, 4.1447, 3.8067],\n",
      "        [3.5885, 3.6713, 3.8802, 3.7354, 3.7116],\n",
      "        [3.6861, 3.9590, 3.9377, 3.8948, 3.7830],\n",
      "        [3.6856, 3.7658, 3.8681, 3.7484, 3.5216],\n",
      "        [3.4138, 3.8588, 3.8362, 3.5534, 3.7196],\n",
      "        [3.5441, 3.8206, 3.8470, 3.7398, 3.7056],\n",
      "        [3.9875, 4.0322, 4.2244, 4.2644, 4.0344],\n",
      "        [3.4507, 3.6642, 3.6790, 3.6084, 3.5898],\n",
      "        [3.6805, 3.7091, 3.8621, 3.6609, 3.5468],\n",
      "        [3.6684, 3.8763, 3.9960, 3.8218, 3.7426],\n",
      "        [3.9119, 3.9835, 4.1791, 4.1539, 3.9268],\n",
      "        [3.4209, 3.5157, 3.6961, 3.6186, 3.4948],\n",
      "        [3.6268, 3.9214, 3.8827, 3.9183, 3.7646],\n",
      "        [3.3829, 3.6058, 3.7284, 3.5779, 3.5193],\n",
      "        [3.3792, 3.6368, 3.7068, 3.6214, 3.5137],\n",
      "        [3.5771, 3.6425, 3.8474, 3.7333, 3.6700],\n",
      "        [3.7911, 4.0589, 3.9596, 3.9722, 4.0573],\n",
      "        [3.3942, 3.6489, 3.7773, 3.6058, 3.5490],\n",
      "        [3.6499, 3.5764, 3.9795, 3.7967, 3.7047],\n",
      "        [3.3866, 3.5970, 3.7302, 3.5806, 3.5196],\n",
      "        [3.5907, 3.6251, 4.0695, 3.7880, 3.7534]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5096, 4.0510, 4.0544, 3.7803, 3.6604],\n",
      "        [3.3937, 3.6502, 3.7772, 3.6057, 3.5491],\n",
      "        [3.5319, 3.7458, 3.7100, 3.7486, 3.6371],\n",
      "        [3.4010, 3.6296, 3.6627, 3.5529, 3.5453],\n",
      "        [3.7529, 3.5980, 3.7271, 3.7111, 3.7830],\n",
      "        [3.5720, 3.6429, 3.8494, 3.7122, 3.6874],\n",
      "        [3.4434, 3.5657, 3.7281, 3.6197, 3.5159],\n",
      "        [3.4694, 3.6301, 3.7909, 3.5508, 3.6660],\n",
      "        [3.5679, 3.7842, 3.9271, 3.8662, 3.6782],\n",
      "        [3.4524, 3.6659, 3.6742, 3.6206, 3.5822],\n",
      "        [3.6178, 3.7559, 3.8619, 3.8711, 3.6889],\n",
      "        [4.0315, 3.8476, 4.1107, 4.4376, 4.2834],\n",
      "        [3.4330, 3.9131, 3.9028, 3.7745, 3.7059],\n",
      "        [3.5935, 3.6879, 3.9175, 3.7827, 3.7178],\n",
      "        [3.7039, 3.7730, 3.8914, 3.7734, 3.5694],\n",
      "        [3.4639, 3.6250, 3.8071, 3.6892, 3.6089],\n",
      "        [3.5700, 3.6383, 3.8202, 3.7022, 3.6838],\n",
      "        [3.8568, 3.8266, 4.0311, 4.0079, 3.8185],\n",
      "        [3.8969, 3.8158, 4.0372, 4.0063, 3.8603],\n",
      "        [3.7619, 3.8704, 4.1275, 4.0657, 3.7110],\n",
      "        [3.5695, 3.6299, 3.8043, 3.6933, 3.6864],\n",
      "        [3.5376, 3.7152, 3.7453, 3.7652, 3.6492],\n",
      "        [3.5794, 4.0558, 3.9219, 3.9511, 3.8390],\n",
      "        [3.3842, 3.6173, 3.6542, 3.5353, 3.5412],\n",
      "        [3.3543, 3.5942, 3.6410, 3.5081, 3.5137],\n",
      "        [3.4148, 3.7721, 3.8398, 3.5878, 3.6736],\n",
      "        [3.7907, 4.0602, 3.9595, 3.9721, 4.0572],\n",
      "        [3.6421, 3.6955, 3.8590, 3.6828, 3.6151],\n",
      "        [3.3816, 3.5660, 3.6869, 3.6178, 3.5079],\n",
      "        [3.7759, 3.9834, 3.9792, 3.8979, 3.9050],\n",
      "        [3.5802, 3.9958, 3.8335, 3.7798, 3.8730],\n",
      "        [3.5325, 3.8394, 3.8599, 3.6537, 3.7195],\n",
      "        [3.4863, 3.6765, 3.7992, 3.6738, 3.6630],\n",
      "        [3.4868, 3.6208, 3.7795, 3.5594, 3.6693],\n",
      "        [3.3068, 3.5424, 3.6032, 3.4419, 3.4625],\n",
      "        [3.5496, 3.6868, 3.7462, 3.6279, 3.6438],\n",
      "        [3.4083, 3.6363, 3.6614, 3.5747, 3.5455],\n",
      "        [3.8985, 3.9901, 4.1843, 4.1839, 3.9560],\n",
      "        [3.5199, 3.6119, 3.8184, 3.6879, 3.6104],\n",
      "        [3.5215, 3.6611, 3.8403, 3.7220, 3.6527],\n",
      "        [3.5226, 3.6090, 3.8242, 3.6838, 3.6088],\n",
      "        [3.8018, 3.8954, 4.0302, 4.0619, 4.0528],\n",
      "        [3.6877, 3.8646, 3.8844, 3.7137, 3.7155],\n",
      "        [3.7067, 3.7194, 3.8697, 3.6903, 3.5749],\n",
      "        [3.5848, 3.8706, 3.8642, 3.7430, 3.6808],\n",
      "        [3.3638, 3.5147, 3.6461, 3.5206, 3.4870],\n",
      "        [3.5088, 3.7026, 3.7303, 3.7106, 3.6012],\n",
      "        [3.3920, 3.5833, 3.7213, 3.5820, 3.5158],\n",
      "        [3.6661, 3.7691, 3.7510, 3.8359, 3.7793],\n",
      "        [3.6481, 3.9915, 4.0276, 3.8691, 3.7228],\n",
      "        [3.5257, 3.7306, 3.6992, 3.7297, 3.6154],\n",
      "        [3.6574, 3.9848, 3.8804, 3.6745, 3.7599],\n",
      "        [3.5528, 3.6563, 3.8921, 3.6308, 3.7946],\n",
      "        [3.5033, 3.9599, 3.8784, 3.8364, 3.8123],\n",
      "        [3.9457, 4.0787, 4.2137, 4.2163, 3.9071],\n",
      "        [3.5251, 3.7270, 3.7017, 3.7296, 3.6170],\n",
      "        [3.6886, 3.7479, 3.8874, 3.7545, 3.5897],\n",
      "        [3.4327, 3.5372, 3.7100, 3.6364, 3.5184],\n",
      "        [3.4166, 3.9175, 3.7603, 3.6208, 3.7111],\n",
      "        [3.6422, 3.5449, 3.9745, 3.7947, 3.6906],\n",
      "        [3.6363, 3.7328, 3.8272, 3.7564, 3.6713],\n",
      "        [3.3327, 3.9936, 3.9369, 3.7324, 3.5826],\n",
      "        [3.6134, 3.6267, 3.8243, 3.7095, 3.7017],\n",
      "        [3.4518, 3.6513, 3.8005, 3.5511, 3.6666]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.3780, 3.6008, 3.6480, 3.5292, 3.5192],\n",
      "        [3.4619, 3.6109, 3.7852, 3.6464, 3.5875],\n",
      "        [3.3116, 3.5866, 3.6857, 3.5537, 3.5303],\n",
      "        [3.6662, 3.9180, 3.8934, 3.9666, 3.8113],\n",
      "        [3.8287, 3.9213, 4.1521, 4.1375, 3.7905],\n",
      "        [3.5251, 3.7324, 3.6991, 3.7300, 3.6150],\n",
      "        [3.4195, 3.6941, 3.6632, 3.6678, 3.5666],\n",
      "        [3.4097, 3.8076, 3.8615, 3.6114, 3.7089],\n",
      "        [3.5067, 3.7042, 3.8308, 3.7163, 3.7636],\n",
      "        [3.3261, 3.5588, 3.6120, 3.4650, 3.4829],\n",
      "        [3.5915, 3.7110, 3.8406, 3.7999, 3.6724],\n",
      "        [3.6662, 3.9180, 3.8934, 3.9666, 3.8113],\n",
      "        [3.3763, 3.6871, 3.7485, 3.5767, 3.5451],\n",
      "        [3.3148, 3.5809, 3.6772, 3.5653, 3.5253],\n",
      "        [3.5847, 3.8098, 3.9763, 3.8168, 3.7730],\n",
      "        [3.6580, 3.8701, 4.0021, 3.7664, 3.6103],\n",
      "        [3.5205, 3.7315, 3.7072, 3.7245, 3.6261],\n",
      "        [3.4021, 3.6038, 3.7210, 3.5793, 3.5412],\n",
      "        [3.5606, 3.6198, 3.8741, 3.7565, 3.7486],\n",
      "        [3.4444, 3.8223, 3.8460, 3.7282, 3.8189],\n",
      "        [3.9699, 3.9131, 4.0052, 4.0342, 4.0028],\n",
      "        [3.6956, 4.0098, 4.0010, 3.8757, 3.8191],\n",
      "        [3.5650, 3.9099, 3.8089, 3.8738, 3.7352],\n",
      "        [3.6181, 3.5898, 3.7457, 3.6582, 3.6727],\n",
      "        [3.9232, 4.0491, 4.1817, 4.2130, 3.8441],\n",
      "        [3.9513, 4.1362, 4.0464, 4.1207, 4.1529],\n",
      "        [3.4229, 3.7306, 3.8201, 3.6249, 3.5878],\n",
      "        [3.4688, 3.6463, 3.7005, 3.5969, 3.5595],\n",
      "        [3.9374, 3.8820, 4.0844, 4.1186, 3.9061],\n",
      "        [3.8239, 3.9409, 4.0116, 4.0480, 3.8155],\n",
      "        [3.6520, 3.6989, 3.8733, 3.7759, 3.6638],\n",
      "        [3.6744, 3.8493, 4.0102, 3.9091, 3.8982],\n",
      "        [3.7898, 3.9720, 4.1009, 4.1068, 4.1453],\n",
      "        [3.5053, 3.7970, 3.8554, 3.7610, 3.6885],\n",
      "        [3.8310, 3.9027, 4.0458, 4.0175, 3.8522],\n",
      "        [3.7580, 3.9219, 4.0836, 3.9653, 3.9633],\n",
      "        [3.7123, 3.9592, 3.9728, 3.8758, 3.7660],\n",
      "        [3.6287, 3.9222, 3.8827, 3.9203, 3.7645],\n",
      "        [3.4340, 3.6299, 3.6715, 3.6406, 3.5429],\n",
      "        [3.4567, 3.7709, 3.9962, 3.7115, 3.8016],\n",
      "        [3.4893, 3.7014, 3.6880, 3.6899, 3.5936],\n",
      "        [3.4205, 3.5124, 3.6874, 3.6255, 3.5014],\n",
      "        [3.3386, 3.5772, 3.6249, 3.4797, 3.4947],\n",
      "        [3.5154, 3.6210, 3.8183, 3.6906, 3.6214],\n",
      "        [3.7141, 3.7391, 3.8693, 4.0598, 3.8719],\n",
      "        [3.6743, 3.9132, 3.8952, 3.8462, 3.7361],\n",
      "        [3.5870, 3.6274, 3.8403, 3.7112, 3.6875],\n",
      "        [3.3317, 3.5674, 3.6195, 3.4693, 3.4945],\n",
      "        [4.0722, 4.2564, 4.0051, 3.9713, 3.8094],\n",
      "        [3.4099, 3.5064, 3.6858, 3.6111, 3.4813],\n",
      "        [3.9143, 3.8730, 3.9548, 3.9536, 3.9227],\n",
      "        [4.0059, 4.1344, 4.1812, 4.2900, 4.0599],\n",
      "        [3.8948, 3.7735, 3.8947, 3.9090, 3.9171],\n",
      "        [3.5579, 3.6935, 3.9411, 3.7775, 3.7121],\n",
      "        [3.5215, 3.8002, 3.8757, 3.7369, 3.6569],\n",
      "        [3.3311, 3.6155, 3.6649, 3.5596, 3.5173],\n",
      "        [3.6672, 3.9056, 3.9034, 3.8822, 3.7602],\n",
      "        [3.9115, 4.1509, 4.0211, 3.8913, 3.8624],\n",
      "        [3.5544, 3.8107, 3.7493, 3.8666, 3.6165],\n",
      "        [3.3814, 3.6989, 3.7621, 3.5937, 3.5664],\n",
      "        [3.9270, 3.8499, 3.9332, 3.9500, 3.8964],\n",
      "        [3.7394, 3.8934, 4.0227, 4.0043, 3.7557],\n",
      "        [3.6692, 3.8436, 3.8626, 3.6914, 3.6962],\n",
      "        [3.6457, 3.7287, 3.8337, 3.7601, 3.6579]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5681, 3.6431, 3.8969, 3.7603, 3.7189],\n",
      "        [3.6075, 3.9224, 4.0863, 3.9462, 3.7860],\n",
      "        [3.4692, 3.6244, 3.7634, 3.6805, 3.5473],\n",
      "        [3.4154, 3.6344, 3.8006, 3.7066, 3.6101],\n",
      "        [3.4412, 3.6098, 3.7579, 3.6603, 3.5224],\n",
      "        [3.4456, 3.4721, 3.7794, 3.4274, 3.6235],\n",
      "        [3.7018, 3.9148, 3.9994, 3.8090, 3.6548],\n",
      "        [3.8325, 3.9183, 4.0468, 4.0412, 3.8447],\n",
      "        [3.4540, 3.7066, 3.7053, 3.6847, 3.5453],\n",
      "        [3.4622, 3.5433, 3.7186, 3.6300, 3.5044],\n",
      "        [3.6374, 3.7960, 3.8805, 3.9224, 3.6980],\n",
      "        [3.4340, 3.6964, 3.8282, 3.5660, 3.7051],\n",
      "        [3.5574, 3.9390, 3.9453, 3.8643, 3.8803],\n",
      "        [3.3865, 3.6206, 3.6534, 3.5356, 3.5403],\n",
      "        [3.6143, 3.6628, 4.0114, 3.9282, 3.5940],\n",
      "        [3.5523, 3.6900, 3.7452, 3.6285, 3.6429],\n",
      "        [3.4231, 3.9080, 3.7467, 3.6312, 3.7133],\n",
      "        [3.5827, 3.6680, 3.8844, 3.7439, 3.6930],\n",
      "        [3.4867, 3.9402, 3.9318, 3.7018, 3.5400],\n",
      "        [3.7609, 3.9244, 4.0835, 3.9653, 3.9625],\n",
      "        [3.4155, 3.6351, 3.6385, 3.6105, 3.4908],\n",
      "        [3.4838, 4.0626, 4.0406, 3.8293, 3.7014],\n",
      "        [3.3334, 3.5664, 3.6208, 3.4632, 3.4861],\n",
      "        [3.7045, 3.9609, 3.9858, 3.8858, 3.7798],\n",
      "        [3.5243, 3.6631, 3.8337, 3.5796, 3.4248],\n",
      "        [3.4569, 3.6578, 3.7085, 3.6304, 3.5891],\n",
      "        [3.6051, 3.6955, 3.8278, 3.6982, 3.8569],\n",
      "        [3.5279, 3.6248, 3.8166, 3.6882, 3.6224],\n",
      "        [3.4169, 3.6362, 3.6608, 3.5766, 3.5443],\n",
      "        [3.6608, 3.8721, 4.0017, 3.7665, 3.6096],\n",
      "        [3.5590, 3.7892, 3.9414, 3.8839, 3.6548],\n",
      "        [3.5323, 3.6399, 3.8859, 3.7393, 3.6663],\n",
      "        [3.5313, 3.6381, 3.8261, 3.6930, 3.6303],\n",
      "        [3.5865, 3.6879, 3.9059, 3.7601, 3.7091],\n",
      "        [3.4255, 3.7291, 3.6330, 3.6615, 3.5283],\n",
      "        [3.9271, 4.1051, 3.9081, 3.8745, 3.7755],\n",
      "        [3.8214, 3.9399, 4.1961, 4.1433, 3.7812],\n",
      "        [3.4374, 3.6784, 3.8161, 3.6566, 3.5551],\n",
      "        [3.9503, 4.0592, 4.2368, 4.2320, 3.8112],\n",
      "        [3.8907, 4.1180, 4.0222, 4.0628, 4.0980],\n",
      "        [3.5272, 3.7762, 3.9437, 3.8405, 3.6354],\n",
      "        [3.5330, 3.8537, 3.9988, 3.7869, 3.5986],\n",
      "        [3.4195, 3.6475, 3.6665, 3.5779, 3.5582],\n",
      "        [3.8784, 3.8608, 3.9601, 3.9272, 3.9069],\n",
      "        [3.3884, 3.5942, 3.7224, 3.5804, 3.5149],\n",
      "        [3.4601, 4.0391, 3.8430, 3.6879, 3.7951],\n",
      "        [3.3735, 3.6520, 3.7076, 3.6212, 3.5117],\n",
      "        [3.5227, 3.6227, 3.8188, 3.6851, 3.6174],\n",
      "        [3.7846, 3.9700, 4.0703, 3.9574, 4.0053],\n",
      "        [3.6387, 3.6801, 3.9824, 3.8630, 3.6579],\n",
      "        [3.5189, 3.6995, 3.7336, 3.6860, 3.6420],\n",
      "        [3.5222, 3.5308, 3.7222, 3.5610, 3.5034],\n",
      "        [3.7781, 3.9295, 4.0310, 3.8747, 3.6775],\n",
      "        [3.3481, 3.6154, 3.6719, 3.5683, 3.5146],\n",
      "        [3.3945, 3.7271, 3.7757, 3.5922, 3.5733],\n",
      "        [3.7419, 3.9188, 4.0789, 3.9663, 3.9655],\n",
      "        [3.8473, 3.9624, 4.2319, 4.1646, 3.7985],\n",
      "        [3.8044, 3.8992, 4.0296, 4.0624, 4.0517],\n",
      "        [3.4026, 3.6297, 3.6602, 3.5465, 3.5635],\n",
      "        [3.8016, 3.8351, 4.0144, 3.9599, 3.7847],\n",
      "        [3.6308, 3.9107, 4.0760, 3.9406, 3.7993],\n",
      "        [3.6245, 3.5989, 3.7524, 3.6697, 3.6825],\n",
      "        [3.8992, 3.9763, 3.9609, 3.9882, 3.9905],\n",
      "        [3.5983, 3.6924, 3.9084, 3.7724, 3.7200]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4193, 3.7779, 3.8380, 3.5894, 3.6714],\n",
      "        [3.4960, 3.7005, 3.6881, 3.6622, 3.6075],\n",
      "        [3.5415, 3.6713, 3.9227, 3.8109, 3.7050],\n",
      "        [3.7414, 3.8093, 3.9940, 3.9132, 3.6199],\n",
      "        [3.5408, 3.5577, 3.7482, 3.5875, 3.5267],\n",
      "        [3.4782, 3.6578, 3.6952, 3.5988, 3.5661],\n",
      "        [3.5296, 3.5686, 3.7599, 3.6015, 3.5374],\n",
      "        [3.5690, 3.6821, 3.9059, 3.7170, 3.7698],\n",
      "        [3.6019, 3.9228, 3.8775, 3.8163, 3.8318],\n",
      "        [3.4570, 3.6714, 3.6727, 3.6221, 3.5802],\n",
      "        [3.7099, 3.8764, 4.0410, 3.9103, 3.9237],\n",
      "        [3.6990, 3.8363, 3.9751, 3.8127, 3.7565],\n",
      "        [3.6976, 3.9727, 3.9349, 3.8876, 3.7860],\n",
      "        [3.7153, 3.6972, 3.8277, 4.0460, 3.8269],\n",
      "        [3.4416, 4.0178, 3.8194, 3.6673, 3.7703],\n",
      "        [3.6065, 3.7345, 3.8476, 3.8312, 3.6752],\n",
      "        [3.6144, 3.6735, 3.9289, 3.8218, 3.7169],\n",
      "        [3.6104, 4.0056, 4.0252, 3.8420, 3.6841],\n",
      "        [3.7366, 3.9002, 3.9922, 3.7977, 3.7859],\n",
      "        [3.3845, 3.5990, 3.7179, 3.5754, 3.5124],\n",
      "        [3.7573, 3.8975, 4.0364, 4.0154, 3.7569],\n",
      "        [3.3771, 3.6517, 3.7361, 3.5782, 3.5222],\n",
      "        [3.5316, 3.5915, 3.8365, 3.5996, 3.6634],\n",
      "        [3.8892, 3.9798, 4.1089, 4.1054, 3.9274],\n",
      "        [3.4826, 3.6187, 3.8162, 3.6890, 3.6111],\n",
      "        [4.0363, 3.9581, 4.0977, 4.1370, 4.0784],\n",
      "        [3.4176, 3.8664, 3.8348, 3.5555, 3.7175],\n",
      "        [3.6716, 3.9223, 3.8922, 3.9680, 3.8095],\n",
      "        [3.6964, 4.1573, 4.1236, 4.1351, 3.9616],\n",
      "        [3.6743, 3.8750, 4.0035, 3.9071, 3.8640],\n",
      "        [3.3934, 3.6287, 3.7323, 3.5910, 3.5428],\n",
      "        [3.5694, 3.6382, 3.8265, 3.7062, 3.6767],\n",
      "        [3.4247, 3.6980, 3.6619, 3.6690, 3.5652],\n",
      "        [3.3910, 3.7210, 3.7649, 3.5878, 3.5670],\n",
      "        [3.5745, 3.8564, 3.8469, 3.7062, 3.6944],\n",
      "        [3.5344, 4.0139, 3.9489, 3.9724, 3.8367],\n",
      "        [3.3415, 3.5756, 3.5640, 3.5100, 3.4376],\n",
      "        [3.5023, 3.8299, 3.8674, 3.6691, 3.7185],\n",
      "        [3.8291, 3.6819, 3.8439, 3.8201, 3.8115],\n",
      "        [3.4548, 3.6812, 3.6859, 3.6266, 3.5782],\n",
      "        [3.4233, 3.7042, 3.8651, 3.6771, 3.6816],\n",
      "        [3.6720, 3.7180, 3.8865, 3.8000, 3.6709],\n",
      "        [3.3887, 3.5801, 3.6850, 3.6142, 3.5048],\n",
      "        [3.4293, 3.5580, 3.6125, 3.6540, 3.4986],\n",
      "        [3.3927, 3.7170, 3.7659, 3.5975, 3.5764],\n",
      "        [3.4013, 3.5969, 3.7247, 3.5919, 3.5289],\n",
      "        [3.7019, 3.7912, 4.1116, 4.0270, 3.7022],\n",
      "        [3.5350, 3.5318, 3.6858, 3.6191, 3.6953],\n",
      "        [3.4193, 3.5824, 3.7333, 3.6154, 3.5327],\n",
      "        [3.6035, 3.7686, 3.8668, 3.7684, 3.7679],\n",
      "        [3.5273, 3.6149, 3.8228, 3.6852, 3.6067],\n",
      "        [3.7063, 3.8945, 3.9746, 3.9693, 3.7480],\n",
      "        [3.4602, 3.9159, 3.8422, 3.7704, 3.7669],\n",
      "        [3.4934, 3.6196, 3.7472, 3.7173, 3.5590],\n",
      "        [3.6425, 3.9065, 3.9646, 3.8132, 3.8380],\n",
      "        [3.7189, 3.9948, 3.9778, 3.8712, 3.8296],\n",
      "        [3.6596, 3.7013, 3.8750, 3.7745, 3.6688],\n",
      "        [3.4866, 3.7016, 3.6893, 3.6642, 3.5973],\n",
      "        [3.9266, 3.9885, 4.1286, 4.1324, 3.9508],\n",
      "        [3.5848, 4.0018, 3.8320, 3.7815, 3.8709],\n",
      "        [3.7340, 3.7701, 3.9733, 3.9400, 3.6776],\n",
      "        [3.8775, 3.9937, 4.1481, 4.1948, 3.9164],\n",
      "        [3.5416, 3.7972, 3.8741, 3.7318, 3.6682],\n",
      "        [3.7649, 3.5694, 3.7314, 3.7356, 3.7426]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5216, 3.7277, 3.7046, 3.7224, 3.6211],\n",
      "        [3.4966, 3.9809, 3.8185, 3.7202, 3.8165],\n",
      "        [3.5908, 3.8494, 3.8395, 3.7390, 3.7223],\n",
      "        [3.4143, 3.5760, 3.7304, 3.6173, 3.5188],\n",
      "        [3.6496, 3.9170, 3.9014, 3.9325, 3.7603],\n",
      "        [3.4834, 3.7794, 3.9665, 3.7946, 3.5773],\n",
      "        [3.5772, 3.6255, 3.8812, 3.7654, 3.7490],\n",
      "        [3.4922, 3.6862, 3.8035, 3.6772, 3.6597],\n",
      "        [3.5224, 3.6968, 3.8251, 3.5987, 3.6826],\n",
      "        [3.9055, 4.0004, 4.1886, 4.1872, 3.9526],\n",
      "        [3.5128, 3.5801, 3.8135, 3.6645, 3.5869],\n",
      "        [3.6300, 3.7459, 3.8283, 3.7346, 3.6863],\n",
      "        [3.3847, 3.7158, 3.7642, 3.5828, 3.5593],\n",
      "        [3.6164, 3.6752, 3.9319, 3.8227, 3.7156],\n",
      "        [3.5411, 3.6977, 3.8548, 3.7491, 3.6602],\n",
      "        [3.5290, 3.6165, 3.8215, 3.6822, 3.6066],\n",
      "        [3.3451, 3.5763, 3.6262, 3.4797, 3.4893],\n",
      "        [3.6527, 3.5801, 3.9827, 3.7978, 3.6992],\n",
      "        [3.2952, 3.5660, 3.6842, 3.5273, 3.5016],\n",
      "        [3.5002, 3.6991, 3.8208, 3.5960, 3.6577],\n",
      "        [3.4768, 3.6461, 3.7932, 3.5630, 3.6672],\n",
      "        [3.5315, 3.7466, 3.7162, 3.7366, 3.6333],\n",
      "        [3.3978, 3.9719, 3.9423, 3.7544, 3.5774],\n",
      "        [3.6959, 3.7554, 3.8886, 3.7573, 3.5867],\n",
      "        [3.5372, 3.5334, 3.6884, 3.6200, 3.6942],\n",
      "        [3.7506, 3.9993, 4.1182, 3.9751, 3.9690],\n",
      "        [3.4079, 3.9650, 3.9358, 3.7588, 3.6776],\n",
      "        [3.4267, 3.6996, 3.6647, 3.6698, 3.5642],\n",
      "        [3.4302, 3.9308, 3.8644, 3.8395, 3.7572],\n",
      "        [3.6099, 3.7911, 3.8951, 3.8122, 3.7631],\n",
      "        [4.0438, 4.2822, 3.9302, 3.9485, 3.7735],\n",
      "        [3.6583, 3.7271, 3.8212, 3.8908, 3.7538],\n",
      "        [3.4160, 3.4951, 3.6821, 3.6112, 3.4673],\n",
      "        [3.6354, 3.6932, 3.8600, 3.6685, 3.6292],\n",
      "        [3.5734, 3.7071, 3.9519, 3.7795, 3.7172],\n",
      "        [3.9496, 3.9288, 4.0429, 4.1203, 3.9461],\n",
      "        [3.3910, 3.6855, 3.7534, 3.5829, 3.5394],\n",
      "        [3.8875, 3.9740, 4.0740, 4.1107, 3.8518],\n",
      "        [3.6048, 3.7037, 3.9280, 3.8071, 3.6526],\n",
      "        [3.5095, 3.6913, 3.9005, 3.8031, 3.7947],\n",
      "        [3.7342, 3.8418, 4.0236, 3.8863, 3.6349],\n",
      "        [3.5770, 3.6369, 3.8052, 3.6958, 3.6832],\n",
      "        [3.5651, 3.6218, 3.8653, 3.7496, 3.7461],\n",
      "        [3.3834, 3.6734, 3.7436, 3.5779, 3.5334],\n",
      "        [3.4251, 3.5253, 3.6978, 3.6198, 3.4947],\n",
      "        [3.4988, 3.5396, 3.7928, 3.6769, 3.6499],\n",
      "        [3.7595, 3.8994, 4.0397, 4.0164, 3.7557],\n",
      "        [3.5248, 3.6465, 3.8167, 3.6902, 3.6160],\n",
      "        [3.5840, 3.6521, 3.9072, 3.7962, 3.7671],\n",
      "        [3.9453, 3.8164, 4.0577, 4.0796, 3.8876],\n",
      "        [3.5400, 3.7625, 3.8624, 3.8014, 3.7293],\n",
      "        [3.5696, 3.9196, 3.8184, 3.7867, 3.6949],\n",
      "        [3.3843, 3.5408, 3.6799, 3.5584, 3.4711],\n",
      "        [3.5595, 3.6618, 3.8941, 3.6336, 3.7798],\n",
      "        [3.6924, 4.0148, 4.0201, 3.9272, 3.9078],\n",
      "        [3.5800, 3.6219, 3.9417, 3.8078, 3.6487],\n",
      "        [3.6815, 3.9194, 3.8972, 3.8488, 3.7333],\n",
      "        [3.6274, 3.7642, 3.7558, 3.7733, 3.6848],\n",
      "        [3.8541, 3.8579, 3.9567, 3.8987, 3.8931],\n",
      "        [3.6926, 4.0303, 4.0170, 3.8819, 3.8021],\n",
      "        [3.9943, 4.0450, 4.2298, 4.2680, 4.0309],\n",
      "        [3.8994, 3.8579, 4.0171, 4.3725, 4.1632],\n",
      "        [3.5823, 3.6620, 3.8702, 3.7513, 3.6820],\n",
      "        [3.4504, 3.7103, 3.7008, 3.7282, 3.5584]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.7695, 3.5721, 3.7364, 3.7369, 3.7402],\n",
      "        [3.4201, 3.5484, 3.7067, 3.6065, 3.5007],\n",
      "        [3.3909, 3.6151, 3.7314, 3.5808, 3.5148],\n",
      "        [3.7203, 3.8071, 4.1433, 4.0648, 3.7137],\n",
      "        [3.6833, 3.7342, 3.8860, 3.7307, 3.5933],\n",
      "        [3.7523, 4.0010, 4.1212, 3.9760, 3.9674],\n",
      "        [3.5428, 3.6990, 3.8573, 3.7497, 3.6586],\n",
      "        [3.7846, 3.8629, 4.0739, 3.9308, 3.6408],\n",
      "        [3.3869, 3.6070, 3.6513, 3.5317, 3.5152],\n",
      "        [3.4345, 3.6114, 3.7431, 3.5643, 3.5502],\n",
      "        [3.9368, 3.8210, 4.0493, 4.0365, 3.8814],\n",
      "        [3.4277, 3.5076, 3.6857, 3.6174, 3.4829],\n",
      "        [3.4389, 3.5694, 3.6194, 3.6534, 3.4741],\n",
      "        [3.6016, 3.6914, 3.9096, 3.7695, 3.7051],\n",
      "        [3.5165, 3.7232, 3.7035, 3.7048, 3.6119],\n",
      "        [3.6537, 3.7409, 3.8517, 3.7780, 3.7727],\n",
      "        [3.3965, 3.7195, 3.7706, 3.5989, 3.5738],\n",
      "        [3.6077, 3.8202, 3.9871, 3.8238, 3.7571],\n",
      "        [3.4018, 3.5930, 3.7302, 3.5882, 3.5132],\n",
      "        [3.5726, 3.7682, 3.8410, 3.7100, 3.7677],\n",
      "        [3.4585, 3.6839, 3.6909, 3.6280, 3.5756],\n",
      "        [3.5694, 3.8069, 3.9713, 3.9132, 3.6525],\n",
      "        [3.7989, 4.0030, 3.9908, 3.9371, 3.9240],\n",
      "        [3.6947, 3.7756, 3.8714, 3.7521, 3.5176],\n",
      "        [3.6340, 3.9281, 3.8649, 3.7912, 3.7288],\n",
      "        [3.4731, 3.6432, 3.8118, 3.6985, 3.6030],\n",
      "        [3.5605, 3.6538, 3.8843, 3.7272, 3.6826],\n",
      "        [3.6291, 3.7654, 3.7580, 3.7739, 3.6834],\n",
      "        [3.7784, 3.9265, 4.0255, 3.8723, 3.6696],\n",
      "        [3.3584, 3.5086, 3.6627, 3.5281, 3.4346],\n",
      "        [3.5378, 3.7787, 3.8836, 3.7799, 3.7221],\n",
      "        [3.8557, 3.9645, 4.2378, 4.1709, 3.7981],\n",
      "        [3.5339, 3.7393, 3.7034, 3.7328, 3.6106],\n",
      "        [3.4012, 3.8103, 3.6986, 3.4717, 3.6217],\n",
      "        [3.6754, 3.9253, 3.8979, 3.9695, 3.8067],\n",
      "        [3.4415, 3.5591, 3.7245, 3.6229, 3.4934],\n",
      "        [3.3925, 3.6972, 3.7587, 3.5869, 3.5508],\n",
      "        [3.4038, 3.7344, 3.7758, 3.6099, 3.5848],\n",
      "        [3.3886, 3.5393, 3.6717, 3.6377, 3.4957],\n",
      "        [3.7596, 4.0034, 3.9870, 3.7604, 3.8161],\n",
      "        [3.6510, 3.5534, 3.9783, 3.7981, 3.6858],\n",
      "        [3.9127, 3.9901, 4.1813, 4.1564, 3.9134],\n",
      "        [3.5596, 3.6399, 3.8427, 3.6699, 3.6650],\n",
      "        [3.4114, 3.6201, 3.6292, 3.5907, 3.4777],\n",
      "        [3.8407, 3.9406, 4.2224, 4.1531, 3.7759],\n",
      "        [3.4969, 3.7113, 3.7021, 3.6795, 3.5972],\n",
      "        [3.5949, 3.6967, 3.8420, 3.7714, 3.6641],\n",
      "        [3.3537, 3.5836, 3.6293, 3.4917, 3.4987],\n",
      "        [3.5843, 3.8482, 3.8405, 3.7254, 3.7216],\n",
      "        [3.6784, 3.8541, 3.8605, 3.8006, 3.7912],\n",
      "        [3.7054, 3.8446, 4.0332, 3.8170, 3.6189],\n",
      "        [4.0534, 4.1718, 3.8802, 3.9305, 3.7596],\n",
      "        [3.5459, 3.7939, 3.7362, 3.8459, 3.5973],\n",
      "        [3.4064, 3.6619, 3.7856, 3.6142, 3.5499],\n",
      "        [3.7028, 3.8393, 3.9806, 3.8142, 3.7538],\n",
      "        [3.7129, 3.6418, 3.8980, 3.9674, 3.9255],\n",
      "        [3.7044, 4.0192, 4.0079, 3.8798, 3.8147],\n",
      "        [3.6646, 4.0175, 4.0226, 3.8893, 3.9293],\n",
      "        [3.3952, 3.6057, 3.6097, 3.5659, 3.4648],\n",
      "        [3.5763, 3.7957, 3.9341, 3.8704, 3.6735],\n",
      "        [3.7830, 4.0356, 4.1226, 3.9307, 3.6631],\n",
      "        [3.4432, 3.6347, 3.6502, 3.6362, 3.4973],\n",
      "        [3.9393, 3.9963, 4.1205, 4.1282, 3.9611],\n",
      "        [3.3627, 3.6019, 3.6440, 3.5109, 3.5094]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5307, 4.0356, 3.8836, 3.9213, 3.7829],\n",
      "        [3.6070, 3.9270, 3.8844, 3.8180, 3.8276],\n",
      "        [3.4289, 3.5085, 3.6875, 3.6175, 3.4814],\n",
      "        [3.5900, 3.9106, 3.9845, 3.8594, 3.6625],\n",
      "        [3.3145, 3.5391, 3.5993, 3.4393, 3.4468],\n",
      "        [3.4255, 3.6687, 3.7876, 3.6312, 3.5481],\n",
      "        [3.7536, 3.9141, 4.0049, 3.8492, 3.6485],\n",
      "        [3.6897, 3.7428, 3.8890, 3.7421, 3.5831],\n",
      "        [3.5705, 3.6423, 3.8347, 3.7198, 3.6568],\n",
      "        [3.7717, 3.5645, 3.7303, 3.7424, 3.7218],\n",
      "        [3.5380, 3.6360, 3.8277, 3.6904, 3.6184],\n",
      "        [3.8968, 3.8174, 4.0518, 4.3835, 4.1803],\n",
      "        [3.4736, 3.5840, 3.8297, 3.6650, 3.5810],\n",
      "        [3.6338, 3.7156, 3.9575, 3.8415, 3.6676],\n",
      "        [3.4328, 3.5906, 3.6504, 3.6566, 3.4535],\n",
      "        [3.6960, 3.9767, 3.9364, 3.8834, 3.7741],\n",
      "        [3.5344, 3.7960, 3.7455, 3.8345, 3.5933],\n",
      "        [3.3866, 3.6940, 3.7530, 3.5794, 3.5395],\n",
      "        [3.4544, 3.6582, 3.6723, 3.6106, 3.5502],\n",
      "        [3.8582, 3.8599, 3.9607, 3.8993, 3.8902],\n",
      "        [3.5967, 3.9112, 4.0691, 3.9264, 3.7608],\n",
      "        [3.3035, 3.5798, 3.6927, 3.5357, 3.5159],\n",
      "        [3.9493, 3.8895, 4.0912, 4.1165, 3.9029],\n",
      "        [3.4576, 3.6540, 3.7992, 3.5489, 3.6550],\n",
      "        [3.6625, 3.7180, 3.8768, 3.7152, 3.5922],\n",
      "        [3.5379, 3.7470, 3.7107, 3.7412, 3.6212],\n",
      "        [3.6763, 3.7785, 3.7568, 3.8391, 3.7732],\n",
      "        [3.4745, 3.7372, 3.7595, 3.7456, 3.5901],\n",
      "        [3.5755, 3.9177, 3.8146, 3.8766, 3.7294],\n",
      "        [3.5187, 3.5860, 3.8181, 3.6680, 3.5840],\n",
      "        [3.7522, 4.0968, 4.0435, 4.0371, 3.8923],\n",
      "        [3.6464, 3.6860, 3.9886, 3.8660, 3.6527],\n",
      "        [3.4448, 3.6837, 3.8211, 3.6594, 3.5501],\n",
      "        [3.5473, 3.7947, 3.7377, 3.8459, 3.5959],\n",
      "        [3.8948, 3.9897, 3.9750, 3.9823, 3.9781],\n",
      "        [3.6755, 3.9234, 3.8810, 3.8014, 3.7413],\n",
      "        [3.4409, 3.6676, 3.6810, 3.6044, 3.5652],\n",
      "        [3.7253, 3.8999, 4.0572, 3.9591, 3.9272],\n",
      "        [4.0074, 4.1374, 4.1517, 4.2704, 4.0375],\n",
      "        [3.4958, 4.1095, 4.0741, 3.7607, 3.6491],\n",
      "        [3.8382, 3.9046, 4.0468, 3.9942, 3.7132],\n",
      "        [3.4087, 3.8048, 3.8551, 3.6013, 3.6908],\n",
      "        [3.4116, 3.4991, 3.6804, 3.6052, 3.4650],\n",
      "        [3.9358, 3.8473, 4.0933, 4.4232, 4.2181],\n",
      "        [3.7470, 3.7340, 3.8655, 3.7143, 3.6076],\n",
      "        [3.8097, 3.9142, 4.0992, 4.0529, 3.7728],\n",
      "        [4.0339, 4.1323, 4.1418, 4.3280, 4.0670],\n",
      "        [3.9218, 3.8060, 4.0466, 4.4025, 4.1728],\n",
      "        [3.4423, 3.7186, 3.8765, 3.7228, 3.7124],\n",
      "        [3.5028, 3.8496, 3.8753, 3.6797, 3.7292],\n",
      "        [3.7982, 3.9802, 4.1155, 4.1196, 4.1313],\n",
      "        [3.4465, 3.9058, 3.9701, 3.7376, 3.8199],\n",
      "        [3.6750, 3.9238, 3.8982, 3.9682, 3.8015],\n",
      "        [3.6523, 3.7049, 3.8638, 3.6859, 3.6087],\n",
      "        [3.4790, 3.6534, 3.7055, 3.5996, 3.5539],\n",
      "        [3.3573, 3.5051, 3.6402, 3.5004, 3.4708],\n",
      "        [3.5858, 3.9043, 3.9347, 3.7660, 3.5637],\n",
      "        [3.3409, 3.6232, 3.6703, 3.5625, 3.5114],\n",
      "        [3.3983, 3.6945, 3.7628, 3.6002, 3.5540],\n",
      "        [3.2677, 3.8525, 3.8155, 3.6611, 3.4543],\n",
      "        [3.8006, 4.0371, 3.9231, 3.8305, 3.7557],\n",
      "        [3.5363, 3.7946, 3.8671, 3.7300, 3.6747],\n",
      "        [3.4620, 3.6749, 3.6795, 3.6235, 3.5762],\n",
      "        [3.5306, 3.6624, 3.8301, 3.7097, 3.6211]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4268, 3.5111, 3.6910, 3.6134, 3.4740],\n",
      "        [3.5664, 3.5685, 3.7607, 3.6878, 3.7199],\n",
      "        [3.4717, 3.4985, 3.6575, 3.6151, 3.4646],\n",
      "        [3.5149, 3.7157, 3.7032, 3.6843, 3.6114],\n",
      "        [3.4123, 3.9677, 3.9412, 3.7611, 3.6732],\n",
      "        [3.5315, 3.7396, 3.7146, 3.7285, 3.6186],\n",
      "        [3.4690, 3.9356, 3.8756, 3.7851, 3.8023],\n",
      "        [3.3100, 3.5233, 3.5606, 3.5101, 3.4236],\n",
      "        [3.7174, 3.7888, 3.8964, 3.7799, 3.5508],\n",
      "        [3.7666, 3.6073, 3.7332, 3.7153, 3.7761],\n",
      "        [3.4962, 3.6773, 3.7178, 3.5457, 3.5689],\n",
      "        [3.5650, 3.6005, 3.8424, 3.7199, 3.7278],\n",
      "        [3.6709, 4.0558, 4.0371, 3.8935, 3.8804],\n",
      "        [3.4310, 3.9147, 3.7538, 3.6355, 3.7064],\n",
      "        [3.9952, 4.1408, 4.1665, 4.2667, 4.0293],\n",
      "        [3.4991, 3.7125, 3.7052, 3.6808, 3.5941],\n",
      "        [3.6345, 3.7482, 3.8331, 3.7365, 3.6817],\n",
      "        [3.3428, 3.5695, 3.6234, 3.4731, 3.4830],\n",
      "        [3.5818, 3.9033, 3.9795, 3.8633, 3.6551],\n",
      "        [3.9670, 4.1584, 3.9917, 3.8991, 3.8172],\n",
      "        [4.0192, 3.9191, 4.0216, 4.0646, 3.9969],\n",
      "        [3.6220, 3.7723, 3.8777, 3.7619, 3.7783],\n",
      "        [3.8557, 3.9726, 4.2454, 4.1703, 3.7913],\n",
      "        [3.3882, 3.5429, 3.6844, 3.5601, 3.4668],\n",
      "        [3.5256, 3.7301, 3.7100, 3.7243, 3.6165],\n",
      "        [3.4253, 3.6419, 3.6676, 3.5804, 3.5378],\n",
      "        [3.5593, 3.8520, 3.9901, 3.7902, 3.6025],\n",
      "        [3.6865, 3.7414, 3.8077, 3.9243, 3.7675],\n",
      "        [3.6683, 3.9157, 3.9074, 3.8910, 3.7458],\n",
      "        [3.4227, 3.6447, 3.7844, 3.6279, 3.5384],\n",
      "        [3.6831, 4.1103, 4.0536, 3.9262, 3.9140],\n",
      "        [3.5362, 3.7405, 3.7066, 3.7341, 3.6075],\n",
      "        [3.4234, 3.6411, 3.8079, 3.7113, 3.6030],\n",
      "        [3.4243, 3.6454, 3.7714, 3.6303, 3.5283],\n",
      "        [3.5816, 3.6391, 3.8100, 3.6977, 3.6786],\n",
      "        [3.3799, 3.5809, 3.6838, 3.6139, 3.4899],\n",
      "        [3.6666, 3.9009, 4.0192, 3.8500, 3.7260],\n",
      "        [3.7109, 3.9217, 4.0074, 3.8138, 3.6481],\n",
      "        [3.6713, 4.1791, 4.1305, 4.1299, 3.9597],\n",
      "        [3.6337, 3.8847, 3.8604, 3.9234, 3.7472],\n",
      "        [3.6485, 3.7379, 3.8329, 3.7562, 3.6536],\n",
      "        [3.4681, 4.0459, 3.8504, 3.6924, 3.7881],\n",
      "        [3.5004, 3.7094, 3.6953, 3.6939, 3.5862],\n",
      "        [3.4121, 3.6603, 3.6768, 3.5744, 3.5526],\n",
      "        [3.4610, 3.6747, 3.6853, 3.6125, 3.5822],\n",
      "        [3.6855, 3.8844, 3.9650, 3.8337, 3.6283],\n",
      "        [3.5306, 3.7315, 3.7033, 3.7245, 3.6031],\n",
      "        [3.6701, 3.9715, 4.0218, 3.9475, 3.8978],\n",
      "        [3.4252, 3.5864, 3.7413, 3.6182, 3.5269],\n",
      "        [3.4389, 3.7776, 3.9512, 3.8130, 3.5198],\n",
      "        [3.6179, 3.7679, 3.8645, 3.7425, 3.7720],\n",
      "        [3.5410, 3.8622, 4.0096, 3.7927, 3.5919],\n",
      "        [3.5445, 3.7567, 3.7319, 3.7568, 3.6312],\n",
      "        [3.5612, 3.6660, 3.9000, 3.7385, 3.6856],\n",
      "        [3.9242, 4.1595, 4.0281, 3.8959, 3.8548],\n",
      "        [3.4017, 3.6262, 3.6610, 3.5533, 3.5454],\n",
      "        [3.4933, 3.9823, 3.7982, 3.6810, 3.7796],\n",
      "        [3.5817, 4.0912, 4.0232, 4.0456, 3.8372],\n",
      "        [4.0128, 3.9233, 4.1279, 4.1834, 3.9529],\n",
      "        [4.0413, 4.0593, 4.2861, 4.2660, 4.0625],\n",
      "        [3.4795, 3.6928, 3.6878, 3.6542, 3.5755],\n",
      "        [3.3922, 3.7011, 3.7320, 3.6485, 3.5441],\n",
      "        [3.5161, 3.6291, 3.7585, 3.7310, 3.5493],\n",
      "        [3.5483, 3.6116, 3.7287, 3.7695, 3.5462]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5954, 4.0012, 3.8561, 3.7887, 3.8594],\n",
      "        [3.5214, 4.0935, 4.0765, 3.7509, 3.6543],\n",
      "        [3.5491, 3.6380, 3.8462, 3.6965, 3.6200],\n",
      "        [3.7543, 3.6416, 3.9075, 4.0219, 3.9476],\n",
      "        [3.4409, 3.5598, 3.7279, 3.6359, 3.5186],\n",
      "        [3.4679, 3.5725, 3.8243, 3.6548, 3.5694],\n",
      "        [4.0548, 4.1613, 4.2765, 4.1378, 4.0668],\n",
      "        [3.6112, 3.7613, 3.8482, 3.7430, 3.7566],\n",
      "        [3.7084, 3.8469, 4.0382, 3.8193, 3.6141],\n",
      "        [3.5459, 3.7336, 3.7574, 3.7826, 3.6509],\n",
      "        [3.9160, 3.9950, 4.1871, 4.1535, 3.9111],\n",
      "        [3.6812, 3.8531, 3.8715, 3.6964, 3.6872],\n",
      "        [3.3980, 3.6430, 3.7547, 3.5989, 3.5345],\n",
      "        [3.4822, 3.6362, 3.8235, 3.6932, 3.6044],\n",
      "        [3.3449, 3.5740, 3.5697, 3.5050, 3.4289],\n",
      "        [3.4450, 3.8004, 3.7028, 3.4773, 3.5813],\n",
      "        [3.6420, 3.8938, 3.9505, 3.7965, 3.5963],\n",
      "        [3.4026, 3.5714, 3.6835, 3.5678, 3.5091],\n",
      "        [3.2859, 3.5551, 3.6931, 3.5129, 3.5114],\n",
      "        [3.5707, 3.6234, 3.8716, 3.7488, 3.7368],\n",
      "        [3.4424, 3.5369, 3.7105, 3.6293, 3.4919],\n",
      "        [3.5658, 3.6664, 3.8995, 3.6358, 3.7846],\n",
      "        [3.5203, 3.7047, 3.9173, 3.8215, 3.7988],\n",
      "        [3.4408, 3.5703, 3.6155, 3.6556, 3.4395],\n",
      "        [3.7309, 3.7618, 3.8650, 4.0345, 3.8447],\n",
      "        [3.3693, 3.6030, 3.6450, 3.5190, 3.5091],\n",
      "        [3.5241, 3.7359, 3.7148, 3.7230, 3.6104],\n",
      "        [3.5195, 3.6507, 3.8218, 3.6960, 3.6069],\n",
      "        [3.8036, 3.9501, 4.0693, 3.9656, 3.7821],\n",
      "        [3.5368, 3.8529, 3.8692, 3.6455, 3.7099],\n",
      "        [3.4937, 3.9253, 3.9403, 3.7999, 3.7896],\n",
      "        [3.7712, 3.9344, 3.9330, 3.8890, 3.8514],\n",
      "        [3.7552, 4.0192, 3.9274, 3.8130, 3.7459],\n",
      "        [3.5911, 3.8781, 3.8717, 3.7328, 3.6794],\n",
      "        [3.5458, 3.5621, 3.7593, 3.5828, 3.5183],\n",
      "        [3.4643, 3.6794, 3.6800, 3.6291, 3.5630],\n",
      "        [3.4804, 3.6785, 3.7202, 3.6507, 3.6055],\n",
      "        [3.3873, 3.6201, 3.8309, 3.6208, 3.6181],\n",
      "        [3.4709, 4.0413, 3.8500, 3.6908, 3.7812],\n",
      "        [3.5391, 3.5513, 3.7452, 3.5691, 3.5075],\n",
      "        [3.5314, 3.5862, 3.7117, 3.7671, 3.5181],\n",
      "        [3.5958, 3.8849, 3.8776, 3.7502, 3.6715],\n",
      "        [3.3820, 3.6996, 3.7563, 3.5805, 3.5385],\n",
      "        [3.6777, 3.7552, 3.8773, 3.7385, 3.8031],\n",
      "        [3.5195, 3.7251, 3.7081, 3.7068, 3.6072],\n",
      "        [3.5537, 3.7672, 3.7284, 3.7670, 3.6349],\n",
      "        [3.4459, 3.9218, 3.9003, 3.6435, 3.4968],\n",
      "        [3.2696, 3.8536, 3.8180, 3.6632, 3.4513],\n",
      "        [3.5557, 3.8346, 3.8577, 3.7464, 3.6963],\n",
      "        [3.4807, 3.6875, 3.6837, 3.6623, 3.5630],\n",
      "        [3.4713, 3.6126, 3.8225, 3.6905, 3.6713],\n",
      "        [3.6547, 3.9204, 3.9086, 3.9353, 3.7540],\n",
      "        [3.7005, 3.9391, 3.9809, 3.9833, 3.7683],\n",
      "        [3.6995, 3.8405, 4.1470, 3.7655, 3.5974],\n",
      "        [3.6571, 3.8334, 3.9893, 3.7677, 3.5958],\n",
      "        [3.6217, 3.9848, 3.9361, 3.8470, 3.8528],\n",
      "        [3.6940, 4.0106, 4.0244, 3.9185, 3.9013],\n",
      "        [3.5224, 3.8080, 3.9772, 3.8026, 3.6109],\n",
      "        [3.6541, 3.7060, 3.8663, 3.6881, 3.6054],\n",
      "        [3.5887, 4.0437, 3.9359, 3.9310, 3.8397],\n",
      "        [3.3881, 3.6762, 3.7494, 3.5804, 3.5273],\n",
      "        [3.4751, 3.6363, 3.8159, 3.6943, 3.5993],\n",
      "        [3.5452, 3.7575, 3.7334, 3.7575, 3.6296],\n",
      "        [3.3964, 3.6737, 3.7249, 3.6498, 3.5153]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5260, 3.7429, 3.8922, 3.7773, 3.6608],\n",
      "        [3.4835, 3.7041, 3.7064, 3.6419, 3.6183],\n",
      "        [3.5541, 3.7676, 3.7296, 3.7675, 3.6331],\n",
      "        [3.4312, 3.6636, 3.8070, 3.6566, 3.5205],\n",
      "        [3.5335, 3.8619, 3.8745, 3.6263, 3.7175],\n",
      "        [3.5579, 3.6012, 3.8431, 3.7226, 3.7167],\n",
      "        [3.6684, 4.0619, 4.0400, 3.8901, 3.8708],\n",
      "        [3.4869, 3.9008, 3.9173, 3.7026, 3.5684],\n",
      "        [4.0267, 3.9634, 4.0349, 4.0890, 4.0070],\n",
      "        [3.6124, 3.8697, 3.8580, 3.7316, 3.7253],\n",
      "        [3.5199, 3.6512, 3.8229, 3.6965, 3.6051],\n",
      "        [3.4874, 3.6298, 3.8278, 3.6895, 3.6028],\n",
      "        [3.5782, 3.9475, 3.7936, 3.7781, 3.6540],\n",
      "        [3.5716, 3.6461, 3.8830, 3.7267, 3.6756],\n",
      "        [3.5514, 3.7710, 3.7324, 3.7679, 3.6335],\n",
      "        [3.7874, 3.8184, 3.9894, 3.9421, 3.7481],\n",
      "        [3.5334, 3.6476, 3.8268, 3.6916, 3.6095],\n",
      "        [3.4089, 3.5873, 3.7332, 3.6013, 3.5151],\n",
      "        [3.4766, 3.7387, 3.7629, 3.7482, 3.5853],\n",
      "        [3.4057, 3.6601, 3.7848, 3.6111, 3.5382],\n",
      "        [3.6118, 3.7617, 3.8491, 3.7436, 3.7548],\n",
      "        [3.7458, 3.9362, 3.8853, 3.9358, 3.9434],\n",
      "        [3.7994, 3.6765, 3.8651, 3.8046, 3.7514],\n",
      "        [3.5031, 3.7158, 3.7006, 3.6776, 3.5951],\n",
      "        [3.4431, 3.6690, 3.6845, 3.6068, 3.5603],\n",
      "        [3.8783, 3.7682, 3.9477, 4.2671, 3.9937],\n",
      "        [3.4784, 3.9792, 3.9213, 3.8874, 3.7362],\n",
      "        [3.6639, 3.7307, 3.8287, 3.8941, 3.7460],\n",
      "        [3.4038, 3.5938, 3.7296, 3.5876, 3.5048],\n",
      "        [3.6989, 3.7780, 3.8766, 3.7549, 3.5114],\n",
      "        [3.9431, 3.9999, 4.1286, 4.1315, 3.9543],\n",
      "        [3.5402, 3.7483, 3.7155, 3.7588, 3.6211],\n",
      "        [3.5268, 3.6711, 3.7434, 3.7340, 3.5837],\n",
      "        [3.6391, 3.7619, 3.7901, 3.8141, 3.7050],\n",
      "        [3.4201, 3.6463, 3.6697, 3.5800, 3.5347],\n",
      "        [3.7661, 3.8242, 3.9313, 3.9180, 3.9033],\n",
      "        [3.5363, 3.8072, 3.9000, 3.7908, 3.6761],\n",
      "        [3.4724, 4.0091, 3.9410, 3.9279, 3.7404],\n",
      "        [3.8138, 3.9129, 4.1966, 4.1175, 3.7260],\n",
      "        [3.3925, 3.5528, 3.6826, 3.6148, 3.4851],\n",
      "        [3.7299, 3.9789, 4.0130, 3.8893, 3.7660],\n",
      "        [3.4847, 3.7461, 3.8849, 3.6301, 3.7512],\n",
      "        [3.5227, 3.7169, 3.7648, 3.6644, 3.6261],\n",
      "        [3.5704, 3.8648, 3.8516, 3.7354, 3.6365],\n",
      "        [3.3331, 3.5609, 3.6183, 3.4609, 3.4633],\n",
      "        [3.6889, 3.7256, 3.9262, 3.8288, 3.6732],\n",
      "        [3.5343, 3.8110, 3.8867, 3.7437, 3.6460],\n",
      "        [3.6349, 3.8859, 3.8632, 3.9247, 3.7436],\n",
      "        [3.8217, 3.8824, 3.9859, 3.9584, 3.9634],\n",
      "        [3.7044, 3.8424, 4.1572, 3.7652, 3.6024],\n",
      "        [3.3397, 3.5971, 3.6640, 3.5594, 3.4886],\n",
      "        [4.0004, 3.9561, 4.1589, 4.1883, 3.9550],\n",
      "        [3.5371, 3.7505, 3.7188, 3.7431, 3.6178],\n",
      "        [3.6852, 3.7421, 3.8164, 3.9285, 3.7644],\n",
      "        [3.9476, 3.7913, 4.0188, 4.3477, 4.1747],\n",
      "        [3.3701, 3.8326, 3.8521, 3.6892, 3.5102],\n",
      "        [3.4133, 3.6613, 3.6790, 3.5755, 3.5493],\n",
      "        [3.7188, 3.9517, 3.9797, 3.8987, 3.7681],\n",
      "        [3.5819, 3.6833, 3.8413, 3.7363, 3.6553],\n",
      "        [3.6878, 3.7651, 3.8647, 3.7469, 3.5014],\n",
      "        [3.3885, 3.7468, 3.9175, 3.6074, 3.6107],\n",
      "        [3.6355, 4.2144, 4.1094, 4.1301, 3.9443],\n",
      "        [3.3893, 3.5439, 3.6865, 3.5613, 3.4635],\n",
      "        [3.4421, 3.6227, 3.7727, 3.6588, 3.5077]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6258, 4.0155, 4.0361, 3.8477, 3.6812],\n",
      "        [3.6791, 3.9279, 3.9062, 3.9724, 3.7987],\n",
      "        [3.4919, 3.5233, 3.8237, 3.4947, 3.6385],\n",
      "        [3.4840, 3.5113, 3.8164, 3.4675, 3.6366],\n",
      "        [3.8927, 3.8682, 3.9722, 3.9329, 3.8964],\n",
      "        [3.3665, 3.6039, 3.6505, 3.5133, 3.5022],\n",
      "        [3.5422, 3.6475, 3.8983, 3.7448, 3.6549],\n",
      "        [3.5438, 3.7570, 3.7221, 3.7544, 3.6247],\n",
      "        [3.6698, 3.9236, 3.9736, 3.8242, 3.8218],\n",
      "        [3.4946, 3.9838, 3.8025, 3.6827, 3.7752],\n",
      "        [3.6334, 3.7678, 3.7652, 3.7765, 3.6761],\n",
      "        [3.5801, 3.8000, 3.9447, 3.8739, 3.6661],\n",
      "        [3.7228, 3.8963, 3.9882, 3.7717, 3.7599],\n",
      "        [3.3847, 3.6810, 3.7586, 3.5908, 3.5295],\n",
      "        [3.5368, 3.5737, 3.7717, 3.6056, 3.5270],\n",
      "        [3.5734, 3.7006, 3.8378, 3.7098, 3.7756],\n",
      "        [3.9098, 3.8303, 4.0493, 4.0129, 3.8484],\n",
      "        [3.4450, 3.5695, 3.6292, 3.6554, 3.4259],\n",
      "        [3.4510, 3.7747, 3.8543, 3.5958, 3.6630],\n",
      "        [3.4746, 3.6667, 3.8283, 3.7295, 3.5892],\n",
      "        [3.6925, 3.9491, 3.9339, 3.8928, 3.7564],\n",
      "        [3.4786, 3.6305, 3.7547, 3.6016, 3.5850],\n",
      "        [3.5241, 3.7008, 3.8265, 3.7024, 3.7570],\n",
      "        [3.6378, 3.8703, 3.8626, 3.7373, 3.7297],\n",
      "        [3.5457, 3.8508, 3.8707, 3.6608, 3.7071],\n",
      "        [3.6864, 4.0097, 4.0575, 3.9124, 3.7301],\n",
      "        [3.4807, 3.5365, 3.7196, 3.6520, 3.4908],\n",
      "        [3.3666, 3.5961, 3.6402, 3.5076, 3.4934],\n",
      "        [3.7084, 3.7790, 3.8858, 3.7679, 3.5240],\n",
      "        [3.5208, 4.0662, 4.0699, 3.7880, 3.6476],\n",
      "        [3.9105, 3.8399, 4.0641, 4.0797, 3.8499],\n",
      "        [3.6889, 3.7341, 3.9142, 3.8232, 3.6725],\n",
      "        [3.7147, 3.9006, 3.9887, 3.9739, 3.7376],\n",
      "        [3.4338, 3.5926, 3.6537, 3.6572, 3.4456],\n",
      "        [3.5994, 4.0864, 4.0271, 4.0287, 3.8573],\n",
      "        [3.7191, 3.9518, 3.9817, 3.8988, 3.7671],\n",
      "        [3.4767, 3.6863, 3.6930, 3.6311, 3.5837],\n",
      "        [3.5806, 3.6504, 3.8550, 3.7135, 3.6698],\n",
      "        [3.7503, 3.7357, 3.8714, 3.7172, 3.6019],\n",
      "        [3.4832, 3.6336, 3.8251, 3.6937, 3.6015],\n",
      "        [3.4402, 3.7802, 3.9579, 3.8149, 3.5155],\n",
      "        [3.5373, 3.7506, 3.7208, 3.7431, 3.6168],\n",
      "        [3.9526, 3.8261, 3.9530, 3.9783, 3.9387],\n",
      "        [3.4100, 3.5715, 3.6861, 3.5785, 3.5151],\n",
      "        [3.4685, 3.9302, 3.9219, 3.6704, 3.5020],\n",
      "        [3.4464, 3.6474, 3.6875, 3.6578, 3.5230],\n",
      "        [3.4194, 3.5677, 3.7279, 3.6007, 3.4995],\n",
      "        [4.0184, 4.1375, 4.1819, 4.2798, 4.0254],\n",
      "        [3.2757, 3.8525, 3.8196, 3.6570, 3.4491],\n",
      "        [3.6594, 3.6979, 4.0083, 3.8662, 3.6892],\n",
      "        [3.4611, 3.9296, 3.9196, 3.7896, 3.7186],\n",
      "        [3.6296, 3.9290, 3.8636, 3.7921, 3.7093],\n",
      "        [3.4278, 3.7791, 3.9575, 3.6969, 3.6940],\n",
      "        [3.8471, 4.0622, 3.9254, 3.8497, 3.7551],\n",
      "        [3.6163, 4.0373, 3.8687, 3.7960, 3.8921],\n",
      "        [3.6351, 3.6822, 3.8562, 3.6749, 3.5958],\n",
      "        [3.4227, 3.9731, 3.9553, 3.7743, 3.6892],\n",
      "        [3.5517, 3.7710, 3.7344, 3.7679, 3.6325],\n",
      "        [3.4101, 3.5784, 3.7276, 3.5915, 3.5009],\n",
      "        [3.6872, 3.8859, 3.9699, 3.8353, 3.6239],\n",
      "        [3.4398, 3.6406, 3.6789, 3.6427, 3.5192],\n",
      "        [3.5213, 3.5875, 3.8239, 3.6706, 3.5781],\n",
      "        [3.4272, 3.5157, 3.6999, 3.6229, 3.4672],\n",
      "        [3.6491, 3.6876, 3.9945, 3.8689, 3.6466]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4023, 3.6208, 3.6600, 3.5494, 3.5143],\n",
      "        [3.6244, 4.1656, 4.0180, 3.9084, 3.9523],\n",
      "        [3.7547, 4.0990, 4.0521, 4.0405, 3.8858],\n",
      "        [3.6198, 3.7399, 3.8210, 3.7236, 3.6706],\n",
      "        [3.3577, 3.6225, 3.6846, 3.5735, 3.5035],\n",
      "        [3.5544, 3.7674, 3.7331, 3.7673, 3.6318],\n",
      "        [3.4381, 3.5245, 3.7088, 3.6156, 3.4873],\n",
      "        [3.4139, 3.6415, 3.6732, 3.5622, 3.5397],\n",
      "        [3.6058, 3.6934, 3.9186, 3.7719, 3.6971],\n",
      "        [3.4021, 3.7317, 3.8954, 3.6390, 3.6313],\n",
      "        [3.5563, 3.6600, 3.9148, 3.6182, 3.7676],\n",
      "        [3.5801, 3.6495, 3.8680, 3.7393, 3.6675],\n",
      "        [3.5755, 3.6419, 3.8868, 3.7303, 3.6272],\n",
      "        [3.5458, 3.8505, 3.8723, 3.6605, 3.7069],\n",
      "        [3.6847, 4.1120, 4.0602, 3.9275, 3.9092],\n",
      "        [3.4214, 3.4987, 3.6934, 3.6144, 3.4581],\n",
      "        [3.5386, 3.7883, 3.8593, 3.7174, 3.6809],\n",
      "        [3.7109, 4.2205, 4.1073, 3.9687, 4.0426],\n",
      "        [3.4129, 3.6828, 3.7658, 3.6027, 3.5578],\n",
      "        [3.9695, 4.1595, 3.9977, 3.9006, 3.8126],\n",
      "        [3.4652, 3.6795, 3.6845, 3.6293, 3.5600],\n",
      "        [3.4093, 3.5871, 3.7365, 3.6011, 3.5139],\n",
      "        [3.9010, 3.7677, 3.8740, 3.8936, 3.8706],\n",
      "        [3.6583, 4.0828, 4.0490, 3.9095, 3.9330],\n",
      "        [3.3991, 3.7717, 3.9321, 3.6854, 3.6601],\n",
      "        [3.7955, 4.0247, 4.0301, 3.7851, 3.8410],\n",
      "        [3.4425, 3.6225, 3.7760, 3.6586, 3.5064],\n",
      "        [3.3781, 3.6028, 3.6064, 3.5482, 3.4546],\n",
      "        [3.5441, 3.9260, 4.0744, 3.9540, 3.6553],\n",
      "        [3.4841, 3.5109, 3.8180, 3.4672, 3.6363],\n",
      "        [3.6355, 4.0095, 3.8783, 3.8197, 3.8845],\n",
      "        [3.5670, 3.6664, 3.9043, 3.6361, 3.7815],\n",
      "        [3.6822, 3.8535, 3.8762, 3.6970, 3.6842],\n",
      "        [3.7189, 4.0085, 4.0008, 3.8802, 3.8081],\n",
      "        [3.5203, 3.6511, 3.8266, 3.6964, 3.6038],\n",
      "        [3.4181, 3.6258, 3.7656, 3.6159, 3.5058],\n",
      "        [3.6892, 4.0350, 4.0270, 3.8835, 3.7851],\n",
      "        [3.8502, 3.9286, 4.0639, 4.0539, 3.8451],\n",
      "        [3.4896, 3.5785, 3.7528, 3.5292, 3.6090],\n",
      "        [3.6926, 3.9490, 3.9356, 3.8926, 3.7563],\n",
      "        [3.6429, 3.8943, 3.9557, 3.7970, 3.5934],\n",
      "        [3.5508, 3.7420, 3.8567, 3.7263, 3.6994],\n",
      "        [3.5501, 3.6447, 3.8495, 3.6997, 3.6220],\n",
      "        [3.5347, 3.6328, 3.8847, 3.7357, 3.6466],\n",
      "        [3.4694, 4.0472, 3.8564, 3.6938, 3.7832],\n",
      "        [3.4901, 3.6239, 3.8309, 3.6929, 3.6006],\n",
      "        [3.4198, 3.5794, 3.7412, 3.6203, 3.5096],\n",
      "        [3.3461, 3.9950, 3.9359, 3.7412, 3.5773],\n",
      "        [3.4268, 3.5874, 3.7471, 3.6193, 3.5223],\n",
      "        [3.6599, 3.9938, 4.0810, 3.8875, 3.7043],\n",
      "        [3.5723, 3.9518, 4.1321, 3.9421, 3.7224],\n",
      "        [3.4959, 3.6757, 3.7189, 3.6122, 3.5662],\n",
      "        [3.3192, 3.5514, 3.6135, 3.4466, 3.4509],\n",
      "        [3.8258, 3.9871, 4.0025, 3.9274, 3.8821],\n",
      "        [3.4927, 3.8021, 3.9876, 3.8441, 3.5616],\n",
      "        [3.7032, 3.9298, 4.0209, 3.8755, 3.7908],\n",
      "        [3.3192, 3.5514, 3.6135, 3.4466, 3.4509],\n",
      "        [3.3847, 3.5335, 3.6644, 3.6183, 3.4731],\n",
      "        [3.8141, 3.9136, 4.2015, 4.1176, 3.7248],\n",
      "        [3.5761, 3.9080, 3.8130, 3.8733, 3.7183],\n",
      "        [3.7047, 3.7689, 3.8960, 3.7539, 3.8267],\n",
      "        [3.4850, 3.7458, 3.8884, 3.6300, 3.7499],\n",
      "        [3.5310, 3.7441, 3.7247, 3.7270, 3.6179],\n",
      "        [3.4769, 3.6457, 3.8213, 3.7011, 3.5951]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4854, 3.7059, 3.8286, 3.5975, 3.6280],\n",
      "        [3.5304, 3.7674, 3.9322, 3.8142, 3.6405],\n",
      "        [3.6365, 3.8935, 3.9514, 3.7944, 3.5872],\n",
      "        [3.7319, 4.0212, 3.9607, 3.8257, 3.7519],\n",
      "        [3.2675, 3.5380, 3.6916, 3.4928, 3.4920],\n",
      "        [3.4005, 3.6965, 3.7701, 3.6020, 3.5473],\n",
      "        [3.5299, 3.6511, 3.8298, 3.6930, 3.6060],\n",
      "        [3.4896, 3.6173, 3.8344, 3.6858, 3.5961],\n",
      "        [3.6516, 3.9033, 3.8808, 3.9352, 3.7550],\n",
      "        [3.8351, 3.6285, 3.9177, 4.1320, 4.0142],\n",
      "        [3.5333, 3.6484, 3.8316, 3.6910, 3.6077],\n",
      "        [3.5865, 3.9612, 4.0621, 3.9488, 3.6591],\n",
      "        [3.8529, 3.6892, 3.7826, 3.8021, 3.8217],\n",
      "        [3.4968, 4.0781, 4.0736, 3.7601, 3.6366],\n",
      "        [3.7193, 3.7906, 3.9034, 3.7808, 3.5462],\n",
      "        [3.6787, 3.9286, 3.9090, 3.9716, 3.7979],\n",
      "        [3.5299, 3.6511, 3.8298, 3.6930, 3.6060],\n",
      "        [3.4414, 3.5714, 3.6286, 3.6547, 3.4657],\n",
      "        [4.0117, 3.8672, 4.1548, 4.4896, 4.2623],\n",
      "        [3.5142, 3.6344, 3.9274, 3.5376, 3.7478],\n",
      "        [3.4172, 3.9451, 3.9377, 3.7183, 3.8167],\n",
      "        [3.8932, 3.8688, 3.9751, 3.9322, 3.8960],\n",
      "        [4.0281, 4.2576, 3.9204, 3.9251, 3.7479],\n",
      "        [3.4005, 3.8614, 3.8299, 3.5447, 3.6903],\n",
      "        [3.8332, 3.8417, 3.9696, 3.8984, 3.9321],\n",
      "        [3.4458, 3.9266, 3.9180, 3.7812, 3.6945],\n",
      "        [3.6023, 3.6385, 4.0835, 3.7940, 3.7396],\n",
      "        [3.5048, 3.8518, 3.8834, 3.6820, 3.7220],\n",
      "        [3.5803, 4.0930, 3.9965, 4.0221, 3.8489],\n",
      "        [3.4144, 3.7406, 3.9008, 3.6415, 3.6395],\n",
      "        [3.6768, 3.9259, 3.9036, 3.9621, 3.7862],\n",
      "        [3.5492, 3.7270, 3.7590, 3.7701, 3.6365],\n",
      "        [3.3954, 3.7636, 3.8294, 3.6575, 3.5416],\n",
      "        [3.5901, 3.8762, 3.8744, 3.7355, 3.6663],\n",
      "        [3.9907, 3.9519, 4.1549, 4.1986, 3.9573],\n",
      "        [3.8121, 3.9908, 4.1254, 4.1354, 4.1319],\n",
      "        [3.4279, 3.6706, 3.7949, 3.6329, 3.5414],\n",
      "        [3.9797, 4.0066, 4.0089, 4.0929, 4.0344],\n",
      "        [3.5076, 3.9949, 3.8347, 3.7289, 3.8170],\n",
      "        [3.4133, 3.6619, 3.6833, 3.5748, 3.5476],\n",
      "        [3.9277, 4.0323, 4.0743, 4.1704, 3.9578],\n",
      "        [3.6102, 3.7082, 3.9406, 3.8100, 3.6428],\n",
      "        [3.5140, 3.7181, 3.7022, 3.7070, 3.5823],\n",
      "        [3.3188, 3.5523, 3.6144, 3.4461, 3.4504],\n",
      "        [3.2884, 3.8547, 3.8294, 3.6627, 3.4544],\n",
      "        [3.7076, 4.0247, 4.0224, 3.8833, 3.8065],\n",
      "        [3.4270, 3.5221, 3.7041, 3.6288, 3.4799],\n",
      "        [3.6363, 3.7500, 3.8398, 3.7371, 3.6768],\n",
      "        [3.6304, 3.9766, 4.0077, 3.8117, 3.7804],\n",
      "        [3.6163, 3.9350, 4.1075, 3.9544, 3.7739],\n",
      "        [3.9341, 3.9976, 4.1501, 4.1373, 3.9395],\n",
      "        [3.5461, 3.7027, 3.8681, 3.7521, 3.6499],\n",
      "        [3.5343, 3.8121, 3.8917, 3.7433, 3.6445],\n",
      "        [3.5503, 3.7430, 3.8581, 3.7259, 3.6990],\n",
      "        [3.5963, 3.6359, 3.8664, 3.7223, 3.6724],\n",
      "        [3.5326, 3.7414, 3.7219, 3.7291, 3.6134],\n",
      "        [3.5720, 3.9246, 3.9486, 3.7575, 3.5486],\n",
      "        [3.5344, 3.6199, 3.8396, 3.6816, 3.5958],\n",
      "        [3.5180, 3.7700, 3.7309, 3.8108, 3.5666],\n",
      "        [3.3870, 3.8487, 3.8175, 3.5333, 3.6850],\n",
      "        [3.4610, 3.6811, 3.6908, 3.6264, 3.5629],\n",
      "        [3.4531, 3.6676, 3.6864, 3.6173, 3.5664],\n",
      "        [3.7868, 3.6453, 3.9185, 4.0704, 3.9761],\n",
      "        [3.5338, 3.9454, 3.9331, 3.8397, 3.8355]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5149, 3.6392, 3.8522, 3.7189, 3.6743],\n",
      "        [3.5500, 3.6202, 3.8525, 3.6342, 3.6544],\n",
      "        [3.9196, 4.0028, 4.2060, 4.1664, 3.9105],\n",
      "        [3.5771, 3.7715, 3.8514, 3.7114, 3.7590],\n",
      "        [4.0226, 4.1982, 4.0287, 3.9415, 3.8325],\n",
      "        [3.6327, 3.7863, 3.9570, 3.7977, 3.7132],\n",
      "        [3.3347, 3.8381, 3.8430, 3.6747, 3.4884],\n",
      "        [3.4130, 3.5021, 3.6898, 3.6066, 3.4579],\n",
      "        [3.5395, 3.7494, 3.7213, 3.7574, 3.6187],\n",
      "        [3.5326, 3.7692, 3.8857, 3.7670, 3.7191],\n",
      "        [3.4545, 3.5775, 3.7418, 3.6241, 3.5026],\n",
      "        [3.3978, 3.6091, 3.6202, 3.5669, 3.4562],\n",
      "        [3.5199, 4.0086, 3.9536, 3.9613, 3.8143],\n",
      "        [3.3838, 3.6208, 3.6634, 3.5353, 3.5150],\n",
      "        [3.6437, 3.7347, 3.7951, 3.8332, 3.6987],\n",
      "        [3.8731, 3.9505, 4.0858, 4.0685, 3.7670],\n",
      "        [3.6140, 3.5351, 3.9559, 3.7906, 3.7137],\n",
      "        [3.4508, 3.6463, 3.7949, 3.6598, 3.5195],\n",
      "        [3.6987, 3.8425, 4.1548, 3.7646, 3.5928],\n",
      "        [3.4241, 3.7509, 3.7926, 3.6110, 3.5943],\n",
      "        [3.4099, 3.8075, 3.8640, 3.6028, 3.6830],\n",
      "        [3.8130, 3.9156, 4.2048, 4.1166, 3.7239],\n",
      "        [3.8778, 3.7698, 3.9540, 4.2662, 3.9915],\n",
      "        [3.4782, 3.7416, 3.7280, 3.7565, 3.5593],\n",
      "        [3.7412, 3.8774, 4.0207, 3.9131, 3.6820],\n",
      "        [3.5389, 3.5526, 3.7516, 3.5684, 3.5035],\n",
      "        [3.4903, 3.6966, 3.6964, 3.6589, 3.5825],\n",
      "        [3.4173, 3.5904, 3.7510, 3.6093, 3.4863],\n",
      "        [3.5866, 3.6983, 3.8375, 3.7009, 3.7969],\n",
      "        [3.5776, 3.6882, 3.9226, 3.7195, 3.7581],\n",
      "        [3.8021, 4.0080, 4.0043, 3.9395, 3.9153],\n",
      "        [3.6976, 4.0115, 3.9110, 3.7042, 3.7585],\n",
      "        [3.3947, 3.6572, 3.7574, 3.5957, 3.5332],\n",
      "        [3.6024, 3.9272, 3.8530, 3.8977, 3.7374],\n",
      "        [3.5120, 3.7206, 3.7169, 3.6965, 3.6046],\n",
      "        [3.5286, 3.9678, 3.8830, 3.8401, 3.7761],\n",
      "        [3.5663, 3.5869, 3.8266, 3.7069, 3.7123],\n",
      "        [3.3448, 3.5868, 3.5587, 3.5852, 3.4526],\n",
      "        [3.6005, 3.6374, 3.8542, 3.7151, 3.6746],\n",
      "        [3.4274, 3.6775, 3.8293, 3.6484, 3.5259],\n",
      "        [3.4819, 3.6380, 3.8305, 3.6924, 3.6003],\n",
      "        [3.6354, 3.8927, 3.9907, 3.8185, 3.8290],\n",
      "        [3.3775, 3.5097, 3.6934, 3.5833, 3.4844],\n",
      "        [3.6400, 3.6915, 3.8651, 3.6838, 3.5918],\n",
      "        [3.3500, 3.5804, 3.6379, 3.4810, 3.4795],\n",
      "        [3.6967, 3.9749, 3.9553, 3.9016, 3.7697],\n",
      "        [3.7141, 3.9019, 3.9928, 3.9726, 3.7365],\n",
      "        [3.6521, 3.6567, 4.0685, 3.8372, 3.7679],\n",
      "        [3.6781, 3.9291, 3.9102, 3.9709, 3.7973],\n",
      "        [3.4632, 3.6874, 3.6898, 3.6135, 3.6025],\n",
      "        [3.8151, 3.8903, 4.0204, 4.0597, 4.0283],\n",
      "        [3.5412, 3.8249, 3.9204, 3.7575, 3.6347],\n",
      "        [3.5668, 3.8203, 3.7629, 3.8705, 3.6043],\n",
      "        [3.5368, 3.9379, 3.9525, 3.7322, 3.5321],\n",
      "        [3.6289, 3.7688, 3.8777, 3.8757, 3.6747],\n",
      "        [3.5170, 3.6969, 3.7756, 3.6572, 3.6057],\n",
      "        [3.4717, 3.5181, 3.6763, 3.6206, 3.4634],\n",
      "        [3.4262, 3.7287, 3.8587, 3.5785, 3.7230],\n",
      "        [3.8499, 3.7095, 3.8750, 3.8479, 3.8184],\n",
      "        [4.1769, 4.4231, 4.0590, 4.0425, 3.9101],\n",
      "        [4.0759, 4.1939, 4.3255, 4.3331, 3.9037],\n",
      "        [3.8930, 3.8693, 3.9764, 3.9314, 3.8956],\n",
      "        [3.4401, 3.6493, 3.6763, 3.5928, 3.5363],\n",
      "        [3.8799, 3.9959, 4.2099, 4.0314, 4.0391]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4182, 3.5595, 3.7274, 3.6106, 3.4942],\n",
      "        [3.5314, 3.7407, 3.7308, 3.7320, 3.6123],\n",
      "        [3.9895, 3.9531, 4.1575, 4.1972, 3.9560],\n",
      "        [3.5067, 3.6463, 3.8470, 3.7177, 3.6882],\n",
      "        [3.6820, 3.8092, 4.1091, 3.7841, 3.5519],\n",
      "        [3.9214, 4.0074, 4.2091, 4.1668, 3.9167],\n",
      "        [3.5429, 3.7239, 3.7621, 3.7100, 3.6444],\n",
      "        [3.8607, 3.7604, 3.9088, 3.9032, 3.8748],\n",
      "        [3.4628, 3.6777, 3.6899, 3.6235, 3.5682],\n",
      "        [3.7908, 3.9608, 3.9471, 3.8865, 3.8853],\n",
      "        [3.9478, 3.9839, 3.9529, 4.0621, 4.0472],\n",
      "        [3.3875, 3.7099, 3.7659, 3.5806, 3.5381],\n",
      "        [3.8484, 3.9366, 4.2188, 4.1411, 3.7760],\n",
      "        [3.7234, 3.8488, 4.0336, 3.8230, 3.6160],\n",
      "        [3.4443, 3.9252, 3.9104, 3.6420, 3.4927],\n",
      "        [3.8573, 4.0009, 4.1811, 3.9982, 4.0405],\n",
      "        [3.5421, 3.7582, 3.7273, 3.7519, 3.6226],\n",
      "        [3.4009, 3.6020, 3.7399, 3.5994, 3.5087],\n",
      "        [3.5354, 3.6339, 3.7590, 3.7480, 3.5559],\n",
      "        [3.5936, 4.1869, 4.1002, 4.0908, 3.9123],\n",
      "        [3.2810, 3.8576, 3.8306, 3.6565, 3.4544],\n",
      "        [3.3686, 3.6048, 3.6523, 3.5170, 3.5044],\n",
      "        [3.3903, 3.5433, 3.6837, 3.6381, 3.4861],\n",
      "        [4.0351, 4.1374, 4.1539, 4.3302, 4.0585],\n",
      "        [3.4659, 3.6274, 3.8182, 3.6890, 3.5861],\n",
      "        [3.4534, 3.9415, 3.9519, 3.7728, 3.8113],\n",
      "        [3.4671, 4.0492, 3.8600, 3.6917, 3.7814],\n",
      "        [3.6845, 3.8115, 4.1173, 3.7881, 3.5606],\n",
      "        [3.5421, 3.7582, 3.7273, 3.7519, 3.6226],\n",
      "        [3.7258, 3.9048, 4.0712, 3.9609, 3.9190],\n",
      "        [3.6822, 3.8400, 3.8617, 3.8591, 3.7548],\n",
      "        [3.7838, 3.8894, 4.0358, 3.9955, 3.7993],\n",
      "        [3.7534, 3.6436, 3.9160, 4.0206, 3.9429],\n",
      "        [4.0129, 4.0128, 4.2377, 4.2271, 3.9960],\n",
      "        [3.5284, 3.5784, 3.8505, 3.5640, 3.6538],\n",
      "        [3.7852, 3.7134, 3.8992, 4.1298, 3.8884],\n",
      "        [3.6966, 3.9807, 3.9485, 3.8846, 3.7663],\n",
      "        [3.3464, 3.4673, 3.6749, 3.5986, 3.4521],\n",
      "        [3.9723, 3.8636, 4.0339, 4.0117, 3.9461],\n",
      "        [3.3773, 3.7369, 3.9030, 3.6123, 3.6072],\n",
      "        [3.7646, 4.1192, 4.0421, 4.0229, 3.9384],\n",
      "        [3.4583, 4.0273, 4.0216, 3.8024, 3.6276],\n",
      "        [3.4748, 3.6796, 3.6905, 3.6420, 3.5529],\n",
      "        [3.5978, 3.6561, 4.0244, 3.9144, 3.5578],\n",
      "        [3.4609, 3.6772, 3.6944, 3.6112, 3.5758],\n",
      "        [3.3758, 3.6040, 3.6101, 3.5536, 3.4420],\n",
      "        [3.5160, 3.8116, 3.8777, 3.7660, 3.6751],\n",
      "        [3.3098, 3.8503, 3.8349, 3.6601, 3.4640],\n",
      "        [3.8022, 4.0924, 3.9766, 3.9905, 3.9617],\n",
      "        [3.4470, 3.9105, 3.9815, 3.7385, 3.8121],\n",
      "        [3.5263, 3.7361, 3.7250, 3.7250, 3.6099],\n",
      "        [3.6669, 4.0647, 4.0477, 3.8878, 3.8678],\n",
      "        [3.6062, 4.0989, 4.0423, 4.0531, 3.8935],\n",
      "        [3.6266, 3.5966, 3.7535, 3.6647, 3.6567],\n",
      "        [3.7254, 4.0031, 4.0717, 3.9437, 3.7620],\n",
      "        [3.7904, 4.0486, 4.0929, 3.9955, 3.9093],\n",
      "        [3.6690, 3.7127, 3.8788, 3.7759, 3.6430],\n",
      "        [3.4577, 3.9997, 3.9382, 3.9139, 3.7309],\n",
      "        [3.9774, 4.0271, 4.0866, 4.1085, 4.0093],\n",
      "        [3.7219, 3.8153, 4.1638, 4.0667, 3.7043],\n",
      "        [3.4703, 3.6148, 3.8310, 3.6888, 3.6664],\n",
      "        [3.3822, 3.5170, 3.6999, 3.5917, 3.4831],\n",
      "        [3.9720, 4.1422, 4.0590, 4.1244, 4.1289],\n",
      "        [3.8749, 3.9501, 3.9424, 3.9741, 3.9440]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4562, 3.7150, 3.7155, 3.7276, 3.5467],\n",
      "        [3.6201, 3.6587, 4.0890, 3.8094, 3.7566],\n",
      "        [3.8041, 4.0415, 3.9373, 3.8302, 3.7464],\n",
      "        [3.3915, 3.6117, 3.6211, 3.5596, 3.4574],\n",
      "        [3.5571, 3.6004, 3.7123, 3.6192, 3.6426],\n",
      "        [3.5594, 3.6618, 3.9196, 3.6145, 3.7767],\n",
      "        [3.5368, 3.6537, 3.8476, 3.6597, 3.6010],\n",
      "        [3.4344, 3.6510, 3.8199, 3.7001, 3.6014],\n",
      "        [3.4096, 3.5889, 3.7408, 3.5976, 3.5108],\n",
      "        [4.0459, 4.1741, 3.9142, 3.9339, 3.7551],\n",
      "        [3.5311, 3.6653, 3.8473, 3.7128, 3.6080],\n",
      "        [3.5302, 3.7374, 3.7184, 3.7192, 3.5973],\n",
      "        [3.9481, 3.8605, 3.9516, 3.9520, 3.8832],\n",
      "        [3.4873, 3.6178, 3.8038, 3.6405, 3.5681],\n",
      "        [3.4435, 3.5390, 3.7193, 3.6263, 3.4859],\n",
      "        [3.6188, 3.9708, 3.9293, 3.8388, 3.8420],\n",
      "        [3.5684, 3.6960, 3.8507, 3.6007, 3.7057],\n",
      "        [3.5486, 3.8899, 3.7875, 3.8408, 3.6946],\n",
      "        [3.5904, 4.1034, 4.0537, 4.0615, 3.8323],\n",
      "        [3.5371, 3.8097, 3.9097, 3.7875, 3.6721],\n",
      "        [3.5168, 3.6110, 3.8055, 3.6279, 3.5592],\n",
      "        [3.5079, 3.7128, 3.8412, 3.6936, 3.6615],\n",
      "        [3.4326, 3.5889, 3.6590, 3.6536, 3.4523],\n",
      "        [3.5235, 3.8112, 3.9884, 3.8004, 3.6054],\n",
      "        [3.5251, 3.6357, 3.8245, 3.6819, 3.5983],\n",
      "        [3.6020, 3.6376, 3.8565, 3.7128, 3.6727],\n",
      "        [3.5442, 3.7581, 3.7283, 3.7505, 3.6213],\n",
      "        [3.6491, 3.7021, 3.8772, 3.6826, 3.5865],\n",
      "        [3.6751, 3.8884, 4.0272, 3.7755, 3.5992],\n",
      "        [3.5388, 3.6869, 3.8576, 3.7345, 3.6211],\n",
      "        [3.5340, 3.6749, 3.8588, 3.7245, 3.6364],\n",
      "        [3.5325, 3.5882, 3.7207, 3.7641, 3.5123],\n",
      "        [3.9774, 3.8145, 4.0512, 4.3477, 4.1927],\n",
      "        [3.5921, 3.6697, 3.8855, 3.7237, 3.6784],\n",
      "        [3.5661, 3.5669, 3.7680, 3.6791, 3.7099],\n",
      "        [3.3518, 3.5867, 3.6399, 3.4807, 3.4804],\n",
      "        [3.5815, 3.6862, 3.9012, 3.6569, 3.7793],\n",
      "        [3.4258, 3.6489, 3.6810, 3.5720, 3.5347],\n",
      "        [3.6302, 3.7691, 3.8800, 3.8733, 3.6726],\n",
      "        [3.4578, 3.9443, 3.9022, 3.8424, 3.7431],\n",
      "        [3.5393, 3.6093, 3.8463, 3.6719, 3.6014],\n",
      "        [3.8348, 3.8424, 3.9734, 3.8953, 3.9298],\n",
      "        [3.3848, 3.8462, 3.8190, 3.5246, 3.6759],\n",
      "        [3.8211, 3.9634, 4.1593, 4.0093, 3.9865],\n",
      "        [3.4469, 3.9692, 3.9763, 3.7551, 3.8294],\n",
      "        [3.5992, 3.6791, 3.9172, 3.7688, 3.6950],\n",
      "        [3.6031, 3.6394, 4.0871, 3.7909, 3.7368],\n",
      "        [3.7123, 3.8050, 4.0479, 3.8157, 3.5364],\n",
      "        [3.3848, 3.5351, 3.6686, 3.6148, 3.4701],\n",
      "        [3.9899, 3.9210, 4.1120, 4.1483, 3.9487],\n",
      "        [3.7959, 3.8443, 3.9894, 3.9235, 3.9308],\n",
      "        [3.4648, 3.6876, 3.6919, 3.6111, 3.6007],\n",
      "        [3.4733, 3.5011, 3.6675, 3.6128, 3.4569],\n",
      "        [3.4971, 3.5562, 3.8024, 3.6379, 3.5503],\n",
      "        [3.9246, 4.1334, 3.9926, 3.8711, 3.7958],\n",
      "        [3.4964, 3.7540, 3.9348, 3.6811, 3.6207],\n",
      "        [3.5307, 3.6520, 3.8333, 3.6900, 3.6033],\n",
      "        [3.5417, 3.7849, 3.9014, 3.7798, 3.7116],\n",
      "        [3.8960, 4.0150, 4.2349, 4.0437, 4.0591],\n",
      "        [3.5877, 3.7025, 3.8386, 3.6983, 3.7953],\n",
      "        [3.7021, 3.9412, 3.9908, 3.9803, 3.7623],\n",
      "        [3.4039, 3.5731, 3.6920, 3.5644, 3.5032],\n",
      "        [3.5367, 3.8065, 3.9970, 3.9357, 3.5792],\n",
      "        [3.4899, 3.9612, 3.8005, 3.6606, 3.7525]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6818, 3.9266, 3.8947, 3.7998, 3.7305],\n",
      "        [3.9285, 4.1330, 3.9938, 3.8696, 3.7943],\n",
      "        [3.4143, 3.6650, 3.7988, 3.6110, 3.5376],\n",
      "        [4.0034, 4.0657, 4.1822, 4.0187, 3.9764],\n",
      "        [3.6903, 3.7853, 4.0386, 3.7857, 3.4766],\n",
      "        [3.5190, 3.6345, 3.9321, 3.5326, 3.7433],\n",
      "        [3.7162, 3.7815, 3.8950, 3.7652, 3.5211],\n",
      "        [3.8974, 3.9808, 4.0930, 4.1098, 3.8373],\n",
      "        [3.3968, 3.5540, 3.6914, 3.6095, 3.4792],\n",
      "        [3.9310, 4.1621, 4.0403, 3.8924, 3.8456],\n",
      "        [3.3917, 3.5405, 3.7003, 3.5567, 3.4635],\n",
      "        [3.9644, 4.0298, 4.1598, 4.0135, 3.9468],\n",
      "        [3.3950, 3.6734, 3.7638, 3.5901, 3.5311],\n",
      "        [3.8398, 3.6290, 3.9224, 4.1278, 4.0104],\n",
      "        [3.5447, 3.7492, 3.7248, 3.7535, 3.6153],\n",
      "        [3.3949, 3.6229, 3.7428, 3.5732, 3.5027],\n",
      "        [3.5162, 3.7252, 3.7210, 3.6949, 3.5965],\n",
      "        [3.8083, 4.0738, 3.9733, 3.9783, 4.0451],\n",
      "        [3.4246, 3.6474, 3.6785, 3.5746, 3.5291],\n",
      "        [3.4775, 3.6849, 3.6941, 3.6305, 3.5621],\n",
      "        [3.3874, 3.6599, 3.7246, 3.6210, 3.4960],\n",
      "        [3.7231, 3.7532, 3.9669, 3.9179, 3.6304],\n",
      "        [3.4270, 3.6325, 3.7735, 3.6169, 3.5078],\n",
      "        [3.4197, 3.9701, 3.9532, 3.7571, 3.6650],\n",
      "        [3.9811, 3.8714, 4.1641, 4.4515, 4.2545],\n",
      "        [3.5502, 3.7587, 3.7440, 3.7528, 3.6219],\n",
      "        [3.4855, 3.6798, 3.7301, 3.6459, 3.5981],\n",
      "        [3.4760, 3.5517, 3.7367, 3.6304, 3.4887],\n",
      "        [3.8066, 3.9831, 4.1297, 4.1183, 4.1203],\n",
      "        [3.4401, 3.7396, 3.8339, 3.6218, 3.5733],\n",
      "        [3.9883, 4.1046, 4.2243, 4.2600, 3.8363],\n",
      "        [3.4006, 3.6282, 3.6707, 3.5352, 3.5250],\n",
      "        [3.5436, 3.6141, 3.7436, 3.7618, 3.5280],\n",
      "        [3.8028, 4.0516, 4.1008, 4.0006, 3.9100],\n",
      "        [3.4608, 4.0150, 3.9397, 3.7511, 3.5858],\n",
      "        [3.3616, 3.6814, 3.5742, 3.6206, 3.4410],\n",
      "        [3.4911, 3.6174, 3.8050, 3.6390, 3.5666],\n",
      "        [3.4780, 3.6215, 3.8030, 3.6470, 3.5702],\n",
      "        [3.4973, 3.7058, 3.7063, 3.6748, 3.5723],\n",
      "        [3.6852, 3.9251, 3.9066, 3.9562, 3.7793],\n",
      "        [3.5634, 3.6614, 3.9208, 3.6129, 3.7751],\n",
      "        [3.2853, 3.5558, 3.6999, 3.5044, 3.4776],\n",
      "        [3.5910, 3.8711, 3.8713, 3.7147, 3.6751],\n",
      "        [3.4667, 3.6768, 3.6965, 3.6083, 3.5732],\n",
      "        [3.8208, 3.9183, 4.2131, 4.1159, 3.7222],\n",
      "        [3.4919, 3.6310, 3.8373, 3.6844, 3.5971],\n",
      "        [3.5345, 3.8536, 3.8802, 3.6124, 3.7025],\n",
      "        [4.0184, 4.0729, 4.1729, 4.0397, 4.0002],\n",
      "        [3.9288, 3.8091, 4.0608, 4.4013, 4.1621],\n",
      "        [3.7322, 3.9046, 4.0737, 3.9582, 3.9162],\n",
      "        [3.4845, 3.6957, 3.7003, 3.6564, 3.5634],\n",
      "        [3.4254, 3.5860, 3.7538, 3.6083, 3.4809],\n",
      "        [3.4473, 3.5387, 3.7205, 3.6248, 3.4844],\n",
      "        [3.4076, 3.5727, 3.6931, 3.5629, 3.5019],\n",
      "        [3.4467, 3.5727, 3.6336, 3.6506, 3.4623],\n",
      "        [3.5494, 3.5376, 3.7040, 3.6180, 3.6815],\n",
      "        [3.9553, 3.8966, 4.1043, 4.1205, 3.8899],\n",
      "        [3.6834, 3.8879, 3.9473, 3.8607, 3.7900],\n",
      "        [3.6446, 3.7864, 3.8884, 3.9033, 3.6745],\n",
      "        [4.0105, 3.9125, 4.0315, 4.0536, 3.9637],\n",
      "        [3.5635, 3.6641, 3.9076, 3.7323, 3.6722],\n",
      "        [3.5505, 3.8518, 3.8781, 3.6554, 3.7024],\n",
      "        [3.5874, 4.0994, 4.0441, 4.0521, 3.8264],\n",
      "        [3.9537, 4.1633, 4.3059, 4.1022, 4.1659]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6070, 3.6403, 3.8659, 3.7387, 3.6296],\n",
      "        [3.7573, 3.6342, 3.9100, 4.0135, 3.9385],\n",
      "        [3.9847, 4.1361, 3.9212, 3.8885, 3.7585],\n",
      "        [3.5396, 3.7329, 3.7173, 3.7189, 3.5921],\n",
      "        [3.5571, 3.8058, 4.0088, 3.9308, 3.5925],\n",
      "        [3.4205, 3.7898, 3.9613, 3.7061, 3.6683],\n",
      "        [3.5277, 3.7258, 3.7205, 3.7004, 3.5979],\n",
      "        [3.4083, 3.6343, 3.7527, 3.5880, 3.5263],\n",
      "        [3.9181, 3.8414, 4.0744, 4.0739, 3.8438],\n",
      "        [3.5052, 3.6246, 3.7682, 3.7075, 3.5343],\n",
      "        [3.4566, 3.9099, 3.9861, 3.7339, 3.8076],\n",
      "        [3.4357, 3.6770, 3.8347, 3.6428, 3.5207],\n",
      "        [3.6868, 3.8874, 3.9495, 3.8591, 3.7883],\n",
      "        [3.5526, 3.6947, 3.8450, 3.5936, 3.6853],\n",
      "        [3.3832, 3.5250, 3.6644, 3.5186, 3.4693],\n",
      "        [3.3135, 3.6343, 3.8514, 3.5418, 3.5999],\n",
      "        [3.9477, 4.0665, 4.2231, 4.2218, 3.8245],\n",
      "        [3.8275, 3.6417, 3.9231, 4.1034, 4.0048],\n",
      "        [3.4544, 3.6279, 3.8060, 3.6646, 3.5803],\n",
      "        [3.5754, 3.8196, 3.7683, 3.8649, 3.5994],\n",
      "        [3.4723, 3.6304, 3.7864, 3.6641, 3.5199],\n",
      "        [3.6592, 3.7041, 3.8825, 3.6597, 3.4848],\n",
      "        [3.5786, 3.9318, 3.9736, 3.8501, 3.8608],\n",
      "        [3.3556, 3.5811, 3.5843, 3.5070, 3.4216],\n",
      "        [3.7176, 3.8035, 4.1452, 4.0267, 3.6859],\n",
      "        [3.4751, 3.6265, 3.8224, 3.6845, 3.5816],\n",
      "        [3.3961, 3.6182, 3.7413, 3.5727, 3.5006],\n",
      "        [3.6274, 3.7863, 3.8994, 3.7782, 3.7542],\n",
      "        [3.4274, 3.5744, 3.7385, 3.5968, 3.4960],\n",
      "        [3.6698, 3.7050, 3.8837, 3.6727, 3.4947],\n",
      "        [3.4017, 3.7679, 3.8329, 3.6432, 3.5322],\n",
      "        [3.5960, 3.6977, 3.8434, 3.6953, 3.7917],\n",
      "        [4.2185, 4.4522, 4.1028, 4.1039, 3.9015],\n",
      "        [3.7827, 3.9719, 4.1024, 3.8686, 3.6632],\n",
      "        [3.6445, 3.9318, 3.8826, 3.7884, 3.7146],\n",
      "        [3.4240, 3.5629, 3.7122, 3.5825, 3.4854],\n",
      "        [3.9820, 4.1078, 4.2658, 4.2792, 3.9951],\n",
      "        [3.4567, 3.6435, 3.6933, 3.6416, 3.5192],\n",
      "        [3.9597, 4.1007, 4.2133, 4.2541, 3.9975],\n",
      "        [3.9192, 4.0595, 4.0507, 3.9990, 3.9981],\n",
      "        [3.4697, 3.6865, 3.7072, 3.6235, 3.5618],\n",
      "        [3.9322, 3.8086, 4.0630, 4.3997, 4.1603],\n",
      "        [3.5936, 3.6538, 3.8693, 3.7107, 3.6688],\n",
      "        [3.5225, 3.7240, 3.7160, 3.7078, 3.5865],\n",
      "        [3.5269, 3.7312, 3.7259, 3.7009, 3.6015],\n",
      "        [3.8884, 3.9956, 4.2164, 4.0260, 4.0336],\n",
      "        [3.7957, 3.8670, 4.0926, 3.9269, 3.6255],\n",
      "        [3.7021, 3.7224, 3.8838, 3.6604, 3.5292],\n",
      "        [3.6120, 3.6318, 3.8609, 3.7276, 3.5972],\n",
      "        [3.9872, 4.0265, 4.0914, 4.1040, 4.0047],\n",
      "        [3.4547, 3.6858, 3.8347, 3.6548, 3.5375],\n",
      "        [3.6300, 3.6793, 3.9518, 3.8191, 3.6997],\n",
      "        [3.4367, 3.9345, 3.7853, 3.6238, 3.6962],\n",
      "        [3.6000, 4.0347, 4.0572, 3.8253, 3.6511],\n",
      "        [3.9067, 3.8141, 4.0417, 4.0469, 3.8147],\n",
      "        [3.8866, 3.7694, 3.9600, 4.2611, 3.9864],\n",
      "        [3.5861, 3.6512, 3.9188, 3.7589, 3.7009],\n",
      "        [3.9251, 3.9965, 4.2045, 4.1534, 3.8991],\n",
      "        [3.3947, 3.6214, 3.8428, 3.6151, 3.6090],\n",
      "        [3.6059, 3.9940, 4.0626, 3.8930, 3.8658],\n",
      "        [3.8119, 4.0731, 3.9809, 3.9719, 4.0375],\n",
      "        [3.4338, 3.7833, 3.8590, 3.5870, 3.6538],\n",
      "        [3.5294, 3.5846, 3.8343, 3.6618, 3.5704],\n",
      "        [3.5484, 3.9027, 3.7951, 3.5694, 3.6538]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5019, 3.6047, 3.7808, 3.5428, 3.6190],\n",
      "        [3.6256, 3.5339, 3.9630, 3.7842, 3.7066],\n",
      "        [3.9092, 3.8182, 4.0525, 4.0437, 3.8193],\n",
      "        [3.5582, 3.8554, 3.9863, 3.7785, 3.5993],\n",
      "        [3.4352, 3.7497, 3.7995, 3.6041, 3.5872],\n",
      "        [3.7193, 4.0244, 4.0317, 3.8765, 3.7991],\n",
      "        [3.4730, 3.9005, 3.9233, 3.7554, 3.7719],\n",
      "        [3.6095, 3.6774, 3.9221, 3.7645, 3.6899],\n",
      "        [3.5445, 3.8540, 3.8788, 3.6348, 3.6860],\n",
      "        [3.3906, 3.7887, 3.8449, 3.6598, 3.5148],\n",
      "        [3.7286, 3.9737, 4.0071, 3.8830, 3.7600],\n",
      "        [3.4797, 3.6849, 3.6966, 3.6355, 3.5577],\n",
      "        [3.4085, 3.6012, 3.7435, 3.5776, 3.4956],\n",
      "        [3.9191, 3.8231, 4.0758, 4.3839, 4.1722],\n",
      "        [3.6666, 4.0357, 4.0416, 3.8820, 3.9301],\n",
      "        [3.7570, 3.9969, 4.0908, 3.8538, 3.5789],\n",
      "        [3.5001, 3.5947, 3.7934, 3.6236, 3.5436],\n",
      "        [3.4161, 3.6600, 3.7969, 3.6027, 3.5287],\n",
      "        [3.5458, 3.7303, 3.8621, 3.7122, 3.6847],\n",
      "        [3.4394, 3.5952, 3.7588, 3.6089, 3.4837],\n",
      "        [3.4515, 3.5706, 3.6289, 3.6482, 3.4287],\n",
      "        [3.5795, 3.8737, 3.8673, 3.7268, 3.6321],\n",
      "        [3.4483, 3.5269, 3.7199, 3.6238, 3.4834],\n",
      "        [3.6503, 3.9346, 3.9062, 3.9165, 3.7439],\n",
      "        [3.5516, 3.5931, 3.7330, 3.7637, 3.5127],\n",
      "        [3.9807, 4.0018, 4.0316, 4.0781, 4.0136],\n",
      "        [3.6900, 3.9275, 3.9178, 3.9640, 3.7898],\n",
      "        [3.4996, 3.6278, 3.8479, 3.6810, 3.5911],\n",
      "        [3.7533, 4.0863, 4.0396, 4.0127, 3.8691],\n",
      "        [3.4360, 3.5288, 3.7157, 3.6119, 3.4697],\n",
      "        [3.5315, 3.6424, 3.9322, 3.5557, 3.7369],\n",
      "        [3.5637, 3.8420, 3.8751, 3.6776, 3.6856],\n",
      "        [3.4957, 3.8683, 3.8884, 3.7481, 3.8048],\n",
      "        [3.7589, 3.8560, 4.0291, 3.9087, 3.6482],\n",
      "        [3.5995, 3.9316, 4.0276, 3.8779, 3.6360],\n",
      "        [3.4484, 3.6135, 3.7598, 3.5587, 3.5349],\n",
      "        [3.9838, 4.0020, 3.9880, 4.0640, 4.0367],\n",
      "        [3.5849, 3.6433, 3.8511, 3.7143, 3.6429],\n",
      "        [3.5894, 3.7102, 3.9727, 3.7744, 3.6991],\n",
      "        [3.4470, 3.5184, 3.7140, 3.6156, 3.4673],\n",
      "        [3.9460, 3.9976, 4.1597, 4.1302, 3.9317],\n",
      "        [3.6157, 4.0855, 3.9441, 3.9636, 3.8194],\n",
      "        [3.6134, 3.9426, 4.0473, 3.8765, 3.6501],\n",
      "        [3.4111, 3.6958, 3.7780, 3.5945, 3.5397],\n",
      "        [3.6029, 4.0341, 4.0589, 3.8243, 3.6492],\n",
      "        [3.5178, 3.7116, 3.8462, 3.6898, 3.6566],\n",
      "        [3.7356, 3.8477, 4.0396, 3.8175, 3.6096],\n",
      "        [3.7415, 3.6894, 3.8598, 4.0777, 3.8224],\n",
      "        [3.8063, 3.9802, 4.0976, 3.9576, 3.9850],\n",
      "        [3.7590, 3.9118, 4.0394, 4.0029, 3.7351],\n",
      "        [3.4211, 3.8060, 3.8713, 3.5962, 3.6754],\n",
      "        [3.5450, 3.6329, 3.8943, 3.7280, 3.6384],\n",
      "        [3.7618, 4.0043, 4.0141, 3.8819, 3.8401],\n",
      "        [3.7041, 3.7438, 3.9055, 3.7370, 3.5692],\n",
      "        [3.7947, 3.9040, 4.0848, 4.0272, 3.7426],\n",
      "        [3.5835, 3.9243, 3.9575, 3.7504, 3.5414],\n",
      "        [3.4857, 3.7394, 3.7333, 3.7516, 3.5547],\n",
      "        [3.6165, 3.6933, 3.9282, 3.7639, 3.6889],\n",
      "        [3.8111, 3.8969, 4.0549, 4.0051, 3.7869],\n",
      "        [3.6662, 3.8957, 3.9243, 3.8363, 3.7421],\n",
      "        [3.5693, 3.8193, 4.0055, 3.9048, 3.6219],\n",
      "        [3.4334, 3.6920, 3.9125, 3.6673, 3.6729],\n",
      "        [3.5468, 3.6939, 3.8728, 3.7233, 3.6322],\n",
      "        [3.7029, 3.9496, 3.9456, 3.8856, 3.7487]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5966, 3.7265, 3.7938, 3.6624, 3.6404],\n",
      "        [3.3407, 3.5499, 3.6207, 3.4541, 3.4540],\n",
      "        [3.6936, 3.7220, 3.9116, 3.7955, 3.6500],\n",
      "        [3.8053, 4.0645, 4.1674, 3.9427, 3.6806],\n",
      "        [3.4462, 3.9541, 3.8891, 3.8270, 3.7426],\n",
      "        [3.7601, 4.0120, 4.1593, 3.9802, 3.9561],\n",
      "        [3.5792, 3.5665, 3.7605, 3.6658, 3.7002],\n",
      "        [3.4755, 3.8996, 3.9244, 3.7549, 3.7699],\n",
      "        [3.5112, 3.7918, 3.9910, 3.8287, 3.5606],\n",
      "        [3.9326, 4.0704, 4.0711, 4.0141, 3.9962],\n",
      "        [3.4361, 3.5461, 3.7259, 3.5971, 3.4809],\n",
      "        [3.6103, 3.6938, 3.9298, 3.7567, 3.6871],\n",
      "        [3.5328, 3.7186, 3.7145, 3.6993, 3.5757],\n",
      "        [3.7152, 3.9387, 3.9970, 3.9757, 3.7551],\n",
      "        [3.4448, 3.7302, 3.9069, 3.6543, 3.6492],\n",
      "        [3.7326, 3.9580, 4.1081, 3.9160, 3.9149],\n",
      "        [3.5460, 3.7378, 3.7375, 3.7260, 3.6040],\n",
      "        [3.4539, 3.5693, 3.7456, 3.6115, 3.4769],\n",
      "        [3.7295, 3.9294, 4.0245, 3.8940, 3.7606],\n",
      "        [3.6683, 3.7047, 3.8812, 3.6803, 3.5921],\n",
      "        [3.5630, 3.7597, 3.8084, 3.7753, 3.6734],\n",
      "        [3.5942, 3.8002, 3.9584, 3.8663, 3.6566],\n",
      "        [4.0101, 3.9533, 4.1737, 4.1798, 3.9419],\n",
      "        [3.5062, 3.9831, 3.8148, 3.6744, 3.7647],\n",
      "        [3.3638, 3.5843, 3.6454, 3.4759, 3.4737],\n",
      "        [3.6855, 4.0586, 4.0549, 3.8865, 3.8653],\n",
      "        [3.5852, 3.6448, 3.8970, 3.7182, 3.6644],\n",
      "        [3.4832, 3.7668, 3.7069, 3.7143, 3.5368],\n",
      "        [3.8993, 3.9936, 4.0451, 4.1106, 3.8940],\n",
      "        [3.6729, 4.0070, 4.0552, 3.8685, 3.7005],\n",
      "        [3.5200, 3.7428, 3.7679, 3.5643, 3.5332],\n",
      "        [3.4634, 3.7732, 3.8661, 3.5874, 3.6520],\n",
      "        [3.4751, 3.6746, 3.7010, 3.6052, 3.5677],\n",
      "        [4.0298, 4.0106, 4.2455, 4.2213, 3.9874],\n",
      "        [3.8080, 3.8601, 4.0011, 3.9347, 3.9030],\n",
      "        [3.5911, 4.0705, 4.0328, 4.0302, 3.8324],\n",
      "        [3.9054, 3.9973, 4.0857, 3.9892, 3.9075],\n",
      "        [3.9012, 3.9955, 4.0016, 3.9776, 3.9500],\n",
      "        [3.5682, 3.8471, 3.9595, 3.7672, 3.6057],\n",
      "        [3.5788, 3.7095, 3.8238, 3.6799, 3.5248],\n",
      "        [3.5109, 3.6288, 3.8003, 3.5566, 3.6462],\n",
      "        [3.6031, 3.6542, 3.9296, 3.7908, 3.7472],\n",
      "        [3.6885, 3.7630, 3.9065, 3.7522, 3.7752],\n",
      "        [3.8664, 4.0029, 4.0094, 3.9668, 3.9166],\n",
      "        [3.6553, 3.7800, 3.9631, 3.7983, 3.6639],\n",
      "        [3.4574, 3.8161, 3.8688, 3.7138, 3.7819],\n",
      "        [3.3721, 3.5054, 3.6562, 3.4940, 3.4552],\n",
      "        [3.4005, 3.6189, 3.6679, 3.5231, 3.5040],\n",
      "        [3.7187, 3.9407, 3.9803, 3.8921, 3.7481],\n",
      "        [3.6134, 3.9165, 3.8525, 3.8879, 3.7221],\n",
      "        [3.7422, 3.9168, 4.0306, 3.9017, 3.7349],\n",
      "        [3.4230, 3.7404, 3.8032, 3.6066, 3.5686],\n",
      "        [3.3995, 3.6199, 3.8455, 3.6136, 3.6052],\n",
      "        [3.5782, 3.6958, 3.7667, 3.6253, 3.6229],\n",
      "        [3.5590, 3.7586, 3.7443, 3.7538, 3.6195],\n",
      "        [3.6741, 3.8855, 3.9636, 3.7938, 3.5900],\n",
      "        [3.3882, 3.5234, 3.6668, 3.5170, 3.4656],\n",
      "        [3.5443, 3.6546, 3.8488, 3.7024, 3.5975],\n",
      "        [3.4188, 3.6923, 3.7773, 3.5997, 3.5462],\n",
      "        [3.5335, 3.7041, 3.9323, 3.8142, 3.7855],\n",
      "        [3.9232, 3.8400, 4.0777, 4.0726, 3.8401],\n",
      "        [3.7754, 3.9657, 4.1224, 3.9735, 3.9335],\n",
      "        [3.4073, 3.6164, 3.7493, 3.5748, 3.4970],\n",
      "        [3.6339, 3.7389, 3.8314, 3.7151, 3.6610]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5276, 3.6910, 3.7410, 3.6680, 3.6025],\n",
      "        [3.5658, 3.8014, 3.9015, 3.7288, 3.6468],\n",
      "        [3.6318, 3.6350, 3.8573, 3.7090, 3.6720],\n",
      "        [3.6355, 3.9009, 3.9611, 3.7827, 3.5687],\n",
      "        [3.4041, 3.6496, 3.7628, 3.5820, 3.5146],\n",
      "        [3.5603, 3.9257, 4.0879, 3.9474, 3.6446],\n",
      "        [3.5673, 3.8895, 3.7994, 3.8371, 3.6862],\n",
      "        [3.4613, 3.6339, 3.8153, 3.7028, 3.5672],\n",
      "        [3.6335, 3.6252, 3.8425, 3.7040, 3.6740],\n",
      "        [3.7518, 3.9001, 3.9006, 3.8336, 3.8187],\n",
      "        [3.4573, 3.6639, 3.8156, 3.5718, 3.6641],\n",
      "        [3.5495, 3.6169, 3.8500, 3.6741, 3.5851],\n",
      "        [3.5833, 4.0427, 4.0562, 3.7894, 3.6147],\n",
      "        [3.3294, 3.8433, 3.8460, 3.6630, 3.4606],\n",
      "        [3.4784, 4.0233, 4.0297, 3.7959, 3.6181],\n",
      "        [3.8940, 3.7668, 3.9641, 4.2602, 3.9815],\n",
      "        [3.5292, 3.7161, 3.7205, 3.6704, 3.5878],\n",
      "        [3.7427, 3.9802, 3.8999, 3.7002, 3.6575],\n",
      "        [3.4509, 3.6896, 3.7238, 3.6983, 3.5300],\n",
      "        [4.0004, 4.1016, 4.2306, 4.2576, 3.8293],\n",
      "        [3.5046, 3.9025, 3.9843, 3.6940, 3.8579],\n",
      "        [3.6789, 3.7813, 3.9002, 3.7460, 3.8002],\n",
      "        [3.7253, 3.9220, 4.0248, 3.8930, 3.7544],\n",
      "        [3.6218, 3.8080, 3.9555, 3.8560, 3.7000],\n",
      "        [3.5398, 3.6714, 3.8557, 3.7181, 3.6064],\n",
      "        [3.3588, 3.5735, 3.6409, 3.4654, 3.4725],\n",
      "        [3.7209, 3.9063, 3.9220, 3.8016, 3.7171],\n",
      "        [3.4448, 3.7075, 3.8906, 3.6734, 3.6593],\n",
      "        [3.5825, 3.5991, 3.8601, 3.7128, 3.7120],\n",
      "        [3.9928, 4.0953, 4.1708, 4.2223, 3.9354],\n",
      "        [3.6902, 3.8925, 4.0290, 3.8210, 3.7262],\n",
      "        [3.7146, 3.9873, 3.9614, 3.8697, 3.7593],\n",
      "        [3.9417, 4.1300, 4.0518, 4.0858, 4.0891],\n",
      "        [3.7944, 3.7413, 3.8886, 3.7374, 3.6205],\n",
      "        [3.5679, 3.7985, 4.0056, 3.9296, 3.6035],\n",
      "        [3.5349, 3.7230, 3.7242, 3.6989, 3.5929],\n",
      "        [3.4187, 3.5919, 3.7440, 3.5791, 3.4924],\n",
      "        [3.4102, 3.5831, 3.7094, 3.6097, 3.4832],\n",
      "        [3.9525, 3.8798, 3.9806, 3.9509, 3.9017],\n",
      "        [3.5587, 3.7542, 3.7352, 3.7460, 3.6131],\n",
      "        [3.7533, 3.9923, 3.9979, 3.8795, 3.8217],\n",
      "        [3.7266, 4.0604, 4.0268, 3.9840, 3.8439],\n",
      "        [3.5641, 3.6941, 3.9398, 3.8453, 3.8248],\n",
      "        [3.6960, 3.7533, 3.8939, 3.7305, 3.7889],\n",
      "        [3.4359, 3.4970, 3.7046, 3.6065, 3.4471],\n",
      "        [3.5645, 3.7569, 3.7530, 3.7493, 3.6208],\n",
      "        [3.5505, 3.8094, 3.9026, 3.7360, 3.6339],\n",
      "        [3.6029, 3.6587, 3.8972, 3.7423, 3.6739],\n",
      "        [3.4281, 3.6591, 3.6933, 3.5669, 3.5372],\n",
      "        [3.9854, 3.9999, 4.0341, 4.0778, 4.0104],\n",
      "        [3.7823, 3.9015, 4.0651, 4.0120, 3.7348],\n",
      "        [3.5933, 3.9176, 3.8340, 3.8711, 3.7121],\n",
      "        [3.6929, 3.9229, 3.9184, 3.9622, 3.7829],\n",
      "        [3.6061, 3.8698, 3.8808, 3.7212, 3.6609],\n",
      "        [3.7195, 3.8404, 4.1740, 3.7563, 3.5873],\n",
      "        [3.6154, 3.9154, 3.8537, 3.8879, 3.7210],\n",
      "        [3.4907, 3.6348, 3.8323, 3.6868, 3.5849],\n",
      "        [3.4185, 3.6316, 3.6780, 3.5503, 3.5152],\n",
      "        [3.5828, 3.6488, 3.8674, 3.6692, 3.6506],\n",
      "        [3.5163, 3.6465, 3.6105, 3.7308, 3.4659],\n",
      "        [3.7685, 4.0392, 3.9405, 3.9160, 3.9748],\n",
      "        [3.4016, 3.6346, 3.7505, 3.5713, 3.5001],\n",
      "        [3.4759, 3.6176, 3.7802, 3.6785, 3.5077],\n",
      "        [3.4137, 3.6503, 3.7616, 3.5864, 3.5255]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5989, 3.7979, 3.9603, 3.8665, 3.6543],\n",
      "        [3.6176, 3.6384, 3.8778, 3.7272, 3.6340],\n",
      "        [3.4939, 3.7349, 3.7781, 3.7394, 3.5721],\n",
      "        [3.5181, 3.6505, 3.7670, 3.6091, 3.5888],\n",
      "        [3.4636, 3.6348, 3.6955, 3.6368, 3.5190],\n",
      "        [4.0633, 4.0595, 4.3103, 4.2602, 4.0451],\n",
      "        [3.5788, 3.8514, 4.0107, 3.7848, 3.5863],\n",
      "        [3.6525, 3.5945, 3.7689, 3.6550, 3.6498],\n",
      "        [3.5083, 3.6011, 3.7837, 3.5422, 3.6146],\n",
      "        [3.4535, 3.9336, 3.8915, 3.8359, 3.7379],\n",
      "        [3.4317, 3.7362, 3.9122, 3.6334, 3.6269],\n",
      "        [3.6780, 3.7340, 3.8586, 3.7566, 3.6335],\n",
      "        [3.5256, 3.7681, 3.9624, 3.6815, 3.6293],\n",
      "        [3.5520, 3.9421, 3.9453, 3.8318, 3.8238],\n",
      "        [3.4062, 3.5407, 3.7014, 3.5524, 3.4507],\n",
      "        [3.4231, 3.6899, 3.7791, 3.5993, 3.5440],\n",
      "        [3.4045, 3.6582, 3.7629, 3.5745, 3.5060],\n",
      "        [3.4799, 3.8973, 3.9264, 3.7547, 3.7677],\n",
      "        [3.4665, 3.6525, 3.8130, 3.6508, 3.5115],\n",
      "        [3.8023, 3.8850, 4.0460, 3.9897, 3.7888],\n",
      "        [3.5547, 3.6907, 3.7778, 3.7106, 3.5813],\n",
      "        [3.4318, 3.5451, 3.7263, 3.5950, 3.4749],\n",
      "        [3.5887, 3.6213, 3.8891, 3.7441, 3.7241],\n",
      "        [3.6848, 3.8126, 4.0097, 3.7814, 3.5702],\n",
      "        [3.7024, 4.1108, 4.0737, 3.9190, 3.8964],\n",
      "        [3.5614, 4.0507, 4.0244, 3.9998, 3.7768],\n",
      "        [3.7660, 3.8525, 4.0322, 3.9081, 3.6438],\n",
      "        [3.6236, 3.9461, 3.8686, 3.6267, 3.7157],\n",
      "        [3.3498, 3.5577, 3.6327, 3.4519, 3.4505],\n",
      "        [4.0626, 3.8565, 4.1385, 4.4369, 4.2579],\n",
      "        [3.4470, 3.7061, 3.8914, 3.6731, 3.6581],\n",
      "        [3.6609, 3.7561, 3.9743, 3.8095, 3.6772],\n",
      "        [3.5041, 3.9453, 3.9118, 3.7775, 3.8147],\n",
      "        [3.7533, 4.1071, 4.1119, 3.9422, 3.9068],\n",
      "        [3.6856, 3.9008, 4.0388, 3.8431, 3.7086],\n",
      "        [3.6970, 3.9239, 3.9208, 3.9634, 3.7852],\n",
      "        [3.8835, 3.7676, 3.9481, 4.2138, 3.9560],\n",
      "        [3.4123, 3.7636, 3.8372, 3.6414, 3.5260],\n",
      "        [3.6171, 3.9121, 4.0928, 3.9231, 3.7421],\n",
      "        [3.5863, 3.5753, 3.8177, 3.6994, 3.7010],\n",
      "        [3.4810, 3.7093, 3.7286, 3.6811, 3.5230],\n",
      "        [3.8352, 3.9141, 4.2199, 4.1137, 3.7141],\n",
      "        [3.6182, 3.6319, 3.8645, 3.7227, 3.6108],\n",
      "        [3.7276, 3.9207, 4.0256, 3.8928, 3.7532],\n",
      "        [3.6164, 3.6738, 3.9251, 3.7640, 3.6855],\n",
      "        [3.6623, 4.1892, 4.1263, 4.1041, 3.9188],\n",
      "        [3.6181, 3.6521, 4.0335, 3.9096, 3.5478],\n",
      "        [3.8888, 4.0406, 4.2440, 4.0732, 4.0322],\n",
      "        [3.5509, 3.6678, 3.8608, 3.5769, 3.4019],\n",
      "        [3.5885, 3.9280, 3.9783, 3.8484, 3.8547],\n",
      "        [3.3000, 3.8265, 3.8187, 3.6826, 3.4887],\n",
      "        [3.7394, 3.7273, 3.8958, 3.6882, 3.5515],\n",
      "        [3.3742, 3.6190, 3.6965, 3.5651, 3.4915],\n",
      "        [3.4592, 3.6194, 3.7878, 3.6498, 3.4943],\n",
      "        [3.3777, 3.5905, 3.5739, 3.5860, 3.4488],\n",
      "        [3.4725, 3.4745, 3.8043, 3.4230, 3.5986],\n",
      "        [4.0004, 3.8961, 3.9976, 4.0167, 3.9521],\n",
      "        [3.5921, 3.6398, 3.8541, 3.7136, 3.6386],\n",
      "        [4.0751, 4.0496, 4.2971, 4.2529, 4.0382],\n",
      "        [3.5576, 3.7443, 3.7313, 3.7502, 3.6073],\n",
      "        [3.9391, 4.0150, 4.0793, 4.1361, 3.9238],\n",
      "        [3.4429, 3.6430, 3.6846, 3.5733, 3.5248],\n",
      "        [4.2449, 4.4411, 4.1354, 4.0901, 3.9300],\n",
      "        [3.5846, 3.6882, 3.8710, 3.6020, 3.4355]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[4.0370, 4.0072, 4.2484, 4.2219, 3.9837],\n",
      "        [3.6605, 3.6320, 3.8362, 3.7035, 3.6806],\n",
      "        [3.5536, 3.6156, 3.8462, 3.6772, 3.5836],\n",
      "        [3.7010, 3.7510, 3.8957, 3.7303, 3.7864],\n",
      "        [3.6974, 3.9205, 3.9200, 3.9621, 3.7803],\n",
      "        [3.4694, 3.6791, 3.8501, 3.6595, 3.6095],\n",
      "        [3.5840, 3.6513, 3.9061, 3.7214, 3.6610],\n",
      "        [3.5907, 3.7104, 3.8010, 3.6438, 3.5319],\n",
      "        [3.4176, 3.6392, 3.7715, 3.5906, 3.5180],\n",
      "        [3.9874, 4.0562, 4.2106, 4.0302, 3.9339],\n",
      "        [3.4015, 3.6956, 3.7726, 3.5717, 3.5220],\n",
      "        [3.7632, 3.9236, 3.9036, 3.9131, 3.8183],\n",
      "        [3.5922, 3.7760, 3.8597, 3.7462, 3.6997],\n",
      "        [3.8152, 3.8566, 4.0041, 3.9346, 3.8993],\n",
      "        [3.4655, 3.6323, 3.6715, 3.6299, 3.4763],\n",
      "        [3.4447, 3.5246, 3.7194, 3.6114, 3.4642],\n",
      "        [3.6180, 3.6707, 3.9250, 3.7681, 3.6806],\n",
      "        [3.6858, 4.1001, 4.1085, 4.0720, 3.8859],\n",
      "        [3.4588, 3.5375, 3.7318, 3.6154, 3.4781],\n",
      "        [4.0145, 4.1147, 4.1770, 4.2416, 3.9672],\n",
      "        [3.7942, 4.1229, 4.0705, 4.0282, 3.9418],\n",
      "        [3.4335, 3.6352, 3.6844, 3.5519, 3.5276],\n",
      "        [3.7636, 4.1245, 4.1626, 4.0964, 3.9219],\n",
      "        [3.4661, 3.6227, 3.8115, 3.6630, 3.5725],\n",
      "        [3.8342, 4.1015, 4.1869, 4.0889, 3.9380],\n",
      "        [3.4636, 3.5443, 3.7357, 3.6340, 3.4924],\n",
      "        [3.5270, 3.7394, 3.7707, 3.5640, 3.5296],\n",
      "        [3.4077, 3.6723, 3.7659, 3.5718, 3.5108],\n",
      "        [3.8448, 4.1004, 4.2127, 4.1050, 3.9876],\n",
      "        [3.5339, 3.7188, 3.7212, 3.7063, 3.5791],\n",
      "        [3.7057, 3.9197, 3.9235, 3.8454, 3.7105],\n",
      "        [3.5583, 3.6086, 3.7507, 3.7586, 3.5191],\n",
      "        [3.5595, 3.7840, 3.8730, 3.7091, 3.6672],\n",
      "        [3.7410, 3.9009, 4.0054, 3.8185, 3.6016],\n",
      "        [3.6866, 3.7683, 4.0202, 3.7524, 3.4567],\n",
      "        [4.0321, 3.8620, 4.1681, 4.4832, 4.2488],\n",
      "        [3.5415, 3.6504, 3.8530, 3.7060, 3.6043],\n",
      "        [3.4463, 3.5173, 3.7159, 3.6212, 3.4668],\n",
      "        [3.6085, 3.6966, 3.8478, 3.6934, 3.7844],\n",
      "        [4.1060, 4.2651, 4.1093, 3.9951, 3.8861],\n",
      "        [3.5182, 3.6395, 3.7939, 3.7011, 3.5430],\n",
      "        [3.6338, 3.9522, 3.9252, 3.8271, 3.8264],\n",
      "        [3.5536, 3.7954, 4.0010, 3.8438, 3.5884],\n",
      "        [3.6168, 3.6023, 3.8480, 3.7101, 3.5650],\n",
      "        [3.5858, 3.6799, 3.9416, 3.7527, 3.6732],\n",
      "        [3.5559, 3.6896, 3.8768, 3.7229, 3.6263],\n",
      "        [3.6981, 3.7132, 3.8500, 3.9182, 3.7350],\n",
      "        [3.6412, 3.9459, 3.9186, 3.8268, 3.8231],\n",
      "        [3.9594, 4.0356, 4.2049, 4.1543, 3.7397],\n",
      "        [3.5438, 3.7314, 3.7324, 3.7150, 3.5936],\n",
      "        [3.3353, 3.5363, 3.6175, 3.4327, 3.4282],\n",
      "        [3.7983, 3.5609, 3.7504, 3.7373, 3.7053],\n",
      "        [3.7041, 3.8556, 4.0344, 3.9038, 3.8685],\n",
      "        [3.6813, 4.0407, 4.0558, 3.8947, 3.9312],\n",
      "        [3.7001, 3.9214, 3.9226, 3.9588, 3.7827],\n",
      "        [3.7453, 3.8104, 4.1742, 4.0624, 3.6924],\n",
      "        [3.8248, 3.8474, 4.0075, 3.9043, 3.9084],\n",
      "        [3.4868, 3.9224, 3.9343, 3.7867, 3.7172],\n",
      "        [3.3819, 3.5897, 3.6555, 3.4899, 3.4901],\n",
      "        [3.5675, 4.0439, 3.9140, 3.9156, 3.7829],\n",
      "        [3.4802, 3.6154, 3.7817, 3.6783, 3.5054],\n",
      "        [3.4150, 3.7431, 3.6501, 3.6587, 3.4896],\n",
      "        [3.4818, 3.8965, 3.9275, 3.7549, 3.7664],\n",
      "        [3.5005, 3.6501, 3.7247, 3.5935, 3.5348]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.4350, 3.6173, 3.6513, 3.5844, 3.4555],\n",
      "        [3.5428, 4.0911, 4.0978, 3.7439, 3.6357],\n",
      "        [3.6615, 3.7574, 3.8081, 3.8054, 3.6893],\n",
      "        [3.4844, 3.9343, 3.9199, 3.6440, 3.5007],\n",
      "        [3.7418, 3.7785, 3.9179, 3.7715, 3.5435],\n",
      "        [3.4454, 3.6528, 3.6902, 3.5750, 3.5320],\n",
      "        [3.6661, 4.1877, 4.1283, 4.1046, 3.9162],\n",
      "        [4.0894, 4.1777, 3.9073, 3.9415, 3.7350],\n",
      "        [3.7072, 3.9907, 4.0303, 3.8902, 3.8637],\n",
      "        [3.9728, 3.8536, 3.9614, 3.9475, 3.8724],\n",
      "        [3.9199, 3.8141, 4.0542, 4.0500, 3.8118],\n",
      "        [3.8174, 3.9752, 4.1290, 4.0974, 4.1056],\n",
      "        [3.6664, 3.7288, 3.8073, 3.8261, 3.6851],\n",
      "        [3.9163, 4.0088, 4.2484, 4.0390, 4.0463],\n",
      "        [3.5131, 3.8821, 3.8091, 3.5528, 3.6753],\n",
      "        [3.8586, 3.8354, 3.9836, 3.8906, 3.9182],\n",
      "        [3.7075, 3.7376, 3.8346, 3.9202, 3.7485],\n",
      "        [3.7737, 4.0918, 4.0680, 4.0372, 3.8681],\n",
      "        [3.7402, 3.9293, 3.9825, 3.7388, 3.7436],\n",
      "        [3.8083, 3.7071, 3.9104, 4.1246, 3.8753],\n",
      "        [3.3366, 3.8434, 3.8450, 3.6538, 3.4514],\n",
      "        [3.6934, 3.9696, 4.0450, 3.9421, 3.8772],\n",
      "        [3.6552, 4.0052, 3.8935, 3.8115, 3.8690],\n",
      "        [3.4282, 3.5690, 3.7380, 3.5835, 3.4847],\n",
      "        [3.6428, 3.9455, 3.9197, 3.8267, 3.8218],\n",
      "        [3.4426, 3.8116, 3.8879, 3.6087, 3.6799],\n",
      "        [3.4586, 3.5201, 3.7226, 3.6076, 3.4724],\n",
      "        [3.9598, 3.8442, 4.1167, 4.4200, 4.1966],\n",
      "        [3.4496, 3.6492, 3.6923, 3.5741, 3.5327],\n",
      "        [3.5921, 3.9266, 3.9807, 3.8485, 3.8520],\n",
      "        [3.7000, 3.9129, 4.0307, 3.8512, 3.6938],\n",
      "        [3.4455, 3.6425, 3.6901, 3.5669, 3.5233],\n",
      "        [3.5552, 3.6150, 3.8471, 3.6771, 3.5822],\n",
      "        [3.5980, 4.0262, 3.9540, 3.8917, 3.8346],\n",
      "        [3.7471, 3.8098, 4.1751, 4.0625, 3.6910],\n",
      "        [4.0114, 3.9472, 4.1710, 4.1918, 3.9429],\n",
      "        [3.9070, 3.9897, 4.0497, 4.1107, 3.8888],\n",
      "        [3.8401, 4.0266, 3.9285, 3.7688, 3.6928],\n",
      "        [3.7073, 3.9192, 3.9245, 3.8453, 3.7092],\n",
      "        [3.3568, 3.6556, 3.5780, 3.5962, 3.4264],\n",
      "        [3.4511, 3.5244, 3.7227, 3.6148, 3.4706],\n",
      "        [3.8820, 4.0457, 4.2267, 3.9927, 4.0429],\n",
      "        [3.7322, 4.0129, 4.0228, 3.8731, 3.7837],\n",
      "        [3.5904, 3.6516, 3.8725, 3.7309, 3.6662],\n",
      "        [3.5456, 3.6292, 3.8340, 3.6774, 3.5860],\n",
      "        [3.5796, 3.5957, 3.8609, 3.7142, 3.7005],\n",
      "        [3.7406, 3.9101, 4.0134, 3.8215, 3.6129],\n",
      "        [3.5007, 3.6894, 3.7083, 3.6530, 3.5531],\n",
      "        [3.4638, 3.5327, 3.7287, 3.6216, 3.4740],\n",
      "        [3.6817, 3.7324, 3.8605, 3.7567, 3.6308],\n",
      "        [3.6991, 3.9198, 3.9210, 3.9620, 3.7789],\n",
      "        [3.5218, 3.7023, 3.7166, 3.6506, 3.5748],\n",
      "        [3.6760, 3.9181, 3.9281, 3.9281, 3.7378],\n",
      "        [3.4187, 3.6039, 3.7550, 3.5772, 3.4926],\n",
      "        [3.6398, 3.6223, 3.8452, 3.7038, 3.6702],\n",
      "        [3.4080, 3.6568, 3.7647, 3.5744, 3.5035],\n",
      "        [3.4416, 3.7900, 3.8713, 3.5943, 3.6515],\n",
      "        [3.4981, 3.6802, 3.7031, 3.6341, 3.5610],\n",
      "        [3.9571, 3.9929, 4.1647, 4.1304, 3.9245],\n",
      "        [3.7267, 3.9790, 3.9702, 3.8708, 3.7641],\n",
      "        [3.7348, 3.7682, 3.9183, 3.7418, 3.8154],\n",
      "        [3.7313, 3.9194, 4.0276, 3.8930, 3.7505],\n",
      "        [3.7818, 3.9105, 4.0272, 3.8439, 3.6277],\n",
      "        [3.5878, 3.7216, 3.7976, 3.6397, 3.5243]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.6109, 3.6352, 3.8162, 3.6821, 3.6650],\n",
      "        [3.3408, 3.8425, 3.8455, 3.6541, 3.4500],\n",
      "        [3.4477, 3.5413, 3.7300, 3.5972, 3.4746],\n",
      "        [3.4684, 3.7142, 3.8985, 3.7178, 3.6891],\n",
      "        [3.3414, 3.8394, 3.8490, 3.6632, 3.4555],\n",
      "        [3.6950, 4.0055, 3.9011, 3.8484, 3.9007],\n",
      "        [3.7050, 3.8866, 4.0258, 3.8206, 3.7132],\n",
      "        [3.4666, 3.5879, 3.6439, 3.6526, 3.4847],\n",
      "        [3.6929, 3.7887, 3.9785, 3.7966, 3.6976],\n",
      "        [3.7612, 4.1069, 4.0446, 3.8852, 4.0380],\n",
      "        [3.6996, 3.8815, 4.0374, 3.7713, 3.5854],\n",
      "        [3.9199, 4.0854, 3.9438, 3.8572, 3.7449],\n",
      "        [3.7737, 3.9056, 4.0448, 4.0030, 3.7264],\n",
      "        [3.5209, 3.7510, 3.7455, 3.7781, 3.5529],\n",
      "        [3.7030, 3.9188, 3.9215, 3.9624, 3.7774],\n",
      "        [3.4832, 3.9371, 3.9128, 3.8391, 3.7306],\n",
      "        [3.5076, 3.6276, 3.8413, 3.6859, 3.5846],\n",
      "        [3.3901, 3.5905, 3.6553, 3.4988, 3.4777],\n",
      "        [3.7331, 3.9192, 4.0529, 3.8940, 3.7998],\n",
      "        [3.5675, 3.7142, 3.8758, 3.7316, 3.6933],\n",
      "        [3.6788, 3.6494, 4.0808, 3.8305, 3.7515],\n",
      "        [3.3770, 3.4673, 3.6778, 3.6069, 3.4305],\n",
      "        [3.6783, 4.0151, 4.0361, 3.8772, 3.9061],\n",
      "        [3.6079, 3.6223, 3.9074, 3.7606, 3.7228],\n",
      "        [3.5480, 3.7271, 3.7296, 3.7102, 3.5889],\n",
      "        [3.8415, 3.8828, 4.0340, 4.0538, 4.0128],\n",
      "        [3.7570, 4.0154, 3.9756, 3.8191, 3.7352],\n",
      "        [3.5453, 4.0619, 4.0878, 3.7807, 3.6310],\n",
      "        [3.5015, 3.6401, 3.8361, 3.6935, 3.5783],\n",
      "        [4.0430, 4.1326, 4.2018, 4.2727, 4.0076],\n",
      "        [4.0836, 4.2226, 4.0604, 3.9680, 3.8357],\n",
      "        [3.5872, 4.0216, 3.8857, 3.7731, 3.8546],\n",
      "        [3.5413, 3.7134, 3.7230, 3.6924, 3.5867],\n",
      "        [3.4922, 4.0418, 3.8722, 3.6859, 3.7659],\n",
      "        [3.4927, 3.9261, 3.9394, 3.6633, 3.4863],\n",
      "        [3.5416, 3.6246, 3.7786, 3.7241, 3.5287],\n",
      "        [3.6802, 3.9021, 3.8877, 3.8161, 3.7140],\n",
      "        [3.3974, 3.5971, 3.6659, 3.5010, 3.4869],\n",
      "        [3.6154, 4.0023, 3.8620, 3.7782, 3.8432],\n",
      "        [3.8668, 3.9243, 4.0790, 4.0407, 3.8170],\n",
      "        [3.6900, 3.7252, 3.8475, 3.8861, 3.7287],\n",
      "        [4.0108, 4.0979, 4.2340, 4.2587, 3.8237],\n",
      "        [3.4799, 3.9348, 3.9645, 3.7669, 3.7965],\n",
      "        [3.8176, 4.0760, 4.1769, 4.0963, 3.9243],\n",
      "        [3.4051, 3.5762, 3.7034, 3.6065, 3.4691],\n",
      "        [3.4862, 3.6800, 3.7138, 3.6220, 3.5519],\n",
      "        [3.6090, 4.0924, 4.0536, 4.0505, 3.8148],\n",
      "        [3.6336, 3.9272, 3.9082, 3.8131, 3.8053],\n",
      "        [3.5239, 3.6997, 3.7150, 3.6773, 3.5748],\n",
      "        [3.3748, 3.5797, 3.6494, 3.4757, 3.4680],\n",
      "        [3.5409, 3.6319, 3.8646, 3.7124, 3.6584],\n",
      "        [3.9285, 4.1024, 4.0282, 4.0541, 4.0502],\n",
      "        [3.6647, 3.8772, 3.9255, 3.8242, 3.7053],\n",
      "        [3.5864, 3.6976, 3.8570, 3.7068, 3.7358],\n",
      "        [3.8513, 3.8759, 4.0064, 3.9502, 3.9458],\n",
      "        [3.8652, 4.0890, 4.2297, 4.0990, 4.0061],\n",
      "        [3.7227, 4.0044, 3.9240, 3.6977, 3.7428],\n",
      "        [3.7046, 3.9211, 3.9232, 3.9638, 3.7809],\n",
      "        [3.7046, 3.9211, 3.9232, 3.9638, 3.7809],\n",
      "        [3.6469, 3.9829, 3.9572, 3.8398, 3.8332],\n",
      "        [3.5060, 3.6782, 3.8221, 3.6626, 3.6236],\n",
      "        [4.0957, 4.1136, 4.3321, 4.3502, 4.0729],\n",
      "        [3.7046, 3.9211, 3.9232, 3.9638, 3.7809],\n",
      "        [3.8820, 3.6819, 3.7966, 3.7953, 3.8078]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "state shape: (64, 3, 60, 60)\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "q_values: tensor([[3.5202, 3.6972, 3.7152, 3.6718, 3.5588],\n",
      "        [3.5171, 3.8974, 3.9884, 3.6941, 3.8506],\n",
      "        [3.5067, 4.0458, 4.0258, 3.8250, 3.6442],\n",
      "        [3.9085, 3.8044, 4.0729, 4.3638, 4.1563],\n",
      "        [3.5700, 3.6893, 3.8745, 3.7347, 3.6239],\n",
      "        [3.7550, 3.9963, 4.0135, 3.8706, 3.8011],\n",
      "        [3.4700, 3.6519, 3.6934, 3.5947, 3.5273],\n",
      "        [3.8264, 3.8668, 4.0938, 3.9490, 3.6396],\n",
      "        [3.5484, 4.0606, 4.0882, 3.7807, 3.6293],\n",
      "        [3.9009, 3.9812, 3.9982, 3.9662, 3.9313],\n",
      "        [3.6454, 3.6297, 3.8609, 3.7092, 3.6651],\n",
      "        [3.5983, 3.6036, 3.7432, 3.6299, 3.6382],\n",
      "        [3.5737, 3.7520, 3.7487, 3.7540, 3.6113],\n",
      "        [3.4101, 3.6065, 3.6671, 3.5206, 3.4955],\n",
      "        [3.5543, 3.6641, 3.7620, 3.7256, 3.5648],\n",
      "        [3.7552, 3.9588, 4.1208, 3.9176, 3.9985],\n",
      "        [3.6961, 3.8975, 4.0418, 3.8436, 3.7026],\n",
      "        [3.6402, 3.7820, 3.9266, 3.8169, 3.7258],\n",
      "        [3.8247, 3.9728, 4.1300, 4.0980, 4.1023],\n",
      "        [3.4422, 3.6952, 3.7879, 3.5957, 3.5492],\n",
      "        [3.7263, 3.9162, 3.9309, 3.8274, 3.7104],\n",
      "        [3.4405, 3.5992, 3.7354, 3.5768, 3.5019],\n",
      "        [3.4292, 3.7244, 3.9107, 3.6308, 3.6123],\n",
      "        [3.4233, 3.5796, 3.7448, 3.5764, 3.4795],\n",
      "        [3.7941, 4.0284, 3.9654, 3.8287, 3.7384],\n",
      "        [3.6143, 3.6339, 3.8166, 3.6821, 3.6634],\n",
      "        [3.5480, 3.6969, 3.7779, 3.7176, 3.5798],\n",
      "        [3.5013, 3.6126, 3.8124, 3.6441, 3.5560],\n",
      "        [3.4042, 3.5961, 3.6207, 3.5397, 3.4374],\n",
      "        [3.7841, 3.9952, 4.0927, 3.8570, 3.5660],\n",
      "        [3.9367, 3.8157, 4.0819, 4.3857, 4.1621],\n",
      "        [3.6604, 3.9252, 3.8827, 3.8023, 3.7005],\n",
      "        [3.9496, 3.9879, 4.1946, 4.1447, 3.8970],\n",
      "        [3.7768, 3.8487, 4.0349, 3.9087, 3.6379],\n",
      "        [4.0243, 4.1365, 4.1917, 4.2618, 4.0052],\n",
      "        [3.6368, 3.8510, 3.8766, 3.7321, 3.6966],\n",
      "        [3.5282, 3.6468, 3.7697, 3.6095, 3.5833],\n",
      "        [3.6070, 3.6304, 3.8901, 3.7142, 3.6540],\n",
      "        [3.7817, 3.9670, 4.1209, 3.9421, 3.9266],\n",
      "        [3.4965, 3.7628, 3.8970, 3.6607, 3.6680],\n",
      "        [3.4715, 3.5673, 3.7558, 3.6141, 3.4723],\n",
      "        [3.7833, 3.8966, 4.0535, 4.0028, 3.7247],\n",
      "        [3.7069, 3.8798, 3.9574, 3.8586, 3.7762],\n",
      "        [3.7550, 3.9963, 4.0135, 3.8706, 3.8011],\n",
      "        [3.7852, 3.9983, 4.1495, 3.9732, 3.9400],\n",
      "        [3.4564, 3.5881, 3.7642, 3.6082, 3.4741],\n",
      "        [3.7087, 3.7154, 3.9162, 3.7960, 3.6417],\n",
      "        [3.6282, 3.9104, 3.8574, 3.8883, 3.7140],\n",
      "        [3.6311, 3.6337, 4.0883, 3.7836, 3.7129],\n",
      "        [3.9469, 3.9905, 4.2107, 4.1477, 3.8893],\n",
      "        [3.5781, 3.8586, 3.8604, 3.6804, 3.6585],\n",
      "        [3.5201, 3.7284, 3.9901, 3.7388, 3.7315],\n",
      "        [3.6479, 3.9234, 3.8857, 3.9021, 3.7267],\n",
      "        [3.3682, 3.8291, 3.8553, 3.6678, 3.4721],\n",
      "        [3.2546, 3.4934, 3.6792, 3.4626, 3.4425],\n",
      "        [3.4604, 3.5855, 3.6696, 3.6489, 3.4288],\n",
      "        [3.8534, 4.0973, 4.2151, 4.1055, 3.9829],\n",
      "        [3.7310, 3.7358, 3.9710, 3.8545, 3.6794],\n",
      "        [3.5266, 3.6368, 3.7957, 3.7013, 3.5387],\n",
      "        [3.7143, 3.9887, 4.0314, 3.8906, 3.8604],\n",
      "        [3.4333, 3.6863, 3.7818, 3.5994, 3.5385],\n",
      "        [3.4786, 3.6135, 3.6967, 3.6362, 3.5044],\n",
      "        [3.4953, 4.0405, 3.8726, 3.6859, 3.7641],\n",
      "        [3.5171, 3.5870, 3.7989, 3.6236, 3.5332]], grad_fn=<AddmmBackward0>)\n",
      "actions_expanded.shape: torch.Size([64, 1])\n",
      "Shape after pooling: torch.Size([64, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([64, 216])\n",
      "Episode: 3/3, Total Reward: 90\n",
      "Highest Score: 220\n"
     ]
    }
   ],
   "source": [
    "from helper import alt_tab\n",
    "import time\n",
    "import keyboard\n",
    "\n",
    "# Training loop\n",
    "num_episodes = 3\n",
    "agent.q_network.train()\n",
    "agent.epsilon = 1.0\n",
    "episode_scores = []\n",
    "\n",
    "alt_tab() # alt tab to the game\n",
    "for e in range(num_episodes):\n",
    "    # Reset the environment and get the initial state (stacked frames managed by PPLEnv)\n",
    "    state, _ = env.reset()  # Initial state, includes stacked frames\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        # Use the state directly as the stacked frames (already handled by PPLEnv)\n",
    "        action = agent.select_action(state)  # Select action (can be exploration or exploitation)\n",
    "        \n",
    "        # Perform the action in the environment and get the next state and reward\n",
    "        next_state, reward, done, _, _ = env.step(action)\n",
    "\n",
    "        # Store experience in replay \n",
    "        agent.memory.add((state, action, reward, next_state, done))\n",
    "\n",
    "        # Train the agent with experience replay\n",
    "        agent.replay()\n",
    "\n",
    "        # Update the state (stacked frames already handled by PPLEnv)\n",
    "        state = next_state  # Update to the new state (stacked frame after the action)\n",
    "        \n",
    "\n",
    "        # Periodically update target network\n",
    "        if e % agent.update_frequency == 0:\n",
    "            agent.update_target_network()\n",
    "\n",
    "    print(f\"Episode: {e+1}/{num_episodes}, Total Reward: {env.episode_score}\")\n",
    "    episode_scores.append(env.episode_score)\n",
    "env.close()         \n",
    "alt_tab() # alt tab out the game\n",
    "print(f\"Highest Score: {max(episode_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "torch.save(agent.q_network.state_dict(), \"dqn_model-v3_lv8_f2_1150.pth\")\n",
    "print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaan\\AppData\\Local\\Temp\\ipykernel_2156\\2897191925.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  agent.q_network.load_state_dict(torch.load(\"dqn_model-v3_lv8_f2_160.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.q_network = DQNCNN(action_size=ACTION_SIZE, channels=3)\n",
    "agent.q_network.load_state_dict(torch.load(\"dqn_model-v3_lv8_f2_160.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Test Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Shape after pooling: torch.Size([1, 3, 12, 6])\n",
      "Shape after flattening: torch.Size([1, 216])\n",
      "Test Episode: 1/1, Total Reward: 0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import keyboard\n",
    "from helper import alt_tab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Test loop\n",
    "num_test_episodes = 1  # Number of test episodes\n",
    "alt_tab()  # Bring the game window to the foreground\n",
    "\n",
    "# Set agent to evaluation mode\n",
    "agent.q_network.eval()\n",
    "agent.epsilon = 0.0  # Ensure no exploration during testing (greedy policy)\n",
    "\n",
    "for e in range(num_test_episodes):\n",
    "    # Reset the environment and get the initial state\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        # Select the best action based on the current policy\n",
    "        action = agent.select_action(state, explore=False)\n",
    "        \n",
    "        # Perform the action in the environment and get the next state and reward\n",
    "        next_state, reward, done, _, _ = env.step(action)\n",
    "        \n",
    "        # Update the state\n",
    "        state = next_state\n",
    "    \n",
    "    print(f\"Test Episode: {e+1}/{num_test_episodes}, Total Reward: {env.episode_score}\")\n",
    "\n",
    "env.close()\n",
    "alt_tab()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "Reward +1 for surviving a frame\n",
    "- on average suvrives for 10 seconds without training\n",
    "- on average survives for 30 seconds after some  (500 eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You are entering the kitchen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=455x800>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.screenshot_history[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessed Image (Agent Input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=60x60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helper import tensor_to_pil\n",
    "\n",
    "tensor_to_pil(env.preprocessed_screenshot_history[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA88AAAJOCAYAAACJEDUKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABi20lEQVR4nO3deZgmZWHv/V899ay9T8/09KzMBsOwI6AoKpssCqgYlyMqgYhoPGjiCXiSmKOI+qox0RePWyTHLdFoBNwRIyhGEWSTfRtg9q17el+frareP3xnDs0Av5vJaKN+P9fldU6GL1V3Vd1V1ffzMDNRlmWZAAAAAADAU8rN9gAAAAAAAHi2Y/EMAAAAAIDB4hkAAAAAAIPFMwAAAAAABotnAAAAAAAMFs8AAAAAABgsngEAAAAAMFg8AwAAAABgsHgGAAAAAMBg8Qz8AXn/+9+vKIr26t/98pe/rCiKtGHDhn07qMfZsGGDoijSl7/85d/aPgAAwL5x/vnna/ny5ft0m8uXL9f555+/T7cJ/K6weAaeBe6//3696U1v0uLFi1UqlbRo0SK98Y1v1P333z/bQ5sVP/vZzxRFka666qrZHgoAALNu1wfcu/5XLpe1evVqveMd71BfX99sD++34vHH+/j/LViw4Leyv6mpKb3//e/Xz372s9/K9v+rdh3/W97ylif953/3d3+3uxkYGPgdj+6PR362BwD8sfvWt76lc845R93d3brgggu0YsUKbdiwQV/4whd01VVX6Rvf+IZe9apXBW3rf/2v/6W/+Zu/2atxnHvuuXr961+vUqm0V/8+AAD47frABz6gFStWqFqt6sYbb9TnPvc5/fCHP9R9992nlpaW2R7ePnfqqafqT//0T2f8WqVS+a3sa2pqSpdddpkk6cQTT/yt7OO/qlwu6+qrr9ZnP/tZFYvFGf/s61//usrlsqrV6iyN7o8Di2dgFj322GM699xztXLlSv385z9XT0/P7n/2l3/5l3rxi1+sc889V/fcc49Wrlz5lNuZnJxUa2ur8vm88vm9u63jOFYcx3v17wIAgN++l73sZTrmmGMkSW95y1s0d+5cfeITn9B3v/tdnXPOObM8un1v9erVetOb3jTbw/gvaTabStN0j8Xu3njpS1+q733ve7r22mv1yle+cvev33TTTVq/fr1e/epX6+qrr/4v7wdPjf9sG5hF//AP/6CpqSldccUVMxbOkjRv3jx9/vOf1+TkpD72sY/t/vVdv6/5gQce0Bve8AbNmTNHL3rRi2b8s8ebnp7WX/zFX2jevHlqb2/XK17xCm3dulVRFOn973//7u7Jfs/z8uXLddZZZ+nGG2/U8573PJXLZa1cuVL/8i//MmMfQ0NDuuSSS3TYYYepra1NHR0detnLXqa77757H52p/3tsa9eu1Zve9CZ1dnaqp6dH733ve5VlmTZv3qxXvvKV6ujo0IIFC/Txj398xr9fr9f1vve9T0cffbQ6OzvV2tqqF7/4xbrhhhv22Nfg4KDOPfdcdXR0qKurS+edd57uvvvuJ/392g899JBe85rXqLu7W+VyWcccc4y+973v7bPjBgDgqZx88smSpPXr10v6zULtgx/8oFatWqVSqaTly5frPe95j2q12h7/7mc/+1kdcsghu3+72EUXXaSRkRG7zzRNdfnll+uQQw5RuVxWb2+v3va2t2l4eHhGl2WZPvShD2nJkiVqaWnRSSedtM9/O9rWrVv15je/Wb29vSqVSjrkkEP0xS9+cUYT8v7fsGHD7p/DLrvsst3/+fOun5NOPPHEJ/02+om/J3zXn+3yj//4j7r88st3X4cHHnhA0n/9Z4bFixfr+OOP17/927/N+PWvfe1rOuyww3TooYfu8e/84he/0Gtf+1rtt99+KpVKWrp0qf7H//gfmp6e3uNY2tratG7dOp1++ulqbW3VokWL9IEPfEBZlgWP8Q8d3zwDs+j73/++li9frhe/+MVP+s+PP/54LV++XNdcc80e/+y1r32tDjjgAH34wx9+2ofa+eefr29+85s699xz9fznP1//+Z//qTPPPDN4jI8++qhe85rX6IILLtB5552nL37xizr//PN19NFH65BDDpEkrVu3Tt/5znf02te+VitWrFBfX58+//nP64QTTtADDzygRYsWBe/P+W//7b/poIMO0kc/+lFdc801+tCHPqTu7m59/vOf18knn6y///u/19e+9jVdcskleu5zn6vjjz9ekjQ2Nqb/83/+j8455xxdeOGFGh8f1xe+8AWdfvrpuvXWW3XkkUdK+s0PBS9/+ct166236u1vf7vWrFmj7373uzrvvPP2GMv999+vF77whVq8eLH+5m/+Rq2trfrmN7+ps88+W1dffXXwf24PAMDeeOyxxyRJc+fOlfSbb6O/8pWv6DWveY0uvvhi3XLLLfrIRz6iBx98UN/+9rd3/3vvf//7ddlll+mUU07R29/+dj388MP63Oc+p9tuu02//OUvVSgUnnKfb3vb2/TlL39Zf/Znf6a/+Iu/0Pr16/XpT39ad95554x/933ve58+9KEP6YwzztAZZ5yhX//61zrttNNUr9eDj69are7x+3fb29tVKpXU19en5z//+YqiSO94xzvU09Oja6+9VhdccIHGxsb0rne9S1LY+7+np0ef+9zn9Pa3v12vetWr9Cd/8ieSpMMPPzx4rI/3pS99SdVqVW9961tVKpXU3d29z35meMMb3qC//Mu/1MTEhNra2tRsNnXllVfqr/7qr570P9m+8sorNTU1pbe//e2aO3eubr31Vn3qU5/Sli1bdOWVV85okyTRS1/6Uj3/+c/Xxz72Mf3oRz/SpZdeqmazqQ984AN7dS7+4GQAZsXIyEgmKXvlK1/5tN0rXvGKTFI2NjaWZVmWXXrppZmk7Jxzztmj3fXPdrnjjjsySdm73vWuGd3555+fScouvfTS3b/2pS99KZOUrV+/fvevLVu2LJOU/fznP9/9a/39/VmpVMouvvji3b9WrVazJElm7GP9+vVZqVTKPvCBD8z4NUnZl770pac95htuuCGTlF155ZV7HNtb3/rW3b/WbDazJUuWZFEUZR/96Ed3//rw8HBWqVSy8847b0Zbq9Vm7Gd4eDjr7e3N3vzmN+/+tauvvjqTlF1++eW7fy1Jkuzkk0/eY+wveclLssMOOyyrVqu7fy1N0+y4447LDjjggKc9RgAAQu16R19//fXZzp07s82bN2ff+MY3srlz52aVSiXbsmVLdtddd2WSsre85S0z/t1LLrkkk5T99Kc/zbLsN+/xYrGYnXbaaTPe3Z/+9KczSdkXv/jF3b923nnnZcuWLdv9f//iF7/IJGVf+9rXZuzjRz/60Yxf37WPM888M0vTdHf3nve8J5M04/38VCQ96f92vYcvuOCCbOHChdnAwMCMf+/1r3991tnZmU1NTWVZFv7+37lz5x4/G+1ywgknZCeccMIev/7E87Pr55yOjo6sv79/Rvtf/ZlBUnbRRRdlQ0NDWbFYzP71X/81y7Isu+aaa7IoirINGzbs/llp586du/+9Xefh8T7ykY9kURRlGzdunHEskrJ3vvOdM8Z35plnZsViccY2/5jxn20Ds2R8fFzSbz5BfTq7/vnY2NiMX//zP/9zu48f/ehHkqT//t//+4xff+c73xk8zoMPPnjGN+M9PT068MADtW7dut2/ViqVlMv95nGSJIkGBwfV1tamAw88UL/+9a+D9xXi8X/KZBzHOuaYY5RlmS644ILdv97V1bXHGOM43v37jdI01dDQkJrNpo455pgZY/zRj36kQqGgCy+8cPev5XI5XXTRRTPGMTQ0pJ/+9Kd63etep/HxcQ0MDGhgYECDg4M6/fTT9cgjj2jr1q379NgBAH/cTjnlFPX09Gjp0qV6/etfr7a2Nn3729/W4sWL9cMf/lCS9Fd/9Vcz/p2LL75Yknb/V2zXX3+96vW63vWud+1+d0vShRdeqI6Ojif9r912ufLKK9XZ2alTTz1193tvYGBARx99tNra2nb/p9C79vHOd75zxm8n2/VtcKhXvvKVuu6662b87/TTT1eWZbr66qv18pe/XFmWzRjL6aefrtHR0d3v9tD3/7706le/esZvx9uXPzPMmTNHL33pS/X1r39dkvRv//ZvOu6447Rs2bIn7R//B6xNTk5qYGBAxx13nLIs05133rlH/453vGP3/3/Xt/r1el3XX3990Pj+0PGfbQOzZNeieNci+qk81SJ7xYoVdh8bN25ULpfbo91///2Dx7nffvvt8Wtz5syZ8Xub0jTVJz/5SX32s5/V+vXrlSTJ7n+26z8l21eeOJ7Ozk6Vy2XNmzdvj18fHByc8Wtf+cpX9PGPf1wPPfSQGo3G7l9//PnZuHGjFi5cuMefWvrEc/boo48qyzK9973v1Xvf+94nHWt/f78WL14cfnAAADyNz3zmM1q9erXy+bx6e3t14IEH7l4A73rnP/F9tWDBAnV1dWnjxo27O0k68MADZ3TFYlErV67c/c+fzCOPPKLR0VHNnz//Sf95f3//jH0ccMABM/55T0+P5syZE3q4WrJkiU455ZQn3c/IyIiuuOIKXXHFFU87Fins/b8vPXG7+/pnhje84Q0699xztWnTJn3nO9+Z8WfjPNGmTZv0vve9T9/73vf2+H3po6OjM/7vXC63xx9Qu3r1akma8Wfi/DFj8QzMks7OTi1cuFD33HPP03b33HOPFi9erI6Ojhm//tv6qxqe6Kn+BO7scb/P+sMf/rDe+9736s1vfrM++MEPqru7W7lcTu9617uUpulvfTwhY/zqV7+q888/X2effbbe/e53a/78+YrjWB/5yEd2/56xZ2LXcV1yySU6/fTTn7R5Jh9SAADgPO95z9v9p20/lSf+waH7Upqmmj9/vr72ta896T9/4h9++tschyS96U1vetI/k0T6v79feV+8/6MoetI/X+bxXxY83hN/RtvXPzO84hWvUKlU0nnnnadarabXve51T9olSaJTTz1VQ0ND+uu//mutWbNGra2t2rp1q84///x9/jPaHwMWz8AsOuuss/TP//zPuvHGG3f/idmP94tf/EIbNmzQ2972tr3a/rJly5SmqdavXz/j099HH310r8f8ZK666iqddNJJ+sIXvjDj10dGRvb4Rni2XHXVVVq5cqW+9a1vzfjB4tJLL53RLVu2TDfccIOmpqZmfPv8xHO265PZQqHwpJ+KAwDwu7Trnf/II4/ooIMO2v3rfX19GhkZ2f2f9e76fx9++OEZ3zLW63WtX7/+ad9pq1at0vXXX68XvvCFT/sh/q59PPLIIzP2sXPnzj2+/dwbPT09am9vV5Ik9h0c+v5/ug8d5syZM+O3gu3ydN/SP96+/pmhUqno7LPP1le/+lW97GUve8qfte69916tXbtWX/nKV2b8fdnXXXfdk/ZpmmrdunW7v22WpLVr10rSjD9V/I8Zv+cZmEXvfve7ValU9La3vW2P/8R4aGhIf/7nf66Wlha9+93v3qvt7/p087Of/eyMX//Upz61dwN+CnEc7/GJ7JVXXvms+j2/u76dfvw4b7nlFt18880zutNPP12NRkP//M//vPvX0jTVZz7zmRnd/PnzdeKJJ+rzn/+8tm/fvsf+du7cuS+HDwDA0zrjjDMkSZdffvmMX//EJz4hSbv/po1TTjlFxWJR//t//+8Z78QvfOELGh0dfdq/keN1r3udkiTRBz/4wT3+WbPZ3P1XXZ1yyikqFAr61Kc+NWMfTxzb3orjePffaXzfffft8c8f/w4Off/v+sD8yf66rlWrVumhhx6asd27775bv/zlL4PG+9v4meGSSy7RpZde+pT/Gbj05MeeZZk++clPPuW/8+lPf3pG++lPf1qFQkEveclLnvEY/xDxzTMwiw444AB95Stf0Rvf+EYddthhuuCCC7RixQpt2LBBX/jCFzQwMKCvf/3rWrVq1V5t/+ijj9arX/1qXX755RocHNz9V1Xt+hRxX/2nXWeddZY+8IEP6M/+7M903HHH6d5779XXvva1PX7fzGw666yz9K1vfUuvetWrdOaZZ2r9+vX6p3/6Jx188MGamJjY3Z199tl63vOep4svvliPPvqo1qxZo+9973saGhqSNPOcfeYzn9GLXvQiHXbYYbrwwgu1cuVK9fX16eabb9aWLVv26d9zDQDA0zniiCN03nnn6YorrtDIyIhOOOEE3XrrrfrKV76is88+WyeddJKk33xr+7d/+7e67LLL9NKXvlSveMUr9PDDD+uzn/2snvvc5+pNb3rTU+7jhBNO0Nve9jZ95CMf0V133aXTTjtNhUJBjzzyiK688kp98pOf1Gte8xr19PTokksu0Uc+8hGdddZZOuOMM3TnnXfq2muv3Wf/RdpHP/pR3XDDDTr22GN14YUX6uCDD9bQ0JB+/etf6/rrr9/93g59/1cqFR188MH693//d61evVrd3d069NBDdeihh+rNb36zPvGJT+j000/XBRdcoP7+fv3TP/2TDjnkkD3+QNensq9/ZjjiiCN0xBFHPG2zZs0arVq1Spdccom2bt2qjo4OXX311U/57X+5XNaPfvQjnXfeeTr22GN17bXX6pprrtF73vOe39l/kv+s9zv/870B7OGee+7JzjnnnGzhwoVZoVDIFixYkJ1zzjnZvffeu0f7ZH8NwRP/2eNNTk5mF110Udbd3Z21tbVlZ599dvbwww9nkmb89U5P9VdVnXnmmXvs54l/ZUO1Ws0uvvjibOHChVmlUsle+MIXZjfffPMe3b74q6qeeNznnXde1tra+qRjPOSQQ3b/32maZh/+8IezZcuWZaVSKXvOc56T/eAHP9jjr5nIst/8dRVveMMbsvb29qyzszM7//zzs1/+8peZpOwb3/jGjPaxxx7L/vRP/zRbsGBBVigUssWLF2dnnXVWdtVVVz3tMQIAEGrXO/q222572q7RaGSXXXZZtmLFiqxQKGRLly7N/vZv/3bGX4+0y6c//elszZo1WaFQyHp7e7O3v/3t2fDw8Izmyd6RWZZlV1xxRXb00UdnlUola29vzw477LDsf/7P/5lt27Ztd5MkSXbZZZft/tngxBNPzO67775s2bJlwX9V1UUXXfS0TV9fX3bRRRdlS5cu3f3z00te8pLsiiuu2N08k/f/TTfdlB199NFZsVjc46+t+upXv5qtXLkyKxaL2ZFHHpn9x3/8x1P+VVX/8A//8KTj/a/8zBByPp7sZ6UHHnggO+WUU7K2trZs3rx52YUXXpjdfffde/w8tuvnqcceeyw77bTTspaWlqy3tze79NJL9/jrSP+YRVn2JL/7HcAftLvuukvPec5z9NWvflVvfOMbZ3s4vxe+853v6FWvepVuvPFGvfCFL5zt4QAAAOwz559/vq666qoZ38ZjT/yeZ+AP3PT09B6/dvnllyuXy+n444+fhRE9+z3xnCVJok996lPq6OjQUUcdNUujAgAAwGzi9zwDf+A+9rGP6Y477tBJJ52kfD6va6+9Vtdee63e+ta3aunSpbM9vGeld77znZqentYLXvAC1Wo1fetb39JNN92kD3/4w7+zvyIMAAAAzy4snoE/cMcdd5yuu+46ffCDH9TExIT2228/vf/979ff/d3fzfbQnrVOPvlkffzjH9cPfvADVatV7b///vrUpz6ld7zjHbM9NAAAAMwSfs8zAAAAAAAGv+cZAAAAAACDxTMAAAAAAAaLZwAAAAAAjOA/MGz+/ONsU27Gtolzfr0e56KgMeXigG35IUkB+wvYlfIBTS7nf4t5yG9DryeJ35mkeqNpm1ozZFt+TC0BfwjxmjV9tunsauyT8UhSlvpmuuovXNIo26ZebfHbSf1JSgOaXNTqm7hoG0mKY/8YyAVM7pB7JOTWjgKigMeIooDjkiTl/UMi5FkTMqgo5NEWco6Cpr+Pwp60UhKwraAhBdyPIdsJOf4sDYgCxvObzodZErCxgDGFbCekSQLeEWH7CnvXJAHHVm/4be2YqNnmrvt+EjQm/PF4zvITZnsIe2XF8upsD+EZm7c45Ge0Z596dsBsD2HvTNdnewTPWP+W4dkewl754W0/C+r45hkAAAAAAIPFMwAAAAAABotnAAAAAAAMFs8AAAAAABgsngEAAAAAMFg8AwAAAABgsHgGAAAAAMBg8QwAAAAAgJEPDdsCltmVQsE2cey3EwU0vwl9kgsYdyH2UT6X2SbNEtvUGk3bTDd9I6UBjdSa9yepp9Vft7aKb8olP562oh/3vI5p2wRc+n1syhZp6v9S+CTzI280/G2ZNFv8eLJW20hSvTbHNqXCUtsUSn4CRLE/tijv78co5EESh82SXOS7XMim9tWk9I8aZQFNuo+a34QhjY+ykB0mvsmSgH3VfZOk/pktSUkjYFvNgHEHHH8asJ3RyTHb9I8P2WZhZ49t8qE/JgRMynLm7+3uAp/pAwCevXhLAQAAAABgsHgGAAAAAMBg8QwAAAAAgMHiGQAAAAAAg8UzAAAAAAAGi2cAAAAAAAwWzwAAAAAAGCyeAQAAAAAw8sFhIbJNnGW2SbPUNpHfjCSpkI99E/vPB7K0aZvJamKbJPNNIfbHP7fNX5b2StilqxT9OcrHfltR3l//VP7CTVdb/XaySdvEoZPkdyiX82PKBZyjQlwP2FvDF82pgO1IiebZJt/Wbptcwc+jXOTnUS7kIz2/GaVNfz9K0vYdfbaZmp62TalYsk1Liz9HrS0F22Rp0TZRUGOT33QBpzIJON9Z0++wUffbSRv+mZ00ArbTDHuOpKkfd5qGvP98M1Wr2uahvgdt04xGbVMKuB87Cv75IIWdo0bim4mA6w8AwGzhm2cAAAAAAAwWzwAAAAAAGCyeAQAAAAAwWDwDAAAAAGCweAYAAAAAwGDxDAAAAACAweIZAAAAAACDxTMAAAAAAEY+NJxu1G3TTFPbtBT8LiulQtCYlGU2qddrfjMBuyoXfdPR4sfdUvKfV8R5f45yceQHJCnO+S5VbJtGwOcsIWPKaZ5tqtOTtinm/VwLFnQqA85j5seUz/v5GOf8dpLUX7PJ2jLbSFJbxwF+TAU/t6OA8xjShNyQAadaWeBng7nIn8vNW7baZuuOHbbp6mzY5vjnlm1TLvoHUtKo2KZeb7WNJDVrHbbJ6u22SRsl2ySJH0/a8BMgTfxEaiZhz5E04N3WTP3+0oBmcGq7bfZbNmqb/Vf4eb1jw4htRvrC5kiW+Js7CjjdYW82AABmB988AwAAAABgsHgGAAAAAMBg8QwAAAAAgMHiGQAAAAAAg8UzAAAAAAAGi2cAAAAAAAwWzwAAAAAAGCyeAQAAAAAwWDwDAAAAAGDkQ8Msy2zTWvKbaysWbJOkSdCYkjS1TcXvTu0tPqqUItvEsW8U1MQ2SaOwzz1S+f3lC/66tZb8OSrEfo4o7bFJY7TDbyYfdvy52B9bFHC+s4DtVOsbbdPR8aht4oBDq9b89ciyot+QpGZ9g22Spr+2zaTFNoXSIttE8tdDqR9P2gh7jnSX59jmuQceZZtl8wZss2nbBtts2TpomwP3n7ZNuThuG7X6RJLSxD9H6vWybabG/Q6rw122qdX93A54PShLA+aapFzqjz9L/LYadb+v7g5/3Vav9vsqFP09Mt7S8I2fapKkLOB815tN20zINwAAzBa+eQYAAAAAwGDxDAAAAACAweIZAAAAAACDxTMAAAAAAAaLZwAAAAAADBbPAAAAAAAYLJ4BAAAAADBYPAMAAAAAYORDw+7Wsm3a4qJtsjSxTTEfBY2pXCrYpuSHpHzI/iL/OUOWj/12Yr+dKPLbyRfDLl2p6M9RyKaiLLVNLufPY1z28yiKKn5feX9ckqR8wMEFXLdGOmmbWAO2iXKZbZqJH0+x6O+jQvawbSQpJ39ta/VW2zSTw2wTB9z/WaNpm6Tpt5M2/XFJUhqwvzTx2+pu6fDN/ofbplr1c61vw6Bt8uUh21RaR20jSaVK1TbFwpRtyvOmbdM5199HSdM/R9Ms4Lke0kjK/G2rNOC+nZr2467V/Llu1P18LBT9eOqJv48GJv11laQk4FzmAppG4PsfeLyF8/3PDc9GC5aunO0hPGON+o7ZHsJeydXWzvYQ9kqhtHm2h/CMRfmu2R7CbxXfPAMAAAAAYLB4BgAAAADAYPEMAAAAAIDB4hkAAAAAAIPFMwAAAAAABotnAAAAAAAMFs8AAAAAABgsngEAAAAAMPKhYTHObFMIWIrnC7FtSsWQEUmR35SSnB9UFNDEsd9ZFgdsp+BPebno91UM2I4k5XL+uuVCxl0s+yYOGFMU+SbgegRNNkm5gPmWy/kxJVW/v6ywwjbV5irbpFnBN01/XSe23WcbScrVRmyTlDptUyo1bdPQTtvEuRbbNBuJbbI0tY0k5QLmUpT3c6RZq/mmUbdNo+bPY3XKPyQna/6ayU81SVLPvCnbzJvTsE25q+R3FnBrF4t+/keRnyP7lj/+tna/lUx+rmWZf64FTEcN7/QnO5+ETZJyzj//8wHvmlrAzxoAAMwWvnkGAAAAAMBg8QwAAAAAgMHiGQAAAAAAg8UzAAAAAAAGi2cAAAAAAAwWzwAAAAAAGCyeAQAAAAAwWDwDAAAAAGDkQ8Mo9k2x4Js4YDvNwCV9GrD2L8RF2+TyAYOKI5vkA5pinPkmSvxwcgFjlhSXS74p+mkQRQEXJRfQBJzrKKDJBZxrKWxIIdOtpbXTNql8k6V+X1ni58jIji1+PLU2vzNJSVKxTW1gwDaN5iY/ppYVtim2LrRNrlDz+4pHbCNJjckJ2xRLdduUWhu26Wzx83aozx9bS9FPpHlz/L4qrQETUlK56LeVi1ts8+gmf46Gxv19NLezapsVS/y+8rmw4/9dCnmyZQEPklzsn2z5gBd7pRL2Y0I+70eeBrzbmpm/bgAAzBa+eQYAAAAAwGDxDAAAAACAweIZAAAAAACDxTMAAAAAAAaLZwAAAAAADBbPAAAAAAAYLJ4BAAAAADBYPAMAAAAAYOSDw7xPo0LBNg0lfjtR2Jq+kI9tky8UbZPLRX5fcWabYpz6Ju+PLV/2Y863ttpGknJxyLn0x6ZCwPUPmCO52J/rgMuhKKCRwj4d8lctrEn81FbW8Oc6q/sNtVbm2aaypMsPSFJtqmabZGCDbdLakG2q6YBt8pVttpm3wJ/HfBRwQSQ1m/7qlit+JoXM20w+Khb9sQU81pSL/HZC5qwkJdN+3GnAs71S9uc6GvXzKBfwAIii4NfbPhFybRXQjE2WbbN2gz/X3R1Tfjilpk3G06rfjqTqpJ9vtYB7rZkLedoCADA7+OYZAAAAAACDxTMAAAAAAAaLZwAAAAAADBbPAAAAAAAYLJ4BAAAAADBYPAMAAAAAYLB4BgAAAADAYPEMAAAAAICRDy6jzCbNgM3kotg2hUIhYEtSnPPDz0X+84FSLvVjyke+KZV8Uwloyv74o1zg5x6xP98q+CaX9/vL+VMU1vgkmL+yUuqnttLEN1ndbyirBtwlmd9Z1vRHllQDBi0pDjjjbZ2LbVNTwzbz5435fbX4c5QLeB6FKhYDJmUQP6YooAl4jARJUn9fj/WHzZF0g59vxaafR12L/ZgWHxbwrIkD7uzMN5nCrn2j7rtawP3f1uaPLWnWbJOL/D1SLPgxj4z4MY+MhT5H/Pu4GPIjRzFsfwAAzAa+eQYAAAAAwGDxDAAAAACAweIZAAAAAACDxTMAAAAAAAaLZwAAAAAADBbPAAAAAAAYLJ4BAAAAADBYPAMAAAAAYORDwySKbBPHfi2ez8W2yeUKQWPKxX5MpXxmm0LRj6lULtomX/HjzgfsK4oCPtMohF26qBByvgOubcCQ/FbCmhBpaBcQJolvsobfUFJt2ibnp6OSxEfNgH0pC9iZpHqzZpvR6jrbLNpvi21aKwEnW2Hj9sJmW5b6rjbaCNiO31e+1d+P+ZIfT8DjWHHOD6ijN+zz0+mAR3Jts7+2+YLfXxTtm+tfr/lzPbw97Dk60l+3Tdt8f/ytbf7453T44y83/LGlO/x22qb21b0m1SN//FX5+ygNfroD/1fX/K7ZHsJeqcztnO0hPGO1rf5nhmej1vb1sz2EvZIk5dkewjO2I/Dd+vuKb54BAAAAADBYPAMAAAAAYLB4BgAAAADAYPEMAAAAAIDB4hkAAAAAAIPFMwAAAAAABotnAAAAAAAMFs8AAAAAABjBf4t1Po5tUyr4zWWZb+LAJX0xn9mmUPLjLrSUfFMp2iYfR7ZRSJP3+4oKYScp5FzmAob0u/yUxV9VKUnDtpU2A/bX9HtMa35DWeq3kwWcyMZ03TbTtSnfVLf5nUmK0422SZJh26Q1P2/Tor8fo4BzFEUBkzakkZQFzJH6WMM2zYB5lI36fZXa/DOy3FGwTVzyxx/nQu42qWVuwLYCxl2vJ7YJuI0UpX4804MBz/WxTr8zSW3lCdu0dvomCni6NRv+2MbX+/NYHfDXY/NI2W9HATeIpLwC3rUBb5Io/McSAAB+5/jmGQAAAAAAg8UzAAAAAAAGi2cAAAAAAAwWzwAAAAAAGCyeAQAAAAAwWDwDAAAAAGCweAYAAAAAwGDxDAAAAACAweIZAAAAAAAjHxrGuZDUN7lcZJtCPg3Yl1Qs+f2VWsoBTdE2cd6PW1HAZxGFgPOY99sJOI3B3e/yE5QsoEkCLn+aBO4v8XvMGk2/v6YfVK4Q2yap1m2jgH3V6tO2GRzu8/uS1F7y5ygfr/T76/fbmRjcaZtiseqbgDEXKv56SFKh5Lvy3JJtmjU/KesN31TrAc2gP/5i2d/Z+YBjl6Spab+/csnvLwp4Ho2O+n21t/nttMzz86jeGnA/SioXAh5KsT/+4VHfjI4UbLN5xL9HBgc7bDOd+nnt3467+OuWZv5ZG0XBP5YAAPA7xzfPAAAAAAAYLJ4BAAAAADBYPAMAAAAAYLB4BgAAAADAYPEMAAAAAIDB4hkAAAAAAIPFMwAAAAAABotnAAAAAACMfGiYKdonTT72+4oLYWv6Qqngm0rR7y8fsD9/aFLBn84o9vvKBewrF/ixR8iwQ4Rc2zTzg0oDplySBYwnTXwkKcrqtkmbqd9QyEWJAs5Rw+8rZI60ljttk+s83DaSFKV+TOXWit9fqWSb0f4h2wxND9omy0ZsUyyN2UaSOjqmbdM21x9/qcs/a0q5gOsfMmfl538SMNca9YC5LymOfFev+SZX8C+AJPHzP/GnSPmivx/jUtNvSGHPpLExP+67b+u2zfhQR8CAApLMX49M/sBCmv8/9EnIuy1g3AAAzBa+eQYAAAAAwGDxDAAAAACAweIZAAAAAACDxTMAAAAAAAaLZwAAAAAADBbPAAAAAAAYLJ4BAAAAADBYPAMAAAAAYORDwywKiAKaKKCJ4zhgZ1KhWLBNPuTjgWbNN6Wyb3IBOws5R/tmM5KkJPXnMonabdPW2WGb3l6/r+55iW3yARdtcNCPWZI2Peb3N5712abSUbJNuVK0TX6JH0+p7K9uHHDnTk2G3d5bHqvaplbdaZuFKxfZ5shT/D376AN+Hm2890HbdM6r2EaSlqzxY9pvZWqb1g4/b0Pux4kxP0d29k3ZpjY9bRulI76RVJ9Ya5ssGbJNUjzSNvstXG2bkZHMNv2P/Ng2c9q32kaSWlv8tS0HvCIWLfLX5OEB/2xLUj8fG/LnyG9FSgJfNiFZ3g8p/OUGAMAs4JtnAAAAAAAMFs8AAAAAABgsngEAAAAAMFg8AwAAAABgsHgGAAAAAMBg8QwAAAAAgMHiGQAAAAAAg8UzAAAAAABGPriMMp/kAprIr9dz+ThoSArpGg3fFAK2k/enKhf5zQQcftAnGgG7kiRt3lm0zUGrB21z/mt+bpvJWodt7l672DaLuh+wzenPHbGNJH3/F39hm3vWHmKbc87+hm1yuYptNmydb5upSZtoqlqyTW2nP9eSNFxYZptK2c//V7/iBtscvuYx29x819m2+UH3mbb5k5O/aRtJOmT/e2zz6OZu22zfWbBNV1vNNgcfO2CbwfEDbfMft7zBNqv3f9g2krRp8wtsc999iW0OObRum4P29/f/l/71WNuse3S5bZb3bLGNJPUs8++2Qsk/lZfvP2WbHdv8A2Cgzz9r/NXYt6KAl1LqT2Pwuw14vGKL/1nn2ainvW+2h/CM9R42Z7aHsFfa4oNmewh75Zc3/v7N7aGhtbM9hN8qvnkGAAAAAMBg8QwAAAAAgMHiGQAAAAAAg8UzAAAAAAAGi2cAAAAAAAwWzwAAAAAAGCyeAQAAAAAwWDwDAAAAAGDkQ8Moi2yTiwKagOV6nI9DhiRlmU/km6hQ8PuK/MADTpFCjmxffqKRJIlt+rf12aazfrdttm4+3jbbH7WJDu3cZpvH7l/uNyTpF79qtc3k+D22mRfdZJv7HjnLNrfdvcw2cW7UNu1tTdtUctO2kaT5c0q2OfnwB22zsLTeNnf+aq5tDllylW1+WTnYNts3B9yQktbMGbTNN7//p7b51R1+3u63pGyb//m679pmfrefjxvWHmWbkf4dtpGks0+6zTbPXdFhm1xuyDZf+tYJtrnz+rW2ibbXbPPglv1tI0nD49tt07PUP2ubTf90L5f8vZ2LUtvEAS8kP2Ip4BUqSUpDuoBbkk/0AQDPZrynAAAAAAAwWDwDAAAAAGCweAYAAAAAwGDxDAAAAACAweIZAAAAAACDxTMAAAAAAAaLZwAAAAAADBbPAAAAAAAY+dAwjnwTBTS5fOybOGxNH6VNHxUCthWyv5BjC2hCthMiC+yigDKtpX47Q4ltenOP2ebwJX226cmN2GbjUKdtJKmt4E94W2fFNsXxgm3i+pRtuiqDtmk0/W05NdFqm4lat20k6cglt9vm5OXX22ZsZ9k2hfGabTqn/Rx5xSH/YpsfP/A620jSYM9DtlndO2ybg186bZtDl/pzPdrv78evfPcE29x0iz+PisPuo2zqONu89WX/bptv/OxU2/ziJ37+ZzvW2Saf+fPYrLXbRpI23F/0zcP+GZlk/nncbPp3ZF5+X1nk348h75E08GWTBWwt6PUXcI4AAJgtfPMMAAAAAIDB4hkAAAAAAIPFMwAAAAAABotnAAAAAAAMFs8AAAAAABgsngEAAAAAMFg8AwAAAABgsHgGAAAAAMDIB5eZT6KAzeTigO1EATuTpCz128oXA3boBxVybCHRvvq0Img8klor/lzuHCjZZtu6Ftvc2nesbb566yrbLGq72zYn77/WNpJ01n6fts3N/W+0zUMPHWWbiTF/O3XWttimlB+zTRpw526aPsJHkqpjfjbd/OvVtvnx/StsU6tP2+YFK/39eOz+m2xTHa/bRpKmdiS2eX7Hv9jmge3zbfMvP1jmt/OYv0em+6dsE9X6bDPn4MW2kaSje++yzY23Hmyb713njz/ZcI9tcs2qbdKAd00chz2Rk4a/4bJ6yMvNP49zmW+igDdAEvDSzsvP/SzwZZMEv5XM/kJ+2AAAYJbwzTMAAAAAAAaLZwAAAAAADBbPAAAAAAAYLJ4BAAAAADBYPAMAAAAAYLB4BgAAAADAYPEMAAAAAIDB4hkAAAAAAIPFMwAAAAAARj40jHKZbXKRb6I48k3mtyNJUeS3pYD9hcjkx5SlvkmChhwy5rDjai3VbbOxVrLNh398sm3q+R7b9M4ft810vdU2/3rH4baRpM6Wsm3q2WbbPLBugW3aChO2qaYF20zVumwzsXXQNpPVh2wjSXPnprb5D+1vmzj1n8UVYn+PfG2Lv7Y/uN3P69H6JttI0sMPrPbbmlhjm/6d/jzmpqds06Ydtmlt+vM4GbXbZnR0u20k6Zs3+Htyff9S2ww/9oBtyrUx24S8Iepp0za5XNgrMJ/3920j8XMyYPorF/D8z9KA539UtEkSJX4z8udRkpqZn/++CHvXAgAwW/jmGQAAAAAAg8UzAAAAAAAGi2cAAAAAAAwWzwAAAAAAGCyeAQAAAAAwWDwDAAAAAGCweAYAAAAAwGDxDAAAAACAkQ8No8w3cc6vxZM0sc3Y9FjIkCTVbVGt+YEnRd+kSm1Ta/rxZAHHP6+z0zatrWXbSFK97o9t1cp5tolL821TbvrrtrX/EdvUqtO22W/RcttIUqUS2yaLRm2TZiW/s8g3LQEfV7U0/VxrbN5hm/r6R/3OJA1vrNgmqfhj61lxoG3yJb+dVvl7pDrk53W+OW4bSRoY8k0x82OaE3D/TyZN26SRn7NxwKO7lPjjr26Yso0kPbTBj0npVpvkA57tWeR3lQv43LeQ+XNUa/rrIUm5fMD+8kXb1EOuf8A7Ihf58RQD3llJzl/XXBb2GXs+8seWZAHv44AGeKLt29fO9hD2ysi26mwP4RkrtrTO9hD2yo6+ltkewl6Z3jTbI3jmosbv57kOxTfPAAAAAAAYLJ4BAAAAADBYPAMAAAAAYLB4BgAAAADAYPEMAAAAAIDB4hkAAAAAAIPFMwAAAAAABotnAAAAAACMfGiYBTRpNm2b5sRO27SVpgL2JuXS1DZ9Yw3bbIn8dtKAM5XL+e30tPoNRe3+bE/7w5Ik5ab8/irtC/x2cnXbDE35a1ufGPf7aka2mRgZto0kTU1M2qattdU2HZ1dfmc5P+5Mvmk2Yr+dlg7bJJm/ZpJUSBLbRImfR1sma7aZnvb7ipv+2naXKrapxGXbSFIU8BliHNC0VPx1U8D1r9WafisBz5o478dcSv2+JKne8Nc2y/z+KgV/3RpZ1e/LH77izJ/rcsiDXdJU4h+4zZyf24V8yTZRwGu50Qy4txP/HokDzmM+8udRkiIVbJOL/JiigPcxAACzhW+eAQAAAAAwWDwDAAAAAGCweAYAAAAAwGDxDAAAAACAweIZAAAAAACDxTMAAAAAAAaLZwAAAAAADBbPAAAAAAAY+dAwyWq2KUXDtinGU35ntShkSMqNFGxz4OKVtpm/vc82O0dGbLMhbvrt9NRt01oYtY0mEt9I6hwr+03132ubeGzcNoXatG2WJ/4cZUlqm2ibv2aSlOZj2+SKJdtMFIu2qef9dqrFFts0c/6aDU346zGU9/uSpHmLj7TNia88wjYvPqVqm4cfW2Sbz/zTetvcv+PHtplT9OdRkjqL7bYpB1yT9oD9tbb4OZLL+c80p6v+Popj/xyN82HP2nzqx1Rr+DEp89spFPxzPWn451+WZraJAs6RJJUy/xxppH5Mk9mkbfKxfy0XA55Z9aRhm2rTv9fTzD+PJakQ+XMUB3xen8lvBwCA2cI3zwAAAAAAGCyeAQAAAAAwWDwDAAAAAGCweAYAAAAAwGDxDAAAAACAweIZAAAAAACDxTMAAAAAAAaLZwAAAAAAjHxomGaZbSariW0KXT22SaL2oDFN7dxim9z6TbbJ6n7cvbXUNp3lit9Xz/62acv8vka3PmAbSYoH/TkKuLRKFPntKGBDIfyulKX7aF+SsoAdTiZ+fwNN34wEfFzV1d1mm4nIj3lreaHfmaRVBx5gm1NPusk2Rx30oG3uvetPbDMyOmaboaF+24xF/j6SpDltnbbpbfPPrXzsm7hQsE2pEvBYjvxEqtX8cy3009NCwP6yKLZNvdawTSPg+ZeL/XmU/PErDZsjuYBnUsi5LGW+qjb9OaomvikWiraplFpsM5XWbCNJ40ndNvnMn8hcyAsAAIBZwjfPAAAAAAAYLJ4BAAAAADBYPAMAAAAAYLB4BgAAAADAYPEMAAAAAIDB4hkAAAAAAIPFMwAAAAAABotnAAAAAACMfGhYzJdtk+QqtslqmW3Kc9qDxpQuXmib/qE+v6FKySabG1O2Wb241zbzuubYpu/Rh20zMlK3jSQ9PJXYJs77z1BWz++0Ta7dH9vI+IRtquPDtukfn7SNJLUW/RSf2+bnbTVNbZN1zvPjafNze0GHH/Mq+ePPNoado00b/DW541f++i8o+eZXt/lzNL7z57bpLBRs09PZbRtJWrTQP0cWzl1km6Tqn20T41W/ncTfs8WyP/44jmxTq/l5LUm5nD+2Uj4O2I7f11StZpt64s9jPufHkyrs+FN/+MrLn+8k8hvKB+wrDvjcu9EIOI85/x4pB7z7JakUF20z1fTXrR75cQMAMFv45hkAAAAAAIPFMwAAAAAABotnAAAAAAAMFs8AAAAAABgsngEAAAAAMFg8AwAAAABgsHgGAAAAAMBg8QwAAAAAgJEPTyNblIvttilUSrapT0wHjagS+THtt3A/20xNjNimY9FC2/TMX2CbuBDbprhgsW02be+3jSRtTzLb5JOmbRbk/bleuWKVbUY2b7HNvDZ/jgptfh5J0n7z/JwsF/1tEMe+iebtb5tHtw3aptLj51FuYsw2h63usI0k1cr+Hjly8WO22bz+ENsMjc+3TfecebaZV2qxTW9Hl20kqaut0zYtpYptoor/LLJQLNhmfHTKNvW6v2fzRX/PVgLmtSQ16oltsiS1TakUcG9Xy7aZmKzaZrrhz1EuCvv8OEr9uWyqYZs4YDtx5OfItPyx+a1IuYDx1Oph7+N8wFzqyPv7tp4Pe7YDj9fT7X/+eDZqJDtnewjPWDnvf658Nlq6yv8c/2w0Ueib7SE8Y7X1/ueB32d88wwAAAAAgMHiGQAAAAAAg8UzAAAAAAAGi2cAAAAAAAwWzwAAAAAAGCyeAQAAAAAwWDwDAAAAAGCweAYAAAAAwMgHlwF/J3oW0KSJb9oq7T6SVIjbbFNsKfsN9fTYJIr8wQUkShP/F4dPTEzaZm67P3ZJyjXrthkeHbPN4Lgf09KRTbZZ1O4/r+kKuK7x/JJtJKkQ+/3Va35SNuq+iSe222ZOzl+Pwb4J25Q7DrbNWcf67UhST8tdtlmQ+Gs7Ojltmz877gHb3LzkNbbZtH6rbebmttlGkrLE37jN6YZtcsXYNpXWgm0KBT//J8b9ua5O+bkW8lyTpFLeH1vTnyJlAVFrp99OseSf66Pj/vgnazW/M0lR4p8jxbRom1rkjz9NfVORn0dpwEu7GvlzlM/CPmPPB9xH9XTKNo2wKQkAwKzgm2cAAAAAAAwWzwAAAAAAGCyeAQAAAAAwWDwDAAAAAGCweAYAAAAAwGDxDAAAAACAweIZAAAAAACDxTMAAAAAAAaLZwAAAAAAjHxomGa+yQKipJn4faVhw8qU+qbh9xcXY7+zKGA8Acefy/nPK/Zfvso2K1f6RpKqtWnb1Os12yS1KdtEkzts0xnXbRMHXNftOydtI0npmL/+paa//lHA/I+K/lyX2/3czhUCjn+4YZuvDxZtI0mV9nbbRPEJfkOZv0mSzI9729h9tpmqj9qm1u7nmiTNyfvrX0oKtkmr/rqp6c9RvuDH09HVYptS0Y95esLf+5JUD3iORsVh28yb658jjbo//olcp99XsWSb8njAs1/S+LSfS43Ez+32gHu7mfhmLGA8UeqPrVVlPx75ay9J9ZzvClnA5/UBzxEAAGYL3zwDAAAAAGCweAYAAAAAwGDxDAAAAACAweIZAAAAAACDxTMAAAAAAAaLZwAAAAAADBbPAAAAAAAYLJ4BAAAAADDyoWESEmU+SZt+S80kDdmb8lHkt9Vo+A3lYp+EnKnMn4CQ488F7CyX+WOXpJZKm23a232jpMsmA8Nl29Ry/vhrtTHb5DsKtpGkfMGfy3LOb6s+OWKbWrNqm+mqn49xNm6b3uKUbRppl20kqdQyzzbllopt0jRkbvvxtHZO+yhXtEn3HH9cklSv+es2umPYNvm6n2tp09+3WcAzq9zhr0cp4B6JcgEPbUnR1IRt2kuTtpnb7o9/YtIf/9B4zTYt5VbbdBbCPj8uTPkxhczb3rn+fE9ONW3z0IP++tdqfj5ONwOeR5F/P0pSa+bvyUbkj62e8w0AALOFb54BAAAAADBYPAMAAAAAYLB4BgAAAADAYPEMAAAAAIDB4hkAAAAAAIPFMwAAAAAABotnAAAAAAAMFs8AAAAAABj50DDLfJOGbCj1G2o2k5AtKc3Htkkafn9Zzo/c70nKRb5JEj+eQs43URxwQQIlkf8MJZfzZ2Bed7dtQubR4JDf1+pjj/YbkvTcY55nm9vuu882P/zPn9pm+/ZNtulta7VNyDyarDdt09XZ6TckaV7R328HHLjUNqsWLLBNnPdzra+vzzb33HuXbaKQEympVKnYZk6vf0ZUxydsMz1Vs00zLdjmsKMPsc2aNQfa5u5f32kbSbrluu/ZZnGXP98h9/94zc+RUrndbygL+Wx4LKCRliwZtc2c9oB3TcC+BgKef0nsm3LJH3+54Of+ZKNhG0mqJv6ZVMz8HGmRn/8AAMwWvnkGAAAAAMBg8QwAAAAAgMHiGQAAAAAAg8UzAAAAAAAGi2cAAAAAAAwWzwAAAAAAGCyeAQAAAAAwWDwDAAAAAGDk9+XG0tQ3US6xTb3WDNpfsRAHVJkt0rrfXxZwqvIBw8nSfTOeXDHyO5MUZX5/kt9WGvsmiv0JyAd8XDNZ82Neu3XEb0jSAzt+apsf5P3Ejc57s22SrVtt0z88bJu4UrFNmvMnMj89bhtJyjX9Pfnj+++3zVmbN9lm//ZW2+zo326bjq4O2wQ9kCSNbN1om8ZQv21a8v48zi36e6SR8+fo5uu/a5tNj+5vmzjgnpWkua112xTism3GJ/2zbbreZZtisWCbJBm0zYKOCdtIUpu/JVVr+GZozI97atrP7bYW/zyu1adsUy7669EV+FPC6EjJNhN1/2yvKuBEAk8wOeqfv89Ggy1zZ3sIz9hdRx0820PYKyff9JPZHsJemZ4zMttDeMb2i/z74PcZ3zwDAAAAAGCweAYAAAAAwGDxDAAAAACAweIZAAAAAACDxTMAAAAAAAaLZwAAAAAADBbPAAAAAAAYLJ4BAAAAADDyoWHa9E0z9U0cZbbJkkbAiKRGveCjgv98IGoktsmy2O+rGPl9+USNuj+R+cDPPaLYH1uc+WuigONv+l1pw9C4bW7b5ifbzke3+Z1JSgsB1+2M5/hm69aAZrtNOru7bXP4ySfb5oFS0TaD111vG0lSf79vuubY5Pp77rZNvneRbeYvnG+bOOfvkdGBPttIUrVvs206S/7G7Wr1z6NcLuBe04QfT6ffzujWO22zfWw6YDzS8nnttqk1/DXZMe7HneT9PduW99e2t7Nmm9BPj/uG/bhHJlptE+XabFNu8e+/1hY/R9oCttPW4o9rbMomkqTJmv9xYk7eH39RYe9/AABmA988AwAAAABgsHgGAAAAAMBg8QwAAAAAgMHiGQAAAAAAg8UzAAAAAAAGi2cAAAAAAAwWzwAAAAAAGCyeAQAAAAAw8qFhM018k6S2iaOA9XrWDBmS6rW6bfK5km3SxB9bkka2yQJOZyHvt5MmmW8Cz1Fcim2TBVzb6clx26zr77PN3SNl24xnFdsoCpy6iZ8jqk0H7M9vp62zwzbPe+XLbdN/0EG2mUr9vVao+HMtSc0fX2+bbMNG21TrDds8vG6zbfL5Ntu0t7XYpl71c1+SAh5bqtX9PVlr+A2Vi/vm88qJpt/XxoB5vaMccH9IGq5P+Mg/RjRa8FFcnLRNb85f29qkb8YCDkuSssjPt55WP//bSzttUy74uZbL+abe9O+aofGCbYaHW20jSfm8f9cmUcCxBdyPAADMFr55BgAAAADAYPEMAAAAAIDB4hkAAAAAAIPFMwAAAAAABotnAAAAAAAMFs8AAAAAABgsngEAAAAAMFg8AwAAAABg5EPDJG3appkktokjv8tcFLamb9YatmkU/P5iRX5fdb+vKPXbiUo2UeQ3o2Yt9ZGkZuq7rRPTtnlgaNI2U3U/nmnFPkr9huLqiN+OpLxqtqlP7mebrHuhbRYcdJht1lcqttm0aZMfjy0kFYohlXJHHG6bZGzUbyjy13btsL+22+99xDbLu9tts2Rul20kabo43zaNxrht6qNTtmkp+GdbI/LP0b4Wf1/vyPsmjQu2kaTROOB5E3Brq+gfbv7opW0BVaMZ8BzpDHjYSiom/jnS2iz7DfkpooGGf2c1AvYVxa22KRf986i1LewcFfL+mtTq/smV1ML2BwDAbOCbZwAAAAAADBbPAAAAAAAYLJ4BAAAAADBYPAMAAAAAYLB4BgAAAADAYPEMAAAAAIDB4hkAAAAAAIPFMwAAAAAABotnAAAAAACMfGg4Xc9s0xG3+A0lRZvEfleSpCxLbNNo+v1FxYJt0sTvazzfsE02OW6bfFtsm0alzTaStHF8yjaPTkW2qZU7bROV2m1TrI3ZJj85aJvXnvxc20hSsein+L/dcrMf0+Ze24z86jbbZKmf3P4sSvKXTIG3kRo5/xlas+rn0Wtf8DzbFDN/P/7b9XfY5v7Bum02DWy0jST1lJq26Sj7cQ/V/DnqzE/77cT+OTLuE51wzOm2KeZLfkOSrv/ZT21TqlRsk4v2zee1IXO7kPNVLZ0M2t/glH9uj2nYNgta/PNoRat/ArQU/DzK5I8tzvkHST6gkaQ09c3gsL8mA32tQfsDAGA28M0zAAAAAAAGi2cAAAAAAAwWzwAAAAAAGCyeAQAAAAAwWDwDAAAAAGCweAYAAAAAwGDxDAAAAACAweIZAAAAAAAjHxr2pEfb5uVzT7PNyNCwbUbXN4PGVCj4pr21ZJuhybptRlSzzc7KoG3Wj/zSNlvO7rJN9rLTbSNJ9e07bNMc9NckLhX9mAp+OjVH+m2j0VGbVOfN8duR9NIjDrfNqvl+W+u+813brB7os01zxJ/rWrNhmzSyiaJyi48kPdaz0DYHvf71tim3d9gmzZdt89dvnGubX17/Q9t0ZhO2kaRClPgml9km7gx4nKb+88pc4ufjK059pW3WLDvENg/+Yr1tJOn5W863TWW62zatbf4c5aPYNn2TVduMVqZts6O5xTaSVMuuts3rLvTvraUL/fHv2L7NNqWCP/6D18zz++oft829D/l9SVI14HYbq/n7aPNYJWh/wOPt99AJsz2EvfKTiwJ+JnqW+dtPfXK2h7BXvrrfmtkewl45acefzfYQnrH2N/4/sz2E3yq+eQYAAAAAwGDxDAAAAACAweIZAAAAAACDxTMAAAAAAAaLZwAAAAAADBbPAAAAAAAYLJ4BAAAAADBYPAMAAAAAYORDw8XDi2wzPlW3zX0TO2yzakl30JieM3+ZbZYM9dpmWzpkm19Pr7fNyEDRNnHaZZup1hbbZNu22EaStGmzTdo6Omxz+AuPtc26uXNt0/fjH9smqya2+dbAoG0k6Wef+axtXvvwvbY5oub3dfiShbbpLZRsM9jv52Mzy2wzrxH22diOHQO2+eFnPm+bHzembTOxn79nW0r+HM1Nh23TWvLnSJIaWWyb6cQ/KqcCttNo+jHtnPbX/55/ucY2fzI+xzaD42GvgGbBH9sBq7tsc2hxqW1a+tps83Din2u3T260zdjUPNtIUqmjYpt53dtt09/vn23Fon+OHnjQatsc/6LTbLNxk38eTzf8eZSkgZ1V24zXJvyG4kbQ/gAAmA188wwAAAAAgMHiGQAAAAAAg8UzAAAAAAAGi2cAAAAAAAwWzwAAAAAAGCyeAQAAAAAwWDwDAAAAAGCweAYAAAAAwMiHhtm0b6ZriW0O33+ubV6ae2HIkNS13m9LdZ/M10LbrCrvZ5vrC7faZsPwXX5AzYZvJid9I6lSabHNc884wzbjRx5hm7GA8eTLJds0r7veNsnaRwP2Jo01m7apjI3YpiPy57Gzb8A2PY2abXoL++YzrTSwixJ/33YMT9kmiyPb9Cddtik2/GNpOIpts3liwjaSVJK/Jmnm78mpzF+3wXq7bZqNim1aqv4cVSbn++0Uxm0jScet9s/Io0eOsk1hzN//8tNRC7TANqs6FtnmyuwmvzNJmwKaas3fI7WAuX3wgX5un37yQbaplHba5tCDl9umrc0flyR9+/v+LEX+EQEAwLMa3zwDAAAAAGCweAYAAAAAwGDxDAAAAACAweIZAAAAAACDxTMAAAAAAAaLZwAAAAAADBbPAAAAAAAYLJ4BAAAAADDyoeFYvmqboYBmeN2obUot9wSN6aj8/raZH82zzc7coG3uaj5mm7unttsmyVLbqDrlm2LY5x7zDzrKNtu7Om2zbvNm22QhA4r8uHOHH26bdHQkZG9BRuOibe5Pmra5Z9DPo+cVSrY5OODaRraQ7qsHzDVJdzXqttme+uNP4optJtMW32StthnO5tgm6CRJysmfp7xqtik0R2yTNgK2k/nrMbfs58hQc8I2ow1/XSXpFw9usk2zxd9HB0XLbVPK+XtkQ7TVNrdMr7XN9vq4bSQpzfun25YtfjvV6cRHh8Q2ufe+O3zzwIBtOrv8/XjASv9+kKRGw497uhr0lgAA4FmLb54BAAAAADBYPAMAAAAAYLB4BgAAAADAYPEMAAAAAIDB4hkAAAAAAIPFMwAAAAAABotnAAAAAAAMFs8AAAAAABj50PA+fc820+0H2iapZbb5YfPGoDHdmCvYZn7cZZv+ZNQ2o/W6berFhm12VO+2je7wlyVKBv12JG166FYf/cAn/qqFCvi8JmRno2NBe2s8ttY2Nzdqtlnd6q9JrZLa5qFsyjadkT9HucgmGoz9eCQpKfsTPlX3O9ye+O1UGv74W0IOLguYJFnY8e8rWdRum4BppCWFnbbp6u60za8eudo2xTndfkCSqhP++XdH4wbb9JRabVPOFW2zve7v/1rAHJku9dtGknZObrHNHT/383Zhd2yb7+/YbpvJaf+umZj08z8KuNe65vj3rCQp9fvbtMFvZty/jgEAmDV88wwAAAAAgMHiGQAAAAAAg8UzAAAAAAAGi2cAAAAAAAwWzwAAAAAAGCyeAQAAAAAwWDwDAAAAAGCweAYAAAAAwMiHhgeduNY2Z53Sb5vBwSnbDI8NBo1p+eIW28zrKdnmV7cP22ZwOLPN+KhNNPxYwHaWFG2TPH+T35mkdDi1TVyNbFMs+fNYi5t+PBN+Oxr150gTfh5JUq67bpsDX9xum5NePMc223aM2Wa6OmKb1avabJMv+HN0yx1+PJI0Ph4Qjfj9zbm3apuX1Nbb5kU9vbYZ3DFgm9qIv68lqdr08zaK/D0SVSq2Ga02bLOj5s/jrf3++DefbRM1Dg+41yRph3+O5ANeJ2vLBdvUEn+ONOnPtQb9vZ/1T/vtSOq63c+R0yeX2mb/on/WDK7dYZvGhL9ppxObKM75z8+zcsAzW9LAhL9uU3U/qO1x0O6AGVrPf99sD2GvTEVhz6Bnk9Hz/c8oz0av//xdsz2EvfL/XHzHbA/hGXvPP/p3/bPS34dlfPMMAAAAAIDB4hkAAAAAAIPFMwAAAAAABotnAAAAAAAMFs8AAAAAABgsngEAAAAAMFg8AwAAAABgsHgGAAAAAMDIh4a9vU3bZOq3TbNRtM2qlQcGjenFxz3HNksXlmyTZP9hm40bq7bZsn3cNtsGG7Zp7le3TVat2EaS2lo6bLPyRb22yc31n7M8Em+xzeTIpG30UMBnOrdHvpGU2+GbBQv9+Z6q+rmdj1ttc9BBh9rm5Be/2DaF/DbbNJJf2UaSdmyv2WbjVj+3dzyW2GbZwLBtcuv9PXLcgh7bzMky20jSzoER20QBm5oz7ce9PUltc23DN0r8NasvD7iPBsOeI/OXz7XNkkO6bTPd4d8jjzQ32qY55Oej7oh9E3CqJangXyNaNj1qm7jq75FTehfZppQbss2OEX+O2iL/HG2thz1rH4n8jxM/jPz1DzjVAADMGr55BgAAAADAYPEMAAAAAIDB4hkAAAAAAIPFMwAAAAAABotnAAAAAAAMFs8AAAAAABgsngEAAAAAMFg8AwAAAABgsHgGAAAAAMDIh4bNtG6bqWrTNpXWgm1OO7E3aEyrVsyxTZqO2uYVLzvANj/92YO22d6f2SayhaQ04DONclvIlpQ831+3dcvW2WZC00H7s+YHNIsDjr+vPWx/9/rjbzRqtpmu+jHNndtqmzNOXW6b3nk2UZq22OZVZy3zG5J0zbWP2mbTtqBNWc2qn0dp5M91x/adtukJuK6S1FvcN58hpgFNI/P7Ku2rzzSbAY/3Hj+PJKl68rht7m/316Qmfz8GWRTQdJV8symgkST5d1tjaso2lYDr39ls2KYroFlYim0Toulfa5Kk4YD3VvAPHAAAPEvxzTMAAAAAAAaLZwAAAAAADBbPAAAAAAAYLJ4BAAAAADBYPAMAAAAAYLB4BgAAAADAYPEMAAAAAIDB4hkAAAAAACMfGo6N+mbDxsw2czt9MzIyGDIkfe+H19hmy44p2xx9ZK9t4rjNNuPjO22TpDaRJsu+2RGwHUnTdzZ8VAho2gu+CfkoZtJffz0aMC37AsYsSZnf3+CQ30wScOFaV/kTsG3rJtvc8J932mZi2o/n6CPn20aScjk/38Yn/ElKAy7tUFzy+6rXbPPAYNU2zy8W/YAkHVj0160ZcGz31BLb3N2s26Yv89sJGI403OKbqt+XJI3d5cetNQEPt5aA50jIM3Is4AzcGftmshmws7DzvSNgbj80MWGbR6f9fDwuYG6vKES2GQ0413fXws7RvQFzeygLubjBP5YAAPA7xzfPAAAAAAAYLJ4BAAAAADBYPAMAAAAAYLB4BgAAAADAYPEMAAAAAIDB4hkAAAAAAIPFMwAAAAAABotnAAAAAACMfGh4/x2+aS70a/HBlpptPnnHQyFD0vBowzb1xG/nuqsHbdPV4U/Vtj6/r23rfZMNZz6qFnwjSQ92+ObGyDdtsW/igM9ixv0101jTNyMB25HUXO/n210DZdusWuzP4+hGf01uvm7YNsPj/vqnqb9m17T7eS1JLS1+bm/c0WWbrTvGbPOTet02va02UVX+xr5JAfNIUlfOz9s04JYcyfsoC7m1a/7a9lf9hio3jdumvCjwOfKQP99ZR8AzIuQ50gw4j+N+POmYv/frAc9sSZoYDrjfcv4+6pzTbptq5uftzzI/npB5XQ2YkOOlgJeopCir2GZkqmqb4YDrDwDAbOGbZwAAAAAADBbPAAAAAAAYLJ4BAAAAADBYPAMAAAAAYLB4BgAAAADAYPEMAAAAAIDB4hkAAAAAAIPFMwAAAAAARj40PGys3Tav6l5om8mdE7aZ6O8LGlOjnvpGmW0KpZJtprKAzxnGE5vsjP1mhk46y0dnnuEbSVmfP5fZwJBt4rI/R1nBT6e0MmgbdTUCminfSIoG77PNqqkTbHNKdrxt+tYN2GZyq5+zS8t+rrUUC348E1XbSNJo0XctuX7bFOvX2OaRsx+0zUMvsImyfn+O8knAzSYpX/bnspY1/ZgmK35nQ35uZzv99ag86OfRecd22WbNAS22kaTN2/0zIpK/Jw8+sNs2o+PTtrnz3rptQp4QAwGPGkm6e6Ef991v+kvbRIv8OzLbvMU3VT9H8m1ttmnWA54Rk6O+kaSaf/9lfTv9dm6+LWx/wOO0fM4/E56NSn/xV7M9hGds7CvzZnsIe+Xyv/rr2R7CXnln1a+/nm0++j/eNttD2CvvC+z45hkAAAAAAIPFMwAAAAAABotnAAAAAAAMFs8AAAAAABgsngEAAAAAMFg8AwAAAABgsHgGAAAAAMBg8QwAAAAAgJEPDZek/i+gb9mywzaLuufbZvmCJUFjGt8+YJuxZmKb3sR/hjCVZba5LudP54YotY2659ok3emPXZK0eZtN2jo7bHPE8cfb5rG5ftx9P/6xbbKt222j1tg3knIdfkzLti2zTd/4tG02NsZtc9DqXtsc0bmfbeb1++NaHwecR0m3T6+3zdSEv4/KcbdtGiv8c0SjFZvMXTjHNvsd3uP3JanR6e/JtdlG29SHJvzO7g6Yt/f4JO9vWS1cOGWbkbGAMUtqL/vzveqA1bZ5yfGn2mZw8CbbZNla2+zsr9omlw87/uJQyY+prc026YYNfmcB12TJyhW2Wf6Sk21z2+bNtqnd5K+HJKkx5pu583xTLoftDwCAWcA3zwAAAAAAGCyeAQAAAAAwWDwDAAAAAGCweAYAAAAAwGDxDAAAAACAweIZAAAAAACDxTMAAAAAAAaLZwAAAAAAjHxomNQbtmk0Etu0pkO2mdusB42pNw6IYh9lAZsZTX3THoV8FuE3lDX9udbkZMC+pEpLi22ee8YZthk/8gjbjAWMJ18u2aZ53fW2ydY+GrC3MOmUb+oFf91euGaxbU6ovsA2lXVtfkBNn8xXr48krWpdYpsf5G6xzYPVgJ0lAY+czlab1E/2F+2h7rUBA5KmVQvqrAUBTU/BN1vKARvyz4hqfdo2WRLyEJUOXOmfbS87ZbVt2ltHbNPdtcg2LS3+afOdH2ywzbpNIU//MNl0wIOk6ufaouXLbHP4q//ENvfPn2+baOlS2+TbAp5HkprX/8RHO/qCtgUAwLMV3zwDAAAAAGCweAYAAAAAwGDxDAAAAACAweIZAAAAAACDxTMAAAAAAAaLZwAAAAAADBbPAAAAAAAYLJ4BAAAAADDyoeFk7NOHldnmlsEB2xxVKAWN6chibJvWgI8HHqz7cd/VqNtmU9K0TVLwY1Z1yjfFsM895h90lG22d3XaZv3mzbZJQwYU+XHHhx9um2R0JGRvkh6yxXDen+9G3LDN7Q8P2ybXco9tDotX2qYz12GbrVGfbSTp9vojtnmkOmibLPP3kUYrvsn5mTR+p78fdVjiG0lqLfgm4NA0HhDdE/DIHfVzLQu42bZv902WhJ2j1cv9c+vhtffb5v4H/fO/UC7a5pA13bZJEn+uJ6dDLqykNKCbHrNJ3DvPNguOOdo2t01P22Zk40bbhIjmzg3qcocfaps05Lkd8hwBAGCW8M0zAAAAAAAGi2cAAAAAAAwWzwAAAAAAGCyeAQAAAAAwWDwDAAAAAGCweAYAAAAAwGDxDAAAAACAweIZAAAAAACDxTMAAAAAAEY+NPxl4tfZW1oqtmmW22zz6zQNGlNb5MdUiSLbDBYS2zSzom2yph/3uulJ2xRuud02bSOjtpGkyVvu8E3A+W7LgnZnZf5yKJOP6pNjQfurPfKQbW5P/bbmd662zfRUwzb3NH9hm+64ZJuu2N9HO5qBcyTx179Z8udoYPx+21T+08//lt6CbXSzv2fVFvjZYFvwY/BpZRN+TNmYnyPVUX+z1Tb78dwccB91L/HbkaTtP+mzTe3arbYZmwx5tvtxd3XusE0h8udx4/qA4Uga3TRim5abf26b0uL5ttlw3822SeWPrdUWUsBmlAU++9OAsLbez5HG0GDYDgEAmAV88wwAAAAAgMHiGQAAAAAAg8UzAAAAAAAGi2cAAAAAAAwWzwAAAAAAGCyeAQAAAAAwWDwDAAAAAGCweAYAAAAAwMiHhhtf8XLbbD7tFNtkA4O+2bkzaExxoeC3VS7ZJh31Y1K97pvxqk1yd99tmzM3PGabV+3wxyVJo0Ojtpka8Oe73mjYJgkYT1yu2GYiYENbJvy5lqQ74qZtNrxsyDZbX+KvWzaQ2iau+8+rCgFzthb565FNlG0jSRrxJzzbOW2b8l3+HnnTaI9tXtTWa5vBHX7O1kaHbSNJ1WbAXIoim+QqLbYZmfbzcdN0zTa/avHjWXdU0TZrj7DJb/T5uZ3P/P7isn9m1xJ/jjTpnyMa8vMxW5D57UhqH/Vz5MKj19tmycJtttm83b+PCnk/nkPWzLPNjv5x29z7UNizdnrCN30lf77vLQQ+t4DH+ci73jXbQ9gr7/l//3G2h/CMfeDi38/v3f7uE7+f4/7wu/1z+tnmL8f+z2wPYS99MKj6/ZxJAAAAAAD8DrF4BgAAAADAYPEMAAAAAIDB4hkAAAAAAIPFMwAAAAAABotnAAAAAAAMFs8AAAAAABgsngEAAAAAMPKhYdbTY5t0ZNRvZ/MW21RaWoLGdPhxx9lm+35LbbP5uutsk23c7AfUEtsk6u62zeJ1D9qmtHmHH4+kw3rm+/3NL9hmpG/QNtNJapv5Tf95zWia2eY/In+uJemRuGmbxvKG39BExSad3R22WXGkvx7ZnMg2a6NNtpkenrCNJOn+gM/Qfu2TuM03y3ZM2Sa3eadtjlvgn0dz8iU/IEk7d47Yxl8RaU7dV9sDHrnXRn7O3l3wc7axImBeD/p5LUnzl3XZZsnB/tlW7fTHtjbZaJvmYMDcviPgGZH4RJIK23yzYIEf03DAO7Krba5t1hy0yDYnveg022zc9GPb5HL+ekjSwM6qbVL5c1QMu20BAJgVfPMMAAAAAIDB4hkAAAAAAIPFMwAAAAAABotnAAAAAAAMFs8AAAAAABgsngEAAAAAMFg8AwAAAABgsHgGAAAAAMDIB5eNhk2yyQnbFItF2xxz2qlBQ2oe+zzbDOX85wOFctk2jZ/+xDbZ/Q/ZJkRSr9um2Qz73KM9G7TNvEbNNr35yO8sH9sk81tRMfFNSxT6uU/AuBM/brW22qR5YtU2axc8apsp+e0E6Q3sFgQ8Bra1BGwoYN5Wp22TRv56dGzvt01Pw49HknqL++YzxDSgaWR+X6V99ZlmM+C69oRcV6l68rht7m/faZtawBwJsjCg6Sr5ZlNAI0lq2qJam7JNreGvycEH+vl/+skH2aZS8tfj0IOX26atzR+XJH37+5tsEwU8jgEAeDbjm2cAAAAAAAwWzwAAAAAAGCyeAQAAAAAwWDwDAAAAAGCweAYAAAAAwGDxDAAAAACAweIZAAAAAACDxTMAAAAAAEY+uKxN+SZObTLvOUfYZrh3fsiI9MiWLbbxI5KUZTaJDz3UNsnwsN/XA/fbZCJXsM2DYUemOwYGbXNMoWibw0uxbYqRH8/9NT/uuxoN22xJm35nktK8v7YaL/tmh9/O5K/9uHVUwLjb/PVXwLnWRMCxS9KDAY+BwYBjC9jdUFyyzXi9ZpsHBqdt8/yin9eSdGDBf4YYMtvuCZjbdzfrtunL/N6Cruxwq2+qSciWNHaXH7fWBDyTWgLmdsijbSzgDNzpn1maDHuOBLwiFPA6UnU64Hwf4sd97313+OaBAdt0drXY5oCVnbaRpEbDj3u6GvhMAgDgWYpvngEAAAAAMFg8AwAAAABgsHgGAAAAAMBg8QwAAAAAgMHiGQAAAAAAg8UzAAAAAAAGi2cAAAAAAAwWzwAAAAAAGPnQsHjzrbZp3dFnm3rxDtvs+Ma/B42pTVlQ52RR5JuA7TSqU7apPvCAbW5r1mwz1RJ26RolP/JHsmnbXBNwjgoBzWAutU2z7Mdca/h9SdKmum/yt/httSxqtU10c9nv7KqA69YW+ybgY69sPPGRpGyiYZvqZNU29W1+3v6k7pveVn89qvLHdpOatpGkrsifTD9rpZG8n7dZwINkuuaPv7/qN1S5acw25YUFPyBJesify6w9YN6GNM2A8zjmr3867uda3b+yJElTm/01ueWmLtss7KrY5ttfCxjP9Khtxif9uY5y/gHZ1TXsByQpy7XZZt0GP4/GR0PuNgAAZgffPAMAAAAAYLB4BgAAAADAYPEMAAAAAIDB4hkAAAAAAIPFMwAAAAAABotnAAAAAAAMFs8AAAAAABgsngEAAAAAMPKh4en9O2xzdotfi0+OTfimvy9oTI1Gwzb1LLNNoVS2zVTmj23L+LRt7sk1bbPk9FbbvOT0ubaRpL5+f77HJ4dts2qZH1N7R2ybm28bsc3omE00OuqvqyR1POiv7VHNC23zkuR42/RtH7DN5NbUNuVyZJuWUtGPZ6JqG0kaLfhuZ67fNmur19jmkbMftM1DL7CJsn5/P+YTPx8lKV8u2KaW+fs2m/RzTUMB29npr0flQT+Pzju2yzZrDmixjSRt3jZkm0hTtjl4TbdtRsf8c/TO++q2mfK3kQb8K0SStHZLr22el3uvbZbX/Xa2Peyfx82AZ2R7a8D8D3iv9U0FPkfa/PXvmNpgm2L12qD9AY/3vz7xidkewl4ZfUfbbA/hGbvwM++f7SHslQ+++5LZHsJeuXiia7aH8IyNf8m/D5+VPhaW8c0zAAAAAAAGi2cAAAAAAAwWzwAAAAAAGCyeAQAAAAAwWDwDAAAAAGCweAYAAAAAwGDxDAAAAACAweIZAAAAAAAjHxouyeq2admy3TaL5863zfIFi4PGNL59wDZjzcQ2vYn/DGEqy2xzXc6fzi2RH8/8+Q3b1JN+2/xGxRarDzjINie+6FjbzOmq2qaR3GCbLVtrttm8bdw2krR9c2ybZVv2s03/+LRtNtX9mA5avcA2R3Qutc28/rm2WR/7+1GSbp9ab5vpCT9vy3G3bRor/HNEI37Ozl04xzb7Hd7j9yWp0ZnaZm220Tb14Um/s7v8fNQ9Psl3+GbhwinbjIxN+A1Jam/x53vV/qtt85LjT7XNwOBNtsm01jY7+/3zKJcPe47syPs5uV/fEtusneyzTb3on39HHe6fWQfn/Hu0sMMf14MFP/cl6fbJTbaZrC70Y1Jr0P4AAJgNfPMMAAAAAIDB4hkAAAAAAIPFMwAAAAAABotnAAAAAAAMFs8AAAAAABgsngEAAAAAMFg8AwAAAABgsHgGAAAAAMBg8QwAAAAAgJEPDZN6wzaNemKb1nTINnOb9aAx9cYBUeyjLGAzI6lv2qN981lEI/HHPzUdBW2ro6Nsm5eessQ2SxdVbJOmftxnn7nSNv9x3VrbbN0ectXCpFO+qRX8BHjhmsW2OaH6AttU1rX5ATV9Ml+9PpK0qtVf/+/nbrHNg9WAnSUBj5yuVpvUT/YX7aFuP48kaVq1oM5aENDMK/hmi79nJf88rtan/WbSkIeotHqFf7a97NQDbdPeMmKb7q5FtmltGbPNd36wwTbrNtskWH3UP5Ni/xjVyw842DaHDh5um/x4wFwLeK8tikImtrSi03f/nt7oNxQwbQEAmC188wwAAAAAgMHiGQAAAAAAg8UzAAAAAAAGi2cAAAAAAAwWzwAAAAAAGCyeAQAAAAAwWDwDAAAAAGCweAYAAAAAwMiHhpM5n65VZptbBwdsc1ShFDSmI4uxbVoDPh54sJ7a5q5GwzabkqZtkrw/R6MjNtGmzX47krR0QWSbgZ07bHPrbQ/67Qz7c3TMc+bbJhe32mZ8YtA2kpT6S6vh/JRtGrE/ttsfHrZNruUe2xwWr7RNZ67DNlujPttI0u31R2zzaNWf7ywLmJOjFd/k/EUbv7Put3NY4htJai34JuR2Gw+I7gl45I76uZYFzOvt232TJmHn6IBl/lm79uH7bHPfg/75XygXbXPomm7bJIk/11NTYc/RNGBu9xXHbTNa8+f7hgfX2aZW8ddjtZbZJs757ayLtthGkn41tdY2Oxv+WRt2swEAMDv45hkAAAAAAIPFMwAAAAAABotnAAAAAAAMFs8AAAAAABgsngEAAAAAMFg8AwAAAABgsHgGAAAAAMBg8QwAAAAAgJEPDW+vp7YZi/3mGpWybR4JGpF0beabljSyzc6AjxAaJX9smYq22RT581h4zI+n2vSNJO0c8Pu768GNthkcadimkfjxXPPTSdt0tftzvb2v4ncmqX8kts107ue2WVg+1G9nvG6bR8cfts3ckj+2ubl222xpDtpGkiYC7u1Gccw2I43NtonvCLhpewMm0n3+XtO1YXNEHQGPwYBha9TflNlowLEN+6Te5x9at//ab2d+j28k6QfXTdjmymtGbDMyFnD8/pGt7jmjtikEPNc3bmzxkaS+yWnb/DL7sW3ai722eSzgOXJ37T7bLCp12CYv/3zcWg+YkJJqAffIeG69baainUH7AwBgNvDNMwAAAAAABotnAAAAAAAMFs8AAAAAABgsngEAAAAAMFg8AwAAAABgsHgGAAAAAMBg8QwAAAAAgMHiGQAAAAAAI8qyLJvtQQAAAAAA8GzGN88AAAAAABgsngEAAAAAMFg8AwAAAABgsHgGAAAAAMBg8QwAAAAAgMHiGQAAAAAAg8UzAAAAAAAGi2cAAAAAAAwWzwAAAAAAGP8fxwpByPrKAmcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "input_img = env.preprocessed_screenshot_history[0].unsqueeze(0)\n",
    "pooled_output = agent.q_network.check_pooling(input_img)\n",
    "input_image_np = input_img.squeeze(0).permute(1, 2, 0).detach().numpy()  # Shape: (60, 60, 3)\n",
    "pooled_output_np = pooled_output.squeeze(0).detach().numpy()\n",
    "pooled_output_np\n",
    "\n",
    "\n",
    "# Plot the original image\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot original image\n",
    "ax[0].imshow(input_image_np)\n",
    "ax[0].set_title(\"Original Image\")\n",
    "ax[0].axis('off')\n",
    "\n",
    "# Normalize pooled output to visualize better\n",
    "# Here, we simply scale the pooled output to [0, 1] for better visualization\n",
    "pooled_output_normalized = np.clip(pooled_output_np, 0, 1)  # Clip values to be within [0, 1]\n",
    "\n",
    "# Plot pooled feature map (you can plot individual channels or the entire map)\n",
    "ax[1].imshow(pooled_output_normalized.transpose(1, 2, 0))  # Shape: (6, 12, 3)\n",
    "ax[1].set_title(\"Pooled Feature Map\")\n",
    "ax[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0x1ceb8d6f4f0\n",
      "Pointer Addre: 0x1ceb8d6f570\n",
      "Address Value: 1987326715008\n",
      "0x1ceb5e72480\n",
      "Pointer Addre: 0x1ceb5e732b0\n",
      "Address Value: 523\n",
      "0x20b\n",
      "523\n"
     ]
    }
   ],
   "source": [
    "import ctypes\n",
    "import psutil\n",
    "\n",
    "# now read the adres\n",
    "\n",
    "# Constants\n",
    "PROCESS_ALL_ACCESS = 0x1F0FFF\n",
    "\n",
    "# Function to get the process ID\n",
    "def get_process_id(process_name):\n",
    "    for proc in psutil.process_iter(['pid', 'name']):\n",
    "        if proc.info['name'] == process_name:\n",
    "            return proc.info['pid']\n",
    "    return None\n",
    "\n",
    "# Function to read memory from a given process at a specific address\n",
    "def read_memory(process_handle, address, data_type=ctypes.c_uint64):\n",
    "    value = data_type()\n",
    "    bytes_read = ctypes.c_size_t()\n",
    "    result = ctypes.windll.kernel32.ReadProcessMemory(process_handle,ctypes.c_void_p(address),ctypes.byref(value),ctypes.sizeof(value),ctypes.byref(bytes_read))\n",
    "    if result:\n",
    "        return value.value\n",
    "    else:\n",
    "        error_code = ctypes.GetLastError()\n",
    "        print(f\"Failed to read memory. Error code: {error_code}\")\n",
    "        return None\n",
    "\n",
    "# Main validation\n",
    "process_name = \"DolphinMemoryEngine.exe\"\n",
    "process_id = get_process_id(process_name)\n",
    "\n",
    "# Open the process\n",
    "process_handle = ctypes.windll.kernel32.OpenProcess(PROCESS_ALL_ACCESS, False, process_id)\n",
    "if process_handle:\n",
    "    # base_address = 0x7FF9E8A90000 # Qt6Gui.dll\n",
    "    # base_offset = 0x006EA868\n",
    "    # offsets = [0xC38, 0x190, 0x750]\n",
    "    base_address = 0x7FFA08340000 #\"Qt6Gui.dll\" 7FFA08340000 - Qt6Gui.dll\n",
    "    base_offset = 0x006EB448\n",
    "    offsets = [0x80, 0xE30]\n",
    "\n",
    "    first_pointer = base_address + base_offset\n",
    "    dereferenced_address  = read_memory(process_handle, first_pointer, data_type=ctypes.c_uint64)\n",
    "    dereferenced_address_hex = (hex(dereferenced_address))\n",
    "    print(dereferenced_address_hex)\n",
    "\n",
    "    for offset in offsets:\n",
    "        pointer = dereferenced_address + offset\n",
    "        print(f'Pointer Addre: {hex(pointer)}')\n",
    "        dereferenced_address  = read_memory(process_handle, pointer)\n",
    "        print(f'Address Value: {dereferenced_address}')\n",
    "        dereferenced_address_hex = (hex(dereferenced_address))\n",
    "        print(dereferenced_address_hex)\n",
    "a = read_memory(process_handle, pointer, data_type=ctypes.c_uint32)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "process_name = \"DolphinMemoryEngine.exe\"\n",
    "process_id = get_process_id(process_name)\n",
    "base_address = 0x7FF9E8A90000 # Qt6Gui.dll\n",
    "base_offset = 0x006EA868\n",
    "offsets = [0xC38, 0x190, 0x750]\n",
    "\n",
    "first_pointer = base_address + base_offset\n",
    "dereferenced_address  = read_memory(process_handle, first_pointer, data_type=ctypes.c_uint64)\n",
    "dereferenced_address_hex = (hex(dereferenced_address))\n",
    "\n",
    "for offset in offsets:\n",
    "    pointer = dereferenced_address + offset\n",
    "    dereferenced_address  = read_memory(process_handle, pointer)\n",
    "    dereferenced_address_hex = (hex(dereferenced_address))\n",
    "\n",
    "read_memory(process_handle, pointer, data_type=ctypes.c_uint32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Pixel Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The color of the pixel at (100, 150) is: (24, 24, 24)\n"
     ]
    }
   ],
   "source": [
    "import pyautogui\n",
    "from PIL import ImageGrab\n",
    "\n",
    "# Coordinates of the pixel (x, y)\n",
    "x, y = 100, 150  # Example coordinates (100, 150)\n",
    "\n",
    "# Capture the screen at a single pixel location\n",
    "screenshot = ImageGrab.grab(bbox=(x, y, x+1, y+1))  # Captures a 1x1 pixel region\n",
    "\n",
    "# Get the color of the pixel at (x, y)\n",
    "pixel_color = screenshot.getpixel((0, 0))  # (0, 0) because it's a 1x1 region\n",
    "\n",
    "# Print the color\n",
    "print(f\"The color of the pixel at ({x}, {y}) is: {pixel_color}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The color of the pixel at (400, 965) is: (75, 89, 190)\n"
     ]
    }
   ],
   "source": [
    "import pyautogui\n",
    "from PIL import ImageGrab, ImageDraw\n",
    "\n",
    "# Coordinates of the pixel (x, y)\n",
    "x, y = 400, 965  # Example coordinates (100, 150)\n",
    "\n",
    "# Capture the screen at a single pixel location\n",
    "alt_tab()\n",
    "range=40\n",
    "screenshot = ImageGrab.grab(bbox=(400, 965, 440, 1005))  # 10x10 region centered on the pixel\n",
    "\n",
    "# Show the screenshot with the red circle\n",
    "screenshot.show()\n",
    "\n",
    "# Get the color of the pixel at (x, y)\n",
    "pixel_color = screenshot.getpixel((3, 3))  # The pixel is at the center of the 10x10 region\n",
    "\n",
    "# Print the color\n",
    "print(f\"The color of the pixel at ({x}, {y}) is: {pixel_color}\")\n",
    "alt_tab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize what the model sees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import deque\n",
    "\n",
    "# Example deque of tensors (you can replace this with env.preprocessed_screenshot_history)\n",
    "# For demonstration, let's assume the frames deque contains tensors\n",
    "# frames = deque([torch.randn(3, 64, 64) for _ in range(5)])  # Replace with your actual deque\n",
    "\n",
    "frames = env.preprocessed_screenshot_history\n",
    "\n",
    "# Loop through the deque and visualize each tensor\n",
    "for i, frame in enumerate(frames):\n",
    "    # Ensure the tensor is detached and moved to CPU, if necessary\n",
    "    frame = frame.detach().cpu() if frame.requires_grad else frame.cpu()\n",
    "\n",
    "    # Convert the tensor to a NumPy array\n",
    "    image_array = frame.numpy()\n",
    "\n",
    "    # Check if the image has 3 channels; if not, handle it\n",
    "    if image_array.shape[0] == 1:  # Single-channel grayscale\n",
    "        image_array = image_array[0]  # Squeeze the channel dimension\n",
    "    else:\n",
    "        # Rearrange dimensions from [C, H, W] to [H, W, C] for RGB visualization\n",
    "        image_array = np.transpose(image_array, (1, 2, 0))\n",
    "\n",
    "    # Normalize or clip the array values to [0, 1] if necessary\n",
    "    if image_array.max() > 1:\n",
    "        image_array = image_array / 255.0\n",
    "\n",
    "    # Display the image\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image_array, cmap='gray' if image_array.ndim == 2 else None)\n",
    "    plt.title(f\"Image {i + 1}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
